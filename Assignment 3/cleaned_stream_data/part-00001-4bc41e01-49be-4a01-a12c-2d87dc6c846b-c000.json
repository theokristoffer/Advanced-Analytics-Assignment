{"aid":"http://arxiv.org/abs/2504.09885v1","title":"Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated\n  Piano Hand Motion Synthesis","summary":"Automating the synthesis of coordinated bimanual piano performances poses\nsignificant challenges, particularly in capturing the intricate choreography\nbetween the hands while preserving their distinct kinematic signatures. In this\npaper, we propose a dual-stream neural framework designed to generate\nsynchronized hand gestures for piano playing from audio input, addressing the\ncritical challenge of modeling both hand independence and coordination. Our\nframework introduces two key innovations: (i) a decoupled diffusion-based\ngeneration framework that independently models each hand's motion via\ndual-noise initialization, sampling distinct latent noise for each while\nleveraging a shared positional condition, and (ii) a Hand-Coordinated\nAsymmetric Attention (HCAA) mechanism suppresses symmetric (common-mode) noise\nto highlight asymmetric hand-specific features, while adaptively enhancing\ninter-hand coordination during denoising. The system operates hierarchically:\nit first predicts 3D hand positions from audio features and then generates\njoint angles through position-aware diffusion models, where parallel denoising\nstreams interact via HCAA. Comprehensive evaluations demonstrate that our\nframework outperforms existing state-of-the-art methods across multiple\nmetrics.","main_category":"cs.SD","categories":"cs.SD,cs.CV,eess.AS","published":"2025-04-14T05:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.09890v1","title":"Probing the Quantum Capacitance of Rydberg Transitions of Surface\n  Electrons on Liquid Helium via Microwave Frequency Modulation","summary":"We present a method for probing the quantum capacitance associated with the\nRydberg transition of surface electrons on liquid helium using RF\nreflectometry. Excitation to Rydberg states induces a redistribution of image\ncharges on capacitively coupled electrodes, giving rise to a quantum\ncapacitance. By applying frequency-modulated resonant microwaves to drive the\nRydberg transition, we systematically measured a capacitance sensitivity of\n0.38~aF/$\\sqrt{\\mathrm{Hz}}$. This level of sensitivity is sufficient to\nresolve the Rydberg transition of a single electron, providing a scalable\npathway toward the implementation of qubit readout schemes based on surface\nelectrons on helium.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-14T05:33:35Z"}
{"aid":"http://arxiv.org/abs/2504.09901v1","title":"On Geometric triangulations of double twist knots","summary":"In this paper we construct two different explicit triangulations of the\nfamily of double twist knots $K(p,q)$ using methods of triangulating Dehn\nfillings, with layered solid tori and their double covers. One construction\nyields the canonical triangulation, and one yields a triangulation that we\nconjecture is minimal. We prove that both are geometric, meaning they are built\nof positively oriented convex hyperbolic tetrahedra. We use the conjecturally\nminimal triangulation to present eight equations cutting out the A-polynomial\nof these knots.","main_category":"math.GT","categories":"math.GT","published":"2025-04-14T05:50:29Z"}
{"aid":"http://arxiv.org/abs/2504.09914v1","title":"Improving Multimodal Hateful Meme Detection Exploiting LMM-Generated\n  Knowledge","summary":"Memes have become a dominant form of communication in social media in recent\nyears. Memes are typically humorous and harmless, however there are also memes\nthat promote hate speech, being in this way harmful to individuals and groups\nbased on their identity. Therefore, detecting hateful content in memes has\nemerged as a task of critical importance. The need for understanding the\ncomplex interactions of images and their embedded text renders the hateful meme\ndetection a challenging multimodal task. In this paper we propose to address\nthe aforementioned task leveraging knowledge encoded in powerful Large\nMultimodal Models (LMM). Specifically, we propose to exploit LMMs in a two-fold\nmanner. First, by extracting knowledge oriented to the hateful meme detection\ntask in order to build strong meme representations. Specifically, generic\nsemantic descriptions and emotions that the images along with their embedded\ntexts elicit are extracted, which are then used to train a simple\nclassification head for hateful meme detection. Second, by developing a novel\nhard mining approach introducing directly LMM-encoded knowledge to the training\nprocess, providing further improvements. We perform extensive experiments on\ntwo datasets that validate the effectiveness of the proposed method, achieving\nstate-of-the-art performance. Our code and trained models are publicly\navailable at: https://github.com/IDT-ITI/LMM-CLIP-meme.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T06:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.09940v1","title":"TianQuan-Climate: A Subseasonal-to-Seasonal Global Weather Model via\n  Incorporate Climatology State","summary":"Subseasonal forecasting serves as an important support for Sustainable\nDevelopment Goals (SDGs), such as climate challenges, agricultural yield and\nsustainable energy production. However, subseasonal forecasting is a complex\ntask in meteorology due to dissipating initial conditions and delayed external\nforces. Although AI models are increasingly pushing the boundaries of this\nforecasting limit, they face two major challenges: error accumulation and\nSmoothness. To address these two challenges, we propose Climate Furnace\nSubseasonal-to-Seasonal (TianQuan-Climate), a novel machine learning model\ndesigned to provide global daily mean forecasts up to 45 days, covering five\nupper-air atmospheric variables at 13 pressure levels and two surface\nvariables. Our proposed TianQuan-Climate has two advantages: 1) it utilizes a\nmulti-model prediction strategy to reduce system error impacts in long-term\nsubseasonal forecasts; 2) it incorporates a Content Fusion Module for\nclimatological integration and extends ViT with uncertainty blocks (UD-ViT) to\nimprove generalization by learning from uncertainty. We demonstrate the\neffectiveness of TianQuan-Climate on benchmarks for weather forecasting and\nclimate projections within the 15 to 45-day range, where TianQuan-Climate\noutperforms existing numerical and AI methods.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T07:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.09945v1","title":"Topological $Ï€/2$ modes in photonic waveguide arrays","summary":"Periodic driving is a powerful tool to generate exotic topological phases\nwithout static counterparts, such as the anomalous chiral edge modes from bulk\nbands with zero Chern number and topological $\\pi$ modes exhibiting\nperiod-doubled dynamics. Recently, a new class of Floquet topological mode,\nnamely the $\\pi/2$ mode, which carries four-period periodicity and has\npotential applications in quantum computing, was proposed based on a\nsquare-root method and realized in an acoustic system. Here we propose a\nlaser-written waveguide array lattice to realize topological $\\pi/2$ modes in\nphotonics. Our photonic model simulates a square-root periodically driven\nSu-Schrieffer-Heeger model and has a rich phase diagram allowing for the\nco-existence of conventional zero, $\\pi$ modes, and the new $\\pi/2$ modes.\nThrough numerical simulations of the wave equation, we uncover the unique\nfour-period evolution feature of the $\\pi/2$ modes. Our model, which only\ncontains four waveguides per unit cell and two driving steps, is easy to\nimplement with current fabrication techniques and may find applications in\nquantum optics.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall","published":"2025-04-14T07:13:39Z"}
{"aid":"http://arxiv.org/abs/2504.09961v1","title":"Privacy Meets Explainability: Managing Confidential Data and\n  Transparency Policies in LLM-Empowered Science","summary":"As Large Language Models (LLMs) become integral to scientific workflows,\nconcerns over the confidentiality and ethical handling of confidential data\nhave emerged. This paper explores data exposure risks through LLM-powered\nscientific tools, which can inadvertently leak confidential information,\nincluding intellectual property and proprietary data, from scientists'\nperspectives. We propose \"DataShield\", a framework designed to detect\nconfidential data leaks, summarize privacy policies, and visualize data flow,\nensuring alignment with organizational policies and procedures. Our approach\naims to inform scientists about data handling practices, enabling them to make\ninformed decisions and protect sensitive information. Ongoing user studies with\nscientists are underway to evaluate the framework's usability, trustworthiness,\nand effectiveness in tackling real-world privacy challenges.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-14T07:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.09969v1","title":"Semi-implicit-explicit Runge-Kutta method for nonlinear differential\n  equations","summary":"A semi-implicit-explicit (semi-IMEX) Runge-Kutta (RK) method is proposed for\nthe numerical integration of ordinary differential equations (ODEs) of the form\n$\\mathbf{u}' = \\mathbf{f}(t,\\mathbf{u}) + G(t,\\mathbf{u}) \\mathbf{u}$, where\n$\\mathbf{f}$ is a non-stiff term and $G\\mathbf{u}$ represents the stiff terms.\nSuch systems frequently arise from spatial discretizations of time-dependent\nnonlinear partial differential equations (PDEs). For instance, $G$ could\ninvolve higher-order derivative terms with nonlinear coefficients. Traditional\nIMEX-RK methods, which treat $\\mathbf{f}$ explicitly and $G\\mathbf{u}$\nimplicitly, require solving nonlinear systems at each time step when $G$\ndepends on $\\mathbf{u}$, leading to increased computational cost and\ncomplexity. In contrast, the proposed semi-IMEX scheme treats $G$ explicitly\nwhile keeping $\\mathbf{u}$ implicit, reducing the problem to solving only\nlinear systems. This approach eliminates the need to compute Jacobians while\npreserving the stability advantages of implicit methods. A family of semi-IMEX\nRK schemes with varying orders of accuracy is introduced. Numerical simulations\nfor various nonlinear equations, including nonlinear diffusion models, the\nNavier-Stokes equations, and the Cahn-Hilliard equation, confirm the expected\nconvergence rates and demonstrate that the proposed method allows for larger\ntime step sizes without triggering stability issues.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T08:18:57Z"}
{"aid":"http://arxiv.org/abs/2504.09991v1","title":"Bipartite Matching is in Catalytic Logspace","summary":"Matching is a central problem in theoretical computer science, with a large\nbody of work spanning the last five decades. However, understanding matching in\nthe time-space bounded setting remains a longstanding open question, even in\nthe presence of additional resources such as randomness or non-determinism.\n  In this work we study space-bounded machines with access to catalytic space,\nwhich is additional working memory that is full with arbitrary data that must\nbe preserved at the end of its computation. Despite this heavy restriction,\nmany recent works have shown the power of catalytic space, its utility in\ndesigning classical space-bounded algorithms, and surprising connections\nbetween catalytic computation and derandomization.\n  Our main result is that bipartite maximum matching ($MATCH$) can be computed\nin catalytic logspace ($CL$) with a polynomial time bound ($CLP$). Moreover, we\nshow that $MATCH$ can be reduced to the lossy coding problem for $NC$ circuits\n($LOSSY[NC]$). This has consequences for matching, catalytic space, and\nderandomization:\n  - Matching: this is the first well studied subclass of $P$ which is known to\ncompute $MATCH$, as well as the first algorithm simultaneously using sublinear\nfree space and polynomial time with any additional resources.\n  - Catalytic space: this is the first new problem shown to be in $CL$ since\nthe model was defined, and one which is extremely central and well-studied.\n  - Derandomization: we give the first class $\\mathcal{C}$ beyond $L$ for which\nwe exhibit a natural problem in $LOSSY[\\mathcal{C}]$ which is not known to be\nin $\\mathcal{C}$, as well as a full derandomization of the isolation lemma in\n$CL$ in the context of $MATCH$.\n  Our proof combines a number of strengthened ideas from isolation-based\nalgorithms for matching alongside the compress-or-random framework in catalytic\ncomputation.","main_category":"cs.CC","categories":"cs.CC,cs.DS","published":"2025-04-14T08:53:50Z"}
{"aid":"http://arxiv.org/abs/2504.09995v1","title":"COUNTER: Cluster GCN based Energy Efficient Resource Management for\n  Sustainable Cloud Computing Environments","summary":"Cloud computing, thanks to the pervasiveness of information technologies,\nprovides a foundational environment for developing IT applications, offering\norganizations virtually unlimited and flexible computing resources on a\npay-per-use basis. However, the large data centres where cloud computing\nservices are hosted consume significant amounts of electricity annually due to\nInformation and Communication Technology (ICT) components. This issue is\nexacerbated by the increasing deployment of large artificial intelligence (AI)\nmodels, which often rely on distributed data centres, thereby significantly\nimpacting the global environment. This study proposes the COUNTER model,\ndesigned for sustainable cloud resource management. COUNTER is integrated with\ncluster graph neural networks and evaluated in a simulated cloud environment,\naiming to reduce energy consumption while maintaining quality of service\nparameters. Experimental results demonstrate improvements in resource\nutilisation, energy consumption, and cost effectiveness compared to the\nbaseline model, HUNTER, which employs a gated graph neural network aimed at\nachieving carbon neutrality in cloud computing for modern ICT systems.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:58:34Z"}
{"aid":"http://arxiv.org/abs/2504.09999v1","title":"Multipartite entanglement based on realignment moments","summary":"Based on the realignment moments of density matrix, we study parameterized\nentanglement criteria for bipartite and multipartite states. By adjusting the\ndifferent parameter values, our criterion can detect not only bound entangled\nstates, but also non-positive partial transpose entangled states for bipartite\nquantum systems. Moreover, we propose the definition of multipartite\nrealignment moments and generalize the result of bipartite systems to obtain a\nsufficient criterion to detect entanglement for multipartite quantum states in\narbitrary dimensions. And we further improve the conclusion to obtain another\nnew entanglement criterion. The new method can detect more entangled states\nthan previous methods as backed by detailed examples.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T09:02:58Z"}
{"aid":"http://arxiv.org/abs/2504.10005v1","title":"Session-based Recommender Systems: User Interest as a Stochastic Process\n  in the Latent Space","summary":"This paper jointly addresses the problem of data uncertainty, popularity\nbias, and exposure bias in session-based recommender systems. We study the\nsymptoms of this bias both in item embeddings and in recommendations. We\npropose treating user interest as a stochastic process in the latent space and\nproviding a model-agnostic implementation of this mathematical concept. The\nproposed stochastic component consists of elements: debiasing item embeddings\nwith regularization for embedding uniformity, modeling dense user interest from\nsession prefixes, and introducing fake targets in the data to simulate extended\nexposure. We conducted computational experiments on two popular benchmark\ndatasets, Diginetica and YooChoose 1/64, as well as several modifications of\nthe YooChoose dataset with different ratios of popular items. The results show\nthat the proposed approach allows us to mitigate the challenges mentioned.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-14T09:08:40Z"}
{"aid":"http://arxiv.org/abs/2504.10026v1","title":"An efffcient numerical scheme for two-dimensional nonlinear time\n  fractional SchrÃ¶dinger equation","summary":"In this paper, a linearized fully discrete scheme is proposed to solve the\ntwo-dimensional nonlinear time fractional Schr\\\"odinger equation with weakly\nsingular solutions, which is constructed by using L1 scheme for Caputo\nfractional derivative, backward formula for the approximation of nonlinear term\nand five-point difference scheme in space. We rigorously prove the\nunconditional stability and pointwise-in-time convergence of the fully discrete\nscheme, which does not require any restriction on the grid ratio. Numerical\nresults are presented to verify the accuracy of the theoretical analysis.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T09:30:49Z"}
{"aid":"http://arxiv.org/abs/2504.10034v1","title":"Uniform Planar Array Based Weighted Cooperative Spectrum Sensing for\n  Cognitive Radio Networks","summary":"Cooperative spectrum sensing (CSS) is essential for improving the spectrum\nefficiency and reliability of cognitive radio applications. Next-generation\nwireless communication networks increasingly employ uniform planar arrays (UPA)\ndue to their ability to steer beamformers towards desired directions,\nmitigating interference and eavesdropping. However, the application of\nUPA-based CSS in cognitive radio remains largely unexplored. This paper\nproposes a multi-beam UPA-based weighted CSS (WCSS) framework to enhance\ndetection reliability, applicable to various cognitive radio networks,\nincluding cellular, vehicular, and satellite communications. We first propose a\nweighting factor for commonly used energy detection (ED) and eigenvalue\ndetection (EVD) techniques, based on the spatial variation of signal strengths\nresulting from UPA antenna beamforming. We then analytically characterize the\nperformance of both weighted ED and weighted EVD by deriving closed-form\nexpressions for false alarm and detection probabilities. Our numerical results,\nconsidering both static and dynamic user behaviors, demonstrate the superiority\nof WCSS in enhancing sensing performance compared to uniformly weighted\ndetectors.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T09:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10036v1","title":"DataMosaic: Explainable and Verifiable Multi-Modal Data Analytics\n  through Extract-Reason-Verify","summary":"Large Language Models (LLMs) are transforming data analytics, but their\nwidespread adoption is hindered by two critical limitations: they are not\nexplainable (opaque reasoning processes) and not verifiable (prone to\nhallucinations and unchecked errors). While retrieval-augmented generation\n(RAG) improves accuracy by grounding LLMs in external data, it fails to address\nthe core challenges of trustworthy analytics - especially when processing\nnoisy, inconsistent, or multi-modal data (for example, text, tables, images).\nWe propose DataMosaic, a framework designed to make LLM-powered analytics both\nexplainable and verifiable. By dynamically extracting task-specific structures\n(for example, tables, graphs, trees) from raw data, DataMosaic provides\ntransparent, step-by-step reasoning traces and enables validation of\nintermediate results. Built on a multi-agent framework, DataMosaic orchestrates\nself-adaptive agents that align with downstream task requirements, enhancing\nconsistency, completeness, and privacy. Through this approach, DataMosaic not\nonly tackles the limitations of current LLM-powered analytics systems but also\nlays the groundwork for a new paradigm of grounded, accurate, and explainable\nmulti-modal data analytics.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T09:38:23Z"}
{"aid":"http://arxiv.org/abs/2504.10037v1","title":"A census of galactic spider binary millisecond pulsars with the\n  NanÃ§ay Radio Telescope","summary":"Spider pulsars are systems in which a millisecond pulsar (MSP) tightly orbits\n(Pb $\\lesssim$ 1 day) a low mass (mc $\\lesssim$ 0.5 M$_\\odot$) semi-degenerate\nstar. Spider often display eclipses around superior conjunction. This eclipse\nphenomenon is currently poorly understood. We analyzed eclipses via pulsar\ntiming. The eclipses were fit with a phenomenological model which gives a\nmeasurement of the duration and asymmetry of the eclipses. These parameters\nwere then compared to other eclipse and system measurements to discuss the\npotential link between the presence of eclipses and orbital inclination,\neclipsing systems being known to have higher mass functions than non-eclipsing\nones. We present here a comprehensive review of the NRT NUPPI backend spider\npulsars dataset. We also present the first review and systematic analysis of a\nlarge sample of eclipsers, monitored with the NRT over several years. The\nphenomenological fit allowed us to compare the eclipsers with each other, which\nled to the categorization of eclipsers depending on the shape of their\neclipses. We present the polarimetric properties of the 19 spiders in the\nsample alongside their profiles, which were previously unpublished in some\ncases. For the eclipsing systems, we found evidence for a positive correlation\nbetween eclipse duration and mass function, as expected if more eclipsing\nmaterial crosses the line-of-sight in higher inclination systems. For the\nentire sample, we found marginal evidence for increasing pulse profile width\nwith decreasing mass function. We finally conducted a comprehensive literature\nreview of the published inclination measurements for the pulsars in the sample\nand compared the inclinations to eclipse parameters. Nevertheless, the small\nnumber of available orbital inclination constraints, contradicting each other\nin some cases, hinders such searches for correlations","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T09:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.10040v1","title":"The Security of Quantum Computing in 6G: from Technical Perspectives to\n  Ethical Implications","summary":"Quantum technologies hold promise as essential components for the upcoming\ndeployment of the future 6G network. In this future network, the security and\ntrustworthiness requirements are not considered fulfilled with the current\nstate of the quantum computers, as the malicious behaviour on the part of the\nservice provider towards the user may still be present. Therefore, this article\nprovides an initial interdisciplinary work of regulations and solutions in the\nscope of trustworthy quantum computing for future 6G that can be viewed as\ncomplimentary regulations to the existing strategies shared by different actors\nof states and organizations. More precisely, we describe the importance of a\nreliable quantum service provider and its implication on the ethical aspects\nconcerning digital sovereignty. By exploring the critical relationship between\ntrustworthiness and digital sovereignty in the context of future 6G networks,\nwe analyse a trade-off between accessibility to this new technology and\npreservation of digital sovereignty engaging in parallel the United Nation's\n(UN's) sustainable development goals. Furthermore, we propose a partnership\nmodel based on cooperation, coordination, and collaboration giving rise to a\ntrusted, ethical, and inclusive quantum ecosystem, whose implications can spill\nover to the entire global scenario.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T09:42:16Z"}
{"aid":"http://arxiv.org/abs/2504.10041v1","title":"Prior Does Matter: Visual Navigation via Denoising Diffusion Bridge\n  Models","summary":"Recent advancements in diffusion-based imitation learning, which show\nimpressive performance in modeling multimodal distributions and training\nstability, have led to substantial progress in various robot learning tasks. In\nvisual navigation, previous diffusion-based policies typically generate action\nsequences by initiating from denoising Gaussian noise. However, the target\naction distribution often diverges significantly from Gaussian noise, leading\nto redundant denoising steps and increased learning complexity. Additionally,\nthe sparsity of effective action distributions makes it challenging for the\npolicy to generate accurate actions without guidance. To address these issues,\nwe propose a novel, unified visual navigation framework leveraging the\ndenoising diffusion bridge models named NaviBridger. This approach enables\naction generation by initiating from any informative prior actions, enhancing\nguidance and efficiency in the denoising process. We explore how diffusion\nbridges can enhance imitation learning in visual navigation tasks and further\nexamine three source policies for generating prior actions. Extensive\nexperiments in both simulated and real-world indoor and outdoor scenarios\ndemonstrate that NaviBridger accelerates policy inference and outperforms the\nbaselines in generating target action sequences. Code is available at\nhttps://github.com/hren20/NaiviBridger.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-14T09:42:35Z"}
{"aid":"http://arxiv.org/abs/2504.10052v1","title":"Frequency Hopping Waveform Design for Secure Integrated Sensing and\n  Communications","summary":"We introduce a comprehensive approach to enhance the security, privacy, and\nsensing capabilities of integrated sensing and communications (ISAC) systems by\nleveraging random frequency agility (RFA) and random pulse repetition interval\n(PRI) agility (RPA) techniques. The combination of these techniques, which we\nrefer to collectively as random frequency and PRI agility (RFPA), with channel\nreciprocity-based key generation (CRKG) obfuscates both Doppler frequency and\nPRIs, significantly hindering the chances that passive adversaries can\nsuccessfully estimate radar parameters. In addition, a hybrid information\nembedding method integrating amplitude shift keying (ASK), phase shift keying\n(PSK), index modulation (IM), and spatial modulation (SM) is incorporated to\nincrease the achievable bit rate of the system significantly. Next, a\nsparse-matched filter receiver design is proposed to efficiently decode the\nembedded information with a low bit error rate (BER). Finally, a novel\nRFPA-based secret generation scheme using CRKG ensures secure code creation\nwithout a coordinating authority. The improved range and velocity estimation\nand reduced clutter effects achieved with the method are demonstrated via the\nevaluation of the ambiguity function (AF) of the proposed waveforms.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-14T09:56:18Z"}
{"aid":"http://arxiv.org/abs/2504.10053v1","title":"Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired\n  Olfactory Perception System","summary":"In this study, we explore how the combination of synthetic biology,\nneuroscience modeling, and neuromorphic electronic systems offers a new\napproach to creating an artificial system that mimics the natural sense of\nsmell. We argue that a co-design approach offers significant advantages in\nreplicating the complex dynamics of odor sensing and processing. We investigate\na hybrid system of synthetic sensory neurons that provides three key features:\na) receptor-gated ion channels, b) interface between synthetic biology and\nsemiconductors and c) event-based encoding and computing based on spiking\nnetworks. This research seeks to develop a platform for ultra-sensitive,\nspecific, and energy-efficient odor detection, with potential implications for\nenvironmental monitoring, medical diagnostics, and security.","main_category":"cs.NE","categories":"cs.NE,cs.ET,q-bio.NC","published":"2025-04-14T09:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.10059v1","title":"Central limit theorem for $Îµ$-independent products and\n  higher-order tensors","summary":"We establish a central limit theorem (CLT) for families of products of\n$\\epsilon$-independent random variables. We utilize graphon limits to encode\nthe evolution of independence and characterize the limiting distribution. Our\nframework subsumes a wide class of dependency structures and includes, as a\nspecial case, a CLT for higher-order tensor products of free random variables.\nOur results extend earlier findings and recover as a special case a recent\ntensor-free CLT, which was obtained through the development of a tensor\nanalogue of free probability. In contrast, our approach is more direct and\nprovides a unified and concise derivation of a more general CLT via graphon\nconvergence.","main_category":"math.PR","categories":"math.PR","published":"2025-04-14T10:02:14Z"}
{"aid":"http://arxiv.org/abs/2504.10061v1","title":"BSFT-like action from cohomomorphism","summary":"By performing a field redefinition via a cohomomorphism on the Maurer-Cartan\naction of the $A_\\infty$ algebra, we construct an action that reproduces the\ncharacteristic structure of boundary string field theory (BSFT), which we refer\nto as the BSFT-like action. We show that the form and several properties of\nthis BSFT-like action closely resemble those of BSFT. Our results suggest that\nthis approach provides a systematic framework to derive the BSFT action from\nthe OSFT based on $A_\\infty$ algebras.","main_category":"hep-th","categories":"hep-th","published":"2025-04-14T10:03:22Z"}
{"aid":"http://arxiv.org/abs/2504.10062v1","title":"Computing the unitary best approximant to the exponential function","summary":"Unitary best approximation to the exponential function on an interval on the\nimaginary axis has been introduced recently. In the present work two algorithms\nare considered to compute this best approximant: an algorithm based on rational\ninterpolation in successively corrected interpolation nodes and the AAA-Lawson\nmethod. Moreover, a posteriori bounds are introduced to evaluate the quality of\na computed approximant and to show convergence to the unitary best approximant\nin practice. Two a priori estimates -- one based on experimental data, and one\nbased on an asymptotic error estimate -- are introduced to determine the\nunderlying frequency for which the unitary best approximant achieves a given\naccuracy. Performance of algorithms and estimates is verified by numerical\nexperiments. In particular, the interpolation-based algorithm converges to the\nunitary best approximant within a small number of iterations in practice.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T10:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.10065v1","title":"A Computational Cognitive Model for Processing Repetitions of\n  Hierarchical Relations","summary":"Patterns are fundamental to human cognition, enabling the recognition of\nstructure and regularity across diverse domains. In this work, we focus on\nstructural repeats, patterns that arise from the repetition of hierarchical\nrelations within sequential data, and develop a candidate computational model\nof how humans detect and understand such structural repeats. Based on a\nweighted deduction system, our model infers the minimal generative process of a\ngiven sequence in the form of a Template program, a formalism that enriches the\ncontext-free grammar with repetition combinators. Such representation\nefficiently encodes the repetition of sub-computations in a recursive manner.\nAs a proof of concept, we demonstrate the expressiveness of our model on short\nsequences from music and action planning. The proposed model offers broader\ninsights into the mental representations and cognitive mechanisms underlying\nhuman pattern recognition.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T10:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.10072v1","title":"Comparison of an OGS/Polystyrene scintillator (BSO-406) with pure OGS\n  (BSO-100), EJ-276, EJ-309, and M600 scintillators","summary":"In this paper, we present an investigation into the scintillation properties\nand pulse shape discrimination (PSD) performance of the new BSO-406, which is a\nblend of 40% organic glass scintillator and 60% polystyrene. We tested a\ncylindrical sample with dimensions of 2x2 inches. The study includes\nmeasurements of neutron-gamma discrimination capability, emission spectra,\nphotoelectron yield, and the analysis of light pulse shapes originating from\nevents related to gamma-rays and fast neutrons. The results were compared to\ndata previously recorded using a pure Organic Glass Scintillator (BSO-100), an\nEJ-309 liquid scintillator, and EJ-276 and M600 polyurethane-based plastic\nscintillators.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-14T10:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.10080v1","title":"Learning to Harmonize Cross-vendor X-ray Images by Non-linear Image\n  Dynamics Correction","summary":"In this paper, we explore how conventional image enhancement can improve\nmodel robustness in medical image analysis. By applying commonly used\nnormalization methods to images from various vendors and studying their\ninfluence on model generalization in transfer learning, we show that the\nnonlinear characteristics of domain-specific image dynamics cannot be addressed\nby simple linear transforms. To tackle this issue, we reformulate the image\nharmonization task as an exposure correction problem and propose a method\ntermed Global Deep Curve Estimation (GDCE) to reduce domain-specific exposure\nmismatch. GDCE performs enhancement via a pre-defined polynomial function and\nis trained with the help of a ``domain discriminator'', aiming to improve model\ntransparency in downstream tasks compared to existing black-box methods.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-14T10:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.10082v1","title":"Leveraging Metaphors in a VR Serious Game for Computational Thinking","summary":"This paper presents Cooking Code, a VR-based serious game designed to\nintroduce programming concepts to students (ages 12-16) through an immersive,\nscenario-driven experience. Set in a futuristic world where humans and machines\ncoexist, players take on the role of a fast-food chef who must assemble food\norders based on pseudocode instructions. By interpreting and executing these\ninstructions correctly, players develop problem-solving skills, computational\nthinking, and a foundational understanding of programming logic. The game\nleverages the kitchen metaphor to teach computational thinking, using\naffordances for an immersive VR experience.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T10:31:48Z"}
{"aid":"http://arxiv.org/abs/2504.10084v1","title":"UP-Person: Unified Parameter-Efficient Transfer Learning for Text-based\n  Person Retrieval","summary":"Text-based Person Retrieval (TPR) as a multi-modal task, which aims to\nretrieve the target person from a pool of candidate images given a text\ndescription, has recently garnered considerable attention due to the progress\nof contrastive visual-language pre-trained model. Prior works leverage\npre-trained CLIP to extract person visual and textual features and fully\nfine-tune the entire network, which have shown notable performance improvements\ncompared to uni-modal pre-training models. However, full-tuning a large model\nis prone to overfitting and hinders the generalization ability. In this paper,\nwe propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method\nfor Text-based Person Retrieval (UP-Person) to thoroughly transfer the\nmulti-modal knowledge from CLIP. Specifically, UP-Person simultaneously\nintegrates three lightweight PETL components including Prefix, LoRA and\nAdapter, where Prefix and LoRA are devised together to mine local information\nwith task-specific information prompts, and Adapter is designed to adjust\nglobal feature representations. Additionally, two vanilla submodules are\noptimized to adapt to the unified architecture of TPR. For one thing, S-Prefix\nis proposed to boost attention of prefix and enhance the gradient propagation\nof prefix tokens, which improves the flexibility and performance of the vanilla\nprefix. For another thing, L-Adapter is designed in parallel with layer\nnormalization to adjust the overall distribution, which can resolve conflicts\ncaused by overlap and interaction among multiple submodules. Extensive\nexperimental results demonstrate that our UP-Person achieves state-of-the-art\nresults across various person retrieval datasets, including CUHK-PEDES,\nICFG-PEDES and RSTPReid while merely fine-tuning 4.7\\% parameters. Code is\navailable at https://github.com/Liu-Yating/UP-Person.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T10:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.10085v1","title":"Giant and anisotropic magnetostriction in $Î²$-O$_{2}$ at 110 T","summary":"Magnetostriction is a crystal's deformation under magnetic fields, usually in\nthe range of $10^{-6}$ - $10^{-3}$, where the lattice change occurs with the\nchange of spin and orbital state through spin-lattice couplings. In strong\nmagnetic fields beyond 100 T, the significant Zeeman energy competes with the\nlattice interactions, where one can expect considerable magnetostriction.\nHowever, directly observing magnetostriction above 100 T is challenging,\nbecause generating magnetic fields beyond 100 T accompanies the destruction of\nthe coil with a single-shot $\\mu$-second pulse. Here, we observed the giant and\nanisotropic magnetostriction of $\\sim$1 % at 110 T in the spin-controlled\ncrystal of $\\beta$-O$_{2}$, by combining the single-shot diffraction of x-ray\nfree-electron laser (XFEL) and the state-of-the-art portable 100 T generator.\nThe magnetostriction of $\\sim$1 % is the largest class as a deformation of the\nunit cell. It is a response of the soft lattice of $\\beta$-O$_{2}$ originating,\nnot only in the competing van der Waals force and exchange interaction, but\nalso the soft state of spin and lattice frustrated on the triangular network.\nMeanwhile, the anisotropy originates from the strong two-dimensionality of the\nspin system. Giant magnetostriction in crystals should become more ubiquitous\nand diverse beyond 100 T, where our XFEL experiment above 100 T opens a novel\npathway for their exploration, providing fundamental insights into the roles of\nspin in stabilizing crystal structures.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci,cond-mat.soft","published":"2025-04-14T10:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.10090v1","title":"CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography","summary":"Large language models (LLMs) and multimodal large language models (MLLMs)\nhave significantly advanced artificial intelligence. However, visual reasoning,\nreasoning involving both visual and textual inputs, remains underexplored.\nRecent advancements, including the reasoning models like OpenAI o1 and Gemini\n2.0 Flash Thinking, which incorporate image inputs, have opened this\ncapability. In this ongoing work, we focus specifically on photography-related\ntasks because a photo is a visual snapshot of the physical world where the\nunderlying physics (i.e., illumination, blur extent, etc.) interplay with the\ncamera parameters. Successfully reasoning from the visual information of a\nphoto to identify these numerical camera settings requires the MLLMs to have a\ndeeper understanding of the underlying physics for precise visual\ncomprehension, representing a challenging and intelligent capability essential\nfor practical applications like photography assistant agents. We aim to\nevaluate MLLMs on their ability to distinguish visual differences related to\nnumerical camera settings, extending a methodology previously proposed for\nvision-language models (VLMs). Our preliminary results demonstrate the\nimportance of visual reasoning in photography-related tasks. Moreover, these\nresults show that no single MLLM consistently dominates across all evaluation\ntasks, demonstrating ongoing challenges and opportunities in developing MLLMs\nwith better visual reasoning.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-14T10:53:44Z"}
{"aid":"http://arxiv.org/abs/2504.10091v1","title":"Wasserstein convergence rates for stochastic particle approximation of\n  Boltzmann models","summary":"We establish quantitative convergence rates for stochastic particle\napproximation based on Nanbu-type Monte Carlo schemes applied to a broad class\nof collisional kinetic models. Using coupling techniques and stability\nestimates in the Wasserstein-1 (Kantorovich-Rubinstein) metric, we derive sharp\nerror bounds that reflect the nonlinear interaction structure of the models.\nOur framework includes classical Nanbu Monte Carlo method and more recent\ndevelopments as Time Relaxed Monte Carlo methods. The results bridge the gap\nbetween probabilistic particle approximations and deterministic numerical error\nanalysis, and provide a unified perspective for the convergence theory of Monte\nCarlo methods for Boltzmann-type equations. As a by-product, we also obtain\nexistence and uniqueness of solutions to a large class of Boltzmann-type\nequations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T10:55:04Z"}
{"aid":"http://arxiv.org/abs/2504.10097v1","title":"STaRFormer: Semi-Supervised Task-Informed Representation Learning via\n  Dynamic Attention-Based Regional Masking for Sequential Data","summary":"Accurate predictions using sequential spatiotemporal data are crucial for\nvarious applications. Utilizing real-world data, we aim to learn the intent of\na smart device user within confined areas of a vehicle's surroundings. However,\nin real-world scenarios, environmental factors and sensor limitations result in\nnon-stationary and irregularly sampled data, posing significant challenges. To\naddress these issues, we developed a Transformer-based approach, STaRFormer,\nwhich serves as a universal framework for sequential modeling. STaRFormer\nemploys a novel, dynamic attention-based regional masking scheme combined with\nsemi-supervised contrastive learning to enhance task-specific latent\nrepresentations. Comprehensive experiments on 15 datasets varying in types\n(including non-stationary and irregularly sampled), domains, sequence lengths,\ntraining samples, and applications, demonstrate the efficacy and practicality\nof STaRFormer. We achieve notable improvements over state-of-the-art\napproaches. Code and data will be made available.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T11:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.10123v1","title":"M2S-RoAD: Multi-Modal Semantic Segmentation for Road Damage Using Camera\n  and LiDAR Data","summary":"Road damage can create safety and comfort challenges for both human drivers\nand autonomous vehicles (AVs). This damage is particularly prevalent in rural\nareas due to less frequent surveying and maintenance of roads. Automated\ndetection of pavement deterioration can be used as an input to AVs and driver\nassistance systems to improve road safety. Current research in this field has\npredominantly focused on urban environments driven largely by public datasets,\nwhile rural areas have received significantly less attention. This paper\nintroduces M2S-RoAD, a dataset for the semantic segmentation of different\nclasses of road damage. M2S-RoAD was collected in various towns across New\nSouth Wales, Australia, and labelled for semantic segmentation to identify nine\ndistinct types of road damage. This dataset will be released upon the\nacceptance of the paper.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:32:01Z"}
{"aid":"http://arxiv.org/abs/2504.10131v1","title":"A three-functor formalism for commutative von Neumann algebras","summary":"A three-functor formalism is the half of a six-functor formalism that\nsupports the projection and base change formulas. In this paper, we provide a\nthree-functor formalism for commutative von Neumann algebras and their modules.\nUsing the Gelfand-Naimark theorem, this gives rise to a three-functor formalism\nfor measure spaces and measurable bundles of Hilbert spaces. We use this to\nprove Fell absorption for unitary representations of measure groupoids.\n  The three-functor formalism for commutative von Neumann algebras takes values\nin W*-categories, and we discuss in what sense it is a unitary three-functor\nformalism.","main_category":"math.OA","categories":"math.OA,math.CT,math.QA","published":"2025-04-14T11:37:36Z"}
{"aid":"http://arxiv.org/abs/2504.10133v1","title":"Discovery of an intriguing chemically rich outflow in the OMC-2/3\n  filament","summary":"Studying chemically rich protostellar outflows and their jet provides an\nimportant insight into the low-mass star formation process and its related\nchemistry. Whilst well-known shock tracers such as SiO can be used to study the\njet properties and give information about the dynamics of the system,\ninterstellar complex organic molecules (iCOMs) have been useful in constraining\nthe age of shocked gas, for example. Yet, the number of outflows mapped in\niCOMs is still limited. In this work, we study the outflow driven by the\nprotostar FIR6c-a (HOPS 409) located in the OMC-2/3 filament. We report the\ndetection of the red-shifted jet, left undetected in previous studies, as well\nas the detection of the iCOMs methanol (CH$_3$OH) and methyl cyanide (CH$_3$CN)\nfor the first time towards this outflow. Using SiO, we derived some jet\nproperties (i.e., collimation and dynamical time). We found a clear dichotomy\nbetween the blue- and red-shifted jets, likely due to the density of the medium\nin which the jets propagate. In addition, we identified two bow shocks within\nthe blue-shifted part of the outflow, which we attribute to two different\nejection events. Finally, using the CH$_3$OH} and \\ce{CH$_3$CN} abundance ratio\nand chemical modelling, we constrained the outflow age to be $\\geq 1000$ yr old\nand, surprisingly, found that a cosmic-ray ionization rate of $10^{-14}$\ns$^{-1}$ is needed to reproduce the observed ratio towards the source.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-14T11:42:54Z"}
{"aid":"http://arxiv.org/abs/2504.10139v1","title":"Conditional Distribution Compression via the Kernel Conditional Mean\n  Embedding","summary":"Existing distribution compression methods, like Kernel Herding (KH), were\noriginally developed for unlabelled data. However, no existing approach\ndirectly compresses the conditional distribution of labelled data. To address\nthis gap, we first introduce the Average Maximum Conditional Mean Discrepancy\n(AMCMD), a natural metric for comparing conditional distributions. We then\nderive a consistent estimator for the AMCMD and establish its rate of\nconvergence. Next, we make a key observation: in the context of distribution\ncompression, the cost of constructing a compressed set targeting the AMCMD can\nbe reduced from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(n)$. Building on this, we\nextend the idea of KH to develop Average Conditional Kernel Herding (ACKH), a\nlinear-time greedy algorithm that constructs a compressed set targeting the\nAMCMD. To better understand the advantages of directly compressing the\nconditional distribution rather than doing so via the joint distribution, we\nintroduce Joint Kernel Herding (JKH), a straightforward adaptation of KH\ndesigned to compress the joint distribution of labelled data. While herding\nmethods provide a simple and interpretable selection process, they rely on a\ngreedy heuristic. To explore alternative optimisation strategies, we propose\nJoint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing\nPoints (ACKIP), which jointly optimise the compressed set while maintaining\nlinear complexity. Experiments show that directly preserving conditional\ndistributions with ACKIP outperforms both joint distribution compression (via\nJKH and JKIP) and the greedy selection used in ACKH. Moreover, we see that JKIP\nconsistently outperforms JKH.","main_category":"stat.ML","categories":"stat.ML,cs.LG,stat.CO,stat.ME","published":"2025-04-14T11:53:29Z"}
{"aid":"http://arxiv.org/abs/2504.10152v1","title":"Neo balcobalancing numbers","summary":"In this work, we defined neo balcobalancing numbers, neo Lucas-balcobalancing\nnumbers, neo balcobalancers and neo Lucas-balcobalancers and derived the\ngeneral terms of these numbers in terms of balancing numbers. Conversely we\ndeduced the general terms of balancing, cobalancing, Lucas-balancing and\nLucas-cobalancing numbers in terms of these numbers. We also deduced some\nrelations on Binet formulas, recurrence relations, relationship with Pell,\nPell-Lucas, triangular, square triangular numbers, Pythagorean triples and\nCassini identities. We also formulate the sum of first $n$-terms of these\nnumbers and obtained some formulas for the sums of Pell, Pell-Lucas, balancing\nand Lucas-cobalancing numbers in terms of these numbers.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T12:04:32Z"}
{"aid":"http://arxiv.org/abs/2504.10165v1","title":"WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs","summary":"Live tracking of wildlife via high-resolution video processing directly\nonboard drones is widely unexplored and most existing solutions rely on\nstreaming video to ground stations to support navigation. Yet, both autonomous\nanimal-reactive flight control beyond visual line of sight and/or\nmission-specific individual and behaviour recognition tasks rely to some degree\non this capability. In response, we introduce WildLive -- a near real-time\nanimal detection and tracking framework for high-resolution imagery running\ndirectly onboard uncrewed aerial vehicles (UAVs). The system performs\nmulti-animal detection and tracking at 17fps+ for HD and 7fps+ on 4K video\nstreams suitable for operation during higher altitude flights to minimise\nanimal disturbance. Our system is optimised for Jetson Orin AGX onboard\nhardware. It integrates the efficiency of sparse optical flow tracking and\nmission-specific sampling with device-optimised and proven YOLO-driven object\ndetection and segmentation techniques. Essentially, computational resource is\nfocused onto spatio-temporal regions of high uncertainty to significantly\nimprove UAV processing speeds without domain-specific loss of accuracy.\nAlongside, we introduce our WildLive dataset, which comprises 200k+ annotated\nanimal instances across 19k+ frames from 4K UAV videos collected at the Ol\nPejeta Conservancy in Kenya. All frames contain ground truth bounding boxes,\nsegmentation masks, as well as individual tracklets and tracking point\ntrajectories. We compare our system against current object tracking approaches\nincluding OC-SORT, ByteTrack, and SORT. Our multi-animal tracking experiments\nwith onboard hardware confirm that near real-time high-resolution wildlife\ntracking is possible on UAVs whilst maintaining high accuracy levels as needed\nfor future navigational and mission-specific animal-centric operational\nautonomy.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T12:21:16Z"}
{"aid":"http://arxiv.org/abs/2504.10169v1","title":"Challenges in interpretability of additive models","summary":"We review generalized additive models as a type of ``transparent'' model that\nhas recently seen renewed interest in the deep learning community as neural\nadditive models. We highlight multiple types of nonidentifiability in this\nmodel class and discuss challenges in interpretability, arguing for restraint\nwhen claiming ``interpretability'' or ``suitability for safety-critical\napplications'' of such models.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-14T12:24:17Z"}
{"aid":"http://arxiv.org/abs/2504.10173v1","title":"Photosensitive materials for neutron optics","summary":"Photosensitive materials with ever-improving properties are of great\nimportance for optical and photonics applications. Additionally, they are\nextremely useful for designing components for neutron optical devices. We\nprovide an overview on materials that have been tested and successfully used to\ncontrol beams of cold and very cold neutrons based on diffractive elements.\nArtificial gratings are generated and optimized for the specific application in\nmind. We discuss the needs of the neutron optics community and highlight the\nprogress obtained during the last decade. Materials that have been employed so\nfar along with their properties are summarized, outlining the most promising\ncandidates for the construction of an interferometer for very cold neutrons.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T12:25:41Z"}
{"aid":"http://arxiv.org/abs/2504.10188v1","title":"Efficient Generative Model Training via Embedded Representation Warmup","summary":"Diffusion models excel at generating high-dimensional data but fall short in\ntraining efficiency and representation quality compared to self-supervised\nmethods. We identify a key bottleneck: the underutilization of high-quality,\nsemantically rich representations during training notably slows down\nconvergence. Our systematic analysis reveals a critical representation\nprocessing region -- primarily in the early layers -- where semantic and\nstructural pattern learning takes place before generation can occur. To address\nthis, we propose Embedded Representation Warmup (ERW), a plug-and-play\nframework where in the first stage we get the ERW module serves as a warmup\nthat initializes the early layers of the diffusion model with high-quality,\npretrained representations. This warmup minimizes the burden of learning\nrepresentations from scratch, thereby accelerating convergence and boosting\nperformance. Our theoretical analysis demonstrates that ERW's efficacy depends\non its precise integration into specific neural network layers -- termed the\nrepresentation processing region -- where the model primarily processes and\ntransforms feature representations for later generation. We further establish\nthat ERW not only accelerates training convergence but also enhances\nrepresentation quality: empirically, our method achieves a 40$\\times$\nacceleration in training speed compared to REPA, the current state-of-the-art\nmethods. Code is available at https://github.com/LINs-lab/ERW.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-14T12:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.10196v1","title":"On compact embeddings in $\\mathbf{L^p}$ and fractional spaces","summary":"Let $X,Y$ be Hilbert spaces and $\\mathcal{A}\\colon X\\to X'$ a continuous and\nsymmetric elliptic operator. We suppose that $X$ is dense in $Y$ and that the\nembedding $X\\subset Y$ is compact. In this paper we show some consequences of\nthis setting on the study of the fractional operator attached to $\\mathcal{A}$\nin the extension setting $\\mathbb{R}^N\\times (0, \\infty)$. Being more specific,\nwe will give some examples where the embedding $H(\\mathbb{R}^{N+1}_+)\\subset\nL^2(\\mathbb{R}^N)$ is compact, with the space $H(\\mathbb{R}^{N+1}_+)$ depending\non the operator $\\mathcal{A}$.","main_category":"math.FA","categories":"math.FA,math.AP","published":"2025-04-14T13:02:48Z"}
{"aid":"http://arxiv.org/abs/2504.10199v1","title":"Multipole Moments of Double Heavy $J^P = \\frac{3}{2}^+$ Baryons","summary":"In the present study, we calculate the multipole moments of spin-3/2 doubly\nheavy baryons within the light cone QCD sum rules. We compare our results on\nmagnetic dipole moments with results existing in the literature. The results\nobtained in the present work may be useful for a deeper understanding of the\nproperties of doubly heavy baryons as well as in the analysis of their strong\nand electromagnetic decays.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-14T13:03:16Z"}
{"aid":"http://arxiv.org/abs/2504.10201v1","title":"VibrantLeaves: A principled parametric image generator for training deep\n  restoration models","summary":"Even though Deep Neural Networks are extremely powerful for image restoration\ntasks, they have several limitations. They are poorly understood and suffer\nfrom strong biases inherited from the training sets. One way to address these\nshortcomings is to have a better control over the training sets, in particular\nby using synthetic sets. In this paper, we propose a synthetic image generator\nrelying on a few simple principles. In particular, we focus on geometric\nmodeling, textures, and a simple modeling of image acquisition. These\nproperties, integrated in a classical Dead Leaves model, enable the creation of\nefficient training sets. Standard image denoising and super-resolution networks\ncan be trained on such datasets, reaching performance almost on par with\ntraining on natural image datasets. As a first step towards explainability, we\nprovide a careful analysis of the considered principles, identifying which\nimage properties are necessary to obtain good performances. Besides, such\ntraining also yields better robustness to various geometric and radiometric\nperturbations of the test sets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T13:09:49Z"}
{"aid":"http://arxiv.org/abs/2504.10214v1","title":"Balancing Stability and Plasticity in Pretrained Detector: A Dual-Path\n  Framework for Incremental Object Detection","summary":"The balance between stability and plasticity remains a fundamental challenge\nin pretrained model-based incremental object detection (PTMIOD). While existing\nPTMIOD methods demonstrate strong performance on in-domain tasks aligned with\npretraining data, their plasticity to cross-domain scenarios remains\nunderexplored. Through systematic component-wise analysis of pretrained\ndetectors, we reveal a fundamental discrepancy: the localization modules\ndemonstrate inherent cross-domain stability-preserving precise bounding box\nestimation across distribution shifts-while the classification components\nrequire enhanced plasticity to mitigate discriminability degradation in\ncross-domain scenarios. Motivated by these findings, we propose a dual-path\nframework built upon pretrained DETR-based detectors which decouples\nlocalization stability and classification plasticity: the localization path\nmaintains stability to preserve pretrained localization knowledge, while the\nclassification path facilitates plasticity via parameter-efficient fine-tuning\nand resists forgetting with pseudo-feature replay. Extensive evaluations on\nboth in-domain (MS COCO and PASCAL VOC) and cross-domain (TT100K) benchmarks\nshow state-of-the-art performance, demonstrating our method's ability to\neffectively balance stability and plasticity in PTMIOD, achieving robust\ncross-domain adaptation and strong retention of anti-forgetting capabilities.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T13:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.10220v1","title":"Modeling the Thermal Structure of a Protoplanetary Disk Using Multiband\n  Flux-Limited Diffusion Approximation","summary":"This work continues the analysis of the model for calculating the thermal\nstructure of an axisymmetric protoplanetary disk, initiated in the paper by\nPavlyuchenkov (2024). The model is based on the well-known Flux-Limited\nDiffusion (FLD) approximation with separate calculation of heating by direct\nstellar radiation (hereinafter referred to as the FLD$^{\\rm s}$ method). In\naddition to the previously described FLD$^{\\rm s}$ model with\nwavelength-averaged opacities, we present a multiband model mFLD$^{\\rm s}$,\nwhere the spectrum of thermal radiation is divided into several frequency\nbands. The model is based on an implicit finite-difference scheme for the\nequations of thermal radiation diffusion, which reduces to a system of linear\nalgebraic equations written in hypermatrix form. A modified Gauss method for\ninverting the sparse hypermatrix of the original system of linear equations is\nproposed. The simulation results described in the article show that the\nmidplane radial temperature profile obtained with the mFLD$^{\\rm s}$ method has\na variable slope in accordance with the reference Monte Carlo radiative\ntransfer simulations. The mFLD$^{\\rm s}$ model also qualitatively reproduces\nthe non-isothermality of the temperature distribution along the angular\ncoordinate near the midplane, which is not provided by the FLD$^{\\rm s}$\nmethod. However, quantitative differences remain between the reference\ntemperature values and the results of mFLD$^{\\rm s}$. These differences are\nlikely due to the diffusive nature of the FLD approximation. It is also shown\nthat the characteristic times for the disk to reach thermal equilibrium within\nthe mFLD$^{\\rm s}$ model can be significantly shorter than in FLD$^{\\rm s}$.\nThis property should be taken into account when modeling non-stationary\nprocesses in protoplanetary disks within FLD-based models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-14T13:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.10226v1","title":"Geodesic interpretation of the global quasi-geostrophic equations","summary":"We give an interpretation of the global shallow water quasi-geostrophic\nequations on the sphere $\\Sph^2$ as a geodesic equation on the central\nextension of the quantomorphism group on $\\Sph^3$. The study includes deriving\nthe model as a geodesic equation for a weak Riemannian metric, demonstrating\nsmooth dependence on the initial data, and establishing global-in-time\nexistence and uniqueness of solutions. We also prove that the Lamb parameter in\nthe model has a stabilizing effect on the dynamics: if it is large enough, the\nsectional curvature along the trade-wind current is positive, implying\nconjugate points.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T13:45:40Z"}
{"aid":"http://arxiv.org/abs/2504.10229v1","title":"ROSFD: Robust Online Streaming Fraud Detection with Resilience to\n  Concept Drift in Data Streams","summary":"Continuous generation of streaming data from diverse sources, such as online\ntransactions and digital interactions, necessitates timely fraud detection.\nTraditional batch processing methods often struggle to capture the rapidly\nevolving patterns of fraudulent activities. This paper highlights the critical\nimportance of processing streaming data for effective fraud detection. To\naddress the inherent challenges of latency, scalability, and concept drift in\nstreaming environments, we propose a robust online streaming fraud detection\n(ROSFD) framework. Our proposed framework comprises two key stages: (i) Stage\nOne: Offline Model Initialization. In this initial stage, a model is built in\noffline settings using incremental learning principles to overcome the\n\"cold-start\" problem. (ii) Stage Two: Real-time Model Adaptation. In this\ndynamic stage, drift detection algorithms (viz.,, DDM, EDDM, and ADWIN) are\nemployed to identify concept drift in the incoming data stream and\nincrementally train the model accordingly. This \"train-only-when-required\"\nstrategy drastically reduces the number of retrains needed without\nsignificantly impacting the area under the receiver operating characteristic\ncurve (AUC). Overall, ROSFD utilizing ADWIN as the drift detection method\ndemonstrated the best performance among the employed methods. In terms of model\nefficacy, Adaptive Random Forest consistently outperformed other models,\nachieving the highest AUC in four out of five datasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T13:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.10231v1","title":"A Model Zoo of Vision Transformers","summary":"The availability of large, structured populations of neural networks - called\n'model zoos' - has led to the development of a multitude of downstream tasks\nranging from model analysis, to representation learning on model weights or\ngenerative modeling of neural network parameters. However, existing model zoos\nare limited in size and architecture and neglect the transformer, which is\namong the currently most successful neural network architectures. We address\nthis gap by introducing the first model zoo of vision transformers (ViT). To\nbetter represent recent training approaches, we develop a new blueprint for\nmodel zoo generation that encompasses both pre-training and fine-tuning steps,\nand publish 250 unique models. They are carefully generated with a large span\nof generating factors, and their diversity is validated using a thorough choice\nof weight-space and behavioral metrics. To further motivate the utility of our\nproposed dataset, we suggest multiple possible applications grounded in both\nextensive exploratory experiments and a number of examples from the existing\nliterature. By extending previous lines of similar work, our model zoo allows\nresearchers to push their model population-based methods from the small model\nregime to state-of-the-art architectures. We make our model zoo available at\ngithub.com/ModelZoos/ViTModelZoo.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T13:52:26Z"}
{"aid":"http://arxiv.org/abs/2504.10234v1","title":"Resolving Nondeterminism by Chance","summary":"History-deterministic automata are those in which nondeterministic choices\ncan be correctly resolved stepwise: there is a strategy to select a\ncontinuation of a run given the next input letter so that if the overall input\nword admits some accepting run, then the constructed run is also accepting.\n  Motivated by checking qualitative properties in probabilistic verification,\nwe consider the setting where the resolver strategy can randomize and only\nneeds to succeed with lower-bounded probability. We study the expressiveness of\nsuch stochastically-resolvable automata as well as consider the decision\nquestions of whether a given automaton has this property. In particular, we\nshow that it is undecidable to check if a given NFA is $\\lambda$-stochastically\nresolvable. This problem is decidable for finitely-ambiguous automata. We also\npresent complexity upper and lower bounds for several well-studied classes of\nautomata for which this problem remains decidable.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-14T13:54:02Z"}
{"aid":"http://arxiv.org/abs/2504.10245v1","title":"A short proof for the acyclicity of oriented exchange graphs of cluster\n  algebras","summary":"The statement in the title was proved in \\cite{Cao23} by introducing dominant\nsets of seeds, which are analogs of torsion classes in representation theory.\nIn this note, we observe a short proof by the existence of consistent cluster\nscattering diagrams.","main_category":"math.RT","categories":"math.RT,math.RA","published":"2025-04-14T14:09:06Z"}
{"aid":"http://arxiv.org/abs/2504.10248v1","title":"Adaptive Sensor Steering Strategy Using Deep Reinforcement Learning for\n  Dynamic Data Acquisition in Digital Twins","summary":"This paper introduces a sensor steering methodology based on deep\nreinforcement learning to enhance the predictive accuracy and decision support\ncapabilities of digital twins by optimising the data acquisition process.\nTraditional sensor placement techniques are often constrained by one-off\noptimisation strategies, which limit their applicability for online\napplications requiring continuous informative data assimilation. The proposed\napproach addresses this limitation by offering an adaptive framework for sensor\nplacement within the digital twin paradigm. The sensor placement problem is\nformulated as a Markov decision process, enabling the training and deployment\nof an agent capable of dynamically repositioning sensors in response to the\nevolving conditions of the physical structure as represented by the digital\ntwin. This ensures that the digital twin maintains a highly representative and\nreliable connection to its physical counterpart. The proposed framework is\nvalidated through a series of comprehensive case studies involving a cantilever\nplate structure subjected to diverse conditions, including healthy and damaged\nconditions. The results demonstrate the capability of the deep reinforcement\nlearning agent to adaptively reposition sensors improving the quality of data\nacquisition and hence enhancing the overall accuracy of digital twins.","main_category":"stat.ML","categories":"stat.ML,cs.LG,eess.SP","published":"2025-04-14T14:11:00Z"}
{"aid":"http://arxiv.org/abs/2504.10278v1","title":"DiffMOD: Progressive Diffusion Point Denoising for Moving Object\n  Detection in Remote Sensing","summary":"Moving object detection (MOD) in remote sensing is significantly challenged\nby low resolution, extremely small object sizes, and complex noise\ninterference. Current deep learning-based MOD methods rely on probability\ndensity estimation, which restricts flexible information interaction between\nobjects and across temporal frames. To flexibly capture high-order inter-object\nand temporal relationships, we propose a point-based MOD in remote sensing.\nInspired by diffusion models, the network optimization is formulated as a\nprogressive denoising process that iteratively recovers moving object centers\nfrom sparse noisy points. Specifically, we sample scattered features from the\nbackbone outputs as atomic units for subsequent processing, while global\nfeature embeddings are aggregated to compensate for the limited coverage of\nsparse point features. By modeling spatial relative positions and semantic\naffinities, Spatial Relation Aggregation Attention is designed to enable\nhigh-order interactions among point-level features for enhanced object\nrepresentation. To enhance temporal consistency, the Temporal Propagation and\nGlobal Fusion module is designed, which leverages an implicit memory reasoning\nmechanism for robust cross-frame feature integration. To align with the\nprogressive denoising process, we propose a progressive MinK optimal transport\nassignment strategy that establishes specialized learning objectives at each\ndenoising level. Additionally, we introduce a missing loss function to\ncounteract the clustering tendency of denoised points around salient objects.\nExperiments on the RsData remote sensing MOD dataset show that our MOD method\nbased on scattered point denoising can more effectively explore potential\nrelationships between sparse moving objects and improve the detection\ncapability and temporal consistency.","main_category":"cs.CV","categories":"cs.CV,I.4.8","published":"2025-04-14T14:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.10281v1","title":"Zero-shot Autonomous Microscopy for Scalable and Intelligent\n  Characterization of 2D Materials","summary":"Characterization of atomic-scale materials traditionally requires human\nexperts with months to years of specialized training. Even for trained human\noperators, accurate and reliable characterization remains challenging when\nexamining newly discovered materials such as two-dimensional (2D) structures.\nThis bottleneck drives demand for fully autonomous experimentation systems\ncapable of comprehending research objectives without requiring large training\ndatasets. In this work, we present ATOMIC (Autonomous Technology for Optical\nMicroscopy & Intelligent Characterization), an end-to-end framework that\nintegrates foundation models to enable fully autonomous, zero-shot\ncharacterization of 2D materials. Our system integrates the vision foundation\nmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),\nunsupervised clustering, and topological analysis to automate microscope\ncontrol, sample scanning, image segmentation, and intelligent analysis through\nprompt engineering, eliminating the need for additional training. When\nanalyzing typical MoS2 samples, our approach achieves 99.7% segmentation\naccuracy for single layer identification, which is equivalent to that of human\nexperts. In addition, the integrated model is able to detect grain boundary\nslits that are challenging to identify with human eyes. Furthermore, the system\nretains robust accuracy despite variable conditions including defocus, color\ntemperature fluctuations, and exposure variations. It is applicable to a broad\nspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardless\nof whether they were fabricated via chemical vapor deposition or mechanical\nexfoliation. This work represents the implementation of foundation models to\nachieve autonomous analysis, establishing a scalable and data-efficient\ncharacterization paradigm that fundamentally transforms the approach to\nnanoscale materials research.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cs.AI,cs.CV,cs.LG","published":"2025-04-14T14:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.10285v1","title":"Grothendieck-Springer resolutions and TQFTs","summary":"Let $G$ be a connected complex semisimple group with Lie algebra\n$\\mathfrak{g}$ and fixed Kostant slice $\\mathrm{Kos}\\subseteq\\mathfrak{g}^*$.\nIn a previous work, we show that\n$((T^*G)_{\\text{reg}}\\rightrightarrows\\mathfrak{g}^*_{\\text{reg}},\\mathrm{Kos})$\nyields the open Moore-Tachikawa TQFT. Morphisms in the image of this TQFT are\ncalled open Moore-Tachikawa varieties. By replacing\n$T^*G\\rightrightarrows\\mathfrak{g}^*$ and $\\mathrm{Kos}\\subseteq\\mathfrak{g}^*$\nwith the double $\\mathrm{D}(G)\\rightrightarrows G$ and a Steinberg slice\n$\\mathrm{Ste}\\subseteq G$, respectively, one obtains quasi-Hamiltonian\nanalogues of the open Moore-Tachikawa TQFT and varieties.\n  We consider a conjugacy class $\\mathcal{C}$ of parabolic subalgebras of\n$\\mathfrak{g}$. This class determines partial Grothendieck-Springer resolutions\n$\\mu_{\\mathcal{C}}:\\mathfrak{g}_{\\mathcal{C}}\\longrightarrow\\mathfrak{g}^*=\\mathfrak{g}$\nand $\\nu_{\\mathcal{C}}:G_{\\mathcal{C}}\\longrightarrow G$. We construct a\ncanonical symplectic groupoid\n$(T^*G)_{\\mathcal{C}}\\rightrightarrows\\mathfrak{g}_{\\mathcal{C}}$ and\nquasi-symplectic groupoid $\\mathrm{D}(G)_{\\mathcal{C}}\\rightrightarrows\nG_{\\mathcal{C}}$. In addition, we prove that the pairs\n$(((T^*G)_{\\mathcal{C}})_{\\text{reg}}\\rightrightarrows(\\mathfrak{g}_{\\mathcal{C}})_{\\text{reg}},\\mu_{\\mathcal{C}}^{-1}(\\mathrm{Kos}))$\nand\n$((\\mathrm{D}(G)_{\\mathcal{C}})_{\\text{reg}}\\rightrightarrows(G_{\\mathcal{C}})_{\\text{reg}},\\nu_{\\mathcal{C}}^{-1}(\\mathrm{Ste}))$\ndetermine TQFTs in a $1$-shifted Weinstein symplectic category. Our main result\nis about the Hamiltonian symplectic varieties arising from the former TQFT; we\nshow that these have canonical Lagrangian relations to the open Moore-Tachikawa\nvarieties. Pertinent specializations of our results to the full\nGrothendieck-Springer resolution are discussed throughout this manuscript.","main_category":"math.SG","categories":"math.SG,math.AG,math.RT","published":"2025-04-14T14:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.10287v1","title":"From translations to non-collapsing logic combinations","summary":"Prawitz suggested expanding a natural deduction system for intuitionistic\nlogic to include rules for classical logic constructors, allowing both\nintuitionistic and classical elements to coexist without losing their inherent\ncharacteristics. Looking at the added rules from the point of view of the\nGodel-Gentzen translation, led us to propose a general method for the\ncoexistent combination of two logics when a conservative translation exists\nfrom one logic (the source) to another (the host). Then we prove that the\ncombined logic is a conservative extension of the original logics, thereby\npreserving the unique characteristics of each component logic. In this way\nthere is no collapse of one logic into the other in the combination. We also\ndemonstrate that a Gentzen calculus for the combined logic can be induced from\na Gentzen calculus for the host logic by considering the translation. This\napproach applies to semantics as well. We then establish a general sufficient\ncondition for ensuring that the combined logic is both sound and complete. We\napply these principles by combining classical and intuitionistic logics\ncapitalizing on the Godel-Gentzen conservative translation, intuitionistic and\nS4 modal logics relying on the Godel-McKinsey-Tarski conservative translation,\nand classical and Jaskowski's paraconsistent logics taking into account the\nexistence of a conservative translation.","main_category":"math.LO","categories":"math.LO","published":"2025-04-14T14:55:11Z"}
{"aid":"http://arxiv.org/abs/2504.10298v1","title":"Cross-talk in superconducting qubit lattices with tunable couplers -\n  comparing transmon and fluxonium architectures","summary":"Cross-talk between qubits is one of the main challenges for scaling\nsuperconducting quantum processors. Here, we use the density-matrix\nrenormalization-group to numerically analyze lattices of superconducting qubits\nfrom a perspective of many-body localization. Specifically, we compare\ndifferent architectures that include tunable couplers designed to decouple\nqubits in the idle state, and calculate the residual ZZ interactions as well as\nthe inverse participation ratio in the computational basis states. For transmon\nqubits outside of the straddling regime, the results confirm that tunable\nC-shunt flux couplers are significantly more efficient in mitigating the ZZ\ninteractions than tunable transmons. A recently proposed fluxonium architecture\nwith tunable transmon couplers is demonstrated to also maintain its strong\nsuppression of the ZZ interactions in larger systems, while having a higher\ninverse participation ratio in the computational basis states than lattices of\ntransmon qubits. Our results thus suggest that fluxonium architectures may\nfeature lower cross talk than transmon lattices when designed to achieve\nsimilar gate speeds and fidelities.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T15:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.10301v1","title":"Three-body problem for nuclear physics","summary":"A brief excursion into the three-body problem is presented for graduate\nstudents in nuclear physics or anyone at a similar stage. Starting from\nsingle-particle coordinates, a step-by-step derivation of the Shcr\\\"{o}dinger\nequation in Jacobi coordinates is outlined. Laplace operators are explicitly\ntransformed through the chain rule for multivariable calculus. The\ntransformation of Faddeev equations from Jacobi coordinates to hyperspherical\ncoordinates is elaborated upon. In all transformations (from single-particle\ncoordinates to Jacobi coordinates, rotation between Jacobi coordinates and from\nJacobi coordinates to hyperspherical coordinates) the determinant of the\nJacobian matrix is computed to show how volume elements transform. The\nprojection of Faddeev equations on a hyperspherical harmonics basis is\nexplicitly carried out to obtain the coupled hyperradial equations that define\nthe hyperspherical harmonics method.","main_category":"nucl-th","categories":"nucl-th,physics.ed-ph","published":"2025-04-14T15:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.10302v1","title":"Nonnegativity of signomials with Newton simplex over convex sets","summary":"We study a class of signomials whose positive support is the set of vertices\nof a simplex and which may have multiple negative support points in the\nsimplex. Various groups of authors have provided an exact characterization for\nthe global nonnegativity of a signomial in this class in terms of circuit\nsignomials and that characterization provides a tractable nonnegativity test.\nWe generalize this characterization to the constrained nonnegativity over a\nconvex set $X$. This provides a tractable $X$-nonnegativity test for the class\nin terms of relative entropy programming and in terms of the support function\nof $X$. Our proof methods rely on the convex cone of constrained SAGE\nsignomials (sums of arithmetic-geometric exponentials) and the duality theory\nof this cone.","main_category":"math.CO","categories":"math.CO,math.AG,math.OC","published":"2025-04-14T15:11:12Z"}
{"aid":"http://arxiv.org/abs/2504.10311v1","title":"Performance of a Brownian information engine through potential\n  profiling: Optimum output requisites, Heating-to-Refrigeration transition and\n  their Re-entrance","summary":"Brownian Information engine (BIE) harnesses the energy from a fluctuating\nenvironment by utilizing the associated information change in the presence of a\nsingle heat bath. The engine operates in a space-dependent confining potential\nand requires an appropriate feedback control mechanism. In general, the\nfeedback controller has three different steps: measurement, feedback, and\nrelaxation. The feedback step is related to a sudden change in the potential\nenergy that is essential for a nonzero work output. BIE utilises the amount of\ninformation (surprise) acquired during the measurement step for the energy\noutput. However, due to the relaxation process, a certain amount of acquired\ninformation is lost or becomes unavailable. So, controlling information loss\nduring relaxation is crucial for the overall efficiency of the engine. The net\n(available) information, therefore, can be monitored by tuning the feedback\ncontroller and the shape of the confining potential. In this paper, we explore\nthe effect of the shape modulation of the confining potential, which may have\nmultiple stable valleys and unstable hills, on the net available information\nand, hence, the performance of a BIE that operates under an asymmetric feedback\nprotocol. We examine the optimal performance requirements of the BIE and the\namount of maximum work output under different potential profiling. For\nmonostable trapping, a concave shape in confining potential results in a higher\nwork output than a convex one. We also find that hills and valleys in the\nconfining potential may lead to multiple good operating conditions. An\nappropriate shape modulation can create a heater-refrigerator transition and\ntheir reentrance due to non-trivial changes in information loss during the\nrelaxation process.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T15:19:33Z"}
{"aid":"http://arxiv.org/abs/2504.10317v1","title":"Analysis of Attention in Video Diffusion Transformers","summary":"We conduct an in-depth analysis of attention in video diffusion transformers\n(VDiTs) and report a number of novel findings. We identify three key properties\nof attention in VDiTs: Structure, Sparsity, and Sinks. Structure: We observe\nthat attention patterns across different VDiTs exhibit similar structure across\ndifferent prompts, and that we can make use of the similarity of attention\npatterns to unlock video editing via self-attention map transfer. Sparse: We\nstudy attention sparsity in VDiTs, finding that proposed sparsity methods do\nnot work for all VDiTs, because some layers that are seemingly sparse cannot be\nsparsified. Sinks: We make the first study of attention sinks in VDiTs,\ncomparing and contrasting them to attention sinks in language models. We\npropose a number of future directions that can make use of our insights to\nimprove the efficiency-quality Pareto frontier for VDiTs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T15:25:37Z"}
{"aid":"http://arxiv.org/abs/2504.10327v1","title":"Probing Einstein-Maxwell-Scalar Black hole via Thin Accretion Disks and\n  Shadows with EHT Observations of M87* and Sgr A*","summary":"We investigated the shadows and thin accretion disks of\nEinstein-Maxwell-Scalar (EMS) black hole. Firstly, we investigated the\ninfluence of EMS parameters on the black hole shadow using the null geodesic\nmethod and constrained these parameters based on EHT observations of M87* and\nSgr A*. Furthermore, we analyzed the direct emission, lensing ring, and photon\nring structures in EMS black hole. Comparing our results with the Schwarzschild\nand Reissner-Nordstr$\\ddot{\\mathrm{o}}$m (RN) black holes, we found that the\nSchwarzschild black hole exhibits the largest shadow radius and the highest\nobserved intensity. Increasing the EMS model parameters leads to a reduction in\nintensity. Ultimately, our findings suggest that imaging black hole accretion\ndisks does not clearly distinguish among these three types of black holes.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T15:35:47Z"}
{"aid":"http://arxiv.org/abs/2504.10330v1","title":"Can genomic analysis actually estimate past population size?","summary":"Genomic data can be used to reconstruct population size over thousands of\ngenerations, using a new class of algorithms (SMC methods). These analyses\noften show a recent decline in $N_e$ (effective size), which at face value\nimplies a conservation or demographic crisis: a population crash and loss of\ngenetic diversity. This interpretation is frequently mistaken. Here we outline\nhow SMC methods work, why they generate this misleading signal, and suggest\nsimple approaches for exploiting the rich information produced by these\nalgorithms. In most species, genomic patterns reflect major changes in the\nspecies' range and subdivision over tens or hundreds of thousands of years.\nConsequently, collaboration between geneticists, palaeoecologists,\npalaeoclimatologists, and geologists is crucial for evaluating the outputs of\nSMC algorithms.","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-14T15:37:55Z"}
{"aid":"http://arxiv.org/abs/2504.10334v1","title":"Flying Hand: End-Effector-Centric Framework for Versatile Aerial\n  Manipulation Teleoperation and Policy Learning","summary":"Aerial manipulation has recently attracted increasing interest from both\nindustry and academia. Previous approaches have demonstrated success in various\nspecific tasks. However, their hardware design and control frameworks are often\ntightly coupled with task specifications, limiting the development of\ncross-task and cross-platform algorithms. Inspired by the success of robot\nlearning in tabletop manipulation, we propose a unified aerial manipulation\nframework with an end-effector-centric interface that decouples high-level\nplatform-agnostic decision-making from task-agnostic low-level control. Our\nframework consists of a fully-actuated hexarotor with a 4-DoF robotic arm, an\nend-effector-centric whole-body model predictive controller, and a high-level\npolicy. The high-precision end-effector controller enables efficient and\nintuitive aerial teleoperation for versatile tasks and facilitates the\ndevelopment of imitation learning policies. Real-world experiments show that\nthe proposed framework significantly improves end-effector tracking accuracy,\nand can handle multiple aerial teleoperation and imitation learning tasks,\nincluding writing, peg-in-hole, pick and place, changing light bulbs, etc. We\nbelieve the proposed framework provides one way to standardize and unify aerial\nmanipulation into the general manipulation community and to advance the field.\nProject website: https://lecar-lab.github.io/flying_hand/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T15:41:14Z"}
{"aid":"http://arxiv.org/abs/2504.10335v1","title":"MorphTok: Morphologically Grounded Tokenization for Indian Languages","summary":"Tokenization is a crucial step in NLP, especially with the rise of large\nlanguage models (LLMs), impacting downstream performance, computational cost,\nand efficiency. Existing LLMs rely on the classical Byte-pair Encoding (BPE)\nalgorithm for subword tokenization that greedily merges frequent character\nbigrams. This often leads to segmentation that does not align with\nlinguistically meaningful units. To address this, we propose morphology-aware\nsegmentation as a pre-tokenization step prior to applying BPE. To facilitate\nmorphology-aware segmentation, we create a novel dataset for Hindi and Marathi,\nincorporating sandhi splitting to enhance the subword tokenization. Experiments\non downstream tasks show that morphologically grounded tokenization improves\nperformance for machine translation and language modeling. Additionally, to\nhandle the ambiguity in the Unicode characters for diacritics, particularly\ndependent vowels in syllable-based writing systems, we introduce Constrained\nBPE (CBPE), an extension to the traditional BPE algorithm that incorporates\nscript-specific constraints. Specifically, CBPE handles dependent vowels. Our\nresults show that CBPE achieves a 1.68\\% reduction in fertility scores while\nmaintaining comparable or improved downstream performance in machine\ntranslation, offering a computationally efficient alternative to standard BPE.\nMoreover, to evaluate segmentation across different tokenization algorithms, we\nintroduce a new human evaluation metric, \\textit{EvalTok}, enabling more\nhuman-grounded assessment.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T15:44:45Z"}
{"aid":"http://arxiv.org/abs/2504.10336v1","title":"Analysis of the complex gas pipeline exploitation process in various\n  operating modes","summary":"The study aims to decrease gas loss and enhance system reliability during gas\npipeline accidents. A computational scheme has been developed that can enable\nthe elimination of gas leakage through the modeling and management of parallel\ngas pipeline systems. The dynamic state of processes for the supply of modern\nautomatic equipment to gas pipelines and the use of an efficient automated\ncontrol system have been extensively studied. The analytical determination of\nthe optimal transition time has been widely applied to ensure the most\nfavorable operating conditions for the system. Methods for calculating complex\ntransient processes in main gas pipelines, from a non-stationary regime to a\nstationary regime, have been developed, particularly at the moment of gas flow\ningress. A comparison of mathematical expressions for calculating transient\nprocesses in complex main gas pipelines has been conducted through theoretical\nsources.","main_category":"math.OC","categories":"math.OC","published":"2025-04-14T15:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.10346v1","title":"On Differential-Algebraic Equations with Bounded Spectrum in Banach\n  Spaces","summary":"The Weierstra{\\ss} form for regular DAEs in finite dimensions decouples a\nlinear DAE into an ODE and the nilpotent part of the underlying pencil. Here,\nwe provide necessary and sufficient conditions for the possibility of such a\ndecomposition in the case of DAEs in Banach spaces. Moreover, we consider the\nlarger class of linear operator pencils with bounded spectra and show that the\nassociated homogeneous DAE can be reduced to an ODE and a seemingly simple DAE\nof the form $\\frac d{dt}Tx = x$ with a quasi-nilpotent operator $T$. As\nexamples show, there are cases with only the trivial solution and others with\nnon-trivial solutions. We characterize the existence of $L^\\infty$-solutions on\nthe half-axis, $L^2$-solutions on compact time intervals, and analytic\nsolutions.","main_category":"math.FA","categories":"math.FA","published":"2025-04-14T15:53:50Z"}
{"aid":"http://arxiv.org/abs/2504.10373v1","title":"DUE: A Deep Learning Framework and Library for Modeling Unknown\n  Equations","summary":"Equations, particularly differential equations, are fundamental for\nunderstanding natural phenomena and predicting complex dynamics across various\nscientific and engineering disciplines. However, the governing equations for\nmany complex systems remain unknown due to intricate underlying mechanisms.\nRecent advancements in machine learning and data science offer a new paradigm\nfor modeling unknown equations from measurement or simulation data. This\nparadigm shift, known as data-driven discovery or modeling, stands at the\nforefront of AI for science, with significant progress made in recent years. In\nthis paper, we introduce a systematic framework for data-driven modeling of\nunknown equations using deep learning. This versatile framework is capable of\nlearning unknown ODEs, PDEs, DAEs, IDEs, SDEs, reduced or partially observed\nsystems, and non-autonomous differential equations. Based on this framework, we\nhave developed Deep Unknown Equations (DUE), an open-source software package\ndesigned to facilitate the data-driven modeling of unknown equations using\nmodern deep learning techniques. DUE serves as an educational tool for\nclassroom instruction, enabling students and newcomers to gain hands-on\nexperience with differential equations, data-driven modeling, and contemporary\ndeep learning approaches such as FNN, ResNet, generalized ResNet, operator\nsemigroup networks (OSG-Net), and Transformers. Additionally, DUE is a\nversatile and accessible toolkit for researchers across various scientific and\nengineering fields. It is applicable not only for learning unknown equations\nfrom data but also for surrogate modeling of known, yet complex, equations that\nare costly to solve using traditional numerical methods. We provide detailed\ndescriptions of DUE and demonstrate its capabilities through diverse examples,\nwhich serve as templates that can be easily adapted for other applications.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.DS,math.NA,stat.ML","published":"2025-04-14T16:20:55Z"}
{"aid":"http://arxiv.org/abs/2504.10379v1","title":"Minimal surfaces in strongly correlated random environments","summary":"A minimal surface in a random environment (MSRE) is a $d$-dimensional surface\nin $(d+n)$-dimensional space which minimizes the sum of its elastic energy and\nits environment potential energy, subject to prescribed boundary values. Apart\nfrom their intrinsic interest, such surfaces are further motivated by\nconnections with disordered spin systems and first-passage percolation models.\nIn this work, we consider the case of strongly correlated environments,\nrealized by the model of harmonic MSRE in a fractional Brownian environment of\nHurst parameter $H\\in(0,1)$. This includes the case of Brownian environment\n($H=1/2$ and $n=1$), which is commonly used to approximate the domain walls of\nthe $(d+1)$-dimensional random-field Ising model.\n  We prove that surfaces of dimension $d\\in\\{1,2,3\\}$ delocalize with power-law\nfluctuations, and determine their precise transversal and minimal energy\nfluctuation exponents, as well as the stretched exponential exponents governing\nthe tail decay of their distributions. These exponents are found to be the same\nin all codimensions $n$, depending only on $d$ and $H$. The transversal and\nminimal energy fluctuation exponents are specified by two scaling relations.\n  We further show that surfaces of dimension $d=4$ delocalize with\nsub-power-law fluctuations, with their height and minimal energy fluctuations\ntied by a scaling relation. Lastly, we prove that surfaces of dimensions $d\\ge\n5$ localize.\n  These results put several predictions from the physics literature on\nmathematically rigorous ground.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-14T16:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.10380v1","title":"Lorentzian Gromov-Hausdorff convergence and pre-compactness","summary":"To goal of the paper is to introduce a convergence \\`a la Gromov-Hausdorff\nfor Lorentzian spaces, building on $\\epsilon$-nets consisting of causal\ndiamonds and relying only on the time separation function. This yields a\ngeometric notion of convergence, which can be applied to synthetic Lorentzian\nspaces (Lorentzian pre-length spaces) or smooth spacetimes. Among the main\nresults, we prove a Lorentzian counterpart of the celebrated Gromov's\npre-compactness theorem for metric spaces, where controlled covers by balls are\nreplaced by controlled covers by diamonds. This yields a geometric\npre-compactness result for classes of globally hyperbolic spacetimes,\nsatisfying a uniform doubling property on Cauchy hypersurfaces and a suitable\ncontrol on the causality. The final part of the paper establishes several\napplications: we show that Chru\\'sciel-Grant approximations are an instance of\nthe Lorentzian Gromov-Hausdorff convergence here introduced, we prove that\ntimelike sectional curvature bounds are stable under such a convergence, we\nintroduce timelike blow-up tangents and discuss connections with the main\nconjecture of causal set theory.","main_category":"math.DG","categories":"math.DG,gr-qc,math-ph,math.MG,math.MP","published":"2025-04-14T16:25:36Z"}
{"aid":"http://arxiv.org/abs/2504.10382v1","title":"Why Cold BGK Modes Are So Cool: Dispersion Relations from\n  Orbit-Constrained Distribution Functions","summary":"We derive analytic dispersion relations for cold, orbitally constrained\nsystems governed by the Vlasov equation. For magnetized plasmas, we obtain the\nfirst explicit relation for two-dimensional anisotropic BGK modes with finite\nmagnetic field, showing that only a finite number of angular modes can become\nunstable and identifying a magnetic-field threshold for stabilization. In the\ngravitational case, we establish a bound on the growth rate of core\nperturbations, set by the potential's curvature. These results clarify how\norbital constraints shape the spectrum and growth of kinetic instabilities in\ncold, collisionless media.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,astro-ph.GA","published":"2025-04-14T16:27:22Z"}
{"aid":"http://arxiv.org/abs/2504.10406v1","title":"A discrete model for surface configuration spaces","summary":"One of the primary methods of studying the topology of configurations of\npoints in a graph and configurations of disks in a planar region has been to\nexamine discrete combinatorial models arising from the underlying spaces.\nDespite the success of these models in the graph and disk settings, they have\nnot been constructed for the vast majority of surface configuration spaces. In\nthis paper, we construct such a model for the ordered configuration space of\n$m$ points in an oriented surface $\\Sigma$. More specifically, we prove that if\nwe give $\\Sigma$ a certain cube complex structure $K$, then the ordered\nconfiguration space of $m$ points in $\\Sigma$ is homotopy equivalent to a\nsubcomplex of $K^{m}$","main_category":"math.AT","categories":"math.AT,math.CO,math.GT","published":"2025-04-14T16:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.10412v1","title":"AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance\n  Software Maintainability","summary":"This study explores Graph Neural Networks (GNNs) as a transformative tool for\ncode refactoring, using abstract syntax trees (ASTs) to boost software\nmaintainability. It analyzes a dataset of 2 million snippets from CodeSearchNet\nand a custom 75000-file GitHub Python corpus, comparing GNNs against rule-based\nSonarQube and decision trees. Metrics include cyclomatic complexity (target\nbelow 10), coupling (target below 5), and refactoring precision. GNNs achieve\n92% accuracy, reducing complexity by 35% and coupling by 33%, outperforming\nSonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% of\nsyntax errors. Bar graphs, tables, and AST visuals clarify results. This offers\na scalable AI-driven path to cleaner codebases, which is crucial for software\nengineering.","main_category":"cs.AI","categories":"cs.AI,cs.LG,cs.SE","published":"2025-04-14T16:58:54Z"}
{"aid":"http://arxiv.org/abs/2504.10441v1","title":"Position Uncertainty in a Prisoner's Dilemma Game : An Experiment","summary":"Gallice and Monzon (2019) present a natural environment that sustains full\ncooperation in one-shot social dilemmas among a finite number of\nself-interested agents. They demonstrate that in a sequential public goods\ngame, where agents lack knowledge of their position in the sequence but can\nobserve some predecessors' actions, full contribution emerges in equilibrium\ndue to agents' incentive to induce potential successors to follow suit.\nFurthermore, they show that this principle extends to a number of social\ndilemmas, with the prominent example that of the prisoner's dilemma. In this\nstudy, we experimentally test the theoretical predictions of this model in a\nmulti- player prisoner's dilemma environment, where subjects are not aware of\ntheir position in the sequence and receive only partial information on past\ncooperating actions. We test the predictions of the model, and through rigorous\nstructural econometric analysis, we test the descriptive capacity of the model\nagainst alternative behavioural strategies, such as conditional cooperation,\naltruistic play and free-riding behaviour. We find that the majority resorts to\nfree-riding behaviour, around 30% is classified as Gallice and Monzon (2019)\ntypes, followed by those with social preference considerations and the\nunconditional altruists.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-14T17:32:07Z"}
{"aid":"http://arxiv.org/abs/2504.10447v1","title":"Quantum geometry from the Moyal product: quantum kinetic equation and\n  non-linear response","summary":"We systematically derive the dissipationless quantum kinetic equation for a\nmulti-band free fermionic system with U(1) symmetry. Using the Moyal product\nformalism, we fully band-diagonalize the dynamics. Expanding to the second\norder in gradients, which is beyond the semiclassical limit, we give a complete\nanalysis of the band-resolved thermodynamics and transport properties,\nespecially those arising from the quantum geometric tensor. We apply our\nframework to a Bloch band theory under electric fields near equilibrium and\nfind the linear and nonlinear transport coefficients. We also obtain the\ndynamical density-density response functions in the metallic case, including\nquantum metric corrections. Our results and approach can be applied very\ngenerally to multi-band problems even in situations with spatially varying\nHamiltonians and distributions.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-14T17:37:09Z"}
{"aid":"http://arxiv.org/abs/2504.10455v1","title":"The stellar decomposition of Gaussian quantum states","summary":"We introduce the stellar decomposition, a novel method for characterizing\nnon-Gaussian states produced by photon-counting measurements on Gaussian\nstates. Given an (m+n)-mode Gaussian state G, we express it as an (m+n)-mode\n\"Gaussian core state\" G_core followed by a fixed m-mode Gaussian transformation\nT that only acts on the first m modes. The defining property of the Gaussian\ncore state G_core is that measuring the last n of its modes in the\nphoton-number basis leaves the first m modes on a finite Fock support, i.e. a\ncore state. Since T is measurement-independent and G_core has an exact and\nfinite Fock representation, this decomposition exactly describes all\nnon-Gaussian states obtainable by projecting n modes of G onto the Fock basis.\nFor pure states we prove that a physical pair (G_core, T) always exists with\nG_core pure and T unitary. For mixed states, we establish necessary and\nsufficient conditions for (G_core, T) to be a Gaussian mixed state and a\nGaussian channel. Finally, we develop a semidefinite program to extract the\n\"largest\" possible Gaussian channel when these conditions fail. The stellar\ndecomposition leads to practical bounds on achievable state quality in photonic\ncircuits and for GKP state generation in particular. Our results are based on a\nnew characterization of Gaussian completely positive maps in the Bargmann\npicture, which may be of independent interest. As a result, this work provides\nnovel tools for improved simulations of quantum optical systems, and for\nunderstanding the generation of non-Gaussian resource states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T17:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.10456v1","title":"Privacy-Preserving Distributed Link Predictions Among Peers in Online\n  Classrooms Using Federated Learning","summary":"Social interactions among classroom peers, represented as social learning\nnetworks (SLNs), play a crucial role in enhancing learning outcomes. While SLN\nanalysis has recently garnered attention, most existing approaches rely on\ncentralized training, where data is aggregated and processed on a local/cloud\nserver with direct access to raw data. However, in real-world educational\nsettings, such direct access across multiple classrooms is often restricted due\nto privacy concerns. Furthermore, training models on isolated classroom data\nprevents the identification of common interaction patterns that exist across\nmultiple classrooms, thereby limiting model performance. To address these\nchallenges, we propose one of the first frameworks that integrates Federated\nLearning (FL), a distributed and collaborative machine learning (ML) paradigm,\nwith SLNs derived from students' interactions in multiple classrooms' online\nforums to predict future link formations (i.e., interactions) among students.\nBy leveraging FL, our approach enables collaborative model training across\nmultiple classrooms while preserving data privacy, as it eliminates the need\nfor raw data centralization. Recognizing that each classroom may exhibit unique\nstudent interaction dynamics, we further employ model personalization\ntechniques to adapt the FL model to individual classroom characteristics. Our\nresults demonstrate the effectiveness of our approach in capturing both shared\nand classroom-specific representations of student interactions in SLNs.\nAdditionally, we utilize explainable AI (XAI) techniques to interpret model\npredictions, identifying key factors that influence link formation across\ndifferent classrooms. These insights unveil the drivers of social learning\ninteractions within a privacy-preserving, collaborative, and distributed ML\nframework -- an aspect that has not been explored before.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-14T17:43:11Z"}
{"aid":"http://arxiv.org/abs/2504.10460v1","title":"Target Pebbling in Trees","summary":"Graph pebbling is a game played on graphs with pebbles on their vertices. A\npebbling move removes two pebbles from one vertex and places one pebble on an\nadjacent vertex. A configuration $C$ is a supply of pebbles at various vertices\nof a graph $G$, and a distribution $D$ is a demand of pebbles at various\nvertices of $G$. The $D$-pebbling number, $\\pi(G, D)$, of a graph $G$ is\ndefined to be the minimum number $m$ such that every configuration of $m$\npebbles can satisfy the demand $D$ via pebbling moves. The special case in\nwhich $t$ pebbles are demanded on vertex $v$ is denoted $D=v^t$, and the\n$t$-fold pebbling number, $\\pi_{t}(G)$, equals $\\max_{v\\in G}\\pi(G,v^t)$. It\nwas conjectured by Alc\\'on, Gutierrez, and Hurlbert that the pebbling numbers\nof chordal graphs forbidding the pyramid graph can be calculated in polynomial\ntime. Trees, of course, are the most prominent of such graphs. In 1989, Chung\ndetermined $\\pi_t(T)$ for all trees $T$. In this paper, we provide a\npolynomial-time algorithm to compute the pebbling numbers $\\pi(T,D)$ for all\ndistributions $D$ on any tree $T$, and characterize maximum-size configurations\nthat do not satisfy $D$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T17:46:17Z"}
{"aid":"http://arxiv.org/abs/2504.10462v1","title":"The Scalability of Simplicity: Empirical Analysis of Vision-Language\n  Learning with a Single Transformer","summary":"This paper introduces SAIL, a single transformer unified multimodal large\nlanguage model (MLLM) that integrates raw pixel encoding and language decoding\nwithin a singular architecture. Unlike existing modular MLLMs, which rely on a\npre-trained vision transformer (ViT), SAIL eliminates the need for a separate\nvision encoder, presenting a more minimalist architecture design. Instead of\nintroducing novel architectural components, SAIL adapts mix-attention\nmechanisms and multimodal positional encodings to better align with the\ndistinct characteristics of visual and textual modalities. We systematically\ncompare SAIL's properties-including scalability, cross-modal information flow\npatterns, and visual representation capabilities-with those of modular MLLMs.\nBy scaling both training data and model size, SAIL achieves performance\ncomparable to modular MLLMs. Notably, the removal of pretrained ViT components\nenhances SAIL's scalability and results in significantly different cross-modal\ninformation flow patterns. Moreover, SAIL demonstrates strong visual\nrepresentation capabilities, achieving results on par with ViT-22B in vision\ntasks such as semantic segmentation. Code and models are available at\nhttps://github.com/bytedance/SAIL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:50:20Z"}
{"aid":"http://arxiv.org/abs/2504.10474v1","title":"Co-optimizing Physical Reconfiguration Parameters and Controllers for an\n  Origami-inspired Reconfigurable Manipulator","summary":"Reconfigurable robots that can change their physical configuration\npost-fabrication have demonstrate their potential in adapting to different\nenvironments or tasks. However, it is challenging to determine how to optimally\nadjust reconfigurable parameters for a given task, especially when the\ncontroller depends on the robot's configuration. In this paper, we address this\nproblem using a tendon-driven reconfigurable manipulator composed of multiple\nserially connected origami-inspired modules as an example. Under tendon\nactuation, these modules can achieve different shapes and motions, governed by\njoint stiffnesses (reconfiguration parameters) and the tendon displacements\n(control inputs). We leverage recent advances in co-optimization of design and\ncontrol for robotic system to treat reconfiguration parameters as design\nvariables and optimize them using reinforcement learning techniques. We first\nestablish a forward model based on the minimum potential energy method to\npredict the shape of the manipulator under tendon actuations. Using the forward\nmodel as the environment dynamics, we then co-optimize the control policy (on\nthe tendon displacements) and joint stiffnesses of the modules for goal\nreaching tasks while ensuring collision avoidance. Through co-optimization, we\nobtain optimized joint stiffness and the corresponding optimal control policy\nto enable the manipulator to accomplish the task that would be infeasible with\nfixed reconfiguration parameters (i.e., fixed joint stiffness). We envision the\nco-optimization framework can be extended to other reconfigurable robotic\nsystems, enabling them to optimally adapt their configuration and behavior for\ndiverse tasks and environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T17:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.10476v1","title":"Donor-Acceptor Pairs near Silicon Carbide surfaces","summary":"Donor-acceptor pairs (DAPs) in wide-bandgap semiconductors are promising\nplatforms for the realization of quantum technologies, due to their optically\ncontrollable, long-range dipolar interactions. Specifically, Al-N DAPs in bulk\nsilicon carbide (SiC) have been predicted to enable coherent coupling over\ndistances exceeding 10 nm. However, their practical implementations require an\nunderstanding of the properties of these pairs near surfaces and interfaces.\nHere, using first principles calculations we investigate how the presence of\nsurfaces influence the stability and optical properties of Al-N DAPs in SiC,\nand we show that they retain favorable optical properties comparable to their\nbulk counterparts, despite a slight increase in electron-phonon coupling.\nFurthermore, we introduce the concept of surface-defect pairs (SDPs), where an\nelectron-hole pair is generated between a near-surface defect and an occupied\nsurface state located in the bandgap of the material. We show that\nvanadium-based SDPs near OH-terminated 4H-SiC surfaces exhibit dipoles\nnaturally aligned perpendicular to the surface, greatly enhancing dipole-dipole\ncoupling between SDPs. Our results also reveal significant\npolarization-dependent modulation in the stimulated emission and\nphotoionization cross sections of V-based SDPs, which are tunable by two orders\nof magnitude via the polarization angle of the incident laser light. The\nnear-surface defects investigated here provide novel possibilities for the\ndevelopment of hybrid quantum-classical interfaces, as they can be used to\nmediate information transfer between quantum nodes and integrated photonic\ncircuits.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,quant-ph","published":"2025-04-14T17:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.10477v1","title":"Vector induced Gravitational Waves sourced by Primordial Magnetic Fields","summary":"In this work, we develop a generic formalism for the study of tensor\nperturbations induced at second order by first-order vector metric\nperturbations, dubbing these induced tensor modes $\\textit{vector-induced\ngravitational waves}$ (VIGWs). Notably, considering an inflation-inspired\npower-law type magnetic field power spectrum of the form $P_B(k)\\propto\nk^{n_\\mathrm{B}}$ (where $n_{\\rm B}$ is the magnetic spectral index), we show\nthat the VIGW signal is enhanced for stiff post-inflationary EoS, with the\nmaximum enhancement happening for $w=1$. We explicitly demonstrate this\ncontribution is dominant over the first-order magnetically-sourced GWs. The\nVIGW spectrum exhibits a maximum at around the scale crossing the cosmological\nhorizon at the end of reheating, $k_\\mathrm{reh}$, with its present day peak\namplitude scaling as $\\Omega_{\\rm GW}(k_{\\rm reh},\\eta_0)\\propto \\Delta N_{\\rm\nreh}\\times(H_{\\rm inf}/M_{\\rm Pl})^{8}$, where $H_{\\rm inf}$ is the Hubble\nparameter at the end of inflation and $\\Delta N_{\\rm reh}$ the duration of the\npost-inflationary era in $e$-folds. For $w=1$ (kination) and $n_{\\rm B}>-3/2$,\none further obtains a nearly $n_{\\rm B}$-independent frequency scaling of the\nGW spectrum of the form $\\Omega_{\\rm GW}(f,\\eta_0)\\propto \\left(\\frac{f}{f_{\\rm\nreh}}\\right)^{-2.8}$ for $f>f_\\mathrm{reh}\\equiv k_\\mathrm{reh}/(2\\pi)$.\nFinally, we need to highlight that the VIGW signal can be well within the\ndetection bands of several next-generation interferometric GW missions at small\nscales. Indicatively, for $H_{\\rm inf} \\sim O(10^{7})\\:\\mathrm{GeV}$ and\n$O(10^{14})\\:\\mathrm{GeV}$, and $\\Delta N_{\\rm reh} \\sim 15$ and $10$, the VIGW\nsignal is found to be detectable by LISA and ET respectively.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-14T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.10478v1","title":"Weight Ensembling Improves Reasoning in Language Models","summary":"We investigate a failure mode that arises during the training of reasoning\nmodels, where the diversity of generations begins to collapse, leading to\nsuboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during\nsupervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a\nsimple intervention of interpolating the weights of the latest SFT checkpoint\nwith an early checkpoint, otherwise known as WiSE-FT, almost completely\nrecovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves\nbetter test-time scaling (Best@k, majority vote) and achieves superior results\nwith less data when tuned further by reinforcement learning. Finally, we find\nthat WiSE-FT provides complementary performance gains that cannot be achieved\nonly through diversity-inducing decoding strategies, like temperature scaling.\nWe formalize a bias-variance tradeoff of Pass@k with respect to the expectation\nand variance of Pass@1 over the test distribution. We find that WiSE-FT can\nreduce bias and variance simultaneously, while temperature scaling inherently\ntrades-off between bias and variance.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-14T17:59:07Z"}
{"aid":"http://arxiv.org/abs/2504.10828v1","title":"Following Is All You Need: Robot Crowd Navigation Using People As\n  Planners","summary":"Navigating in crowded environments requires the robot to be equipped with\nhigh-level reasoning and planning techniques. Existing works focus on\ndeveloping complex and heavyweight planners while ignoring the role of human\nintelligence. Since humans are highly capable agents who are also widely\navailable in a crowd navigation setting, we propose an alternative scheme where\nthe robot utilises people as planners to benefit from their effective planning\ndecisions and social behaviours. Through a set of rule-based evaluations, we\nidentify suitable human leaders who exhibit the potential to guide the robot\ntowards its goal. Using a simple base planner, the robot follows the selected\nleader through shorthorizon subgoals that are designed to be straightforward to\nachieve. We demonstrate through both simulated and real-world experiments that\nour novel framework generates safe and efficient robot plans compared to\nexisting planners, even without predictive or data-driven modules. Our method\nalso brings human-like robot behaviours without explicitly defining traffic\nrules and social norms. Code will be available at\nhttps://github.com/centiLinda/PeopleAsPlanner.git.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T03:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.10838v1","title":"Directional Expansiveness for Rd-Actions and for Penrose Tilings","summary":"We define and study two kinds of directional expansiveness, weak and strong,\nfor an action T of \\mathbb{R}^d on a compact metric space X. We show that for\n\\mathbb{R}^2 finite local complexity (FLC) tiling dynamical systems, weak and\nstrong expansiveness are the same, and are both equivalent to a simple coding\nproperty. Then we show for the Penrose tiling dynamical system, which is FLC,\nthere are exactly five non expansive directions, the directions perpendicular\nto the 5th roots of unity. We also study Raphael Robinson's set of 24 Penrose\nWang tiles and show the corresponding Penrose Wang tile dynamical system is\nstrictly ergodic. Finally, we study two deformations of the Penrose Wang tile\nsystem, one where the square Wang tiles are all deformed into a 2\\pi/5 rhombus,\nand another where they are deformed into a set of eleven tetragon tiles. We\nshow both of these are topologically conjugate to the Penrose tiling dynamical\nsystem.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T03:43:06Z"}
{"aid":"http://arxiv.org/abs/2504.10845v1","title":"Moving Beyond Next-Token Prediction: Transformers are Context-Sensitive\n  Language Generators","summary":"Large Language Models (LLMs), powered by Transformers, have demonstrated\nhuman-like intelligence capabilities, yet their underlying mechanisms remain\npoorly understood. This paper presents a novel framework for interpreting LLMs\nas probabilistic left context-sensitive languages (CSLs) generators. We\nhypothesize that Transformers can be effectively decomposed into three\nfundamental components: context windows, attention mechanisms, and\nautoregressive generation frameworks. This decomposition allows for the\ndevelopment of more flexible and interpretable computational models, moving\nbeyond the traditional view of attention and autoregression as inseparable\nprocesses. We argue that next-token predictions can be understood as\nprobabilistic, dynamic approximations of left CSL production rules, providing\nan intuitive explanation for how simple token predictions can yield human-like\nintelligence outputs. Given that all CSLs are left context-sensitive\n(Penttonen, 1974), we conclude that Transformers stochastically approximate\nCSLs, which are widely recognized as models of human-like intelligence. This\ninterpretation bridges the gap between Formal Language Theory and the observed\ngenerative power of Transformers, laying a foundation for future advancements\nin generative AI theory and applications. Our novel perspective on Transformer\narchitectures will foster a deeper understanding of LLMs and their future\npotentials.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T04:06:27Z"}
{"aid":"http://arxiv.org/abs/2504.10853v1","title":"PT-Mark: Invisible Watermarking for Text-to-image Diffusion Models via\n  Semantic-aware Pivotal Tuning","summary":"Watermarking for diffusion images has drawn considerable attention due to the\nwidespread use of text-to-image diffusion models and the increasing need for\ntheir copyright protection. Recently, advanced watermarking techniques, such as\nTree Ring, integrate watermarks by embedding traceable patterns (e.g., Rings)\ninto the latent distribution during the diffusion process. Such methods disrupt\nthe original semantics of the generated images due to the inevitable\ndistribution shift caused by the watermarks, thereby limiting their\npracticality, particularly in digital art creation. In this work, we present\nSemantic-aware Pivotal Tuning Watermarks (PT-Mark), a novel invisible\nwatermarking method that preserves both the semantics of diffusion images and\nthe traceability of the watermark. PT-Mark preserves the original semantics of\nthe watermarked image by gradually aligning the generation trajectory with the\noriginal (pivotal) trajectory while maintaining the traceable watermarks during\nwhole diffusion denoising process. To achieve this, we first compute the\nsalient regions of the watermark at each diffusion denoising step as a spatial\nprior to identify areas that can be aligned without disrupting the watermark\npattern. Guided by the region, we then introduce an additional pivotal tuning\nbranch that optimizes the text embedding to align the semantics while\npreserving the watermarks. Extensive evaluations demonstrate that PT-Mark can\npreserve the original semantics of the diffusion images while integrating\nrobust watermarks. It achieves a 10% improvement in the performance of semantic\npreservation (i.e., SSIM, PSNR, and LPIPS) compared to state-of-the-art\nwatermarking methods, while also showing comparable robustness against\nreal-world perturbations and four times greater efficiency.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T04:25:57Z"}
{"aid":"http://arxiv.org/abs/2504.10856v1","title":"On five-dimensional curvature squared supergravity and holography","summary":"In this work, we report the recent progress in obtaining new\ncurvature-squared invariants in 5D, N=1 gauged minimal supergravity. We exhibit\nthe structure of various composite multiplets that are pivotal in the\nconstruction. We also present the form of the gauged Riemann-squared and\nGauss-Bonnet superinvariants in a dilaton-Weyl multiplet. As a first\napplication of the new curvature squared invariants, we compute their\ncorrections to holographic central charges and the Euclidean action of\nsupersymmetric charged rotating black holes, exhibiting exact matching between\nthe gravity and CFT results.","main_category":"hep-th","categories":"hep-th","published":"2025-04-15T04:35:09Z"}
{"aid":"http://arxiv.org/abs/2504.10857v1","title":"ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping","summary":"Robotic grasping is a cornerstone capability of embodied systems. Many\nmethods directly output grasps from partial information without modeling the\ngeometry of the scene, leading to suboptimal motion and even collisions. To\naddress these issues, we introduce ZeroGrasp, a novel framework that\nsimultaneously performs 3D reconstruction and grasp pose prediction in near\nreal-time. A key insight of our method is that occlusion reasoning and modeling\nthe spatial relationships between objects is beneficial for both accurate\nreconstruction and grasping. We couple our method with a novel large-scale\nsynthetic dataset, which comprises 1M photo-realistic images, high-resolution\n3D reconstructions and 11.3B physically-valid grasp pose annotations for 12K\nobjects from the Objaverse-LVIS dataset. We evaluate ZeroGrasp on the\nGraspNet-1B benchmark as well as through real-world robot experiments.\nZeroGrasp achieves state-of-the-art performance and generalizes to novel\nreal-world objects by leveraging synthetic data.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-15T04:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.10865v1","title":"Understanding the theoretical properties of projected Bellman equation,\n  linear Q-learning, and approximate value iteration","summary":"In this paper, we study the theoretical properties of the projected Bellman\nequation (PBE) and two algorithms to solve this equation: linear Q-learning and\napproximate value iteration (AVI). We consider two sufficient conditions for\nthe existence of a solution to PBE : strictly negatively row dominating\ndiagonal (SNRDD) assumption and a condition motivated by the convergence of\nAVI. The SNRDD assumption also ensures the convergence of linear Q-learning,\nand its relationship with the convergence of AVI is examined. Lastly, several\ninteresting observations on the solution of PBE are provided when using\n$\\epsilon$-greedy policy.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-15T04:56:33Z"}
{"aid":"http://arxiv.org/abs/2504.10890v1","title":"Gravitational Entropy of Hayward Black Hole","summary":"We analyze the gravitational entropy defined by the Weyl curvature for the\nHayward black hole, which is one of the regular black holes without singularity\nin the event horizon. Using the definition by the ratio of the Weyl curvature\nscalar and the Kretschmann scalar as the entropy measure, we evaluate the\ngravitational entropy on the outer and inner horizons. We derive an expression\nfor the curvature tensor of the Hayward black hole that is as independent as\npossible of the parameter added to the black hole and give an equation for the\nentropy measure explicitly independent of that parameter. The gravitational\nentropy density used in previous studies presents questions from the standpoint\nof mathematical rigor while we discuss possible improvements in its definition.\nWe compare the results for the Hayward black hole with the analysis for the\nReisner-Nordst\\\"{o}m black hole and discuss the effect of singularity\nresolution on gravitational entropy.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-15T05:53:40Z"}
{"aid":"http://arxiv.org/abs/2504.10893v1","title":"ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search","summary":"Large language models (LLMs) have demonstrated impressive capabilities and\nare receiving increasing attention to enhance their reasoning through scaling\ntest--time compute. However, their application in open--ended,\nknowledge--intensive, complex reasoning scenarios is still limited.\nReasoning--oriented methods struggle to generalize to open--ended scenarios due\nto implicit assumptions of complete world knowledge. Meanwhile,\nknowledge--augmented reasoning (KAR) methods fail to address two core\nchallenges: 1) error propagation, where errors in early steps cascade through\nthe chain, and 2) verification bottleneck, where the explore--exploit tradeoff\narises in multi--branch decision processes. To overcome these limitations, we\nintroduce ARise, a novel framework that integrates risk assessment of\nintermediate reasoning states with dynamic retrieval--augmented generation\n(RAG) within a Monte Carlo tree search paradigm. This approach enables\neffective construction and optimization of reasoning plans across multiple\nmaintained hypothesis branches. Experimental results show that ARise\nsignificantly outperforms the state--of--the--art KAR methods by up to 23.10%,\nand the latest RAG-equipped large reasoning models by up to 25.37%.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-15T06:06:50Z"}
{"aid":"http://arxiv.org/abs/2504.10897v1","title":"SCOOP: A Scalable Quantum-Computing Framework to Constrained\n  Combinatorial Optimization","summary":"While the ultimate goal of solving computationally intractable problems is to\nfind a provably optimal solutions, practical constraints of real-world\nscenarios often necessitate focusing on efficiently obtaining high-quality,\nnear-optimal solutions. The Quantum Approximate Optimization Algorithm (QAOA)\nis a state-of-the-art hybrid quantum-classical approach for tackling these\nchallenging problems that are encoded using quadratic and higher-order\nunconstrained binary optimization problems (QUBO and HUBO). We present SCOOP, a\nnovel QAOA-based framework for solving constrained optimization problems. SCOOP\ntransforms a constrained problem into an unconstrained counterpart, forming\nSCOOP problem twins. The QAOA quantum algorithm operates on the unconstrained\ntwin to identify potential optimal and near-optimal solutions. Effective\nclassical post-processing reduces the solution set to the constrained problem\nspace. Our SCOOP approach is solution-enhanced, objective-function-compatible,\nand scalable. We demonstrate the framework on three NP-hard problems, Minimum\nDominating Set, Minimum Maximal Matching, and Minimum Set Cover appearing in\npractical application domains such as resource allocation, communication\nnetworks, and machine learning. We validate SCOOP's feasibility and\neffectiveness on Xanadu PennyLane simulators.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T06:17:23Z"}
{"aid":"http://arxiv.org/abs/2504.10907v1","title":"Evidence for GeV Gamma-Ray Emission from Intense GRB 240529A During the\n  Afterglow's Shallow Decay Phase","summary":"X-ray light curves of gamma-ray burst (GRB) afterglows exhibit various\nfeatures, with the shallow decay phase being particularly puzzling. While some\nstudies report absence of the X-ray shallow decay for hyper-energetic GRBs,\nrecently discovered GRB 240529A shows a clear shallow decay phase with an\nisotropic gamma-ray energy of \\SI{2.2e54}{erg}, making it a highly unusual case\ncompared to typical GRBs. In order to investigate the physical mechanism of the\nshallow decay, we perform the \\textit{Fermi}-LAT analysis of GRB 240529A along\nwith \\textit{Swift}-XRT analysis. We find no jet break feature in the X-ray\nlight curve and then give the lower bound of the collimation-corrected jet\nenergy of $>10^{52}$~erg, which is close to the maximum rotational energy of a\nmagnetar. Our LAT data analysis reveals evidence of GeV emission with a\nstatistical significance of $4.5\\sigma$ during the shallow decay phase, which\ncan be interpreted as the first case for hyper-energetic GRBs with a typical\nshallow decay phase. The GeV to keV flux ratio is calculated to be $4.2\\pm2.3$.\nTogether with X-ray spectral index, this indicates an inverse Compton origin of\nthe GeV emission. Multiwavelength modeling based on time-dependent simulations\ntested two promising models, the energy injection and wind models. Both models\ncan explain the X-ray and gamma-ray data, while our modeling demonstrates that\ngamma-ray observations, along with future GeV--TeV observations by CTAO, will\ndistinguish between them.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T06:39:53Z"}
{"aid":"http://arxiv.org/abs/2504.10908v1","title":"Generalizability of local neural operator: example for elastodynamic\n  problems","summary":"Local neural operator (LNO) conception has provided a feasible way for\nscientific computations. The LNO learns transient partial differential\nequations from random field samples, and then the pre-trained LNO solves\npractical problems on specific computational domains. For applications, we may\nask: Are the training samples rich enough? To what extent can we trust the\nsolutions obtained from pre-trained LNO models for unknown cases? The\ngeneralizability of LNO could answer these questions. Here, we propose to use\ntwo plain scalar features, the amplitude and wavenumber of the input functions,\nto indicate the richness of training samples and to evaluate the generalization\nerror of pre-trained LNO. In elastodynamic practices, we find that isolated\nevolving wavenumber modes for Lam\\'e-Navier equation caused the training\ndataset to lack mode diversity. By data supplementation and model fine-tuning\ntargeting to the discovered lack modes, the pre-trained and fine-tuned LNO\nmodel solves Lamb problem correctly and efficiently. These results and the\nproposed generalization criteria provide a paradigm for LNO applications.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-15T06:41:05Z"}
{"aid":"http://arxiv.org/abs/2504.10915v1","title":"LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI\n  Agent Ecosystems","summary":"The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that enables agents to make context-aware decisions grounded in\nshared ethical baselines. Anchored in emerging standards such as Decentralized\nIdentifiers (DIDs), Verifiable Credentials (VCs), and post-quantum\ncryptography, LOKA offers a scalable, future-resilient blueprint for\nmulti-agent AI governance. By embedding identity, trust, and ethics into the\nprotocol layer itself, LOKA establishes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.CY","published":"2025-04-15T06:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.10921v1","title":"MSCRS: Multi-modal Semantic Graph Prompt Learning Framework for\n  Conversational Recommender Systems","summary":"Conversational Recommender Systems (CRSs) aim to provide personalized\nrecommendations by interacting with users through conversations. Most existing\nstudies of CRS focus on extracting user preferences from conversational\ncontexts. However, due to the short and sparse nature of conversational\ncontexts, it is difficult to fully capture user preferences by conversational\ncontexts only. We argue that multi-modal semantic information can enrich user\npreference expressions from diverse dimensions (e.g., a user preference for a\ncertain movie may stem from its magnificent visual effects and compelling\nstoryline). In this paper, we propose a multi-modal semantic graph prompt\nlearning framework for CRS, named MSCRS. First, we extract textual and image\nfeatures of items mentioned in the conversational contexts. Second, we capture\nhigher-order semantic associations within different semantic modalities\n(collaborative, textual, and image) by constructing modality-specific graph\nstructures. Finally, we propose an innovative integration of multi-modal\nsemantic graphs with prompt learning, harnessing the power of large language\nmodels to comprehensively explore high-dimensional semantic relationships.\nExperimental results demonstrate that our proposed method significantly\nimproves accuracy in item recommendation, as well as generates more natural and\ncontextually relevant content in response generation. We have released the code\nand the expanded multi-modal CRS datasets to facilitate further exploration in\nrelated research\\footnote{https://github.com/BIAOBIAO12138/MSCRS-main}.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-15T07:05:22Z"}
{"aid":"http://arxiv.org/abs/2504.10926v1","title":"RedDots: Planetary masses in the GJ1061 system from planet-planet\n  interaction","summary":"GJ1061 is a very nearby M star hosting three low-mass temperate planets\ndetected from radial velocity variations. The close to 4:2:1 period\ncommensurability of the planets, the available long-term monitoring of the\nsystem and new very high-precision radial velocity measurements from ESPRESSO\nenable the determination of masses from the planet-planet interaction. Using\nnested sampling, we derived parameter distributions for a co-planar\nconfiguration. The three planets (Mb =1.07 +- 0.11M_Earth, Pb =3.2073 +- 0.0003\nd, Mc=1.76 +- 0.13M_Earth, Pc=6.6821 +- 0.0008 d, Md =1.55 +- 0.17M_Earth, Pd\n=13.066 +- 0.002 d) are potentially all rocky with equilibrium temperatures\nbetween 360 K and 240 K. This makes the GJ1061 system one of the prime targets\nfor future ground or space based instruments suitable for a direct detection of\nthe planetary atmospheres.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-15T07:12:03Z"}
{"aid":"http://arxiv.org/abs/2504.10927v1","title":"Translating between NIP integral domains and topological fields","summary":"We prove that definable ring topologies on NIP fields are closely connected\nto NIP integral domains. More precisely, we show that up to elementary\nequivalence, any NIP topological field arises from an NIP integral domain. As\nan application, we prove several results about definable ring topologies on NIP\nfields, including the following. Let $K$ be an NIP field or expansion of a\nfield. Let $\\tau$ be a definable ring topology on $K$. Then $\\tau$ is a field\ntopology, and $\\tau$ is locally bounded. If $K$ has characteristic $p$ or\nfinite dp-rank, then $\\tau$ is \"generalized t-henselian\" in the sense of\nDittman, Walsberg, and Ye, meaning that the implicit function theorem holds for\npolynomials. If $K$ has finite dp-rank, then $\\tau$ must be a topology of\n\"finite breadth\" (a $W_n$-topology). Using these techniques, we give some\nreformulations of the conjecture that NIP local rings are henselian.","main_category":"math.LO","categories":"math.LO","published":"2025-04-15T07:13:03Z"}
{"aid":"http://arxiv.org/abs/2504.10935v1","title":"Sasaki-Einstein orbits in compact Hermitian symmetric spaces","summary":"The aim of the present papar is to study the orbits of the isotropy gourp\naction on an irreducible Hermitian symmetric space of compact type.\nSpecifically, we examine the properties of these orbits as {\\it CR}\nsubmanifolds of a K\\\"{a}hler manifold. Our focus is on the leaves of the\ntotally real distribution, and we investigate the properties of leaves as a\nRiemannian submanifold. In particular, we prove that any leaf is a totally\ngeodesic submanifold of the orbit. Additionally, we explore the conditions\nunder which each leaf becomes a totally geodesic submanifold of the ambient\nspace. The integrability of the complex distribution is also studied. Moreover,\nwe analyze a contact structure of orbits where the rank of the totally real\ndistribution is 1. We obtain a classification of the orbits that possess either\na contact structure or a Sasakian structure compatible with the complex\nstructure on the ambient space. Furthermore, we classify those Sasaki orbits\nthat are Einstein with respect to the induced metric. Specifically, we\ncompletely detemine Sasaki-Einstein orbits.","main_category":"math.DG","categories":"math.DG","published":"2025-04-15T07:32:14Z"}
{"aid":"http://arxiv.org/abs/2504.10941v1","title":"Tidal interactions in stellar and planetary systems","summary":"Gravitational tidal interactions drive long-term rotational and orbital\nevolution in planetary systems, in multiple (particularly close binary) star\nsystems and in planetary moon systems. Dissipation of tidal flows in Earth's\noceans is primarily responsible for producing gradual expansion of the Moon's\norbit at a few centimetres per year as the Earth's day lengthens by a few\nmilliseconds per century. Similar processes occur in many astrophysical\nsystems. For example, tidal dissipation inside (slowly rotating) stars hosting\nshort-period planets can cause the orbits of these planets to decay,\npotentially leading to planetary destruction; tidal dissipation inside stars in\nclose stellar binary systems -- and inside short-period planets such as hot\nJupiters in planetary systems -- can cause initially eccentric orbits to become\ncircular. To model these processes, explain many current observational results,\nand make predictions for future observations, we require a detailed theoretical\nunderstanding of tidal flows and the mechanisms by which -- and how efficiently\n-- they are dissipated inside stars and planets. This article will introduce\nour current understanding of tidal flows and dissipation inside stars (and to a\nlesser extent giant planets), as well as highlight some unsolved problems.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-15T07:41:32Z"}
{"aid":"http://arxiv.org/abs/2504.10947v1","title":"Improved MST3 Encryption scheme based on small Ree groups","summary":"This article presents an encryption scheme based on the small Ree groups. We\npropose utilizing the small Ree group structure to enhance the overall security\nparameters of the encryption scheme. By extending the logarithmic signature to\nencompass the entire group and modifying the encryption algorithm, we have\ndeveloped robust protection against sequential key recovery attacks.","main_category":"cs.CR","categories":"cs.CR,math.GR","published":"2025-04-15T07:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10958v1","title":"Recognition of Geometrical Shapes by Dictionary Learning","summary":"Dictionary learning is a versatile method to produce an overcomplete set of\nvectors, called atoms, to represent a given input with only a few atoms. In the\nliterature, it has been used primarily for tasks that explore its powerful\nrepresentation capabilities, such as for image reconstruction. In this work, we\npresent a first approach to make dictionary learning work for shape\nrecognition, considering specifically geometrical shapes. As we demonstrate,\nthe choice of the underlying optimization method has a significant impact on\nrecognition quality. Experimental results confirm that dictionary learning may\nbe an interesting method for shape recognition tasks.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-15T08:05:16Z"}
{"aid":"http://arxiv.org/abs/2504.10959v1","title":"Learning-Based User Association for MmWave Vehicular Networks With\n  Kernelized Contextual Bandits","summary":"Vehicles require timely channel conditions to determine the base station (BS)\nto communicate with, but it is costly to estimate the fast-fading mmWave\nchannels frequently. Without additional channel estimations, the proposed\nDistributed Kernelized Upper Confidence Bound (DK-UCB) algorithm estimates the\ncurrent instantaneous transmission rates utilizing past contexts, such as the\nvehicle's location and velocity, along with past instantaneous transmission\nrates. To capture the nonlinear mapping from a context to the instantaneous\ntransmission rate, DK-UCB maps a context into the reproducing kernel Hilbert\nspace (RKHS) where a linear mapping becomes observable. To improve estimation\naccuracy, we propose a novel kernel function in RKHS which incorporates the\npropagation characteristics of the mmWave signals. Moreover, DK-UCB encourages\na vehicle to share necessary information when it has conducted significant\nexplorations, which speeds up the learning process while maintaining affordable\ncommunication costs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T08:05:27Z"}
{"aid":"http://arxiv.org/abs/2504.10965v1","title":"Investigating the light curve variation of magnetic white dwarfs induced\n  by the axion-photon conversion","summary":"Axion-photon oscillation refers to the process of mutual conversion between\nphotons and axions when they propagate in a magnetic field. This process\ndepends on the strength of the background magnetic field, and magnetic white\ndwarfs provide a natural laboratory for testing this process. In this work, we\nstudy the behavior of axion-photon oscillation near magnetic white dwarfs: as\nthe magnetic white dwarf rotates, its magnetic field structure rotates\naccordingly, causing a periodic change of the magnetic field along the path of\nphotons. These variations affect the axion-photon oscillation process\nexperienced by the photons emitted from the white dwarf, thereby inducing a\nperiodic modulation in the intensity and polarization of the white dwarf's\nthermal emission that we observe. Our study focuses on the impact of axion\neffects on the observed light curve variation and conducts a detailed\ninvestigation through numerical calculations. Using the light curve data of the\nwhite dwarf PG1015+014 obtained from the observations by the Jacobus Kapteyn\nTelescope, which has a photometric precision of $\\sim1\\%$, we derive the\nconstraints on axion parameters. In the axion mass range of\n$\\lesssim10^{-8}\\,{\\rm eV}$, the 95\\% credible interval upper limit of the\naxion-photon coupling $g_{a\\gamma\\gamma}$ is constrained to $<8.1 \\times\n10^{-12} \\mathrm{GeV^{-1}}$.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE","published":"2025-04-15T08:17:41Z"}
{"aid":"http://arxiv.org/abs/2504.10975v1","title":"Simplicial volume of open books in dimension 4","summary":"In this short note we adapt a proof by Bucher and Neofytidis to prove that\nthe simplicial volume of 4-manifolds admitting an open book decomposition\nvanishes. In particular this shows that Quinns signature invariant, which\ndetects the existence of an open book decomposition in dimensions above 4, is\ninsufficient to characterize open books in dimension 4, even if one allows\narbitrary stabilizations via connected sums.","main_category":"math.GT","categories":"math.GT,math.AT","published":"2025-04-15T08:36:54Z"}
{"aid":"http://arxiv.org/abs/2504.10978v1","title":"AgentPolyp: Accurate Polyp Segmentation via Image Enhancement Agent","summary":"Since human and environmental factors interfere, captured polyp images\nusually suffer from issues such as dim lighting, blur, and overexposure, which\npose challenges for downstream polyp segmentation tasks. To address the\nchallenges of noise-induced degradation in polyp images, we present AgentPolyp,\na novel framework integrating CLIP-based semantic guidance and dynamic image\nenhancement with a lightweight neural network for segmentation. The agent first\nevaluates image quality using CLIP-driven semantic analysis (e.g., identifying\n``low-contrast polyps with vascular textures\") and adapts reinforcement\nlearning strategies to dynamically apply multi-modal enhancement operations\n(e.g., denoising, contrast adjustment). A quality assessment feedback loop\noptimizes pixel-level enhancement and segmentation focus in a collaborative\nmanner, ensuring robust preprocessing before neural network segmentation. This\nmodular architecture supports plug-and-play extensions for various enhancement\nalgorithms and segmentation networks, meeting deployment requirements for\nendoscopic devices.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-15T08:39:35Z"}
{"aid":"http://arxiv.org/abs/2504.10986v1","title":"PraNet-V2: Dual-Supervised Reverse Attention for Medical Image\n  Segmentation","summary":"Accurate medical image segmentation is essential for effective diagnosis and\ntreatment. Previously, PraNet-V1 was proposed to enhance polyp segmentation by\nintroducing a reverse attention (RA) module that utilizes background\ninformation. However, PraNet-V1 struggles with multi-class segmentation tasks.\nTo address this limitation, we propose PraNet-V2, which, compared to PraNet-V1,\neffectively performs a broader range of tasks including multi-class\nsegmentation. At the core of PraNet-V2 is the Dual-Supervised Reverse Attention\n(DSRA) module, which incorporates explicit background supervision, independent\nbackground modeling, and semantically enriched attention fusion. Our PraNet-V2\nframework demonstrates strong performance on four polyp segmentation datasets.\nAdditionally, by integrating DSRA to iteratively enhance foreground\nsegmentation results in three state-of-the-art semantic segmentation models, we\nachieve up to a 1.36% improvement in mean Dice score. Code is available at:\nhttps://github.com/ai4colonoscopy/PraNet-V2/tree/main/binary_seg/jittor.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:49:29Z"}
{"aid":"http://arxiv.org/abs/2504.10993v1","title":"A broken Hardy inequality on finite element space and application to\n  strain gradient elasticity","summary":"We illustrate a broken Hardy inequality on discontinuous finite element\nspaces, blowing up with a logarithmic factor with respect to the meshes size.\nThis is motivated by numerical analysis for the strain gradient elasticity with\nnatural boundary conditions. A mixed finite element pair is employed to solve\nthis model with nearly incompressible materials. This pair is quasi-stable with\na logarithmic factor, which is not significant in the approximation error, and\nconverges robustly in the incompressible limit and uniformly in the microscopic\nmaterial parameter. Numerical results back up that the theoretical predictions\nare nearly optimal. Moreover, the regularity estimates for the model over a\nsmooth domain have been proved with the aid of the Agmon-Douglis-Nirenberg\ntheory.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T09:08:57Z"}
{"aid":"http://arxiv.org/abs/2504.11007v1","title":"Kubernetes in the Cloud vs. Bare Metal: A Comparative Study of Network\n  Costs","summary":"Modern cloud-native applications increasingly utilise managed cloud services\nand containerisation technologies, such as Kubernetes, to achieve rapid\ntime-to-market and scalable deployments. Organisations must consider various\nfactors, including cost implications when deciding on a hosting platform for\ncontainerised applications as the usage grows. An emerging discipline called\nFinOps combines financial management and cloud operations to optimise costs in\ncloud-based applications. While prior research has explored system-level\noptimisation strategies for cost and resource efficiency in containerized\nsystems, analysing network costs in Kubernetes clusters remains underexplored.\nThis paper investigates the network usage and cost implications of\ncontainerised applications running on Kubernetes clusters. Using a methodology\nthat combines measurement analysis, experimentation, and cost modelling, we aim\nto provide organisations with actionable insights into network cost\noptimisation. Our findings highlight key considerations for analysing network\nexpenditures and evaluating the potential cost benefits of deploying\napplications on cloud providers. Overall, this paper contributes to the\nemerging FinOps discipline by addressing the financial and operational aspects\nof managing network costs in cloud-native environments.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-15T09:26:08Z"}
{"aid":"http://arxiv.org/abs/2504.11012v1","title":"Structure and dynamics of open-shell nuclei from spherical\n  coupled-cluster theory","summary":"We extend the spherical coupled-cluster ab initio method for open-shell\nnuclei where two nucleons are removed from a shell subclosure. Following the\nrecent implementation of the two-particle attached approach [Phys. Rev.C 110\n(2024) 4, 044306], we focus on the two-particle-removed method. Using the\nequations-of-motion framework, we address both nuclear structure and dipole\nresponse functions by coupling coupled-cluster theory with the Lorentz integral\ntransform technique. We perform calculations using chiral interactions,\nincluding three-nucleon forces, and estimate many-body uncertainties by\ncomparing different coupled-cluster truncation schemes. We validate our\napproach by studying ground-state energies, excited states, and electric dipole\npolarizabilities in the oxygen and calcium isotopic chains. For binding\nenergies and selected low-lying excited states, we achieve an accuracy\ncomparable to that of the established closed-shell coupled-cluster theory and\ngenerally agree with experiment. Finally, we underestimate experimental data\nfor electric dipole polarizabilities, particularly in calcium isotopes.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-15T09:32:57Z"}
{"aid":"http://arxiv.org/abs/2504.11014v1","title":"GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*","summary":"The emerging trend in computer vision emphasizes developing universal models\ncapable of simultaneously addressing multiple diverse tasks. Such universality\ntypically requires joint training across multi-domain datasets to ensure\neffective generalization. However, monocular 3D object detection presents\nunique challenges in multi-domain training due to the scarcity of datasets\nannotated with accurate 3D ground-truth labels, especially beyond typical\nroad-based autonomous driving contexts. To address this challenge, we introduce\na novel weakly supervised framework leveraging pseudo-labels. Current\npretrained models often struggle to accurately detect pedestrians in non-road\nenvironments due to inherent dataset biases. Unlike generalized image-based 2D\nobject detection models, achieving similar generalization in monocular 3D\ndetection remains largely unexplored. In this paper, we propose GATE3D, a novel\nframework designed specifically for generalized monocular 3D object detection\nvia weak supervision. GATE3D effectively bridges domain gaps by employing\nconsistency losses between 2D and 3D predictions. Remarkably, our model\nachieves competitive performance on the KITTI benchmark as well as on an\nindoor-office dataset collected by us to evaluate the generalization\ncapabilities of our framework. Our results demonstrate that GATE3D\nsignificantly accelerates learning from limited annotated data through\neffective pre-training strategies, highlighting substantial potential for\nbroader impacts in robotics, augmented reality, and virtual reality\napplications. Project page: https://ies0411.github.io/GATE3D/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T09:37:54Z"}
{"aid":"http://arxiv.org/abs/2504.11023v1","title":"An Inexact Variable Metric Proximal Gradient-subgradient Algorithm for a\n  Class of Fractional Optimization Problems","summary":"In this paper, we study a class of fractional optimization problems, in which\nthe numerator of the objective is the sum of a convex function and a\ndifferentiable function with a Lipschitz continuous gradient, while the\ndenominator is a nonsmooth convex function. This model has broad applicability\nand encompasses several important optimization problems in the literature. To\naddress these problems, we propose an inexact variable metric proximal\ngradient-subgradient algorithm (iVPGSA), which, to our knowledge, is the first\ninexact proximal algorithm specifically designed for solving such type of\nfractional problems. By incorporating a variable metric proximal term and\nallowing for inexact solutions to the subproblem under a flexible error\ncriterion, the proposed algorithm is highly adaptable to a broader range of\nproblems while achieving favorable computational efficiency. Under mild\nassumptions, we establish that any accumulation point of the sequence generated\nby the iVPGSA is a critical point of the target problem. Moreover, we develop\nan improved Kurdyka-{\\L}ojasiewicz (KL)-based analysis framework to prove the\nglobal convergence of the entire sequence and characterize its convergence\nrate, \\textit{without} requiring a strict sufficient descent property. Our\nresults offer detailed insights into how the KL exponent and inexactness\ninfluence the convergence rate. The proposed analysis framework also has the\npotential to serve as a theoretical tool for studying the convergence rates of\na wide range of inexact algorithms beyond the iVPGSA. Finally, some numerical\nexperiments on the $\\ell_1/\\ell_2$ Lasso problem and the constrained\n$\\ell_1/\\ell_2$ sparse optimization problem are conducted to show the superior\nperformance of the iVPGSA in comparison to existing algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T09:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.11027v1","title":"From Heteropolymer Stiffness Distributions to Effective Homopolymers: A\n  Conformational Analysis of Intrinsically Disordered Proteins","summary":"Intrinsically disordered proteins (IDPs) are characterized by a lack of\ndefined secondary and tertiary structures, and are thus well-suited for\ndescriptions within polymer theory. However, the intrinsic heterogeneity of\nproteins, stemming from their diverse amino acid building blocks, introduces\nlocal variations in chain stiffness, which can impact conformational behavior\nat larger scales. To investigate this effect, we developed a heterogeneous\nworm-like chain model in which the local persistence length follows a Gaussian\ndistribution. We demonstrate that these heterogeneous chains can be effectively\nmapped to homogeneous chains with a single effective persistence length. To\nassess whether this mapping can be extended to naturally occurring IDPs, we\nperformed simulations using various coarse-grained IDP models, finding that the\nsimulated IDPs have similar shapes like the corresponding homogeneous and\nheterogeneous worm-like chains. However, the IDPs are systematically larger\nthan ideal worm-like chains, yet slightly more compact when excluded volume\ninteractions are considered. We attribute these differences to intramolecular\ninteractions between non-bonded monomers, which our theoretical models do not\naccount for.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-15T09:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.11028v1","title":"Measuring coherent dynamics of a superconducting qubit in an open\n  waveguide","summary":"We measured the relaxation and decoherence rates of a superconducting\ntransmon qubit in a resonator-free setting. In our experiments, the qubit is\ncoupled to an open coplanar waveguide such that the transmission of microwaves\nthrough this line depends on the qubit's state. To determine the occupation of\nthe first excited qubit energy level, we introduced a two-pulse technique. The\nfirst applied pulse, at a frequency close to the eigenfrequency of the qubit,\nserves to excite the qubit. A second pulse is then used for probing the\ntransition between the first and second excited energy levels. Utilizing this\nmeasurement technique allowed for the reconstruction of the relaxation dynamics\nand Rabi oscillations. Furthermore, we demonstrate the consistency between the\nextracted parameters and the corresponding estimations from frequency-domain\nmeasurements.","main_category":"quant-ph","categories":"quant-ph,cond-mat.supr-con","published":"2025-04-15T09:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.11029v1","title":"Analytical coordinate time at the second post-Newtonian order","summary":"We derive the analytical expression of the coordinate time $t$ in terms of\nthe eccentric anomaly $u$ at the second post-Newtonian order in General\nRelativity for a compact binary system moving on eccentric orbits. The\nparametrization of $t$ with $u$ permits to reduce at the minimum the presence\nof discontinuous trigonometric functions. This is helpful as they must be\nproperly connected via accumulation functions to finally have a smooth\ncoordinate time $t(u)$. Another difficulty relies on the presence of an\ninfinite sum, about which we derive a compact form. This effort reveals to be\nextremely useful for application purposes. Indeed, we need to truncate the\naforementioned sum to a certain finite threshold, which strongly depends on the\nselected parameter values and the accuracy error we would like to achieve.\nThanks to our work, this analysis can be easily carried out.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th,math-ph,math.MP","published":"2025-04-15T09:53:26Z"}
{"aid":"http://arxiv.org/abs/2504.11032v1","title":"On Rigid Varieties Isogenous to a Product of Curves","summary":"In this note, we study rigid complex manifolds that are realized as quotients\nof a product of curves by a free action of a finite group. They serve as\nhigher-dimensional analogues of Beauville surfaces. Using uniformization, we\noutline the theory to characterize these manifolds through specific\ncombinatorial data associated with the group under the assumption that the\naction is diagonal and the manifold is of general type. This leads to the\nnotion of a $n$-fold Beauville structure. We define an action on the set of all\n$n$-fold Beauville structures of a given finite group that allows us to\ndistinguish the biholomorphism classes of the underlying rigid manifolds. As an\napplication, we give a classification of these manifolds with group $\\mathbb\nZ_5^2$ in the three dimensional case and prove that this is the smallest\npossible group that allows a rigid, free and diagonal action on a product of\nthree curves. In addition, we provide the classification of rigid 3-folds $X$\ngiven by a group acting faithfully on each factor for any value of the\nholomorphic Euler number $\\chi(\\mathcal O_X) \\geq -5$.","main_category":"math.AG","categories":"math.AG,math.CV,math.GR","published":"2025-04-15T09:54:58Z"}
{"aid":"http://arxiv.org/abs/2504.11035v1","title":"A conceptual synthesis of causal assumptions for causal discovery and\n  inference","summary":"This work presents a conceptual synthesis of causal discovery and inference\nframeworks, with a focus on how foundational assumptions -- causal sufficiency,\ncausal faithfulness, and the causal Markov condition -- are formalized and\noperationalized across methodological traditions. Through structured tables and\ncomparative summaries, I map core assumptions, tasks, and analytical choices\nfrom multiple causal frameworks, highlighting their connections and\ndifferences. The synthesis provides practical guidance for researchers\ndesigning causal studies, especially in settings where observational or\nexperimental constraints challenge standard approaches. This guide spans all\nphases of causal analysis, including question formulation, formalization of\nbackground knowledge, selection of appropriate frameworks, choice of study\ndesign or algorithm, and interpretation. It is intended as a tool to support\nrigorous causal reasoning across diverse empirical domains.","main_category":"stat.ME","categories":"stat.ME,q-bio.QM,stat.AP,stat.OT","published":"2025-04-15T09:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.11038v1","title":"QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models","summary":"In typical multimodal tasks, such as Visual Question Answering (VQA),\nadversarial attacks targeting a specific image and question can lead large\nvision-language models (LVLMs) to provide incorrect answers. However, it is\ncommon for a single image to be associated with multiple questions, and LVLMs\nmay still answer other questions correctly even for an adversarial image\nattacked by a specific question. To address this, we introduce the\nquery-agnostic visual attack (QAVA), which aims to create robust adversarial\nexamples that generate incorrect responses to unspecified and unknown\nquestions. Compared to traditional adversarial attacks focused on specific\nimages and questions, QAVA significantly enhances the effectiveness and\nefficiency of attacks on images when the question is unknown, achieving\nperformance comparable to attacks on known target questions. Our research\nbroadens the scope of visual adversarial attacks on LVLMs in practical\nsettings, uncovering previously overlooked vulnerabilities, particularly in the\ncontext of visual adversarial threats. The code is available at\nhttps://github.com/btzyd/qava.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T10:00:01Z"}
{"aid":"http://arxiv.org/abs/2504.11059v1","title":"Quantifying Group Fairness in Community Detection","summary":"Understanding community structures is crucial for analyzing networks, as\nnodes join communities that collectively shape large-scale networks. In\nreal-world settings, the formation of communities is often impacted by several\nsocial factors, such as ethnicity, gender, wealth, or other attributes. These\nfactors may introduce structural inequalities; for instance, real-world\nnetworks can have a few majority groups and many minority groups. Community\ndetection algorithms, which identify communities based on network topology, may\ngenerate unfair outcomes if they fail to account for existing structural\ninequalities, particularly affecting underrepresented groups. In this work, we\npropose a set of novel group fairness metrics to assess the fairness of\ncommunity detection methods. Additionally, we conduct a comparative evaluation\nof the most common community detection methods, analyzing the trade-off between\nperformance and fairness. Experiments are performed on synthetic networks\ngenerated using LFR, ABCD, and HICH-BA benchmark models, as well as on\nreal-world networks. Our results demonstrate that the fairness-performance\ntrade-off varies widely across methods, with no single class of approaches\nconsistently excelling in both aspects. We observe that Infomap and\nSignificance methods are high-performing and fair with respect to different\ntypes of communities across most networks. The proposed metrics and findings\nprovide valuable insights for designing fair and effective community detection\nalgorithms.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-15T10:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.11063v1","title":"UKDM: Underwater keypoint detection and matching using underwater image\n  enhancement techniques","summary":"The purpose of this paper is to explore the use of underwater image\nenhancement techniques to improve keypoint detection and matching. By applying\nadvanced deep learning models, including generative adversarial networks and\nconvolutional neural networks, we aim to find the best method which improves\nthe accuracy of keypoint detection and the robustness of matching algorithms.\nWe evaluate the performance of these techniques on various underwater datasets,\ndemonstrating significant improvements over traditional methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T10:52:19Z"}
{"aid":"http://arxiv.org/abs/2504.11076v1","title":"Using Time Structure to Estimate Causal Effects","summary":"There exist several approaches for estimating causal effects in time series\nwhen latent confounding is present. Many of these approaches rely on additional\nauxiliary observed variables or time series such as instruments, negative\ncontrols or time series that satisfy the front- or backdoor criterion in\ncertain graphs. In this paper, we present a novel approach for estimating\ndirect (and via Wright's path rule total) causal effects in a time series setup\nwhich does not rely on additional auxiliary observed variables or time series.\nThis approach assumes that the underlying time series is a Structural Vector\nAutoregressive (SVAR) process and estimates direct causal effects by solving\ncertain linear equation systems made up of different covariances and model\nparameters. We state sufficient graphical criteria in terms of the so-called\nfull time graph under which these linear equations systems are uniquely\nsolvable and under which their solutions contain the to-be-identified direct\ncausal effects as components. We also state sufficient lag-based criteria under\nwhich the previously mentioned graphical conditions are satisfied and, thus,\nunder which direct causal effects are identifiable. Several numerical\nexperiments underline the correctness and applicability of our results.","main_category":"stat.ME","categories":"stat.ME,cs.LG,G.3","published":"2025-04-15T11:21:37Z"}
{"aid":"http://arxiv.org/abs/2504.11094v1","title":"Evaluation Report on MCP Servers","summary":"With the rise of LLMs, a large number of Model Context Protocol (MCP)\nservices have emerged since the end of 2024. However, the effectiveness and\nefficiency of MCP servers have not been well studied. To study these questions,\nwe propose an evaluation framework, called MCPBench. We selected several widely\nused MCP server and conducted an experimental evaluation on their accuracy,\ntime, and token usage. Our experiments showed that the most effective MCP, Bing\nWeb Search, achieved an accuracy of 64%. Importantly, we found that the\naccuracy of MCP servers can be substantially enhanced by involving declarative\ninterface. This research paves the way for further investigations into\noptimized MCP implementations, ultimately leading to better AI-driven\napplications and data retrieval solutions.","main_category":"cs.IR","categories":"cs.IR,cs.DB","published":"2025-04-15T11:40:12Z"}
{"aid":"http://arxiv.org/abs/2504.11107v1","title":"An Invariance Principle for some Reaction-Diffusion Equations with a\n  Multiplicative Random Source","summary":"We establish a notion of universality for the parabolic Anderson model via an\ninvariance principle for a wide family of parabolic stochastic partial\ndifferential equations. We then use this invariance principle in order to\nprovide an asymptotic theory for a wide class of non-linear SPDEs. A novel\ningredient of this invariance principle is the dissipativity of the underlying\nstochastic PDE.","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T11:55:05Z"}
{"aid":"http://arxiv.org/abs/2504.11120v1","title":"Improved approximation ratios for the Quantum Max-Cut problem on\n  general, triangle-free and bipartite graphs","summary":"We study polynomial-time approximation algorithms for the Quantum Max-Cut\n(QMC) problem. Given an edge-weighted graph $G$ on n vertices, the QMC problem\nis to determine the largest eigenvalue of a particular $2^n \\times 2^n$ matrix\nthat corresponds to $G$. We provide a sharpened analysis of the currently\nbest-known QMC approximation algorithm for general graphs. This algorithm\nachieves an approximation ratio of $0.599$, which our analysis improves to\n$0.603$. Additionally, we propose two new approximation algorithms for the QMC\nproblem on triangle-free and bipartite graphs, that achieve approximation\nratios of $0.61383$ and $0.8162$, respectively. These are the best-known\napproximation ratios for their respective graph classes.","main_category":"quant-ph","categories":"quant-ph,math.OC","published":"2025-04-15T12:08:07Z"}
{"aid":"http://arxiv.org/abs/2504.11126v1","title":"KubeFence: Security Hardening of the Kubernetes Attack Surface","summary":"Kubernetes (K8s) is widely used to orchestrate containerized applications,\nincluding critical services in domains such as finance, healthcare, and\ngovernment. However, its extensive and feature-rich API interface exposes a\nbroad attack surface, making K8s vulnerable to exploits of software\nvulnerabilities and misconfigurations. Even if K8s adopts role-based access\ncontrol (RBAC) to manage access to K8s APIs, this approach lacks the\ngranularity needed to protect specification attributes within API requests.\nThis paper proposes a novel solution, KubeFence, which implements finer-grain\nAPI filtering tailored to specific client workloads. KubeFence analyzes\nKubernetes Operators from trusted repositories and leverages their\nconfiguration files to restrict unnecessary features of the K8s API, to\nmitigate misconfigurations and vulnerabilities exploitable through the K8s API.\nThe experimental results show that KubeFence can significantly reduce the\nattack surface and prevent attacks compared to RBAC.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T12:15:34Z"}
{"aid":"http://arxiv.org/abs/2504.11142v1","title":"On the dimension of the boundaries of attracting basins of entire maps","summary":"We study the dimension of the boundaries of periodic Fatou components of\ntranscendental entire maps. We prove that if $U$ is an immediate component of\nthe basin of an attracting periodic point $\\zeta$ of period $p\\ge 1$ of a\ntranscendental entire function $f\\colon \\mathbb C \\to \\mathbb C$ from the\nEremenko--Lyubich class $\\mathcal B$, such that $\\text{deg} f^p|_U = \\infty$\nand $\\overline{\\text{Sing}(f^p|_U)}$ is a compact subset of $U$, then the\nhyperbolic (and, consequently, Hausdorff) dimension of the boundary of $U$ is\nlarger than $1$. The same holds if $U$ is an immediate component of the basin\nof a parabolic $p$-periodic point $\\zeta$, under an additional assumption\n$\\zeta \\notin \\overline{\\text{Sing}(f^p)}$. We also show that if $U$ is a\nbounded immediate component of an attracting basin of a transcendental entire\nfunction $f$, then the hyperbolic dimension of the boundary of $U$ is larger\nthan $1$. In particular, this implies that the boundary of a component of an\nattracting basin of a transcendental entire function is never a smooth or\nrectifiable curve.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T12:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.11149v1","title":"An Application of Membrane Computing to Humanitarian Relief via\n  Generalized Nash Equilibrium","summary":"Natural and political disasters, including earthquakes, hurricanes, and\ntsunamis, but also migration and refugees crisis, need quick and coordinated\nresponses in order to support vulnerable populations. In such disasters,\nnongovernmental organizations compete with each other for financial donations,\nwhile people who need assistance suffer a lack of coordination, congestion in\nterms of logistics, and duplication of services. From a theoretical point of\nview, this problem can be formalized as a Generalized Nash Equilibrium (GNE)\nproblem. This is a generalization of the Nash equilibrium problem, where the\nagents' strategies are not fixed but depend on the other agents' strategies. In\nthis paper, we show that Membrane Computing can model humanitarian relief as a\nGNE problem. We propose a family of P systems that compute GNE in this context,\nand we illustrate their capabilities with Hurricane Katrina in 2005 as a case\nstudy.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-15T12:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.11153v1","title":"The interplay between Jahn-Teller distortions and structural degrees of\n  freedom on pseudocubic states in manganite perovskites","summary":"The average structure of the solid solution LaMn$_{1-x}$Ga$_x$O$_3$ (LMGO)\nhas been investigated from a symmetry-motivated approach utilizing synchrotron\nx-ray and neutron powder diffraction techniques. We show experimentally that a\ntrilinear coupling term ($\\Gamma_5^+$M$_2^+$M$_3^+$) between shear strain,\noctahedral rotation, and the $C$-type orbital ordering mode is responsible for\ndriving the orthorhombic to pseudocubic phase transition occurring in the\ncomposition range 0.5 $<$ $x$ $<$ 0.6. Our Monte Carlo simulations elucidate\nthe macroscopic origin of this coupling to shear strain, and point to its\nimportance with respect to controlling the orbital order-disorder transitions.\nWe find that the emergence of the pseudocubic state can be rationalized by\nconsidering the competition between this trilinear term and a linear-quadratic\nterm of the out-of-phase octahedral tilting with strain\n($\\Gamma_5^+$(R$_5^-$)$^2$). Illustrating the general nature of these results,\nwe construct a simple function that captures the change in Landau free energy\nat the order-disorder transition, in parameters that are trivial to relate to\nthe concentration of Jahn--Teller active species, temperature, tolerance factor\nand unit cell strain, for a broad range of manganite perovskites. Our results\npoint to the fact that far from the pseudocubic state being a symptom of\norbital disorder, it is in many cases more correctly to view it as a cause. The\nresults have a broad impact on the study of orbital ordering physics in the\nperovskite materials and on chemical and physical control parameters through\nwhich to tune the richness of the intertwined physical properties.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T12:56:38Z"}
{"aid":"http://arxiv.org/abs/2504.11177v1","title":"Pressure-Tunable Generalized Wigner Crystal and Fractional Chern\n  Insulator in twisted MoTe$_2$","summary":"Due to the forming of low-energy flat bands, the moir\\'e superlattices of the\ntransition metal dichalcogenides are fascinating platforms for studying novel\ncorrelated states when such flat bands are fractionally filled, with the\nCoulomb interaction dominating. Here, we demonstrate that pressure can\nefficiently tune the flatness and quantum geometry of the single-particle bands\nin twisted bilayer MoTe$_2$ ($\\textit{t}$MoTe$_2$). By fractionally filling the\ntopmost valence band, we find that pressure can act as a flexible means to\nmodulate the fractional Chern insulator (FCI) and the generalized Wigner\ncrystal (GWC) and control their many-body topological phase transitions.\nMoreover, our results indicate a remarkable correspondence between the\nsingle-particle band geometry and the formation of FCI and GWC. As the recent\nexperiments report the presence of FCI phases in $\\textit{t}$MoTe$_2$, our\npredictions could be readily implemented experimentally.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T13:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.11178v1","title":"MeerKAT 1.3 GHz Observations Towards the Milky Way Bulge","summary":"We present a MeerKAT survey of portions of the Milky Way bulge. The survey\ncovers 172.8 square degrees in two contiguous mosaics above and below the\nGalactic Center as well as 32 single pointing fields at higher longitudes. The\nresolution of the images is $\\sim$8\\asec\\ at a frequency of 1333 MHz with a\ntypical Stokes I RMS of 20 $\\mu$Jy Beam$^{-1}$. Most of the emission seen is\nfrom background extragalactic sources but many compact Galactic objects are\nidentifiable by their polarization properties. Apparent polarized emission\nresulting from fine scale Faraday rotation in the ISM is widespread in this\nregion of the Galaxy. The survey is used to search for background Giant Radio\nGalaxies, $>$700 kpc in size, identifying 17 such objects. Data products\ninclude FITS images of Stokes I, Q, U and V as well as a Faraday analysis and\nlists of compact total intensity and polarized sources.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T13:32:45Z"}
{"aid":"http://arxiv.org/abs/2504.11189v1","title":"Characteristics of the Invariant Measure of the Strange Attractor of the\n  Bacteria Mathematical Model","summary":"The bacteria metabolic process of open nonlinear dissipative system far from\nequilibrium point is modeled using classical methods of synergetics. The\ninvariant measure and its convergence in the phase space of the system was\nobtained in strange attractor mode. The distribution of point density of\ntrajectory intersection of phase space cells with maximum invariant measure and\nconvergence in time of its average value was obtained. The result concluded is\nthat the value of an invariant measure can be a characteristic of the\ntransitional process of adaptation of cell metabolic process to change outside\nenvironment.","main_category":"nlin.CD","categories":"nlin.CD,math.DS","published":"2025-04-15T13:47:43Z"}
{"aid":"http://arxiv.org/abs/2504.11190v1","title":"Enhancing multimodal analogical reasoning with Logic Augmented\n  Generation","summary":"Recent advances in Large Language Models have demonstrated their capabilities\nacross a variety of tasks. However, automatically extracting implicit knowledge\nfrom natural language remains a significant challenge, as machines lack active\nexperience with the physical world. Given this scenario, semantic knowledge\ngraphs can serve as conceptual spaces that guide the automated text generation\nreasoning process to achieve more efficient and explainable results. In this\npaper, we apply a logic-augmented generation (LAG) framework that leverages the\nexplicit representation of a text through a semantic knowledge graph and\napplies it in combination with prompt heuristics to elicit implicit analogical\nconnections. This method generates extended knowledge graph triples\nrepresenting implicit meaning, enabling systems to reason on unlabeled\nmultimodal data regardless of the domain. We validate our work through three\nmetaphor detection and understanding tasks across four datasets, as they\nrequire deep analogical reasoning capabilities. The results show that this\nintegrated approach surpasses current baselines, performs better than humans in\nunderstanding visual metaphors, and enables more explainable reasoning\nprocesses, though still has inherent limitations in metaphor understanding,\nespecially for domain-specific metaphors. Furthermore, we propose a thorough\nerror analysis, discussing issues with metaphorical annotations and current\nevaluation methods.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-15T13:47:55Z"}
{"aid":"http://arxiv.org/abs/2504.11198v1","title":"Semi-asymptotic bounds for moderate deviations of suprema of Gaussian\n  polynomials","summary":"We use decoupling inequalities for general Gaussian vectors and classical\ntools from Gaussian processes theory to study moderate deviations of suprema of\n  trigonometric and almost periodic\n  Gaussian polynomials.\n  Let \\begin{eqnarray*} X_x(t) &=& \\sum_{k\\le x} a_k \\,\\big( g_k \\cos 2\\pi k\n\\,t+ g'_k\\sin 2\\pi k \\, t\\, \\big), \\quad 0\\le t\\le 1, \\ x>0, \\end{eqnarray*}\nwhere $(g_k)_{k\\ge 1}$, $(g'_k)_{k\\ge 1}$ are two independent sequences of\ni.i.d. $\\mathcal N(0,1)$ distributed random variables, and $(a_k)_{k\\ge 1}$ are\nreal numbers such that $A_x = \\sum_{k\\le x} a_k^2\\uparrow \\infty$ with $x$.\n  Assume for instance that $A(x)\\sim \\log\\log x$, $x\\to \\infty$ and\n$B=\\sum_{k\\ge 1} a_k^4<\\infty$. Let $0<\\eta< 1$. We prove that\n  there exists an absolute constant $C$, such that for all $x$ large enough,\n\\begin{align*}\n  \\P\\Big\\{ \\sup_{0\\le t\\le 1}\n  X_x(t) \\le\\sqrt{2\\eta (\\log\\log x)(\\log \\log\\log x)}\\Big\\}\n  \\ \\le \\ e^{-\\,\\frac{C (\\log\\log x)^{1-\\eta}}{ \\sqrt{8\\eta (B+1)(\\log \\log\\log\nx)}}}.\n  \\end{align*}\n  We also establish an approximation theorem of moderate deviations of almost\nperiodic Gaussian polynomials by Gaussian polynomials with $\\Q$-frequencies,\nand show that the error term has an exponential decay.\n  We finally study for general non-vanishing coefficient sequences, the\nbehavior along lattices of almost periodic Gaussian polynomials with linearly\nindependent frequencies.","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T13:55:21Z"}
{"aid":"http://arxiv.org/abs/2504.11199v1","title":"Video Summarization with Large Language Models","summary":"The exponential increase in video content poses significant challenges in\nterms of efficient navigation, search, and retrieval, thus requiring advanced\nvideo summarization techniques. Existing video summarization methods, which\nheavily rely on visual features and temporal dynamics, often fail to capture\nthe semantics of video content, resulting in incomplete or incoherent\nsummaries. To tackle the challenge, we propose a new video summarization\nframework that leverages the capabilities of recent Large Language Models\n(LLMs), expecting that the knowledge learned from massive data enables LLMs to\nevaluate video frames in a manner that better aligns with diverse semantics and\nhuman judgments, effectively addressing the inherent subjectivity in defining\nkeyframes. Our method, dubbed LLM-based Video Summarization (LLMVS), translates\nvideo frames into a sequence of captions using a Muti-modal Large Language\nModel (M-LLM) and then assesses the importance of each frame using an LLM,\nbased on the captions in its local context. These local importance scores are\nrefined through a global attention mechanism in the entire context of video\ncaptions, ensuring that our summaries effectively reflect both the details and\nthe overarching narrative. Our experimental results demonstrate the superiority\nof the proposed method over existing ones in standard benchmarks, highlighting\nthe potential of LLMs in the processing of multimedia content.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:56:14Z"}
{"aid":"http://arxiv.org/abs/2504.11207v1","title":"On deformations of AdS$_3$ solutions, supersymmetry and $G$-structures","summary":"We construct new families of supersymmetric AdS$_3$ solutions in both massive\nand massless Type IIA supergravity via deformations to known backgrounds\npreserving $\\mathcal{N} = (4,0)$ and $\\mathcal{N} = (6,0)$ supersymmetry. These\ndeformations are performed along internal isometries and lead to backgrounds\nwith fully preserved or reduced supersymmetry. Using the formalism of\n$G$-structures, we systematically characterise the resulting geometries and\ntrack the evolution of their supersymmetric properties under the deformation.\nIn particular, we identify transitions among SU(3), SU(2), and identity\nstructures, and demonstrate the preservation of Killing spinors through\nexplicit spinor bilinear constructions. Additionally, we investigate D-brane\nembeddings in the deformed geometries, uncovering stable and supersymmetric\nconfigurations supported by the new backgrounds. Our results offer new insights\ninto the classification of AdS$_3$ flux vacua and provide a concrete framework\nfor understanding their potential holographic duals.","main_category":"hep-th","categories":"hep-th","published":"2025-04-15T14:11:35Z"}
{"aid":"http://arxiv.org/abs/2504.11219v1","title":"$P$-wave single charmed baryons of the $SU(3)$ flavor $\\bf\\bar3_F$","summary":"We study the $P$-wave single charmed baryons of the $SU(3)$ flavor\n$\\bf\\bar3_F$ within the framework of heavy quark effective theory. We\nsystematically calculate their strong and radiative decay properties using the\nlight-cone sum rule method. Besides the $\\Lambda_c(2595)$, $\\Lambda_c(2625)$,\n$\\Xi_c(2790)$, and $\\Xi_c(2815)$, our results suggest the existence of two\nadditional $\\Lambda_c$ baryons and two additional $\\Xi_c$ baryons. Their\nmasses, mass splittings within the same multiplets, and decay properties are\nsummarized in Table V for future experimental searches.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-15T14:22:57Z"}
{"aid":"http://arxiv.org/abs/2504.11220v1","title":"Test of lepton flavor universality with measurements of $R(D^{+})$ and\n  $R(D^{*+})$ using semileptonic $B$ tagging at the Belle II experiment","summary":"We report measurements of the ratios of branching fractions\n$\\mathcal{R}(D^{(*)+}) = \\mathcal{B}(\\overline{B}{}^0 \\to D^{(*)+} \\,\\tau^- \\,\n\\overline{\\nu}_\\tau) / \\mathcal{B}(\\overline{B}{}^0 \\to D^{(*)+} \\, \\ell^- \\,\n\\overline{\\nu}_\\ell)$, where $\\ell$ denotes either an electron or a muon. These\nratios test the universality of the charged-current weak interaction. The\nresults are based on a $365\\, \\mathrm{fb}^{-1}$ data sample collected with the\nBelle II detector at the SuperKEKB $e^+e^-$ collider, which operates at a\ncenter-of-mass energy corresponding to the $\\Upsilon(4S)$ resonance, just above\nthe threshold for $B\\overline{B}{}$ production. Signal candidates are\nreconstructed by selecting events in which the companion $B$ meson from the\n$\\Upsilon(4S) \\to B\\overline{B}{}$ decay is identified in semileptonic modes.\nThe $\\tau$ lepton is reconstructed via its leptonic decays. We obtain\n$\\mathcal{R}(D^+) = 0.418 \\pm 0.074 ~({\\mathrm{stat}}) \\pm 0.051\n~({\\mathrm{syst}})$ and $\\mathcal{R}(D^{*+}) = 0.306 \\pm 0.034\n~({\\mathrm{stat}}) \\pm 0.018 ~({\\mathrm{syst}})$, which are consistent with\nworld average values. Accounting for the correlation between them, these values\ndiffer from the Standard Model expectation by a collective significance of\n$1.7$ standard deviations.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-15T14:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.11227v1","title":"VEXP: A Low-Cost RISC-V ISA Extension for Accelerated Softmax\n  Computation in Transformers","summary":"While Transformers are dominated by Floating-Point (FP)\nMatrix-Multiplications, their aggressive acceleration through dedicated\nhardware or many-core programmable systems has shifted the performance\nbottleneck to non-linear functions like Softmax. Accelerating Softmax is\nchallenging due to its non-pointwise, non-linear nature, with exponentiation as\nthe most demanding step. To address this, we design a custom arithmetic block\nfor Bfloat16 exponentiation leveraging a novel approximation algorithm based on\nSchraudolph's method, and we integrate it into the Floating-Point Unit (FPU) of\nthe RISC-V cores of a compute cluster, through custom Instruction Set\nArchitecture (ISA) extensions, with a negligible area overhead of 1\\%. By\noptimizing the software kernels to leverage the extension, we execute Softmax\nwith 162.7$\\times$ less latency and 74.3$\\times$ less energy compared to the\nbaseline cluster, achieving an 8.2$\\times$ performance improvement and\n4.1$\\times$ higher energy efficiency for the FlashAttention-2 kernel in GPT-2\nconfiguration. Moreover, the proposed approach enables a multi-cluster system\nto efficiently execute end-to-end inference of pre-trained Transformer models,\nsuch as GPT-2, GPT-3 and ViT, achieving up to 5.8$\\times$ and 3.6$\\times$\nreduction in latency and energy consumption, respectively, without requiring\nre-training and with negligible accuracy loss.","main_category":"cs.AR","categories":"cs.AR,cs.LG","published":"2025-04-15T14:28:48Z"}
{"aid":"http://arxiv.org/abs/2504.11231v1","title":"Emergent Magnetic Structures at the 2D Limit of the Altermagnet MnTe","summary":"MnTe has recently emerged as a canonical altermagnet, a newly identified\nclass of magnetism characterized by compensated antiferromagnetic order\ncoexisting with spin-split electronic bands, traditionally considered exclusive\nto ferromagnets. However, the extent to which altermagnetism persists as\naltermagnets are thinned to the two-dimensional (2D) limit remains unexplored.\nHere, we investigate the magnetic behaviour of 2D MnTe, specifically\natomically-thin monolayers (MLs) and bilayers (BLs) grown on graphene/Ir(111)\nsubstrate, by combining experimental scanning tunneling microscopy, x-ray\nphotoelectron spectroscopy, x-ray absorption spectroscopy and x-ray magnetic\ncircular dichroism with density functional theory calculations. We find that\nwhile ML and BL MnTe adopt atomic structures with symmetries incompatible with\naltermagnetism, they exhibit intriguing magnetic phases: the BL forms a\nhighly-robust layered antiferromagnet with in-plane spin anisotropy, whereas\nthe ML exhibits a spin-glass-like behavior below its freezing temperature, a\nphenomenon not previously observed in an atomically thin material. These\nfindings highlight how reduced dimensionality can promote the emergence of\nunusual magnetic structures distinct from those of their three-dimensional\ncounterparts, providing new insights into low-dimensional magnetism.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-15T14:30:28Z"}
{"aid":"http://arxiv.org/abs/2504.11239v1","title":"Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling\n  Reasoning Benchmark for LLMs","summary":"Reasoning is the fundamental capability of large language models (LLMs). Due\nto the rapid progress of LLMs, there are two main issues of current benchmarks:\ni) these benchmarks can be crushed in a short time (less than 1 year), and ii)\nthese benchmarks may be easily hacked. To handle these issues, we propose the\never-scalingness for building the benchmarks which are uncrushable, unhackable,\nauto-verifiable and general. This paper presents Nondeterministic\nPolynomial-time Problem Challenge (NPPC), an ever-scaling reasoning benchmark\nfor LLMs. Specifically, the NPPC has three main modules: i) npgym, which\nprovides a unified interface of 25 well-known NP-complete problems and can\ngenerate any number of instances with any levels of complexities, ii) npsolver:\nwhich provides a unified interface to evaluate the problem instances with both\nonline and offline models via APIs and local deployments, respectively, and\niii) npeval: which provides the comprehensive and ready-to-use tools to analyze\nthe performances of LLMs over different problems, the number of tokens, the aha\nmoments, the reasoning errors and the solution errors. Extensive experiments\nover widely-used LLMs demonstrate: i) NPPC can successfully decrease the\nperformances of advanced LLMs' performances to below 10%, demonstrating that\nNPPC is uncrushable, ii) DeepSeek-R1, Claude-3.7-Sonnet, and o1/o3-mini are the\nmost powerful LLMs, where DeepSeek-R1 outperforms Claude-3.7-Sonnet and\no1/o3-mini in most NP-complete problems considered, and iii) the numbers of\ntokens, aha moments in the advanced LLMs, e.g., Claude-3.7-Sonnet and\nDeepSeek-R1, are observed first to increase and then decrease when the problem\ninstances become more and more difficult. We believe that NPPC is the first\never-scaling reasoning benchmark, serving as the uncrushable and unhackable\ntestbed for LLMs toward artificial general intelligence (AGI).","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-15T14:40:29Z"}
{"aid":"http://arxiv.org/abs/2504.11242v1","title":"Measurement of the g factor of ground-state 87Sr at the\n  parts-per-million level using co-trapped ultracold atoms","summary":"We demonstrate nuclear magnetic resonance of optically trapped ground-state\nultracold 87Sr atoms. Using a scheme in which a cloud of ultracold 87Rb is\nco-trapped nearby, we improve the determination of the nuclear g factor, gI ,\nof atomic 87Sr by more than two orders of magnitude, reaching accuracy at the\nparts-per-million level. We achieve similar accuracy in the ratio of relevant g\nfactors between Rb and Sr. This establishes ultracold 87Sr as an excellent\nlinear in-vacuum magnetometer. These results are relevant for ongoing efforts\ntowards quantum simulation, quantum computation and optical atomic clocks\nemploying 87Sr, and these methods can also be applied to other alkaline-earth\nand alkaline-earth-like atoms.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-15T14:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.11247v1","title":"Next-Future: Sample-Efficient Policy Learning for Robotic-Arm Tasks","summary":"Hindsight Experience Replay (HER) is widely regarded as the state-of-the-art\nalgorithm for achieving sample-efficient multi-goal reinforcement learning (RL)\nin robotic manipulation tasks with binary rewards. HER facilitates learning\nfrom failed attempts by replaying trajectories with redefined goals. However,\nit relies on a heuristic-based replay method that lacks a principled framework.\nTo address this limitation, we introduce a novel replay strategy,\n\"Next-Future\", which focuses on rewarding single-step transitions. This\napproach significantly enhances sample efficiency and accuracy in learning\nmulti-goal Markov decision processes (MDPs), particularly under stringent\naccuracy requirements -- a critical aspect for performing complex and precise\nrobotic-arm tasks. We demonstrate the efficacy of our method by highlighting\nhow single-step learning enables improved value approximation within the\nmulti-goal RL framework. The performance of the proposed replay strategy is\nevaluated across eight challenging robotic manipulation tasks, using ten random\nseeds for training. Our results indicate substantial improvements in sample\nefficiency for seven out of eight tasks and higher success rates in six tasks.\nFurthermore, real-world experiments validate the practical feasibility of the\nlearned policies, demonstrating the potential of \"Next-Future\" in solving\ncomplex robotic-arm tasks.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.LG","published":"2025-04-15T14:45:51Z"}
{"aid":"http://arxiv.org/abs/2504.11267v1","title":"Optimal control of geometric phase in pairs of interacting atoms\n  traveling along two-dimensional closed paths","summary":"Universal quantum gates whose operation depends on the manipulation of the\ngeometric phase of atomic systems are promising candidates for implementation\nof quantum computing. We propose a scheme inducing a non-trivial\nAharonov-Anandan geometric phase in pairs of atoms interacting via\ndipole-dipole potential. Our protocol relies on mobile optical trap technology\nand consists of steering a single atom along a closed loop. The trajectory of\nthe atom is controlled by a mobile optical trap, and the shape of the path is\ndesigned by applying an optimal control procedure. The geometric phase is\ngenerated as a residual of the two-atom entanglement induced by the\ndipole-dipole interaction. The stability of our scheme in the presence of noise\nor experimental imperfections is discussed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:06:40Z"}
{"aid":"http://arxiv.org/abs/2504.11268v1","title":"Single-Input Multi-Output Model Merging: Leveraging Foundation Models\n  for Dense Multi-Task Learning","summary":"Model merging is a flexible and computationally tractable approach to merge\nsingle-task checkpoints into a multi-task model. Prior work has solely focused\non constrained multi-task settings where there is a one-to-one mapping between\na sample and a task, overlooking the paradigm where multiple tasks may operate\non the same sample, e.g., scene understanding. In this paper, we focus on the\nmulti-task setting with single-input-multiple-outputs (SIMO) and show that it\nqualitatively differs from the single-input-single-output model merging\nsettings studied in the literature due to the existence of task-specific\ndecoders and diverse loss objectives. We identify that existing model merging\nmethods lead to significant performance degradation, primarily due to\nrepresentation misalignment between the merged encoder and task-specific\ndecoders. We propose two simple and efficient fixes for the SIMO setting to\nre-align the feature representation after merging. Compared to joint\nfine-tuning, our approach is computationally effective and flexible, and sheds\nlight into identifying task relationships in an offline manner. Experiments on\nNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task\narithmetic suffices to enable multi-task capabilities; however, the\nrepresentations generated by the merged encoder has to be re-aligned with the\ntask-specific heads; (2) the proposed architecture rivals traditional\nmulti-task learning in performance but requires fewer samples and training\nsteps by leveraging the existence of task-specific models.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T15:10:46Z"}
{"aid":"http://arxiv.org/abs/2504.11281v1","title":"The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to\n  Fine-Print Injections","summary":"A Large Language Model (LLM) powered GUI agent is a specialized autonomous\nsystem that performs tasks on the user's behalf according to high-level\ninstructions. It does so by perceiving and interpreting the graphical user\ninterfaces (GUIs) of relevant apps, often visually, inferring necessary\nsequences of actions, and then interacting with GUIs by executing the actions\nsuch as clicking, typing, and tapping. To complete real-world tasks, such as\nfilling forms or booking services, GUI agents often need to process and act on\nsensitive user data. However, this autonomy introduces new privacy and security\nrisks. Adversaries can inject malicious content into the GUIs that alters agent\nbehaviors or induces unintended disclosures of private information. These\nattacks often exploit the discrepancy between visual saliency for agents and\nhuman users, or the agent's limited ability to detect violations of contextual\nintegrity in task automation. In this paper, we characterized six types of such\nattacks, and conducted an experimental study to test these attacks with six\nstate-of-the-art GUI agents, 234 adversarial webpages, and 39 human\nparticipants. Our findings suggest that GUI agents are highly vulnerable,\nparticularly to contextually embedded threats. Moreover, human users are also\nsusceptible to many of these attacks, indicating that simple human oversight\nmay not reliably prevent failures. This misalignment highlights the need for\nprivacy-aware agent design. We propose practical defense strategies to inform\nthe development of safer and more reliable GUI agents.","main_category":"cs.HC","categories":"cs.HC,cs.CL,cs.CR","published":"2025-04-15T15:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.11286v1","title":"Efficient Medical Image Restoration via Reliability Guided Learning in\n  Frequency Domain","summary":"Medical image restoration tasks aim to recover high-quality images from\ndegraded observations, exhibiting emergent desires in many clinical scenarios,\nsuch as low-dose CT image denoising, MRI super-resolution, and MRI artifact\nremoval. Despite the success achieved by existing deep learning-based\nrestoration methods with sophisticated modules, they struggle with rendering\ncomputationally-efficient reconstruction results. Moreover, they usually ignore\nthe reliability of the restoration results, which is much more urgent in\nmedical systems. To alleviate these issues, we present LRformer, a Lightweight\nTransformer-based method via Reliability-guided learning in the frequency\ndomain. Specifically, inspired by the uncertainty quantification in Bayesian\nneural networks (BNNs), we develop a Reliable Lesion-Semantic Prior Producer\n(RLPP). RLPP leverages Monte Carlo (MC) estimators with stochastic sampling\noperations to generate sufficiently-reliable priors by performing multiple\ninferences on the foundational medical image segmentation model, MedSAM.\nAdditionally, instead of directly incorporating the priors in the spatial\ndomain, we decompose the cross-attention (CA) mechanism into real symmetric and\nimaginary anti-symmetric parts via fast Fourier transform (FFT), resulting in\nthe design of the Guided Frequency Cross-Attention (GFCA) solver. By leveraging\nthe conjugated symmetric property of FFT, GFCA reduces the computational\ncomplexity of naive CA by nearly half. Extensive experimental results in\nvarious tasks demonstrate the superiority of the proposed LRformer in both\neffectiveness and efficiency.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-15T15:26:28Z"}
{"aid":"http://arxiv.org/abs/2504.11288v1","title":"Large-time asymptotics of periodic two-dimensional Vlasov-Navier-Stokes\n  flows","summary":"We study the large-time behavior of finite-energy weak solutions for the\nVlasov-Navier-Stokes equations in a two-dimensional torus. We focus first on\nthe homogeneous case where the ambient (incompressible and viscous) fluid\ncarrying the particles has a constant density, and then on the variable-density\ncase. In both cases, large-time convergence to a monokinetic final state is\ndemonstrated. For any finite energy initial data, we exhibit an algebraic\nconvergence rate that deteriorates as the initial particle distribution\nincreases. When the initial particle distribution is suitably small, then the\nconvergence rate becomes exponential, a result consistent with the work of\nHan-Kwan et al. [17] dedicated to the homogeneous, three-dimensional case,\nwhere an additional smallness condition on the velocity was required. In the\nnon-homogeneous case, we establish similar stability results, allowing a\npiecewise constant fluid density with jumps.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T15:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.11307v1","title":"Uncertainty Estimation for Trust Attribution to Speed-of-Sound\n  Reconstruction with Variational Networks","summary":"Speed-of-sound (SoS) is a biomechanical characteristic of tissue, and its\nimaging can provide a promising biomarker for diagnosis. Reconstructing SoS\nimages from ultrasound acquisitions can be cast as a limited-angle\ncomputed-tomography problem, with Variational Networks being a promising\nmodel-based deep learning solution. Some acquired data frames may, however, get\ncorrupted by noise due to, e.g., motion, lack of contact, and acoustic shadows,\nwhich in turn negatively affects the resulting SoS reconstructions. We propose\nto use the uncertainty in SoS reconstructions to attribute trust to each\nindividual acquired frame. Given multiple acquisitions, we then use an\nuncertainty based automatic selection among these retrospectively, to improve\ndiagnostic decisions. We investigate uncertainty estimation based on Monte\nCarlo Dropout and Bayesian Variational Inference. We assess our automatic frame\nselection method for differential diagnosis of breast cancer, distinguishing\nbetween benign fibroadenoma and malignant carcinoma. We evaluate 21 lesions\nclassified as BI-RADS~4, which represents suspicious cases for probable\nmalignancy. The most trustworthy frame among four acquisitions of each lesion\nwas identified using uncertainty based criteria. Selecting a frame informed by\nuncertainty achieved an area under curve of 76% and 80% for Monte Carlo Dropout\nand Bayesian Variational Inference, respectively, superior to any\nuncertainty-uninformed baselines with the best one achieving 64%. A novel use\nof uncertainty estimation is proposed for selecting one of multiple data\nacquisitions for further processing and decision making.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:48:51Z"}
{"aid":"http://arxiv.org/abs/2504.11319v1","title":"Sensitivity Analysis of State Space Models for Scrap Composition\n  Estimation in EAF and BOF","summary":"This study develops and analyzes linear and nonlinear state space models for\nestimating the elemental composition of scrap steel used in steelmaking, with\napplications to Electric Arc Furnace (EAF) and Basic Oxygen Furnace (BOF)\nprocesses. The models incorporate mass balance equations and are fitted using a\nmodified Kalman filter for linear cases and the Unscented Kalman Filter (UKF)\nfor nonlinear cases. Using Cu and Cr as representative elements, we assess the\nsensitivity of model predictions to measurement noise in key process variables,\nincluding steel mass, steel composition, scrap input mass, slag mass, and iron\noxide fraction in slag. Results show that the models are robust to moderate\nnoise levels in most variables, particularly when errors are below $10\\%$.\nHowever, accuracy significantly deteriorates with noise in slag mass\nestimation. These findings highlight the practical feasibility and limitations\nof applying state space models for real-time scrap composition estimation in\nindustrial settings.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T15:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.11331v1","title":"Dependency Structure Augmented Contextual Scoping Framework for\n  Multimodal Aspect-Based Sentiment Analysis","summary":"Multimodal Aspect-Based Sentiment Analysis (MABSA) seeks to extract\nfine-grained information from image-text pairs to identify aspect terms and\ndetermine their sentiment polarity. However, existing approaches often fall\nshort in simultaneously addressing three core challenges: Sentiment Cue\nPerception (SCP), Multimodal Information Misalignment (MIM), and Semantic Noise\nElimination (SNE). To overcome these limitations, we propose DASCO\n(\\textbf{D}ependency Structure \\textbf{A}ugmented \\textbf{Sco}ping Framework),\na fine-grained scope-oriented framework that enhances aspect-level sentiment\nreasoning by leveraging dependency parsing trees. First, we designed a\nmulti-task pretraining strategy for MABSA on our base model, combining\naspect-oriented enhancement, image-text matching, and aspect-level\nsentiment-sensitive cognition. This improved the model's perception of aspect\nterms and sentiment cues while achieving effective image-text alignment,\naddressing key challenges like SCP and MIM. Furthermore, we incorporate\ndependency trees as syntactic branch combining with semantic branch, guiding\nthe model to selectively attend to critical contextual elements within a\ntarget-specific scope while effectively filtering out irrelevant noise for\naddressing SNE problem. Extensive experiments on two benchmark datasets across\nthree subtasks demonstrate that DASCO achieves state-of-the-art performance in\nMABSA, with notable gains in JMASA (+3.1\\% F1 and +5.4\\% precision on\nTwitter2015).","main_category":"cs.CL","categories":"cs.CL,cs.MM","published":"2025-04-15T16:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.11341v1","title":"Evaluating DAO Sustainability and Longevity Through On-Chain Governance\n  Metrics","summary":"Decentralised Autonomous Organisations (DAOs) automate governance and\nresource allocation through smart contracts, aiming to shift decision-making to\ndistributed token holders. However, many DAOs face sustainability challenges\nlinked to limited user participation, concentrated voting power, and technical\ndesign constraints. This paper addresses these issues by identifying research\ngaps in DAO evaluation and introducing a framework of Key Performance\nIndicators (KPIs) that capture governance efficiency, financial robustness,\ndecentralisation, and community engagement. We apply the framework to a\ncustom-built dataset of real-world DAOs constructed from on-chain data and\nanalysed using non-parametric methods. The results reveal recurring governance\npatterns, including low participation rates and high proposer concentration,\nwhich may undermine long-term viability. The proposed KPIs offer a replicable,\ndata-driven method for assessing DAO governance structures and identifying\npotential areas for improvement. These findings support a multidimensional\napproach to evaluating decentralised systems and provide practical tools for\nresearchers and practitioners working to improve the resilience and\neffectiveness of DAO-based governance models.","main_category":"cs.CY","categories":"cs.CY,cs.ET,cs.SI","published":"2025-04-15T16:13:20Z"}
{"aid":"http://arxiv.org/abs/2504.11369v1","title":"OpenTuringBench: An Open-Model-based Benchmark and Framework for\n  Machine-Generated Text Detection and Attribution","summary":"Open Large Language Models (OLLMs) are increasingly leveraged in generative\nAI applications, posing new challenges for detecting their outputs. We propose\nOpenTuringBench, a new benchmark based on OLLMs, designed to train and evaluate\nmachine-generated text detectors on the Turing Test and Authorship Attribution\nproblems. OpenTuringBench focuses on a representative set of OLLMs, and\nfeatures a number of challenging evaluation tasks, including\nhuman/machine-manipulated texts, out-of-domain texts, and texts from previously\nunseen models. We also provide OTBDetector, a contrastive learning framework to\ndetect and attribute OLLM-based machine-generated texts. Results highlight the\nrelevance and varying degrees of difficulty of the OpenTuringBench tasks, with\nour detector achieving remarkable capabilities across the various tasks and\noutperforming most existing detectors. Resources are available on the\nOpenTuringBench Hugging Face repository at\nhttps://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.HC,physics.soc-ph","published":"2025-04-15T16:36:14Z"}
{"aid":"http://arxiv.org/abs/2504.11380v1","title":"Speak with Confidence: Designing an Augmented Reality Training Tool for\n  Public Speaking","summary":"Public speaking anxiety affects many individuals, yet opportunities for\nreal-world practice remain limited. This study explores how augmented reality\n(AR) can provide an accessible training environment for public speaking.\nDrawing from literature on public speaking, VR-based training, self-efficacy,\nand behavioral feedback mechanisms, we designed SpeakAR, an AR-based tool that\nsimulates audience interaction through virtual models. SpeakAR was evaluated\nwith five participants of varying anxiety levels, each completing six speaking\ntasks. Results indicate that AR exposure can enhance confidence, with\nparticipants finding the system useful for practice. Feedback highlighted the\nimportance of dynamic facial expressions and idle animations in virtual models\nto improve realism and engagement. Our findings contribute to the design of\nAR-based training tools for public speaking, offering insights into how\nimmersive environments can support skill development and anxiety reduction.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-15T16:53:30Z"}
{"aid":"http://arxiv.org/abs/2504.11421v1","title":"HeatSense: Intelligent Thermal Anomaly Detection for Securing\n  NoC-Enabled MPSoCs","summary":"Multi-Processor System-on-Chips (MPSoCs) are highly vulnerable to thermal\nattacks that manipulate dynamic thermal management systems. To counter this, we\npropose an adaptive real-time monitoring mechanism that detects abnormal\nthermal patterns in chip tiles. Our design space exploration helped identify\nkey thermal features for an efficient anomaly detection module to be\nimplemented at routers of network-enabled MPSoCs. To minimize hardware\noverhead, we employ weighted moving average (WMA) calculations and bit-shift\noperations, ensuring a lightweight yet effective implementation. By defining a\nspectrum of abnormal behaviors, our system successfully detects and mitigates\nmalicious temperature fluctuations, reducing severe cases from 3.00{\\deg}C to\n1.9{\\deg}C. The anomaly detection module achieves up to 82% of accuracy in\ndetecting thermal attacks, which is only 10-15% less than top-performing\nmachine learning (ML) models like Random Forest. However, our approach reduces\nhardware usage by up to 75% for logic resources and 100% for specialized\nresources, making it significantly more efficient than ML-based solutions. This\nmethod provides a practical, low-cost solution for resource-constrained\nenvironments, ensuring resilience against thermal attacks while maintaining\nsystem performance.","main_category":"cs.AR","categories":"cs.AR,cs.SY,eess.SY","published":"2025-04-15T17:36:53Z"}
{"aid":"http://arxiv.org/abs/2504.11424v1","title":"MINDS. Anatomy of a water-rich, inclined, brown dwarf disk: lack of\n  abundant hydrocarbons","summary":"2MASS J04381486+2611399 (or J0438) is one of the few young brown dwarfs (BD)\nwith a highly inclined ($i\\!\\sim\\!70^\\circ$) disk. Here we report results from\nJWST-MIRI MRS, HST-ACS and ALMA Band 7 observations. Despite its late spectral\ntype (M7.25), the spectrum of J0438 resembles those of inner disks around\nearlier-type stars (K1-M5, T Tauri stars), with a volatile reservoir lacking\nhydrocarbons (except for acetylene, C$_2$H$_2$) and dominated by water. Other\nidentified species are H$_2$, CO$_2$, HCN, [Ar$^{+}$], and [Ne$^{+}$]. The\ndominance of water over hydrocarbons is driven by multiple factors such as disk\ndynamics, young disk age, low accretion rate and possible inner disk clearing.\nJ0438 appears highly dynamic, showing a seesaw-like variability and extended\nemission in H$_2 \\,\\,\\, S$(1), $S$(3), $S$(5), [Ne$^{+}$] and CO ($J=3-2$).\nInterestingly, the CO emission reaches up to 400 au from the brown dwarf,\nsuggesting ongoing infalling/outflowing activity impacting the disk chemistry.\nThese observations underscore the combined power of JWST, HST and ALMA in\ncharacterizing the chemical diversity and dynamics of brown dwarf disks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA,astro-ph.SR","published":"2025-04-15T17:37:59Z"}
{"aid":"http://arxiv.org/abs/2504.11439v1","title":"Combined Evidence for the $X_{17}$ Boson After PADME Results on Resonant\n  Production in Positron Annihilation","summary":"The Positron Annihilation into Dark Matter Experiment at the Laboratori\nNazionali di Frascati has reported an excess of $e^+e^-$ final-state events\nfrom positron annihilation on fixed-target atomic electrons. While the global\nsignificance remains at the $1.8\\,\\sigma$ level, the excess is centered around\n$\\sqrt{s} \\sim 17\\,\\text{MeV}$, coinciding with the invariant mass at which\nanomalous $e^+e^-$ pair production has previously been observed in nuclear\ntransitions from excited to ground states in $^8$Be, $^4$He and $^{12}$C,\nthereby strengthening the case for a common underlying origin, possibly\ninvolving a hypothetical new $X_{17}$ boson. We discuss the significance of\nthis independent accelerator-based evidence. Combining it with existing nuclear\nphysics results, we obtain a value for the $X_{17}$ mass of $m_{X_{17}} = 16.88\n\\pm 0.05\\,$ MeV, reducing the uncertainty from nuclear physics determinations\nalone by more than a factor of two.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-15T17:53:40Z"}
{"aid":"http://arxiv.org/abs/2504.11443v1","title":"Early Impacts of M365 Copilot","summary":"Advances in generative AI have rapidly expanded the potential of computers to\nperform or assist in a wide array of tasks traditionally performed by humans.\nWe analyze a large, real-world randomized experiment of over 6,000 workers at\n56 firms to present some of the earliest evidence on how these technologies are\nchanging the way knowledge workers do their jobs. We find substantial time\nsavings on common core tasks across a wide range of industries and occupations:\nworkers who make use of this technology spent half an hour less reading email\neach week and completed documents 12% faster. Despite the newness of the\ntechnology, nearly 40% of workers who were given access to the tool used it\nregularly in their work throughout the 6-month study.","main_category":"econ.GN","categories":"econ.GN,cs.LG,q-fin.EC","published":"2025-04-15T17:55:32Z"}
{"aid":"http://arxiv.org/abs/2504.11444v1","title":"Fault Tolerant Quantum Simulation via Symplectic Transvections","summary":"Conventional approaches to fault-tolerant quantum computing realize logical\ncircuits gate-by-gate, synthesizing each gate independently on one or more code\nblocks. This incurs excess overhead and doesn't leverage common structures in\nquantum algorithms. In contrast, we propose a framework that enables the\nexecution of entire logical circuit blocks at once, preserving their global\nstructure. This whole-block approach allows for the direct implementation of\nlogical Trotter circuits - of arbitrary rotation angles - on any stabilizer\ncode, providing a powerful new method for fault tolerant Hamiltonian simulation\nwithin a single code block. At the heart of our approach lies a deep structural\ncorrespondence between symplectic transvections and Trotter circuits. This\nconnection enables both logical and physical circuits to share the Trotter\nstructure while preserving stabilizer centralization and circuit symmetry even\nin the presence of non-Clifford rotations. We discuss potential approaches to\nfault tolerance via biased noise and code concatenation. While we illustrate\nthe key principles using a $[[8,3,3]]$ code, our simulations show that the\nframework applies to Hamiltonian simulation on even good quantum LDPC codes.\nThese results open the door to new algorithm-tailored, block-level strategies\nfor fault tolerant circuit design, especially in quantum simulation.","main_category":"quant-ph","categories":"quant-ph,cs.IT,math.IT","published":"2025-04-15T17:56:07Z"}
{"aid":"http://arxiv.org/abs/2504.11448v1","title":"Full-Diversity Construction-D Lattices: Design and Decoding Perspective\n  on Block-Fading Channels","summary":"This paper introduces a novel framework for constructing algebraic lattices\nbased on Construction-D, leveraging nested linear codes and prime ideals from\nalgebraic number fields. We focus on the application of these lattices in\nblock-fading (BF) channels, which are characterized by piecewise-constant\nfading across blocks of transmitted symbols. This approach results in a\nsemi-systematic generator matrix, providing a structured foundation for\nhigh-dimensional lattice design for BF channels. The proposed Construction-D\nlattices exhibit the full diversity property, making them highly effective for\nerror performance improvement. To address this, we develop an efficient\ndecoding algorithm designed specifically for full-diversity Construction-D\nlattices.\n  Simulations indicate that the proposed lattices notably enhance error\nperformance compared to full-diversity Construction-A lattices in diversity-2\ncases. Interestingly, unlike AWGN channels, the expected performance\nenhancement of Construction-D over Construction-A, resulting from an increased\nnumber of nested code levels, was observed only in the two-level and\ndiversity-2 cases. This phenomenon is likely attributed to the intensified\neffects of error propagation that occur during successive cancellation at\nhigher levels, as well as the higher diversity orders.\n  These findings highlight the promise of Construction-D lattices as an\neffective coding strategy for enhancing communication reliability in BF\nchannels.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-15T17:57:56Z"}
{"aid":"http://arxiv.org/abs/2504.12606v1","title":"Robo-SGG: Exploiting Layout-Oriented Normalization and Restitution for\n  Robust Scene Graph Generation","summary":"In this paper, we introduce a novel method named Robo-SGG, i.e.,\nLayout-Oriented Normalization and Restitution for Robust Scene Graph\nGeneration. Compared to the existing SGG setting, the robust scene graph\ngeneration aims to perform inference on a diverse range of corrupted images,\nwith the core challenge being the domain shift between the clean and corrupted\nimages. Existing SGG methods suffer from degraded performance due to\ncompromised visual features e.g., corruption interference or occlusions. To\nobtain robust visual features, we exploit the layout information, which is\ndomain-invariant, to enhance the efficacy of existing SGG methods on corrupted\nimages. Specifically, we employ Instance Normalization(IN) to filter out the\ndomain-specific feature and recover the unchangeable structural features, i.e.,\nthe positional and semantic relationships among objects by the proposed\nLayout-Oriented Restitution. Additionally, we propose a Layout-Embedded Encoder\n(LEE) that augments the existing object and predicate encoders within the SGG\nframework, enriching the robust positional and semantic features of objects and\npredicates. Note that our proposed Robo-SGG module is designed as a\nplug-and-play component, which can be easily integrated into any baseline SGG\nmodel. Extensive experiments demonstrate that by integrating the\nstate-of-the-art method into our proposed Robo-SGG, we achieve relative\nimprovements of 5.6%, 8.0%, and 6.5% in mR@50 for PredCls, SGCls, and SGDet\ntasks on the VG-C dataset, respectively, and achieve new state-of-the-art\nperformance in corruption scene graph generation benchmark (VG-C and GQA-C). We\nwill release our source code and model.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T03:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.12609v1","title":"Crossing the Human-Robot Embodiment Gap with Sim-to-Real RL using One\n  Human Demonstration","summary":"Teaching robots dexterous manipulation skills often requires collecting\nhundreds of demonstrations using wearables or teleoperation, a process that is\nchallenging to scale. Videos of human-object interactions are easier to collect\nand scale, but leveraging them directly for robot learning is difficult due to\nthe lack of explicit action labels from videos and morphological differences\nbetween robot and human hands. We propose Human2Sim2Robot, a novel\nreal-to-sim-to-real framework for training dexterous manipulation policies\nusing only one RGB-D video of a human demonstrating a task. Our method utilizes\nreinforcement learning (RL) in simulation to cross the human-robot embodiment\ngap without relying on wearables, teleoperation, or large-scale data collection\ntypically necessary for imitation learning methods. From the demonstration, we\nextract two task-specific components: (1) the object pose trajectory to define\nan object-centric, embodiment-agnostic reward function, and (2) the\npre-manipulation hand pose to initialize and guide exploration during RL\ntraining. We found that these two components are highly effective for learning\nthe desired task, eliminating the need for task-specific reward shaping and\ntuning. We demonstrate that Human2Sim2Robot outperforms object-aware open-loop\ntrajectory replay by 55% and imitation learning with data augmentation by 68%\nacross grasping, non-prehensile manipulation, and multi-step tasks. Project\nSite: https://human2sim2robot.github.io","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-17T03:15:20Z"}
{"aid":"http://arxiv.org/abs/2504.12617v1","title":"Bayesian Density-Density Regression with Application to Cell-Cell\n  Communications","summary":"We introduce a scalable framework for regressing multivariate distributions\nonto multivariate distributions, motivated by the application of inferring\ncell-cell communication from population-scale single-cell data. The observed\ndata consist of pairs of multivariate distributions for ligands from one cell\ntype and corresponding receptors from another. For each ordered pair $e=(l,r)$\nof cell types $(l \\neq r)$ and each sample $i = 1, \\ldots, n$, we observe a\npair of distributions $(F_{ei}, G_{ei})$ of gene expressions for ligands and\nreceptors of cell types $l$ and $r$, respectively. The aim is to set up a\nregression of receptor distributions $G_{ei}$ given ligand distributions\n$F_{ei}$. A key challenge is that these distributions reside in distinct spaces\nof differing dimensions. We formulate the regression of multivariate densities\non multivariate densities using a generalized Bayes framework with the sliced\nWasserstein distance between fitted and observed distributions. Finally, we use\ninference under such regressions to define a directed graph for cell-cell\ncommunications.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO,stat.ML","published":"2025-04-17T03:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.12618v1","title":"Simultaneous Superoscillations in Space and Time in Nonseparable Light\n  Pulses","summary":"A remarkable phenomenon of superoscillations implies that electromagnetic\nwaves can locally oscillate in space or time faster than the fastest spatial\nand temporal Fourier component of the entire function. This phenomenon allows\nto focus light into an arbitrary small hotspot enabling superresolution imaging\nand optical metrology with accuracy far beyond the Abbey-Reileigh diffraction\nlimit. Here we show that, in band-limited supertoroidal light pulses, the\ntemporal and spatial superoscillations can be observed simultaneously at a\nspecific region in space and at a specific interval in time.","main_category":"physics.optics","categories":"physics.optics,physics.class-ph","published":"2025-04-17T03:47:11Z"}
{"aid":"http://arxiv.org/abs/2504.12622v1","title":"Can metric radio bursts be used as a diagnostics tool for interplanetary\n  coronal mass ejections?","summary":"Metric radio bursts are often said to be valuable diagnostic tools for\nstudying the near-sun kinematics and energetics of the Interplanetary Coronal\nMass Ejections (ICMEs). Radio observations also serve as an indirect tool to\nestimate the coronal magnetic fields. However, how these estimated coronal\nmagnetic fields are related to the magnetic field strength in the ICME at 1 AU\nhas rarely been explored. We aim to establish a relation between the coronal\nmagnetic fields obtained from the radio observations very close to the Sun and\nthe magnetic field measured at 1 AU when the ICME arrives at the Earth. We\nperformed statistical analysis of all metric type II radio bursts in solar\ncycles 23 and 24, which were found to be associated with ICMEs. We estimated\nthe coronal magnetic field associated with the corresponding CME near the Sun\n(middle corona) using a split-band radio technique and compared those with the\nmagnetic fields recorded at 1 AU with in-situ observations. We found that the\nestimated magnetic fields near the Sun using radio techniques are not well\ncorrelated with the magnetic fields measured at 1 AU using in-situ\nobservations. This could be due to the complex evolution of the magnetic field\nas it propagates through the heliosphere. Our results suggest that while metric\nradio observations can serve as effective proxies for estimating magnetic\nfields near the Sun, they may not be as effective close to the Earth. At least,\nno linear relation could be established using metric radio emissions to\nestimate the magnetic fields at 1 AU with acceptable error margins.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.space-ph","published":"2025-04-17T03:55:30Z"}
{"aid":"http://arxiv.org/abs/2504.12626v1","title":"Packing Input Frame Context in Next-Frame Prediction Models for Video\n  Generation","summary":"We present a neural network structure, FramePack, to train next-frame (or\nnext-frame-section) prediction models for video generation. The FramePack\ncompresses input frames to make the transformer context length a fixed number\nregardless of the video length. As a result, we are able to process a large\nnumber of frames using video diffusion with computation bottleneck similar to\nimage diffusion. This also makes the training video batch sizes significantly\nhigher (batch sizes become comparable to image diffusion training). We also\npropose an anti-drifting sampling method that generates frames in inverted\ntemporal order with early-established endpoints to avoid exposure bias (error\naccumulation over iterations). Finally, we show that existing video diffusion\nmodels can be finetuned with FramePack, and their visual quality may be\nimproved because the next-frame prediction supports more balanced diffusion\nschedulers with less extreme flow shift timesteps.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T04:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.12630v1","title":"Crystal growth, structure and physical properties of\n  quasi-one-dimensional tellurides Fe$_{4-x}$VTe$_{4-y}$ ($x=1.01$, $y=0.74$)\n  and V$_{4.64}$Te$_4$","summary":"A new ternary compound Fe$_{4-x}$VTe$_{4-y}$ ($x=1.01$, $y=0.74$) with\nTi5Te4-type structure is identified. Fe and V atoms tend to occupy different\ncrystallographic positions and form quasi-one-dimensional (quasi-1D) Fe-V\nchains along the c-axis. Millimeter-sized single crystal of\nFe$_{2.99}$VTe$_{3.26}$ (FVT) with slender-stick shape could be grown by\nchemical vapor transport method which reflects its quasi-1D crystal structure.\nMagnetization measurements reveal that FVT orders antiferromagnetically below\nT$_N$=93 K with strong easy ab-plane magnetic anisotropy. Although a weak\nglassy-like behavior appears below 10 K, FVT is dominant by long-range\nantiferromagnetic order in contrast to the spin-glass state in previously\nreported isostructural Fe$_{5}$Te$_{4}$. We also synthesize V$_{4.64}$Te$_4$\nwith similar quasi-1D V-chains and find it has weak anomalies at 144 K on both\nresistivity and susceptibility curves. However, no clear evidence is found for\nthe development of magnetic or charge order. X-ray photoelectron spectroscopy\nand Curie-Weiss fit reveal that the effective moments for Fe$^{2+}$ and\nV$^{4+}$ in both compounds have large deviations from the conventional local\nmoment model, which may possibly result from the formation of Fe/V metal-metal\nbondings. Furthermore the resistivity of both FVT and V$_{4.64}$Te$_4$ exhibits\nsemiconducting-like temperature-dependent behavior but with average values\nclose to typical bad metals, which resembles the transport behavior in the\nnormal state of Fe-based superconductors. These quasi-1D compounds have shown\ninteresting physical properties for future condensed matter physics research.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci,cond-mat.supr-con","published":"2025-04-17T04:13:56Z"}
{"aid":"http://arxiv.org/abs/2504.12639v1","title":"Mass measurements of proton-rich nuclei in the vicinity of ${}^{84}$Mo\n  and their impact on rp-process in type I X-ray burst","summary":"We report on the mass measurement of the rapid proton-capture process key\nnuclide ${}^{84}$Mo and its vicinity, such as ${}^{78}$Y${}^{\\rm m}$,\n${}^{79}$Y, ${}^{83}$Nb, and ${}^{88}$Ru, using the multi-reflection\ntime-of-flight spectrograph at RIKEN RIBF. For ${}^{78}$Y${}^{\\rm m}$,\n${}^{84}$Mo, and ${}^{88}$Ru, their masses are experimentally determined for\nthe first time with uncertainties of $\\delta m \\approx 20~{\\rm keV}$. The mass\nprecision of ${}^{79}$Y and ${}^{83}$Nb is improved to 13 keV and 9.6 keV,\nrespectively. The new $\\alpha$-separation energy of ${}^{84}$Mo, 1.434(83) MeV,\nunambiguously rules out the possibility of forming the ZrNb cycle. The X-ray\nburst simulation with the new masses shows that our measurements effectively\nremove the large final abundance uncertainties in the $A=80-90$ mass region.\nThe new mass values improve the prediction power for the composition of the\nnuclear ashes in X-ray bursts, including the production of light $p$-nuclei.","main_category":"nucl-ex","categories":"nucl-ex,astro-ph.HE,nucl-th","published":"2025-04-17T04:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.12648v1","title":"Enantiospecific Two-Photon Electric-Dipole Selection Rules of Chiral\n  Molecules","summary":"Distinguishing between enantiomers is crucial in the study of chiral\nmolecules in chemistry and pharmacology. Many optical approaches rely on\nenantiospecific cyclic electric-dipole transitions induced by three microwave\nor laser beams. However, these approaches impose stringent requirements,\nincluding phase locking, three-photon resonance, and precise control over beam\nintensities and operation times, which enhance the complexity and restrict the\napplicability. In this letter, we present a novel optical method that {\\it\neliminates these constraints entirely.} Specifically, we demonstrate that in\nthe presence of a static electric field, the selection rules for two-photon\nelectric-dipole transitions differ between enantiomers. This distinction arises\nbecause the static electric field breaks the symmetry associated with the\ncombined action of a specific rotation and time-reversal transformation.\nLeveraging the enantiospecific two-photon selection rule, one can selectively\nexcite a desired enantiomer using only two beams, without the need for phase\nlocking, resonance condition, and the precise control of their intensities and\noperation times. Our method significantly enhances the feasibility and\napplicability of optical approaches for enantiomer differentiation.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T05:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.12654v1","title":"The Paradox of Professional Input: How Expert Collaboration with AI\n  Systems Shapes Their Future Value","summary":"This perspective paper examines a fundamental paradox in the relationship\nbetween professional expertise and artificial intelligence: as domain experts\nincreasingly collaborate with AI systems by externalizing their implicit\nknowledge, they potentially accelerate the automation of their own expertise.\nThrough analysis of multiple professional contexts, we identify emerging\npatterns in human-AI collaboration and propose frameworks for professionals to\nnavigate this evolving landscape. Drawing on research in knowledge management,\nexpertise studies, human-computer interaction, and labor economics, we develop\na nuanced understanding of how professional value may be preserved and\ntransformed in an era of increasingly capable AI systems. Our analysis suggests\nthat while the externalization of tacit knowledge presents certain risks to\ntraditional professional roles, it also creates opportunities for the evolution\nof expertise and the emergence of new forms of professional value. We conclude\nwith implications for professional education, organizational design, and policy\ndevelopment that can help ensure the codification of expert knowledge enhances\nrather than diminishes the value of human expertise.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-17T05:32:21Z"}
{"aid":"http://arxiv.org/abs/2504.12655v1","title":"Optimizing low-dissipation Carnot-like thermal devices with heat leak","summary":"Delimiting the bounds of optimal performance for heat engines (HEs),\nrefrigerators (REs), and heat pumps (HPs) is a central goal in thermodynamics.\nWhile low-dissipation (LD) models have proven valuable for this purpose, the\nrole of heat leak in such models has received limited attention. Here, we\npresent a unified framework for LD Carnot-like (CL) HEs, REs, and HPs that\nincorporates heat leaks, and derive new results for the efficiency at maximum\npower and the power at maximum efficiency. We further investigate the\nrelationship between the bounds of power at fixed efficiency and efficiency at\nfixed power, demonstrating that these bounds coincide and are described by\nidentical curves across all thermal devices. Finally, we show that the optimal\nperformance of all three devices can be achieved by optimizing the average\nentropy production rate over the cycle, a result that holds for any CL device\nand extends beyond the LD assumption.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-17T05:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.12674v1","title":"Can spacetime fluctuations generate entanglement between co-moving\n  accelerated detectors?","summary":"Recent studies [Class. Quant. Grav. 42, 03LT01 (2025); Phys. Rev. D 111,\n045023 (2025)] indicate that in a nested sequence of Rindler wedges, vacuum of\nformer Rindler frame appears to be thermally populated for an observer in\nshifted Rindler frame. Interestingly, this thermality is independent of shift\nparameter as long as it is non-zero and therefore arises even if the shift\nparameter is as small as Planck length. Building on this insight, we propose a\nset-up involving two atoms accelerating with identical acceleration. We find\nthat if their Rindler frames (consequently their trajectories) get\ninfinitesimally separated, the atoms become entangled. Remarkably again, this\nentanglement, like the perceived thermality, is independent of the shift\nparameter, provided it is non-vanishing. We investigate the dependence of\nentanglement on acceleration of the detectors. The present study indicates that\nthe entanglement between two detectors, moving on the same Rindler wedge, is\npossible. Moreover, small spacetime fluctuations can lead to entanglement\nbetween detectors, moving along same classical trajectory. Hence we feel that\nsuch theoretical prediction has potential to probe the Planck length nature of\nspacetime.","main_category":"gr-qc","categories":"gr-qc,hep-th,quant-ph","published":"2025-04-17T06:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.12681v1","title":"GRAIL: Gradient-Based Adaptive Unlearning for Privacy and Copyright in\n  LLMs","summary":"Large Language Models (LLMs) trained on extensive datasets often learn\nsensitive information, which raises significant social and legal concerns under\nprinciples such as the \"Right to be forgotten.\" Retraining entire models from\nscratch to remove undesired information is both costly and impractical.\nFurthermore, existing single-domain unlearning methods fail to address\nmulti-domain scenarios, where knowledge is interwoven across domains such as\nprivacy and copyright, creating overlapping representations that lead to\nexcessive knowledge removal or degraded performance. To tackle these issues, we\npropose GRAIL (GRadient-based AdaptIve unLearning), a novel multi-domain\nunlearning framework. GRAIL leverages gradient information from multiple\ndomains to precisely distinguish the unlearning scope from the retention scope,\nand applies an adaptive parameter-wise localization strategy to selectively\nremove targeted knowledge while preserving critical parameters for each domain.\nExperimental results on unlearning benchmarks show that GRAIL achieves\nunlearning success on par with the existing approaches, while also\ndemonstrating up to 17% stronger knowledge retention success compared to the\nprevious state-of-art method. Our findings establish a new paradigm for\neffectively managing and regulating sensitive information in large-scale\npre-trained language models.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T06:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.12687v1","title":"Data-efficient LLM Fine-tuning for Code Generation","summary":"Large language models (LLMs) have demonstrated significant potential in code\ngeneration tasks. However, there remains a performance gap between open-source\nand closed-source models. To address this gap, existing approaches typically\ngenerate large amounts of synthetic data for fine-tuning, which often leads to\ninefficient training. In this work, we propose a data selection strategy in\norder to improve the effectiveness and efficiency of training for code-based\nLLMs. By prioritizing data complexity and ensuring that the sampled subset\naligns with the distribution of the original dataset, our sampling strategy\neffectively selects high-quality data. Additionally, we optimize the\ntokenization process through a \"dynamic pack\" technique, which minimizes\npadding tokens and reduces computational resource consumption. Experimental\nresults show that when training on 40% of the OSS-Instruct dataset, the\nDeepSeek-Coder-Base-6.7B model achieves an average performance of 66.9%,\nsurpassing the 66.1% performance with the full dataset. Moreover, training time\nis reduced from 47 minutes to 34 minutes, and the peak GPU memory decreases\nfrom 61.47 GB to 42.72 GB during a single epoch. Similar improvements are\nobserved with the CodeLlama-Python-7B model on the Evol-Instruct dataset. By\noptimizing both data selection and tokenization, our approach not only improves\nmodel performance but also improves training efficiency.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T06:29:28Z"}
{"aid":"http://arxiv.org/abs/2504.12705v1","title":"7-Methylquinolinium Iodobismuthate Memristor: Exploring Plasticity and\n  Memristive Properties for Digit Classification in Physical Reservoir\n  Computing","summary":"This study investigates 7-methylquinolinium halobismuthates (I, Br, and Cl)\nin two aspects: (1) their structural and semiconducting properties influenced\nby anionic composition, and (2) their memristive and plasticity characteristics\nfor neuromorphic and reservoir computing applications. Structural changes\ninduced by halides form low-dimensional halobismuthate fragments, confirmed by\ncrystallographic analysis. Optical band gaps were studied using diffuse\nreflectance spectroscopy, aligning with density functional theory results. Due\nto solubility limitations, only bismuth iodide complexes were explored in\nelectronic devices. Current-voltage scans showed pinched hysteresis loops,\ncharacteristic of memristors. Conductivity versus temperature study indicates\ncombined ionic and electronic contributions to conductivity of the devices.\nGiven that a memristor can function as a single synapse without the need for\nprogramming, aligning with the requirements of neuromorphic computing, the\nstudy investigated long-term depression, potentiation, and spike-time-dependent\nplasticity. As the potentiation-depression plots showed non-linearity with\nfading memory, these materials can be a good candidate for application in\nphysical reservoir computing. To further assess this material, an electronic\ndevice with sixteen gold electrodes was applied, featuring one input and 15\noutput electrodes deposited on silicon substrate and covered with a layer of\nstudied compound. Basic test to assess the complexity and non-linearity of the\ndevices were conducted through a series of benchmark tasks, including waveform\ngeneration, NARMA-2, memory capacity assessment, and noise study under both DC\nand AC current. The ability of device in MNIST digit classification with 82.26%\naccuracy and voice classification for digit 2 for six different people with 82\n% accuracy has been demonstrated.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-17T07:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.12709v1","title":"Self-Supervised Pre-training with Combined Datasets for 3D Perception in\n  Autonomous Driving","summary":"The significant achievements of pre-trained models leveraging large volumes\nof data in the field of NLP and 2D vision inspire us to explore the potential\nof extensive data pre-training for 3D perception in autonomous driving. Toward\nthis goal, this paper proposes to utilize massive unlabeled data from\nheterogeneous datasets to pre-train 3D perception models. We introduce a\nself-supervised pre-training framework that learns effective 3D representations\nfrom scratch on unlabeled data, combined with a prompt adapter based domain\nadaptation strategy to reduce dataset bias. The approach significantly improves\nmodel performance on downstream tasks such as 3D object detection, BEV\nsegmentation, 3D object tracking, and occupancy prediction, and shows steady\nperformance increase as the training data volume scales up, demonstrating the\npotential of continually benefit 3D perception models for autonomous driving.\nWe will release the source code to inspire further investigations in the\ncommunity.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T07:26:11Z"}
{"aid":"http://arxiv.org/abs/2504.12724v1","title":"Faster multivariate integration in D-modules","summary":"We present a new algorithm for solving the reduction problem in the context\nof holonomic integrals, which in turn provides an approach to integration with\nparameters. Our method extends the Griffiths--Dwork reduction technique to\nholonomic systems and is implemented in Julia. While not yet outperforming\ncreative telescoping in D-finite cases, it enhances computational capabilities\nwithin the holonomic framework. As an application, we derive a previously\nunattainable differential equation for the generating series of 8-regular\ngraphs.","main_category":"cs.SC","categories":"cs.SC","published":"2025-04-17T08:00:01Z"}
{"aid":"http://arxiv.org/abs/2504.12742v1","title":"Decentralized Nonconvex Composite Federated Learning with Gradient\n  Tracking and Momentum","summary":"Decentralized Federated Learning (DFL) eliminates the reliance on the\nserver-client architecture inherent in traditional federated learning,\nattracting significant research interest in recent years. Simultaneously, the\nobjective functions in machine learning tasks are often nonconvex and\nfrequently incorporate additional, potentially nonsmooth regularization terms\nto satisfy practical requirements, thereby forming nonconvex composite\noptimization problems. Employing DFL methods to solve such general optimization\nproblems leads to the formulation of Decentralized Nonconvex Composite\nFederated Learning (DNCFL), a topic that remains largely underexplored. In this\npaper, we propose a novel DNCFL algorithm, termed \\bf{DEPOSITUM}. Built upon\nproximal stochastic gradient tracking, DEPOSITUM mitigates the impact of data\nheterogeneity by enabling clients to approximate the global gradient. The\nintroduction of momentums in the proximal gradient descent step, replacing\ntracking variables, reduces the variance introduced by stochastic gradients.\nAdditionally, DEPOSITUM supports local updates of client variables,\nsignificantly reducing communication costs. Theoretical analysis demonstrates\nthat DEPOSITUM achieves an expected $\\epsilon$-stationary point with an\niteration complexity of $\\mathcal{O}(1/\\epsilon^2)$. The proximal gradient,\nconsensus errors, and gradient estimation errors decrease at a sublinear rate\nof $\\mathcal{O}(1/T)$. With appropriate parameter selection, the algorithm\nachieves network-independent linear speedup without requiring mega-batch\nsampling. Finally, we apply DEPOSITUM to the training of neural networks on\nreal-world datasets, systematically examining the influence of various\nhyperparameters on its performance. Comparisons with other federated composite\noptimization algorithms validate the effectiveness of the proposed method.","main_category":"cs.LG","categories":"cs.LG,cs.DC,math.OC","published":"2025-04-17T08:32:25Z"}
{"aid":"http://arxiv.org/abs/2504.12747v1","title":"Privacy Protection Against Personalized Text-to-Image Synthesis via\n  Cross-image Consistency Constraints","summary":"The rapid advancement of diffusion models and personalization techniques has\nmade it possible to recreate individual portraits from just a few publicly\navailable images. While such capabilities empower various creative\napplications, they also introduce serious privacy concerns, as adversaries can\nexploit them to generate highly realistic impersonations. To counter these\nthreats, anti-personalization methods have been proposed, which add adversarial\nperturbations to published images to disrupt the training of personalization\nmodels. However, existing approaches largely overlook the intrinsic multi-image\nnature of personalization and instead adopt a naive strategy of applying\nperturbations independently, as commonly done in single-image settings. This\nneglects the opportunity to leverage inter-image relationships for stronger\nprivacy protection. Therefore, we advocate for a group-level perspective on\nprivacy protection against personalization. Specifically, we introduce\nCross-image Anti-Personalization (CAP), a novel framework that enhances\nresistance to personalization by enforcing style consistency across perturbed\nimages. Furthermore, we develop a dynamic ratio adjustment strategy that\nadaptively balances the impact of the consistency loss throughout the attack\niterations. Extensive experiments on the classical CelebHQ and VGGFace2\nbenchmarks show that CAP substantially improves existing methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:39:32Z"}
{"aid":"http://arxiv.org/abs/2504.12752v1","title":"Model calculations of the strains associated with surface acoustic waves","summary":"Magnon-phonon coupling has garnered increasing interest in condensed matter\nphysics due to its fertile physics and potential applications in devices with\nnovel functionalities. Surface acoustic waves (SAWs) are commonly employed as a\nsource of coherent acoustic phonons. The strain associated with SAWs couples to\nmagnetization of magnetic materials via magnetoelastic coupling and/or\nspin-rotation coupling. A typical SAW device is formed on a piezoelectric\nsubstrate with anisotropic crystal structure. Since the form of strain depends\non the material parameters and structure of the SAW device, it is of vital\nimportance to understand its character. In this paper, we present a\ncomprehensive methodology to numerically calculate the SAW velocity, SAW\nexcitation efficiency, lattice displacement and all strain components\nassociated with SAW. LiNbO$_3$ is used as a prototypical material system. All\nquantities depend on the SAW propagation direction with respect to the\ncrystalline axis and on the electrical boundary conditions. In contrast to\nnon-piezoelectric isotropic media, we find that all shear strain components can\nbe induced in LiNbO$_3$, with their amplitude and relative phase (with respect\nto the longitudinal strain) dependent on the propagation direction and the\nboundary conditions at the LiNbO$_3$ surface. These results offer a robust\nfoundation for analyzing strain-driven magnon-phonon coupling mechanisms and\ncontribute to designing strain-engineered functional magnonic and phononic\ndevices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T08:44:59Z"}
{"aid":"http://arxiv.org/abs/2504.12768v1","title":"Self-consistent random phase approximation and optimized hybrid\n  functionals for solids","summary":"The random phase approximation (RPA) and the $GW$ approximation share the\nsame total energy functional but RPA is defined on a restricted domain of\nGreen's functions determined by a local Kohn-Sham (KS) potential. In this work,\nwe perform self-consistent RPA calculations by optimizing the local KS\npotential through the optimized effective potential equation. We study a number\nof solids (C, Si, BN, LiF, MgO, TiO$_2$), and find in all cases a lowering of\nthe total energy with respect to non-self-consistent RPA. We then propose a\nvariational approach to optimize PBE0-type hybrid functionals based on the\nminimization of the RPA total energy with respect to the fraction of exact\nexchange used to generate the input KS orbitals. We show that this scheme leads\nto hybrid functionals with a KS band structure in close agreement with RPA, and\nwith lattice constants of similar accuracy as within RPA. Finally, we evaluate\n$G_0W_0$ gaps using RPA and hybrid KS potentials as starting points. Special\nattention is given to TiO$_2$, which exhibits a strong starting-point\ndependence.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T09:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.12769v1","title":"On Error Classification from Physiological Signals within Airborne\n  Environment","summary":"Human error remains a critical concern in aviation safety, contributing to\n70-80% of accidents despite technological advancements. While physiological\nmeasures show promise for error detection in laboratory settings, their\neffectiveness in dynamic flight environments remains underexplored. Through\nlive flight trials with nine commercial pilots, we investigated whether\nestablished error-detection approaches maintain accuracy during actual flight\noperations. Participants completed standardized multi-tasking scenarios across\nconditions ranging from laboratory settings to straight-and-level flight and 2G\nmanoeuvres while we collected synchronized physiological data. Our findings\ndemonstrate that EEG-based classification maintains high accuracy (87.83%)\nduring complex flight manoeuvres, comparable to laboratory performance\n(89.23%). Eye-tracking showed moderate performance (82.50\\%), while ECG\nperformed near chance level (51.50%). Classification accuracy remained stable\nacross flight conditions, with minimal degradation during 2G manoeuvres. These\nresults provide the first evidence that physiological error detection can\ntranslate effectively to operational aviation environments.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-17T09:08:21Z"}
{"aid":"http://arxiv.org/abs/2504.12777v1","title":"Multi-Agent Reinforcement Learning Simulation for Environmental Policy\n  Synthesis","summary":"Climate policy development faces significant challenges due to deep\nuncertainty, complex system dynamics, and competing stakeholder interests.\nClimate simulation methods, such as Earth System Models, have become valuable\ntools for policy exploration. However, their typical use is for evaluating\npotential polices, rather than directly synthesizing them. The problem can be\ninverted to optimize for policy pathways, but the traditional optimization\napproaches often struggle with non-linear dynamics, heterogeneous agents, and\ncomprehensive uncertainty quantification. We propose a framework for augmenting\nclimate simulations with Multi-Agent Reinforcement Learning (MARL) to address\nthese limitations. We identify key challenges at the interface between climate\nsimulations and the application of MARL in the context of policy synthesis,\nincluding reward definition, scalability with increasing agents and state\nspaces, uncertainty propagation across linked systems, and solution validation.\nAdditionally, we discuss challenges in making MARL-derived solutions\ninterpretable and useful for policy-makers. Our framework provides a foundation\nfor more sophisticated climate policy exploration while acknowledging important\nlimitations and areas for future research.","main_category":"cs.MA","categories":"cs.MA,cs.AI","published":"2025-04-17T09:18:04Z"}
{"aid":"http://arxiv.org/abs/2504.12778v1","title":"Towards Lossless Token Pruning in Late-Interaction Retrieval Models","summary":"Late interaction neural IR models like ColBERT offer a competitive\neffectiveness-efficiency trade-off across many benchmarks. However, they\nrequire a huge memory space to store the contextual representation for all the\ndocument tokens. Some works have proposed using either heuristics or\nstatistical-based techniques to prune tokens from each document. This however\ndoesn't guarantee that the removed tokens have no impact on the retrieval\nscore. Our work uses a principled approach to define how to prune tokens\nwithout impacting the score between a document and a query. We introduce three\nregularization losses, that induce a solution with high pruning ratios, as well\nas two pruning strategies. We study them experimentally (in and out-domain),\nshowing that we can preserve ColBERT's performance while using only 30\\% of the\ntokens.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-17T09:18:58Z"}
{"aid":"http://arxiv.org/abs/2504.12779v1","title":"Crossover in Electronic Specific Heat near Narrow-Sense Type-III Dirac\n  Cones","summary":"Two-dimensional massless Dirac fermions exhibit Dirac cones, which are\nclassified into three types: type-I, type-II, and type-III. In both type-I and\ntype-II cones, the energy dispersion is linear in all momentum directions.\nType-I cones are characterized by a non-overtilted structure, where the Dirac\npoint serves as a local minimum (maximum) for the upper (lower) band. In\ncontrast, type-II cones exhibit overtilted dispersions, leading to the\ncoexistence of electron and hole pockets. At the critical tilt, the linear\nenergy dispersion vanishes in one momentum direction, corresponding to a\ntype-III Dirac cone. We further define a special case, termed the\n\"narrow-sense\" type-III cone, where not only the linear term but also quadratic\nand higher-order terms vanish, resulting in a completely flat dispersion along\none direction. In this work, we numerically investigate the temperature ($T$)\n-dependence of the electronic specific heat ($C$), as the Dirac cone is\ncontinuously tilted from type-I to narrow-sense type-III. A model with\nparticle-hole symmetry is employed to ensure that the chemical potential\n($\\mu$) remains temperature independent. Our results reveal a notable crossover\nin $C$ near narrow-sense type-III, where $C$ changes from $C \\propto T^{2}$\nbelow the crossover temperature ($T_{\\rm co}$) to $C \\propto T^{\\frac{1}{2}}$\nabove $T_{\\rm co}$. This crossover is attributed to the energy-dependent\nstructure of the density of states. The present findings suggest a feasible\napproach for experimentally probing the degree of Dirac cone tilting near the\nnarrow-sense type-III limit.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-17T09:23:00Z"}
{"aid":"http://arxiv.org/abs/2504.12783v1","title":"A Battle-LemariÃ© Frame Characterization of Besov and Triebel-Lizorkin\n  Spaces","summary":"In this paper, we investigate a spline frame generated by oversampling\nagainst the well-known Battle-Lemari\\'e wavelet system of nonnegative integer\norder, $n$. We establish a characterization of the Besov and Triebel-Lizorkin\n(quasi-) norms for the smoothness parameter up to $s < n+1$, which includes\nvalues of $s$ where the Battle-Lemari\\'e system no longer provides an\nunconditional basis; we, additionally, prove a result for the endpoint case\n$s=n+1$. This builds off of earlier work by G. Garrig\\'os, A. Seeger, and T.\nUllrich, where they proved the case $n=0$, i.e. that of the Haar wavelet, and\nwork of R. Srivastava, where she gave a necessary range for the\nBattle-Lemari\\'e system to give an unconditional basis of the Triebel-Lizorkin\nspaces.","main_category":"math.FA","categories":"math.FA,math.CA","published":"2025-04-17T09:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.12794v1","title":"Supporting Urban Low-Altitude Economy: Channel Gain Map Inference Based\n  on 3D Conditional GAN","summary":"The advancement of advanced air mobility (AAM) in recent years has given rise\nto the concept of low-altitude economy (LAE). However, the diverse flight\nactivities associated with the emerging LAE applications in urban scenarios\nconfront complex physical environments, which urgently necessitates ubiquitous\nand reliable communication to guarantee the operation safety of the\nlow-altitude aircraft. As one of promising technologies for the sixth\ngeneration (6G) mobile networks, channel knowledge map (CKM) enables the\nenvironment-aware communication by constructing a site-specific dataset,\nthereby providing a priori on-site information for the aircraft to obtain the\nchannel state information (CSI) at arbitrary locations with much reduced online\noverhead. Diverse base station (BS) deployments in the three-dimensional (3D)\nurban low-altitude environment require efficient 3D CKM construction to capture\nspatial channel characteristics with less overhead. Towards this end, this\npaper proposes a 3D channel gain map (CGM) inference method based on a 3D\nconditional generative adversarial network (3D-CGAN). Specifically, we first\nanalyze the potential deployment types of BSs in urban low-altitude scenario,\nand investigate the CGM representation with the corresponding 3D channel gain\nmodel. The framework of the proposed 3D-CGAN is then discussed, which is\ntrained by a dataset consisting of existing CGMs. Consequently, the trained\n3D-CGAN is capable of inferring the corresponding CGM only based on the BS\ncoordinate without additional measurement. The simulation results demonstrate\nthat the CGMs inferred by the proposed 3D-CGAN outperform those of the\nbenchmark schemes, which can accurately reflect the radio propagation condition\nin 3D environment.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T09:55:03Z"}
{"aid":"http://arxiv.org/abs/2504.12800v1","title":"CAGE-GS: High-fidelity Cage Based 3D Gaussian Splatting Deformation","summary":"As 3D Gaussian Splatting (3DGS) gains popularity as a 3D representation of\nreal scenes, enabling user-friendly deformation to create novel scenes while\npreserving fine details from the original 3DGS has attracted significant\nresearch attention. We introduce CAGE-GS, a cage-based 3DGS deformation method\nthat seamlessly aligns a source 3DGS scene with a user-defined target shape.\nOur approach learns a deformation cage from the target, which guides the\ngeometric transformation of the source scene. While the cages effectively\ncontrol structural alignment, preserving the textural appearance of 3DGS\nremains challenging due to the complexity of covariance parameters. To address\nthis, we employ a Jacobian matrix-based strategy to update the covariance\nparameters of each Gaussian, ensuring texture fidelity post-deformation. Our\nmethod is highly flexible, accommodating various target shape representations,\nincluding texts, images, point clouds, meshes and 3DGS models. Extensive\nexperiments and ablation studies on both public datasets and newly proposed\nscenes demonstrate that our method significantly outperforms existing\ntechniques in both efficiency and deformation quality.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T10:00:15Z"}
{"aid":"http://arxiv.org/abs/2504.12805v1","title":"Assesing LLMs in Art Contexts: Critique Generation and Theory of Mind\n  Evaluation","summary":"This study explored how large language models (LLMs) perform in two areas\nrelated to art: writing critiques of artworks and reasoning about mental states\n(Theory of Mind, or ToM) in art-related situations. For the critique generation\npart, we built a system that combines Noel Carroll's evaluative framework with\na broad selection of art criticism theories. The model was prompted to first\nwrite a full-length critique and then shorter, more coherent versions using a\nstep-by-step prompting process. These AI-generated critiques were then compared\nwith those written by human experts in a Turing test-style evaluation. In many\ncases, human subjects had difficulty telling which was which, and the results\nsuggest that LLMs can produce critiques that are not only plausible in style\nbut also rich in interpretation, as long as they are carefully guided. In the\nsecond part, we introduced new simple ToM tasks based on situations involving\ninterpretation, emotion, and moral tension, which can appear in the context of\nart. These go beyond standard false-belief tests and allow for more complex,\nsocially embedded forms of reasoning. We tested 41 recent LLMs and found that\ntheir performance varied across tasks and models. In particular, tasks that\ninvolved affective or ambiguous situations tended to reveal clearer\ndifferences. Taken together, these results help clarify how LLMs respond to\ncomplex interpretative challenges, revealing both their cognitive limitations\nand potential. While our findings do not directly contradict the so-called\nGenerative AI Paradox--the idea that LLMs can produce expert-like output\nwithout genuine understanding--they suggest that, depending on how LLMs are\ninstructed, such as through carefully designed prompts, these models may begin\nto show behaviors that resemble understanding more closely than we might\nassume.","main_category":"cs.CL","categories":"cs.CL,cs.CY,cs.HC","published":"2025-04-17T10:10:25Z"}
{"aid":"http://arxiv.org/abs/2504.12828v1","title":"Predicting Stock Prices using Permutation Decision Trees and Strategic\n  Trailing","summary":"In this paper, we explore the application of Permutation Decision Trees (PDT)\nand strategic trailing for predicting stock market movements and executing\nprofitable trades in the Indian stock market. We focus on high-frequency data\nusing 5-minute candlesticks for the top 50 stocks listed in the NIFTY 50 index.\nWe implement a trading strategy that aims to buy stocks at lower prices and\nsell them at higher prices, capitalizing on short-term market fluctuations. Due\nto regulatory constraints in India, short selling is not considered in our\nstrategy. The model incorporates various technical indicators and employs\nhyperparameters such as the trailing stop-loss value and support thresholds to\nmanage risk effectively. Our results indicate that the proposed trading bot has\nthe potential to outperform the market average and yield returns higher than\nthe risk-free rate offered by 10-year Indian government bonds. We trained and\ntested data on a 60 day dataset provided by Yahoo Finance. Specifically, 12\ndays for testing and 48 days for training. Our bot based on permutation\ndecision tree achieved a profit of 1.3468 % over a 12-day testing period, where\nas a bot based on LSTM gave a return of 0.1238 % over a 12-day testing period\nand a bot based on RNN gave a return of 0.3096 % over a 12-day testing period.\nAll of the bots outperform the buy-and-hold strategy, which resulted in a loss\nof 2.2508 %.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T10:42:38Z"}
{"aid":"http://arxiv.org/abs/2504.12831v1","title":"Long-wavelength optical lattices from optical beatnotes: theory and\n  applications","summary":"We present a theoretical analysis of Beat-Note Superlattices (BNSLs), a\nrecently demonstrated technique for generating periodic trapping potentials for\nultracold atomic clouds, with arbitrarily large lattice spacings while\nmaintaining interferometric stability. By combining two optical lattices with\nslightly different wavelengths, a beatnote intensity pattern is formed,\ngenerating, for low depths, an effective lattice potential with a periodicity\nequal to the wavelength associated to the difference between the wavevectors of\nthe two lattices. We study the range of lattice depths and wavelengths under\nwhich this approximation is valid and investigate its robustness against\nperturbations. We present a few examples where the use of BNSLs could offer\nsignificant advantages in comparison to well established techniques for the\nmanipulation of ultracold atomic gases. Our results highlight the potential of\nBNSLs for quantum simulation, atom interferometry, and other applications in\nquantum technologies.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,quant-ph","published":"2025-04-17T10:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.12837v1","title":"Dipole-pion cross section in the saturation regime","summary":"We analyse HERA data on leading neutron production in one-pion exchange\napproximation. The dipole-pion cross section as function of transverse\nseparation $\\bf r$ at small Bjorken variable $\\beta$ is parameterized within\nthe bSat model.\n  The evolution of the dipole-pion cross section is performed applying the\nLaplace transformation technique. We demonstrate that geometric scaling\n  for the dipole-pion cross section hold approximately within a wide kinematic\nregion of $rQ_s$. The geometrical scaling is improved applying the evolution\nmethod. That is compared with the constituent quark picture and the color\ndipole BFKL expansion. The cross section saturates at large dipole sizes.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T10:53:08Z"}
{"aid":"http://arxiv.org/abs/2504.12844v1","title":"High-Fidelity Image Inpainting with Multimodal Guided GAN Inversion","summary":"Generative Adversarial Network (GAN) inversion have demonstrated excellent\nperformance in image inpainting that aims to restore lost or damaged image\ntexture using its unmasked content. Previous GAN inversion-based methods\nusually utilize well-trained GAN models as effective priors to generate the\nrealistic regions for missing holes. Despite excellence, they ignore a hard\nconstraint that the unmasked regions in the input and the output should be the\nsame, resulting in a gap between GAN inversion and image inpainting and thus\ndegrading the performance. Besides, existing GAN inversion approaches often\nconsider a single modality of the input image, neglecting other auxiliary cues\nin images for improvements. Addressing these problems, we propose a novel GAN\ninversion approach, dubbed MMInvertFill, for image inpainting. MMInvertFill\ncontains primarily a multimodal guided encoder with a pre-modulation and a GAN\ngenerator with F&W+ latent space. Specifically, the multimodal encoder aims to\nenhance the multi-scale structures with additional semantic segmentation edge\ntexture modalities through a gated mask-aware attention module. Afterwards, a\npre-modulation is presented to encode these structures into style vectors. To\nmitigate issues of conspicuous color discrepancy and semantic inconsistency, we\nintroduce the F&W+ latent space to bridge the gap between GAN inversion and\nimage inpainting. Furthermore, in order to reconstruct faithful and\nphotorealistic images, we devise a simple yet effective Soft-update Mean Latent\nmodule to capture more diversified in-domain patterns for generating\nhigh-fidelity textures for massive corruptions. In our extensive experiments on\nsix challenging datasets, we show that our MMInvertFill qualitatively and\nquantitatively outperforms other state-of-the-arts and it supports the\ncompletion of out-of-domain images effectively.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T10:58:45Z"}
{"aid":"http://arxiv.org/abs/2504.12853v1","title":"A scaling relation of vortex-induced rectification effects in a\n  superconducting thin-film heterostructure","summary":"Supercurrent rectification, nonreciprocal response of superconducting\nproperties sensitive to the polarity of bias and magnetic field, has attracted\ngrowing interest as an ideal diode. While the superconducting rectification\neffect is a consequence of the asymmetric vortex pinning, the mechanisms to\ndevelop its asymmetric potentials have been a subject of ongoing debate, mainly\nfocusing on microscopic breaking of spatial inversion symmetry and macroscopic\nimbalance of the sample structure. Here, we report on comparative study of the\nsuperconducting diode effect and nonreciprocal resistance in a superconducting\nFe(Se,Te)/FeTe heterostructure. In normal state, we observe finite\nnonreciprocal resistance as a hallmark of the spin-orbit interaction with\nstructural inversion asymmetry. In the superconducting state, we find that the\nstrongly enhanced nonreciprocal coefficient in transition regime is directly\ncoupled to the superconducting diode efficiency through a universal scaling\nlaw, indicating the role of spin-momentum-locked state on the asymmetric\npinning potential. Our findings, providing a unified picture of the\nsuperconducting rectification, pave the way for functionalizing superconducting\ndiode devices.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-17T11:20:04Z"}
{"aid":"http://arxiv.org/abs/2504.12856v1","title":"3D-PNAS: 3D Industrial Surface Anomaly Synthesis with Perlin Noise","summary":"Large pretrained vision foundation models have shown significant potential in\nvarious vision tasks. However, for industrial anomaly detection, the scarcity\nof real defect samples poses a critical challenge in leveraging these models.\nWhile 2D anomaly generation has significantly advanced with established\ngenerative models, the adoption of 3D sensors in industrial manufacturing has\nmade leveraging 3D data for surface quality inspection an emerging trend. In\ncontrast to 2D techniques, 3D anomaly generation remains largely unexplored,\nlimiting the potential of 3D data in industrial quality inspection. To address\nthis gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS,\nbased on Perlin noise and surface parameterization. Our method generates\nrealistic 3D surface anomalies by projecting the point cloud onto a 2D plane,\nsampling multi-scale noise values from a Perlin noise field, and perturbing the\npoint cloud along its normal direction. Through comprehensive visualization\nexperiments, we demonstrate how key parameters - including noise scale,\nperturbation strength, and octaves, provide fine-grained control over the\ngenerated anomalies, enabling the creation of diverse defect patterns from\npronounced deformations to subtle surface variations. Additionally, our\ncross-category experiments show that the method produces consistent yet\ngeometrically plausible anomalies across different object types, adapting to\ntheir specific surface characteristics. We also provide a comprehensive\ncodebase and visualization toolkit to facilitate future research.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG,cs.RO,I.5.4","published":"2025-04-17T11:23:17Z"}
{"aid":"http://arxiv.org/abs/2504.12868v1","title":"Computer-Aided Design of Personalized Occlusal Positioning Splints Using\n  Multimodal 3D Data","summary":"Contemporary digital technology has a pivotal role in the design of\ncustomized medical appliances, including occlusal splints used in the treatment\nof stomatognathic system dysfunctions. We present an approach to computer-aided\ndesign and precision assessment of positioning occlusal splints, bridging\nclinical concepts with current digital dental practice. In our model, a 3D\nsplint is generated based on a transformation matrix that represents the\ntherapeutic change in mandibular position, defined by a specialist using a\nvirtual patient model reconstructed from intraoral scans, CBCT, 3D facial scans\nand plaster model digitisation. The paper introduces a novel method for\ngenerating splints that accurately reproduce occlusal conditions in the\ntherapeutic position, including a mechanism for resolving surface conflicts\nthrough virtual embossing. We demonstrate how transformation matrices can be\nacquired through clinical tools and intraoral devices, and evaluate the\naccuracy of the designed and printed splints using profile and surface\ndeviation analysis. The proposed method enables reproducible, patient-specific\nsplint fabrication and opens new possibilities in diagnostics, multimodal image\nregistration and quantification of occlusal discrepancies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T11:53:49Z"}
{"aid":"http://arxiv.org/abs/2504.12869v1","title":"SC3EF: A Joint Self-Correlation and Cross-Correspondence Estimation\n  Framework for Visible and Thermal Image Registration","summary":"Multispectral imaging plays a critical role in a range of intelligent\ntransportation applications, including advanced driver assistance systems\n(ADAS), traffic monitoring, and night vision. However, accurate visible and\nthermal (RGB-T) image registration poses a significant challenge due to the\nconsiderable modality differences. In this paper, we present a novel joint\nSelf-Correlation and Cross-Correspondence Estimation Framework (SC3EF),\nleveraging both local representative features and global contextual cues to\neffectively generate RGB-T correspondences. For this purpose, we design a\nconvolution-transformer-based pipeline to extract local representative features\nand encode global correlations of intra-modality for inter-modality\ncorrespondence estimation between unaligned visible and thermal images. After\nmerging the local and global correspondence estimation results, we further\nemploy a hierarchical optical flow estimation decoder to progressively refine\nthe estimated dense correspondence maps. Extensive experiments demonstrate the\neffectiveness of our proposed method, outperforming the current\nstate-of-the-art (SOTA) methods on representative RGB-T datasets. Furthermore,\nit also shows competitive generalization capabilities across challenging\nscenarios, including large parallax, severe occlusions, adverse weather, and\nother cross-modal datasets (e.g., RGB-N and RGB-D).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T11:54:12Z"}
{"aid":"http://arxiv.org/abs/2504.12874v1","title":"Homomorphisms with semilocal endomorphism rings between modules","summary":"We study the category $\\operatorname{Morph}(\\operatorname{Mod} R)$ whose\nobjects are all morphisms between two right $R$-modules. The behavior of\nobjects of $\\operatorname{Morph}(\\operatorname{Mod} R)$ whose endomorphism ring\nin $\\operatorname{Morph}(\\operatorname{Mod} R)$ is semilocal is very similar to\nthe behavior of modules with a semilocal endomorphism ring. For instance,\ndirect-sum decompositions of a direct sum $\\oplus_{i=1}^nM_i$, that is,\nblock-diagonal decompositions, where each object $M_i$ of\n$\\operatorname{Morph}(\\operatorname{Mod} R)$ denotes a morphism\n$\\mu_{M_i}\\colon M_{0,i}\\to M_{1,i}$ and where all the modules $M_{j,i}$ have a\nlocal endomorphism ring $\\operatorname{End}(M_{j,i})$, depend on two\ninvariants. This behavior is very similar to that of direct-sum decompositions\nof serial modules of finite Goldie dimension, which also depend on two\ninvariants (monogeny class and epigeny class). When all the modules $M_{j,i}$\nare uniserial modules, the direct-sum decompositions (block-diagonal\ndecompositions) of a direct-sum $\\oplus_{i=1}^nM_i$ depend on four invariants.","main_category":"math.RA","categories":"math.RA","published":"2025-04-17T12:02:26Z"}
{"aid":"http://arxiv.org/abs/2504.12875v1","title":"A Client-level Assessment of Collaborative Backdoor Poisoning in Non-IID\n  Federated Learning","summary":"Federated learning (FL) enables collaborative model training using\ndecentralized private data from multiple clients. While FL has shown robustness\nagainst poisoning attacks with basic defenses, our research reveals new\nvulnerabilities stemming from non-independent and identically distributed\n(non-IID) data among clients. These vulnerabilities pose a substantial risk of\nmodel poisoning in real-world FL scenarios.\n  To demonstrate such vulnerabilities, we develop a novel collaborative\nbackdoor poisoning attack called CollaPois. In this attack, we distribute a\nsingle pre-trained model infected with a Trojan to a group of compromised\nclients. These clients then work together to produce malicious gradients,\ncausing the FL model to consistently converge towards a low-loss region\ncentered around the Trojan-infected model. Consequently, the impact of the\nTrojan is amplified, especially when the benign clients have diverse local data\ndistributions and scattered local gradients. CollaPois stands out by achieving\nits goals while involving only a limited number of compromised clients, setting\nit apart from existing attacks. Also, CollaPois effectively avoids noticeable\nshifts or degradation in the FL model's performance on legitimate data samples,\nallowing it to operate stealthily and evade detection by advanced robust FL\nalgorithms.\n  Thorough theoretical analysis and experiments conducted on various benchmark\ndatasets demonstrate the superiority of CollaPois compared to state-of-the-art\nbackdoor attacks. Notably, CollaPois bypasses existing backdoor defenses,\nespecially in scenarios where clients possess diverse data distributions.\nMoreover, the results show that CollaPois remains effective even when involving\na small number of compromised clients. Notably, clients whose local data is\nclosely aligned with compromised clients experience higher risks of backdoor\ninfections.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T12:03:02Z"}
{"aid":"http://arxiv.org/abs/2504.12903v1","title":"Reduced ÄŒech complexes and computing higher direct images under\n  toric maps","summary":"This paper has three main goals : (1) To give an axiomatic formulation of the\nconstruction of \"reduced \\v{C}ech complexes\", complexes using fewer than the\nusual number of intersections but still computing cohomology of sheaves; (2) To\ngive a construction of such a reduced \\v{C}ech complex for every semi-proper\ntoric variety $X$, such that every open used in the complex is torus stable,\nand such that the cell complex governing the reduced \\v{C}ech complex has\ndimension the cohomological dimension of $X$; and (3) to give an algorithm to\ncompute the higher direct images of line bundles relative to a toric fibration\nbetween smooth proper toric varieties.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T12:48:18Z"}
{"aid":"http://arxiv.org/abs/2504.12914v1","title":"In Which Areas of Technical AI Safety Could Geopolitical Rivals\n  Cooperate?","summary":"International cooperation is common in AI research, including between\ngeopolitical rivals. While many experts advocate for greater international\ncooperation on AI safety to address shared global risks, some view cooperation\non AI with suspicion, arguing that it can pose unacceptable risks to national\nsecurity. However, the extent to which cooperation on AI safety poses such\nrisks, as well as provides benefits, depends on the specific area of\ncooperation. In this paper, we consider technical factors that impact the risks\nof international cooperation on AI safety research, focusing on the degree to\nwhich such cooperation can advance dangerous capabilities, result in the\nsharing of sensitive information, or provide opportunities for harm. We begin\nby why nations historically cooperate on strategic technologies and analyse\ncurrent US-China cooperation in AI as a case study. We further argue that\nexisting frameworks for managing associated risks can be supplemented with\nconsideration of key risks specific to cooperation on technical AI safety\nresearch. Through our analysis, we find that research into AI verification\nmechanisms and shared protocols may be suitable areas for such cooperation.\nThrough this analysis we aim to help researchers and governments identify and\nmitigate the risks of international cooperation on AI safety research, so that\nthe benefits of cooperation can be fully realised.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-17T13:03:56Z"}
{"aid":"http://arxiv.org/abs/2504.12938v1","title":"Optimal analysis of penalized lowest-order mixed FEMs for the\n  Stokes-Darcy model","summary":"This paper is concerned with non-uniform fully-mixed FEMs for dynamic coupled\nStokes-Darcy model with the well-known Beavers-Joseph-Saffman (BJS) interface\ncondition. In particular, a decoupled algorithm with the lowest-order mixed\nnon-uniform FE approximations (MINI for the Stokes equation and RT0-DG0 for the\nDarcy equation) and the classical Nitsche-type penalty is studied. The method\nwith the combined approximation of different orders is commonly used in\npractical simulations. However, the optimal error analysis of methods with\nnon-uniform approximations for the coupled Stokes-Darcy flow model has remained\nchallenging, although the analysis for uniform approximations has been well\ndone. The key question is how the lower-order approximation to the Darcy flow\ninfluences the accuracy of the Stokes solution through the interface condition.\nIn this paper, we prove that the decoupled algorithm provides a truly optimal\nconvergence rate in L^2-norm in spatial direction: O(h^2) for Stokes velocity\nand O(h) for Darcy flow in the coupled Stokes-Darcy model. This implies that\nthe lower-order approximation to the Darcy flow does not pollute the accuracy\nof numerical velocity for Stokes flow. The analysis presented in this paper is\nbased on a well-designed Stokes-Darcy Ritz projection and given for a dynamic\ncoupled model. The optimal error estimate holds for more general combined\napproximations and more general coupled models, including the corresponding\nmodel of steady-state Stokes-Darcy flows and the model of coupled dynamic\nStokes and steady-state Darcy flows. Numerical results confirm our theoretical\nanalysis and show that the decoupled algorithm is efficient.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-17T13:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.12949v1","title":"RL-PINNs: Reinforcement Learning-Driven Adaptive Sampling for Efficient\n  Training of PINNs","summary":"Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving partial differential equations (PDEs). However, their performance\nheavily relies on the strategy used to select training points. Conventional\nadaptive sampling methods, such as residual-based refinement, often require\nmulti-round sampling and repeated retraining of PINNs, leading to computational\ninefficiency due to redundant points and costly gradient\ncomputations-particularly in high-dimensional or high-order derivative\nscenarios. To address these limitations, we propose RL-PINNs, a reinforcement\nlearning(RL)-driven adaptive sampling framework that enables efficient training\nwith only a single round of sampling. Our approach formulates adaptive sampling\nas a Markov decision process, where an RL agent dynamically selects optimal\ntraining points by maximizing a long-term utility metric. Critically, we\nreplace gradient-dependent residual metrics with a computationally efficient\nfunction variation as the reward signal, eliminating the overhead of derivative\ncalculations. Furthermore, we employ a delayed reward mechanism to prioritize\nlong-term training stability over short-term gains. Extensive experiments\nacross diverse PDE benchmarks, including low-regular, nonlinear,\nhigh-dimensional, and high-order problems, demonstrate that RL-PINNs\nsignificantly outperforms existing residual-driven adaptive methods in\naccuracy. Notably, RL-PINNs achieve this with negligible sampling overhead,\nmaking them scalable to high-dimensional and high-order problems.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-17T13:50:55Z"}
{"aid":"http://arxiv.org/abs/2504.12981v1","title":"Efficient Chebyshev Reconstruction for the Anisotropic Equilibrium Model\n  in Magnetic Particle Imaging","summary":"Magnetic Particle Imaging (MPI) is a tomographic imaging modality capable of\nreal-time, high-sensitivity mapping of superparamagnetic iron oxide\nnanoparticles. Model-based image reconstruction provides an alternative to\nconventional methods that rely on a measured system matrix, eliminating the\nneed for laborious calibration measurements. Nevertheless, model-based\napproaches must account for the complexities of the imaging chain to maintain\nhigh image quality. A recently proposed direct reconstruction method leverages\nweighted Chebyshev polynomials in the frequency domain, removing the need for a\nsimulated system matrix. However, the underlying model neglects key physical\neffects, such as nanoparticle anisotropy, leading to distortions in\nreconstructed images. To mitigate these artifacts, an adapted direct Chebyshev\nreconstruction (DCR) method incorporates a spatially variant deconvolution\nstep, significantly improving reconstruction accuracy at the cost of increased\ncomputational demands. In this work, we evaluate the adapted DCR on six\nexperimental phantoms, demonstrating enhanced reconstruction quality in real\nmeasurements and achieving image fidelity comparable to or exceeding that of\nsimulated system matrix reconstruction. Furthermore, we introduce an efficient\napproximation for the spatially variable deconvolution, reducing both runtime\nand memory consumption while maintaining accuracy. This method achieves\ncomputational complexity of O(N log N ), making it particularly beneficial for\nhigh-resolution and three-dimensional imaging. Our results highlight the\npotential of the adapted DCR approach for improving model-based MPI\nreconstruction in practical applications.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.NA,eess.IV,math.NA","published":"2025-04-17T14:37:49Z"}
{"aid":"http://arxiv.org/abs/2504.12989v1","title":"Query Complexity of Classical and Quantum Channel Discrimination","summary":"Quantum channel discrimination has been studied from an information-theoretic\nperspective, wherein one is interested in the optimal decay rate of error\nprobabilities as a function of the number of unknown channel accesses. In this\npaper, we study the query complexity of quantum channel discrimination, wherein\nthe goal is to determine the minimum number of channel uses needed to reach a\ndesired error probability. To this end, we show that the query complexity of\nbinary channel discrimination depends logarithmically on the inverse error\nprobability and inversely on the negative logarithm of the (geometric and\nHolevo) channel fidelity. As a special case of these findings, we precisely\ncharacterize the query complexity of discriminating between two classical\nchannels. We also provide lower and upper bounds on the query complexity of\nbinary asymmetric channel discrimination and multiple quantum channel\ndiscrimination. For the former, the query complexity depends on the geometric\nR\\'enyi and Petz R\\'enyi channel divergences, while for the latter, it depends\non the negative logarithm of (geometric and Uhlmann) channel fidelity. For\nmultiple channel discrimination, the upper bound scales as the logarithm of the\nnumber of channels.","main_category":"quant-ph","categories":"quant-ph,cs.IT,cs.LG,math.IT,math.ST,stat.TH","published":"2025-04-17T14:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.12991v1","title":"Chain-of-Thought Prompting for Out-of-Distribution Samples: A\n  Latent-Variable Study","summary":"Chain-of-Thought (CoT) prompting has emerged as a powerful technique to\nimprove in-context learning (ICL) in large language models (LLMs) by breaking\ncomplex reasoning into intermediate steps. However, the ability of CoT to\ngeneralize under distribution shift remains poorly understood. In this work, we\nextend a latent-variable framework for CoT prompting and study its behavior on\ntwo prototypical out-of-distribution (OOD) scenarios: (i) the latent variables\nfor CoT steps are permuted into novel combinations, and (ii) the latent\nvariables uniformly scaled by a factor. Our experiments demonstrate that CoT\ninference generalizes effectively to OOD samples whose latent variables closely\nresemble those seen during training, but its performance degrades as this\nsimilarity decreases. These findings provide foundational insights into the\nstrengths and limitations of CoT prompting under OOD conditions and suggest\ndirections for developing more resilient reasoning strategies in future LLMs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T14:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.12993v1","title":"New Frontiers in Muon-Spin Spectroscopy Using Si-Pixel Detectors","summary":"The study of novel quantum materials relies on muon-spin rotation,\nrelaxation, or resonance (\\mSR) measurements. Yet, a fundamental limitation\npersists: many of these materials can only be synthesized in extremely small\nquantities, often at sub-millimeter scales. While \\mSR ~offers unique insights\ninto electronic and magnetic properties, existing spectrometers lack a\nsub-millimeter spatial resolution and the possibility of triggerless pump-probe\ndata acquisition, which would enable more advanced measurements. The General\nPurpose Surface-muon instrument (GPS) at the Paul Scherrer Institute (PSI) is\ncurrently limited to a muon stopping rate of \\SI{40}{\\kilo\\hertz} to\n\\SI{120}{\\kilo\\hertz}, a constraint that will become more pressing with the\nupcoming High-Intensity Muon Beam (HIMB) project. To overcome these challenges,\nwe demonstrate the feasibility of employing ultra-thin monolithic Si-pixel\ndetectors to reconstruct the stopping position of muons within the sample,\nthereby significantly enhancing the capability of measuring at higher muon\nrate. Additionally, we explore the first steps toward a triggerless pump-probe\n\\mSR ~measurement scheme. Unlike conventional pump-probe techniques that\nrequire external triggers, a triggerless readout system can continuously\nintegrate stimuli pulses into the data stream, allowing real-time tracking of\nultra-fast dynamics in quantum materials. This approach will enable the study\nof transient states, spin dynamics, and quantum coherence under external\nstimuli.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-17T15:02:36Z"}
{"aid":"http://arxiv.org/abs/2504.13011v1","title":"Two-loop Feynman integrals for leading colour $t\\bar{t}W$ production at\n  hadron colliders","summary":"We compute a complete set of the two-loop Feynman integrals that are required\nfor the next-to-next-to-leading order QCD corrections to on-shell top-pair\nproduction in association with a $W$ boson at hadron colliders in the leading\ncolour approximation. These Feynman integrals also contribute to Higgs or\n$Z$-boson production in association with a top pair. We employ the method of\ndifferential equations (DEs), facilitated by the use of finite field methods to\nhandle the algebraic complexity stemming from the seven-scale kinematics. The\npresence of the top quark in the virtual propagators, in addition to the mass\nof the external $W$ boson, gives rise to nested square roots and three elliptic\ncurves. We obtain DEs that depend at most quadratically on the dimensional\nregulator $\\epsilon$ for sectors where these analytic structures appear, and\nare $\\epsilon$-factorised otherwise. We express the DEs in terms of a minimal\nset of differential one-forms, separating the logarithmic ones. We solve the\nDEs numerically in the physical kinematic region, with the method of\ngeneralised power series expansions.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-17T15:17:35Z"}
{"aid":"http://arxiv.org/abs/2504.13026v1","title":"TTRD3: Texture Transfer Residual Denoising Dual Diffusion Model for\n  Remote Sensing Image Super-Resolution","summary":"Remote Sensing Image Super-Resolution (RSISR) reconstructs high-resolution\n(HR) remote sensing images from low-resolution inputs to support fine-grained\nground object interpretation. Existing methods face three key challenges: (1)\nDifficulty in extracting multi-scale features from spatially heterogeneous RS\nscenes, (2) Limited prior information causing semantic inconsistency in\nreconstructions, and (3) Trade-off imbalance between geometric accuracy and\nvisual quality. To address these issues, we propose the Texture Transfer\nResidual Denoising Dual Diffusion Model (TTRD3) with three innovations: First,\na Multi-scale Feature Aggregation Block (MFAB) employing parallel heterogeneous\nconvolutional kernels for multi-scale feature extraction. Second, a Sparse\nTexture Transfer Guidance (STTG) module that transfers HR texture priors from\nreference images of similar scenes. Third, a Residual Denoising Dual Diffusion\nModel (RDDM) framework combining residual diffusion for deterministic\nreconstruction and noise diffusion for diverse generation. Experiments on\nmulti-source RS datasets demonstrate TTRD3's superiority over state-of-the-art\nmethods, achieving 1.43% LPIPS improvement and 3.67% FID enhancement compared\nto best-performing baselines. Code/model: https://github.com/LED-666/TTRD3.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:37:13Z"}
{"aid":"http://arxiv.org/abs/2504.13028v1","title":"Profinite Iterated Monodromy Groups of Unicritical Polynomials","summary":"Let $f(x) = ax^d + b \\in K[x]$ be a unicritical polynomial with degree $d\n\\geq 2$ which is coprime to $\\mathrm{char} K$. We provide an explicit\npresentation for the profinite iterated monodromy group of $f$, analyze the\nstructure of this group, and use this analysis to determine the constant field\nextension in $K(f^{-\\infty}(t))/K(t)$.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-17T15:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.13030v1","title":"High-Density Ultracold Neutron Source for Low-Energy Particle Physics\n  Experiments","summary":"SuperSUN, a new superthermal source of ultracold neutrons (UCN) at the\nInstitut Laue-Langevin, exploits inelastic scattering of neutrons in\nisotopically pure superfluid $^4$He at temperatures below $0.6\\,$K. For the\nfirst time, continuous operation with an intense broad-spectrum cold neutron\nbeam is demonstrated over 60 days. We observe continuous UCN extraction rates\nof $21000\\,$s$^{-1}$, and storage in the source with saturated\n$\\textit{in-situ}$ density $273\\,$cm$^{-3}$. The high stored density,\nlow-energy UCN spectrum, and long storage times open new possibilities in\nfundamental and applied physics.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex,nucl-ex","published":"2025-04-17T15:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.13038v1","title":"How Large Language Models Are Changing MOOC Essay Answers: A Comparison\n  of Pre- and Post-LLM Responses","summary":"The release of ChatGPT in late 2022 caused a flurry of activity and concern\nin the academic and educational communities. Some see the tool's ability to\ngenerate human-like text that passes at least cursory inspections for factual\naccuracy ``often enough'' a golden age of information retrieval and\ncomputer-assisted learning. Some, on the other hand, worry the tool may lead to\nunprecedented levels of academic dishonesty and cheating. In this work, we\nquantify some of the effects of the emergence of Large Language Models (LLMs)\non online education by analyzing a multi-year dataset of student essay\nresponses from a free university-level MOOC on AI ethics. Our dataset includes\nessays submitted both before and after ChatGPT's release. We find that the\nlaunch of ChatGPT coincided with significant changes in both the length and\nstyle of student essays, mirroring observations in other contexts such as\nacademic publishing. We also observe -- as expected based on related public\ndiscourse -- changes in prevalence of key content words related to AI and LLMs,\nbut not necessarily the general themes or topics discussed in the student\nessays as identified through (dynamic) topic modeling.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-04-17T15:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.13039v1","title":"Evidence for sulfur chemistry in the atmosphere of the warm sub-Neptune\n  TOI-270 d","summary":"Context: Recent JWST measurements allow access to the near-infrared spectrum\nof the sub-Neptune TOI-270 d, for which two different interpretations, a\nhigh-metallicity miscible envelope and a lower metallicity hycean world, are\ncurrently in conflict. Aims: Here, we reanalyze the published data and\nreproduce previously retrieved molecular abundances based on an independent\ndata reduction and a different retrieval framework. The aim of this study is to\nrefine the understanding of TOI-270 d and highlight considerations for JWST\ndata analysis. Additionally, we test the impact of data resolution on\natmospheric retrieval calculations. Methods: We reduce one JWST NIRSpec G395H\nand one NIRISS SOSS GR700XD transit dataset using the Eureka! pipeline and a\ncustom MCMC-based light curve fitting algorithm at the instruments' native\nresolutions. The atmospheric composition is estimated with the updated BeAR\nretrieval code across a grid of retrieval setups and spectral resolutions.\nResults: Our transit spectrum is consistent with previous studies, except at\nthe red end of the NIRISS data. Our retrievals support a higher mean molecular\nweight atmosphere for TOI-270 d. We provide refined abundance constraints and\nfind statistically favored model extensions indicating either sulfur-rich\nchemistry with species such as CS2, CS, and H2CS, or the possible presence of\nCH3Cl or CH3F. However, Bayesian inference cannot distinguish between these\nscenarios due to similar opacities below 4 microns. Conclusions: Our analysis\nreinforces TOI-270 d as a highly interesting warm sub-Neptune for atmospheric\nstudies, with a complex chemistry in a cloud-free upper atmosphere. However,\nits exact nature remains uncertain and warrants further detailed photochemical\nmodeling and observations.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-17T15:52:23Z"}
{"aid":"http://arxiv.org/abs/2504.13054v1","title":"Aspect-Based Summarization with Self-Aspect Retrieval Enhanced\n  Generation","summary":"Aspect-based summarization aims to generate summaries tailored to specific\naspects, addressing the resource constraints and limited generalizability of\ntraditional summarization approaches. Recently, large language models have\nshown promise in this task without the need for training. However, they rely\nexcessively on prompt engineering and face token limits and hallucination\nchallenges, especially with in-context learning. To address these challenges,\nin this paper, we propose a novel framework for aspect-based summarization:\nSelf-Aspect Retrieval Enhanced Summary Generation. Rather than relying solely\non in-context learning, given an aspect, we employ an embedding-driven\nretrieval mechanism to identify its relevant text segments. This approach\nextracts the pertinent content while avoiding unnecessary details, thereby\nmitigating the challenge of token limits. Moreover, our framework optimizes\ntoken usage by deleting unrelated parts of the text and ensuring that the model\ngenerates output strictly based on the given aspect. With extensive experiments\non benchmark datasets, we demonstrate that our framework not only achieves\nsuperior performance but also effectively mitigates the token limitation\nproblem.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T16:09:57Z"}
{"aid":"http://arxiv.org/abs/2504.13055v1","title":"NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation","summary":"Recent advances in reinforcement learning (RL) have strengthened the\nreasoning capabilities of vision-language models (VLMs). However, enhancing\npolicy exploration to more effectively scale test-time compute remains\nunderexplored in VLMs. In addition, VLMs continue to struggle with imperfect\nvisual perception, which in turn affects the subsequent reasoning process. To\nthis end, we propose NoisyRollout, a simple yet effective RL approach that\nmixes trajectories from both clean and moderately distorted images to introduce\ntargeted diversity in visual perception and the resulting reasoning patterns.\nWithout additional training cost, NoisyRollout enhances the exploration\ncapabilities of VLMs by incorporating a vision-oriented inductive bias.\nFurthermore, NoisyRollout employs a noise annealing schedule that gradually\nreduces distortion strength over training, ensuring benefit from noisy signals\nearly while maintaining training stability and scalability in later stages.\nWith just 2.1K training samples, NoisyRollout achieves state-of-the-art\nperformance among open-source RL-tuned models on 5 out-of-domain benchmarks\nspanning both reasoning and perception tasks, while preserving comparable or\neven better in-domain performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T16:10:13Z"}
{"aid":"http://arxiv.org/abs/2504.13068v1","title":"Accuracy is Not Agreement: Expert-Aligned Evaluation of Crash Narrative\n  Classification Models","summary":"This study explores the relationship between deep learning (DL) model\naccuracy and expert agreement in the classification of crash narratives. We\nevaluate five DL models -- including BERT variants, the Universal Sentence\nEncoder (USE), and a zero-shot classifier -- against expert-labeled data and\nnarrative text. The analysis is further extended to four large language models\n(LLMs): GPT-4, LLaMA 3, Qwen, and Claude. Our results reveal a counterintuitive\ntrend: models with higher technical accuracy often exhibit lower agreement with\ndomain experts, whereas LLMs demonstrate greater expert alignment despite\nrelatively lower accuracy scores. To quantify and interpret model-expert\nagreement, we employ Cohen's Kappa, Principal Component Analysis (PCA), and\nSHAP-based explainability techniques. Findings indicate that expert-aligned\nmodels tend to rely more on contextual and temporal language cues, rather than\nlocation-specific keywords. These results underscore that accuracy alone is\ninsufficient for evaluating models in safety-critical NLP applications. We\nadvocate for incorporating expert agreement as a complementary metric in model\nevaluation frameworks and highlight the promise of LLMs as interpretable,\nscalable tools for crash analysis pipelines.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T16:29:08Z"}
{"aid":"http://arxiv.org/abs/2504.13078v1","title":"Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual\n  Try-Off","summary":"Computer vision is transforming fashion through Virtual Try-On (VTON) and\nVirtual Try-Off (VTOFF). VTON generates images of a person in a specified\ngarment using a target photo and a standardized garment image, while a more\nchallenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo\nof another person wearing the garment. VTOFF, on the other hand, extracts\nstandardized garment images from clothed individuals. We introduce TryOffDiff,\na diffusion-based VTOFF model. Built on a latent diffusion framework with\nSigLIP image conditioning, it effectively captures garment properties like\ntexture, shape, and patterns. TryOffDiff achieves state-of-the-art results on\nVITON-HD and strong performance on DressCode dataset, covering upper-body,\nlower-body, and dresses. Enhanced with class-specific embeddings, it pioneers\nmulti-garment VTOFF, the first of its kind. When paired with VTON models, it\nimproves p2p-VTON by minimizing unwanted attribute transfer, such as skin\ncolor. Code is available at: https://rizavelioglu.github.io/tryoffdiff/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T16:45:18Z"}
{"aid":"http://arxiv.org/abs/2504.13101v1","title":"An Empirically Grounded Identifiability Theory Will Accelerate\n  Self-Supervised Learning Research","summary":"Self-Supervised Learning (SSL) powers many current AI systems. As research\ninterest and investment grow, the SSL design space continues to expand. The\nPlatonic view of SSL, following the Platonic Representation Hypothesis (PRH),\nsuggests that despite different methods and engineering approaches, all\nrepresentations converge to the same Platonic ideal. However, this phenomenon\nlacks precise theoretical explanation. By synthesizing evidence from\nIdentifiability Theory (IT), we show that the PRH can emerge in SSL. However,\ncurrent IT cannot explain SSL's empirical success. To bridge the gap between\ntheory and practice, we propose expanding IT into what we term Singular\nIdentifiability Theory (SITh), a broader theoretical framework encompassing the\nentire SSL pipeline. SITh would allow deeper insights into the implicit data\nassumptions in SSL and advance the field towards learning more interpretable\nand generalizable representations. We highlight three critical directions for\nfuture research: 1) training dynamics and convergence properties of SSL; 2) the\nimpact of finite samples, batch size, and data diversity; and 3) the role of\ninductive biases in architecture, augmentations, initialization schemes, and\noptimizers.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-17T17:10:33Z"}
{"aid":"http://arxiv.org/abs/2504.13102v1","title":"A Multi-task Learning Balanced Attention Convolutional Neural Network\n  Model for Few-shot Underwater Acoustic Target Recognition","summary":"Underwater acoustic target recognition (UATR) is of great significance for\nthe protection of marine diversity and national defense security. The\ndevelopment of deep learning provides new opportunities for UATR, but faces\nchallenges brought by the scarcity of reference samples and complex\nenvironmental interference. To address these issues, we proposes a multi-task\nbalanced channel attention convolutional neural network (MT-BCA-CNN). The\nmethod integrates a channel attention mechanism with a multi-task learning\nstrategy, constructing a shared feature extractor and multi-task classifiers to\njointly optimize target classification and feature reconstruction tasks. The\nchannel attention mechanism dynamically enhances discriminative acoustic\nfeatures such as harmonic structures while suppressing noise. Experiments on\nthe Watkins Marine Life Dataset demonstrate that MT-BCA-CNN achieves 97\\%\nclassification accuracy and 95\\% $F1$-score in 27-class few-shot scenarios,\nsignificantly outperforming traditional CNN and ACNN models, as well as popular\nstate-of-the-art UATR methods. Ablation studies confirm the synergistic\nbenefits of multi-task learning and attention mechanisms, while a dynamic\nweighting adjustment strategy effectively balances task contributions. This\nwork provides an efficient solution for few-shot underwater acoustic\nrecognition, advancing research in marine bioacoustics and sonar signal\nprocessing.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-17T17:11:32Z"}
{"aid":"http://arxiv.org/abs/2504.13108v1","title":"Global patterns in signed permutations","summary":"Global permutation patterns have recently been shown to characterize\nimportant properties of a Coxeter group. Here we study global patterns in the\ncontext of signed permutations, with both characterizing and enumerative\nresults. Surprisingly, many properties of signed permutations may be\ncharacterized by avoidance of the same set of patterns as the corresponding\nproperties in the symmetric group. We also extend previous enumerative work of\nEgge, and our work has connections to the Garfinkle--Barbasch--Vogan\ncorrespondence, the Erd\\H{o}s--Szekeres theorem, and well-known integer\nsequences.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T17:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.13111v1","title":"Uncertainty-Aware Trajectory Prediction via Rule-Regularized\n  Heteroscedastic Deep Classification","summary":"Deep learning-based trajectory prediction models have demonstrated promising\ncapabilities in capturing complex interactions. However, their\nout-of-distribution generalization remains a significant challenge,\nparticularly due to unbalanced data and a lack of enough data and diversity to\nensure robustness and calibration. To address this, we propose SHIFT (Spectral\nHeteroscedastic Informed Forecasting for Trajectories), a novel framework that\nuniquely combines well-calibrated uncertainty modeling with informative priors\nderived through automated rule extraction. SHIFT reformulates trajectory\nprediction as a classification task and employs heteroscedastic\nspectral-normalized Gaussian processes to effectively disentangle epistemic and\naleatoric uncertainties. We learn informative priors from training labels,\nwhich are automatically generated from natural language driving rules, such as\nstop rules and drivability constraints, using a retrieval-augmented generation\nframework powered by a large language model. Extensive evaluations over the\nnuScenes dataset, including challenging low-data and cross-location scenarios,\ndemonstrate that SHIFT outperforms state-of-the-art methods, achieving\nsubstantial gains in uncertainty calibration and displacement metrics. In\nparticular, our model excels in complex scenarios, such as intersections, where\nuncertainty is inherently higher. Project page:\nhttps://kumarmanas.github.io/SHIFT/.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-17T17:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.13119v1","title":"Object-Driven Narrative in AR: A Scenario-Metaphor Framework with VLM\n  Integration","summary":"Most adaptive AR storytelling systems define environmental semantics using\nsimple object labels and spatial coordinates, limiting narratives to rigid,\npre-defined logic. This oversimplification overlooks the contextual\nsignificance of object relationships-for example, a wedding ring on a\nnightstand might suggest marital conflict, yet is treated as just \"two objects\"\nin space. To address this, we explored integrating Vision Language Models\n(VLMs) into AR pipelines. However, several challenges emerged: First, stories\ngenerated with simple prompt guidance lacked narrative depth and spatial usage.\nSecond, spatial semantics were underutilized, failing to support meaningful\nstorytelling. Third, pre-generated scripts struggled to align with AR\nFoundation's object naming and coordinate systems. We propose a scene-driven AR\nstorytelling framework that reimagines environments as active narrative agents,\nbuilt on three innovations: 1. State-aware object semantics: We decompose\nobject meaning into physical, functional, and metaphorical layers, allowing\nVLMs to distinguish subtle narrative cues between similar objects. 2.\nStructured narrative interface: A bidirectional JSON layer maps VLM-generated\nmetaphors to AR anchors, maintaining spatial and semantic coherence. 3. STAM\nevaluation framework: A three-part experimental design evaluates narrative\nquality, highlighting both strengths and limitations of VLM-AR integration. Our\nfindings show that the system can generate stories from the environment itself,\nnot just place them on top of it. In user studies, 70% of participants reported\nseeing real-world objects differently when narratives were grounded in\nenvironmental symbolism. By merging VLMs' generative creativity with AR's\nspatial precision, this framework introduces a novel object-driven storytelling\nparadigm, transforming passive spaces into active narrative landscapes.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-17T17:37:49Z"}
{"aid":"http://arxiv.org/abs/2504.13123v1","title":"Low-hallucination Synthetic Captions for Large-Scale Vision-Language\n  Model Pre-training","summary":"In recent years, the field of vision-language model pre-training has\nexperienced rapid advancements, driven primarily by the continuous enhancement\nof textual capabilities in large language models. However, existing training\nparadigms for multimodal large language models heavily rely on high-quality\nimage-text pairs. As models and data scales grow exponentially, the\navailability of such meticulously curated data has become increasingly scarce\nand saturated, thereby severely limiting further advancements in this domain.\nThis study investigates scalable caption generation techniques for\nvision-language model pre-training and demonstrates that large-scale\nlow-hallucination synthetic captions can serve dual purposes: 1) acting as a\nviable alternative to real-world data for pre-training paradigms and 2)\nachieving superior performance enhancement when integrated into vision-language\nmodels through empirical validation. This paper presents three key\ncontributions: 1) a novel pipeline for generating high-quality,\nlow-hallucination, and knowledge-rich synthetic captions. Our continuous DPO\nmethodology yields remarkable results in reducing hallucinations. Specifically,\nthe non-hallucination caption rate on a held-out test set increases from 48.2%\nto 77.9% for a 7B-size model. 2) Comprehensive empirical validation reveals\nthat our synthetic captions confer superior pre-training advantages over their\ncounterparts. Across 35 vision language tasks, the model trained with our data\nachieves a significant performance gain of at least 6.2% compared to alt-text\npairs and other previous work. Meanwhile, it also offers considerable support\nin the text-to-image domain. With our dataset, the FID score is reduced by 17.1\non a real-world validation benchmark and 13.3 on the MSCOCO validation\nbenchmark. 3) We will release Hunyuan-Recap100M, a low-hallucination and\nknowledge-intensive synthetic caption dataset.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T17:40:06Z"}
{"aid":"http://arxiv.org/abs/2504.13128v1","title":"FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on\n  Technical Documents","summary":"We introduce FreshStack, a reusable framework for automatically building\ninformation retrieval (IR) evaluation benchmarks from community-asked questions\nand answers. FreshStack conducts the following steps: (1) automatic corpus\ncollection from code and technical documentation, (2) nugget generation from\ncommunity-asked questions and answers, and (3) nugget-level support, retrieving\ndocuments using a fusion of retrieval techniques and hybrid architectures. We\nuse FreshStack to build five datasets on fast-growing, recent, and niche topics\nto ensure the tasks are sufficiently challenging. On FreshStack, existing\nretrieval models, when applied out-of-the-box, significantly underperform\noracle approaches on all five topics, denoting plenty of headroom to improve IR\nquality. In addition, we identify cases where rerankers do not clearly improve\nfirst-stage retrieval accuracy (two out of five topics). We hope that\nFreshStack will facilitate future work toward constructing realistic, scalable,\nand uncontaminated IR and RAG evaluation benchmarks. FreshStack datasets are\navailable at: https://fresh-stack.github.io.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-17T17:44:06Z"}
{"aid":"http://arxiv.org/abs/2504.13130v1","title":"General Analytic Solutions for Circumplanetary Disks during the Late\n  Stages of Giant Planet Formation","summary":"Forming giant planets are accompanied by circumplanetary disks, as indicated\nby considerations of angular momentum conservation, observations of candidate\nprotoplanets, and the satellite systems of planets in our Solar System. This\npaper derives surface density distributions for circumplanetary disks during\nthe final stage of evolution when most of the mass is accreted. This approach\ngeneralizes previous treatments to include the angular momentum bias for the\ninfalling material, more accurate solutions for the incoming trajectories,\ncorrections to the outer boundary condition of the circumplanetary disk, and\nthe adjustment of newly added material as it becomes incorporated into the\nKeplerian flow of the pre-existing disk. These generalizations lead to smaller\ncentrifugal radii, higher column density for the surrounding envelopes, and\nhigher disk accretion efficiency. In addition, we explore the consequences of\ndifferent angular distributions for the incoming material at the outer\nboundary, with the concentration of the incoming flow varying from polar to\nisotropic to equatorial. These geometric variations modestly affect the disk\nsurface density, but also lead to substantial modification to the location in\nthe disk where the mass accretion rate changes sign. This paper finds analytic\nsolutions for the orbits, source functions, surface density distributions, and\nthe corresponding disk temperature profiles over the expanded parameter space\noutlined above.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-17T17:45:32Z"}
{"aid":"http://arxiv.org/abs/2504.13133v1","title":"Giant nematic response of the incommensurate charge density wave in the\n  nickel-pnictide Ba$_{1-x}$Sr$_x$Ni$_2$As$_2$","summary":"Electron nematicity-the breaking of rotational symmetry while preserving\ntranslational symmetry-is the quantum analogue of classical nematic liquid\ncrystals. First predicted in 1998, electronic nematicity has been established\nin a variety of materials, including two-dimensional electron gases (2DEGs) in\nmagnetic fields, copper-oxide superconductors, and Fe-based superconductors. A\nlong-standing open question is what physical mechanisms drive electronic\nnematic order. In BaFe$_2$As$_2$ and highly underdoped YBa$_2$Cu$_3$O$_{6+y}$,\nstrong evidence suggests that nematicity arises from vestigial\nspin-density-wave (SDW) order. However, evidence for nematicity associated with\ncharge-density-wave (CDW) order has been less conclusive, particularly in\nsystems near a superconducting state. Here, we present direct evidence for\nCDW-driven nematic fluctuations in the pnictide superconductor\nBa$_{1-x}$Sr$_x$Ni$_2$As$_2$ (BSNA), a Ni-based homologue of Fe-based\nsuperconductors that exhibits CDW rather than SDW order. Previous\nelastoresistance studies have shown that BSNA displays a large nematic\nsusceptibility-linked to a six-fold enhancement of superconductivity-within a\nregion of the phase diagram occupied by an incommensurate CDW. Using x-ray\nscattering under uniaxial strain, we demonstrate that even minimal strain\nlevels ($\\epsilon \\sim 10^{-4}$) significantly break the fourfold symmetry of\nthe CDW. Within a Ginzburg-Landau framework, we define a nematic susceptibility\nbased on the asymmetric response of symmetry-related CDW superlattice\nreflections, showing strong agreement with elastoresistivity measurements. Our\nstudy provides the first clear demonstration of a direct link between charge\norder and a nematic state, offering key insights into the intertwined\nsuperconducting phases of these materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-17T17:47:04Z"}
{"aid":"http://arxiv.org/abs/2504.13134v1","title":"Energy-Based Reward Models for Robust Language Model Alignment","summary":"Reward models (RMs) are essential for aligning Large Language Models (LLMs)\nwith human preferences. However, they often struggle with capturing complex\nhuman preferences and generalizing to unseen data. To address these challenges,\nwe introduce Energy-Based Reward Model (EBRM), a lightweight post-hoc\nrefinement framework that enhances RM robustness and generalization. EBRM\nmodels the reward distribution explicitly, capturing uncertainty in human\npreferences and mitigating the impact of noisy or misaligned annotations. It\nachieves this through conflict-aware data filtering, label-noise-aware\ncontrastive training, and hybrid initialization. Notably, EBRM enhances RMs\nwithout retraining, making it computationally efficient and adaptable across\ndifferent models and tasks. Empirical evaluations on RM benchmarks demonstrate\nsignificant improvements in both robustness and generalization, achieving up to\na 5.97% improvement in safety-critical alignment tasks compared to standard\nRMs. Furthermore, reinforcement learning experiments confirm that our refined\nrewards enhance alignment quality, effectively delaying reward hacking. These\nresults demonstrate our approach as a scalable and effective enhancement for\nexisting RMs and alignment pipelines. The code is available at EBRM.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-17T17:47:15Z"}
{"aid":"http://arxiv.org/abs/2504.13136v1","title":"Freezing of the renormalized one-loop primordial scalar power spectrum","summary":"By consistently using the effective field theory of inflationary fluctuations\nin the decoupling limit, we explicitly prove that the renormalized one-loop\npower spectrum of the primordial curvature perturbation freezes exactly on\nscales larger than its sound horizon.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-17T17:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.13138v1","title":"Extending the Mott-Gurney law to one-dimensional nonplanar diodes using\n  point transformations","summary":"Recent studies have applied variational calculus, conformal mapping, and\npoint transformations to generalize the one-dimensional (1D) space-charge\nlimited current density (SCLCD) and electron emission mechanisms to nonplanar\ngeometries; however, these assessments have focused on extending the\nChild-Langmuir law (CLL) for SCLCD in vacuum. Since the charge in the diode is\nindependent of coordinate system (i.e., covariant), we apply bijective point\ntransformations to extend the Mott-Gurney law (MGL) for the SCLCD in a\ncollisional or semiconductor gap to nonplanar 1D geometries. This yields a\nmodified MGL that replaces the Cartesian gap distance with a canonical gap\ndistance that may be written generally in terms of geometric scale factors that\nare known for multiple geometries. We tabulate results for common geometries.\nSuch an approach may be applied to any current density, including\nnon-space-charge limited gaps and SCLCD that may fall between the CLL and MGL.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.plasm-ph","published":"2025-04-17T17:49:06Z"}
{"aid":"http://arxiv.org/abs/2504.13141v1","title":"Complexity at Scale: A Quantitative Analysis of an Alibaba Microservice\n  Deployment","summary":"Microservice architectures are increasingly prevalent in organisations\nproviding online applications. Recent studies have begun to explore the\ncharacteristics of real-world large-scale microservice deployments; however,\ntheir operational complexities, and the degree to which this complexities are\nconsistent across different deployments, remains under-explored. In this paper,\nwe analyse a microservice dataset released by Alibaba along three dimensions of\ncomplexity: scale, heterogeneity, and dynamicity. We find that large-scale\ndeployments can consist of tens of thousands of microservices, that support an\neven broader array of front-end functionality. Moreover, our analysis shows\nwide-spread long-tailed distributions of characteristics between microservices,\nsuch as share of workload and dependencies, highlighting inequality across the\ndeployment. This diversity is also reflected in call graphs, where we find that\nwhilst front-end services produce dominant call graphs, rarer non-dominant call\ngraphs are prevalent and could involve dissimilar microservice calls. We also\nfind that runtime dependencies between microservices deviate from the static\nview of system dependencies, and that the deployment undergoes daily changes to\nmicroservices. We discuss the implications of our findings for state-of-the-art\nresearch in microservice management and research testbed realism, and compare\nour results to previous descriptions of large-scale microservice deployments to\nbegin to build an understanding of their commonalities.","main_category":"cs.DC","categories":"cs.DC,cs.SE","published":"2025-04-17T17:50:44Z"}
{"aid":"http://arxiv.org/abs/2504.13142v1","title":"Transfer Learning via Auxiliary Labels with Application to\n  Cold-Hardiness Prediction","summary":"Cold temperatures can cause significant frost damage to fruit crops depending\non their resilience, or cold hardiness, which changes throughout the dormancy\nseason. This has led to the development of predictive cold-hardiness models,\nwhich help farmers decide when to deploy expensive frost-mitigation measures.\nUnfortunately, cold-hardiness data for model training is only available for\nsome fruit cultivars due to the need for specialized equipment and expertise.\nRather, farmers often do have years of phenological data (e.g. date of\nbudbreak) that they regularly collect for their crops. In this work, we\nintroduce a new transfer-learning framework, Transfer via Auxiliary Labels\n(TAL), that allows farmers to leverage the phenological data to produce more\naccurate cold-hardiness predictions, even when no cold-hardiness data is\navailable for their specific crop. The framework assumes a set of source tasks\n(cultivars) where each has associated primary labels (cold hardiness) and\nauxiliary labels (phenology). However, the target task (new cultivar) is\nassumed to only have the auxiliary labels. The goal of TAL is to predict\nprimary labels for the target task via transfer from the source tasks.\nSurprisingly, despite the vast literature on transfer learning, to our\nknowledge, the TAL formulation has not been previously addressed. Thus, we\npropose several new TAL approaches based on model selection and averaging that\ncan leverage recent deep multi-task models for cold-hardiness prediction. Our\nresults on real-world cold-hardiness and phenological data for multiple grape\ncultivars demonstrate that TAL can leverage the phenological data to improve\ncold-hardiness predictions in the absence of cold-hardiness data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T17:51:38Z"}
{"aid":"http://arxiv.org/abs/2504.13148v1","title":"Relative entropy of squeezed states in Quantum Field Theory","summary":"Utilizing the Tomita-Takesaki modular theory, we derive a closed-form\nanalytic expression for the Araki-Uhlmann relative entropy between a squeezed\nstate and the vacuum state in a free relativistic massive scalar Quantum Field\nTheory within wedge regions of Minkowski spacetime. Similarly to the case of\ncoherent states, this relative entropy is proportional to the smeared\nPauli-Jordan distribution. Consequently, the Araki-Uhlmann entropy between a\nsqueezed state and the vacuum satisfies all expected properties: it remains\npositive, increases with the size of the Minkowski region under consideration,\nand decreases as the mass parameter grows.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-17T17:55:00Z"}
{"aid":"http://arxiv.org/abs/2504.13162v1","title":"Personalized Text-to-Image Generation with Auto-Regressive Models","summary":"Personalized image synthesis has emerged as a pivotal application in\ntext-to-image generation, enabling the creation of images featuring specific\nsubjects in diverse contexts. While diffusion models have dominated this\ndomain, auto-regressive models, with their unified architecture for text and\nimage modeling, remain underexplored for personalized image generation. This\npaper investigates the potential of optimizing auto-regressive models for\npersonalized image synthesis, leveraging their inherent multimodal capabilities\nto perform this task. We propose a two-stage training strategy that combines\noptimization of text embeddings and fine-tuning of transformer layers. Our\nexperiments on the auto-regressive model demonstrate that this method achieves\ncomparable subject fidelity and prompt following to the leading diffusion-based\npersonalization methods. The results highlight the effectiveness of\nauto-regressive models in personalized image generation, offering a new\ndirection for future research in this area.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.13165v1","title":"RUKA: Rethinking the Design of Humanoid Hands with Learning","summary":"Dexterous manipulation is a fundamental capability for robotic systems, yet\nprogress has been limited by hardware trade-offs between precision,\ncompactness, strength, and affordability. Existing control methods impose\ncompromises on hand designs and applications. However, learning-based\napproaches present opportunities to rethink these trade-offs, particularly to\naddress challenges with tendon-driven actuation and low-cost materials. This\nwork presents RUKA, a tendon-driven humanoid hand that is compact, affordable,\nand capable. Made from 3D-printed parts and off-the-shelf components, RUKA has\n5 fingers with 15 underactuated degrees of freedom enabling diverse human-like\ngrasps. Its tendon-driven actuation allows powerful grasping in a compact,\nhuman-sized form factor. To address control challenges, we learn\njoint-to-actuator and fingertip-to-actuator models from motion-capture data\ncollected by the MANUS glove, leveraging the hand's morphological accuracy.\nExtensive evaluations demonstrate RUKA's superior reachability, durability, and\nstrength compared to other robotic hands. Teleoperation tasks further showcase\nRUKA's dexterous movements. The open-source design and assembly instructions of\nRUKA, code, and data are available at https://ruka-hand.github.io/.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-17T17:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.13169v1","title":"Generate, but Verify: Reducing Hallucination in Vision-Language Models\n  with Retrospective Resampling","summary":"Vision-Language Models (VLMs) excel at visual understanding but often suffer\nfrom visual hallucinations, where they generate descriptions of nonexistent\nobjects, actions, or concepts, posing significant risks in safety-critical\napplications. Existing hallucination mitigation methods typically follow one of\ntwo paradigms: generation adjustment, which modifies decoding behavior to align\ntext with visual inputs, and post-hoc verification, where external models\nassess and correct outputs. While effective, generation adjustment methods\noften rely on heuristics and lack correction mechanisms, while post-hoc\nverification is complicated, typically requiring multiple models and tending to\nreject outputs rather than refine them. In this work, we introduce REVERSE, a\nunified framework that integrates hallucination-aware training with on-the-fly\nself-verification. By leveraging a new hallucination-verification dataset\ncontaining over 1.3M semi-synthetic samples, along with a novel inference-time\nretrospective resampling technique, our approach enables VLMs to both detect\nhallucinations during generation and dynamically revise those hallucinations.\nOur evaluations show that REVERSE achieves state-of-the-art hallucination\nreduction, outperforming the best existing methods by up to 12% on CHAIR-MSCOCO\nand 28% on HaloQuest. Our dataset, model, and code are available at:\nhttps://reverse-vlm.github.io.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.14827v1","title":"LACE: Exploring Turn-Taking and Parallel Interaction Modes in Human-AI\n  Co-Creation for Iterative Image Generation","summary":"This paper introduces LACE, a co-creative system enabling professional\nartists to leverage generative AI through controlled prompting and iterative\nrefinement within Photoshop. Addressing challenges in precision, iterative\ncoherence, and workflow compatibility, LACE allows flexible control via\nlayer-based editing and dual-mode collaboration (turn-taking and parallel). A\npilot study (N=21) demonstrates significant improvements in user satisfaction,\nownership, usability, and artistic perception compared to standard AI\nworkflows. We offer comprehensive findings, system details, nuanced user\nfeedback, and implications for integrating generative AI in professional art\npractices.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-21T03:01:27Z"}
{"aid":"http://arxiv.org/abs/2504.14833v1","title":"IoT-AMLHP: Aligned Multimodal Learning of Header-Payload Representations\n  for Resource-Efficient Malicious IoT Traffic Classification","summary":"Traffic classification is crucial for securing Internet of Things (IoT)\nnetworks. Deep learning-based methods can autonomously extract latent patterns\nfrom massive network traffic, demonstrating significant potential for IoT\ntraffic classification tasks. However, the limited computational and spatial\nresources of IoT devices pose challenges for deploying more complex deep\nlearning models. Existing methods rely heavily on either flow-level features or\nraw packet byte features. Flow-level features often require inspecting entire\nor most of the traffic flow, leading to excessive resource consumption, while\nraw packet byte features fail to distinguish between headers and payloads,\noverlooking semantic differences and introducing noise from feature\nmisalignment. Therefore, this paper proposes IoT-AMLHP, an aligned multimodal\nlearning framework for resource-efficient malicious IoT traffic classification.\nFirstly, the framework constructs a packet-wise header-payload representation\nby parsing packet headers and payload bytes, resulting in an aligned and\nstandardized multimodal traffic representation that enhances the\ncharacterization of heterogeneous IoT traffic. Subsequently, the traffic\nrepresentation is fed into a resource-efficient neural network comprising a\nmultimodal feature extraction module and a multimodal fusion module. The\nextraction module employs efficient depthwise separable convolutions to capture\nmulti-scale features from different modalities while maintaining a lightweight\narchitecture. The fusion module adaptively captures complementary features from\ndifferent modalities and effectively fuses multimodal features.","main_category":"cs.NI","categories":"cs.NI,cs.CR","published":"2025-04-21T03:24:14Z"}
{"aid":"http://arxiv.org/abs/2504.14854v1","title":"Uncertainty quantification of neural network models of evolving\n  processes via Langevin sampling","summary":"We propose a scalable, approximate inference hypernetwork framework for a\ngeneral model of history-dependent processes. The flexible data model is based\non a neural ordinary differential equation (NODE) representing the evolution of\ninternal states together with a trainable observation model subcomponent. The\nposterior distribution corresponding to the data model parameters (weights and\nbiases) follows a stochastic differential equation with a drift term related to\nthe score of the posterior that is learned jointly with the data model\nparameters. This Langevin sampling approach offers flexibility in balancing the\ncomputational budget between the evaluation cost of the data model and the\napproximation of the posterior density of its parameters. We demonstrate\nperformance of the hypernetwork on chemical reaction and material physics data\nand compare it to mean-field variational inference.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-21T04:45:40Z"}
{"aid":"http://arxiv.org/abs/2504.14871v1","title":"Natural Fingerprints of Large Language Models","summary":"Large language models (LLMs) often exhibit biases -- systematic deviations\nfrom expected norms -- in their outputs. These range from overt issues, such as\nunfair responses, to subtler patterns that can reveal which model produced\nthem. We investigate the factors that give rise to identifiable characteristics\nin LLMs. Since LLMs model training data distribution, it is reasonable that\ndifferences in training data naturally lead to the characteristics. However,\nour findings reveal that even when LLMs are trained on the exact same data, it\nis still possible to distinguish the source model based on its generated text.\nWe refer to these unintended, distinctive characteristics as natural\nfingerprints. By systematically controlling training conditions, we show that\nthe natural fingerprints can emerge from subtle differences in the training\nprocess, such as parameter sizes, optimization settings, and even random seeds.\nWe believe that understanding natural fingerprints offers new insights into the\norigins of unintended bias and ways for improving control over LLM behavior.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T05:48:52Z"}
{"aid":"http://arxiv.org/abs/2504.14881v1","title":"Towards Fuzzing Zero-Knowledge Proof Circuits (Short Paper)","summary":"Zero-knowledge proofs (ZKPs) have evolved from a theoretical cryptographic\nconcept into a powerful tool for implementing privacy-preserving and verifiable\napplications without requiring trust assumptions. Despite significant progress\nin the field, implementing and using ZKPs via \\emph{ZKP circuits} remains\nchallenging, leading to numerous bugs that affect ZKP circuits in practice, and\n\\emph{fuzzing} remains largely unexplored as a method to detect bugs in ZKP\ncircuits. We discuss the unique challenges of applying fuzzing to ZKP circuits,\nexamine the oracle problem and its potential solutions, and propose techniques\nfor input generation and test harness construction. We demonstrate that fuzzing\ncan be effective in this domain by implementing a fuzzer for \\texttt{zk-regex},\na cornerstone library in modern ZKP applications. In our case study, we\ndiscovered \\textit{$10$} new bugs.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-21T06:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.14882v1","title":"Some Optimizers are More Equal: Understanding the Role of Optimizers in\n  Group Fairness","summary":"We study whether and how the choice of optimization algorithm can impact\ngroup fairness in deep neural networks. Through stochastic differential\nequation analysis of optimization dynamics in an analytically tractable setup,\nwe demonstrate that the choice of optimization algorithm indeed influences\nfairness outcomes, particularly under severe imbalance. Furthermore, we show\nthat when comparing two categories of optimizers, adaptive methods and\nstochastic methods, RMSProp (from the adaptive category) has a higher\nlikelihood of converging to fairer minima than SGD (from the stochastic\ncategory). Building on this insight, we derive two new theoretical guarantees\nshowing that, under appropriate conditions, RMSProp exhibits fairer parameter\nupdates and improved fairness in a single optimization step compared to SGD. We\nthen validate these findings through extensive experiments on three publicly\navailable datasets, namely CelebA, FairFace, and MS-COCO, across different\ntasks as facial expression recognition, gender classification, and multi-label\nclassification, using various backbones. Considering multiple fairness\ndefinitions including equalized odds, equal opportunity, and demographic\nparity, adaptive optimizers like RMSProp and Adam consistently outperform SGD\nin terms of group fairness, while maintaining comparable predictive accuracy.\nOur results highlight the role of adaptive updates as a crucial yet overlooked\nmechanism for promoting fair outcomes.","main_category":"cs.LG","categories":"cs.LG,cs.CV,stat.ML","published":"2025-04-21T06:20:50Z"}
{"aid":"http://arxiv.org/abs/2504.14895v1","title":"MetasurfaceViT: A generic AI model for metasurface inverse design","summary":"Metasurfaces, sub-wavelength artificial structures, can control light's\namplitude, phase, and polar ization, enabling applications in efficient\nimaging, holograms, and sensing. Recent years, AI has witnessed remarkable\nprogress and spurred scientific discovery. In metasurface design, optical\ninverse design has recently emerged as a revolutionary approach. It uses deep\nlearning to create a nonlinear mapping between optical structures and\nfunctions, bypassing time-consuming traditional design and attaining higher\naccuracy. Yet, current deep-learning models for optical design face\nlimitations. They often work only for fixed wavelengths and polarizations, and\nlack universality as input-output vector size changes may require retraining.\nThere's also a lack of compatibility across different application scenarios.\nThis paper introduces MetasurfaceViT, a revolutionary generic AI model. It\nleverages a large amount of data using Jones matrices and physics-informed data\naugmentation. By pre-training through masking wavelengths and polarization\nchannels, it can reconstruct full-wavelength Jones matrices, which will be\nutilized by fine-tuning model to enable inverse design. Finally, a tandem\nworkflow appended by a forward prediction network is introduced to evaluate\nperformance. The versatility of MetasurfaceViT with high prediction accuracy\nwill open a new paradigm for optical inverse design.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-21T06:54:43Z"}
{"aid":"http://arxiv.org/abs/2504.14907v1","title":"Dynamic Graph-Like Learning with Contrastive Clustering on\n  Temporally-Factored Ship Motion Data for Imbalanced Sea State Estimation in\n  Autonomous Vessel","summary":"Accurate sea state estimation is crucial for the real-time control and future\nstate prediction of autonomous vessels. However, traditional methods struggle\nwith challenges such as data imbalance and feature redundancy in ship motion\ndata, limiting their effectiveness. To address these challenges, we propose the\nTemporal-Graph Contrastive Clustering Sea State Estimator (TGC-SSE), a novel\ndeep learning model that combines three key components: a time dimension\nfactorization module to reduce data redundancy, a dynamic graph-like learning\nmodule to capture complex variable interactions, and a contrastive clustering\nloss function to effectively manage class imbalance. Our experiments\ndemonstrate that TGC-SSE significantly outperforms existing methods across 14\npublic datasets, achieving the highest accuracy in 9 datasets, with a 20.79%\nimprovement over EDI. Furthermore, in the field of sea state estimation,\nTGC-SSE surpasses five benchmark methods and seven deep learning models.\nAblation studies confirm the effectiveness of each module, demonstrating their\nrespective roles in enhancing overall model performance. Overall, TGC-SSE not\nonly improves the accuracy of sea state estimation but also exhibits strong\ngeneralization capabilities, providing reliable support for autonomous vessel\noperations.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T07:22:11Z"}
{"aid":"http://arxiv.org/abs/2504.14912v1","title":"Dynamics of pulsating swarmalators on a ring","summary":"We study a simple one-dimensional model of swarmalators, a generalization of\nphase oscillators that swarm around in space as well as synchronize internal\noscillations in time. Previous studies of the model focused on Kuramoto-type\ncouplings, where the phase interactions are governed by phase differences. Here\nwe consider Winfree-type coupling, where the interactions are multiplicative,\ndetermined by the product of a phase response function $R(\\theta)$ and phase\npulse function $P(\\theta)$. This more general interaction (from which the\nKuramoto phase differences emerge after averaging) produces rich physics: six\nlong-term modes of organization are found, which we characterize numerically\nand analytically.","main_category":"nlin.AO","categories":"nlin.AO,math-ph,math.MP","published":"2025-04-21T07:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.14914v1","title":"K-DRIFT Preparation: Experimental Verification of an Observation\n  Strategy for Accurate Dark-Sky Flats","summary":"Despite its scientific importance, the low-surface-brightness universe has\nyet to be fully explored due to various systematic uncertainties that affect\nthe achievable surface-brightness limit. Reducing these uncertainties requires\nvery accurate data processing. The dark-sky flat is a widely used calibration\nframe for accurate flat-field correction, generated by combining the sky\nbackground from science images. However, the night sky will likely contain\ncomplex local fluctuations, thus may still lead to photometric errors in data\ncalibrated with dark-sky flats. To address this concern, we conduct mock\nobservations with semi-realistic sky simulation data and evaluate observation\nstrategies to mitigate the impact of the fluctuating sky background. Our\nexperiments consider two representative sky conditions (clear and dirty) and\nperform intensive comparative analysis on two observation methods (offset and\nrolling). Our findings suggest that the rolling dithering method, which\nincorporates the operation of camera rotation into conventional dithering, can\nprovide more accurate dark-sky flats. Finally, we discuss the broader\nimplications of this method through additional experiments examining several\nfactors that may affect the imaging quality of observational data.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.GA","published":"2025-04-21T07:32:49Z"}
{"aid":"http://arxiv.org/abs/2504.14924v1","title":"Quantum Curves in the Context of Symplectic Duality","summary":"We discuss how to use the recent progress in understanding of the $x$-$y$\nduality and symplectic duality in the theory of topological recursion and its\ngeneralizations in order to efficiently compute the quantum spectral curve\noperators for the wave functions with arbitrary base points. The paper also\ncontains an overview of recent generalizations of the setup of topological\nrecursion prompted by the progress in understanding the $x$-$y$ duality.","main_category":"math-ph","categories":"math-ph,hep-th,math.AG,math.MP","published":"2025-04-21T07:47:02Z"}
{"aid":"http://arxiv.org/abs/2504.14932v1","title":"Hilbert expansion of the Boltzmann equation on a 2-dimensional disk with\n  specular boundary condition","summary":"In the present paper, we concern the hydrodynamic limit of Boltzmann equation\nwith specular reflection boundary condition in a two-dimensional disk to the\ncompressible Euler equations. Due to the non-zero curvature and non-zero\ntangential velocity of compressible Euler solution on the boundary, new\ndifficulties arise in the construction of Knudsen boundary layer. By employing\nthe geometric correction, and an innovative and refined $L^2-L^\\infty$ method,\nwe establish the existence and space-decay for a truncated Knudsen boundary\nlayer. Then, by the Hilbert expansion of multi-scales, we successfully justify\nthe hydrodynamic limit of Boltzmann equation with specular reflection boundary\ncondition to the compressible Euler equations in the two-dimensional disk.","main_category":"math.AP","categories":"math.AP","published":"2025-04-21T07:51:48Z"}
{"aid":"http://arxiv.org/abs/2504.14933v1","title":"TWIG: Two-Step Image Generation using Segmentation Masks in Diffusion\n  Models","summary":"In today's age of social media and marketing, copyright issues can be a major\nroadblock to the free sharing of images. Generative AI models have made it\npossible to create high-quality images, but concerns about copyright\ninfringement are a hindrance to their abundant use. As these models use data\nfrom training images to generate new ones, it is often a daunting task to\nensure they do not violate intellectual property rights. Some AI models have\neven been noted to directly copy copyrighted images, a problem often referred\nto as source copying. Traditional copyright protection measures such as\nwatermarks and metadata have also proven to be futile in this regard. To\naddress this issue, we propose a novel two-step image generation model inspired\nby the conditional diffusion model. The first step involves creating an image\nsegmentation mask for some prompt-based generated images. This mask embodies\nthe shape of the image. Thereafter, the diffusion model is asked to generate\nthe image anew while avoiding the shape in question. This approach shows a\ndecrease in structural similarity from the training image, i.e. we are able to\navoid the source copying problem using this approach without expensive\nretraining of the model or user-centered prompt generation techniques. This\nmakes our approach the most computationally inexpensive approach to avoiding\nboth copyright infringement and source copying for diffusion model-based image\ngeneration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T07:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.14938v1","title":"Integrating Response Time and Attention Duration in Bayesian Preference\n  Learning for Multiple Criteria Decision Aiding","summary":"We introduce a multiple criteria Bayesian preference learning framework\nincorporating behavioral cues for decision aiding. The framework integrates\npairwise comparisons, response time, and attention duration to deepen insights\ninto decision-making processes. The approach employs an additive value function\nmodel and utilizes a Bayesian framework to derive the posterior distribution of\npotential ranking models by defining the likelihood of observed preference data\nand specifying a prior on the preference structure. This distribution\nhighlights each model's ability to reconstruct Decision-Makers' holistic\npairwise comparisons. By leveraging both response time as a proxy for cognitive\neffort and alternative discriminability as well as attention duration as an\nindicator of criterion importance, the proposed model surpasses traditional\nmethods by uncovering richer behavioral patterns. We report the results of a\nlaboratory experiment on mobile phone contract selection involving 30 real\nsubjects using a dedicated application with time-, eye-, and mouse-tracking\ncomponents. We validate the novel method's ability to reconstruct complete\npreferences. The detailed ablation studies reveal time- and attention-related\nbehavioral patterns, confirming that integrating comprehensive data leads to\ndeveloping models that better align with the DM's actual preferences.","main_category":"stat.AP","categories":"stat.AP,cs.LG","published":"2025-04-21T08:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.14940v1","title":"Gigaparsec structures are nowhere to be seen in $Î›$CDM: an\n  enhanced analysis of LSS in FLAMINGO-10K simulations","summary":"Recently, Sawala et al. 2025 claimed to refute the cosmological significance\nof the Giant Arc based on their analysis of the FLAMINGO-10K simulation data.\nIn our paper here, we highlight several shortcomings of the authors' analysis.\nWe then perform an enhanced analysis on the FLAMINGO-10K simulation data with\napplications of: the Single-Linkage Hierarchical Clustering (SLHC), the Convex\nHull of Member Spheres (CHMS), and the Minimal Spanning Tree (MST) algorithms.\nUsing the full $2.8^3$ Gpc$^3$ FLAMINGO-10K box, with subhaloes at $z=0.7$, and\n$100$ random realisations (from random subset selections) we find no gigaparsec\nstructures in FLAMINGO-10K, and only a few ultra-large large-scale structures\n(uLSSs, structures exceeding a maximum pairwise separation of $370$ Mpc).\nSomewhat surprisingly, we found that the large-scale aspects of the\nFLAMINGO-10K data could be adequately represented by a Poisson point\ndistribution. The enhanced analysis presented here further supports the\nremarkable nature of the Giant Arc as a cosmologically-significant structure.\nOf course, the Giant Arc is also accompanied by a second uLSS, the Big Ring.\nThe analysis presented here builds on the work presented by Sawala et al., but\namends the application of their statistical assessments. We do not yet know why\nthere appears to be such a large discrepancy between the FLAMINGO-10K data and\nthe observed LSS in MgII absorbers. Perhaps the results presented here might\nsuggest that the GA, and especially the GA + BR, presents a more direct\nchallenge to $\\Lambda$CDM. In contrast to the conclusion of Sawala et al. that\n`gigaparsec patterns abound in a $\\Lambda$CDM universe' we find that they are\nnowhere to be seen.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T08:02:11Z"}
{"aid":"http://arxiv.org/abs/2504.14941v1","title":"Vector Embedding, Retrieval-Augmented Generation, CPU-NPU Collaboration,\n  Heterogeneous Computing","summary":"Retrieval-Augmented Generation is a technology that enhances large language\nmodels by integrating information retrieval. In the industry, inference\nservices based on LLMs are highly sensitive to cost-performance ratio,\nprompting the need for improving hardware resource utilization in the inference\nservice. Specifically, vector embedding and retrieval processes take up to 20%\nof the total latency. Therefore, optimizing the utilization of computational\nresources in vector embeddings is crucial for enhancing the cost-performance\nratio of inference processes, which in turn boosts their product\ncompetitiveness.In this paper, we analyze the deployment costs of vector\nembedding technology in inference services, propose a theoretical formula, and\ndetermine through the mathematical expression that increasing the capacity to\nprocess concurrent queries is the key to reducing the deployment costs of\nvector embeddings. Therefore, in this paper, we focus on improving the\nproduct's capability to process concurrent queries. To optimize concurrency\nwithout sacrificing performance, we have designed a queue manager that adeptly\noffloads CPU peak queries. This manager utilizes a linear regression model to\nascertain the optimal queue depths, a critical parameter that significantly\ninfluences the efficacy of the system. We further develop a system named WindVE\nthat uses a CPU-NPU heterogeneous architecture to offload peak concurrent\nqueries, which leverages the performance differences between the two processors\nto effectively manage traffic surges. Through experiments, we compare WindVE to\nthe state-of-the-art vector embedding framework FlagEmbedding, and achieve a\nconcurrency level up to 22.3% higher than the scheme without offloading.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-21T08:02:25Z"}
{"aid":"http://arxiv.org/abs/2504.14949v1","title":"Photoinduced DC Hall current in few-layer black phosphorus with a\n  gate-tunable Floquet gap","summary":"We theoretically explore Floquet engineering in few-layer black phosphorus\n(fBP) under time-periodic driving. Motivated by the ability of circularly\npolarized light to induce nontrivial topological states at Dirac nodes, we\ninvestigate the emergence of a photoinduced DC Hall effect in the Dirac\nsemimetal phase of fBP. Starting from a low-energy continuum model, we derive\nthe effective Floquet Hamiltonian and analytically calculate the Berry\ncurvature, demonstrating the opening of a topological gap. We also perform\nlattice-model calculations incorporating a self-consistent Hartree method to\ncompute Floquet band structures and DC Hall conductivity under a perpendicular\nelectric field. Our results reveal that the DC Hall current in fBP can be\neffectively tuned via a periodic driving field and electrostatic gating.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-21T08:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.14960v1","title":"MoE Parallel Folding: Heterogeneous Parallelism Mappings for Efficient\n  Large-Scale MoE Model Training with Megatron Core","summary":"Mixture of Experts (MoE) models enhance neural network scalability by\ndynamically selecting relevant experts per input token, enabling larger model\nsizes while maintaining manageable computation costs. However, efficient\ntraining of large-scale MoE models across thousands of GPUs presents\nsignificant challenges due to limitations in existing parallelism strategies.\nWe introduce an end-to-end training framework for large-scale MoE models that\nutilizes five-dimensional hybrid parallelism: Tensor Parallelism, Expert\nParallelism, Context Parallelism, Data Parallelism, and Pipeline Parallelism.\nCentral to our approach is MoE Parallel Folding, a novel strategy that\ndecouples the parallelization of attention and MoE layers in Transformer\nmodels, allowing each layer type to adopt optimal parallel configurations.\nAdditionally, we develop a flexible token-level dispatcher that supports both\ntoken-dropping and token-dropless MoE training across all five dimensions of\nparallelism. This dispatcher accommodates dynamic tensor shapes and coordinates\ndifferent parallelism schemes for Attention and MoE layers, facilitating\ncomplex parallelism implementations. Our experiments demonstrate significant\nimprovements in training efficiency and scalability. We achieve up to 49.3%\nModel Flops Utilization (MFU) for the Mixtral 8x22B model and 39.0% MFU for the\nQwen2-57B-A14B model on H100 GPUs, outperforming existing methods. The\nframework scales efficiently up to 1,024 GPUs and maintains high performance\nwith sequence lengths up to 128K tokens, validating its effectiveness for\nlarge-scale MoE model training. The code is available in Megatron-Core.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-21T08:39:47Z"}
{"aid":"http://arxiv.org/abs/2504.14974v1","title":"Nonreciprocal photon blockade induced by parametric amplification in an\n  asymmetrical cavity","summary":"We propose a scheme to generate and manipulate nonreciprocal photon blockade\neffect in an asymmetrical Fabry-P\\'{e}rot cavity, which consists of a single\ntwo-level atom and a second-order nonlinear medium. By utilizing the intrinsic\nspatial asymmetry of cavity and applying a parametric amplification pumping\nlaser to the nonlinear medium, we can realize direction-dependent single-photon\nand two-photon blockade effects. For nonreciprocal single-photon blockade, our\nproposal is robust across a wide range of parameters, such as the cavity or\natomic detuning, coupling strength, and atomic decay. Within similar parameter\nranges, nonreciprocal two-photon blockade can be achieved and modulated by\nfinely adjusting the parametric amplification pumping. Our project offers a\nfeasible access to generating high-quality and tunable nonreciprocal\nsingle/two-photon source and paves a new avenue for investigating the\nnonreciprocity of photon quantum statistical properties.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T09:00:37Z"}
{"aid":"http://arxiv.org/abs/2504.14977v1","title":"RealisDance-DiT: Simple yet Strong Baseline towards Controllable\n  Character Animation in the Wild","summary":"Controllable character animation remains a challenging problem, particularly\nin handling rare poses, stylized characters, character-object interactions,\ncomplex illumination, and dynamic scenes. To tackle these issues, prior work\nhas largely focused on injecting pose and appearance guidance via elaborate\nbypass networks, but often struggles to generalize to open-world scenarios. In\nthis paper, we propose a new perspective that, as long as the foundation model\nis powerful enough, straightforward model modifications with flexible\nfine-tuning strategies can largely address the above challenges, taking a step\ntowards controllable character animation in the wild. Specifically, we\nintroduce RealisDance-DiT, built upon the Wan-2.1 video foundation model. Our\nsufficient analysis reveals that the widely adopted Reference Net design is\nsuboptimal for large-scale DiT models. Instead, we demonstrate that minimal\nmodifications to the foundation model architecture yield a surprisingly strong\nbaseline. We further propose the low-noise warmup and \"large batches and small\niterations\" strategies to accelerate model convergence during fine-tuning while\nmaximally preserving the priors of the foundation model. In addition, we\nintroduce a new test dataset that captures diverse real-world challenges,\ncomplementing existing benchmarks such as TikTok dataset and UBC fashion video\ndataset, to comprehensively evaluate the proposed method. Extensive experiments\nshow that RealisDance-DiT outperforms existing methods by a large margin.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T09:09:21Z"}
{"aid":"http://arxiv.org/abs/2504.14979v1","title":"Identify hadron anomalous couplings at colliders","summary":"We investigate the identification of the Wess-Zumino-Witten (WZW) Lagrangian\nat colliders such as BESIII and the Super-$\\tau$-Charm Facility. Our analysis\nconcentrates on the radiative decays of $\\eta$ and $\\eta'$ mesons, including\n$\\eta^{(\\prime)} \\to \\gamma\\gamma$, $\\eta^{(\\prime)} \\to \\gamma\\ell^+ \\ell^-$,\n$\\eta^{(\\prime)} \\to \\pi^+\\pi^-\\gamma$, and $\\eta^{(\\prime)} \\to\n\\pi^+\\pi^-\\ell^+\\ell^-$, as well as semileptonic kaon decays such as $K^+ \\to\n\\pi^+\\pi^- e^+ \\nu_e$. Employing the hidden local symmetry framework to\nincorporate vector meson contributions, we compute the decay amplitudes and\nform factors. For the decay $\\eta \\to \\pi^+\\pi^-\\gamma$, the box anomaly\ndominates, and we find that the anomalous coupling can be experimentally\ndetermined to percent-level precision at BESIII. In contrast, vector meson\ncontributions are significant in the decay $\\eta' \\to \\pi^+\\pi^-\\gamma$. Using\nexperimental data for $\\eta' \\to \\pi^+\\pi^-\\gamma$, we obtain ${\\cal\nB}_{\\mathrm{box}}^{\\text{exp}} = (1.70 \\pm 0.05)\\%$, which is approximately ten\ntimes larger than previously expected experimentally. We observe good agreement\nbetween our calculated anomalous couplings and experimental results. In kaon\ndecays, WZW terms uniquely contribute to the form factor $H$, which can be\nextracted from parity-conserving decay distributions. While predictions at the\nchiral point closely match experimental values (e.g., $H^+ = -2.31$ versus\n$-2.27 \\pm 0.10$), we find that intermediate vector meson states introduce\nsubstantial corrections, potentially as large as 25%. We strongly advocate for\nrevisiting these experiments to achieve improved precision in form factor\nextractions.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-21T09:14:32Z"}
{"aid":"http://arxiv.org/abs/2504.14989v1","title":"Dynamic Legged Ball Manipulation on Rugged Terrains with Hierarchical\n  Reinforcement Learning","summary":"Advancing the dynamic loco-manipulation capabilities of quadruped robots in\ncomplex terrains is crucial for performing diverse tasks. Specifically, dynamic\nball manipulation in rugged environments presents two key challenges. The first\nis coordinating distinct motion modalities to integrate terrain traversal and\nball control seamlessly. The second is overcoming sparse rewards in end-to-end\ndeep reinforcement learning, which impedes efficient policy convergence. To\naddress these challenges, we propose a hierarchical reinforcement learning\nframework. A high-level policy, informed by proprioceptive data and ball\nposition, adaptively switches between pre-trained low-level skills such as ball\ndribbling and rough terrain navigation. We further propose Dynamic\nSkill-Focused Policy Optimization to suppress gradients from inactive skills\nand enhance critical skill learning. Both simulation and real-world experiments\nvalidate that our methods outperform baseline approaches in dynamic ball\nmanipulation across rugged terrains, highlighting its effectiveness in\nchallenging environments. Videos are on our website: dribble-hrl.github.io.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T09:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.14998v1","title":"Decay of mass for a semilinear heat equation on Heisenberg group","summary":"In this paper, we are concerned with the Cauchy problem for the\nreaction-diffusion equation with time-dependent absorption\n$u_{t}-\\Delta_{\\mathbb{H}}u=- k(t)u^p$ posed on $\\mathbb{H}^n$, driven by the\nHeisenberg Laplacian and supplemented with a nonnegative integrable initial\ndata, where $p>1$, $n\\geq 1$, and $k:(0,\\infty)\\to(0,\\infty)$ is a locally\nintegrable function. We study the large time behavior of non-negative solutions\nand show that the nonlinear term determines the large time asymptotic for\n$p\\leq 1+2/Q,$ while the classical/anomalous diffusion effects win if\n$p>1+{2}/{Q}$, where $Q=2n+2$ is the homogeneous dimension of $\\mathbb{H}^n$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-21T09:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.15003v1","title":"NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and\n  Enhancement: KwaiSR Dataset and Study","summary":"In this work, we build the first benchmark dataset for short-form UGC Image\nSuper-resolution in the wild, termed KwaiSR, intending to advance the research\non developing image super-resolution algorithms for short-form UGC platforms.\nThis dataset is collected from the Kwai Platform, which is composed of two\nparts, i.e., synthetic and wild parts. Among them, the synthetic dataset,\nincluding 1,900 image pairs, is produced by simulating the degradation\nfollowing the distribution of real-world low-quality short-form UGC images,\naiming to provide the ground truth for training and objective comparison in the\nvalidation/testing. The wild dataset contains low-quality images collected\ndirectly from the Kwai Platform, which are filtered using the quality\nassessment method KVQ from the Kwai Platform. As a result, the KwaiSR dataset\ncontains 1800 synthetic image pairs and 1900 wild images, which are divided\ninto training, validation, and testing parts with a ratio of 8:1:1. Based on\nthe KwaiSR dataset, we organize the NTIRE 2025 challenge on a second short-form\nUGC Video quality assessment and enhancement, which attracts lots of\nresearchers to develop the algorithm for it. The results of this competition\nhave revealed that our KwaiSR dataset is pretty challenging for existing Image\nSR methods, which is expected to lead to a new direction in the image\nsuper-resolution field. The dataset can be found from\nhttps://lixinustc.github.io/NTIRE2025-KVQE-KwaSR-KVQ.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T10:04:26Z"}
{"aid":"http://arxiv.org/abs/2504.15005v1","title":"Analytical constraints on gravitational models with a quadratic Weyl\n  tensor","summary":"We set analytical constraints on the parameter space of models of gravity\ncontaining a term quadratic in Weyl curvature $-\\alpha C^2$. In this class of\nmodels, there are four propagating tensorial degrees of freedom, two vector\ndegrees of freedom, and two scalar degrees of freedom, $\\delta_m$ and $\\Phi$,\ncorresponding to gauge invariant perturbations in the matter density and the\ngravitational Bardeen potential, respectively. We consider the era of matter\ndomination, and requiring that growth of perturbations are recovered in the\nscalar sector and classical instabilities are eliminated in the vector and\ntensor sectors, we obtain bounds on the free coupling parameter to the\nquadratic Weyl curvature term, $10^{14}H^2_0 \\lesssim \\alpha^{-1} \\ll\nM^2_{\\text{cutoff}}$, where $M_{\\text{cutoff}}$ is the cutoff scale of the low\nenergy effective field theory, and $\\alpha^{-1}$ is proportional to the masses\nof the additional propagating degrees of freedom.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-21T10:11:40Z"}
{"aid":"http://arxiv.org/abs/2504.15009v1","title":"Insert Anything: Image Insertion via In-Context Editing in DiT","summary":"This work presents Insert Anything, a unified framework for reference-based\nimage insertion that seamlessly integrates objects from reference images into\ntarget scenes under flexible, user-specified control guidance. Instead of\ntraining separate models for individual tasks, our approach is trained once on\nour new AnyInsertion dataset--comprising 120K prompt-image pairs covering\ndiverse tasks such as person, object, and garment insertion--and effortlessly\ngeneralizes to a wide range of insertion scenarios. Such a challenging setting\nrequires capturing both identity features and fine-grained details, while\nallowing versatile local adaptations in style, color, and texture. To this end,\nwe propose to leverage the multimodal attention of the Diffusion Transformer\n(DiT) to support both mask- and text-guided editing. Furthermore, we introduce\nan in-context editing mechanism that treats the reference image as contextual\ninformation, employing two prompting strategies to harmonize the inserted\nelements with the target scene while faithfully preserving their distinctive\nfeatures. Extensive experiments on AnyInsertion, DreamBooth, and VTON-HD\nbenchmarks demonstrate that our method consistently outperforms existing\nalternatives, underscoring its great potential in real-world applications such\nas creative content generation, virtual try-on, and scene composition.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T10:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.15033v1","title":"Blinding the Wiretapper: RIS-Enabled User Occultation in the ISAC Era","summary":"An undesirable consequence of the foreseeable proliferation of sophisticated\nintegrated sensing and communications (ISAC) technologies is the enabling of\nspoofing, by malicious agents, of situational information (such as proximity,\ndirection or location) of legitimate users of wireless systems. In order to\nmitigate this threat, we present a novel ISAC scheme that, aided by a\nreconfigurable intelligent surface (RIS), enables the occultation of the\npositions of user equipment (UE) from wiretappers, while maintaining both\nsensing and desired communication performance between the UEs and a legitimate\nbase station (BS). To that end, we first formulate an RIS phase-shift\noptimization problem that jointly maximizes the sum-rate performance of the UEs\n(communication objective), while minimizing the projection of the wiretapper's\neffective channel onto the legitimate channel (hiding objective), thereby\ndisrupting the attempts by a wiretapper of localizing the UEs. Then, in order\nto efficiently solve the resulting non-convex joint optimization problem, a\nnovel manifold optimization algorithm is derived, whose effectiveness is\nvalidated by numerical results, which demonstrate that the proposed approach\npreserves legitimate ISAC performance while significantly degrading the\nwiretapper's sensing capability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T11:41:28Z"}
{"aid":"http://arxiv.org/abs/2504.15034v1","title":"Predicting Methane Adsorption in Metal-Substituted MOFs: A Comparative\n  Study between Density Functional Theory and Machine Learning","summary":"Metal-organic frameworks (MOFs) are promising materials for methane capture\ndue to their high surface area and tunable properties. Metal substitution\nrepresents a powerful strategy to enhance MOF performance, yet systematic\nexploration of the vast chemical space remains challenging. In this work, we\ncompare density functional theory (DFT) and machine learning (ML) in predicting\nmethane adsorption properties in metal-substituted variants of three\nhigh-performing MOFs: M-HKUST-1, M-ATC, and M-ZIF-8 (M = Cu, Zn). DFT\ncalculations reveal significant differences in methane binding energetics\nbetween Cu and Zn variants of all three MOFs. On the other hand, we fine-tuned\na pretrained multimodal ML model, PMTransformer, on a curated subset of\nhypothetical MOF (hMOF) structures to predict macroscopic adsorption\nproperties. While the model qualitatively predicts adsorption properties for\nthe original unaltered MOFs, it fails to distinguish between metal variants\ndespite their different binding energetics identified by DFT. We trace this\nlimitation to the hMOF training data generated using Grand Canonical Monte\nCarlo (GCMC) simulations based on classical force fields (UFF/TraPPE). Our\nstudy highlights a key challenge in ML-based MOF screening: ML models inherit\nthe limitations of their training data, particularly when electronic effects\nsignificantly impact adsorption behavior. Our findings emphasize the need for\nimproved force fields or hybrid GCMC/DFT datasets to incorporate both geometric\nand electronic factors for accurate prediction of adsorption properties in\nmetal-substituted MOFs.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.chem-ph","published":"2025-04-21T11:41:32Z"}
{"aid":"http://arxiv.org/abs/2504.15035v1","title":"SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank\n  Adaptation","summary":"The accelerated advancement of speech generative models has given rise to\nsecurity issues, including model infringement and unauthorized abuse of\ncontent. Although existing generative watermarking techniques have proposed\ncorresponding solutions, most methods require substantial computational\noverhead and training costs. In addition, some methods have limitations in\nrobustness when handling variable-length inputs. To tackle these challenges, we\npropose \\textsc{SOLIDO}, a novel generative watermarking method that integrates\nparameter-efficient fine-tuning with speech watermarking through low-rank\nadaptation (LoRA) for speech diffusion models. Concretely, the watermark\nencoder converts the watermark to align with the input of diffusion models. To\nachieve precise watermark extraction from variable-length inputs, the watermark\ndecoder based on depthwise separable convolution is designed for watermark\nrecovery. To further enhance speech generation performance and watermark\nextraction capability, we propose a speech-driven lightweight fine-tuning\nstrategy, which reduces computational overhead through LoRA. Comprehensive\nexperiments demonstrate that the proposed method ensures high-fidelity\nwatermarked speech even at a large capacity of 2000 bps. Furthermore, against\ncommon individual and compound speech attacks, our SOLIDO achieves a maximum\naverage extraction accuracy of 99.20\\% and 98.43\\%, respectively. It surpasses\nother state-of-the-art methods by nearly 23\\% in resisting time-stretching\nattacks.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.SD","published":"2025-04-21T11:43:36Z"}
{"aid":"http://arxiv.org/abs/2504.15036v1","title":"Dynamic Robustness Verification Against Weak Memory (Extended Version)","summary":"Dynamic race detection is a highly effective runtime verification technique\nfor identifying data races by instrumenting and monitoring concurrent program\nruns. However, standard dynamic race detection is incompatible with practical\nweak memory models; the added instrumentation introduces extra synchronization,\nwhich masks weakly consistent behaviors and inherently misses certain data\nraces. In response, we propose to dynamically verify program robustness-a\nproperty ensuring that a program exhibits only strongly consistent behaviors.\nBuilding on an existing static decision procedures, we develop an algorithm for\ndynamic robustness verification under a C11-style memory model. The algorithm\nis based on \"location clocks\", a variant of vector clocks used in standard race\ndetection. It allows effective and easy-to-apply defense against weak memory on\na per-program basis, which can be combined with race detection that assumes\nstrong consistency. We implement our algorithm in a tool, called RSAN, and\nevaluate it across various settings. To our knowledge, this work is the first\nto propose and develop dynamic verification of robustness against weak memory\nmodels.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-21T11:44:58Z"}
{"aid":"http://arxiv.org/abs/2504.15043v1","title":"Energy-Efficient UAV-Mounted RIS for IoT: A Hybrid Energy Harvesting and\n  DRL Approach","summary":"Many future Internet of Things (IoT) applications are expected to rely\nheavily on reconfigurable intelligent surface (RIS)-aided unmanned aerial\nvehicles (UAVs). However, the endurance of such systems is constrained by the\nlimited onboard energy, where frequent recharging or battery replacements are\nrequired. This consequently disrupts continuous operation and may be\nimpractical in disaster scenarios. To address this challenge, we explore a dual\nenergy harvesting (EH) framework that integrates time-switching (TS),\npower-splitting (PS), and element-splitting (ES) EH protocols for radio\nfrequency energy, along with solar energy as a renewable source. First, we\npresent the proposed system architecture and EH operating protocols,\nintroducing the proposed hybrid ES-TS-PS EH strategy to extend UAV-mounted RIS\nendurance. Next, we outline key application scenarios and the associated design\nchallenges. After that, a deep reinforcement learning-based framework is\nintroduced to maximize the EH efficiency by jointly optimizing UAV trajectory,\nRIS phase shifts, and EH strategies. The framework considers dual EH, hardware\nimpairments, and channel state information imperfections to reflect real-world\ndeployment conditions. The optimization problem is formulated as a Markov\ndecision process and solved using an enhanced deep deterministic policy\ngradient algorithm, incorporating clipped double Q-learning and softmax-based\nQ-value estimation for improved stability and efficiency. The results\ndemonstrate significant performance gains compared to the considered baseline\napproaches. Finally, possible challenges and open research directions are\npresented, highlighting the transformative potential of energy-efficient\nUAV-mounted RIS networks for IoT systems.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T11:54:40Z"}
{"aid":"http://arxiv.org/abs/2504.15045v1","title":"Period-luminosity and period-luminosity-metallicity relation for\n  $Î´$ Scuti Stars","summary":"$\\delta$ Scuti ($\\delta$ Sct) stars are potential distance tracers for\nstudying the Milky Way structure. We conduct a comprehensive analysis of the\nperiod-luminosity (PL) and period-luminosity-metallicity (PLZ) relation for\n$\\delta$ Sct stars, integrating data from the Zwicky Transient Facility (ZTF),\nthe Transiting Exoplanet Survey Satellite (TESS), Large Sky Area Multi-Object\nFiber Spectroscopic Telescope (LAMOST), Apache Point Observatory Galactic\nEvolution Experiment (APOGEE), and Gaia. To mitigate the impact of the Gaia\nparallax zero point offset, we applied a correction method, determining the\noptimal zero point value to be $zp_\\varpi = 35 \\pm 2 \\, \\mu\\text{as}$. Using\nthe three best bands, by varying the parallax error threshold, we found that\nthe total error of the PLR zero point was minimized to 0.9\\% at a parallax\nerror threshold of 6\\%. With this threshold, we derived the PL and PLZ relation\nfor nine bands (from optical to mid-infrared) and five Wesenheit bands. Through\nour analysis, we conclude that the influence of metallicity on the PLR of\n$\\delta$ Sct stars is not significant, and the differences across various bands\nare minimal.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-21T11:57:12Z"}
{"aid":"http://arxiv.org/abs/2504.15049v1","title":"ScanEdit: Hierarchically-Guided Functional 3D Scan Editing","summary":"With the fast pace of 3D capture technology and resulting abundance of 3D\ndata, effective 3D scene editing becomes essential for a variety of graphics\napplications. In this work we present ScanEdit, an instruction-driven method\nfor functional editing of complex, real-world 3D scans. To model large and\ninterdependent sets of ob- jectswe propose a hierarchically-guided approach.\nGiven a 3D scan decomposed into its object instances, we first construct a\nhierarchical scene graph representation to enable effective, tractable editing.\nWe then leverage reason- ing capabilities of Large Language Models (LLMs) and\ntranslate high-level language instructions into actionable commands applied\nhierarchically to the scene graph. Fi- nally, ScanEdit integrates LLM-based\nguidance with ex- plicit physical constraints and generates realistic scenes\nwhere object arrangements obey both physics and common sense. In our extensive\nexperimental evaluation ScanEdit outperforms state of the art and demonstrates\nexcellent re- sults for a variety of real-world scenes and input instruc-\ntions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T12:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.15051v1","title":"VeLU: Variance-enhanced Learning Unit for Deep Neural Networks","summary":"Activation functions are fundamental in deep neural networks and directly\nimpact gradient flow, optimization stability, and generalization. Although ReLU\nremains standard because of its simplicity, it suffers from vanishing gradients\nand lacks adaptability. Alternatives like Swish and GELU introduce smooth\ntransitions, but fail to dynamically adjust to input statistics. We propose\nVeLU, a Variance-enhanced Learning Unit as an activation function that\ndynamically scales based on input variance by integrating ArcTan-Sin\ntransformations and Wasserstein-2 regularization, effectively mitigating\ncovariate shifts and stabilizing optimization. Extensive experiments on\nViT_B16, VGG19, ResNet50, DenseNet121, MobileNetV2, and EfficientNetB3 confirm\nVeLU's superiority over ReLU, ReLU6, Swish, and GELU on six vision benchmarks.\nThe codes of VeLU are publicly available on GitHub.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-21T12:20:46Z"}
{"aid":"http://arxiv.org/abs/2504.15060v1","title":"Flexible polyhedral nets in isotropic geometry","summary":"We study flexible polyhedral nets in isotropic geometry. This geometry has a\ndegenerate metric, but there is a natural notion of flexibility. We study\ninfinitesimal and finite flexibility, and classify all finitely flexible\npolyhedral nets of arbitrary size. We show that there are just two classes, in\ncontrast to Izmestiev's rather involved classification in Euclidean geometry,\nfor size 3x3 only. Using these nets to initialize the optimization algorithms,\nwe turn them into approximate Euclidean mechanisms. We also explore the smooth\nversions of these classes.","main_category":"math.MG","categories":"math.MG","published":"2025-04-21T12:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.15065v1","title":"On the behavior of orbits of Vanhaecke system on integral surfaces","summary":"In the 1990s, P. Vanhecke described a Hamiltonian system with two degrees of\nfreedom and a polynomial Hamiltonian integrable in Abelian functions of two\nvariables. This system provides a convenient example of an integrable system in\nwhich integral curves are wound on a two-dimensional manifold, an algebraic\nsurface in a 4-dimensional phase space. In this report, we show that all\nnecessary calculations can be performed in the Sage system. The role of periods\nof Abelian integrals and their commensurability in describing the nature of the\nwinding of integral curves on an algebraic integral surface is discussed. The\nresults of numerical experiments performed in fdm for Sage are presented.","main_category":"nlin.SI","categories":"nlin.SI,math.CA","published":"2025-04-21T12:51:05Z"}
{"aid":"http://arxiv.org/abs/2504.15082v1","title":"An island-parallel ensemble metaheuristic algorithm for large graph\n  coloring problems","summary":"Graph Coloring Problem (GCP) is an NP-Hard vertex labeling problem in graphs\nsuch that no two adjacent vertices can have the same color. Large instances of\nGCP cannot be solved in reasonable execution times by exact algorithms.\nTherefore, soft computing approaches, such as metaheuristics, have proven to be\nvery efficient for solving large instances of GCP. In this study, we propose a\nnew island-parallel ensemble metaheuristic algorithm (PEM-Color) to solve large\nGCP instances. Ensemble learning is a new machine learning approach based on\ncombining the output of multiple models instead of using a single one. We use\nMessage Passing Interface (MPI) parallel computation libraries to combine\nrecent state-of-the-art metaheuristics: Harris Hawk Optimization (HHO),\nArtificial Bee Colony (ABC), and Teaching Learning Based (TLBO) to improve the\nquality of their solutions further. To the best of our knowledge, this is the\nfirst study that combines metaheuristics and applies to the GCP using an\nensemble approach. We conducted experiments on large graph instances from the\nwell-known DIMACS benchmark using 64 processors and achieved significant\nimprovements in execution times. The experiments also indicate an almost linear\nspeed-up with a strong scalability potential. The solution quality of the\ninstances is promising, as our algorithm outperforms 13 state-of-the-art\nalgorithms.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-21T13:15:23Z"}
{"aid":"http://arxiv.org/abs/2504.15084v1","title":"Reconfiguration and Real-Time Operation of Networked Microgrids Under\n  Load Uncertainty","summary":"Distribution networks are increasingly exposed to threats such as extreme\nweather, aging infrastructure, and cyber risks--resulting in more frequent\ncontingencies and outages, a trend likely to persist. Microgrids, particularly\ndynamic networked microgrids (DNMGs), offer a promising solution to mitigate\nthe impacts of such contingencies and enhance resiliency. However, distribution\nnetworks present unique challenges due to their unbalanced nature and the\ninherent uncertainty in both loads and generation. This paper builds upon our\nprior work on the two-stage mixed-integer robust optimization problem for\nconfiguring DNMGs, improving the solve time and scalability. Furthermore, we\nintroduce a model-free, real-time optimal power flow algorithm to manage DNMG\noperations in the time between reconfigurations. A case study on a realistic\nnetwork based on part of the San Francisco Bay Area demonstrates the\nscalability of both approaches. The case study also illustrates the ability to\nmaintain power flow feasibility as loads vary and operating conditions change\nwhen the methods are used in tandem.","main_category":"math.OC","categories":"math.OC","published":"2025-04-21T13:16:28Z"}
{"aid":"http://arxiv.org/abs/2504.15086v1","title":"Configuration Requirements for 21-cm Forest Background Quasar Searches\n  with the Moon-based Interferometer","summary":"The 21-cm forest offers a powerful cosmological probe of the thermal history\nand small-scale structure of the intergalactic medium during the Epoch of\nReionization (EoR). Its success, however, critically depends on the\navailability of high-redshift radio-loud quasars (HzRLQs) as background\nsources. In this work, we investigate the configuration requirements for a\nMoon-based low-frequency radio interferometer aimed at maximizing the detection\nof HzRLQs for future 21-cm forest studies. Building upon a previously developed\nquasar luminosity function (QLF), we forecast HzRLQ abundances under various\narray configurations. Assuming a total survey area of $10^4\\,\\mathrm{deg}^2$\nand 1 year of observation, we compare continuum surveys with 10 MHz bandwidth\nand 21-cm forest surveys with 5 kHz resolution. Our results show that a minimum\ncollecting area of $\\sim$6 500 m$^2$ enables detection at $z \\sim 6$, while\nSKA-like arrays ($N_{\\mathrm{st}} = 512$) extend the detection limit to $z \\sim\n10$ for 21-cm forest survey and $z \\sim 16$ for continuum survey. Larger arrays\nwith $N_{\\mathrm{st}} = 2048$ can reach $z \\sim 11$ in 21-cm forest mode. We\nalso explore configurations that maintain fixed collecting areas while\nincreasing the number to enhance survey efficiency. This boosts source\ndetection but significantly increases the data volume and computational\ndemands. These results underscore the importance of optimizing array design for\ndifferent survey goals and balancing sensitivity, spectral resolution, and data\nmanagement. A well-designed Moon-based array could open a new observational\nwindow on reionization and early cosmic structure formation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-21T13:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.15088v1","title":"Safety Co-Option and Compromised National Security: The Self-Fulfilling\n  Prophecy of Weakened AI Risk Thresholds","summary":"Risk thresholds provide a measure of the level of risk exposure that a\nsociety or individual is willing to withstand, ultimately shaping how we\ndetermine the safety of technological systems. Against the backdrop of the Cold\nWar, the first risk analyses, such as those devised for nuclear systems,\ncemented societally accepted risk thresholds against which safety-critical and\ndefense systems are now evaluated. But today, the appropriate risk tolerances\nfor AI systems have yet to be agreed on by global governing efforts, despite\nthe need for democratic deliberation regarding the acceptable levels of harm to\nhuman life. Absent such AI risk thresholds, AI technologists-primarily industry\nlabs, as well as \"AI safety\" focused organizations-have instead advocated for\nrisk tolerances skewed by a purported AI arms race and speculative\n\"existential\" risks, taking over the arbitration of risk determinations with\nlife-or-death consequences, subverting democratic processes.\n  In this paper, we demonstrate how such approaches have allowed AI\ntechnologists to engage in \"safety revisionism,\" substituting traditional\nsafety methods and terminology with ill-defined alternatives that vie for the\naccelerated adoption of military AI uses at the cost of lowered safety and\nsecurity thresholds. We explore how the current trajectory for AI risk\ndetermination and evaluation for foundation model use within national security\nis poised for a race to the bottom, to the detriment of the US's national\nsecurity interests. Safety-critical and defense systems must comply with\nassurance frameworks that are aligned with established risk thresholds, and\nfoundation models are no exception. As such, development of evaluation\nframeworks for AI-based military systems must preserve the safety and security\nof US critical and defense infrastructure, and remain in alignment with\ninternational humanitarian law.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-21T13:20:56Z"}
{"aid":"http://arxiv.org/abs/2504.15090v1","title":"Federated Latent Factor Model for Bias-Aware Recommendation with\n  Privacy-Preserving","summary":"A recommender system (RS) aims to provide users with personalized item\nrecommendations, enhancing their overall experience. Traditional RSs collect\nand process all user data on a central server. However, this centralized\napproach raises significant privacy concerns, as it increases the risk of data\nbreaches and privacy leakages, which are becoming increasingly unacceptable to\nprivacy-sensitive users. To address these privacy challenges, federated\nlearning has been integrated into RSs, ensuring that user data remains secure.\nIn centralized RSs, the issue of rating bias is effectively addressed by\njointly analyzing all users' raw interaction data. However, this becomes a\nsignificant challenge in federated RSs, as raw data is no longer accessible due\nto privacy-preserving constraints. To overcome this problem, we propose a\nFederated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is\nexplicitly incorporated into every local model's loss function, allowing for\nthe effective elimination of rating bias without compromising data privacy.\nExtensive experiments conducted on three real-world datasets demonstrate that\nFBALF achieves significantly higher recommendation accuracy compared to other\nstate-of-the-art federated RSs.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T13:24:30Z"}
{"aid":"http://arxiv.org/abs/2504.15091v1","title":"Wireless energy transfer in non-Hermitian quantum battery","summary":"The extraction of energy is one of fundamental challenges in realizing\nquantum batteries (QBs). Here, we propose two wireless transfer schemes with\nparity-time symmetries to efficiently extract the energy stored in\nnon-Hermitian QBs to consumption centers. For linear cases, the transfer energy\noscillates periodically in the unbroken symmetry region and grows\nhyperbolically in the broken region. For nonlinear cases, the transfer energy\neventually reach and remain steady-state values arising from the feedback\nmechanism of the nonlinear saturable gain. Furthermore, we show the significant\nrobustness and the ultrafast response of the wireless transfer schemes to\nsudden movements around one metre. Our work overcomes energy bottlenecks for\nwireless transfer schemes in QBs and may provide inspirations for practical\napplications of QBs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T13:24:31Z"}
{"aid":"http://arxiv.org/abs/2504.15110v1","title":"Kolmogorov-Arnold Networks: Approximation and Learning Guarantees for\n  Functions and their Derivatives","summary":"Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold\nNetworks (KANs) have recently emerged as an improved backbone for most deep\nlearning frameworks, promising more adaptivity than their multilayer perception\n(MLP) predecessor by allowing for trainable spline-based activation functions.\nIn this paper, we probe the theoretical foundations of the KAN architecture by\nshowing that it can optimally approximate any Besov function in\n$B^{s}_{p,q}(\\mathcal{X})$ on a bounded open, or even fractal, domain\n$\\mathcal{X}$ in $\\mathbb{R}^d$ at the optimal approximation rate with respect\nto any weaker Besov norm $B^{\\alpha}_{p,q}(\\mathcal{X})$; where $\\alpha < s$.\nWe complement our approximation guarantee with a dimension-free estimate on the\nsample complexity of a residual KAN model when learning a function of Besov\nregularity from $N$ i.i.d. noiseless samples. Our KAN architecture incorporates\ncontemporary deep learning wisdom by leveraging residual/skip connections\nbetween layers.","main_category":"cs.LG","categories":"cs.LG,cs.NA,cs.NE,math.FA,math.NA,stat.ML","published":"2025-04-21T14:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.15113v1","title":"Adaptive sieving with semismooth Newton proximal augmented Lagrangian\n  algorithm for multi-task Lasso problems","summary":"Multi-task learning enhances model generalization by jointly learning from\nrelated tasks. This paper focuses on the $\\ell_{1,\\infty}$-norm constrained\nmulti-task learning problem, which promotes a shared feature representation\nwhile inducing sparsity in task-specific parameters. We propose an adaptive\nsieving (AS) strategy to efficiently generate a solution path for multi-task\nLasso problems. Each subproblem along the path is solved via an inexact\nsemismooth Newton proximal augmented Lagrangian ({\\sc Ssnpal}) algorithm,\nachieving an asymptotically superlinear convergence rate. By exploiting the\nKarush-Kuhn-Tucker (KKT) conditions and the inherent sparsity of multi-task\nLasso solutions, the {\\sc Ssnpal} algorithm solves a sequence of reduced\nsubproblems with small dimensions. This approach enables our method to scale\neffectively to large problems. Numerical experiments on synthetic and\nreal-world datasets demonstrate the superior efficiency and robustness of our\nalgorithm compared to state-of-the-art solvers.","main_category":"math.OC","categories":"math.OC","published":"2025-04-21T14:06:25Z"}
{"aid":"http://arxiv.org/abs/2504.15114v1","title":"Sensing with Quantum Light: A perspective","summary":"I present my perspective on sensing with quantum light. I summarise the\nmotivations and methodology for identifying quantum enhancements in sensing\nover a classical sensor. In the real world, this enhancement will be a constant\nfactor, and not increase with the size of the quantum probe as is often\nadvertised. I use a limited survey of interferometry, microscopy, and\nspectroscopy to extract the vital challenges that must be faced to realise\ntangible enhancements in sensing with quantum light.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T14:07:57Z"}
{"aid":"http://arxiv.org/abs/2504.15139v1","title":"GIFDL: Generated Image Fluctuation Distortion Learning for Enhancing\n  Steganographic Security","summary":"Minimum distortion steganography is currently the mainstream method for\nmodification-based steganography. A key issue in this method is how to define\nsteganographic distortion. With the rapid development of deep learning\ntechnology, the definition of distortion has evolved from manual design to deep\nlearning design. Concurrently, rapid advancements in image generation have made\ngenerated images viable as cover media. However, existing distortion design\nmethods based on machine learning do not fully leverage the advantages of\ngenerated cover media, resulting in suboptimal security performance. To address\nthis issue, we propose GIFDL (Generated Image Fluctuation Distortion Learning),\na steganographic distortion learning method based on the fluctuations in\ngenerated images. Inspired by the idea of natural steganography, we take a\nseries of highly similar fluctuation images as the input to the steganographic\ndistortion generator and introduce a new GAN training strategy to disguise\nstego images as fluctuation images. Experimental results demonstrate that\nGIFDL, compared with state-of-the-art GAN-based distortion learning methods,\nexhibits superior resistance to steganalysis, increasing the detection error\nrates by an average of 3.30% across three steganalyzers.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-21T14:43:00Z"}
{"aid":"http://arxiv.org/abs/2504.15159v1","title":"Acquire and then Adapt: Squeezing out Text-to-Image Model for Image\n  Restoration","summary":"Recently, pre-trained text-to-image (T2I) models have been extensively\nadopted for real-world image restoration because of their powerful generative\nprior. However, controlling these large models for image restoration usually\nrequires a large number of high-quality images and immense computational\nresources for training, which is costly and not privacy-friendly. In this\npaper, we find that the well-trained large T2I model (i.e., Flux) is able to\nproduce a variety of high-quality images aligned with real-world distributions,\noffering an unlimited supply of training samples to mitigate the above issue.\nSpecifically, we proposed a training data construction pipeline for image\nrestoration, namely FluxGen, which includes unconditional image generation,\nimage selection, and degraded image simulation. A novel light-weighted adapter\n(FluxIR) with squeeze-and-excitation layers is also carefully designed to\ncontrol the large Diffusion Transformer (DiT)-based T2I model so that\nreasonable details can be restored. Experiments demonstrate that our proposed\nmethod enables the Flux model to adapt effectively to real-world image\nrestoration tasks, achieving superior scores and visual quality on both\nsynthetic and real-world degradation datasets - at only about 8.5\\% of the\ntraining cost compared to current approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T15:05:22Z"}
{"aid":"http://arxiv.org/abs/2504.15161v1","title":"A few identities and integrals involving Pochhammer symbol, Jacobi\n  polynomials and hypergeometric function","summary":"In this paper, we find some identities involving Pochhammer symbol (rising\nfactorial) and apply them to find a closed form for some integrals of the\nJacobi polynomials as well as a hypergeometric function multiplied by the\nproduct of Jacobi polynomial and the Beta density that makes this polynomial\nmember of the family of orthogonal polynomials. In other words, we expand a\nhypergeometric function in an orthogonal series of Jacobi polynomials.","main_category":"math.CA","categories":"math.CA","published":"2025-04-21T15:07:38Z"}
{"aid":"http://arxiv.org/abs/2504.15169v1","title":"Improving efficiency and stability for perovskite solar cell with\n  diethylene glycol dimethacrylate modification","summary":"The humidity resistance is the key challenges that hinder the commercial\napplication of perovskite solar cells (PSCs). Herein, we propose an ultra-thin\nacrylate polymer (diethylene glycol dimethacrylate, DGDMA) into perovskite\nfilms to investigate the influence of polymerized networks on stability. The\nmonomer molecules containing acrylate and carbonyl groups were selected, and\nthe effects of the polymerized were quantified with different concentration.\nThe experimental results show that, when the concentration of DGDMA is 1 mg/ml,\nthe PCE increases from 18.06% to 21.82%, which is optimum. The monomer\nmolecules with carbonyl groups polymerize, they can chelate with uncoordinated\nPb2+ in perovskite films to improve the film quality, reduce the surface defect\ndensity to decrease non-radiative recombination, and also significantly enhance\nthe humidity stability of PSCs.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T15:23:51Z"}
{"aid":"http://arxiv.org/abs/2504.15173v1","title":"Poroelastic flow across a permeable interface: a Hamilton's principle\n  approach and its finite element implementation","summary":"We consider fluid flow across a permeable interface within a deformable\nporous medium. We use mixture theory. The mixture's constituents are assumed to\nbe incompressible in their pure form. We use Hamilton's principle to obtain the\ngoverning equations, and we propose a corresponding finite element\nimplementation. The filtration velocity and the pore pressure are allowed to be\ndiscontinuous across the interface while some control of these discontinuities\nis built into the interfacial constitutive behavior. To facilitate the\npractical implementation of the formulation in a finite element scheme, we\nintroduce a Lagrange multiplier field over the interface for the explicit\nenforcement of the jump condition of the balance of mass. Our formulation\nappears to recover some basic results from the literature. The novelty of the\nwork is the formulation of an approach that can accommodate specific\nconstitutive assumptions pertaining to the behavior of the interface that do\nnot necessarily imply the continuity of the filtration velocity and/or of the\npore pressure across it.","main_category":"math.NA","categories":"math.NA,cs.NA,physics.flu-dyn","published":"2025-04-21T15:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.15175v1","title":"Geometric speed limit of state preparation and curved control spaces","summary":"The preparation of quantum many-body systems faces the difficulty that in a\nrealistic scenario only few control parameters of the system may be accessible.\nIn this context, an interesting connection between the energy fluctuations\nduring state preparation and its geometric length as measured by the\nFubini-Study metric was discussed in Bukov et al., \"Geometric Speed Limit of\nAccessible Many-Body State Preparation\", Phys. Rev. X 9, 011034 (2019). An\ninspiring conjecture was put forward lower bounding the energy fluctuations by\nthe minimal geometric length of all accessible state preparation protocols. We\nhere show that the conjecture holds if the accessible parameter space has no\nextrinsic curvature, when embedded into the space of all dynamically accessible\nstates. If the parameter space has extrinsic curvature a weakened version of\nthe conjecture applies. We discuss instructive examples for a qubit system and\nharmonic oscillators.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T15:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.15182v1","title":"Tiger200K: Manually Curated High Visual Quality Video Dataset from UGC\n  Platform","summary":"The recent surge in open-source text-to-video generation models has\nsignificantly energized the research community, yet their dependence on\nproprietary training datasets remains a key constraint. While existing open\ndatasets like Koala-36M employ algorithmic filtering of web-scraped videos from\nearly platforms, they still lack the quality required for fine-tuning advanced\nvideo generation models. We present Tiger200K, a manually curated high visual\nquality video dataset sourced from User-Generated Content (UGC) platforms. By\nprioritizing visual fidelity and aesthetic quality, Tiger200K underscores the\ncritical role of human expertise in data curation, and providing high-quality,\ntemporally consistent video-text pairs for fine-tuning and optimizing video\ngeneration architectures through a simple but effective pipeline including shot\nboundary detection, OCR, border detecting, motion filter and fine bilingual\ncaption. The dataset will undergo ongoing expansion and be released as an\nopen-source initiative to advance research and applications in video generative\nmodels. Project page: https://tinytigerpan.github.io/tiger200k/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T15:44:06Z"}
{"aid":"http://arxiv.org/abs/2504.15188v1","title":"Synergistic Weak-Strong Collaboration by Aligning Preferences","summary":"Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T15:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.15199v1","title":"Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's\n  LLM-CLIP Framework for Image Captioning","summary":"MILS (Multimodal Iterative LLM Solver) is a recently published framework that\nclaims \"LLMs can see and hear without any training\" by leveraging an iterative,\nLLM-CLIP based approach for zero-shot image captioning. While this MILS\napproach demonstrates good performance, our investigation reveals that this\nsuccess comes at a hidden, substantial computational cost due to its expensive\nmulti-step refinement process. In contrast, alternative models such as BLIP-2\nand GPT-4V achieve competitive results through a streamlined, single-pass\napproach. We hypothesize that the significant overhead inherent in MILS's\niterative process may undermine its practical benefits, thereby challenging the\nnarrative that zero-shot performance can be attained without incurring heavy\nresource demands. This work is the first to expose and quantify the trade-offs\nbetween output quality and computational cost in MILS, providing critical\ninsights for the design of more efficient multimodal models.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.PF","published":"2025-04-21T16:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.15222v1","title":"Did DESI DR2 truly reveal dynamical dark energy?","summary":"A fundamental question in cosmology is whether dark energy evolves over time,\na topic that has gained prominence since the discovery of cosmic acceleration.\nRecently, the DESI collaboration has reported increasing evidence for evolving\ndark energy using combinations of cosmic microwave background (CMB), type Ia\nsupernova (SN), and their new measurements of baryon acoustic oscillations\n(BAO). However, our analysis reveals that these combinations are problematic\ndue to clear tensions among the CMB, BAO and SN datasets. Consequently, DESI's\nclaim of dynamical dark energy (DDE) is not robust. A more reliable approach\ninvolves constraining the evolution of dark energy using each dataset\nindependently. Through a statistical comparison for each dataset, on average,\nwe find that DDE is strongly preferred over the $\\Lambda$CDM model. This\nsuggests that DDE likely exists, although its real parameter space remains\nelusive due to weak constraints on the dark energy equation of state and\ninconsistencies among the datasets. Interestingly, when considering DDE, none\nof the individual datasets -- including CMB, DESI DR2, Pantheon+, Union3, and\nDESY5 -- can independently detect cosmic acceleration at a significant level.\nOur findings not only clarify the current understanding of the nature of dark\nenergy but also challenge the established discovery of cosmic acceleration and\nthe long-held notion that dark energy exerts negative pressure. Both individual\nand combined datasets suggest that the ultimate fate of the universe is likely\nto be dominated by matter rather than dark energy.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.HE,gr-qc","published":"2025-04-21T16:50:54Z"}
{"aid":"http://arxiv.org/abs/2504.15229v1","title":"Immersive Teleoperation Framework for Locomanipulation Tasks","summary":"Recent advancements in robotic loco-manipulation have leveraged Virtual\nReality (VR) to enhance the precision and immersiveness of teleoperation\nsystems, significantly outperforming traditional methods reliant on 2D camera\nfeeds and joystick controls. Despite these advancements, challenges remain,\nparticularly concerning user experience across different setups. This paper\nintroduces a novel VR-based teleoperation framework designed for a robotic\nmanipulator integrated onto a mobile platform. Central to our approach is the\napplication of Gaussian splatting, a technique that abstracts the manipulable\nscene into a VR environment, thereby enabling more intuitive and immersive\ninteractions. Users can navigate and manipulate within the virtual scene as if\ninteracting with a real robot, enhancing both the engagement and efficacy of\nteleoperation tasks. An extensive user study validates our approach,\ndemonstrating significant usability and efficiency improvements. Two-thirds\n(66%) of participants completed tasks faster, achieving an average time\nreduction of 43%. Additionally, 93% preferred the Gaussian Splat interface\noverall, with unanimous (100%) recommendations for future use, highlighting\nimprovements in precision, responsiveness, and situational awareness. Finally,\nwe demonstrate the effectiveness of our framework through real-world\nexperiments in two distinct application scenarios, showcasing the practical\ncapabilities and versatility of the Splat-based VR interface.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:00:31Z"}
{"aid":"http://arxiv.org/abs/2504.15230v1","title":"Rydberg Atoms in a Ladder Geometry: Quench Dynamics and Floquet\n  Engineering","summary":"In recent days, Rydberg atom quantum simulator platforms have emerged as\nnovel quantum simulators for physical systems ranging from condensed matter to\nparticle physics. On a fundamental level, these platforms allow for a direct\ntest of our understanding of the emergence of quantum statistical mechanics\nstarting from the laws of quantum dynamics. In this paper, we investigate the\nfate of quantum dynamics in a model of Rydberg atoms arranged in a square\nladder geometry, with a Rabi frequency $2\\Omega$ and a detuning profile which\nis staggered along the longer direction with amplitude $\\Delta$. As the\nstaggering strength $\\Delta$ is tuned from $\\Delta/\\Omega=0\\rightarrow\\infty$,\nthe model exhibits a wide class of dynamical phenomena, ranging from (i)\nquantum many-body scars (QMBS) ($\\Delta/\\Omega \\sim 0,1$), (ii) integrability\ninduced slow dynamics and approximate Krylov fractures ($\\Delta/\\Omega \\gg 1$)\n. Additionally, by leveraging the underlying chiral nature of the spectrum of\nthis model Hamiltonian, it is possible to design Floquet protocols leading to\ndynamical signatures reminiscent of discrete time-crystalline order and exact\nFloquet flat bands. Finally, we study the robustness of these dynamical\nfeatures against imperfections in the implementation of the Floquet protocols,\nlong-range van der Waals interactions and inevitable influences from the\nenvironment in the form of pure dephasing and the finite lifetime of the\nRydberg excited state.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-21T17:00:44Z"}
{"aid":"http://arxiv.org/abs/2504.15236v1","title":"Values in the Wild: Discovering and Analyzing Values in Real-World\n  Language Model Interactions","summary":"AI assistants can impart value judgments that shape people's decisions and\nworldviews, yet little is known empirically about what values these systems\nrely on in practice. To address this, we develop a bottom-up,\nprivacy-preserving method to extract the values (normative considerations\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\nin hundreds of thousands of real-world interactions. We empirically discover\nand taxonomize 3,307 AI values and study how they vary by context. We find that\nClaude expresses many practical and epistemic values, and typically supports\nprosocial human values while resisting values like \"moral nihilism\". While some\nvalues appear consistently across contexts (e.g. \"transparency\"), many are more\nspecialized and context-dependent, reflecting the diversity of human\ninterlocutors and their varied contexts. For example, \"harm prevention\" emerges\nwhen Claude resists users, \"historical accuracy\" when responding to queries\nabout controversial events, \"healthy boundaries\" when asked for relationship\nadvice, and \"human agency\" in technology ethics discussions. By providing the\nfirst large-scale empirical mapping of AI values in deployment, our work\ncreates a foundation for more grounded evaluation and design of values in AI\nsystems.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG","published":"2025-04-21T17:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.15238v1","title":"Swap Monte Carlo for diatomic molecules","summary":"In recent years the Swap Monte Carlo algorithm has led to remarkable progress\nin equilibrating supercooled model liquids at low temperatures. Applications\nhave so far been limited to systems composed of spherical particles, however,\nwhereas most real-world supercooled liquids are molecular. We here introduce a\nsimple size-polydisperse molecular model that allows for efficient thermal\nequilibration \\textit{in silico} with the Swap Monte Carlo method, resulting in\nan estimated speedup of $10^3-10^6$ at moderate polydispersity (5-10 %).\nDespite being polydisperse, the model exhibits little difference between the\nsize-resolved orientational time-autocorrelation functions. Our results\ndemonstrate the possibility of designing molecular models that can be simulated\nclose to the calorimetric glass transition.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-21T17:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.15240v1","title":"Conformalized-KANs: Uncertainty Quantification with Coverage Guarantees\n  for Kolmogorov-Arnold Networks (KANs) in Scientific Machine Learning","summary":"This paper explores uncertainty quantification (UQ) methods in the context of\nKolmogorov-Arnold Networks (KANs). We apply an ensemble approach to KANs to\nobtain a heuristic measure of UQ, enhancing interpretability and robustness in\nmodeling complex functions. Building on this, we introduce Conformalized-KANs,\nwhich integrate conformal prediction, a distribution-free UQ technique, with\nKAN ensembles to generate calibrated prediction intervals with guaranteed\ncoverage. Extensive numerical experiments are conducted to evaluate the\neffectiveness of these methods, focusing particularly on the robustness and\naccuracy of the prediction intervals under various hyperparameter settings. We\nshow that the conformal KAN predictions can be applied to recent extensions of\nKANs, including Finite Basis KANs (FBKANs) and multifideilty KANs (MFKANs). The\nresults demonstrate the potential of our approaches to improve the reliability\nand applicability of KANs in scientific machine learning.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T17:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.15254v1","title":"CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation","summary":"C-to-Rust transpilation is essential for modernizing legacy C code while\nenhancing safety and interoperability with modern Rust ecosystems. However, no\ndataset currently exists for evaluating whether a system can transpile C into\nsafe Rust that passes a set of test cases. We introduce CRUST-Bench, a dataset\nof 100 C repositories, each paired with manually-written interfaces in safe\nRust as well as test cases that can be used to validate correctness of the\ntranspilation. By considering entire repositories rather than isolated\nfunctions, CRUST-Bench captures the challenges of translating complex projects\nwith dependencies across multiple files. The provided Rust interfaces provide\nexplicit specifications that ensure adherence to idiomatic, memory-safe Rust\npatterns, while the accompanying test cases enforce functional correctness. We\nevaluate state-of-the-art large language models (LLMs) on this task and find\nthat safe and idiomatic Rust generation is still a challenging problem for\nvarious state-of-the-art methods and techniques. We also provide insights into\nthe errors LLMs usually make in transpiling code from C to safe Rust. The best\nperforming model, OpenAI o1, is able to solve only 15 tasks in a single-shot\nsetting. Improvements on CRUST-Bench would lead to improved transpilation\nsystems that can reason about complex scenarios and help in migrating legacy\ncodebases from C into languages like Rust that ensure memory safety. You can\nfind the dataset and code at https://github.com/anirudhkhatry/CRUST-bench.","main_category":"cs.SE","categories":"cs.SE,cs.CL","published":"2025-04-21T17:33:33Z"}
{"aid":"http://arxiv.org/abs/2504.15266v1","title":"Roll the dice & look before you leap: Going beyond the creative limits\n  of next-token prediction","summary":"We design a suite of minimal algorithmic tasks that are a loose abstraction\nof open-ended real-world tasks. This allows us to cleanly and controllably\nquantify the creative limits of the present-day language model. Much like\nreal-world tasks that require a creative, far-sighted leap of thought, our\ntasks require an implicit, open-ended stochastic planning step that either (a)\ndiscovers new connections in an abstract knowledge graph (like in wordplay,\ndrawing analogies, or research) or (b) constructs new patterns (like in\ndesigning math problems or new proteins). In these tasks, we empirically and\nconceptually argue how next-token learning is myopic and memorizes excessively;\ncomparatively, multi-token approaches, namely teacherless training and\ndiffusion models, excel in producing diverse and original output. Secondly, in\nour tasks, we find that to elicit randomness from the Transformer without\nhurting coherence, it is better to inject noise right at the input layer (via a\nmethod we dub hash-conditioning) rather than defer to temperature sampling from\nthe output layer. Thus, our work offers a principled, minimal test-bed for\nanalyzing open-ended creative skills, and offers new arguments for going beyond\nnext-token learning and softmax-based sampling. We make part of the code\navailable under https://github.com/chenwu98/algorithmic-creativity","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-21T17:47:46Z"}
{"aid":"http://arxiv.org/abs/2504.15282v1","title":"Multi-Target Rydberg Gates via Spatial Blockade Engineering","summary":"Multi-target gates offer the potential to reduce gate depth in syndrome\nextraction for quantum error correction. Although neutral-atom quantum\ncomputers have demonstrated native multi-qubit gates, existing approaches that\navoid additional control or multiple atomic species have been limited to\nsingle-target gates. We propose single-control-multi-target CZ^{\\otimes N})\ngates on a single-species neutral-atom platform that require no extra control\nand have gate durations comparable to standard CZ gates. Our approach leverages\ntailored interatomic distances to create an asymmetric blockade between the\ncontrol and target atoms. Using a GPU-accelerated pulse synthesis protocol, we\ndesign smooth control pulses for CZZ and CZZZ gates, achieving fidelities of up\nto 99.55% and 99.24%, respectively, even in the presence of simulated atom\nplacement errors and Rydberg-state decay. This work presents a practical path\nto implementing multi-target gates in neutral-atom systems, significantly\nreducing the resource overhead for syndrome extraction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.15554v1","title":"Partition laser assembling technique","summary":"The advancement of micro/nanofabrication techniques with high throughput,\nefficiency, and flexibility is critical for fields like integrated photonics,\nbiosensing, and medical diagnostics. This study presents Partition Laser\nAssembling (PLA), a novel laser technique for fabricating complex\nmicro/nanostructures akin to puzzle pieces. By dividing the target patterns\ndescribed by scalable vector graphics into partitions, any structures in each\npartition can be fabricated via structured lights as \"light stamp\" through\nspatial light modulation. Unlike traditional direct laser writing, PLA\neliminates reliance on mechanical components, avoiding step-like artifacts and\nensuring smoother fabrication of complex micro/nanostructures. By seamlessly\nassembling basic shapes, PLA achieves intricate structures like micro artworks\nand metalenses with unmatched precision and resolution. Leveraging two-photon\nfabrication, PLA guarantees high resolution and structural integrity,\npositioning it as a transformative tool for nanoscale 3D printing. With\napplications spanning research and industry, PLA paves the way for advanced\noptical devices, micro/nanofabrications, and next-gen manufacturing\ntechnologies.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-22T03:18:54Z"}
{"aid":"http://arxiv.org/abs/2504.15563v1","title":"Designing Optimal Distorted-Octahedra Superlattices for Strong\n  Topological Hall Effect","summary":"Topologically protected spin states hold great promise for applications in\nnext generation of memory circuits and spintronic devices. These intriguing\ntextures typically emerge in bulk materials or heterostructures with broken\ninversion symmetry, accompanied by an enhanced Dzyaloshinskii-Moriya\ninteraction (DMI). In this study, we successfully induced the topological Hall\neffect (THE) in atomically designed (DyScO3)n/(SrRuO3)n (DnSn) superlattices\nover a significant range of temperatures (10~120K) and thicknesses (16~40nm).\nUsing magnetic force microscopy (MFM), we observed the formation and stability\nof magnetic domains, such as topological skyrmions. By precisely controlling\nthe interlayer thickness (n) and biaxial strain, we elucidated the mechanisms\nunderlying the modulation and induction of magnetic topological states.\nSupporting evidence was provided by scanning transmission electron microscopy\n(STEM) and X-ray absorption spectroscopy (XAS), thereby lending further\ncredence to our conclusions. These heterostructures offer a universal method\nfor exploring topological phenomena driven by distorted octahedra, while\nenhancing the integrability and addressability of topologically protected\nfunctional devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T03:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.15580v1","title":"On the Price of Differential Privacy for Hierarchical Clustering","summary":"Hierarchical clustering is a fundamental unsupervised machine learning task\nwith the aim of organizing data into a hierarchy of clusters. Many applications\nof hierarchical clustering involve sensitive user information, therefore\nmotivating recent studies on differentially private hierarchical clustering\nunder the rigorous framework of Dasgupta's objective. However, it has been\nshown that any privacy-preserving algorithm under edge-level differential\nprivacy necessarily suffers a large error. To capture practical applications of\nthis problem, we focus on the weight privacy model, where each edge of the\ninput graph is at least unit weight. We present a novel algorithm in the weight\nprivacy model that shows significantly better approximation than known\nimpossibility results in the edge-level DP setting. In particular, our\nalgorithm achieves $O(\\log^{1.5}n/\\varepsilon)$ multiplicative error for\n$\\varepsilon$-DP and runs in polynomial time, where $n$ is the size of the\ninput graph, and the cost is never worse than the optimal additive error in\nexisting work. We complement our algorithm by showing if the unit-weight\nconstraint does not apply, the lower bound for weight-level DP hierarchical\nclustering is essentially the same as the edge-level DP, i.e.\n$\\Omega(n^2/\\varepsilon)$ additive error. As a result, we also obtain a new\nlower bound of $\\tilde{\\Omega}(1/\\varepsilon)$ additive error for balanced\nsparsest cuts in the weight-level DP model, which may be of independent\ninterest. Finally, we evaluate our algorithm on synthetic and real-world\ndatasets. Our experimental results show that our algorithm performs well in\nterms of extra cost and has good scalability to large graphs.","main_category":"cs.DS","categories":"cs.DS,cs.CR,cs.LG","published":"2025-04-22T04:39:40Z"}
{"aid":"http://arxiv.org/abs/2504.15585v1","title":"A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training\n  and Deployment","summary":"The remarkable success of Large Language Models (LLMs) has illuminated a\npromising pathway toward achieving Artificial General Intelligence for both\nacademic and industrial communities, owing to their unprecedented performance\nacross various applications. As LLMs continue to gain prominence in both\nresearch and commercial domains, their security and safety implications have\nbecome a growing concern, not only for researchers and corporations but also\nfor every nation. Currently, existing surveys on LLM safety primarily focus on\nspecific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning\nphase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.\nTo address this gap, this paper introduces, for the first time, the concept of\n\"full-stack\" safety to systematically consider safety issues throughout the\nentire process of LLM training, deployment, and eventual commercialization.\nCompared to the off-the-shelf LLM safety surveys, our work demonstrates several\ndistinctive advantages: (I) Comprehensive Perspective. We define the complete\nLLM lifecycle as encompassing data preparation, pre-training, post-training,\ndeployment and final commercialization. To our knowledge, this represents the\nfirst safety survey to encompass the entire lifecycle of LLMs. (II) Extensive\nLiterature Support. Our research is grounded in an exhaustive review of over\n800+ papers, ensuring comprehensive coverage and systematic organization of\nsecurity issues within a more holistic understanding. (III) Unique Insights.\nThrough systematic literature analysis, we have developed reliable roadmaps and\nperspectives for each chapter. Our work identifies promising research\ndirections, including safety in data generation, alignment techniques, model\nediting, and LLM-based agent systems. These insights provide valuable guidance\nfor researchers pursuing future work in this field.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.CL,cs.LG","published":"2025-04-22T05:02:49Z"}
{"aid":"http://arxiv.org/abs/2504.15586v1","title":"Joint leave-group-out cross-validation in Bayesian spatial models","summary":"Cross-validation (CV) is a widely-used method of predictive assessment based\non repeated model fits to different subsets of the available data. CV is\napplicable in a wide range of statistical settings. However, in cases where\ndata are not exchangeable, the design of CV schemes should account for\nsuspected correlation structures within the data. CV scheme designs include the\nselection of left-out blocks and the choice of scoring function for evaluating\npredictive performance.\n  This paper focuses on the impact of two scoring strategies for block-wise CV\napplied to spatial models with Gaussian covariance structures. We investigate,\nthrough several experiments, whether evaluating the predictive performance of\nblocks of left-out observations jointly, rather than aggregating individual\n(pointwise) predictions, improves model selection performance. Extending recent\nfindings for data with serial correlation (such as time-series data), our\nexperiments suggest that joint scoring reduces the variability of CV estimates,\nleading to more reliable model selection, particularly when spatial dependence\nis strong and model differences are subtle.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-22T05:02:58Z"}
{"aid":"http://arxiv.org/abs/2504.15592v1","title":"Yet Another Diminishing Spark: Low-level Cyberattacks in the Israel-Gaza\n  Conflict","summary":"We report empirical evidence of web defacement and DDoS attacks carried out\nby low-level cybercrime actors in the Israel-Gaza conflict. Our quantitative\nmeasurements indicate an immediate increase in such cyberattacks following the\nHamas-led assault and the subsequent declaration of war. However, the surges\nwaned quickly after a few weeks, with patterns resembling those observed in the\naftermath of the Russian invasion of Ukraine. The scale of attacks and\ndiscussions within the hacking community this time was both significantly lower\nthan those during the early days of the Russia-Ukraine war, and attacks have\nbeen prominently one-sided: many pro-Palestinian supporters have targeted\nIsrael, while attacks on Palestine have been much less significant. Beyond\ntargeting these two, attackers also defaced sites of other countries to express\ntheir war support. Their broader opinions are also largely disparate, with far\nmore support for Palestine and many objections expressed toward Israel.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-22T05:13:54Z"}
{"aid":"http://arxiv.org/abs/2504.15602v1","title":"Mean Curvature Flow for Isoparametric Submanifolds in Hyperbolic Spaces","summary":"Mean curvature flows of isoparametric submanifolds in Euclidean spaces and\nspheres have been studied by Liu and Terng in \\cite{X.CT} and \\cite{X.C}. In\nparticular, it was proved that such flows always have ancient solutions. This\nis also true for mean curvature flows of isoparametric hypersurfaces in\nhyperbolic spaces by a result of Reis and Tenenblat in \\cite{S.H.T}. In this\npaper, we study mean curvature flows of isoparametric submanifolds in\nhyperbolic spaces with arbitrary codimension. In particular, we will show that\nthey always have ancient solutions and study their limiting behaviors.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T05:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.15603v1","title":"Quantum Speedup for Sampling Random Spanning Trees","summary":"We present a quantum algorithm for sampling random spanning trees from a\nweighted graph in $\\widetilde{O}(\\sqrt{mn})$ time, where $n$ and $m$ denote the\nnumber of vertices and edges, respectively. Our algorithm has sublinear runtime\nfor dense graphs and achieves a quantum speedup over the best-known classical\nalgorithm, which runs in $\\widetilde{O}(m)$ time. The approach carefully\ncombines, on one hand, a classical method based on ``large-step'' random walks\nfor reduced mixing time and, on the other hand, quantum algorithmic techniques,\nincluding quantum graph sparsification and a sampling-without-replacement\nvariant of Hamoudi's multiple-state preparation. We also establish a matching\nlower bound, proving the optimality of our algorithm up to polylogarithmic\nfactors. These results highlight the potential of quantum computing in\naccelerating fundamental graph sampling problems.","main_category":"quant-ph","categories":"quant-ph,cs.DS","published":"2025-04-22T05:45:04Z"}
{"aid":"http://arxiv.org/abs/2504.15616v1","title":"SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory\n  Prediction","summary":"The analysis and prediction of agent trajectories are crucial for\ndecision-making processes in intelligent systems, with precise short-term\ntrajectory forecasting being highly significant across a range of applications.\nAgents and their social interactions have been quantified and modeled by\nresearchers from various perspectives; however, substantial limitations exist\nin the current work due to the inherent high uncertainty of agent intentions\nand the complex higher-order influences among neighboring groups. SocialMOIF is\nproposed to tackle these challenges, concentrating on the higher-order\nintention interactions among neighboring groups while reinforcing the primary\nrole of first-order intention interactions between neighbors and the target\nagent. This method develops a multi-order intention fusion model to achieve a\nmore comprehensive understanding of both direct and indirect intention\ninformation. Within SocialMOIF, a trajectory distribution approximator is\ndesigned to guide the trajectories toward values that align more closely with\nthe actual data, thereby enhancing model interpretability. Furthermore, a\nglobal trajectory optimizer is introduced to enable more accurate and efficient\nparallel predictions. By incorporating a novel loss function that accounts for\ndistance and direction during training, experimental results demonstrate that\nthe model outperforms previous state-of-the-art baselines across multiple\nmetrics in both dynamic and static datasets.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-22T06:14:49Z"}
{"aid":"http://arxiv.org/abs/2504.15621v1","title":"Regularization of elliptic multiple zeta values","summary":"In this paper, we show that regularized elliptic multiple zeta values are\ngiven by polynomials in elliptic multiple zeta values with admissible indices\nand special ones whose indices consist of 0 and 1.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T06:24:48Z"}
{"aid":"http://arxiv.org/abs/2504.15640v1","title":"Cost-Effective Text Clustering with Large Language Models","summary":"Text clustering aims to automatically partition a collection of text\ndocuments into distinct clusters based on linguistic features. In the\nliterature, this task is usually framed as metric clustering based on text\nembeddings from pre-trained encoders or a graph clustering problem upon\npairwise similarities from an oracle, e.g., a large ML model. Recently, large\nlanguage models (LLMs) bring significant advancement in this field by offering\ncontextualized text embeddings and highly accurate similarity scores, but\nmeanwhile, present grand challenges to cope with substantial computational\nand/or financial overhead caused by numerous API-based queries or inference\ncalls to the models.\n  In response, this paper proposes TECL, a cost-effective framework that taps\ninto the feedback from LLMs for accurate text clustering within a limited\nbudget of queries to LLMs. Under the hood, TECL adopts our EdgeLLM or\nTriangleLLM to construct must-link/cannot-link constraints for text pairs, and\nfurther leverages such constraints as supervision signals input to our weighted\nconstrained clustering approach to generate clusters. Particularly, EdgeLLM\n(resp. TriangleLLM) enables the identification of informative text pairs (resp.\ntriplets) for querying LLMs via well-thought-out greedy algorithms and accurate\nextraction of pairwise constraints through carefully-crafted prompting\ntechniques. Our experiments on multiple benchmark datasets exhibit that TECL\nconsistently and considerably outperforms existing solutions in unsupervised\ntext clustering under the same query cost for LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T06:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.15646v1","title":"Quantum Corrections and Extremality: A Generalized Universal Relation","summary":"Logarithmic corrections to the entropy of extremal black holes have proven\neffective in precisely matching the microscopic degeneracies obtained from\nstring-theoretic as well as a non-perturbative quantum correction manifests as\nan exponential term in the black hole entropy. In this work, we extend the\nuniversal relation proposed by Goon and Penco by deriving a generalized form\nwhere entropy is not just the Bekenstein-Hawking entropy. Our analysis treats\nentropy as a general function of the horizon radius, and with the help of that,\nwe formulate the generalized universal relation. We show that, in the case of\nBekenstein-Hawking entropy, the generalized relation coincides with the\noriginal universal relation by Goon and Penco. Furthermore, we explore the\nimplications of logarithmic and exponential corrections to entropy and test the\nvalidity of the generalized universal relation under these modifications.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-22T07:12:53Z"}
{"aid":"http://arxiv.org/abs/2504.15658v1","title":"Improved Upper Bound on Brun's Constant Under GRH","summary":"Brun's constant is the summation of the reciprocals of all twin primes, given\nby $B=\\sum_{p \\in P_2}{\\left( \\frac{1}{p} + \\frac{1}{p+2}\\right)}$. In this\npaper, we provide the first rigorous bound on Brun's constant under the GRH\nassumption, resulting in $B < 2.1609$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T07:30:00Z"}
{"aid":"http://arxiv.org/abs/2504.15663v1","title":"FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep\n  Learning","summary":"Recently, fake audio detection has gained significant attention, as\nadvancements in speech synthesis and voice conversion have increased the\nvulnerability of automatic speaker verification (ASV) systems to spoofing\nattacks. A key challenge in this task is generalizing models to detect unseen,\nout-of-distribution (OOD) attacks. Although existing approaches have shown\npromising results, they inherently suffer from overconfidence issues due to the\nusage of softmax for classification, which can produce unreliable predictions\nwhen encountering unpredictable spoofing attempts. To deal with this\nlimitation, we propose a novel framework called fake audio detection with\nevidential learning (FADEL). By modeling class probabilities with a Dirichlet\ndistribution, FADEL incorporates model uncertainty into its predictions,\nthereby leading to more robust performance in OOD scenarios. Experimental\nresults on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets\nindicate that the proposed method significantly improves the performance of\nbaseline models. Furthermore, we demonstrate the validity of uncertainty\nestimation by analyzing a strong correlation between average uncertainty and\nequal error rate (EER) across different spoofing algorithms.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-22T07:40:35Z"}
{"aid":"http://arxiv.org/abs/2504.15664v1","title":"An XAI-based Analysis of Shortcut Learning in Neural Networks","summary":"Machine learning models tend to learn spurious features - features that\nstrongly correlate with target labels but are not causal. Existing approaches\nto mitigate models' dependence on spurious features work in some cases, but\nfail in others. In this paper, we systematically analyze how and where neural\nnetworks encode spurious correlations. We introduce the neuron spurious score,\nan XAI-based diagnostic measure to quantify a neuron's dependence on spurious\nfeatures. We analyze both convolutional neural networks (CNNs) and vision\ntransformers (ViTs) using architecture-specific methods. Our results show that\nspurious features are partially disentangled, but the degree of disentanglement\nvaries across model architectures. Furthermore, we find that the assumptions\nbehind existing mitigation methods are incomplete. Our results lay the\ngroundwork for the development of novel methods to mitigate spurious\ncorrelations and make AI models safer to use in practice.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-22T07:40:45Z"}
{"aid":"http://arxiv.org/abs/2504.15688v1","title":"Subject islands do not reduce to construction-specific discourse\n  function","summary":"The term islands in linguistics refers to phrases from which extracting an\nelement results in ungrammaticality (Ross, 1967). Grammatical subjects are\nconsidered islands because extracting a sub-part of a subject results in an\nill-formed sentence, despite having a clear intended meaning (e.g., \"Which\ntopic did the article about inspire you?\"). The generative tradition, which\nviews syntax as autonomous of meaning and function, attributes this\nungrammaticality to the abstract movement dependency between the wh-phrase and\nthe subject-internal position with which it is associated for interpretation.\nHowever, research on language that emphasizes its communicative function\nsuggests instead that syntactic constraints, including islands, can be\nexplained based on the way different constructions package information.\nAccordingly, Abeill\\'e et al. (2020) suggest that the islandhood of subjects is\nspecific to the information structure of wh-questions, and propose that\nsubjects are not islands for movement, but for focusing, due to their\ndiscourse-backgroundedness. This predicts that other constructions that differ\nin their information structure from wh-questions, but still involve movement,\nshould not create a subject island effect. We test this prediction in three\nlarge-scale acceptability studies, using a super-additive design that singles\nout subject island violations, in three different constructions: wh-questions,\nrelative clauses, and topicalization. We report evidence for a subject island\neffect in each construction type, despite only wh-questions introducing what\nAbeill\\'e et al. (2020) call \"a clash in information structure.\" We argue that\nthis motivates an account of islands in terms of abstract, syntactic\nrepresentations, independent of the communicative function associated with the\nconstructions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T08:13:04Z"}
{"aid":"http://arxiv.org/abs/2504.15702v1","title":"Form factors from string amplitudes","summary":"In this letter, we propose a stringy model for $n$-point tree-level form\nfactor with the off-shell operator in the scalar and gluon theories, from the\nbosonic string disk amplitude: $n$ open string states and $1$ closed string\nstate scatter on the disk. In the field-theory limit ($\\alpha'\\to0$), the\nstringy form factor reduces to the form factor, helps us to investigate the\nhidden properties of the field-theory form factors, manifest the factorization\nand soft behaviors, and uncover more non-trivial relations between form factors\nand scattering amplitudes.","main_category":"hep-th","categories":"hep-th","published":"2025-04-22T08:45:17Z"}
{"aid":"http://arxiv.org/abs/2504.15704v1","title":"On relaxing the N-Reachability Implicit Requirement in NMPC Design","summary":"This paper proposes a proof of stability for Model Predictive Control\nformulations involving a prediction horizon that might be too short to meet the\nreachability condition generally invoked as a sufficient condition for\nclosed-loop stability. This condition is replaced by a contraction condition on\nthe stage cost. But unlike the contraction based existing formulations where\nthe prediction horizon becomes a decision variable, the formulation proposed in\nthis paper remains standard in that it uses constant and short prediction\nhorizon. An illustrative example is provided to assess the relevance of the\nproposed formulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T08:46:23Z"}
{"aid":"http://arxiv.org/abs/2504.15709v1","title":"Backreaction in $f(R,G)$ Gravitational Waves","summary":"We present a comprehensive analysis of gravitational wave dynamics in\n$f(R,G)$ modified gravity, where $R$ is the Ricci scalar and $G$ the\nGauss-Bonnet invariant. By developing a scalar-tensor formulation with two\nauxiliary fields, we systematically investigate both the propagation and\nbackreaction of high-frequency gravitational waves in cosmological backgrounds.\nThe linearized field equations reveal how the Gauss-Bonnet term introduces new\ncurvature-dependent couplings between tensor and scalar degrees of freedom,\nleading to modified dispersion relations and distinctive wave propagation\neffects. On de Sitter backgrounds, we obtain exact decoupled equations for the\ntensor and scalar modes, demonstrating how the additional $G$-dependence alters\nboth the effective masses and energy transport mechanisms compared to pure\n$f(R)$ theories.\n  Our derivation of the effective energy-momentum tensor extends Isaacson's\napproach to incorporate the novel scalar field contributions, revealing a\ncomplex hierarchy of characteristic length scales ($\\lambda$, $\\ell$, and\n$\\mathcal{L}$) that govern the backreaction dynamics. The resulting formalism\nsuggests potentially observable signatures in both the propagation (phase\nshifts, amplitude modulation) and stochastic background of gravitational waves.\nThese effects could be probed by next-generation detectors, offering new\nconstraints on the $f(R,G)$ coupling parameters. The theoretical framework\ndeveloped here provides a foundation for future studies of gravitational wave\ngeneration in modified gravity scenarios and their role in cosmological\nstructure formation.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-22T08:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.15711v1","title":"New limit on the Î¼+->e+Î³decay with the MEG II experiment","summary":"This letter reports the result of the search for the decay \\mu+->e+\\gamma\nundertaken at the Paul Scherrer Institut in Switzerland with the MEG II\nexperiment using the data collected in the 2021- 2022 physics runs. The\nsensitivity of this search is 2.2x10-13, a factor of 2.4 better than that of\nthe full MEG dataset and obtained in a data taking period of about one fourth\nthat of MEG, thanks to the superior performances of the new detector. The\nresult is consistent with the expected background, yielding an upper limit on\nthe branching ratio of B(\\mu+->e+\\gamma)<1.5 x 10-13 (90 % C.L.). Additional\nimprovements are expected with the data collected during the years 2023-2024.\nThe data-taking will continue in the coming years.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-22T08:53:35Z"}
{"aid":"http://arxiv.org/abs/2504.15713v1","title":"Zernike system revisited: imaginary gauge and Higgs oscillator","summary":"We analyze that recently proposed clasical/quantum mechanical interpretation\nof Zernike system and establish its equivalence to the Higgs oscillator on\nsphere or pseudosphere (Lobachevsky plane). We show that the non-reality of the\nclassical Zernike Hamiltonian is an insignificant artifact of imaginary gauge\nand can be eliminated with a canonical transformation. The quantum counterpart\nof this canonical transformation is a similarity transformation mapping the\nsystem to the quantum Higgs oscillator with integration measure depending on\n$\\alpha,\\beta$ parameters. When $\\alpha=2 \\beta$ it results in the Hermitian\nHamiltonian describing a free particle on (pseudo)sphere, while deviation from\nthis point leads to a pseudo-Hermitian system.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,physics.optics","published":"2025-04-22T08:55:07Z"}
{"aid":"http://arxiv.org/abs/2504.15721v1","title":"BBAL: A Bidirectional Block Floating Point-Based Quantisation\n  Accelerator for Large Language Models","summary":"Large language models (LLMs), with their billions of parameters, pose\nsubstantial challenges for deployment on edge devices, straining both memory\ncapacity and computational resources. Block Floating Point (BFP) quantisation\nreduces memory and computational overhead by converting high-overhead floating\npoint operations into low-bit fixed point operations. However, BFP requires\naligning all data to the maximum exponent, which causes loss of small and\nmoderate values, resulting in quantisation error and degradation in the\naccuracy of LLMs. To address this issue, we propose a Bidirectional Block\nFloating Point (BBFP) data format, which reduces the probability of selecting\nthe maximum as shared exponent, thereby reducing quantisation error. By\nutilizing the features in BBFP, we present a full-stack Bidirectional Block\nFloating Point-Based Quantisation Accelerator for LLMs (BBAL), primarily\ncomprising a processing element array based on BBFP, paired with proposed\ncost-effective nonlinear computation unit. Experimental results show BBAL\nachieves a 22% improvement in accuracy compared to an outlier-aware accelerator\nat similar efficiency, and a 40% efficiency improvement over a BFP-based\naccelerator at similar accuracy.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-22T09:11:21Z"}
{"aid":"http://arxiv.org/abs/2504.15730v1","title":"Enhancing Radiation Hardness and Granularity in HV-CMOS: The RD50-MPW4\n  Sensor","summary":"The latest HV-CMOS pixel sensor developed by the former CERN-RD50-CMOS group,\nknown as the \\mpw, demonstrates competitive radiation tolerance, spatial\ngranularity, and timing resolution -- key requirements for future high-energy\nphysics experiments such as the HL-LHC and FCC. Fabricated using a \\SI{150}{nm}\nCMOS process by \\emph{LFoundry}, it introduces several improvements over its\npredecessor, the \\emph{RD50-MPW3}, including separated power domains for\nreduced noise, a new backside biasing scheme, and an enhanced guard ring\nstructure, enabling operation at bias voltages up to \\SI{800}{V}.\n  Tests with non-irradiated samples achieved hit detection efficiencies\nexceeding \\SI{99.9}{\\%} and a spatial resolution around \\SI{16}{\\mu m}.\nNeutron-irradiated sensors were characterized using IV measurements and\ntest-beam campaigns, confirming the sensor's robustness in high-radiation\nenvironments. The results highlight the ability of HV-CMOS technology to\nrestore hit detection efficiency post-irradiation by increasing the applied\nbias voltage. Details of these measurements and timing performance are\npresented in this paper.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-22T09:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.15731v1","title":"Entropy Stabilized ZrHfCoNiSnSb Half-Heusler Alloy for Thermoelectric\n  Applications: A Theoretical Prediction","summary":"Half-Heusler (HH) alloys are potential thermoelectric materials for use at\nelevated temperatures due to their high Seebeck coefficient and superior\nmechanical and thermal stability. However, their enhanced lattice thermal\nconductivity is detrimental to thermoelectric applications. One way to\ncircumvent this problem is to introduce mass disorder at lattice sites by\nmixing the components of two or more alloys. Such systems are typically\nstabilized by the entropy of mixing. In this work, using computational tools,\nwe propose a mixed HH, namely, ZrHfCoNiSnSb, which can be formed by the\nelemental compositions of the parent half-Heuslers ZrNiSn/HfNiSn and\nHfCoSb/ZrCoSb. We propose that this new compound can be synthesized at elevated\ntemperatures, as its Gibbs free energy is reduced due to higher configurational\nentropy, making it more thermodynamically stable than the parent compounds\nunder such conditions. Our calculations indicate that it is a dynamically\nstable semiconductor with a band gap of 0.61 eV. Its lattice thermal\nconductivity at room temperature is $5.39~\\text{Wm}^{-1}\\text{K}^{-1}$, which\nis significantly lower than those of the parent compounds. The peak value of\nthis alloy's figure of merit (ZT) is 1.00 for the n-type carriers at 1100 K,\nwhich is 27% more than the best figure of merit obtained for the parent\ncompounds.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T09:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.15738v1","title":"RRC Signaling Storm Detection in O-RAN","summary":"The Open Radio Access Network (O-RAN) marks a significant shift in the mobile\nnetwork industry. By transforming a traditionally vertically integrated\narchitecture into an open, data-driven one, O-RAN promises to enhance\noperational flexibility and drive innovation. In this paper, we harness O-RAN's\nopenness to address one critical threat to 5G availability: signaling storms\ncaused by abuse of the Radio Resource Control (RRC) protocol. Such attacks\noccur when a flood of RRC messages from one or multiple User Equipments (UEs)\ndeplete resources at a 5G base station (gNB), leading to service degradation.\nWe provide a reference implementation of an RRC signaling storm attack, using\nthe OpenAirInterface (OAI) platform to evaluate its impact on a gNB. We\nsupplement the experimental results with a theoretical model to extend the\nfindings for different load conditions. To mitigate RRC signaling storms, we\ndevelop a threshold-based detection technique that relies on RRC layer features\nto distinguish between malicious activity and legitimate high network load\nconditions. Leveraging O-RAN capabilities, our detection method is deployed as\nan external Application (xApp). Performance evaluation shows attacks can be\ndetected within 90ms, providing a mitigation window of 60ms before gNB\nunavailability, with an overhead of 1.2% and 0% CPU and memory consumption,\nrespectively.","main_category":"cs.CR","categories":"cs.CR,cs.NI","published":"2025-04-22T09:32:11Z"}
{"aid":"http://arxiv.org/abs/2504.15755v1","title":"Emergent Kitaev materials in synthetic Fermi-Hubbard bilayers","summary":"We investigate the emergence of bond-directional spin-spin interactions in a\nsynthetic Fermi-Hubbard bilayer that can be realized with ultracold fermions in\nRaman optical lattices. The model exploits synthetic dimensions to couple two\nhoneycomb layers, each corresponding to a different hyperfine atomic state, via\nRaman-assisted tunneling and, moreover, via an inter-layer Hubbard repulsion\ndue to the cold-atom scattering. In the strong-coupling regime at half filling,\nwe derive effective spin Hamiltonians for the kinetic exchange featuring\nKitaev, Heisenberg, off-diagonal exchange ($\\Gamma$-couplings), as well as\ntunable Dzyaloshinskii-Moriya interactions. We identify specific configurations\nthat generate both ferromagnetic and antiferromagnetic Kitaev couplings with\nvarious perturbations of relevance to Kitaev materials, providing a tunable\nplatform that can explore how quantum spin liquids emerge from itinerant\nfermion systems. We analyze the Fermi-liquid and Mott-insulating phases,\nhighlighting a correspondence between Dirac and Majorana quasi-particles, with\npossible phase transitions thereof. In an extreme anisotropic limit, we show\nthat the model reduces to an inter-layer ribbon in a quasi-1D ladder, allowing\nfor a numerical study of the correlated ground state using matrix product\nstates. We find a transition from a symmetry-protected topological insulator to\na Kitaev-like regime characterized by nonlocal string order. Our results\nestablish that cold-atom quantum simulators based on Raman optical lattices can\nbe a playground for extended Kitaev models, bridging itinerant fermionic\nsystems and spin-liquid physics.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.str-el,quant-ph","published":"2025-04-22T10:07:56Z"}
{"aid":"http://arxiv.org/abs/2504.15764v1","title":"From Spin Waves to Monte Carlo Simulations: Compiling an Experimental\n  Exchange Interaction Dataset for Magnetic Materials","summary":"Inelastic neutron scattering data on magnetic crystals are highly valuable in\nmaterials science, as they provide direct insight into microscopic magnetic\ninteractions. Using spin wave theory, these interactions can be extracted from\nmagnetic excitations observed in such experiments. However, these datasets are\noften scattered across the literature and lack standardization, limiting their\naccessibility and usability. In this paper, we compile and standardize\nHeisenberg exchange interaction data for magnetic materials obtained from\ninelastic neutron scattering experiments. Through an extensive literature\nreview, we identify experimental data for approximately 100 magnetic materials.\nThe standardized dataset includes mapping the results of various Heisenberg\nHamiltonians into a unified standard form, visualizations of crystal structures\nwith annotated exchange interactions, and input and output files from Monte\nCarlo simulations performed for each compound using the ESpinS code. Using\nexperimentally determined exchange interactions, we calculate transition\ntemperatures $T_c$ via classical Monte Carlo simulations. Additionally, we\nassess the effectiveness of the $S+1)/S$ correction within classical Monte\nCarlo simulations, finding that it produces transition temperatures in\nexcellent agreement with experimental values in most cases. The complete\ndataset, along with supporting resources, is publicly available on GitHub.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T10:17:32Z"}
{"aid":"http://arxiv.org/abs/2504.15769v1","title":"Spin structure of spin-1 charmonium states near $T_c$","summary":"We investigate the spin structure of the $1^{--}$ and $1^{++}$ charmonium\nstates near the critical temperature using QCD sum rules. To this end, we\ncompute the contribution of the dimension-4 twist-2 gluon operator to the\ntwo-point function of heavy vector and axial vector currents in a rotating\nframe. As temperature increases, the quark spin contribution slightly\nincreases, while the quark orbital angular momentum decreases by a comparable\namount. The gluon contribution remains nearly unchanged. These thermal changes\ncancel each other, ensuring that the total spin is preserved even at finite\ntemperature.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-22T10:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.15773v1","title":"Clifford Group Equivariant Diffusion Models for 3D Molecular Generation","summary":"This paper explores leveraging the Clifford algebra's expressive power for\n$\\E(n)$-equivariant diffusion models. We utilize the geometric products between\nClifford multivectors and the rich geometric information encoded in Clifford\nsubspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion\nprocess beyond just Clifford one-vectors to incorporate all higher-grade\nmultivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us\nto apply latent diffusion across complete multivectors. This enables CDMs to\ncapture the joint distribution across different subspaces of the algebra,\nincorporating richer geometric information through higher-order features. We\nprovide empirical results for unconditional molecular generation on the QM9\ndataset, showing that CDMs provide a promising avenue for generative modeling.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T10:30:06Z"}
{"aid":"http://arxiv.org/abs/2504.15774v1","title":"Performance Analysis of IEEE 802.11bn Non-Primary Channel Access","summary":"This paper presents a performance analysis of the Non-Primary Channel Access\n(NPCA) mechanism, a new feature introduced in IEEE 802.11bn to enhance spectrum\nutilization in Wi-Fi networks. NPCA enables devices to contend for and transmit\non the secondary channel when the primary channel is occupied by transmissions\nfrom an Overlapping Basic Service Set (OBSS). We develop a Continuous-Time\nMarkov Chain (CTMC) model that captures the interactions among OBSSs in dense\nWLAN environments when NPCA is enabled, incorporating new NPCA-specific states\nand transitions. In addition to the analytical insights offered by the model,\nwe conduct numerical evaluations and simulations to quantify NPCA's impact on\nthroughput and channel access delay across various scenarios. Our results show\nthat NPCA can significantly improve throughput and reduce access delays in\nfavorable conditions for BSSs that support the mechanism. Moreover, NPCA helps\nmitigate the OBSS performance anomaly, where low-rate OBSS transmissions\ndegrade network performance for all nearby devices. However, we also observe\ntrade-offs: NPCA may increase contention on secondary channels, potentially\nreducing transmission opportunities for BSSs operating there.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-22T10:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.15783v1","title":"Towards prediction of morphological heart age from computed tomography\n  angiography","summary":"Age prediction from medical images or other health-related non-imaging data\nis an important approach to data-driven aging research, providing knowledge of\nhow much information a specific tissue or organ carries about the chronological\nage of the individual. In this work, we studied the prediction of age from\ncomputed tomography angiography (CTA) images, which provide detailed\nrepresentations of the heart morphology, with the goals of (i) studying the\nrelationship between morphology and aging, and (ii) developing a novel\n\\emph{morphological heart age} biomarker. We applied an image\nregistration-based method that standardizes the images from the whole cohort\ninto a single space. We then extracted supervoxels (using unsupervised\nsegmentation), and corresponding robust features of density and local volume,\nwhich provide a detailed representation of the heart morphology while being\nrobust to registration errors. Machine learning models are then trained to fit\nregression models from these features to the chronological age. We applied the\nmethod to a subset of the images from the Swedish CArdioPulomonary bioImage\nStudy (SCAPIS) dataset, consisting of 721 females and 666 males. We observe a\nmean absolute error of $2.74$ years for females and $2.77$ years for males. The\npredictions from different sub-regions of interest were observed to be more\nhighly correlated with the predictions from the whole heart, compared to the\nchronological age, revealing a high consistency in the predictions from\nmorphology. Saliency analysis was also performed on the prediction models to\nstudy what regions are associated positively and negatively with the predicted\nage. This resulted in detailed association maps where the density and volume of\nknown, as well as some novel sub-regions of interest, are determined to be\nimportant. The saliency analysis aids in the interpretability of the models and\ntheir predictions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T10:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.15791v1","title":"Crisp complexity of fuzzy classifiers","summary":"Rule-based systems are a very popular form of explainable AI, particularly in\nthe fuzzy community, where fuzzy rules are widely used for control and\nclassification problems. However, fuzzy rule-based classifiers struggle to\nreach bigger traction outside of fuzzy venues, because users sometimes do not\nknow about fuzzy and because fuzzy partitions are not so easy to interpret in\nsome situations. In this work, we propose a methodology to reduce fuzzy\nrule-based classifiers to crisp rule-based classifiers. We study different\npossible crisp descriptions and implement an algorithm to obtain them. Also, we\nanalyze the complexity of the resulting crisp classifiers. We believe that our\nresults can help both fuzzy and non-fuzzy practitioners understand better the\nway in which fuzzy rule bases partition the feature space and how easily one\nsystem can be translated to another and vice versa. Our complexity metric can\nalso help to choose between different fuzzy classifiers based on what the\nequivalent crisp partitions look like.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-22T11:06:25Z"}
{"aid":"http://arxiv.org/abs/2504.15797v1","title":"Bridging Bond Beyond Life: Designing VR Memorial Space with Stakeholder\n  Collaboration via Research through Design","summary":"The integration of digital technologies into memorialization practices offers\nopportunities to transcend physical and temporal limitations. However,\ndesigning personalized memorial spaces that address the diverse needs of the\ndying and the bereaved remains underexplored. Using a Research through Design\n(RtD) approach, we conducted a three-phase study: participatory design, VR\nmemorial space development, and user testing. This study highlights three key\naspects: 1) the value of VR memorial spaces as bonding mediums, 2) the role of\na design process that engages users through co-design, development, and user\ntesting in addressing the needs of the dying and the bereaved, and 3) design\nelements that enhance the VR memorial experience. This research lays the\nfoundation for personalized VR memorialization practices, providing insights\ninto how technology can enrich remembrance and relational experiences.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-22T11:17:34Z"}
{"aid":"http://arxiv.org/abs/2504.15822v1","title":"Quantifying Source Speaker Leakage in One-to-One Voice Conversion","summary":"Using a multi-accented corpus of parallel utterances for use with commercial\nspeech devices, we present a case study to show that it is possible to quantify\na degree of confidence about a source speaker's identity in the case of\none-to-one voice conversion. Following voice conversion using a HiFi-GAN\nvocoder, we compare information leakage for a range speaker characteristics;\nassuming a \"worst-case\" white-box scenario, we quantify our confidence to\nperform inference and narrow the pool of likely source speakers, reinforcing\nthe regulatory obligation and moral duty that providers of synthetic voices\nhave to ensure the privacy of their speakers' data.","main_category":"cs.SD","categories":"cs.SD,cs.CR,eess.AS","published":"2025-04-22T12:09:03Z"}
{"aid":"http://arxiv.org/abs/2504.15862v1","title":"SBH-ellipticity of the relaxed interfacial energy density in the context\n  of second-order structured deformations","summary":"Starting from an energy comprised of both a bulk term and a surface term, set\nin the space of special functions of bounded hessian, $SBH$, a relaxation\nproblem in the context of second-order structured deformations was studied in\nFonseca-Hagerty-Paroni. It was shown, via the global method for relaxation,\nthat the relaxed functional admits an integral representation and the relaxed\nenergy densities were identified. In this paper we show that, under certain\nhypotheses on the original densities, the corresponding relaxed energy\ndensities verify the same type of growth conditions and the surface energy\ndensity satisfies a specific ``convexity-type'' property, i.e. it is\n$SBH$-elliptic.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T12:57:43Z"}
{"aid":"http://arxiv.org/abs/2504.15876v1","title":"Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement\n  Learning for Strategic Confrontation","summary":"In swarm robotics, confrontation scenarios, including strategic\nconfrontations, require efficient decision-making that integrates discrete\ncommands and continuous actions. Traditional task and motion planning methods\nseparate decision-making into two layers, but their unidirectional structure\nfails to capture the interdependence between these layers, limiting\nadaptability in dynamic environments. Here, we propose a novel bidirectional\napproach based on hierarchical reinforcement learning, enabling dynamic\ninteraction between the layers. This method effectively maps commands to task\nallocation and actions to path planning, while leveraging cross-training\ntechniques to enhance learning across the hierarchical framework. Furthermore,\nwe introduce a trajectory prediction model that bridges abstract task\nrepresentations with actionable planning goals. In our experiments, it achieves\nover 80\\% in confrontation win rate and under 0.01 seconds in decision time,\noutperforming existing approaches. Demonstrations through large-scale tests and\nreal-world robot experiments further emphasize the generalization capabilities\nand practical applicability of our method.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-22T13:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.15881v1","title":"Measurement of the time-integrated $CP$ asymmetry in $D^0 \\to K^0_{\\rm\n  S} K^0_{\\rm S}$ decays using opposite-side flavor tagging at Belle and Belle\n  II","summary":"We measure the time-integrated $CP$ asymmetry in $D^0 \\to K^0_{\\rm S}\nK^0_{\\rm S}$ decays reconstructed in $e^+e^-\\to c{\\overline c}$ events\ncollected by the Belle and Belle II experiments. The corresponding data samples\nhave integrated luminosities of 980 and 428 fb${}^{-1}$, respectively. To infer\nthe flavor of the $D^0$ meson, we exploit the correlation between the flavor of\nthe reconstructed decay and the electric charges of particles reconstructed in\nthe rest of the $e^+e^-\\to c{\\overline c}$ event. This results in a sample\nwhich is independent from any other previously used at Belle or Belle II. The\nresult, $A_{CP}(D^0 \\to K^0_{\\rm S} K^0_{\\rm S}) = (1.3 \\pm 2.0 \\pm 0.2)\\%$,\nwhere the first uncertainty is statistical and the second systematic, is\nconsistent with previous determinations and with $CP$ symmetry.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-22T13:25:40Z"}
{"aid":"http://arxiv.org/abs/2504.15892v1","title":"The accretion disk and neutrino pair annihilation process of\n  Barrow-modified Black Hole","summary":"This paper attempts to clarify the deep consequences of Barrow fractal black\nhole spacetime configurations caused by quantum gravity on neutrino pair\nannihilation and accretion disk dynamics. We systematically derive the\nanalytical expression for the innermost stable circular orbit (ISCO) radius\n($r_{\\text{ISCO}}\\propto M^{2/(2+\\Delta)}$) by building a Barrow-modified\nstatic spherically symmetric metric ($r\\rightarrow r^{1+\\Delta/2}$), and we\nfind that increasing $\\Delta$ significantly shifts the ISCO inward. We\nnumerically solve the radiation flux, effective temperature, and differential\nluminosity distribution under the modified metric based on the Novikov-Thorne\nrelativistic thin accretion disk model. For $\\Delta=1$, the results show that\nthe temperature increases by $62.5\\%$, the peak disk radiation flux increases\nby $22.5\\%$, and the spectral radiance increases by around $50\\%$. Fractal\nhorizons enhance neutrino trajectory bending effects, according to further\nstudy of neutrino pair annihilation ($\\nu\\bar{\\nu}\\rightarrow e^+e^-$) energy\ndeposition processes using local Lorentz transformations and null geodesic\nequations. The energy deposition rate for $\\Delta=1$ is $8-28$ times higher\nthan classical estimates when the black hole radius is $R/M\\sim3-4$. This work\nprovides important theoretical insights into the influence of quantum spacetime\ngeometry on high-energy astrophysical phenomena in extreme gravitational fields\nby establishing, for the first time, quantitative relationships between the\nBarrow parameter $\\Delta$ and neutrino pair annihilation energy and accretion\ndisk radiative efficiency.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-22T13:34:54Z"}
{"aid":"http://arxiv.org/abs/2504.15893v1","title":"Leveraging differentiable programming in the inverse problem of neutron\n  stars","summary":"Neutron stars (NSs) probe the high-density regime of the nuclear equation of\nstate (EOS). However, inferring the EOS from observations of NSs is a\ncomputationally challenging task. In this work, we efficiently solve this\ninverse problem by leveraging differential programming in two ways. First, we\nenable full Bayesian inference in under one hour of wall time on a GPU by using\ngradient-based samplers, without requiring pre-trained machine learning\nemulators. Moreover, we demonstrate efficient scaling to high-dimensional\nparameter spaces. Second, we introduce a novel gradient-based optimization\nscheme that recovers the EOS of a given NS mass-radius curve. We demonstrate\nhow our framework can reveal consistencies or tensions between nuclear physics\nand astrophysics. First, we show how the breakdown density of a metamodel\ndescription of the EOS can be determined from NS observations. Second, we\ndemonstrate how degeneracies in EOS modeling using nuclear empirical parameters\ncan influence the inverse problem during gradient-based optimization. Looking\nahead, our approach opens up new theoretical studies of the relation between NS\nproperties and the EOS, while effectively tackling the data analysis challenges\nbrought by future detectors.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.IM,gr-qc","published":"2025-04-22T13:35:22Z"}
{"aid":"http://arxiv.org/abs/2504.15900v1","title":"SARI: Structured Audio Reasoning via Curriculum-Guided Reinforcement\n  Learning","summary":"Recent work shows that reinforcement learning(RL) can markedly sharpen the\nreasoning ability of large language models (LLMs) by prompting them to \"think\nbefore answering.\" Yet whether and how these gains transfer to audio-language\nreasoning remains largely unexplored. We extend the Group-Relative Policy\nOptimization (GRPO) framework from DeepSeek-R1 to a Large Audio-Language Model\n(LALM), and construct a 32k sample multiple-choice corpus. Using a two-stage\nregimen supervised fine-tuning on structured and unstructured\nchains-of-thought, followed by curriculum-guided GRPO, we systematically\ncompare implicit vs. explicit, and structured vs. free form reasoning under\nidentical architectures. Our structured audio reasoning model, SARI (Structured\nAudio Reasoning via Curriculum-Guided Reinforcement Learning), achieves a\n16.35% improvement in average accuracy over the base model\nQwen2-Audio-7B-Instruct. Furthermore, the variant built upon Qwen2.5-Omni\nreaches state-of-the-art performance of 67.08% on the MMAU test-mini benchmark.\nAblation experiments show that on the base model we use: (i) SFT warm-up is\nimportant for stable RL training, (ii) structured chains yield more robust\ngeneralization than unstructured ones, and (iii) easy-to-hard curricula\naccelerate convergence and improve final performance. These findings\ndemonstrate that explicit, structured reasoning and curriculum learning\nsubstantially enhances audio-language understanding.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T13:41:26Z"}
{"aid":"http://arxiv.org/abs/2504.15909v1","title":"Synergizing RAG and Reasoning: A Systematic Review","summary":"Recent breakthroughs in large language models (LLMs), particularly in\nreasoning capabilities, have propelled Retrieval-Augmented Generation (RAG) to\nunprecedented levels. By synergizing retrieval mechanisms with advanced\nreasoning, LLMs can now tackle increasingly complex problems. This paper\npresents a systematic review of the collaborative interplay between RAG and\nreasoning, clearly defining \"reasoning\" within the RAG context. It construct a\ncomprehensive taxonomy encompassing multi-dimensional collaborative objectives,\nrepresentative paradigms, and technical implementations, and analyze the\nbidirectional synergy methods. Additionally, we critically evaluate current\nlimitations in RAG assessment, including the absence of intermediate\nsupervision for multi-step reasoning and practical challenges related to\ncost-risk trade-offs. To bridge theory and practice, we provide practical\nguidelines tailored to diverse real-world applications. Finally, we identify\npromising research directions, such as graph-based knowledge integration,\nhybrid model collaboration, and RL-driven optimization. Overall, this work\npresents a theoretical framework and practical foundation to advance RAG\nsystems in academia and industry, fostering the next generation of RAG\nsolutions.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-22T13:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.15912v1","title":"Automated Bug Report Prioritization in Large Open-Source Projects","summary":"Large open-source projects receive a large number of issues (known as bugs),\nincluding software defect (i.e., bug) reports and new feature requests from\ntheir user and developer communities at a fast rate. The often limited project\nresources do not allow them to deal with all issues. Instead, they have to\nprioritize them according to the project's priorities and the issues'\nseverities. In this paper, we propose a novel approach to automated bug\nprioritization based on the natural language text of the bug reports that are\nstored in the open bug repositories of the issue-tracking systems. We conduct\ntopic modeling using a variant of LDA called TopicMiner-MTM and text\nclassification with the BERT large language model to achieve a higher\nperformance level compared to the state-of-the-art. Experimental results using\nan existing reference dataset containing 85,156 bug reports of the Eclipse\nPlatform project indicate that we outperform existing approaches in terms of\nAccuracy, Precision, Recall, and F1-measure of the bug report priority\nprediction.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-22T13:57:48Z"}
{"aid":"http://arxiv.org/abs/2504.15915v1","title":"Topology and Diffeology via Metric-like Functions","summary":"This paper investigates spaces equipped with a family of metric-like\nfunctions satisfying certain axioms. These functions provide a unified\nframework for defining topology, uniformity, and diffeology. The framework is\nbased on a family of metric-like functions originally introduced for spaces of\nsubmanifolds. We show that the topologies, uniformities, and diffeologies of\nthese spaces can be systematically derived from the proposed axioms.\nFurthermore, the framework covers examples such as spaces with compact-open\ntopologies, tiling spaces, and spaces of graphs, which have appeared in\ndifferent contexts. These results support the study of spaces with metric-like\nstructures from both topological and diffeological perspectives.","main_category":"math.GN","categories":"math.GN,math.MG","published":"2025-04-22T14:02:25Z"}
{"aid":"http://arxiv.org/abs/2504.15928v1","title":"A Clinician-Friendly Platform for Ophthalmic Image Analysis Without\n  Technical Barriers","summary":"Artificial intelligence (AI) shows remarkable potential in medical imaging\ndiagnostics, but current models typically require retraining when deployed\nacross different clinical centers, limiting their widespread adoption. We\nintroduce GlobeReady, a clinician-friendly AI platform that enables ocular\ndisease diagnosis without retraining/fine-tuning or technical expertise.\nGlobeReady achieves high accuracy across imaging modalities: 93.9-98.5% for an\n11-category fundus photo dataset and 87.2-92.7% for a 15-category OCT dataset.\nThrough training-free local feature augmentation, it addresses domain shifts\nacross centers and populations, reaching an average accuracy of 88.9% across\nfive centers in China, 86.3% in Vietnam, and 90.2% in the UK. The built-in\nconfidence-quantifiable diagnostic approach further boosted accuracy to\n94.9-99.4% (fundus) and 88.2-96.2% (OCT), while identifying out-of-distribution\ncases at 86.3% (49 CFP categories) and 90.6% (13 OCT categories). Clinicians\nfrom multiple countries rated GlobeReady highly (average 4.6 out of 5) for its\nusability and clinical relevance. These results demonstrate GlobeReady's\nrobust, scalable diagnostic capability and potential to support ophthalmic care\nwithout technical barriers.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T14:17:22Z"}
{"aid":"http://arxiv.org/abs/2504.15932v1","title":"Reasoning Physical Video Generation with Diffusion Timestep Tokens via\n  Reinforcement Learning","summary":"Despite recent progress in video generation, producing videos that adhere to\nphysical laws remains a significant challenge. Traditional diffusion-based\nmethods struggle to extrapolate to unseen physical conditions (eg, velocity)\ndue to their reliance on data-driven approximations. To address this, we\npropose to integrate symbolic reasoning and reinforcement learning to enforce\nphysical consistency in video generation. We first introduce the Diffusion\nTimestep Tokenizer (DDT), which learns discrete, recursive visual tokens by\nrecovering visual attributes lost during the diffusion process. The recursive\nvisual tokens enable symbolic reasoning by a large language model. Based on it,\nwe propose the Phys-AR framework, which consists of two stages: The first stage\nuses supervised fine-tuning to transfer symbolic knowledge, while the second\nstage applies reinforcement learning to optimize the model's reasoning\nabilities through reward functions based on physical conditions. Our approach\nallows the model to dynamically adjust and improve the physical properties of\ngenerated videos, ensuring adherence to physical laws. Experimental results\ndemonstrate that PhysAR can generate videos that are physically consistent.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:20:59Z"}
{"aid":"http://arxiv.org/abs/2504.15936v1","title":"An effectful object calculus","summary":"We show how to smoothly incorporate in the object-oriented paradigm\nconstructs to raise, compose, and handle effects in an arbitrary monad. The\nunderlying pure calculus is meant to be a representative of the last generation\nof OO languages, and the effectful extension is manageable enough for ordinary\nprogrammers; notably, constructs to raise effects are just special methods. We\nequip the calculus with an expressive type-and-effect system, which, again by\nrelying on standard features such as inheritance and generic types, allows a\nsimple form of effect polymorphism. The soundness of the type-and-effect system\nis expressed and proved by a recently introduced technique, where the semantics\nis formalized by a one-step reduction relation from language expressions into\nmonadic ones, so that it is enough to prove progress and subject reduction\nproperties on this relation.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-22T14:24:59Z"}
{"aid":"http://arxiv.org/abs/2504.15944v1","title":"Deep learning of point processes for modeling high-frequency data","summary":"We investigate applications of deep neural networks to a point process having\nan intensity with mixing covariates processes as input. Our generic model\nincludes Cox-type models and marked point processes as well as multivariate\npoint processes. An oracle inequality and a rate of convergence are derived for\nthe prediction error. A simulation study shows that the marked point process\ncan be superior to the simple multivariate model in prediction. We apply the\nmarked ratio model to real limit order book data","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-22T14:42:16Z"}
{"aid":"http://arxiv.org/abs/2504.15946v1","title":"The e-Partitioning Principle of False Discovery Rate Control","summary":"We present a novel necessary and sufficient principle for False Discovery\nRate (FDR) control. This e-Partitioning Principle says that a procedure\ncontrols FDR if and only if it is a special case of a general e-Partitioning\nprocedure. By writing existing methods as special cases of this procedure, we\ncan achieve uniform improvements of these methods, and we show this in\nparticular for the eBH, BY and Su methods. We also show that methods developed\nusing the $e$-Partitioning Principle have several valuable properties. They\ngenerally control FDR not just for one rejected set, but simultaneously over\nmany, allowing post hoc flexibility for the researcher in the final choice of\nthe rejected hypotheses. Under some conditions, they also allow for post hoc\nadjustment of the error rate, choosing the FDR level $\\alpha$ post hoc, or\nswitching to familywise error control after seeing the data. In addition,\ne-Partitioning allows FDR control methods to exploit logical relationships\nbetween hypotheses to gain power.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-22T14:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.15954v1","title":"Monocular inspection of spacecraft under illumination constraints and\n  avoidance regions","summary":"This paper presents an adaptive control approach to information-based\nguidance and control of a spacecraft carrying out on-orbit inspection by\nactively computing optimal policies for the spacecraft to achieve the best\npossible representation of objects within its orbital environment. Due to the\ncomplexity of navigating the space environment, it may be impossible to carry\nout on-orbit servicing to maintain space systems like satellites using a\nspacecraft equipped with controllers that cannot adapt to changing conditions.\nIn particular, the presence of constraints such as illumination, field-of-view\n(FOV), minimal fuel, the use of visual-inertial navigation for improved\nlocalization, and the need for real-time computation of control policies render\nthe spacecraft motion planning problem challenging. The control framework\ndeveloped in this paper addresses these challenges by formulating the\ninspection task as a constrained optimization problem where the goal is to\nmaximize information gained from the cameras, while navigating to the next best\nview, subject to illumination and FOV constraints. The developed architecture\nis analyzed using a Lyapunov-based stability analysis and the effectiveness of\nthe planning algorithm is verified in simulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T14:50:09Z"}
{"aid":"http://arxiv.org/abs/2504.15962v1","title":"Blimp-based Crime Scene Analysis","summary":"To tackle the crucial problem of crime, evidence at indoor crime scenes must\nbe analyzed before it becomes contaminated or degraded. Here, as an application\nof artificial intelligence (AI), computer vision, and robotics, we explore how\na blimp could be designed as a kind of \"floating camera\" to drift over and\nrecord evidence with minimal disturbance. In particular, rapid prototyping is\nused to develop a proof-of-concept to gain insight into what such blimps could\ndo, manually piloted or semi-autonomously. As a result, we show the feasibility\nof attaching various components to an indoor blimp, and confirm our basic\npremise, that blimps can sense evidence without producing much wind. Some\nadditional suggestions--regarding mapping, sensing, and path-finding--aim to\nstimulate the flow of ideas for further exploration.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T15:01:10Z"}
{"aid":"http://arxiv.org/abs/2504.15968v1","title":"Global Compactness Result for a BrÃ©zis-Nirenberg-Type Problem\n  Involving Mixed Local Nonlocal Operator","summary":"This paper investigates the profile decomposition of Palais-Smale sequences\nassociated with a Br\\'ezis-Nirenberg-type problem involving a combination of\nlocal nonlocal operator, given by\n  \\begin{equation*}\n  \\begin{aligned}\n  &-\\Delta u + (-\\Delta)^s u - \\lambda u = |u|^{2^*-2}u \\;\\;\\mbox{ in } \\Omega,\n  &\\quad u=0\\,\\mbox{ in }\\mathbb{R}^N\\setminus \\Omega.\n  \\end{aligned}\n  \\end{equation*} where $ N \\geq 3$ and $2^* = \\frac{2N}{N - 2} $ denotes the\ncritical Sobolev exponent. As an application of the derived global compactness\nresult, we further study the corresponding Coron-type problem.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-22T15:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.15986v1","title":"Charting the Uncharted: The Landscape of Monero Peer-to-Peer Network","summary":"The Monero blockchain enables anonymous transactions through advanced\ncryptography in its peer-to-peer network, which underpins decentralization,\nsecurity, and trustless interactions. However, privacy measures obscure peer\nconnections, complicating network analysis. This study proposes a method to\ninfer peer connections in Monero's latest protocol version, where timestamp\ndata is unavailable. We collect peerlist data from TCP flows, validate our\ninference algorithm, and map the network structure. Our results show high\naccuracy, improving with longer observation periods. This work is the first to\nreveal connectivity patterns in Monero's updated protocol, providing\nvisualizations and insights into its topology. Our findings enhance the\nunderstanding of Monero's P2P network, including the role of supernodes, and\nhighlight potential protocol and security improvements.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-22T15:42:31Z"}
{"aid":"http://arxiv.org/abs/2504.15987v1","title":"Few-shot Hate Speech Detection Based on the MindSpore Framework","summary":"The proliferation of hate speech on social media poses a significant threat\nto online communities, requiring effective detection systems. While deep\nlearning models have shown promise, their performance often deteriorates in\nfew-shot or low-resource settings due to reliance on large annotated corpora.\nTo address this, we propose MS-FSLHate, a prompt-enhanced neural framework for\nfew-shot hate speech detection implemented on the MindSpore deep learning\nplatform. The model integrates learnable prompt embeddings, a CNN-BiLSTM\nbackbone with attention pooling, and synonym-based adversarial data\naugmentation to improve generalization. Experimental results on two benchmark\ndatasets-HateXplain and HSOL-demonstrate that our approach outperforms\ncompetitive baselines in precision, recall, and F1-score. Additionally, the\nframework shows high efficiency and scalability, suggesting its suitability for\ndeployment in resource-constrained environments. These findings highlight the\npotential of combining prompt-based learning with adversarial augmentation for\nrobust and adaptable hate speech detection in few-shot scenarios.","main_category":"cs.CL","categories":"cs.CL,cs.CY","published":"2025-04-22T15:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.15993v1","title":"Benchmarking machine learning models for predicting aerofoil performance","summary":"This paper investigates the capability of Neural Networks (NNs) as\nalternatives to the traditional methods to analyse the performance of aerofoils\nused in the wind and tidal energy industry. The current methods used to assess\nthe characteristic lift and drag coefficients include Computational Fluid\nDynamics (CFD), thin aerofoil and panel methods, all face trade-offs between\ncomputational speed and the accuracy of the results and as such NNs have been\ninvestigated as an alternative with the aim that it would perform both quickly\nand accurately. As such, this paper provides a benchmark for the windAI_bench\ndataset published by the National Renewable Energy Laboratory (NREL) in the\nUSA. In order to validate the methodology of the benchmarking, the AirfRANS\n{\\tt arXiv:2212.07564v3} dataset is used as both a starting point and a point\nof comparison. This study evaluates four neural networks (MLP, PointNet,\nGraphSAGE, GUNet) trained on a range aerofoils at 25 angles of attack\n(4$^\\circ$ to 20$^\\circ$). to predict fluid flow and calculate lift\ncoefficients ($C_L$) via the panel method. GraphSAGE and GUNet performed well\nduring the testing phase, but underperformed during validation. Accordingly,\nthis paper has identified PointNet and MLP as the two strongest models tested,\nhowever whilst the results from MLP are more commonly correct for predicting\nthe behaviour of the fluid, the results from PointNet provide the more accurate\nresults for calculating $C_L$.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-22T15:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.16030v1","title":"LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale","summary":"Recent video large language models (Video LLMs) often depend on costly human\nannotations or proprietary model APIs (e.g., GPT-4o) to produce training data,\nwhich limits their training at scale. In this paper, we explore large-scale\ntraining for Video LLM with cheap automatic speech recognition (ASR)\ntranscripts. Specifically, we propose a novel streaming training approach that\ndensely interleaves the ASR words and video frames according to their\ntimestamps. Compared to previous studies in vision-language representation with\nASR, our method naturally fits the streaming characteristics of ASR, thus\nenabling the model to learn temporally-aligned, fine-grained vision-language\nmodeling. To support the training algorithm, we introduce a data production\npipeline to process YouTube videos and their closed captions (CC, same as ASR),\nresulting in Live-CC-5M dataset for pre-training and Live-WhisperX-526K dataset\nfor high-quality supervised fine-tuning (SFT). Remarkably, even without SFT,\nthe ASR-only pre-trained LiveCC-7B-Base model demonstrates competitive general\nvideo QA performance and exhibits a new capability in real-time video\ncommentary. To evaluate this, we carefully design a new LiveSports-3K\nbenchmark, using LLM-as-a-judge to measure the free-form commentary.\nExperiments show our final LiveCC-7B-Instruct model can surpass advanced 72B\nmodels (Qwen2.5-VL-72B-Instruct, LLaVA-Video-72B) in commentary quality even\nworking in a real-time mode. Meanwhile, it achieves state-of-the-art results at\nthe 7B/8B scale on popular video QA benchmarks such as VideoMME and OVOBench,\ndemonstrating the broad generalizability of our approach. All resources of this\npaper have been released at https://showlab.github.io/livecc.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T16:52:09Z"}
{"aid":"http://arxiv.org/abs/2504.16032v1","title":"LLMs meet Federated Learning for Scalable and Secure IoT Management","summary":"The rapid expansion of IoT ecosystems introduces severe challenges in\nscalability, security, and real-time decision-making. Traditional centralized\narchitectures struggle with latency, privacy concerns, and excessive resource\nconsumption, making them unsuitable for modern large-scale IoT deployments.\nThis paper presents a novel Federated Learning-driven Large Language Model\n(FL-LLM) framework, designed to enhance IoT system intelligence while ensuring\ndata privacy and computational efficiency. The framework integrates Generative\nIoT (GIoT) models with a Gradient Sensing Federated Strategy (GSFS),\ndynamically optimizing model updates based on real-time network conditions. By\nleveraging a hybrid edge-cloud processing architecture, our approach balances\nintelligence, scalability, and security in distributed IoT environments.\nEvaluations on the IoT-23 dataset demonstrate that our framework improves model\naccuracy, reduces response latency, and enhances energy efficiency,\noutperforming traditional FL techniques (i.e., FedAvg, FedOpt). These findings\nhighlight the potential of integrating LLM-powered federated learning into\nlarge-scale IoT ecosystems, paving the way for more secure, scalable, and\nadaptive IoT management solutions.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.ET","published":"2025-04-22T16:56:59Z"}
{"aid":"http://arxiv.org/abs/2504.16038v1","title":"The Global Phase Space of the Three-Vortex Interaction System","summary":"We derive a symplectic reduction of the evolution equations for a system of\nthree point vortices and use the reduced system to succinctly explain a kind of\nbifurcation diagram that has appeared in the literature in a form that was\ndifficult to understand and interpret. Using this diagram, we enumerate and\nplot all the global phase-space diagrams that occur as the circulations of the\nthree vortices are varied. The reduction proceeds in two steps: a reduction to\nJacobi coordinates and a Lie-Poisson reduction. In a recent paper, we used a\ndifferent method in the second step. This took two forms depending on a sign\nthat arose in the calculation. The Lie-Poisson equations unify these into a\nsingle form. The Jacobi coordinate reduction fails when the total circulation\nvanishes. We adapt the reduction method to this case and show how it relates to\nthe non-vanishing case.","main_category":"math.DS","categories":"math.DS","published":"2025-04-22T17:03:03Z"}
{"aid":"http://arxiv.org/abs/2504.16042v1","title":"Approximate matrices of systems of max-min fuzzy relational equations","summary":"In this article, we address the inconsistency of a system of max-min fuzzy\nrelational equations by minimally modifying the matrix governing the system in\norder to achieve consistency. Our method yields consistent systems that\napproximate the original inconsistent system in the following sense: the\nright-hand side vector of each consistent system is that of the inconsistent\nsystem, and the coefficients of the matrix governing each consistent system are\nobtained by modifying, exactly and minimally, the entries of the original\nmatrix that must be corrected to achieve consistency, while leaving all other\nentries unchanged.\n  To obtain a consistent system that closely approximates the considered\ninconsistent system, we study the distance (in terms of a norm among $L_1$,\n$L_2$ or $L_\\infty$) between the matrix of the inconsistent system and the set\nformed by the matrices of consistent systems that use the same right-hand side\nvector as the inconsistent system. We show that our method allows us to\ndirectly compute matrices of consistent systems that use the same right-hand\nside vector as the inconsistent system whose distance in terms of $L_\\infty$\nnorm to the matrix of the inconsistent system is minimal (the computational\ncosts are higher when using $L_1$ norm or $L_2$ norm). We also give an explicit\nanalytical formula for computing this minimal $L_\\infty$ distance. Finally, we\ntranslate our results for systems of min-max fuzzy relational equations and\npresent some potential applications.","main_category":"cs.AI","categories":"cs.AI,cs.LO","published":"2025-04-22T17:09:02Z"}
{"aid":"http://arxiv.org/abs/2504.16048v1","title":"PRIME: Fast Primal-Dual Feedback Optimization for Markets with\n  Application to Optimal Power Flow","summary":"Online Feedback Optimization (OFO) controllers iteratively drive a plant to\nan optimal operating point that satisfies input and output constraints, relying\nsolely on the input-output sensitivity as model information. This paper\nintroduces PRIME (PRoximal Iterative MarkEts), a novel OFO approach based on\nproximal-point iterations. Unlike existing OFO solutions, PRIME admits a\nmarket-based implementation, where self-interested actors are incentivized to\nmake choices that result in a safe and efficient operation, without\ncommunicating private costs or constraints. Furthermore, PRIME can cope with\nnon-smooth objective functions, achieve fast convergence rates and rapid\nconstraint satisfaction, and reject measurement noise. We demonstrate PRIME on\nan AC optimal power flow problem, obtaining an efficient real-time nonlinear\nlocal marginal pricing scheme.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T17:25:40Z"}
{"aid":"http://arxiv.org/abs/2504.16050v1","title":"The jet and circumstellar environment of the young binary DF Tau","summary":"Jets and disc winds play an important role in the evolution of protoplanetary\ndiscs and the formation of planetary systems. However, there is still a lack of\nobservational data regarding the presence and parameters of outflows,\nespecially for close young binaries. In this study, we aim to find the HH flow\nnear the young sub-arcsecond binary DF Tau and explore its morphology.\nNarrow-band H$\\alpha$ and H$_2$ 2.12 $\\mu$m imaging and spectroscopic\nobservations of DF Tau and its vicinity were performed. We have discovered\nseveral emission nebulae near the binary, which likely result from the\ninteraction of gas outflow from the binary components with the surrounding\nmedium. The outflow appears to occur both in the form of jets, generating\nnumerous Herbig-Haro objects (HH 1266 flow), and as a weakly collimated wind\nresponsible for the formation of the ring-like nebula around the binary and the\nrim of the cometary globule. We have found that the angle between the jet and\nthe counter-jet is $168^\\circ$ and discuss the complex morphology of the HH\nflow.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,astro-ph.GA","published":"2025-04-22T17:27:17Z"}
{"aid":"http://arxiv.org/abs/2504.16054v1","title":"$Ï€_{0.5}$: a Vision-Language-Action Model with Open-World\n  Generalization","summary":"In order for robots to be useful, they must perform practically relevant\ntasks in the real world, outside of the lab. While vision-language-action (VLA)\nmodels have demonstrated impressive results for end-to-end robot control, it\nremains an open question how far such models can generalize in the wild. We\ndescribe $\\pi_{0.5}$, a new model based on $\\pi_{0}$ that uses co-training on\nheterogeneous tasks to enable broad generalization. $\\pi_{0.5}$\\ uses data from\nmultiple robots, high-level semantic prediction, web data, and other sources to\nenable broadly generalizable real-world robotic manipulation. Our system uses a\ncombination of co-training and hybrid multi-modal examples that combine image\nobservations, language commands, object detections, semantic subtask\nprediction, and low-level actions. Our experiments show that this kind of\nknowledge transfer is essential for effective generalization, and we\ndemonstrate for the first time that an end-to-end learning-enabled robotic\nsystem can perform long-horizon and dexterous manipulation skills, such as\ncleaning a kitchen or bedroom, in entirely new homes.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-22T17:31:29Z"}
{"aid":"http://arxiv.org/abs/2504.16057v1","title":"Automated Static Vulnerability Detection via a Holistic Neuro-symbolic\n  Approach","summary":"Static vulnerability detection is still a challenging problem and demands\nexcessive human efforts, e.g., manual curation of good vulnerability patterns.\nNone of prior works, including classic program analysis or Large Language Model\n(LLM)-based approaches, have fully automated such vulnerability pattern\ngenerations with reasonable detection accuracy. In this paper, we design and\nimplement, MoCQ, a novel holistic neuro-symbolic framework that combines the\ncomplementary strengths of LLMs and classical static analysis to enable\nscalable vulnerability detection. The key insight is that MoCQ leverages an LLM\nto automatically extract vulnerability patterns and translate them into\ndetection queries, and then on static analysis to refine such queries in a\nfeedback loop and eventually execute them for analyzing large codebases and\nmining vulnerabilities. We evaluate MoCQ on seven types of vulnerabilities\nspanning two programming languages. We found MoCQ-generated queries uncovered\nat least 12 patterns that were missed by experts. On a ground truth dataset,\nMoCQ achieved comparable precision and recall compared to expert-crafted\nqueries. Moreover, MoCQ has identified seven previously unknown vulnerabilities\nin real-world applications, demonstrating its practical effectiveness. We have\nresponsibly disclosed them to the corresponding developers.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-22T17:33:53Z"}
{"aid":"http://arxiv.org/abs/2504.16067v1","title":"Two-step laser resonant ionization spectroscopy of chromium","summary":"At TRIUMF's off-line laser ion source test stand, stepwise resonant laser\nionization spectroscopy of chromium (Cr) was carried out, to find an efficient\nionization scheme suitable for titanium sapphire (Ti:Sa) laser systems. With\nthree different first-excitation transitions, 357.971 nm, 359.451 nm, and\n360.636 nm, automated continuous laser-frequency scans using a\nfrequency-doubled, grating-tuned Ti:Sa laser were performed. Rydberg series as\nwell as autoionizing(AI) states were observed. From these results, the\nionization potential (IP) of Cr was determined as\n54575.49(2)$_\\text{stat}$(2)$_\\text{sys}$ cm$^{-1}$, which is one order of\nmagnitude more precise than the previously reported 54575.6(3) cm$^{-1}$ in\nNIST database. The ionization scheme using the observed AI resonance, with\n357.971 nm as the first step and 373.935 nm as the second step was subsequently\ndeployed to the online delivery of radioactive Cr isotope beams for precision\nmass measurements. The online yields of $^{50-59}$Cr have been measured at\nTRIUMF-ISAC.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.acc-ph,physics.app-ph","published":"2025-04-22T17:46:56Z"}
{"aid":"http://arxiv.org/abs/2504.16073v1","title":"Guiding VLM Agents with Process Rewards at Inference Time for GUI\n  Navigation","summary":"Recent advancements in visual language models (VLMs) have notably enhanced\ntheir capabilities in handling complex Graphical User Interface (GUI)\ninteraction tasks. Despite these improvements, current frameworks often\nstruggle to generate correct actions in challenging GUI environments.\nState-of-the-art commercial VLMs are black-boxes, and fine-tuning open-source\nVLMs for GUI tasks requires significant resources. Additionally, existing\ntrajectory-level evaluation and refinement techniques frequently fall short due\nto delayed feedback and local optimization issues. To address these challenges,\nwe propose an approach that guides VLM agents with process supervision by a\nreward model during GUI navigation and control at inference time. This guidance\nallows the VLM agent to optimize actions at each inference step, thereby\nimproving performance in both static and dynamic environments. In particular,\nour method demonstrates significant performance gains in three GUI navigation\ntasks, achieving a 3.4% improvement in single step action accuracy for static\nenvironments, along with a around 33% increase in task success rate in one\ndynamic environment. With further integration of trajectory reflection and\nretry mechanisms, we also demonstrate even greater enhancement in task success.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T17:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.16389v1","title":"SaENeRF: Suppressing Artifacts in Event-based Neural Radiance Fields","summary":"Event cameras are neuromorphic vision sensors that asynchronously capture\nchanges in logarithmic brightness changes, offering significant advantages such\nas low latency, low power consumption, low bandwidth, and high dynamic range.\nWhile these characteristics make them ideal for high-speed scenarios,\nreconstructing geometrically consistent and photometrically accurate 3D\nrepresentations from event data remains fundamentally challenging. Current\nevent-based Neural Radiance Fields (NeRF) methods partially address these\nchallenges but suffer from persistent artifacts caused by aggressive network\nlearning in early stages and the inherent noise of event cameras. To overcome\nthese limitations, we present SaENeRF, a novel self-supervised framework that\neffectively suppresses artifacts and enables 3D-consistent, dense, and\nphotorealistic NeRF reconstruction of static scenes solely from event streams.\nOur approach normalizes predicted radiance variations based on accumulated\nevent polarities, facilitating progressive and rapid learning for scene\nrepresentation construction. Additionally, we introduce regularization losses\nspecifically designed to suppress artifacts in regions where photometric\nchanges fall below the event threshold and simultaneously enhance the light\nintensity difference of non-zero events, thereby improving the visual fidelity\nof the reconstructed scene. Extensive qualitative and quantitative experiments\ndemonstrate that our method significantly reduces artifacts and achieves\nsuperior reconstruction quality compared to existing methods. The code is\navailable at https://github.com/Mr-firework/SaENeRF.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T03:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.16412v1","title":"Superconductivity and Electron Correlations in Kagome Metal LuOs3B2","summary":"We report a comprehensive investigation of the physical properties of\nLuOs3B2, characterized by an ideal Os-based kagome lattice. Resistivity and\nmagnetization measurements confirm the emergence of type-II bulk\nsuperconductivity with a critical temperature Tc=4.63 K. The specific heat jump\nand the calculated electron-phonon coupling parameter support a moderately\ncoupled superconducting state. Electron correlation effects are supported by\nthe enhanced Wilson ratios. First-principles calculations reveal hallmark\nfeatures of kagome band structure, including Dirac points, van Hove\nsingularities, and quasi-flat bands, primarily derived from the Os d orbitals.\nThe inclusion of spin-orbit coupling opens a gap at the Dirac points,\nsignificantly altering the electronic properties. Furthermore, the\nsuperconductivity and electronic properties of isomorphic compounds are\ndiscussed. This work provides a thorough exploration of the superconducting and\nnormal states of LuOs3B2, deepening the understanding of kagome\nsuperconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-23T04:28:50Z"}
{"aid":"http://arxiv.org/abs/2504.16414v1","title":"Evaluating Multi-Hop Reasoning in Large Language Models: A\n  Chemistry-Centric Case Study","summary":"In this study, we introduced a new benchmark consisting of a curated dataset\nand a defined evaluation process to assess the compositional reasoning\ncapabilities of large language models within the chemistry domain. We designed\nand validated a fully automated pipeline, verified by subject matter experts,\nto facilitate this task. Our approach integrates OpenAI reasoning models with\nnamed entity recognition (NER) systems to extract chemical entities from recent\nliterature, which are then augmented with external knowledge bases to form a\ncomprehensive knowledge graph. By generating multi-hop questions across these\ngraphs, we assess LLM performance in both context-augmented and non-context\naugmented settings. Our experiments reveal that even state-of-the-art models\nface significant challenges in multi-hop compositional reasoning. The results\nreflect the importance of augmenting LLMs with document retrieval, which can\nhave a substantial impact on improving their performance. However, even perfect\nretrieval accuracy with full context does not eliminate reasoning errors,\nunderscoring the complexity of compositional reasoning. This work not only\nbenchmarks and highlights the limitations of current LLMs but also presents a\nnovel data generation pipeline capable of producing challenging reasoning\ndatasets across various domains. Overall, this research advances our\nunderstanding of reasoning in computational linguistics.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T04:36:19Z"}
{"aid":"http://arxiv.org/abs/2504.16416v1","title":"FeedQUAC: Quick Unobtrusive AI-Generated Commentary","summary":"Design thrives on feedback. However, gathering constant feedback throughout\nthe design process can be labor-intensive and disruptive. We explore how AI can\nbridge this gap by providing effortless, ambient feedback. We introduce\nFeedQUAC, a design companion that delivers real-time AI-generated commentary\nfrom a variety of perspectives through different personas. A design probe study\nwith eight participants highlights how designers can leverage quick yet ambient\nAI feedback to enhance their creative workflows. Participants highlight\nbenefits such as convenience, playfulness, confidence boost, and inspiration\nfrom this lightweight feedback agent, while suggesting additional features,\nlike chat interaction and context curation. We discuss the role of AI feedback,\nits strengths and limitations, and how to integrate it into existing design\nworkflows while balancing user involvement. Our findings also suggest that\nambient interaction is a valuable consideration for both the design and\nevaluation of future creativity support systems.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CY,cs.MM","published":"2025-04-23T04:48:00Z"}
{"aid":"http://arxiv.org/abs/2504.16436v1","title":"Towards a fast and robust deep hedging approach","summary":"We present a robust Deep Hedging framework for the pricing and hedging of\noption portfolios that significantly improves training efficiency and model\nrobustness. In particular, we propose a neural model for training model\nembeddings which utilizes the paths of several advanced equity option models\nwith stochastic volatility in order to learn the relationships that exist\nbetween hedging strategies. A key advantage of the proposed method is its\nability to rapidly and reliably adapt to new market regimes through the\nrecalibration of a low-dimensional embedding vector, rather than retraining the\nentire network. Moreover, we examine the observed Profit and Loss distributions\non the parameter space of the models used to learn the embeddings. The results\nshow that the proposed framework works well with data generated by complex\nmodels and can serve as a construction basis for an efficient and robust\nsimulation tool for the systematic development of an entirely model-independent\nhedging strategy.","main_category":"q-fin.CP","categories":"q-fin.CP","published":"2025-04-23T05:48:52Z"}
{"aid":"http://arxiv.org/abs/2504.16443v1","title":"Marginalized Generalized IoU (MGIoU): A Unified Objective Function for\n  Optimizing Any Convex Parametric Shapes","summary":"Optimizing the similarity between parametric shapes is crucial for numerous\ncomputer vision tasks, where Intersection over Union (IoU) stands as the\ncanonical measure. However, existing optimization methods exhibit significant\nshortcomings: regression-based losses like L1/L2 lack correlation with IoU,\nIoU-based losses are unstable and limited to simple shapes, and task-specific\nmethods are computationally intensive and not generalizable accross domains. As\na result, the current landscape of parametric shape objective functions has\nbecome scattered, with each domain proposing distinct IoU approximations. To\naddress this, we unify the parametric shape optimization objective functions by\nintroducing Marginalized Generalized IoU (MGIoU), a novel loss function that\novercomes these challenges by projecting structured convex shapes onto their\nunique shape Normals to compute one-dimensional normalized GIoU. MGIoU offers a\nsimple, efficient, fully differentiable approximation strongly correlated with\nIoU. We then extend MGIoU to MGIoU+ that supports optimizing unstructured\nconvex shapes. Together, MGIoU and MGIoU+ unify parametric shape optimization\nacross diverse applications. Experiments on standard benchmarks demonstrate\nthat MGIoU and MGIoU+ consistently outperform existing losses while reducing\nloss computation latency by 10-40x. Additionally, MGIoU and MGIoU+ satisfy\nmetric properties and scale-invariance, ensuring robustness as an objective\nfunction. We further propose MGIoU- for minimizing overlaps in tasks like\ncollision-free trajectory prediction. Code is available at\nhttps://ldtho.github.io/MGIoU","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T06:05:39Z"}
{"aid":"http://arxiv.org/abs/2504.16449v1","title":"From Past to Present: A Survey of Malicious URL Detection Techniques,\n  Datasets and Code Repositories","summary":"Malicious URLs persistently threaten the cybersecurity ecosystem, by either\ndeceiving users into divulging private data or distributing harmful payloads to\ninfiltrate host systems. Gaining timely insights into the current state of this\nongoing battle holds significant importance. However, existing reviews exhibit\n4 critical gaps: 1) Their reliance on algorithm-centric taxonomies obscures\nunderstanding of how detection approaches exploit specific modal information\nchannels; 2) They fail to incorporate pivotal LLM/Transformer-based defenses;\n3) No open-source implementations are collected to facilitate benchmarking; 4)\nInsufficient dataset coverage.This paper presents a comprehensive review of\nmalicious URL detection technologies, systematically analyzing methods from\ntraditional blacklisting to advanced deep learning approaches (e.g.\nTransformer, GNNs, and LLMs). Unlike prior surveys, we propose a novel\nmodality-based taxonomy that categorizes existing works according to their\nprimary data modalities (URL, HTML, Visual, etc.). This hierarchical\nclassification enables both rigorous technical analysis and clear understanding\nof multimodal information utilization. Furthermore, to establish a profile of\naccessible datasets and address the lack of standardized benchmarking (where\ncurrent studies often lack proper baseline comparisons), we curate and analyze:\n1) publicly available datasets (2016-2024), and 2) open-source implementations\nfrom published works(2013-2025). Then, we outline essential design principles\nand architectural frameworks for product-level implementations. The review\nconcludes by examining emerging challenges and proposing actionable directions\nfor future research. We maintain a GitHub repository for ongoing curating\ndatasets and open-source implementations:\nhttps://github.com/sevenolu7/Malicious-URL-Detection-Open-Source/tree/master.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-23T06:23:18Z"}
{"aid":"http://arxiv.org/abs/2504.16454v1","title":"Killing Two Birds with One Stone: Unifying Retrieval and Ranking with a\n  Single Generative Recommendation Model","summary":"In recommendation systems, the traditional multi-stage paradigm, which\nincludes retrieval and ranking, often suffers from information loss between\nstages and diminishes performance. Recent advances in generative models,\ninspired by natural language processing, suggest the potential for unifying\nthese stages to mitigate such loss. This paper presents the Unified Generative\nRecommendation Framework (UniGRF), a novel approach that integrates retrieval\nand ranking into a single generative model. By treating both stages as sequence\ngeneration tasks, UniGRF enables sufficient information sharing without\nadditional computational costs, while remaining model-agnostic. To enhance\ninter-stage collaboration, UniGRF introduces a ranking-driven enhancer module\nthat leverages the precision of the ranking stage to refine retrieval\nprocesses, creating an enhancement loop. Besides, a gradient-guided adaptive\nweighter is incorporated to dynamically balance the optimization of retrieval\nand ranking, ensuring synchronized performance improvements. Extensive\nexperiments demonstrate that UniGRF significantly outperforms existing models\non benchmark datasets, confirming its effectiveness in facilitating information\ntransfer. Ablation studies and further experiments reveal that UniGRF not only\npromotes efficient collaboration between stages but also achieves synchronized\noptimization. UniGRF provides an effective, scalable, and compatible framework\nfor generative recommendation systems.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-23T06:43:54Z"}
{"aid":"http://arxiv.org/abs/2504.16455v1","title":"Cross Paradigm Representation and Alignment Transformer for Image\n  Deraining","summary":"Transformer-based networks have achieved strong performance in low-level\nvision tasks like image deraining by utilizing spatial or channel-wise\nself-attention. However, irregular rain patterns and complex geometric overlaps\nchallenge single-paradigm architectures, necessitating a unified framework to\nintegrate complementary global-local and spatial-channel representations. To\naddress this, we propose a novel Cross Paradigm Representation and Alignment\nTransformer (CPRAformer). Its core idea is the hierarchical representation and\nalignment, leveraging the strengths of both paradigms (spatial-channel and\nglobal-local) to aid image reconstruction. It bridges the gap within and\nbetween paradigms, aligning and coordinating them to enable deep interaction\nand fusion of features. Specifically, we use two types of self-attention in the\nTransformer blocks: sparse prompt channel self-attention (SPC-SA) and spatial\npixel refinement self-attention (SPR-SA). SPC-SA enhances global channel\ndependencies through dynamic sparsity, while SPR-SA focuses on spatial rain\ndistribution and fine-grained texture recovery. To address the feature\nmisalignment and knowledge differences between them, we introduce the Adaptive\nAlignment Frequency Module (AAFM), which aligns and interacts with features in\na two-stage progressive manner, enabling adaptive guidance and complementarity.\nThis reduces the information gap within and between paradigms. Through this\nunified cross-paradigm dynamic interaction framework, we achieve the extraction\nof the most valuable interactive fusion information from the two paradigms.\nExtensive experiments demonstrate that our model achieves state-of-the-art\nperformance on eight benchmark datasets and further validates CPRAformer's\nrobustness in other image restoration tasks and downstream applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T06:44:46Z"}
{"aid":"http://arxiv.org/abs/2504.16456v1","title":"A measure-theoretic expansion exponent","summary":"The expansion exponent (or expansion constant) for maps was introduced by\nSchreiber in \\cite{s}. In this paper, we introduce the analogous exponent for\nmeasures. We shall prove the following results: The expansion exponent of a\nmeasurable maps is equal to the minimum of the expansion exponent taken over\nthe Borel probability measures. In particular, a map expands small distances\n(in the sense of Reddy \\cite{r}) if and only if every Borel probability has\npositive expansion exponent. Any nonatomic invariant measure with positive\nexpansion exponent is positively expansive in the sense of \\cite{m}. For\nergodic invariant measures, the Kolmogorov-Sinai entropy is bounded below by\nthe product of the expansion exponent and the measure upper capacity. As a\nconsequence, any ergodic invariant measure with both positive upper capacity\nand positive expansion exponent must have positive entropy.","main_category":"math.DS","categories":"math.DS","published":"2025-04-23T06:50:53Z"}
{"aid":"http://arxiv.org/abs/2504.16460v1","title":"T-VEC: A Telecom-Specific Vectorization Model with Enhanced Semantic\n  Understanding via Deep Triplet Loss Fine-Tuning","summary":"The specialized vocabulary and complex concepts of the telecommunications\nindustry present significant challenges for standard Natural Language\nProcessing models. Generic text embeddings often fail to capture\ntelecom-specific semantics, hindering downstream task performance. We introduce\nT-VEC (Telecom Vectorization Model), a novel embedding model tailored for the\ntelecom domain through deep fine-tuning. Developed by NetoAI, T-VEC is created\nby adapting the state-of-the-art gte-Qwen2-1.5B-instruct model using a triplet\nloss objective on a meticulously curated, large-scale dataset of\ntelecom-specific data. Crucially, this process involved substantial\nmodification of weights across 338 layers of the base model, ensuring deep\nintegration of domain knowledge, far exceeding superficial adaptation\ntechniques. We quantify this deep change via weight difference analysis. A key\ncontribution is the development and open-sourcing (MIT License) of the first\ndedicated telecom-specific tokenizer, enhancing the handling of industry\njargon. T-VEC achieves a leading average MTEB score (0.825) compared to\nestablished models and demonstrates vastly superior performance (0.9380 vs.\nless than 0.07) on our internal telecom-specific triplet evaluation benchmark,\nindicating an exceptional grasp of domain-specific nuances, visually confirmed\nby improved embedding separation. This work positions NetoAI at the forefront\nof telecom AI innovation, providing the community with a powerful, deeply\nadapted, open-source tool.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T07:10:37Z"}
{"aid":"http://arxiv.org/abs/2504.16463v1","title":"Multiplicative Spanners in Minor-Free Graphs","summary":"In FOCS 2017, Borradaille, Le, and Wulff-Nilsen addressed a long-standing\nopen problem by proving that minor-free graphs have light spanners.\nSpecifically, they proved that every $K_h$-minor-free graph has a\n$(1+\\epsilon)$-spanner of lightness $O_{\\epsilon}(h \\sqrt{\\log h})$, hence\nconstant when $h$ and $\\epsilon$ are regarded as constants.\n  We extend this result by showing that a more expressive size/stretch tradeoff\nis available. Specifically: for any positive integer $k$, every $n$-node,\n$K_h$-minor-free graph has a $(2k-1)$-spanner with sparsity\n\\[O\\left(h^{\\frac{2}{k+1}} \\cdot \\text{polylog } h\\right),\\] and a\n$(1+\\epsilon)(2k-1)$-spanner with lightness\n\\[O_{\\epsilon}\\left(h^{\\frac{2}{k+1}} \\cdot \\text{polylog } h \\right).\\] We\nfurther prove that this exponent $\\frac{2}{k+1}$ is best possible, assuming the\ngirth conjecture. At a technical level, our proofs leverage the recent\nimprovements by Postle (2020) to the remarkable density increment theorem for\nminor-free graphs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T07:22:24Z"}
{"aid":"http://arxiv.org/abs/2504.16464v1","title":"ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree\n  and Visual Guidance","summary":"While recent advancements in robotic manipulation video synthesis have shown\npromise, significant challenges persist in ensuring effective\ninstruction-following and achieving high visual quality. Recent methods, like\nRoboDreamer, utilize linguistic decomposition to divide instructions into\nseparate lower-level primitives, conditioning the world model on these\nprimitives to achieve compositional instruction-following. However, these\nseparate primitives do not consider the relationships that exist between them.\nFurthermore, recent methods neglect valuable visual guidance, including depth\nand semantic guidance, both crucial for enhancing visual quality. This paper\nintroduces ManipDreamer, an advanced world model based on the action tree and\nvisual guidance. To better learn the relationships between instruction\nprimitives, we represent the instruction as the action tree and assign\nembeddings to tree nodes, each instruction can acquire its embeddings by\nnavigating through the action tree. The instruction embeddings can be used to\nguide the world model. To enhance visual quality, we combine depth and semantic\nguidance by introducing a visual guidance adapter compatible with the world\nmodel. This visual adapter enhances both the temporal and physical consistency\nof video generation. Based on the action tree and visual guidance, ManipDreamer\nsignificantly boosts the instruction-following ability and visual quality.\nComprehensive evaluations on robotic manipulation benchmarks reveal that\nManipDreamer achieves large improvements in video quality metrics in both seen\nand unseen tasks, with PSNR improved from 19.55 to 21.05, SSIM improved from\n0.7474 to 0.7982 and reduced Flow Error from 3.506 to 3.201 in unseen tasks,\ncompared to the recent RoboDreamer model. Additionally, our method increases\nthe success rate of robotic manipulation tasks by 2.5% in 6 RLbench tasks on\naverage.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-23T07:23:41Z"}
{"aid":"http://arxiv.org/abs/2504.16475v1","title":"The Dodecacopter: a Versatile Multirotor System of Dodecahedron-Shaped\n  Modules","summary":"With the promise of greater safety and adaptability, modular reconfigurable\nuncrewed air vehicles have been proposed as unique, versatile platforms holding\nthe potential to replace multiple types of monolithic vehicles at once.\nState-of-the-art rigidly assembled modular vehicles are generally\ntwo-dimensional configurations in which the rotors are coplanar and assume the\nshape of a \"flight array\". We introduce the Dodecacopter, a new type of modular\nrotorcraft where all modules take the shape of a regular dodecahedron, allowing\nthe creation of richer sets of configurations beyond flight arrays. In\nparticular, we show how the chosen module design can be used to create\nthree-dimensional and fully actuated configurations. We justify the relevance\nof these types of configurations in terms of their structural and actuation\nproperties with various performance indicators. Given the broad range of\nconfigurations and capabilities that can be achieved with our proposed design,\nwe formulate tractable optimization programs to find optimal configurations\ngiven structural and actuation constraints. Finally, a prototype of such a\nvehicle is presented along with results of performed flights in multiple\nconfigurations.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T07:38:00Z"}
{"aid":"http://arxiv.org/abs/2504.16481v1","title":"Estimating Random-Walk Probabilities in Directed Graphs","summary":"We study discounted random walks in a directed graph. In each vertex, the\nwalk will either terminate with some probability $\\alpha$, or continue to a\nrandom out-neighbor. We are interested in the probability $\\pi(s,t)$ that such\na random walk starting in $s$ ends in $t$. We wish to, with constant\nprobability, estimate $\\pi(s, t)$ within a constant relative error, unless\n$\\pi(s, t) < \\delta$ for some given threshold $\\delta$.\n  The current status is as follows. Algorithms with worst-case running time\n$\\tilde O(m)$ and $O(1/\\delta)$ are known. A more complicated algorithm is\nknown, which does not perform better in the worst case, but for the average\nrunning time over all $n$ possible targets $t$, it achieves an alternative\nbound of $O(\\sqrt{d/\\delta})$. All the above algorithms assume query access to\nthe adjacency list of a node.\n  On the lower bound side, the best-known lower bound for the worst case is\n$\\Omega(n^{1/2}m^{1/4})$ with $\\delta \\leq 1/(n^{1/2}m^{1/4})$, and for the\naverage case it is $\\Omega(\\sqrt{n})$ with $\\delta \\leq 1/n$. This leaves\nsubstantial polynomial gaps in both cases.\n  In this paper, we show that the above upper bounds are tight across all\nparameters $n$, $m$ and $\\delta$. We show that the right bound is\n$\\tilde\\Theta(\\min\\{m, 1/\\delta\\})$ for the worst case, and\n$\\tilde\\Theta(\\min\\{m, \\sqrt{d/\\delta}, 1/\\delta\\})$ for the average case.\n  We also consider some additional graph queries from the literature. One\nallows checking whether there is an edge from $u$ to $v$ in constant time.\nAnother allows access to the adjacency list of $u$ sorted by out-degree. We\nprove that none of these access queries help in the worst case, but if we have\nboth of them, we get an average-case bound of $\\tilde\n\\Theta(\\min\\{m,\\sqrt{d/\\delta}, (1/\\delta)^{2/3}\\})$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T07:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.16485v1","title":"On Developers' Self-Declaration of AI-Generated Code: An Analysis of\n  Practices","summary":"AI code generation tools have gained significant popularity among developers,\nwho use them to assist in software development due to their capability to\ngenerate code. Existing studies mainly explored the quality, e.g., correctness\nand security, of AI-generated code, while in real-world software development,\nthe prerequisite is to distinguish AI-generated code from human-written code,\nwhich emphasizes the need to explicitly declare AI-generated code by\ndevelopers. To this end, this study intends to understand the ways developers\nuse to self-declare AI-generated code and explore the reasons why developers\nchoose to self-declare or not. We conducted a mixed-methods study consisting of\ntwo phases. In the first phase, we mined GitHub repositories and collected 613\ninstances of AI-generated code snippets. In the second phase, we conducted a\nfollow-up industrial survey, which received 111 valid responses. Our research\nrevealed the practices followed by developers to self-declare AI-generated\ncode. Most practitioners (76.6%) always or sometimes self-declare AI-generated\ncode. In contrast, other practitioners (23.4%) noted that they never\nself-declare AI-generated code. The reasons for self-declaring AI-generated\ncode include the need to track and monitor the code for future review and\ndebugging, and ethical considerations. The reasons for not self-declaring\nAI-generated code include extensive modifications to AI-generated code and the\ndevelopers' perception that self-declaration is an unnecessary activity. We\nfinally provided guidelines for practitioners to self-declare AI-generated\ncode, addressing ethical and code quality concerns.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-23T07:52:39Z"}
{"aid":"http://arxiv.org/abs/2504.16500v1","title":"Strongly inhomogeneous spin dynamics induced by ultrashort laser pulses\n  with a gradient intensity profile","summary":"The optical pump-probe technique is a common tool for investigation of\nultrafast spin dynamics, which usually utilizes single-diode detection\naveraging the dynamics over the pumped area. Using ultrafast imaging technique,\nwe show experimentally that a femtosecond laser pulse with a gradient\ndistribution of intensity efficiently excites strongly inhomogeneous spin\ndynamics on spatial scales much smaller than the pump spot size. The mechanism\nresponsible for the inhomogeneous distribution is based on temperature\ngradients and corresponds to a sign change of the torque derivative in\ndifferent areas of the pump. We argue that the observed phenomenon is general\nfor the systems with competitive magnetic anisotropies. Overlooking this effect\nin the majority of pump-probe experiments may result in a dramatic\nunderestimation of the live time and amplitude of the laser-induced spin\ndynamics.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-23T08:23:54Z"}
{"aid":"http://arxiv.org/abs/2504.16501v1","title":"Dynamic Time-aware Continual User Representation Learning","summary":"Traditional user modeling (UM) approaches have primarily focused on designing\nmodels for a single specific task, but they face limitations in generalization\nand adaptability across various tasks. Recognizing these challenges, recent\nstudies have shifted towards continual learning (CL)-based universal user\nrepresentation learning aiming to develop a single model capable of handling\nmultiple tasks. Despite advancements, existing methods are in fact evaluated\nunder an unrealistic scenario that does not consider the passage of time as\ntasks progress, which overlooks newly emerged items that may change the item\ndistribution of previous tasks. In this paper, we introduce a practical\nevaluation scenario on which CL-based universal user representation learning\napproaches should be evaluated, which takes into account the passage of time as\ntasks progress. Then, we propose a novel framework Dynamic Time-aware continual\nuser representation learner, named DITTO, designed to alleviate catastrophic\nforgetting despite continuous shifts in item distribution, while also allowing\nthe knowledge acquired from previous tasks to adapt to the current shifted item\ndistribution. Through our extensive experiments, we demonstrate the superiority\nof DITTO over state-of-the-art methods under a practical evaluation scenario.\nOur source code is available at\nhttps://github.com/seungyoon-Choi/DITTO_official.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T08:23:59Z"}
{"aid":"http://arxiv.org/abs/2504.16509v1","title":"Solvability of the ${\\rm SK}_1$-analog of the orthogonal groups","summary":"We prove the dilation principle for the relative Dickson-Siegel-Eichler-Roy\n(DSER) elementary orthogonal group and using the dilation principle we prove\nthe Quillen's analog of the local-global principle for the group. Applying the\nrelative local-global principle, we prove the solvability and nilpotency of the\n${\\rm SK_1}$-analog of the orthogonal groups and study the homotopy and\ncommutativity principle for odd elementary orthogonal groups.","main_category":"math.KT","categories":"math.KT","published":"2025-04-23T08:36:07Z"}
{"aid":"http://arxiv.org/abs/2504.16517v1","title":"Gravitational Equilibrium with Steady Flow and Relativistic Local\n  Thermodynamics","summary":"A relativistic self-gravitating equilibrium system with steady flow as well\nas spherical symmetry is discovered. The energy-momentum tensor contains the\ncontribution of a current related to the flow and the metric tensor does an\noff-diagonal component to balance with the flow momentum. The presence of the\noff-diagonal component of the metric implies the radial motion of the reference\nframe, which gives rise to a problem how the relativistic effect is included in\nthermodynamic observables for such a general relativistic system. This problem\nis solved by taking an instantaneously rest frame in which geometric\nthermodynamic observables read as previously and giving them the special\nrelativistic effect emerged from the inverse transformation to the original\nframe pointwise. The solution of the thermodynamic observables in accord with\nthe laws of thermodynamics and the theory of relativity is presented. Finally\nthe relativistic structure equations for the equilibrium are derived, from\nwhich the general relativistic Poisson equation as well as the heat conduction\none are developed exactly.","main_category":"gr-qc","categories":"gr-qc,astro-ph.SR,hep-ph,hep-th","published":"2025-04-23T08:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.16522v1","title":"On Bell numbers of type $D$","summary":"In this paper, we will introduce Bell numbers $D(n)$ of type $D$ as an\nanalogue to the classical Bell numbers related to all the partitions of the set\n$[n]$. Then based on a signed set partition of type $D$, we will construct the\nrecurrence relations of Bell numbers $D(n)$. In addition, we deduce the\nexponential generating function for $D(n)$. Finally, we will provide an\nexplicit formula for $D(n)$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-23T08:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.16534v1","title":"Partitioning of multiple brain metastases improves dose gradients in\n  single-isocenter radiosurgery","summary":"Background: A growing number of cancer patients with brain metastases can\nbenefit from stereotactic radiosurgery (SRS) thanks to recent advances in\nsystemic therapies. With an increasing patient load, single-isocenter\ntreatments on widely available C-arm linear accelerators are an attractive\noption. However, the planning of such treatments is challenging for\nmulti-target cases due to the island blocking problem, which occurs when the\nmulti-leaf collimator cannot conform to all targets simultaneously.\n  Purpose: We propose a multi-target partitioning algorithm that mitigates\nexcessive exposure of normal tissue caused by the island blocking problem.\n  Methods: The algorithm divides (partitions) the set of targets into subsets\nto treat with separate arc passes, optimizing both subsets and collimator\nangles to minimize island blocking. The algorithm was incorporated into a fully\nautomated treatment planning script and evaluated on 20 simulated patient\ncases, each with 10 brain metastases and 21 Gy prescriptions. It was also\nretrospectively evaluated on six clinical cases.\n  Results: Partitioning significantly improved the gradient index, global\nefficiency index, and brain V12Gy compared to simultaneous treatment of all\nmetastases. For example, the average gradient index improved from 5.9 to 3.3,\nglobal efficiency index from 0.32 to 0.46, and normal brain V12Gy from 49 cm3\nto 26 cm3 between 3 and 9 arcs. The proposed algorithm outperformed baselines\nin utilizing a limited number of arcs. All target partitioning strategies\nincreased the total number of monitor units (MUs).\n  Conclusions: The dose gradient in single-isocenter VMAT plans can be\nsubstantially improved by treating a smaller subset of metastases at a time.\nThis requires more MUs and arcs, implying a trade-off between delivery time and\nplan quality which can be explored using the algorithm proposed in this paper.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-23T09:02:57Z"}
{"aid":"http://arxiv.org/abs/2504.16556v1","title":"How Irrationality Shapes Nash Equilibria: A Prospect-Theoretic\n  Perspective","summary":"Noncooperative games with uncertain payoffs have been classically studied\nunder the expected-utility theory framework, which relies on the strong\nassumption that agents behave rationally. However, simple experiments on human\ndecision makers found them to be not fully rational, due to their subjective\nrisk perception. Prospect theory was proposed as an empirically-grounded model\nto incorporate irrational behaviours into game-theoretic models. But, how\nprospect theory shapes the set of Nash equilibria when considering irrational\nagents, is still poorly understood. To this end, we study how prospect\ntheoretic transformations may generate new equilibria while eliminating\nexisting ones. Focusing on aggregative games, we show that capturing users'\nirrationality can preserve symmetric equilibria while causing the vanishing of\nasymmetric equilibria. Further, there exist value functions which map\nuncountable sets of equilibria in the expected-utility maximization framework\nto finite sets. This last result may shape some equilibrium selection theories\nfor human-in-the-loop systems where computing a single equilibrium is\ninsufficient and comparison of equilibria is needed.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T09:33:07Z"}
{"aid":"http://arxiv.org/abs/2504.16560v1","title":"On existence of spatially regular strong solutions for a class of\n  transport equations","summary":"The paper considers existence of spatially regular solutions for a class of\nlinear Boltzmann transport equations. The related transport problem is an\n(initial) inflow boundary value problem. This problem is characteristic with\nvariable multiplicity, that is, the rank of the boundary matrix (here a scalar)\nis not constant on the boundary. It is known that for these types of (initial)\nboundary value problems the full higher order Sobolev regularity cannot\ngenerally be established. In this paper we present Sobolev regularity results\nfor solutions of linear Boltzmann transport problems when the data belongs to\nappropriate anisotropic Sobolev spaces whose elements are zero on the inflow\nand characteristic parts of the boundary.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T09:39:32Z"}
{"aid":"http://arxiv.org/abs/2504.16572v1","title":"Bridging Data Gaps and Building Knowledge Networks in Indian Football\n  Analytics","summary":"The global rise of football analytics has rapidly transformed how clubs make\nstrategic decisions. However, in India, the adoption of analytics remains\nconstrained by institutional resistance, infrastructural limitations, and\ncultural barriers -- challenges that grassroots innovation and low-cost data\nsolutions have the potential to overcome. Despite the growing popularity of the\nIndian Super League, resource scarcity and fragmented governance continue to\nhinder the widespread adoption and impact of analytics. This mixed-methods\nstudy explores how informal, decentralised analytics communities -- comprising\namateur analysts and Twitter-based \"data sleuths\" -- navigate these constraints\nthrough peer mentorship and grassroots innovation. Drawing on extensive digital\nethnography, participant observation, and interviews, the study illustrates how\nthese informal networks mitigate data scarcity, limited digital infrastructure,\nand institutional indifference while fostering skill development and\nprofessional growth. Building on these insights, the paper proposes HCI\ninterventions such as decentralised knowledge platforms to facilitate\nstructured, cross-border peer mentorship and low-cost data solutions --\nincluding AI-assisted player tracking and mobile analytics dashboards -- rooted\nin principles of frugal innovation. These interventions aim to bridge the data\ndivide, support inclusive technical engagement in sport, and enhance\nanalytics-driven decision-making in resource-constrained environments. This\npaper contributes to HCIxB's focus on cross-border collaboration by\nhighlighting how community-driven technological adaptation in the Global South\ncan foster meaningful participation, skill-building, and long-term\nsustainability through informal learning networks and scalable,\ncontext-sensitive tools.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T09:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.16575v1","title":"Impact of a tunneling particle on the quantum state of a barrier:\n  two-particle wave-packet model","summary":"We investigate the scattering of two distinguishable particles with unequal\nmasses and a mutual short-range interaction with the aim of quantifying the\nimpact of a tunneling ``projectile'' particle on the quantum mechanical state\nof the ``barrier'' particle. We find that the states of the barrier particle\nafter the tunneling or reflection of the projectile are displaced by a finite\ndistance that is given by the derivative of the phase of the transmission or\nreflection amplitudes multiplied by factors dependent on particles' masses,\nrespectively. We demonstrate these results on a numerical example with a\nresonant interaction between a projectile and barrier. Our work demonstrates\nphysical implication of the concept of phase time delay in the form of finite\ndisplacements of particles that are, in principle, experimentally measurable.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-04-23T09:53:32Z"}
{"aid":"http://arxiv.org/abs/2504.16579v1","title":"Optimization Framework for Reducing Mid-circuit Measurements and Resets","summary":"The paper addresses the optimization of dynamic circuits in quantum\ncomputing, with a focus on reducing the cost of mid-circuit measurements and\nresets. We extend the probabilistic circuit model (PCM) and implement an\noptimization framework that targets both mid-circuit measurements and resets.\nTo overcome the limitation of the prior PCM-based pass, where optimizations are\nonly possible on pure single-qubit states, we incorporate circuit synthesis to\nenable optimizations on multi-qubit states. With a parameter $n_{pcm}$, our\nframework balances optimization level against resource usage.We evaluate our\nframework using a large dataset of randomly generated dynamic circuits.\nExperimental results demonstrate that our method is highly effective in\nreducing mid-circuit measurements and resets. In our demonstrative example,\nwhen applying our optimization framework to the Bernstein-Vazirani algorithm\nafter employing qubit reuse, we significantly reduce its runtime overhead by\nremoving all of the resets.","main_category":"quant-ph","categories":"quant-ph,cs.PL,cs.SE","published":"2025-04-23T10:01:00Z"}
{"aid":"http://arxiv.org/abs/2504.16586v1","title":"Learning Switchable Priors for Neural Image Compression","summary":"Neural image compression (NIC) usually adopts a predefined family of\nprobabilistic distributions as the prior of the latent variables, and meanwhile\nrelies on entropy models to estimate the parameters for the probabilistic\nfamily. More complex probabilistic distributions may fit the latent variables\nmore accurately, but also incur higher complexity of the entropy models,\nlimiting their practical value. To address this dilemma, we propose a solution\nto decouple the entropy model complexity from the prior distributions. We use a\nfinite set of trainable priors that correspond to samples of the parametric\nprobabilistic distributions. We train the entropy model to predict the index of\nthe appropriate prior within the set, rather than the specific parameters.\nSwitching between the trained priors further enables us to embrace a skip mode\ninto the prior set, which simply omits a latent variable during the entropy\ncoding. To demonstrate the practical value of our solution, we present a\nlightweight NIC model, namely FastNIC, together with the learning of switchable\npriors. FastNIC obtains a better trade-off between compression efficiency and\ncomputational complexity for neural image compression. We also implanted the\nswitchable priors into state-of-the-art NIC models and observed improved\ncompression efficiency with a significant reduction of entropy coding\ncomplexity.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-23T10:06:58Z"}
{"aid":"http://arxiv.org/abs/2504.16587v1","title":"Spin polarization as a probe of the QCD critical point","summary":"Spin polarization is a novel method for probing the rotational properties of\nthe quark-gluon plasma (QGP) produced in relativistic heavy-ion collisions. In\nthis work, we investigate the effective transport and thermodynamic\ncoefficients in non-central O+O light-ion collisions, considering a parton\ndistribution function that incorporates the spin polarization induced by\nthermal vorticity during the collision. Using a kinetic theory approach, we\nfind that while the speed of sound squared ($c_s^2$) remains largely unaffected\nby spin polarization, the specific shear viscosity ($\\eta/s$), specific bulk\nviscosity ($\\zeta/s$), and mean free path ($\\lambda$) are significantly\nmodified.\n  Notably, when spin polarization is taken into account, both $c_s^2 $ and\n$\\zeta/s$ exhibit a non-monotonic dependence on collision energy, with an\ninflection point around $\\sqrt{s_{NN}} = 27 $~GeV, corresponding to an average\nparton chemical potential of $\\langle\\mu_p\\rangle = 0.021 $~GeV. This\nnon-monotonic behavior suggests that incorporating spin polarization into\ntheoretical calculations could provide an effective probe for locating the\ncritical point of the QCD phase transition.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-23T10:08:31Z"}
{"aid":"http://arxiv.org/abs/2504.16600v1","title":"3D-1D modelling of cranial plate heating induced by low or medium\n  frequency magnetic fields","summary":"Safety assessment of patients with one-dimensionally structured passive\nimplants, like cranial plates or stents, exposed to low or medium frequency\nmagnetic fields, like those generated in magnetic resonance imaging or magnetic\nhyperthermia, can be challenging, because of the different length scales of the\nimplant and the human body. Most of the methods used to estimate the heating\ninduced near such implants neglect the presence of the metallic materials\nwithin the body, modeling the metal as thermal seeds. To overcome this\nlimitation, a novel numerical approach that solves three-dimensional and\none-dimensional coupled problems is proposed. This method leads to improved\nresults by modelling the thermal diffusion through the highly conductive\nmetallic implants. A comparison of the proposed method predictions with\nmeasurements performed on a cranial plate exposed to the magnetic field\ngenerated by a gradient coil system for magnetic resonance imaging is\npresented, showing an improved accuracy up to 25 % with respect to the method\nbased on thermal seeds. The proposed method is finally applied to a magnetic\nhyperthermia case study in which a patient with a cranial plate is exposed to\nthe magnetic field generated by a collar-type magnetic hyperthermia applicator\nfor neck tumour treatment, predicting a temperature increase in proximity of\nthe implant that is 10 % lower than the one overestimated by relying on thermal\nseeds.","main_category":"cs.CE","categories":"cs.CE,cs.NA,math.NA,physics.med-ph","published":"2025-04-23T10:29:53Z"}
{"aid":"http://arxiv.org/abs/2504.16615v1","title":"Algorithmic Mirror: Designing an Interactive Tool to Promote\n  Self-Reflection for YouTube Recommendations","summary":"Big Data analytics and Artificial Intelligence systems derive non-intuitive\nand often unverifiable inferences about individuals' behaviors, preferences,\nand private lives. Drawing on diverse, feature-rich datasets of unpredictable\nvalue, these systems erode the intuitive connection between our actions and how\nwe are perceived, diminishing control over our digital identities. While\nExplainable Artificial Intelligence scholars have attempted to explain the\ninner workings of algorithms, their visualizations frequently overwhelm\nend-users with complexity. This research introduces 'hypothetical inference', a\nnovel approach that uses language models to simulate how algorithms might\ninterpret users' digital footprints and infer personal characteristics without\nrequiring access to proprietary platform algorithms. Through empirical studies\nwith fourteen adult participants, we identified three key design opportunities\nto foster critical algorithmic literacy: (1) reassembling scattered digital\nfootprints into a unified map, (2) simulating algorithmic inference through\nLLM-generated interpretations, and (3) incorporating temporal dimensions to\nvisualize evolving patterns. This research lays the groundwork for tools that\ncan help users recognize the influence of data on platforms and develop greater\nautonomy in increasingly algorithm-mediated digital environments.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T11:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.16616v1","title":"EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for\n  Hybrid Event Stream Perception","summary":"Event cameras, with microsecond temporal resolution and high dynamic range\n(HDR) characteristics, emit high-speed event stream for perception tasks.\nDespite the recent advancement in GNN-based perception methods, they are prone\nto use straightforward pairwise connectivity mechanisms in the pure Euclidean\nspace where they struggle to capture long-range dependencies and fail to\neffectively characterize the inherent hierarchical structures of non-uniformly\ndistributed event stream. To this end, in this paper we propose a novel\napproach named EHGCN, which is a pioneer to perceive event stream in both\nEuclidean and hyperbolic spaces for event vision. In EHGCN, we introduce an\nadaptive sampling strategy to dynamically regulate sampling rates, retaining\ndiscriminative events while attenuating chaotic noise. Then we present a Markov\nVector Field (MVF)-driven motion-aware hyperedge generation method based on\nmotion state transition probabilities, thereby eliminating cross-target\nspurious associations and providing critically topological priors while\ncapturing long-range dependencies between events. Finally, we propose a\nEuclidean-Hyperbolic GCN to fuse the information locally aggregated and\nglobally hierarchically modeled in Euclidean and hyperbolic spaces,\nrespectively, to achieve hybrid event perception. Experimental results on event\nperception tasks such as object detection and recognition validate the\neffectiveness of our approach.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T11:01:03Z"}
{"aid":"http://arxiv.org/abs/2504.16623v1","title":"Censored lifespans in a double-truncated sample: Maximum likelihood\n  inference for the exponential distribution","summary":"The analysis of a truncated sample can be hindered by censoring. Survival\ninformation may be lost to follow-up or the birthdate may be missing. The data\ncan still be modeled as a truncated point process and it is close to a Poisson\nprocess, in the Hellinger distance, as long as the sample is small relative to\nthe population. We assume an exponential distribution for the lifespan, derive\nthe likelihood and profile out the unobservable sample size. Identification of\nthe exponential parameter is shown, together with consistency and asymptotic\nnormality of its M-estimator. Even though the estimator sequence is indexed in\nthe sample size, both the point estimator and the standard error are\nobservable. Enterprise lifespans in Germany constitute our example.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-23T11:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.16641v1","title":"$H^1$ local exact controllability of some one-dimensional bilinear\n  Schr{Ã¶}dinger equations","summary":"The local exact controllability of the one-dimensional bilinear\nSchr{\\\"o}dinger equation with Dirichlet boundary conditions has been\nextensively studied in subspaces of H 3 since the seminal work of K. Beauchard.\nOur first objective is to revisit this result and establish the controllability\nin H 1 0 for suitable discontinuous control potentials. In the second part, we\nconsider the equation in the presence of periodic boundary conditions and a\nconstant magnetic field. We prove the local exact controllability of periodic H\n1 -states, thanks to a Zeeman-type effect induced by the magnetic field which\ndecouples the resonant spectrum. Finally, we discuss open problems and partial\nresults for the Neumann case and the harmonic oscillator.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T12:00:07Z"}
{"aid":"http://arxiv.org/abs/2504.16647v1","title":"Medium-induced coherent gluon radiation for $2\\to 2$ processes with\n  general kinematics","summary":"High-energy proton-nucleus (pA) collisions have provided various clues for\nthe role of cold nuclear matter effects in hadron production. In particular,\nmultiple rescatterings of an incoming parton by the nuclear target are known to\ninduce the radiation of many soft gluons, with those having a long formation\ntime leading to the modification of hadron production rates due to fully\ncoherent energy loss (FCEL). Here we present a recently derived formula for the\ninduced single soft gluon radiation spectrum beyond leading logarithmic\naccuracy, whose main features are demonstrated with the example of $q\\, g \\to\nq\\, g$ scattering.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-23T12:07:39Z"}
{"aid":"http://arxiv.org/abs/2504.16656v1","title":"Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning","summary":"We present Skywork R1V2, a next-generation multimodal reasoning model and a\nmajor leap forward from its predecessor, Skywork R1V. At its core, R1V2\nintroduces a hybrid reinforcement learning paradigm that harmonizes\nreward-model guidance with rule-based strategies, thereby addressing the\nlong-standing challenge of balancing sophisticated reasoning capabilities with\nbroad generalization. To further enhance training efficiency, we propose the\nSelective Sample Buffer (SSB) mechanism, which effectively counters the\n``Vanishing Advantages'' dilemma inherent in Group Relative Policy Optimization\n(GRPO) by prioritizing high-value samples throughout the optimization process.\nNotably, we observe that excessive reinforcement signals can induce visual\nhallucinations--a phenomenon we systematically monitor and mitigate through\ncalibrated reward thresholds throughout the training process. Empirical results\naffirm the exceptional capability of R1V2, with benchmark-leading performances\nsuch as 62.6 on OlympiadBench, 79.0 on AIME2024, 63.6 on LiveCodeBench, and\n74.0 on MMMU. These results underscore R1V2's superiority over existing\nopen-source models and demonstrate significant progress in closing the\nperformance gap with premier proprietary systems, including Gemini 2.5 and\nOpenAI o4-mini. The Skywork R1V2 model weights have been publicly released to\npromote openness and reproducibility\nhttps://huggingface.co/Skywork/Skywork-R1V2-38B.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T12:24:10Z"}
{"aid":"http://arxiv.org/abs/2504.16666v1","title":"Anomalies in Muon-Induced Neutron Emissions from Pb","summary":"This paper analyses neutron multiplicity spectra from massive targets at\ndepths of 3, 40, 210, 583, 1166, and 4000 m.w.e. The measurements, conducted\nbetween 2001 and 2024, utilised three experimental setups with either 14 or 60\nHe-3 neutron detectors and lead (Pb) targets weighing 306, 565, or 1134 kg. The\ntotal acquisition time exceeded six years. When available, the acquired spectra\nwere compared with Monte Carlo simulations. Our data challenges the practice of\napproximating the muon-induced neutron multiplicity spectra with one power-law\nfunction $k \\times m^{-p}$, where m is the multiplicity, k is the depth-related\nparameter decreasing with overburden, and p is the slope parameter that remains\nunchanged with depth. Instead, we see the emergence of a second component. It\nis evident already in the muon-suppressed spectrum collected on the surface and\ndominates the spectra at 1166 and 4000 m.w.e. In addition, we see indications\nof a possible structure in the second component that resembles emissions of\napproximately 74, 106, 143, and 214 neutrons from the target. Since the anomaly\nvaries only slightly with depth, it is not directly correlated with the muon\nflux. We propose new underground measurements employing low-cost, large-area,\nposition-sensitive neutron counters to verify and investigate the observed\nanomalies and ascertain their origin.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-23T12:35:20Z"}
{"aid":"http://arxiv.org/abs/2504.16682v1","title":"Provable wavelet-based neural approximation","summary":"In this paper, we develop a wavelet-based theoretical framework for analyzing\nthe universal approximation capabilities of neural networks over a wide range\nof activation functions. Leveraging wavelet frame theory on the spaces of\nhomogeneous type, we derive sufficient conditions on activation functions to\nensure that the associated neural network approximates any functions in the\ngiven space, along with an error estimate. These sufficient conditions\naccommodate a variety of smooth activation functions, including those that\nexhibit oscillatory behavior. Furthermore, by considering the $L^2$-distance\nbetween smooth and non-smooth activation functions, we establish a generalized\napproximation result that is applicable to non-smooth activations, with the\nerror explicitly controlled by this distance. This provides increased\nflexibility in the design of network architectures.","main_category":"cs.LG","categories":"cs.LG,math.CA,stat.ML","published":"2025-04-23T13:02:37Z"}
{"aid":"http://arxiv.org/abs/2504.16687v1","title":"Non-uniqueness of (Stochastic) Lagrangian Trajectories for Euler\n  Equations","summary":"We are concerned with the (stochastic) Lagrangian trajectories associated\nwith Euler or Navier-Stokes equations. First, we construct solutions to the 3D\nEuler equations which dissipate kinetic energy with $C_{t,x}^{1/3-}$\nregularity, such that the associated Lagrangian trajectories are not unique.\nThe proof is based on the non-uniqueness of positive solutions to the\ncorresponding transport equations, in conjunction with the superposition\nprinciple. Second, in dimension $d\\geq2$, for any\n$1<p<2,\\frac{1}{p}+\\frac{1}{s}>1+\\frac1d$, we construct solutions to the Euler\nor Navier-Stokes equations in the space $C_tL^p\\cap L_t^1W^{1,s}$,\ndemonstrating that the associated (stochastic) Lagrangian trajectories are not\nunique. Our result is sharp in 2D in the sense that: (1) in the stochastic\ncase, for any vector field $v\\in C_tL^p$ with $p>2$, the associated stochastic\nLagrangian trajectory associated with $v$ is unique (see \\cite{KR05}); (2) in\nthe deterministic case, the LPS condition guarantees that for any weak solution\n$v\\in C_tL^p$ with $p>2$ to the Navier-Stokes equations, the associated\n(deterministic) Lagrangian trajectory is unique. Our result is also sharp in\ndimension $d\\geq2$ in the sense that for any divergence-free vector field $v\\in\nL_t^1W^{1,s}$ with $s>d$, the associated (deterministic) Lagrangian trajectory\nis unique (see \\cite{CC21}).","main_category":"math.AP","categories":"math.AP,math-ph,math.MP,math.PR","published":"2025-04-23T13:16:04Z"}
{"aid":"http://arxiv.org/abs/2504.16694v1","title":"Emergent Kagome lattice and non-Abelian lattice gauge field of\n  biexcitons in t-MoTe$_2$","summary":"Non-Abelian gauge fields, characterized by their non-commutative symmetry\ngroups, shape physical laws from the Standard Model to emergent topological\nmatter for quantum computation. Here we find that moir\\'e exciton dimers\n(biexcitons) in twisted bilayer MoTe$_2$ are governed by a genuine non-Abelian\nlattice gauge field. These dipolar-bound exciton dimers, formed on bonds of the\nhoneycomb moir\\'e superlattice, exhibit three quadrupole configurations\norganized into a Kagome lattice geometry, on which the valley-flip biexciton\nhoppings through electron-hole Coulomb exchange act as link variables of the\nnon-Abelian lattice gauge theory. The emergence of gauge structure here is a\nnew possibility for composite particles, where the moir\\'e electronic structure\nand interactions between the electron and hole constituents jointly enforce the\nunderlying geometric constraint. The quadrupole nature of biexciton further\nmakes possible local gate controls to isolate designated pathways from the\nextended lattice for exploiting consequences of non-commutative gauge structure\nincluding the genuine non-Abelian Aharonov-Bohm effect. This also provides a\nnew approach for quantum manipulation of excitonic valley qubit. We show path\ninterference on a simplest loop can deterministically transform the\ncomputational basis states into Bell states.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-23T13:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.16704v1","title":"Electronic Paddlewheels Impact the Dynamics of Superionic Conduction in\n  AgI","summary":"Solid-state ion conductors hold promise as next generation battery materials.\nTo realize their full potential, an understanding of atomic-scale ion\nconduction mechanisms is needed, including ionic and electronic degrees of\nfreedom. Molecular simulations can create such an understanding, however,\nincluding a description of electronic structure necessitates computationally\nexpensive methods that limit their application to small scales. We examine an\nalternative approach, in which neural network models are used to efficiently\nsample ionic configurations and dynamics at ab initio accuracy. Then, these\nconfigurations are used to determine electronic properties in a post-processing\nstep. We demonstrate this approach by modeling the superionic phase of AgI, in\nwhich cation diffusion is coupled to rotational motion of local electron\ndensity on the surrounding iodide ions, termed electronic paddlewheels. The\nneural network potential can capture the many-body effects of electronic\npaddlewheels on ionic dynamics, but classical force field models cannot.\nThrough an analysis rooted the generalized Langevin equation framework, we find\nthat electronic paddlewheels have a significant impact on the time-dependent\nfriction experienced by a mobile cation. Our approach will enable\ninvestigations of electronic fluctuations in materials on large length and time\nscales, and ultimately the control of ion dynamics through electronic\npaddlewheels.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.stat-mech,physics.chem-ph","published":"2025-04-23T13:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.16715v1","title":"Modeling of Experimentally Observed Two-Dimensional Precursor Solitons\n  in a Dusty Plasma by the forced Kadomtsev-Petviashvili Equation","summary":"We compare model solutions of a forced Kadomtsev-Petviashvili (fKP) equation\nwith experimental observations of dust acoustic precursor solitons excited by a\nsupersonically moving charged cylindrical object in a dusty plasma medium. The\nfKP equation is derived from a three-fluid-Poisson model of the dusty plasma\nusing the reductive perturbation technique and numerically solved for\nparameters close to the experimental investigations of cylindrical precursor\nsolitons. The fKP model solutions show excellent agreement with the\nexperimental results in reproducing the prominent geometric features of the\ntwo-dimensional solitons and closely matching the quantitative values of their\nvelocities, amplitudes, and temporal evolutions. Our findings suggest that the\nfKP equation can serve as a very realistic model to investigate the dynamics of\nprecursor solitons and can be usefully employed in practical applications such\nas space debris detection and tracking techniques that are based on\nobserving/predicting nonlinear plasma excitations induced by the debris in the\nionosphere.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-23T13:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.16720v1","title":"From Theory to Practice: Engineering Approximation Algorithms for\n  Dynamic Orientation","summary":"Dynamic graph algorithms have seen significant theoretical advancements, but\npractical evaluations often lag behind. This work bridges the gap between\ntheory and practice by engineering and empirically evaluating recently\ndeveloped approximation algorithms for dynamically maintaining graph\norientations. We comprehensively describe the underlying data structures,\nincluding efficient bucketing techniques and round-robin updates. Our\nimplementation has a natural parameter $\\lambda$, which allows for a trade-off\nbetween algorithmic efficiency and the quality of the solution. In the\nextensive experimental evaluation, we demonstrate that our implementation\noffers a considerable speedup. Using different quality metrics, we show that\nour implementations are very competitive and can outperform previous methods.\nOverall, our approach solves more instances than other methods while being up\nto 112 times faster on instances that are solvable by all methods compared.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T13:51:10Z"}
{"aid":"http://arxiv.org/abs/2504.16725v1","title":"Quantum sensing with spin defects in boron nitride nanotubes","summary":"Spin defects in semiconductors are widely investigated for various\napplications in quantum sensing. Conventional host materials such as diamond\nand hexagonal boron nitride (hBN) provide bulk or low-dimensional platforms for\noptically addressable spin systems, but often lack the structural properties\nneeded for chemical sensing. Here, we introduce a new class of quantum sensors\nbased on naturally occurring spin defects in boron nitride nanotubes (BNNTs),\nwhich combine high surface area with omnidirectional spin control, key features\nfor enhanced sensing performance. First, we present strong evidence that these\ndefects are carbon-related, akin to recently identified centers in hBN, and\ndemonstrate coherent spin control over ensembles embedded within dense,\nmicroscale BNNTs networks. Using dynamical decoupling, we enhance spin\ncoherence times by a factor exceeding 300x and implement high-resolution\ndetection of radiofrequency signals. By integrating the BNNT mesh sensor into a\nmicrofluidic platform we demonstrate chemical sensing of paramagnetic ions in\nsolution, with detectable concentrations reaching levels nearly 1000 times\nlower than previously demonstrated using comparable hBN-based systems. This\nhighly porous and flexible architecture positions BNNTs as a powerful new host\nmaterial for quantum sensing.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.mtrl-sci,physics.app-ph,physics.chem-ph","published":"2025-04-23T13:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.16729v1","title":"MEC Task Offloading in AIoT: A User-Centric DRL Model Splitting\n  Inference Scheme","summary":"With the rapid development of the Artificial Intelligence of Things (AIoT),\nmobile edge computing (MEC) becomes an essential technology underpinning AIoT\napplications. However, multi-angle resource constraints, multi-user task\ncompetition, and the complexity of task offloading decisions in dynamic MEC\nenvironments present new technical challenges. Therefore, a user-centric deep\nreinforcement learning (DRL) model splitting inference scheme is proposed to\naddress the problem. This scheme combines model splitting inference technology\nand designs a UCMS_MADDPG-based offloading algorithm to realize efficient model\nsplitting inference responses in the dynamic MEC environment with multi-angle\nresource constraints. Specifically, we formulate a joint optimization problem\nthat integrates resource allocation, server selection, and task offloading,\naiming to minimize the weighted sum of task execution delay and energy\nconsumption. We also introduce a user-server co-selection algorithm to address\nthe selection issue between users and servers. Furthermore, we design an\nalgorithm centered on user pre-decision to coordinate the outputs of continuous\nand discrete hybrid decisions, and introduce a priority sampling mechanism\nbased on reward-error trade-off to optimize the experience replay mechanism of\nthe network. Simulation results show that the proposed UCMS_MADDPG-based\noffloading algorithm demonstrates superior overall performance compared with\nother benchmark algorithms in dynamic environments.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-23T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.16733v1","title":"Identification of quasars variable over long time scales from infrared\n  surveys. Ensemble variability and structure function properties","summary":"Quasars are variable and their variability can both constrain their physical\nproperties and help to identify them. We look for ways to efficiently identify\nquasars exhibiting consistent variability over multi-year time-scales, based on\na small number of epochs. Using infrared (IR) is desirable to avoid bias\nagainst reddened objects. We compare the apparent brightness of known quasars\nthat have been observed with two IR surveys, covering up to a twenty-year\nbaseline: the Two Micron All Sky Survey (2MASS; 1997-2001) and the VISTA\nHemisphere Survey (VHS; 2009-2017). We look at the previous studies of the\nselected variable quasars to see if their variable behaviour is known and when\navailable we use multi-epoch monitoring with the Zwicky Transient Facility\n(ZTF) to obtain a measure of optical variability of individual objects. We\nbuild a sample of ~2500 quasars that show statistically significant variability\nbetween the 2MASS and VHS. About 1500 of these come from the new Quaia sample\nbased on Gaia spectra and about 1/3 of these have hardly been studied. The\nQuaia sample constitutes the main product of this work. Based on ensemble\nvariability and structure function analysis we demonstrate that the selected\nobjects in our sample are representative of the typical quasar population and\nshow behaviour, consistent with other quasar samples. Our analysis strengthens\nprevious results, for example that variability decreases with the rest-frame\nwavelength and that it exhibits peaks for certain absolute magnitudes of the\nquasars. Similarly, the structure function shows an increase in variability for\nrest-frame time lags below ~1500 d and a decrease for longer lags, just like in\nprevious studies. Our selection, even though it is based on two epochs only,\nseems to be surprisingly robust, showing up to ~11% contamination by quasars\nthat show stable non-variable behaviour in ZTF.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-23T14:04:47Z"}
{"aid":"http://arxiv.org/abs/2504.16740v1","title":"Gaussian Splatting is an Effective Data Generator for 3D Object\n  Detection","summary":"We investigate data augmentation for 3D object detection in autonomous\ndriving. We utilize recent advancements in 3D reconstruction based on Gaussian\nSplatting for 3D object placement in driving scenes. Unlike existing\ndiffusion-based methods that synthesize images conditioned on BEV layouts, our\napproach places 3D objects directly in the reconstructed 3D space with\nexplicitly imposed geometric transformations. This ensures both the physical\nplausibility of object placement and highly accurate 3D pose and position\nannotations.\n  Our experiments demonstrate that even by integrating a limited number of\nexternal 3D objects into real scenes, the augmented data significantly enhances\n3D object detection performance and outperforms existing diffusion-based 3D\naugmentation for object detection. Extensive testing on the nuScenes dataset\nreveals that imposing high geometric diversity in object placement has a\ngreater impact compared to the appearance diversity of objects. Additionally,\nwe show that generating hard examples, either by maximizing detection loss or\nimposing high visual occlusion in camera images, does not lead to more\nefficient 3D data augmentation for camera-based 3D object detection in\nautonomous driving.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T14:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.16748v1","title":"Simple Graph Contrastive Learning via Fractional-order Neural Diffusion\n  Networks","summary":"Graph Contrastive Learning (GCL) has recently made progress as an\nunsupervised graph representation learning paradigm. GCL approaches can be\ncategorized into augmentation-based and augmentation-free methods. The former\nrelies on complex data augmentations, while the latter depends on encoders that\ncan generate distinct views of the same input. Both approaches may require\nnegative samples for training. In this paper, we introduce a novel\naugmentation-free GCL framework based on graph neural diffusion models.\nSpecifically, we utilize learnable encoders governed by Fractional Differential\nEquations (FDE). Each FDE is characterized by an order parameter of the\ndifferential operator. We demonstrate that varying these parameters allows us\nto produce learnable encoders that generate diverse views, capturing either\nlocal or global information, for contrastive learning. Our model does not\nrequire negative samples for training and is applicable to both homophilic and\nheterophilic datasets. We demonstrate its effectiveness across various\ndatasets, achieving state-of-the-art performance.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T14:17:28Z"}
{"aid":"http://arxiv.org/abs/2504.16759v1","title":"Cyclic Riemannian Lie groups: description and curvatures","summary":"A cyclic Riemannian Lie group is a Lie group $G$ equipped with a\nleft-invariant Riemannian metric $h$ that satisfies $\\oint_{X,Y,Z}h([X,Y],Z)=0$\nfor any left-invariant vector fields $X,Y,Z$. The initial concept and\nexploration of these Lie groups were presented in Monatsh. Math. \\textbf{176}\n(2015), 219-239. This paper builds upon the results from the aforementioned\nstudy by providing a complete description of cyclic Riemannian Lie groups and\nan in-depth analysis of their various curvatures.","main_category":"math.DG","categories":"math.DG","published":"2025-04-23T14:32:20Z"}
{"aid":"http://arxiv.org/abs/2504.16764v1","title":"A Note on the Stability of the Dark Energy Model from Time Crystals","summary":"In this note, we investigate the stability of the dark energy model from time\ncrystals proposed in [1]. We emphasize two ingredients, the coupling of the\nscalar field to gravity, and the fact that these time crystals are on an\nexpanding FRW background, which play a crucial role in the field's dynamics.\nThe Hubble parameter, which contributes a drag term to the equations of motion,\ngrows with time until the scale factor diverges. When taken into account, these\nfactors also alleviate the stability concern of [2].","main_category":"gr-qc","categories":"gr-qc,hep-ph,hep-th","published":"2025-04-23T14:34:30Z"}
{"aid":"http://arxiv.org/abs/2504.16770v1","title":"DeBiasMe: De-biasing Human-AI Interactions with Metacognitive AIED (AI\n  in Education) Interventions","summary":"While generative artificial intelligence (Gen AI) increasingly transforms\nacademic environments, a critical gap exists in understanding and mitigating\nhuman biases in AI interactions, such as anchoring and confirmation bias. This\nposition paper advocates for metacognitive AI literacy interventions to help\nuniversity students critically engage with AI and address biases across the\nHuman-AI interaction workflows. The paper presents the importance of\nconsidering (1) metacognitive support with deliberate friction focusing on\nhuman bias; (2) bi-directional Human-AI interaction intervention addressing\nboth input formulation and output interpretation; and (3) adaptive scaffolding\nthat responds to diverse user engagement patterns. These frameworks are\nillustrated through ongoing work on \"DeBiasMe,\" AIED (AI in Education)\ninterventions designed to enhance awareness of cognitive biases while\nempowering user agency in AI interactions. The paper invites multiple\nstakeholders to engage in discussions on design and evaluation methods for\nscaffolding mechanisms, bias visualization, and analysis frameworks. This\nposition contributes to the emerging field of AI-augmented learning by\nemphasizing the critical role of metacognition in helping students navigate the\ncomplex interaction between human, statistical, and systemic biases in AI use\nwhile highlighting how cognitive adaptation to AI systems must be explicitly\nintegrated into comprehensive AI literacy frameworks.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T14:41:31Z"}
{"aid":"http://arxiv.org/abs/2504.16777v1","title":"Systemic Flakiness: An Empirical Analysis of Co-Occurring Flaky Test\n  Failures","summary":"Flaky tests produce inconsistent outcomes without code changes, creating\nmajor challenges for software developers. An industrial case study reported\nthat developers spend 1.28% of their time repairing flaky tests at a monthly\ncost of $2,250. We discovered that flaky tests often exist in clusters, with\nco-occurring failures that share the same root causes, which we call systemic\nflakiness. This suggests that developers can reduce repair costs by addressing\nshared root causes, enabling them to fix multiple flaky tests at once rather\nthan tackling them individually. This study represents an inflection point by\nchallenging the deep-seated assumption that flaky test failures are isolated\noccurrences. We used an established dataset of 10,000 test suite runs from 24\nJava projects on GitHub, spanning domains from data orchestration to job\nscheduling. It contains 810 flaky tests, which we levered to perform a\nmixed-method empirical analysis of co-occurring flaky test failures. Systemic\nflakiness is significant and widespread. We performed agglomerative clustering\nof flaky tests based on their failure co-occurrence, finding that 75% of flaky\ntests across all projects belong to a cluster, with a mean cluster size of 13.5\nflaky tests. Instead of requiring 10,000 test suite runs to identify systemic\nflakiness, we demonstrated a lightweight alternative by training machine\nlearning models based on static test case distance measures. Through manual\ninspection of stack traces, conducted independently by four authors and\nresolved through negotiated agreement, we identified intermittent networking\nissues and instabilities in external dependencies as the predominant causes of\nsystemic flakiness.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.16784v1","title":"Particles in finite volumes and a toy model of decaying neutrons","summary":"It is well-known that the momentum spectra of particles confined to finite\nspatial volumes deviate from the continuous spectra used for unconfined\nparticles. In this article, we consider real scalar particles confined to\nfinite volumes with periodic boundary conditions, such that the particles'\nspectra are discrete. We directly compute the density matrices describing the\ndecay processes $\\phi \\to \\varphi^2$ and $\\phi \\to \\varphi\\chi\\nu$, and\nsubsequently derive expressions for the decay probabilities both for confined\nand unconfined particles. The latter decay process is used as a rough toy model\nfor a neutron decaying into a proton, an electron, and an anti-electron\nneutrino. We propose that finite volume effects can have an impact on the\noutcomes of experiments measuring the neutron lifetime. In addition, our\nfindings at the toy model level suggest that taking into account possible\ninitial correlations between neutrons and their daughter particles might be\nrelevant as well.","main_category":"hep-ph","categories":"hep-ph,hep-th,nucl-ex,nucl-th,quant-ph","published":"2025-04-23T15:01:40Z"}
{"aid":"http://arxiv.org/abs/2504.16789v1","title":"MLOps Monitoring at Scale for Digital Platforms","summary":"Machine learning models are widely recognized for their strong performance in\nforecasting. To keep that performance in streaming data settings, they have to\nbe monitored and frequently re-trained. This can be done with machine learning\noperations (MLOps) techniques under supervision of an MLOps engineer. However,\nin digital platform settings where the number of data streams is typically\nlarge and unstable, standard monitoring becomes either suboptimal or too labor\nintensive for the MLOps engineer. As a consequence, companies often fall back\non very simple worse performing ML models without monitoring. We solve this\nproblem by adopting a design science approach and introducing a new monitoring\nframework, the Machine Learning Monitoring Agent (MLMA), that is designed to\nwork at scale for any ML model with reasonable labor cost. A key feature of our\nframework concerns test-based automated re-training based on a data-adaptive\nreference loss batch. The MLOps engineer is kept in the loop via key metrics\nand also acts, pro-actively or retrospectively, to maintain performance of the\nML model in the production stage. We conduct a large-scale test at a last-mile\ndelivery platform to empirically validate our monitoring framework.","main_category":"econ.EM","categories":"econ.EM,stat.AP","published":"2025-04-23T15:04:38Z"}
{"aid":"http://arxiv.org/abs/2504.16800v1","title":"Array Partitioning Based Near-Field Attitude and Location Estimation","summary":"This paper studies a passive source localization system, where a single base\nstation (BS) is employed to estimate the positions and attitudes of multiple\nmobile stations (MSs). The BS and the MSs are equipped with uniform rectangular\narrays, and the MSs are located in the near-field region of the BS array. To\navoid the difficulty of tackling the problem directly based on the near-field\nsignal model, we establish a subarray-wise far-field received signal model. In\nthis model, the entire BS array is divided into multiple subarrays to ensure\nthat each MS is in the far-field region of each BS subarray. By exploiting the\nangles of arrival (AoAs) of an MS antenna at different BS subarrays, we\nformulate the attitude and location estimation problem under the Bayesian\ninference framework. Based on the factor graph representation of the\nprobabilistic problem model, a message passing algorithm named array\npartitioning based pose and location estimation (APPLE) is developed to solve\nthis problem. An estimation-error lower bound is obtained as a performance\nbenchmark of the proposed algorithm. Numerical results demonstrate that the\nproposed APPLE algorithm outperforms other baseline methods in the accuracy of\nposition and attitude estimation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T15:20:39Z"}
{"aid":"http://arxiv.org/abs/2504.16806v1","title":"V4141 Sgr: Outflows and repeated outbursts","summary":"In this work, we analyze the ongoing brightening of the poorly studied\nsymbiotic star V4141 Sgr and examine its long-term variability. We present new\nlow-resolution spectroscopic observations of the system in its bright state and\ncombine them with multi-color photometric data from our observations, ASAS-SN,\nATLAS, and Gaia DR3. To investigate its long-term evolution, we also\nincorporate historical data, including photographic plates, constructing a\nlight curve spanning more than a century. Our analysis reveals that V4141 Sgr\nhas undergone multiple outbursts, with at least one exhibiting characteristics\ntypical of \"slow\" symbiotic novae. The current outburst is characterized by the\nejection of optically thick material and possibly bipolar jets, a phenomenon\nobserved in only a small fraction of symbiotic stars. These findings establish\nV4141 Sgr as an intriguing target for continued monitoring.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.16825v1","title":"Symbiotic stars in the era of modern ground- and space-based surveys","summary":"Symbiotic stars, interacting binaries composed of a cool giant and a hot\ncompact companion, exhibit complex variability across the electromagnetic\nspectrum. Over the past decades, large-scale photometric and spectroscopic\nsurveys from ground- and space-based observatories have significantly advanced\ntheir discovery and characterization. These datasets have transformed the\nsearch for new symbiotic candidates, providing extensive time-domain\ninformation crucial for their classification and analysis. This review\nhighlights recent observational results that have expanded the known population\nof symbiotic stars, refined classification criteria, and enhanced our\nunderstanding of their variability. Despite these advances, fundamental\nquestions remain regarding their long-term evolution, mass transfer and\naccretion processes, or their potential role as progenitors of Type Ia\nsupernovae. With ongoing and upcoming surveys, the coming years promise new\ndiscoveries and a more comprehensive picture of these intriguing interacting\nsystems.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.16834v1","title":"Improving Significant Wave Height Prediction Using Chronos Models","summary":"Accurate wave height prediction is critical for maritime safety and coastal\nresilience, yet conventional physics-based models and traditional machine\nlearning methods face challenges in computational efficiency and nonlinear\ndynamics modeling. This study introduces Chronos, the first implementation of a\nlarge language model (LLM)-powered temporal architecture (Chronos) optimized\nfor wave forecasting. Through advanced temporal pattern recognition applied to\nhistorical wave data from three strategically chosen marine zones in the\nNorthwest Pacific basin, our framework achieves multimodal improvements: (1)\n14.3% reduction in training time with 2.5x faster inference speed compared to\nPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;\n(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)\nsustained predictive leadership in extended-range forecasts (1-120h); and (4)\ndemonstrated zero-shot capability maintaining median performance (rank 4/12)\nagainst specialized operational models. This LLM-enhanced temporal modeling\nparadigm establishes a new standard in wave prediction, offering both\ncomputationally efficient solutions and a transferable framework for complex\ngeophysical systems modeling.","main_category":"cs.LG","categories":"cs.LG,cs.AI,physics.ao-ph","published":"2025-04-23T15:56:28Z"}
{"aid":"http://arxiv.org/abs/2504.16841v1","title":"Braiding of Majorana Zero Modes in Vortex Cores","summary":"We demonstrate the successful simulation of $\\sqrt{Z}$-, $\\sqrt{X}$- and\n$X$-quantum gates using Majorana zero modes (MZMs) that emerge in magnetic\nvortices located in topological superconductors. We compute the transition\nprobabilities and geometric phase differences accounting for the full many-body\ndynamics and show that qubit states can be read out by fusing the vortex core\nMZMs and measuring the resulting charge density. We visualize the gate\nprocesses using the time- and energy-dependent non-equilibrium local density of\nstates. Our results demonstrate the feasibility of employing vortex core MZMs\nfor the realization of fault-tolerant topological quantum computing.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-23T16:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.16849v1","title":"Magnetorotational instability in a solar mean-field dynamo","summary":"We address the question whether the magneto-rotational instability (MRI) can\noperate in the near-surface shear layer (NSSL) of the Sun and how it affects\nthe interaction with the dynamo process. Using hydromagnetic mean-field\nsimulations of $\\alpha\\Omega$-type dynamos in rotating shearing-periodic boxes,\nwe show that for negative shear, the MRI can operate above a certain critical\nshear parameter. This parameter scales inversely with the equipartition\nmagnetic field strength above which $\\alpha$ quenching set in. Like the usual\n$\\Omega$ effect, the MRI produces toroidal magnetic field, but in our Cartesian\ncases it is found to reduce the resulting magnetic field strength and thus to\nsuppress the dynamo process. In view of the application to the solar NSSL, we\nconclude that the turbulent magnetic diffusivity may be too large for the MRI\nto be excited and that therefore only the standard $\\Omega$ effect is expected\nto operate.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.plasm-ph","published":"2025-04-23T16:10:59Z"}
{"aid":"http://arxiv.org/abs/2504.16865v1","title":"General method for solving nonlinear optical scattering problems using\n  fix point iterations","summary":"In this paper we introduce a new fix point iteration scheme for solving\nnonlinear electromagnetic scattering problems. The method is based on a\nspectral formulation of Maxwell's equations called the Bidirectional Pulse\nPropagation Equations. The scheme can be applied to a wide array of slab-like\ngeometries, and for arbitrary material responses. We derive the scheme and\ninvestigated how it performs with respect to convergence and accuracy by\napplying it to the case of light scattering from a simple slab whose nonlinear\nmaterial response is a sum a very fast electronic vibrational response, and a\nmuch slower molecular vibrational response.","main_category":"physics.class-ph","categories":"physics.class-ph,physics.comp-ph","published":"2025-04-23T16:38:49Z"}
{"aid":"http://arxiv.org/abs/2504.16872v1","title":"The FAST Discovery of a Millisecond Pulsar Hidden in the Harmonics of\n  PSR J2129+1210A (M15A)","summary":"We report the discovery of an isolated millisecond pulsar M15O (J2129+1210O)\nfrom the globular cluster M15 (NGC 7078) with a period of $\\sim$11.06686 ms and\na dispersion measure of $\\sim$67.44 cm$^{-3}$ pc. Its spin period is so close\nto the $10^{\\text{th}}$ harmonic of the bright pulsar M15A ($\\sim$11.06647 ms)\nand thus missed in previous pulsar search. We suggest adding the spectrum in\nthe pulsar candidate diagnostic plot to identify new signals near the\nharmonics. M15O has the first spin frequency derivative and the second spin\nfrequency derivative,being 1.79191(5) $\\times$ $10^{-14}$ Hz $s^{-2}$ and\n3.3133(6)$\\times$ $10^{-23}$ Hz $s^{-3}$, respectively. Its projected distance\nfrom the optical centre of M15 is the closest among all the pulsars in M15. The\norigin can be something from the center of the massive and core-collapsed\nglobular cluster M15.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T16:46:20Z"}
{"aid":"http://arxiv.org/abs/2504.16882v1","title":"Fractional $Q$-curvature on the sphere and optimal partitions","summary":"We study an optimal partition problem on the sphere, where the cost\nfunctional is associated with the fractional $Q$-curvature in terms of the\nconformal fractional Laplacian on the sphere. By leveraging symmetries, we\nprove the existence of a symmetric minimal partition through a variational\napproach. A key ingredient in our analysis is a new H\\\"older regularity result\nfor symmetric functions in a fractional Sobolev space on the sphere. As a\nbyproduct, we establish the existence of infinitely many solutions to a\nnonlocal weakly-coupled competitive system on the sphere that remain invariant\nunder a group of conformal diffeomorphisms and we investigate the asymptotic\nbehavior of least-energy solutions as the coupling parameters approach negative\ninfinity.","main_category":"math.AP","categories":"math.AP,math.DG","published":"2025-04-23T16:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.16883v1","title":"Enhancing Critical Thinking with AI: A Tailored Warning System for RAG\n  Models","summary":"Retrieval-Augmented Generation (RAG) systems offer a powerful approach to\nenhancing large language model (LLM) outputs by incorporating fact-checked,\ncontextually relevant information. However, fairness and reliability concerns\npersist, as hallucinations can emerge at both the retrieval and generation\nstages, affecting users' reasoning and decision-making. Our research explores\nhow tailored warning messages -- whose content depends on the specific context\nof hallucination -- shape user reasoning and actions in an educational quiz\nsetting. Preliminary findings suggest that while warnings improve accuracy and\nawareness of high-level hallucinations, they may also introduce cognitive\nfriction, leading to confusion and diminished trust in the system. By examining\nthese interactions, this work contributes to the broader goal of AI-augmented\nreasoning: developing systems that actively support human reflection, critical\nthinking, and informed decision-making rather than passive information\nconsumption.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T17:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.16887v1","title":"The Sponge is Quantum Indifferentiable","summary":"The sponge is a cryptographic construction that turns a public permutation\ninto a hash function. When instantiated with the Keccak permutation, the sponge\nforms the NIST SHA-3 standard. SHA-3 is a core component of most post-quantum\npublic-key cryptography schemes slated for worldwide adoption.\n  While one can consider many security properties for the sponge, the ultimate\none is indifferentiability from a random oracle, or simply indifferentiability.\nThe sponge was proved indifferentiable against classical adversaries by Bertoni\net al. in 2008. Despite significant efforts in the years since, little is known\nabout sponge security against quantum adversaries, even for simple properties\nlike preimage or collision resistance beyond a single round. This is primarily\ndue to the lack of a satisfactory quantum analog of the lazy sampling technique\nfor permutations.\n  In this work, we develop a specialized technique that overcomes this barrier\nin the case of the sponge. We prove that the sponge is in fact indifferentiable\nfrom a random oracle against quantum adversaries. Our result establishes that\nthe domain extension technique behind SHA-3 is secure in the post-quantum\nsetting. Our indifferentiability bound for the sponge is a loose\n$O(\\mathsf{poly}(q) 2^{-\\mathsf{min}(r, c)/4})$, but we also give bounds on\npreimage and collision resistance that are tighter.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-23T17:04:25Z"}
{"aid":"http://arxiv.org/abs/2504.16892v1","title":"Collective Defined Contribution Schemes Without Intergenerational\n  Cross-Subsidies","summary":"We present an architecture for managing Collective Defined Contribution (CDC)\nschemes. The current approach to UK CDC can be described as shared-indexation,\nwhere the nominal benefit of every member in a scheme receives the same level\nof indexation each year. The design of such schemes rely on the use of\napproximate discounting methodologies to value liabilities, and this leads to\nintergenerational cross-subsidies which can be large and unpredictable. We\npresent an alternative approach which we call Collective-Drawdown CDC. This\napproach does not result in intergenerational cross-subsidies since all pooling\nis performed by explicit insurance contracts. It is therefore completely fair.\nMoreover, this scheme results in better pension outcomes when compared to\nshared-indexation CDC under the same model parameters.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-23T17:15:35Z"}
{"aid":"http://arxiv.org/abs/2504.16895v1","title":"Exact analytic solutions in 2+1 HoÅ™ava gravity with cosmological\n  constant","summary":"We investigate the static solutions with rotational symmetry in the\nnonprojectable Ho\\v{r}ava theory in 2+1 dimensions. We consider all\ninequivalent terms of the effective theory, including the cosmological\nconstant. We find two distinct types of solutions: the first one corresponds to\na Lifshitz solution, while the second one is obtained through a coordinate\ntransformation of the equations of motion. This exact solution does not exhibit\nLifshitz behavior and features a naked singularity.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T17:24:53Z"}
{"aid":"http://arxiv.org/abs/2504.16899v1","title":"Linear convergence of a one-cut conditional gradient method for total\n  variation regularization","summary":"We introduce a fully-corrective generalized conditional gradient method for\nconvex minimization problems involving total variation regularization on\nmultidimensional domains. It relies on alternating between updating an active\nset of subsets of the spatial domain as well as of an iterate given by a conic\ncombination of the associated characteristic functions. Different to previous\napproaches in the same spirit, the computation of a new candidate set only\nrequires the solution of one prescribed mean curvature problem instead of the\nresolution of a fractional minimization task analogous to finding a generalized\nCheeger set. After discretization, the former can be realized by a single run\nof a graph cut algorithm leading to significant speedup in practice. We prove\nthe global sublinear convergence of the resulting method, under mild\nassumptions, and its asymptotic linear convergence in a more restrictive\ntwo-dimensional setting which uses results of stability of surfaces of\nprescribed curvature under perturbations of the curvature. Finally, we\nnumerically demonstrate this convergence behavior in some model PDE-constrained\nminimization problems.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-23T17:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.16906v1","title":"An Accelerated Camera 3DMA Framework for Efficient Urban GNSS Multipath\n  Estimation","summary":"Robust GNSS positioning in urban environments is still plagued by multipath\neffects, particularly due to the complex signal propagation induced by\nubiquitous surfaces with varied radio frequency reflectivities. Current 3D\nMapping Aided (3DMA) GNSS techniques show great potentials in mitigating\nmultipath but face a critical trade-off between computational efficiency and\nmodeling accuracy. Most approaches often rely on offline outdated or\noversimplified 3D maps, while real-time LiDAR-based reconstruction boasts high\naccuracy, it is problematic in low laser reflectivity conditions; camera 3DMA\nis a good candidate to balance accuracy and efficiency but current methods\nsuffer from extremely low reconstruction speed, a far cry from real-time\nmultipath-mitigated navigation. This paper proposes an accelerated framework\nincorporating camera multi-view stereo (MVS) reconstruction and ray tracing. By\nhypothesizing on surface textures, an orthogonal visual feature fusion\nframework is proposed, which robustly addresses both texture-rich and\ntexture-poor surfaces, lifting off the reflectivity challenges in visual\nreconstruction. A polygonal surface modeling scheme is further integrated to\naccurately delineate complex building boundaries, enhancing the reconstruction\ngranularity. To avoid excessively accurate reconstruction, reprojected point\ncloud multi-plane fitting and two complexity control strategies are proposed,\nthus improving upon multipath estimation speed. Experiments were conducted in\nLujiazui, Shanghai, a typical multipath-prone district. The results show that\nthe method achieves an average reconstruction accuracy of 2.4 meters in dense\nurban environments featuring glass curtain wall structures, a traditionally\ntough case for reconstruction, and achieves a ray-tracing-based multipath\ncorrection rate of 30 image frames per second, 10 times faster than the\ncontemporary benchmarks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T17:34:37Z"}
{"aid":"http://arxiv.org/abs/2504.16910v1","title":"Self-interacting dark matter with observable $Î”N_{\\rm eff}$","summary":"We propose a GeV-scale self-interacting dark matter (SIDM) candidate within a\ndark $U(1)_D$ gauged extension of the Standard Model (SM), addressing\nsmall-scale structure issues in $\\Lambda$CDM while predicting an observable\ncontribution to $\\Delta N_{\\rm eff}$ in the form of dark radiation. The model\nintroduces a fermionic DM candidate $\\chi$ and a scalar $\\phi$, both charged\nunder an unbroken $U(1)_D$ gauge symmetry. The self-interactions of $\\chi$ are\nmediated by a light vector boson $X^\\mu$, whose mass is generated via the\nStueckelberg mechanism. The relic abundance of $\\chi$ is determined by thermal\nfreeze-out through annihilations into $X^\\mu$, supplemented by a non-thermal\ncomponent from the late decay of $\\phi$. Crucially, $\\phi$ decays after the Big\nBang Nucleosynthesis (BBN) but before the Cosmic Microwave Background (CMB)\nepoch, producing additional $\\chi$ and a dark radiation species ($\\nu_S$). This\nlate-time production compensates for thermal underabundance due to efficient\nannihilation into light mediators, while remaining consistent with structure\nformation constraints. The accompanying dark radiation yields a detectable\n$\\Delta N_{\\rm eff}$, compatible with Planck 2018 bounds and within reach of\nnext-generation experiments such as SPT-3G, CMB-S4, and CMB-HD.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-23T17:37:57Z"}
{"aid":"http://arxiv.org/abs/2504.16911v1","title":"Dynamical tides in neutron stars with first-order phase transitions: the\n  role of the discontinuity mode","summary":"During the late stages of a binary neutron star inspiral, dynamical tides\ninduced in each star by its companion become significant and should be included\nin complete gravitational-wave (GW) modeling. We investigate the coupling\nbetween the tidal field and quasi-normal modes in hybrid stars and show that\nthe discontinuity mode ($g$-mode)--intrinsically associated with first-order\nphase transitions and buoyancy--can rival the contribution of the fundamental\n$f$-mode. We find that the $g$-mode overlap integral can reach up to $\\sim\n10\\%$ of the $f$-mode value for hybrid star masses in the range\n1.4-2.0$M_{\\odot}$, with the largest values generally associated with larger\ndensity jumps. This leads to a GW phase shift due to the $g$-mode of $\\Delta\n\\phi_g \\lesssim 0.1$-$1$ rad (i.e., up to $\\sim$5\\%-10\\% of $\\Delta \\phi_f$),\nwith the largest shifts occurring for masses near the phase transition. At\nhigher masses, the shifts remain smaller and nearly constant, with $\\Delta\n\\phi_g \\lesssim 0.1$ rad (roughly $\\sim 1\\%$ of $\\Delta \\phi_f$). These GW\nshifts may be relevant even at the design sensitivity of current\nsecond-generation GW detectors in the most optimistic cases. Moreover, if a\n$g$-mode is present and lies near the $f$-mode frequency, neglecting it in the\nGW modeling can lead to systematic biases in neutron star parameter estimation,\nresulting in radius errors of up to $1\\%-2\\%$. These results show the\nimportance of dynamical tides to probe neutron stars' equation of state, and to\ntest the existence of dense-matter phase transitions.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-23T17:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.16914v1","title":"MorphoNavi: Aerial-Ground Robot Navigation with Object Oriented Mapping\n  in Digital Twin","summary":"This paper presents a novel mapping approach for a universal aerial-ground\nrobotic system utilizing a single monocular camera. The proposed system is\ncapable of detecting a diverse range of objects and estimating their positions\nwithout requiring fine-tuning for specific environments. The system's\nperformance was evaluated through a simulated search-and-rescue scenario, where\nthe MorphoGear robot successfully located a robotic dog while an operator\nmonitored the process. This work contributes to the development of intelligent,\nmultimodal robotic systems capable of operating in unstructured environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T17:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.16918v1","title":"OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents","summary":"Optimization plays a vital role in scientific research and practical\napplications, but formulating a concrete optimization problem described in\nnatural language into a mathematical form and selecting a suitable solver to\nsolve the problem requires substantial domain expertise. We introduce\n\\textbf{OptimAI}, a framework for solving \\underline{Optim}ization problems\ndescribed in natural language by leveraging LLM-powered \\underline{AI} agents,\nachieving superior performance over current state-of-the-art methods. Our\nframework is built upon four key roles: (1) a \\emph{formulator} that translates\nnatural language problem descriptions into precise mathematical formulations;\n(2) a \\emph{planner} that constructs a high-level solution strategy prior to\nexecution; and (3) a \\emph{coder} and a \\emph{code critic} capable of\ninteracting with the environment and reflecting on outcomes to refine future\nactions. Ablation studies confirm that all roles are essential; removing the\nplanner or code critic results in $5.8\\times$ and $3.1\\times$ drops in\nproductivity, respectively. Furthermore, we introduce UCB-based debug\nscheduling to dynamically switch between alternative plans, yielding an\nadditional $3.3\\times$ productivity gain. Our design emphasizes multi-agent\ncollaboration, allowing us to conveniently explore the synergistic effect of\ncombining diverse models within a unified system. Our approach attains 88.1\\%\naccuracy on the NLP4LP dataset and 71.2\\% on the Optibench (non-linear w/o\ntable) subset, reducing error rates by 58\\% and 50\\% respectively over prior\nbest results.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T17:45:05Z"}
{"aid":"http://arxiv.org/abs/2504.16926v1","title":"Meteor CNEOS 2014-01-08 has nothing to do with Planet 9","summary":"It has been suggested that a gravitational slingshot from the hypothetical\nPlanet 9 (P9) could explain the unusually large velocity of meteor CNEOS\n2014-01-08. I show that this explanation does not work because P9 can at most\nprovide an insignificant 0.25 km/s of the object's 42 km/s asymptotic\nheliocentric velocity and at most a 7.6 degree deflection due to P9's low\norbital speed and non-zero radius. Furthermore, the hypothesis requires an\nencounter with two planets that is trillions of times more unlikely than CNEOS\n2014-01-08 simply being fast from the beginning.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-23T17:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.16929v1","title":"I-Con: A Unifying Framework for Representation Learning","summary":"As the field of representation learning grows, there has been a proliferation\nof different loss functions to solve different classes of problems. We\nintroduce a single information-theoretic equation that generalizes a large\ncollection of modern loss functions in machine learning. In particular, we\nintroduce a framework that shows that several broad classes of machine learning\nmethods are precisely minimizing an integrated KL divergence between two\nconditional distributions: the supervisory and learned representations. This\nviewpoint exposes a hidden information geometry underlying clustering, spectral\nmethods, dimensionality reduction, contrastive learning, and supervised\nlearning. This framework enables the development of new loss functions by\ncombining successful techniques from across the literature. We not only present\na wide array of proofs, connecting over 23 different approaches, but we also\nleverage these theoretical results to create state-of-the-art unsupervised\nimage classifiers that achieve a +8% improvement over the prior\nstate-of-the-art on unsupervised classification on ImageNet-1K. We also\ndemonstrate that I-Con can be used to derive principled debiasing methods which\nimprove contrastive representation learners.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,cs.IT,math.IT","published":"2025-04-23T17:59:01Z"}
{"aid":"http://arxiv.org/abs/2504.17586v1","title":"A Machine Learning Approach for Denoising and Upsampling HRTFs","summary":"The demand for realistic virtual immersive audio continues to grow, with\nHead-Related Transfer Functions (HRTFs) playing a key role. HRTFs capture how\nsound reaches our ears, reflecting unique anatomical features and enhancing\nspatial perception. It has been shown that personalized HRTFs improve\nlocalization accuracy, but their measurement remains time-consuming and\nrequires a noise-free environment. Although machine learning has been shown to\nreduce the required measurement points and, thus, the measurement time, a\ncontrolled environment is still necessary. This paper proposes a method to\naddress this constraint by presenting a novel technique that can upsample\nsparse, noisy HRTF measurements. The proposed approach combines an HRTF Denoisy\nU-Net for denoising and an Autoencoding Generative Adversarial Network (AE-GAN)\nfor upsampling from three measurement points. The proposed method achieves a\nlog-spectral distortion (LSD) error of 5.41 dB and a cosine similarity loss of\n0.0070, demonstrating the method's effectiveness in HRTF upsampling.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-24T14:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.17623v1","title":"Thermal Hall conductivity in the strongest cuprate superconductor:\n  Estimate of the mean free path in the trilayer cuprate\n  HgBa$_2$Ca$_2$Cu$_3$O$_{8 + Î´}$","summary":"The thermal Hall conductivity of the trilayer cuprate\nHgBa$_2$Ca$_2$Cu$_3$O$_{8+\\delta}$ (Hg1223) - the superconductor with the\nhighest critical temperature $T_c$ at ambient pressure - was measured at\ntemperatures down to 2 K for three dopings in the underdoped regime ($p$ =\n0.09, 0.10, 0.11). By combining a previously introduced simple model and prior\ntheoretical results, we derive a formula for the inverse mean free path, $1 /\n\\ell$, which allows us to estimate the mean free path of $d$-wave\nquasiparticles in Hg1223 below $T_c$. We find that $1 / \\ell$ grows as $T^3$,\nin agreement with the theoretical expectation for a clean $d$-wave\nsuperconductor. Measurements were also conducted on the single layer\nmercury-based cuprate HgBa$_2$CuO$_{6+\\delta}$ (Hg1201), revealing that the\nmean free path in this compound is roughly half that of its three-layered\ncounterpart at the same doping ($p$ = 0.10). This observation can be attributed\nto the protective role of the outer planes in Hg1223, which results in a more\npristine inner plane. We also report data in an ultraclean crystal of\nYBa$_2$Cu$_3$O$_y$ (YBCO) with full oxygen content $p$ = 0.18, believed to be\nthe cleanest of any cuprate, and find that $\\ell$ is not longer than in Hg1223.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-04-24T14:45:57Z"}
{"aid":"http://arxiv.org/abs/2504.17634v1","title":"Sparsity-Exploiting Channel Estimation For Unsourced Random Access With\n  Fluid Antenna","summary":"This work explores the channel estimation (CE) problem in uplink transmission\nfor unsourced random access (URA) with a fluid antenna receiver. The additional\nspatial diversity in a fluid antenna system (FAS) addresses the needs of URA\ndesign in multiple-input and multiple-output (MIMO) systems. We present two CE\nstrategies based on the activation of different FAS ports, namely alternate\nports and partial ports CE. Both strategies facilitate the estimation of\nchannel coefficients and angles of arrival (AoAs). Additionally, we discuss how\nto refine channel estimation by leveraging the sparsity of finite scatterers.\nSpecifically, the proposed partial ports CE strategy is implemented using a\nregularized estimator, and we optimize the estimator's parameter to achieve the\ndesired AoA precision and refinement. Extensive numerical results demonstrate\nthe feasibility of the proposed strategies, and a comparison with a\nconventional receiver using half-wavelength antennas highlights the promising\nfuture of integrating URA and FAS.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T15:07:12Z"}
{"aid":"http://arxiv.org/abs/2504.17642v1","title":"Quantum coherence and counterdiabatic quantum computing","summary":"Counterdiabatic driving emerges as a valuable technique for implementing\nshortcuts to adiabaticity protocols, enhancing quantum technology applications.\nIn this context, counterdiabatic quantum computing represents a new paradigm\nwith the potential to achieve quantum advantage for industrial problems. This\nwork investigates the production of quantum coherence in adiabatic evolution\naccelerated by counterdiabatic driving within the framework of counterdiabatic\nquantum computing. Specifically, we analyze different orders in the nested\ncommutator expansion for approximated counterdiabatic drivings for three cases:\na weighted max-cut problem, a 4-local Hamiltonian, and a non-stoquastic\nHamiltonian. Our findings reveal that the hierarchy introduced by coherence\nproduction correlates with the success probability in the impulse regime. This\nsuggests that protocols increasing coherence during evolution enhance\nperformance in adiabatic evolution driven by counterdiabatic techniques. We\nshow that large quantum coherence also means large energy fluctuation during\nevolution, which is associated with the speed of evolution, paving the way for\ndesigning superior algorithms in counterdiabatic quantum computing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-24T15:12:49Z"}
{"aid":"http://arxiv.org/abs/2504.17648v1","title":"A Robust Fault Detection Filter for Linear Time-Varying System with\n  Non-Gaussian Noise","summary":"This paper addresses the problem of robust fault detection filtering for\nlinear time-varying (LTV) systems with non-Gaussian noise and additive faults.\nThe conventional generalized likelihood ratio (GLR) method utilizes the Kalman\nfilter, which may exhibit inadequate performance under non-Gaussian noise\nconditions. To mitigate this issue, a fault detection method employing the\n$H_{\\infty}$ filter is proposed. The $H_{\\infty}$ filter is first derived as\nthe solution to a regularized least-squares (RLS) optimization problem, and the\neffect of faults on the output prediction error is then analyzed. The proposed\napproach using the $H_{\\infty}$ filter demonstrates robustness in non-Gaussian\nnoise environments and significantly improves fault detection performance\ncompared to the original GLR method that employs the Kalman filter. The\neffectiveness of the proposed approach is illustrated using numerical examples.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T15:18:31Z"}
{"aid":"http://arxiv.org/abs/2504.17665v1","title":"Evaluating Grounded Reasoning by Code-Assisted Large Language Models for\n  Mathematics","summary":"Assisting LLMs with code generation improved their performance on\nmathematical reasoning tasks. However, the evaluation of code-assisted LLMs is\ngenerally restricted to execution correctness, lacking a rigorous evaluation of\ntheir generated programs. In this work, we bridge this gap by conducting an\nin-depth analysis of code-assisted LLMs' generated programs in response to math\nreasoning tasks. Our evaluation focuses on the extent to which LLMs ground\ntheir programs to math rules, and how that affects their end performance. For\nthis purpose, we assess the generations of five different LLMs, on two\ndifferent math datasets, both manually and automatically. Our results reveal\nthat the distribution of grounding depends on LLMs' capabilities and the\ndifficulty of math problems. Furthermore, mathematical grounding is more\neffective for closed-source models, while open-source models fail to employ\nmath rules in their solutions correctly. On MATH500, the percentage of grounded\nprograms decreased to half, while the ungrounded generations doubled in\ncomparison to ASDiv grade-school problems. Our work highlights the need for\nin-depth evaluation beyond execution accuracy metrics, toward a better\nunderstanding of code-assisted LLMs' capabilities and limits in the math\ndomain.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T15:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.17670v1","title":"DiMeR: Disentangled Mesh Reconstruction Model","summary":"With the advent of large-scale 3D datasets, feed-forward 3D generative\nmodels, such as the Large Reconstruction Model (LRM), have gained significant\nattention and achieved remarkable success. However, we observe that RGB images\noften lead to conflicting training objectives and lack the necessary clarity\nfor geometry reconstruction. In this paper, we revisit the inductive biases\nassociated with mesh reconstruction and introduce DiMeR, a novel disentangled\ndual-stream feed-forward model for sparse-view mesh reconstruction. The key\nidea is to disentangle both the input and framework into geometry and texture\nparts, thereby reducing the training difficulty for each part according to the\nPrinciple of Occam's Razor. Given that normal maps are strictly consistent with\ngeometry and accurately capture surface variations, we utilize normal maps as\nexclusive input for the geometry branch to reduce the complexity between the\nnetwork's input and output. Moreover, we improve the mesh extraction algorithm\nto introduce 3D ground truth supervision. As for texture branch, we use RGB\nimages as input to obtain the textured mesh. Overall, DiMeR demonstrates robust\ncapabilities across various tasks, including sparse-view reconstruction,\nsingle-image-to-3D, and text-to-3D. Numerous experiments show that DiMeR\nsignificantly outperforms previous methods, achieving over 30% improvement in\nChamfer Distance on the GSO and OmniObject3D dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T15:39:20Z"}
{"aid":"http://arxiv.org/abs/2504.17681v1","title":"Long-range four-body interactions in the Hamiltonian mean field model","summary":"In this paper, a Hamiltonian mean field model with long-range four-body\ninteractions is proposed. The model describes a long-range mean-field system in\nwhich N unit-mass particles move on a unit circle. Each particle theta_i\ninteracts with any three other particles through an infinite-range cosine\npotential with an attractive interaction (epsilon > 0). By applying a method\nthat remaps the average phase of global particle pairs onto a new unit circle,\nand using the saddle-point technique, the partition function is solved\nanalytically after introducing four-body interactions, yielding expressions for\nthe free energy f and the energy per particle U. These results were further\nvalidated through numerical simulations. The results show that the system\nundergoes a second-order phase transition at the critical energy U_c.\nSpecifically, the critical energy corresponds to U_c = 0.32 when the coupling\nconstant epsilon = 5, and U_c = 0.63 when epsilon = 10. Finally, we calculated\nthe system's largest Lyapunov exponent lambda and kinetic energy fluctuations\nSigma through numerical simulations. It is found that the peak of the largest\nLyapunov exponent lambda occurs slightly below the critical energy U_c, which\nis consistent with the point of maximum kinetic energy fluctuations Sigma. And\nthere is a scaling law of Sigma / N^(1/2) proportional to lambda between them.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-24T15:53:33Z"}
{"aid":"http://arxiv.org/abs/2504.17685v1","title":"Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve\n  LLM-level Accuracy in Profile Matching Tasks","summary":"This study explores the potential of small language model(SLM) ensembles to\nachieve accuracy comparable to proprietary large language models (LLMs). We\npropose Ensemble Bayesian Inference (EBI), a novel approach that applies\nBayesian estimation to combine judgments from multiple SLMs, allowing them to\nexceed the performance limitations of individual models. Our experiments on\ndiverse tasks(aptitude assessments and consumer profile analysis in both\nJapanese and English) demonstrate EBI's effectiveness. Notably, we analyze\ncases where incorporating models with negative Lift values into ensembles\nimproves overall performance, and we examine the method's efficacy across\ndifferent languages. These findings suggest new possibilities for constructing\nhigh-performance AI systems with limited computational resources and for\neffectively utilizing models with individually lower performance. Building on\nexisting research on LLM performance evaluation, ensemble methods, and\nopen-source LLM utilization, we discuss the novelty and significance of our\napproach.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T15:55:10Z"}
{"aid":"http://arxiv.org/abs/2504.17694v1","title":"Using mathematical models of heart cells to assess the safety of new\n  pharmaceutical drugs","summary":"Many drugs have been withdrawn from the market worldwide, at a cost of\nbillions of dollars, because of patient fatalities due to them unexpectedly\ndisturbing heart rhythm. Even drugs for ailments as mild as hay fever have been\nwithdrawn due to an unacceptable increase in risk of these heart rhythm\ndisturbances. Consequently, the whole pharmaceutical industry expends a huge\neffort in checking all new drugs for any unwanted side effects on the heart.\nThe predominant root cause has been identified as drug molecules blocking ionic\ncurrent flows in the heart. Block of individual types of ionic currents can now\nbe measured experimentally at an early stage of drug development, and this is\nthe standard screening approach for a number of ion currents in many large\npharmaceutical companies. However, clinical risk is a complex function of the\ndegree of block of many different types of cardiac ion currents, and this is\ndifficult to understand by looking at results of these screens independently.\nBy using ordinary differential equation models for the electrical activity of\nheart cells (electrophysiology models) we can integrate information from\ndifferent types of currents, to predict the effect on whole heart cells and\nsubsequent risk of side effects. The resulting simulations can provide a more\naccurate summary of the risk of a drug earlier in development and hence more\ncheaply than the pre-existing approaches.","main_category":"q-bio.CB","categories":"q-bio.CB,q-bio.SC","published":"2025-04-24T16:03:06Z"}
{"aid":"http://arxiv.org/abs/2504.17699v1","title":"Quadratic Interest Network for Multimodal Click-Through Rate Prediction","summary":"Multimodal click-through rate (CTR) prediction is a key technique in\nindustrial recommender systems. It leverages heterogeneous modalities such as\ntext, images, and behavioral logs to capture high-order feature interactions\nbetween users and items, thereby enhancing the system's understanding of user\ninterests and its ability to predict click behavior. The primary challenge in\nthis field lies in effectively utilizing the rich semantic information from\nmultiple modalities while satisfying the low-latency requirements of online\ninference in real-world applications. To foster progress in this area, the\nMultimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshop\nformulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding:\nthis task aims to explore multimodal information extraction and item\nrepresentation learning methods that enhance recommendation tasks; and (2) Task\n2 of Multimodal CTR Prediction: this task aims to explore what multimodal\nrecommendation model can effectively leverage multimodal embedding features and\nachieve better performance. In this paper, we propose a novel model for Task 2,\nnamed Quadratic Interest Network (QIN) for Multimodal CTR Prediction.\nSpecifically, QIN employs adaptive sparse target attention to extract\nmultimodal user behavior features, and leverages Quadratic Neural Networks to\ncapture high-order feature interactions. As a result, QIN achieved an AUC of\n0.9798 on the leaderboard and ranked second in the competition. The model code,\ntraining logs, hyperparameter configurations, and checkpoints are available at\nhttps://github.com/salmon1802/QIN.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-24T16:08:52Z"}
{"aid":"http://arxiv.org/abs/2504.17706v1","title":"Inverse problem in the LaMET framework","summary":"One proposal to compute parton distributions from first principles is the\nlarge momentum effective theory (LaMET), which requires the Fourier transform\nof matrix elements computed non-perturbatively. Lattice quantum chromodynamics\n(QCD) provides calculations of these matrix elements over a finite range of\nFourier harmonics that are often noisy or unreliable in the largest computed\nharmonics. It has been suggested that enforcing an exponential decay of the\nmissing harmonics helps alleviate this issue. Using non-perturbative data, we\nshow that the uncertainty introduced by this inverse problem in a realistic\nsetup remains significant without very restrictive assumptions, and that the\nimportance of the exact asymptotic behavior is minimal for values of $x$ where\nthe framework is currently applicable. We show that the crux of the inverse\nproblem lies in harmonics of the order of $\\lambda=zP_z \\sim 5-15$, where the\nsignal in the lattice data is often barely existent in current studies, and the\nasymptotic behavior is not firmly established. We stress the need for more\nsophisticated techniques to account for this inverse problem, whether in the\nLaMET or related frameworks like the short-distance factorization. We also\naddress a misconception that, with available lattice methods, the LaMET\nframework allows a \"direct\" computation of the $x$-dependence, whereas the\nalternative short-distance factorization only gives access to moments or fits\nof the $x$-dependence.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-24T16:11:48Z"}
{"aid":"http://arxiv.org/abs/2504.17713v1","title":"Target-Date Funds: A State-of-the-Art Review with Policy Applications to\n  Chile's Pension Reform","summary":"This review paper explores the evolution and implementation of target-date\nfunds (TDFs), specifically focusing on their application within the context of\nChile's 2025 pension reform. The introduction of TDFs marks a significant shift\nin Chile's pension system, which has traditionally relied on a multifund\nstructure (essentially a target-risk funds system). We offer a comprehensive\nreview of the theoretical foundations and practical considerations of TDFs,\nhighlighting key challenges and opportunities for Chilean regulators and fund\nmanagers. Notably, we recommend that the glide path design should be dynamic,\nincorporating adjustments based on total accumulated wealth, with particular\nflexibility depending on each investor's risk tolerance. Furthermore, we\npropose that the new benchmark for generational funds should feature a wide\ndeviation band relative to the new benchmark portfolio, which could foster a\nmarket with more investment strategies and better competition among fund\nmanagers, encourage the inclusion of alternative assets, and foster greater\ndiversification. Lastly, we highlight the need for future work to define a\nglide path model that incorporates the theoretical frameworks described,\ntailored to the unique parameters of the Chilean pension system. These\nrecommendations aim to optimize the long-term retirement outcomes for Chilean\nworkers under the new pension structure.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-24T16:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.17728v1","title":"CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from\n  Casually Captured Videos","summary":"Recently, photo-realistic novel view synthesis from multi-view images, such\nas neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered\nwidespread attention due to their superior performance. However, most works\nrely on low dynamic range (LDR) images, which limits the capturing of richer\nscene details. Some prior works have focused on high dynamic range (HDR) scene\nreconstruction, typically require capturing of multi-view sharp images with\ndifferent exposure times at fixed camera positions during exposure times, which\nis time-consuming and challenging in practice. For a more flexible data\nacquisition, we propose a one-stage method: \\textbf{CasualHDRSplat} to easily\nand robustly reconstruct the 3D HDR scene from casually captured videos with\nauto-exposure enabled, even in the presence of severe motion blur and varying\nunknown exposure time. \\textbf{CasualHDRSplat} contains a unified\ndifferentiable physical imaging model which first applies continuous-time\ntrajectory constraint to imaging process so that we can jointly optimize\nexposure time, camera response function (CRF), camera poses, and sharp 3D HDR\nscene. Extensive experiments demonstrate that our approach outperforms existing\nmethods in terms of robustness and rendering quality. Our source code will be\navailable at https://github.com/WU-CVGL/CasualHDRSplat","main_category":"cs.GR","categories":"cs.GR,cs.CV,cs.MM","published":"2025-04-24T16:42:37Z"}
{"aid":"http://arxiv.org/abs/2504.17729v1","title":"Fully-Mixed Virtual Element Method for the Biot Problem","summary":"Poroelasticity describes the interaction of deformation and fluid flow in\nsaturated porous media. A fully-mixed formulation of Biot's poroelasticity\nproblem has the advantage of producing a better approximation of the Darcy\nvelocity and stress field, as well as satisfying local mass and momentum\nconservation. In this work, we focus on a novel four-fields Virtual Element\ndiscretization of Biot's equations. The stress symmetry is strongly imposed in\nthe definition of the discrete space, thus avoiding the use of an additional\nLagrange multiplier. A complete a priori analysis is performed, showing the\nrobustness of the proposed numerical method with respect to limiting material\nproperties. The first order convergence of the lowest-order fully-discrete\nnumerical method, which is obtained by coupling the spatial approximation with\nthe backward Euler time-advancing scheme, is confirmed by a complete 3D\nnumerical validation. A well known poroelasticity benchmark is also considered\nto assess the robustness properties and computational performance.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-24T16:42:50Z"}
{"aid":"http://arxiv.org/abs/2504.17730v1","title":"Bandstructure of a coupled BEC-cavity system: effects of dissipation and\n  geometry","summary":"We present a theoretical model for a transversally driven Bose-Einstein\ncondensate coupled to an optical cavity. We focus on the interplay between\ndifferent coherent couplings, which can trigger a structural phase transition,\nknown as the superradiant phase transition. Our approach, based on band\nstructure theory and a mean-field description, enables a comprehensive analysis\nof the nature of the system's excited modes, precursing the phase transitions.\nBy incorporating dissipative couplings, intrinsic to these systems, we find\nnon-Hermitian phenomena such as the coalescence of crossing precursor modes and\nthe emergence of exceptional points (EPs). The general formulation of our model\nallows us to explain the role of an angle between transverse pump and the\ncavity deviating from $90^\\circ$. This offers us a unified perspective on the\nplethora of different implementations of such systems.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,quant-ph","published":"2025-04-24T16:43:45Z"}
{"aid":"http://arxiv.org/abs/2504.17732v1","title":"DPMambaIR:All-in-One Image Restoration via Degradation-Aware Prompt\n  State Space Model","summary":"All-in-One image restoration aims to address multiple image degradation\nproblems using a single model, significantly reducing training costs and\ndeployment complexity compared to traditional methods that design dedicated\nmodels for each degradation type. Existing approaches typically rely on\nDegradation-specific models or coarse-grained degradation prompts to guide\nimage restoration. However, they lack fine-grained modeling of degradation\ninformation and face limitations in balancing multi-task conflicts. To overcome\nthese limitations, we propose DPMambaIR, a novel All-in-One image restoration\nframework. By integrating a Degradation-Aware Prompt State Space Model (DP-SSM)\nand a High-Frequency Enhancement Block (HEB), DPMambaIR enables fine-grained\nmodeling of complex degradation information and efficient global integration,\nwhile mitigating the loss of high-frequency details caused by task competition.\nSpecifically, the DP-SSM utilizes a pre-trained degradation extractor to\ncapture fine-grained degradation features and dynamically incorporates them\ninto the state space modeling process, enhancing the model's adaptability to\ndiverse degradation types. Concurrently, the HEB supplements high-frequency\ninformation, effectively addressing the loss of critical details, such as edges\nand textures, in multi-task image restoration scenarios. Extensive experiments\non a mixed dataset containing seven degradation types show that DPMambaIR\nachieves the best performance, with 27.69dB and 0.893 in PSNR and SSIM,\nrespectively. These results highlight the potential and superiority of\nDPMambaIR as a unified solution for All-in-One image restoration.","main_category":"cs.CV","categories":"cs.CV,I.4.4","published":"2025-04-24T16:46:32Z"}
{"aid":"http://arxiv.org/abs/2504.17733v1","title":"Fuzzy clustering and community detection: an integrated approach","summary":"This paper addresses the ambitious goal of merging two different approaches\nto group detection in complex domains: one based on fuzzy clustering and the\nother on community detection theory. To achieve this, two clustering algorithms\nare proposed: Fuzzy C-Medoids Clustering with Modularity Spatial Correction and\nFuzzy C-Modes Clustering with Modularity Spatial Correction. The former is\ndesigned for quantitative data, while the latter is intended for qualitative\ndata. The concept of fuzzy modularity is introduced into the standard objective\nfunction of fuzzy clustering algorithms as a spatial regularization term, whose\ncontribution to the clustering criterion based on attributes is controlled by\nan exogenous parameter. An extensive simulation study is conducted to support\nthe theoretical framework, complemented by two applications to real-world data\nrelated to the theme of sustainability. The first application involves data\nfrom the 2030 Agenda for Sustainable Development, while the second focuses on\nurban green spaces in Italian provincial capitals and metropolitan cities. Both\nthe simulation results and the applications demonstrate the advantages of this\nnew methodological proposal.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-24T16:47:17Z"}
{"aid":"http://arxiv.org/abs/2504.17738v1","title":"Asteroseismology of blue stragglers in $Ï‰$ Centauri: the case of\n  five double-mode radial SX Phoenicis pulsators","summary":"We present the first extensive seismic modelling of SX Phe stars in the\nstellar system $\\omega$ Cen. First, using the new values of reddening $E(B-V)$\nand distance modulus $(m-M)_V$, and bolometric corrections from Kurucz model\natmospheres, we determine the effective temperatures and luminosities of all SX\nPhe variables in $\\omega$ Cen with available $(B-V)$ colours. Next, we\ncarefully select SX Phe stars that have a frequency ratio strongly suggesting\nexcitation of two radial modes, and, in addition, their preliminary pulsational\nmodels have the values of $(T_{\\rm eff},~ L)$ consistent with observational\ndeterminations. For five double-mode radial pulsators, we perform an extensive\nseismic modeling using the Bayesian analysis based on Monte Carlo simulations.\nWe study the effect of opacity tables and helium abundance. With the OPAL data\nand $Y=0.30$, we obtained masses in the range (1.0,~1.2) M$_{\\odot}$,\nmetallicity $Z\\in(0.0007,~0.0029)$ and the age of about (1.9,~3.8) Gyr. The OP\nand OPLIB seismic models have always higher metallicites, sometimes outside the\nallowed range for $\\omega$ Cen. In the case of three stars, we find seismic\nmodels within the observed range of $(T_{\\rm eff},~L)$ with all three opacity\ntables. In the case of two stars, with the highest metallicity, seismic models\ncomputed with the OP and OPLIB tables are located far outside the observed\nerror box. The OPAL seismic models follow the age$-$metallicity relation known\nfor $\\omega$ Cen from the literature.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-24T16:50:15Z"}
{"aid":"http://arxiv.org/abs/2504.17741v1","title":"Multi-messenger standard-siren cosmology for third-generation\n  gravitational-wave detectors: Considering observations of gamma-ray bursts\n  and kilonovae","summary":"In the third-generation (3G) gravitational-wave (GW) detector era, GW\nmulti-messenger observations for binary neutron star merger events can exert\ngreat impacts on exploring the cosmic expansion history. Extending the previous\nwork, we explore the potential of 3G GW standard siren observations in\ncosmological parameter estimation by considering their associated\nelectromagnetic (EM) counterparts, including $\\gamma$-ray burst (GRB)\ncoincidence observations by the Gravitational wave high-energy Electromagnetic\nCounterpart All-sky Monitor and GW-triggered target-of-opportunity observations\nof kilonovae by different optical survey projects. During an assumed 10-year\nobservation, we predict that the number of detectable GW-kilonova events is\n$\\sim 4900$ with redshifts below $\\sim 0.4$ under GW network and Large Synoptic\nSurvey Telescope in the $i$ band, which is three times more than that of GW-GRB\ndetections. For the cosmological analysis, we find that with the inclusion of\nGW-kilonova detections, the constraints on cosmological parameters from GW-EM\ndetections are significantly improved compared to those from GW-GRB detections.\nIn particular, GW-EM detections can tightly constrain the Hubble constant with\na precision ranging from $0.076\\%$ to $0.034\\%$. Moreover, GW multi-messenger\nobservations could effectively break the cosmological parameter degeneracies\ngenerated by the mainstream EM observations, CMB+BAO+SN (CBS). The combination\nof CBS and GW-EM can tightly constrain the equation of state parameters of dark\nenergy $w$ in the $w$CDM model and $w_0$ in the $w_0w_a$CDM model with\nprecisions of $0.72\\%$ and $0.99\\%$, respectively, meeting the standard of\nprecision cosmology. In conclusion, GW multi-messenger observations could play\na crucial role in helping solve the Hubble tension and probing the fundamental\nnature of dark energy.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-24T16:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.17743v1","title":"Realization of Temporally Connected Graphs Based on Degree Sequences","summary":"Given an undirected graph $G$, the problem of deciding whether $G$ admits a\nsimple and proper time-labeling that makes it temporally connected is known to\nbe NP-hard (G\\\"obel et al., 1991). In this article, we relax this problem and\nask whether a given degree sequence can be realized as a temporally connected\ngraph. Our main results are a complete characterization of the feasible cases,\nand a recognition algorithm that runs in $O(n)$ time for graphical degree\nsequences (realized as simple temporal graphs) and in $O(n+m)$ time for\nmultigraphical degree sequences (realized as non-simple temporal graphs, where\nthe number of time labels on an edge corresponds to the multiplicity of the\nedge in the multigraph). In fact, these algorithms can be made constructive at\nessentially no cost. Namely, we give a constructive $O(n+m)$ time algorithm\nthat outputs, for a given (multi)graphical degree sequence $\\mathbf{d}$, a\ntemporally connected graph whose underlying (multi)graph is a realization of\n$\\mathbf{d}$, if one exists.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T17:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.17744v1","title":"Nearby open clusters with tidal features: golden sample selection and 3D\n  structure","summary":"Open clusters offer unique opportunities to study stellar dynamics and\nevolution under the influence of their internal gravity, the Milky Way's\ngravitational field, and the interactions with encounters. Using the Gaia DR3\ndata for a catalog of open clusters within 500 parsecs that exhibit tidal\nfeatures reported by the literature, we apply a novel method based on 3D\nprincipal component analysis to select a ``golden sample'' of nearby open\nclusters with minimal line-of-sight distortions. This approach ensures a\nsystematic comparison of 3D and 2D structural parameters for tidally perturbed\nclusters. The selected golden sample includes Blanco 1, Melotte 20, Melotte 22,\nNGC 2632, NGC 7092, NGC 1662, Roslund 6 and Melotte 111. We analyze these\nclusters by fitting both 2D and 3D King Profiles to their stellar density\ndistributions. Our results reveal systematic discrepancies: most of the golden\nsample clusters exhibit larger 3D tidal radii compared to their 2D\ncounterparts, demonstrating that the 2D projection effects bias the measured\ncluster size. Furthermore, the 3D density profiles show stronger deviations\nfrom King profiles at the tidal radii ($\\Delta \\rho_{\\rm 3D} > \\Delta \\rho_{\\rm\n2D}$), highlighting enhanced sensitivity to tidal disturbances. Additionally,\nwe investigate the spatial distribution of cluster members relative to their\nbulk motion in the Galactic plane. We find that some clusters exhibit tidal\nfeatures oriented perpendicular to their direction of motion, which can be\nattributed to the fact that the current surveys only detect the curved inner\nregions of the tidal features. In conclusion, this work offers a golden sample\nof nearby open clusters that are most reliable for 3D structure analysis and\nunderscores the necessity of 3D analysis in characterizing OC morphological\nasymmetries, determining cluster size, and identifying tidal features.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-24T17:02:37Z"}
{"aid":"http://arxiv.org/abs/2504.17761v1","title":"Step1X-Edit: A Practical Framework for General Image Editing","summary":"In recent years, image editing models have witnessed remarkable and rapid\ndevelopment. The recent unveiling of cutting-edge multimodal models such as\nGPT-4o and Gemini2 Flash has introduced highly promising image editing\ncapabilities. These models demonstrate an impressive aptitude for fulfilling a\nvast majority of user-driven editing requirements, marking a significant\nadvancement in the field of image manipulation. However, there is still a large\ngap between the open-source algorithm with these closed-source models. Thus, in\nthis paper, we aim to release a state-of-the-art image editing model, called\nStep1X-Edit, which can provide comparable performance against the closed-source\nmodels like GPT-4o and Gemini2 Flash. More specifically, we adopt the\nMultimodal LLM to process the reference image and the user's editing\ninstruction. A latent embedding has been extracted and integrated with a\ndiffusion image decoder to obtain the target image. To train the model, we\nbuild a data generation pipeline to produce a high-quality dataset. For\nevaluation, we develop the GEdit-Bench, a novel benchmark rooted in real-world\nuser instructions. Experimental results on GEdit-Bench demonstrate that\nStep1X-Edit outperforms existing open-source baselines by a substantial margin\nand approaches the performance of leading proprietary models, thereby making\nsignificant contributions to the field of image editing.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T17:25:12Z"}
{"aid":"http://arxiv.org/abs/2504.17762v1","title":"Introducing STARDIS: An Open and Modular Stellar Spectral Synthesis Code","summary":"We introduce a new 1D stellar spectral synthesis Python code called \\stardis.\n\\stardis\\ is a modular, open-source radiative transfer code that is capable of\nspectral synthesis from near-UV to IR for FGK stars. We describe the structure,\ninputs, features, underlying physics, and assumptions of \\stardis\\ as well as\nthe radiative transfer scheme implemented. To validate our code, we show\nspectral comparisons between \\stardis\\ and \\textsc{korg} with the same input\natmospheric structure models, and also compare qualitatively to\n\\textsc{phoenix} for solar models. We find that \\stardis\\ generally agrees well\nwith \\textsc{korg} for solar models on the few percent level or better, that\nthe codes can diverge in the ultraviolet, with more extreme differences in\ncooler stars. \\stardis\\ can be found at\n\\href{https://github.com/tardis-sn/stardis}{https://github.com/tardis-sn/stardis},\nand documentation can be found at\n\\href{https://tardis-sn.github.io/stardis/}{https://tardis-sn.github.io/stardis/}.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM","published":"2025-04-24T17:26:23Z"}
{"aid":"http://arxiv.org/abs/2504.17763v1","title":"Geodesic causality in Kerr spacetimes with $|a|\\geq M$","summary":"The analytic extension of the Kerr spacetimes into the negative radial region\ncontains closed causal curves for any non-zero rotation parameter $a$ and mass\nparameter $M$. Furthermore, the spacetimes become totally vicious when $|a|>M$,\nmeaning that through every point there exists a closed timelike curve. Despite\nthis, we prove that the Kerr spacetimes do not admit any closed null geodesics\nwhen $|a|\\geq M$. This result generalises recent findings by one of the\nauthors, which showed the nonexistence of closed causal geodesics in the case\n$|a|<M$. Combining these results, we establish the absence of closed null\ngeodesics in Kerr spacetimes for any non-zero $a$.","main_category":"gr-qc","categories":"gr-qc,math.DG","published":"2025-04-24T17:26:42Z"}
{"aid":"http://arxiv.org/abs/2504.17770v1","title":"Zeptosecond free-electron compression through temporal lensing","summary":"The pursuit of ever-shorter time scales is a frontier in modern physics,\nexemplified by the synthesis of attosecond light pulses -- an achievement made\npossible by coherently superimposing a broad range of photon energies, as\nrequired by the uncertainty principle. However, extending this progress into\nthe zeptosecond regime poses significant challenges, as it demands\nphase-correlated optical spectra spanning hundreds of electronvolts. In this\ncontext, electrons offer a compelling alternative to light because they can be\ncoherently manipulated to form broad energy superpositions, as demonstrated by\nthe generation of attosecond pulses in ultrafast electron microscopes. Here, we\npropose a practical scheme for compressing free electrons into the zeptosecond\ndomain by modulating their wave functions using suitably tailored broadband\nlight fields. Building on recent advances in {free-electron--light--matter}\ninteractions, our method introduces the concept of temporal lensing -- an\nextension of conventional optical lensing to the time domain -- to produce\nelectron pulses with arbitrarily short durations.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-24T17:41:22Z"}
{"aid":"http://arxiv.org/abs/2504.19938v1","title":"Mesh-Learner: Texturing Mesh with Spherical Harmonics","summary":"In this paper, we present a 3D reconstruction and rendering framework termed\nMesh-Learner that is natively compatible with traditional rasterization\npipelines. It integrates mesh and spherical harmonic (SH) texture (i.e.,\ntexture filled with SH coefficients) into the learning process to learn each\nmesh s view-dependent radiance end-to-end. Images are rendered by interpolating\nsurrounding SH Texels at each pixel s sampling point using a novel\ninterpolation method. Conversely, gradients from each pixel are back-propagated\nto the related SH Texels in SH textures. Mesh-Learner exploits graphic features\nof rasterization pipeline (texture sampling, deferred rendering) to render,\nwhich makes Mesh-Learner naturally compatible with tools (e.g., Blender) and\ntasks (e.g., 3D reconstruction, scene rendering, reinforcement learning for\nrobotics) that are based on rasterization pipelines. Our system can train vast,\nunlimited scenes because we transfer only the SH textures within the frustum to\nthe GPU for training. At other times, the SH textures are stored in CPU RAM,\nwhich results in moderate GPU memory usage. The rendering results on\ninterpolation and extrapolation sequences in the Replica and FAST-LIVO2\ndatasets achieve state-of-the-art performance compared to existing\nstate-of-the-art methods (e.g., 3D Gaussian Splatting and M2-Mapping). To\nbenefit the society, the code will be available at\nhttps://github.com/hku-mars/Mesh-Learner.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-28T16:09:25Z"}
{"aid":"http://arxiv.org/abs/2504.19944v1","title":"Probabilistic and Causal Satisfiability: Constraining the Model","summary":"We study the complexity of satisfiability problems in probabilistic and\ncausal reasoning. Given random variables $X_1, X_2,\\ldots$ over finite domains,\nthe basic terms are probabilities of propositional formulas over atomic events\n$X_i = x_i$, such as $P(X_1 = x_1)$ or $P(X_1 = x_1 \\vee X_2 = x_2)$. The basic\nterms can be combined using addition (yielding linear terms) or multiplication\n(polynomial terms). The probabilistic satisfiability problem asks whether a\njoint probability distribution satisfies a Boolean combination of\n(in)equalities over such terms. Fagin et al. (1990) showed that for basic and\nlinear terms, this problem is NP-complete, making it no harder than Boolean\nsatisfiability, while Moss\\'e et al. (2022) proved that for polynomial terms,\nit is complete for the existential theory of the reals.\n  Pearl's Causal Hierarchy (PCH) extends the probabilistic setting with\ninterventional and counterfactual reasoning, enriching the expressiveness of\nlanguages. However, Moss\\'e et al. (2022) found that satisfiability complexity\nremains unchanged. Van der Zander et al. (2023) showed that introducing a\nmarginalization operator to languages induces a significant increase in\ncomplexity.\n  We extend this line of work by adding two new dimensions to the problem by\nconstraining the models. First, we fix the graph structure of the underlying\nstructural causal model, motivated by settings like Pearl's do-calculus, and\ngive a nearly complete landscape across different arithmetics and PCH levels.\nSecond, we study small models. While earlier work showed that satisfiable\ninstances admit polynomial-size models, this is no longer guaranteed with\ncompact marginalization. We characterize the complexities of satisfiability\nunder small-model constraints across different settings.","main_category":"cs.CC","categories":"cs.CC,cs.AI,cs.LO","published":"2025-04-28T16:14:06Z"}
{"aid":"http://arxiv.org/abs/2504.19955v1","title":"Robust Federated Personalised Mean Estimation for the Gaussian Mixture\n  Model","summary":"Federated learning with heterogeneous data and personalization has received\nsignificant recent attention. Separately, robustness to corrupted data in the\ncontext of federated learning has also been studied. In this paper we explore\ncombining personalization for heterogeneous data with robustness, where a\nconstant fraction of the clients are corrupted. Motivated by this broad\nproblem, we formulate a simple instantiation which captures some of its\ndifficulty. We focus on the specific problem of personalized mean estimation\nwhere the data is drawn from a Gaussian mixture model. We give an algorithm\nwhose error depends almost linearly on the ratio of corrupted to uncorrupted\nsamples, and show a lower bound with the same behavior, albeit with a gap of a\nconstant factor.","main_category":"cs.LG","categories":"cs.LG,cs.IT,math.IT","published":"2025-04-28T16:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.19963v1","title":"Stochastic Subspace via Probabilistic Principal Component Analysis for\n  Characterizing Model Error","summary":"This paper proposes a probabilistic model of subspaces based on the\nprobabilistic principal component analysis (PCA). Given a sample of vectors in\nthe embedding space -- commonly known as a snapshot matrix -- this method uses\nquantities derived from the probabilistic PCA to construct distributions of the\nsample matrix, as well as the principal subspaces. It is applicable to\nprojection-based reduced-order modeling methods, such as proper orthogonal\ndecomposition and related model reduction methods. The stochastic subspace thus\nconstructed can be used, for example, to characterize model-form uncertainty in\ncomputational mechanics. The proposed method has multiple desirable properties:\n(1) it is naturally justified by the probabilistic PCA and has analytic forms\nfor the induced random matrix models; (2) it satisfies linear constraints, such\nas boundary conditions of all kinds, by default; (3) it has only one\nhyperparameter, which significantly simplifies training; and (4) its algorithm\nis very easy to implement. We compare the proposed method with existing\napproaches in a low-dimensional visualization example and a parametric static\nproblem, and demonstrate its performance in a dynamics model of a space\nstructure.","main_category":"cs.CE","categories":"cs.CE,math.ST,physics.comp-ph,physics.data-an,stat.ME,stat.TH","published":"2025-04-28T16:35:01Z"}
{"aid":"http://arxiv.org/abs/2504.19980v1","title":"Deep Declarative Risk Budgeting Portfolios","summary":"Recent advances in deep learning have spurred the development of end-to-end\nframeworks for portfolio optimization that utilize implicit layers. However,\nmany such implementations are highly sensitive to neural network\ninitialization, undermining performance consistency. This research introduces a\nrobust end-to-end framework tailored for risk budgeting portfolios that\neffectively reduces sensitivity to initialization. Importantly, this enhanced\nstability does not compromise portfolio performance, as our framework\nconsistently outperforms the risk parity benchmark.","main_category":"q-fin.PM","categories":"q-fin.PM,q-fin.CP","published":"2025-04-28T16:53:13Z"}
{"aid":"http://arxiv.org/abs/2504.19985v1","title":"Real-Time Imitation of Human Head Motions, Blinks and Emotions by Nao\n  Robot: A Closed-Loop Approach","summary":"This paper introduces a novel approach for enabling real-time imitation of\nhuman head motion by a Nao robot, with a primary focus on elevating human-robot\ninteractions. By using the robust capabilities of the MediaPipe as a computer\nvision library and the DeepFace as an emotion recognition library, this\nresearch endeavors to capture the subtleties of human head motion, including\nblink actions and emotional expressions, and seamlessly incorporate these\nindicators into the robot's responses. The result is a comprehensive framework\nwhich facilitates precise head imitation within human-robot interactions,\nutilizing a closed-loop approach that involves gathering real-time feedback\nfrom the robot's imitation performance. This feedback loop ensures a high\ndegree of accuracy in modeling head motion, as evidenced by an impressive R2\nscore of 96.3 for pitch and 98.9 for yaw. Notably, the proposed approach holds\npromise in improving communication for children with autism, offering them a\nvaluable tool for more effective interaction. In essence, proposed work\nexplores the integration of real-time head imitation and real-time emotion\nrecognition to enhance human-robot interactions, with potential benefits for\nindividuals with unique communication needs.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-28T17:01:54Z"}
{"aid":"http://arxiv.org/abs/2504.20003v1","title":"Deciding summability via residues in theory and in practice","summary":"In difference algebra, summability arises as a basic problem upon which rests\nthe effective solution of other more elaborate problems, such as creative\ntelescoping problems and the computation of Galois groups of difference\nequations. In 2012 Chen and Singer introduced discrete residues as a\ntheoretical obstruction to summability for rational functions with respect to\nthe shift and $q$-dilation difference operators. Since then analogous notions\nof discrete residues have been defined in other difference settings relevant\nfor applications, such as for Mahler and elliptic shift difference operators.\nVery recently there have been some advances in making these theoretical\nobstructions computable in practice.","main_category":"cs.SC","categories":"cs.SC,math.AG,math.NT","published":"2025-04-28T17:24:02Z"}
{"aid":"http://arxiv.org/abs/2504.20014v1","title":"Thin-film scandium aluminum nitride bulk acoustic resonator with high Q\n  of 208 and K2 of 9.5% at 12.5 GHz","summary":"This work describes sputtered scandium aluminum nitride (ScAlN) thin-film\nbulk acoustic resonators (FBAR) at 12.5 GHz with high electromechanical\ncoupling (k2) of 9.5% and quality factor (Q) of 208, resulting in a figure of\nmerit (FoM, Qk2) of 19.8. ScAlN resonators employ a stack of 90 nm thick 20% Sc\ndoping ScAlN piezoelectric film on the floating bottom 38 nm thick platinum\n(Pt) electrode to achieve low losses and high coupling toward centimeter wave\n(cmWave) frequency band operation. Three fabricated and FBARs are reported,\nshow promising prospects of ScAlN-Pt stack towards cmWave front-end filters.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-28T17:33:46Z"}
{"aid":"http://arxiv.org/abs/2504.20031v1","title":"Towards Scalable Braiding: Topological Superconductivity Unlocked under\n  Nearly Arbitrary Magnetic Field Directions in Planar Josephson Junctions","summary":"Majorana zero modes (MZM), distinguished by their non-locality and\nnon-Abelian statistics, are central to the pursuit of fault-tolerant\ntopological quantum computing. Planar Josephson junctions (PJJ) have emerged as\na promising platform, offering robust and tunable MZM. However, the perceived\nsensitivity of topological superconductivity to the magnetic field orientation\nhas posed a major obstacle, particularly for scalable network architectures.\nHere, we uncover that topological superconductivity in PJJ fundamentally\npersists under nearly arbitrary in-plane magnetic field directions. The\napparent collapse of the global gap under misaligned fields originates not from\nthe destruction of superconductivity itself, but from emergent shifted bulk\nstates from other momentum points, which obscure the gap and MZM. By\nintroducing spatial modulations along the junction to scatter and gap out these\nbulk states, we restore the global topological gap and recover visible MZM.\nRemarkably, the spatially modulated PJJs render topological superconductivity\nrobust against maligned fields, thereby enabling MZM survival across complex\njunction networks and facilitating their braiding. We propose a scalable\nprotocol for MZM braiding and fusion with phase or gate control, opening new\nroutes toward scalable topological quantum computing.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-28T17:55:52Z"}
{"aid":"http://arxiv.org/abs/2504.20039v1","title":"AutoJudge: Judge Decoding Without Manual Annotation","summary":"We introduce AutoJudge, a framework that accelerates large language model\n(LLM) inference with task-specific lossy speculative decoding. Instead of\nmatching the original model output distribution token-by-token, we identify\nwhich of the generated tokens affect the downstream quality of the generated\nresponse, relaxing the guarantee so that the \"unimportant\" tokens can be\ngenerated faster. Our approach relies on a semi-greedy search algorithm to test\nwhich of the mismatches between target and draft model should be corrected to\npreserve quality, and which ones may be skipped. We then train a lightweight\nclassifier based on existing LLM embeddings to predict, at inference time,\nwhich mismatching tokens can be safely accepted without compromising the final\nanswer quality. We test our approach with Llama 3.2 1B (draft) and Llama 3.1 8B\n(target) models on zero-shot GSM8K reasoning, where it achieves up to 1.5x more\naccepted tokens per verification cycle with under 1% degradation in answer\naccuracy compared to standard speculative decoding and over 2x with small loss\nin accuracy. When applied to the LiveCodeBench benchmark, our approach\nautomatically detects other, programming-specific important tokens and shows\nsimilar speedups, demonstrating its ability to generalize across tasks.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-28T17:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.20046v1","title":"On the Properties of Cosmological Ionization Fronts","summary":"We investigate the properties of cosmological ionization fronts during the\nEpoch of Reionization using the CROC simulations. By analyzing reionization\ntiming maps, we characterize ionization front velocities and curvatures and\ntheir dependence on the density structure of the intergalactic medium (IGM).\nThe velocity distribution of ionization fronts in the simulations indicates\nthat while the barrier-crossing analytical model captures the overall shape in\nhigh-velocity regions, it fails to reproduce the low-velocity tail,\nhighlighting the non-Gaussian nature of the IGM's density field. Ionization\nfront velocities are inversely correlated with local density, propagating\nfaster in underdense regions and more slowly in overdense environments. Faster\nionization fronts also lead to higher post-ionization temperatures, reaching a\nplateau at $\\sim 2 \\times 10^4$ K for velocities exceeding 3000 km/s. Examining\ncurvature statistics further establishes a connection between ionization front\nstructure and the normalized density contrast $\\nu$, with trends in overdense\nregions aligning well with barrier-crossing model predictions, while deviations\nappear in underdense environments due to model limitations. These results\nprovide a detailed characterization of ionization front dynamics and their\ninteraction with the underlying density field, bridging small-scale\nreionization physics with large-scale observables such as the 21 cm signal and\nthe IGM's thermal history.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-28T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.20388v1","title":"The two-clock problem in population dynamics","summary":"Biological time can be measured in two ways: in generations and in physical\ntime. When generation intervals differ between individuals, these two clocks\ndiverge, which impedes our ability to relate mathematical models to real\npopulations. In this paper we show that nevertheless, these disparate clocks\nbecome equivalent in the long run via a simple identity relating generational\nand physical time. This equivalence allows us to directly translate statements\nfrom mathematical models to the physical world and vice versa. As an\napplication, we obtain a generalized Euler-Lotka equation linking the basic\nreproduction number $R_0$ to the growth rate, and derive several\ninformation-theoretic bounds on these quantities. We also show how the fitness\nof a lineage can be defined consistently in population models, with\napplications to microbial growth, epidemiology and population biology.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.bio-ph","published":"2025-04-29T03:15:23Z"}
{"aid":"http://arxiv.org/abs/2504.20424v1","title":"ESPARTACO 2, a new stellar spectrograph at Uniandes","summary":"We present the construction and early results of ESPARTACO 2, the new stellar\nspectrograph built for research and education at the Astronomical Observatory\nof the Universidad de los Andes in Bogot\\'a, Colombia. This instrument offers\nseveral resolutions from 20,000 in first order using a 50 $\\mu$m fiber, to\n100,000 in second order in the near infrared. Precise radial-velocity\nmeasurements are made possible by simultaneous wavelength calibration. Combined\nwith the 40-cm Meade telescope located at our facilities, a limiting magnitude\nof 6 is reached. This instrument is a considerable improvement over its\npredecessor in throughput, reliability and ease.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.SR","published":"2025-04-29T04:39:20Z"}
{"aid":"http://arxiv.org/abs/2504.20425v1","title":"Metaheuristic Optimization of Trajectory and Dynamic Time Splitting for\n  UAV Communication Systems","summary":"The integration of unmanned aerial vehicles (UAVs) into wireless\ncommunication systems has emerged as a transformative approach, promising\ncost-efficient connectivity. This paper addresses the optimization of the\ndynamic time-splitting ratio and flight trajectory for a communication system\nlinking a ground base station to the UAV equipped with backscatter devices\n(referred to as UB), and from UB to an end user. Given the inherent\nnon-convexity of the problem, we develop two meta-heuristic-based approaches\ninspired by genetic algorithm and particle swarm optimization to enhance the\ntotal achievable rate while reducing computational complexity. Numerical\nresults demonstrate the effectiveness of these meta-heuristic solutions,\nshowcasing significant improvements in the achievable rate and computation time\ncompared to existing benchmarks.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-29T04:39:29Z"}
{"aid":"http://arxiv.org/abs/2504.20427v1","title":"Trees in the Largest Order With a Given Burning Number","summary":"Graph burning is modelled upon the spread of contagion, and the burning\nnumber measures the speed of the spread. By the fact that the burning number of\na connected graph is the minimum burning number of its spanning trees, our work\nfocuses on identifying the largest order of a general tree with a given burning\nnumber up to homeomorphism. In this work, we propose the concept of admissible\nsequences over a homeomorphically irreducible tree in addition to developing a\ngeneral framework. We then determine whether an admissible sequence induces a\ntree with a given burning number of the largest order. Additionally, we obtain\nsome results on the smallest attainable diameter of an $n$-spider having the\nlargest order with a given burning number.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T04:45:57Z"}
{"aid":"http://arxiv.org/abs/2504.20435v1","title":"AI Assisted Cervical Cancer Screening for Cytology Samples in Developing\n  Countries","summary":"Cervical cancer remains a significant health challenge, with high incidence\nand mortality rates, particularly in transitioning countries. Conventional\nLiquid-Based Cytology(LBC) is a labor-intensive process, requires expert\npathologists and is highly prone to errors, highlighting the need for more\nefficient screening methods. This paper introduces an innovative approach that\nintegrates low-cost biological microscopes with our simple and efficient AI\nalgorithms for automated whole-slide analysis. Our system uses a motorized\nmicroscope to capture cytology images, which are then processed through an AI\npipeline involving image stitching, cell segmentation, and classification. We\nutilize the lightweight UNet-based model involving human-in-the-loop approach\nto train our segmentation model with minimal ROIs. CvT-based classification\nmodel, trained on the SIPaKMeD dataset, accurately categorizes five cell types.\nOur framework offers enhanced accuracy and efficiency in cervical cancer\nscreening compared to various state-of-art methods, as demonstrated by\ndifferent evaluation metrics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T05:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.20438v1","title":"PixelHacker: Image Inpainting with Structural and Semantic Consistency","summary":"Image inpainting is a fundamental research area between image editing and\nimage generation. Recent state-of-the-art (SOTA) methods have explored novel\nattention mechanisms, lightweight architectures, and context-aware modeling,\ndemonstrating impressive performance. However, they often struggle with complex\nstructure (e.g., texture, shape, spatial relations) and semantics (e.g., color\nconsistency, object restoration, and logical correctness), leading to artifacts\nand inappropriate generation. To address this challenge, we design a simple yet\neffective inpainting paradigm called latent categories guidance, and further\npropose a diffusion-based model named PixelHacker. Specifically, we first\nconstruct a large dataset containing 14 million image-mask pairs by annotating\nforeground and background (potential 116 and 21 categories, respectively).\nThen, we encode potential foreground and background representations separately\nthrough two fixed-size embeddings, and intermittently inject these features\ninto the denoising process via linear attention. Finally, by pre-training on\nour dataset and fine-tuning on open-source benchmarks, we obtain PixelHacker.\nExtensive experiments show that PixelHacker comprehensively outperforms the\nSOTA on a wide range of datasets (Places2, CelebA-HQ, and FFHQ) and exhibits\nremarkable consistency in both structure and semantics. Project page at\nhttps://hustvl.github.io/projects/PixelHacker.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T05:28:36Z"}
{"aid":"http://arxiv.org/abs/2504.20442v1","title":"Multidimensional precipitation index prediction based on CNN-LSTM hybrid\n  framework","summary":"With the intensification of global climate change, accurate prediction of\nweather indicators is of great significance in disaster prevention and\nmitigation, agricultural production, and transportation. Precipitation, as one\nof the key meteorological indicators, plays a crucial role in water resource\nmanagement, agricultural production, and urban flood control. This study\nproposes a multidimensional precipitation index prediction model based on a\nCNN- LSTM hybrid framework, aiming to improve the accuracy of precipitation\nforecasts. The dataset is sourced from Pune, Maharashtra, India, covering\nmonthly mean precipitation data from 1972 to 2002. This dataset includes nearly\n31 years (1972-2002) of monthly average precipitation, reflecting the long-term\nfluctuations and seasonal variations of precipitation in the region. By\nanalyzing these time series data, the CNN-LSTM model effectively captures local\nfeatures and long-term dependencies. Experimental results show that the model\nachieves a root mean square error (RMSE) of 6.752, which demonstrates a\nsignificant advantage over traditional time series prediction methods in terms\nof prediction accuracy and generalization ability. Furthermore, this study\nprovides new research ideas for precipitation prediction. However, the model\nrequires high computational resources when dealing with large-scale datasets,\nand its predictive ability for multidimensional precipitation data still needs\nimprovement. Future research could extend the model to support and predict\nmultidimensional precipitation data, thereby promoting the development of more\naccurate and efficient meteorological prediction technologies.","main_category":"cs.LG","categories":"cs.LG,cs.HC","published":"2025-04-29T05:32:43Z"}
{"aid":"http://arxiv.org/abs/2504.20447v1","title":"APG-MOS: Auditory Perception Guided-MOS Predictor for Synthetic Speech","summary":"Automatic speech quality assessment aims to quantify subjective human\nperception of speech through computational models to reduce the need for\nlabor-consuming manual evaluations. While models based on deep learning have\nachieved progress in predicting mean opinion scores (MOS) to assess synthetic\nspeech, the neglect of fundamental auditory perception mechanisms limits\nconsistency with human judgments. To address this issue, we propose an auditory\nperception guided-MOS prediction model (APG-MOS) that synergistically\nintegrates auditory modeling with semantic analysis to enhance consistency with\nhuman judgments. Specifically, we first design a perceptual module, grounded in\nbiological auditory mechanisms, to simulate cochlear functions, which encodes\nacoustic signals into biologically aligned electrochemical representations.\nSecondly, we propose a residual vector quantization (RVQ)-based semantic\ndistortion modeling method to quantify the degradation of speech quality at the\nsemantic level. Finally, we design a residual cross-attention architecture,\ncoupled with a progressive learning strategy, to enable multimodal fusion of\nencoded electrochemical signals and semantic representations. Experiments\ndemonstrate that APG-MOS achieves superior performance on two primary\nbenchmarks. Our code and checkpoint will be available on a public repository\nupon publication.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-29T05:45:09Z"}
{"aid":"http://arxiv.org/abs/2504.20461v1","title":"Efficient Graph-Based Approximate Nearest Neighbor Search Achieving: Low\n  Latency Without Throughput Loss","summary":"The increase in the dimensionality of neural embedding models has enhanced\nthe accuracy of semantic search capabilities but also amplified the\ncomputational demands for Approximate Nearest Neighbor Searches (ANNS). This\ncomplexity poses significant challenges in online and interactive services,\nwhere query latency is a critical performance metric. Traditional graph-based\nANNS methods, while effective for managing large datasets, often experience\nsubstantial throughput reductions when scaled for intra-query parallelism to\nminimize latency. This reduction is largely due to inherent inefficiencies in\nthe conventional fork-join parallelism model.\n  To address this problem, we introduce AverSearch, a novel parallel\ngraph-based ANNS framework that overcomes these limitations through a fully\nasynchronous architecture. Unlike existing frameworks that struggle with\nbalancing latency and throughput, AverSearch utilizes a dynamic workload\nbalancing mechanism that supports continuous, dependency-free processing. This\napproach not only minimizes latency by eliminating unnecessary synchronization\nand redundant vertex processing but also maintains high throughput levels. Our\nevaluations across various datasets, including both traditional benchmarks and\nmodern large-scale model generated datasets, show that AverSearch consistently\noutperforms current state-of-the-art systems. It achieves up to 2.1-8.9 times\nhigher throughput at comparable latency levels across different datasets and\nreduces minimum latency by 1.5 to 1.9 times.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-29T06:50:20Z"}
{"aid":"http://arxiv.org/abs/2504.20472v1","title":"Robustness via Referencing: Defending against Prompt Injection Attacks\n  by Referencing the Executed Instruction","summary":"Large language models (LLMs) have demonstrated impressive performance and\nhave come to dominate the field of natural language processing (NLP) across\nvarious tasks. However, due to their strong instruction-following capabilities\nand inability to distinguish between instructions and data content, LLMs are\nvulnerable to prompt injection attacks. These attacks manipulate LLMs into\ndeviating from the original input instructions and executing maliciously\ninjected instructions within data content, such as web documents retrieved from\nsearch engines. Existing defense methods, including prompt-engineering and\nfine-tuning approaches, typically instruct models to follow the original input\ninstructions while suppressing their tendencies to execute injected\ninstructions. However, our experiments reveal that suppressing\ninstruction-following tendencies is challenging. Through analyzing failure\ncases, we observe that although LLMs tend to respond to any recognized\ninstructions, they are aware of which specific instructions they are executing\nand can correctly reference them within the original prompt. Motivated by these\nfindings, we propose a novel defense method that leverages, rather than\nsuppresses, the instruction-following abilities of LLMs. Our approach prompts\nLLMs to generate responses that include both answers and their corresponding\ninstruction references. Based on these references, we filter out answers not\nassociated with the original input instructions. Comprehensive experiments\ndemonstrate that our method outperforms prompt-engineering baselines and\nachieves performance comparable to fine-tuning methods, reducing the attack\nsuccess rate (ASR) to 0 percent in some scenarios. Moreover, our approach has\nminimal impact on overall utility.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T07:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.20474v1","title":"Research on Non-Contact Resistance","summary":"This paper investigated the phenomenon of non-contact resistance by inserting\na non-magnetic metal rod into an induction coil to explore the response changes\nof an LRC circuit. We focused on analyzing the changes in inductance when\nnon-ferromagnetic materials (such as H59 brass) were inserted into the coil and\nverified the impact of the copper rod on inductance through theoretical\nderivation and experimental validation. Based on Maxwell's equations, the\nmagnetic field distribution within the copper rod was thoroughly derived, and\nthe inductance and resistance values were experimentally measured. These\nresults confirm the accuracy of the theoretical model.","main_category":"physics.class-ph","categories":"physics.class-ph,cond-mat.mtrl-sci","published":"2025-04-29T07:14:58Z"}
{"aid":"http://arxiv.org/abs/2504.20482v1","title":"Group Relative Knowledge Distillation: Learning from Teacher's\n  Relational Inductive Bias","summary":"Knowledge distillation typically transfers knowledge from a teacher model to\na student model by minimizing differences between their output distributions.\nHowever, existing distillation approaches largely focus on mimicking absolute\nprobabilities and neglect the valuable relational inductive biases embedded in\nthe teacher's relative predictions, leading to exposure bias. In this paper, we\npropose Group Relative Knowledge Distillation (GRKD), a novel framework that\ndistills teacher knowledge by learning the relative ranking among classes,\nrather than directly fitting the absolute distribution. Specifically, we\nintroduce a group relative loss that encourages the student model to preserve\nthe pairwise preference orderings provided by the teacher's outputs. Extensive\nexperiments on classification benchmarks demonstrate that GRKD achieves\nsuperior generalization compared to existing methods, especially in tasks\nrequiring fine-grained class differentiation. Our method provides a new\nperspective on exploiting teacher knowledge, focusing on relational structure\nrather than absolute likelihood.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-29T07:23:22Z"}
{"aid":"http://arxiv.org/abs/2504.20487v1","title":"Continuum, CO and Water vapour maps of the Orion Nebula. First\n  millimetre spectral imaging with Concerto","summary":"The millimetre spectrum of Galactic regions and galaxies is rich in continuum\nand molecular lines. That diversity is mostly tackled by either broad-band\nphotometry or high resolution heterodyne spectroscopy. We aim to map the\nmillimetre continuum emission of Galactic regions with a spectral resolution\nintermediate between broad-band photometry and heterodyne spectroscopy,\nenabling us to quickly cover large sky areas with spectroscopy. We report\nobservations of the Orion Nebula with the CONCERTO instrument, which was\ninstalled at the APEX telescope focal plane from April 2021 to December 2023.\nWe find that the spectrum of Orion is dominated by dust emission with an\nemissivity index from 1.3 to 2.0 along with the strong CO(2-1) and H$_2$O lines\nwhich are naturally separated from the continuum, thanks to CONCERTO spectral\ncapabilities. Many regions show a strong free-free emission as well, at lower\nfrequencies. We demonstrate the spectral capabilities of CONCERTO at\nintermediate spectral resolution, with a frequency coverage from 130 to 310\nGHz. A sensitivity of 200 mK is achieved in one second, for one beam and a 6\nGHz frequency width, over an 18 arcmin diameter field-of-view, which is within\na factor 3 of the expectations. We show that we can spectrally disentangle the\ncontinuum from the CO line emission. The slope of the millimetre continuum is\nline-free mapped for the first time in Orion.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.IM","published":"2025-04-29T07:25:42Z"}
{"aid":"http://arxiv.org/abs/2504.20510v1","title":"SteelBlastQC: Shot-blasted Steel Surface Dataset with Interpretable\n  Detection of Surface Defects","summary":"Automating the quality control of shot-blasted steel surfaces is crucial for\nimproving manufacturing efficiency and consistency. This study presents a\ndataset of 1654 labeled RGB images (512x512) of steel surfaces, classified as\neither \"ready for paint\" or \"needs shot-blasting.\" The dataset captures\nreal-world surface defects, including discoloration, welding lines, scratches\nand corrosion, making it well-suited for training computer vision models.\nAdditionally, three classification approaches were evaluated: Compact\nConvolutional Transformers (CCT), Support Vector Machines (SVM) with ResNet-50\nfeature extraction, and a Convolutional Autoencoder (CAE). The supervised\nmethods (CCT and SVM) achieve 95% classification accuracy on the test set, with\nCCT leveraging transformer-based attention mechanisms and SVM offering a\ncomputationally efficient alternative. The CAE approach, while less effective,\nestablishes a baseline for unsupervised quality control. We present\ninterpretable decision-making by all three neural networks, allowing industry\nusers to visually pinpoint problematic regions and understand the model's\nrationale. By releasing the dataset and baseline codes, this work aims to\nsupport further research in defect detection, advance the development of\ninterpretable computer vision models for quality control, and encourage the\nadoption of automated inspection systems in industrial applications.","main_category":"cs.CV","categories":"cs.CV,cs.NE","published":"2025-04-29T07:51:58Z"}
{"aid":"http://arxiv.org/abs/2504.20519v1","title":"Conversations with AI Chatbots Increase Short-Term Vaccine Intentions\n  But Do Not Outperform Standard Public Health Messaging","summary":"Large language model (LLM) based chatbots show promise in persuasive\ncommunication, but existing studies often rely on weak controls or focus on\nbelief change rather than behavioral intentions or outcomes. This\npre-registered multi-country (US, Canada, UK) randomized controlled trial\ninvolving 930 vaccine-hesitant parents evaluated brief (three-minute)\nmulti-turn conversations with LLM-based chatbots against standard public health\nmessaging approaches for increasing human papillomavirus (HPV) vaccine\nintentions for their children. Participants were randomly assigned to: (1) a\nweak control (no message), (2) a strong control reflecting the standard of care\n(reading official public health materials), or (3 and 4) one of two chatbot\nconditions. One chatbot was prompted to deliver short, conversational\nresponses, while the other used the model's default output style (longer with\nbullet points). While chatbot interactions significantly increased\nself-reported vaccination intent (by 7.1-10.3 points on a 100-point scale)\ncompared to no message, they did not outperform standard public health\nmaterials, with the conversational chatbot performing significantly worse.\nAdditionally, while the short-term effects of chatbot interactions faded during\na 15-day follow-up, the effects of public health material persisted relative to\nno message. These findings suggest that while LLMs can effectively shift\nvaccination intentions in the short-term, their incremental value over existing\npublic health communications is questionable, offering a more tempered view of\ntheir persuasive capabilities and highlighting the importance of integrating\nAI-driven tools alongside, rather than replacing, current public health\nstrategies.","main_category":"cs.CY","categories":"cs.CY,cs.HC","published":"2025-04-29T07:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.20520v1","title":"PRISM: Projection-based Reward Integration for Scene-Aware\n  Real-to-Sim-to-Real Transfer with Few Demonstrations","summary":"Learning from few demonstrations to develop policies robust to variations in\nrobot initial positions and object poses is a problem of significant practical\ninterest in robotics. Compared to imitation learning, which often struggles to\ngeneralize from limited samples, reinforcement learning (RL) can autonomously\nexplore to obtain robust behaviors. Training RL agents through direct\ninteraction with the real world is often impractical and unsafe, while building\nsimulation environments requires extensive manual effort, such as designing\nscenes and crafting task-specific reward functions. To address these\nchallenges, we propose an integrated real-to-sim-to-real pipeline that\nconstructs simulation environments based on expert demonstrations by\nidentifying scene objects from images and retrieving their corresponding 3D\nmodels from existing libraries. We introduce a projection-based reward model\nfor RL policy training that is supervised by a vision-language model (VLM)\nusing human-guided object projection relationships as prompts, with the policy\nfurther fine-tuned using expert demonstrations. In general, our work focuses on\nthe construction of simulation environments and RL-based policy training,\nultimately enabling the deployment of reliable robotic control policies in\nreal-world scenarios.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-29T08:01:27Z"}
{"aid":"http://arxiv.org/abs/2504.20538v1","title":"Molecular gas in cool-core brightest cluster galaxies at $z\\simeq0.4$","summary":"Brightest cluster galaxies (BCG) are today passive and very massive galaxies\nat the center of their clusters, still accreting mass through swallowing\ncompanions, and flows of cold gas, regulated by radio-mode active galactic\nnucleus (AGN) feedback. However, their formation history is still a matter of\ndebate. We report new results based on millimeter observations performed with\nthe Northern Extended Millimeter Array (NOEMA) interferometer, mapping the cold\nmolecular gas (CO) that feeds the star formation of distant BCGs. We selected\nthree among the strongest cool-core BCGs at intermediate redshifts\n($z\\simeq0.4$), namely RX 1532, MACS 1447, and CHIPS 1911. Previous unresolved\nmillimeter observations and multi-wavelength analysis showed that they are\namong the most star forming (${\\rm SFR}\\simeq100~ M_\\odot/{\\rm yr}$) and gas\nrich ($M_{H_2}\\simeq10^{11}~M_\\odot$) BCGs at intermediate redshifts. The\nselected BCGs are thus caught in a phase of rapid mass assembly, which makes\nthem ideal targets for high-resolution observations of their molecular gas. By\ncombining NOEMA intensity and velocity maps with archival images from the\nHubble Space Telescope, we detect in-situ star formation, filaments of\naccreting cold gas likely regulated by AGN feedback, disturbed morphology\nassociated with tidal tails of molecular gas, as well as gas compression and\ntails originated from stripping of gas. While effective condensation of the\nintra-cluster medium is required to explain the large molecular gas reservoirs,\nthe BCGs exhibit a broad variety of environment-driven mechanisms responsible\nfor the processing of their cold gas: flows of cooling gas (RX 1532), ram\npressure or sloshing of the intra-cluster medium (MACS 1447), and galactic\ntides (CHIPS 1911). This study thus sheds new insights on the physical\nmechanisms responsible for the mass assembly of galaxies hosting AGN at the\ncenter of clusters.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-29T08:31:45Z"}
{"aid":"http://arxiv.org/abs/2504.20543v1","title":"Evolution of precessing binary black holes on eccentric orbits using\n  orbit-averaged evolution equations","summary":"The most general bound binary black hole (BBH) system has an eccentric orbit\nand precessing spins. The detection of such a system with significant\neccentricity close to the merger would be a clear signature of dynamical\nformation. In order to study such systems, it is important to be able to evolve\ntheir spins and eccentricity from the larger separations at which the binary\nformed to the smaller separations at which it is detected, or vice versa.\nKnowledge of the precessional evolution of the binary's orbital angular\nmomentum can also be used to twist up aligned-spin eccentric waveform models to\ncreate a spin-precessing eccentric waveform model. In this paper, we present a\nnew publicly available code to evolve eccentric, precessing BBHs using\norbit-averaged post-Newtonian (PN) equations from the literature. The\nspin-precession dynamics is 2PN accurate, i.e., with the leading spin-orbit and\nspin-spin corrections. The evolution of orbital parameters (orbital frequency,\neccentricity, and periastron precession), which follow the quasi-Keplerian\nparametrization, is 3PN accurate in the point particle terms and includes the\nleading order spin-orbit and spin-spin effects. All the spin-spin terms include\nthe quadrupole-monopole interaction. The eccentricity enhancement functions in\nthe fluxes use the high-accuracy hyperasymptotic expansions from Loutrel and\nYunes [Classical Quantum Gravity {\\bf 34} 044003 (2017)]. We discuss various\nfeatures of the code and study the evolution of the orbital and spin-precession\nparameters of eccentric, precessing BBHs. In particular, we study the\ndependence of the spin morphologies on eccentricity, where we find that the\ntransition point from one spin morphology to another can depend\nnonmonotonically on eccentricity, and the fraction of binaries in a given\nmorphology at a given point in the evolution of a population depends on the\ninstantaneous eccentricity.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-29T08:40:07Z"}
{"aid":"http://arxiv.org/abs/2504.20555v1","title":"From regular expressions to deterministic finite automata:\n  $2^{\\frac{n}{2}+\\sqrt{n}(\\log n)^{Î˜(1)}}$ states are necessary and\n  sufficient","summary":"It is proved that every regular expression of alphabetic width $n$, that is,\nwith $n$ occurrences of symbols of the alphabet, can be transformed into a\ndeterministic finite automaton (DFA) with $2^{\\frac{n}{2}+(\\frac{\\log_2\ne}{2\\sqrt{2}}+o(1))\\sqrt{n\\ln n}}$ states recognizing the same language (the\nbest upper bound up to date is $2^n$). At the same time, it is also shown that\nthis bound is close to optimal, namely, that there exist regular expressions of\nalphabetic width $n$ over a two-symbol alphabet, such that every DFA for the\nsame language has at least $2^{\\frac{n}{2}+(\\sqrt{2} + o(1))\\sqrt{\\frac{n}{\\ln\nn}}}$ states (the previously known lower bound is\n$\\frac{5}{4}2^{\\frac{n}{2}}$). The same bounds are obtained for an intermediate\nproblem of determinizing nondetermistic finite automata (NFA) with each state\nhaving all incoming transitions by the same symbol.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-29T08:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.20558v1","title":"Galois measures and the Katz map","summary":"The purpose of this paper is to explain the proofs of the results announced\nby Nick Katz in 1977, namely a description of ``Galois measures for Tate\nmodules of height two formal groups over the ring of integers of a finite\nunramified extension of $\\mathbf{Q}_p$''.","main_category":"math.NT","categories":"math.NT","published":"2025-04-29T09:00:18Z"}
{"aid":"http://arxiv.org/abs/2504.20576v1","title":"From Klein-Gordon-Wave to SchrÃ¶dinger-Wave: a Normal Form Approach","summary":"In this study, we consider a Klein-Gordon-Wave system, which couples the\nevolution of a massive field and a massless one through a Yukawa interaction\nand we derive its Hamiltonian normal form to second order. To the first-order\napproximation, the normal form results in a Schr\\\"odinger-Wave system, while a\nSchr\\\"odinger-Poisson system is derived in the limit of vanishing perturbative\nparameter. A second-order approximation provides the successive corrections to\nthe Schr\\\"odinger-Wave system, while higher-order approximations can be\nobtained by iterating our constructive procedure.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-29T09:30:42Z"}
{"aid":"http://arxiv.org/abs/2504.20579v1","title":"Representation Learning Preserving Ignorability and Covariate Matching\n  for Treatment Effects","summary":"Estimating treatment effects from observational data is challenging due to\ntwo main reasons: (a) hidden confounding, and (b) covariate mismatch (control\nand treatment groups not having identical distributions). Long lines of works\nexist that address only either of these issues. To address the former,\nconventional techniques that require detailed knowledge in the form of causal\ngraphs have been proposed. For the latter, covariate matching and importance\nweighting methods have been used. Recently, there has been progress in\ncombining testable independencies with partial side information for tackling\nhidden confounding. A common framework to address both hidden confounding and\nselection bias is missing. We propose neural architectures that aim to learn a\nrepresentation of pre-treatment covariates that is a valid adjustment and also\nsatisfies covariate matching constraints. We combine two different neural\narchitectures: one based on gradient matching across domains created by\nsubsampling a suitable anchor variable that assumes causal side information,\nfollowed by the other, a covariate matching transformation. We prove that\napproximately invariant representations yield approximate valid adjustment sets\nwhich would enable an interval around the true causal effect. In contrast to\nusual sensitivity analysis, where an unknown nuisance parameter is varied, we\nhave a testable approximation yielding a bound on the effect estimate. We also\noutperform various baselines with respect to ATE and PEHE errors on causal\nbenchmarks that include IHDP, Jobs, Cattaneo, and an image-based Crowd\nManagement dataset.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-29T09:33:56Z"}
{"aid":"http://arxiv.org/abs/2504.20595v1","title":"ReasonIR: Training Retrievers for Reasoning Tasks","summary":"We present ReasonIR-8B, the first retriever specifically trained for general\nreasoning tasks. Existing retrievers have shown limited gains on reasoning\ntasks, in part because existing training datasets focus on short factual\nqueries tied to documents that straightforwardly answer them. We develop a\nsynthetic data generation pipeline that, for each document, our pipeline\ncreates a challenging and relevant query, along with a plausibly related but\nultimately unhelpful hard negative. By training on a mixture of our synthetic\ndata and existing public data, ReasonIR-8B achieves a new state-of-the-art of\n29.9 nDCG@10 without reranker and 36.9 nDCG@10 with reranker on BRIGHT, a\nwidely-used reasoning-intensive information retrieval (IR) benchmark. When\napplied to RAG tasks, ReasonIR-8B improves MMLU and GPQA performance by 6.4%\nand 22.6% respectively, relative to the closed-book baseline, outperforming\nother retrievers and search engines. In addition, ReasonIR-8B uses test-time\ncompute more effectively: on BRIGHT, its performance consistently increases\nwith longer and more information-rich rewritten queries; it continues to\noutperform other retrievers when combined with an LLM reranker. Our training\nrecipe is general and can be easily extended to future LLMs; to this end, we\nopen-source our code, data, and model.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.IR,cs.LG","published":"2025-04-29T09:49:28Z"}
{"aid":"http://arxiv.org/abs/2504.20602v1","title":"Purifying, Labeling, and Utilizing: A High-Quality Pipeline for Small\n  Object Detection","summary":"Small object detection is a broadly investigated research task and is\ncommonly conceptualized as a \"pipeline-style\" engineering process. In the\nupstream, images serve as raw materials for processing in the detection\npipeline, where pre-trained models are employed to generate initial feature\nmaps. In the midstream, an assigner selects training positive and negative\nsamples. Subsequently, these samples and features are fed into the downstream\nfor classification and regression. Previous small object detection methods\noften focused on improving isolated stages of the pipeline, thereby neglecting\nholistic optimization and consequently constraining overall performance gains.\nTo address this issue, we have optimized three key aspects, namely Purifying,\nLabeling, and Utilizing, in this pipeline, proposing a high-quality Small\nobject detection framework termed PLUSNet. Specifically, PLUSNet comprises\nthree sequential components: the Hierarchical Feature Purifier (HFP) for\npurifying upstream features, the Multiple Criteria Label Assignment (MCLA) for\nimproving the quality of midstream training samples, and the Frequency\nDecoupled Head (FDHead) for more effectively exploiting information to\naccomplish downstream tasks. The proposed PLUS modules are readily integrable\ninto various object detectors, thus enhancing their detection capabilities in\nmulti-scale scenarios. Extensive experiments demonstrate the proposed PLUSNet\nconsistently achieves significant and consistent improvements across multiple\ndatasets for small object detection.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T10:11:03Z"}
{"aid":"http://arxiv.org/abs/2504.20611v1","title":"Multi-Component Ionized Gas Outflows in a Hot Dust-Obscured Galaxy\n  W2026+0716 with Keck/OSIRIS","summary":"We present narrowband-filtered integral field unit (IFU) observations of the\nHot Dust-Obscured Galaxy (Hot DOG) WISE J202615.27$+$071624.0 (hereafter\nW2026$+$0716) at redshift $z=2.570$ using Keck/OSIRIS. Our analysis reveals a\nmulti-component ionized gas outflow structure in this heavily obscured AGN host\ngalaxy. Multi-component Gaussian decomposition of the [O III] and H$\\alpha$\nemission lines uncovers extremely broad and asymmetric profiles, characteristic\nof AGN-driven outflows. Kinematic mapping shows spatially distinct structures:\nthe [O III] and H$\\alpha$ dominated components (with radii of $1.20 \\pm 0.56$\nkpc) are separated by a projected offset of $\\sim 1.1$ kpc and exhibit\ndivergent velocity regimes. The [O III] outflow reaches a velocity of 3210\n$\\pm$ 50 km s$^{-1}$, while the H$\\alpha$ outflow component attains 2310 $\\pm$\n840 km s$^{-1}$. Dynamical modeling supports a biconical outflow structure,\nwith [O III] and H$\\alpha$ emissions dominating separate cones and significant\ndust obscuration of the redshifted outflow. Their comparable momentum outflow\nrates and energy outflow rates suggest a potential physical connection in their\ndriving mechanisms. Spectral energy distribution (SED) analysis reveals\nanomalous optical/UV excess, attributed to AGN photon scattering by dust or\noutflowing material, classifying W2026+0716 as a \"Blue Hot DOG\". The derived\noutflow timescale ($\\sim10^{5}$ yr) aligns with the evolutionary phase of Blue\nHot DOGs, suggesting AGN feedback operates persistently during this\ntransitional stage.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-29T10:23:02Z"}
{"aid":"http://arxiv.org/abs/2504.20617v1","title":"Sobolev norm inconsistency of kernel interpolation","summary":"We study the consistency of minimum-norm interpolation in reproducing kernel\nHilbert spaces corresponding to bounded kernels. Our main result give lower\nbounds for the generalization error of the kernel interpolation measured in a\ncontinuous scale of norms that interpolate between $L^2$ and the hypothesis\nspace. These lower bounds imply that kernel interpolation is always\ninconsistent, when the smoothness index of the norm is larger than a constant\nthat depends only on the embedding index of the hypothesis space and the decay\nrate of the eigenvalues.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-29T10:35:12Z"}
{"aid":"http://arxiv.org/abs/2504.20626v1","title":"A Novel Cipher for Enhancing MAVLink Security: Design, Security\n  Analysis, and Performance Evaluation Using a Drone Testbed","summary":"We present MAVShield, a novel lightweight cipher designed to secure\ncommunications in Unmanned Aerial Vehicles (UAVs) using the MAVLink protocol,\nwhich by default transmits unencrypted messages between UAVs and Ground Control\nStations (GCS). While existing studies propose encryption for MAVLink, most\nremain theoretical or simulation-based. We implement MAVShield alongside\nAES-CTR, ChaCha20, Speck-CTR, and Rabbit, and evaluate them on a real drone\ntestbed. A comprehensive security analysis using statistical test suites (NIST\nand Diehard) demonstrates strong resistance of the novel cipher to\ncryptanalysis. Performance evaluation across key metrics including memory\nusage, CPU load, and battery power consumption, demonstrates that MAVShield\noutperforms existing algorithms and offers an efficient, real-world solution\nfor securing MAVLink communications in UAVs.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T10:53:17Z"}
{"aid":"http://arxiv.org/abs/2504.20645v1","title":"LDPoly: Latent Diffusion for Polygonal Road Outline Extraction in\n  Large-Scale Topographic Mapping","summary":"Polygonal road outline extraction from high-resolution aerial images is an\nimportant task in large-scale topographic mapping, where roads are represented\nas vectorized polygons, capturing essential geometric features with minimal\nvertex redundancy. Despite its importance, no existing method has been\nexplicitly designed for this task. While polygonal building outline extraction\nhas been extensively studied, the unique characteristics of roads, such as\nbranching structures and topological connectivity, pose challenges to these\nmethods. To address this gap, we introduce LDPoly, the first dedicated\nframework for extracting polygonal road outlines from high-resolution aerial\nimages. Our method leverages a novel Dual-Latent Diffusion Model with a\nChannel-Embedded Fusion Module, enabling the model to simultaneously generate\nroad masks and vertex heatmaps. A tailored polygonization method is then\napplied to obtain accurate vectorized road polygons with minimal vertex\nredundancy. We evaluate LDPoly on a new benchmark dataset, Map2ImLas, which\ncontains detailed polygonal annotations for various topographic objects in\nseveral Dutch regions. Our experiments include both in-region and cross-region\nevaluations, with the latter designed to assess the model's generalization\nperformance on unseen regions. Quantitative and qualitative results demonstrate\nthat LDPoly outperforms state-of-the-art polygon extraction methods across\nvarious metrics, including pixel-level coverage, vertex efficiency, polygon\nregularity, and road connectivity. We also design two new metrics to assess\npolygon simplicity and boundary smoothness. Moreover, this work represents the\nfirst application of diffusion models for extracting precise vectorized object\noutlines without redundant vertices from remote-sensing imagery, paving the way\nfor future advancements in this field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T11:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.20647v1","title":"Electroactive differential growth and delayed instability in accelerated\n  healing tissues","summary":"Guided by experiments contrasting electrically accelerated recovery with\nnatural healing, this study formulates a model to investigate the importance of\nelectroactive differential growth and morphological changes in tissue repair.\nIt underscores the clinical potential of leveraging electroactive differential\ngrowth for improved healing outcomes. The study reveals that voltage\nstimulation significantly enhances the healing and growth of biological\ntissues, accelerating the regeneration process across various growth modalities\nand steering towards isotropic growth conditions that do not favor any specific\ngrowth pathways. Enhancing the electroelastic coupling parameters improves the\nefficacy of bioelectric devices, initiating contraction and fortification of\nbiological tissues in alignment with the electric field. This process\nfacilitates swift cell migration and proliferation, as well as oriented growth\nof tissue. In instances of strain stiffening at elevated strains, the extreme\ncritical growth ratio aligns with the predictions of neo-Hookean models.\nConversely, for tissues experiencing strain stiffening under moderate to very\nlow strain conditions, the strain stiffening effect substantially delays the\nonset of electroelastic growth instability, ultimately producing a smooth,\nhyperelastic surface devoid of any unstable morphologies. Our investigation,\ngrounded in nonlinear electroelastic field and perturbation theories, explores\nhow electric fields influence differential growth and instability in biological\ntissues. We examine the interactions among dimensionless voltage, internal\npressure, electroelastic coupling, radius ratio, and strain stiffening,\nrevealing their effects on promoting growth and delaying instability. This\nframework offers insights into the mechanisms behind electroactive growth and\nits instabilities, contributing valuable knowledge to the tissue healing.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-29T11:15:55Z"}
{"aid":"http://arxiv.org/abs/2504.20651v1","title":"Learning and Generalization with Mixture Data","summary":"In many, if not most, machine learning applications the training data is\nnaturally heterogeneous (e.g. federated learning, adversarial attacks and\ndomain adaptation in neural net training). Data heterogeneity is identified as\none of the major challenges in modern day large-scale learning. A classical way\nto represent heterogeneous data is via a mixture model. In this paper, we study\ngeneralization performance and statistical rates when data is sampled from a\nmixture distribution. We first characterize the heterogeneity of the mixture in\nterms of the pairwise total variation distance of the sub-population\ndistributions. Thereafter, as a central theme of this paper, we characterize\nthe range where the mixture may be treated as a single (homogeneous)\ndistribution for learning. In particular, we study the generalization\nperformance under the classical PAC framework and the statistical error rates\nfor parametric (linear regression, mixture of hyperplanes) as well as\nnon-parametric (Lipschitz, convex and H\\\"older-smooth) regression problems. In\norder to do this, we obtain Rademacher complexity and (local) Gaussian\ncomplexity bounds with mixture data, and apply them to get the generalization\nand convergence rates respectively. We observe that as the (regression)\nfunction classes get more complex, the requirement on the pairwise total\nvariation distance gets stringent, which matches our intuition. We also do a\nfiner analysis for the case of mixed linear regression and provide a tight\nbound on the generalization error in terms of heterogeneity.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-29T11:21:15Z"}
{"aid":"http://arxiv.org/abs/2504.20664v1","title":"Challenging $Î›$CDM: 5$Ïƒ$ Evidence for a Dynamical Dark Energy\n  Late-Time Transition","summary":"Recently, there has been considerable debate regarding potential evidence for\nthe dynamical nature of dark energy (DE), particularly in light of Baryon\nAcoustic Oscillations (BAO) measurements released by DESI survey. In this work,\nwe propose an agnostic test that simultaneously constrains the dark energy (DE)\nequation of state (EoS) and probes the possibility of a transition between the\nquintessence and phantom regimes, or vice versa. Our initial approach is\nindependent of physical priors, allowing the data to determine which behavior\nbest fits the parameters. We then consider a minimally modified gravity theory\nknown as VCDM, into which we can map our initial approximation, placing it\nwithin a theoretically stable framework. To this end, we incorporate the most\nup-to-date datasets available, including BAO measurements from DESI-DR2, Type\nIa Supernovae from the PantheonPlus, DESY5, and Union3 samples, as well as\nCosmic Microwave Background (CMB) data from Planck. Our analysis reveals strong\nand statistically significant evidence for a quintessence-phantom transition\nacross various data combinations. \\textit{The strongest evidence is found for\nPlanck+DESI+DESY5, with a significance exceeding $\\sim$5$\\sigma$ in favor of a\nquintessence-phantom transition at $z_{\\dag} = 0.493^{+0.063}_{-0.081}$}.\nBeyond this redshift, the EoS remains within the phantom regime, while for $z <\nz_{\\dag}$, it favors the quintessence regime. Despite this strong indication,\n\\textit{we find that such transitions do not resolve the $H_0$ tension}.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-29T11:38:28Z"}
{"aid":"http://arxiv.org/abs/2504.20675v1","title":"Hydrodynamics converts chiral flagellar rotation into contactless\n  actuation of microdiscs","summary":"Motile bacteria are a wonder of nature's engineering: microscopic engines\nthat transduce biochemical energy into the work they require to explore their\nenvironment. This added energy turns the surrounding fluid into a bath that\ndeparts from an equilibrium one. Bacterial baths agitate suspended spheres more\nvividly than thermal fluctuations and can power microscopic ratchets. A salient\nrequirement to extract work from bacterial baths was the asymmetric shape of\nthe ratchets, designed to rectify the interactions with bacteria. In contrast\nwith past results, here we show that swimming E. coli power the persistent\nrotation of discs, in absence of asymmetry. Combining state-of-the art\nnanoprinting, quantitative measurements of the dynamics of individual bacteria,\nand hydrodynamic modeling, we elucidate the mechanism and show that the\ncounter-rotation of the flagella and the bacterium body lead to a torque dipole\nand traction onto the disc, and subsequent rotation. Remarkably, the mechanism\nis independent of the direction or orientation of navigation of bacteria under\nthe disc, hence additive and contactless. Resulting from the interplay of the\ntorque dipole of flagellated bacteria with simple geometric confinement, this\nhydrodynamic mechanism bridges scales, leveraging the chirality of bacteria\nnanomotors towards the manipulation of objects at least ten thousand times\nlarger. The study lays the groundwork for novel bio-hybrid micromachines that\nharness living microorganisms for controlled motion at the microscale. Our\nfindings provide further fundamental insights into bacterial hydrodynamics and\nopen avenues for the development of autonomous, self-powered microdiscs for the\nstudy of chiral fluids.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-29T11:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.20678v1","title":"Non-native Children's Automatic Speech Assessment Challenge (NOCASA)","summary":"This paper presents the \"Non-native Children's Automatic Speech Assessment\"\n(NOCASA) - a data competition part of the IEEE MLSP 2025 conference. NOCASA\nchallenges participants to develop new systems that can assess single-word\npronunciations of young second language (L2) learners as part of a gamified\npronunciation training app. To achieve this, several issues must be addressed,\nmost notably the limited nature of available training data and the highly\nunbalanced distribution among the pronunciation level categories. To expedite\nthe development, we provide a pseudo-anonymized training data (TeflonNorL2),\ncontaining 10,334 recordings from 44 speakers attempting to pronounce 205\ndistinct Norwegian words, human-rated on a 1 to 5 scale (number of stars that\nshould be given in the game). In addition to the data, two already trained\nsystems are released as official baselines: an SVM classifier trained on the\nComParE_16 acoustic feature set and a multi-task wav2vec 2.0 model. The latter\nachieves the best performance on the challenge test set, with an unweighted\naverage recall (UAR) of 36.37%.","main_category":"cs.CL","categories":"cs.CL,eess.AS","published":"2025-04-29T11:59:08Z"}
{"aid":"http://arxiv.org/abs/2504.20692v1","title":"Inhomogeneous Diffusion in Confined Colloidal Suspensions","summary":"We have performed confocal microscopy experiments and computer simulations of\ncolloidal suspensions with moderate volume fraction confined between two\nquasi-parallel, rough walls [A. Villada-Balbuena et al., Soft Matter, 2022, 18,\n4699-4714]. Here we investigate many facets of the dynamical properties of the\nsystem, such as confined and inhomogeneous diffusion, mean first-passage times\nand generalized incoherent scattering functions. We observe that the experiment\nfeatures strong footprints of the confinement in the dynamical properties, such\nas inhomogeneous diffusion coefficients and non-zero off-diagonal elements in\nthe incoherent scattering function which we can quantitatively model and\nanalyze with computer simulations. This allows us, for example, to\nsystematically investigate the impact of surface roughness. Our comparative\nstudy therefore advances the fundamental understanding of the impact of\nconfinement on dynamics in fluids and colloidal suspensions.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-29T12:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.20699v1","title":"Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine\n  Translation?","summary":"A frequently observed problem with LLMs is their tendency to generate output\nthat is nonsensical, illogical, or factually incorrect, often referred to\nbroadly as hallucination. Building on the recently proposed HalluciGen task for\nhallucination detection and generation, we evaluate a suite of open-access LLMs\non their ability to detect intrinsic hallucinations in two conditional\ngeneration tasks: translation and paraphrasing. We study how model performance\nvaries across tasks and language and we investigate the impact of model size,\ninstruction tuning, and prompt choice. We find that performance varies across\nmodels but is consistent across prompts. Finally, we find that NLI models\nperform comparably well, suggesting that LLM-based detectors are not the only\nviable option for this specific task.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-29T12:30:05Z"}
{"aid":"http://arxiv.org/abs/2504.20721v1","title":"Unitary ensembles with a critical edge point, their multiplicative\n  statistics and the Korteweg-de-Vries hierarchy","summary":"We study the multiplicative statistics associated to the limiting\ndeterminantal point process describing unitary random matrices with a critical\nedge point, where limiting density vanishes like a power 5/2. We prove that\nthese statistics are governed by the first three equations of the KdV\nhierarchy, and study the asymptotic behavior of the relevant solutions.","main_category":"math-ph","categories":"math-ph,math.MP,math.PR","published":"2025-04-29T13:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.20726v1","title":"Enhancing Vulnerability Reports with Automated and Augmented Description\n  Summarization","summary":"Public vulnerability databases, such as the National Vulnerability Database\n(NVD), document vulnerabilities and facilitate threat information sharing.\nHowever, they often suffer from short descriptions and outdated or insufficient\ninformation. In this paper, we introduce Zad, a system designed to enrich NVD\nvulnerability descriptions by leveraging external resources. Zad consists of\ntwo pipelines: one collects and filters supplementary data using two encoders\nto build a detailed dataset, while the other fine-tunes a pre-trained model on\nthis dataset to generate enriched descriptions. By addressing brevity and\nimproving content quality, Zad produces more comprehensive and cohesive\nvulnerability descriptions. We evaluate Zad using standard summarization\nmetrics and human assessments, demonstrating its effectiveness in enhancing\nvulnerability information.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.LG","published":"2025-04-29T13:08:27Z"}
{"aid":"http://arxiv.org/abs/2504.20727v1","title":"All-dielectric metasurface polarization scrambler for imaging\n  applications","summary":"Polarization scramblers are essential for many imaging applications involving\npolarization sensitive instruments and partially polarized fluxes. In such\ncases, the light must be depolarized to allow properly calibrated measurements.\nSeveral types of depolarizers are already in use, but none is optimal due to\nthe inevitable image degradation associated with the scrambling process. Here,\nwe present a device based on an all-dielectric metasurface using anisotropic\nscatterers capable of generating multiple polarization states by varying their\norientation angle. Our new scrambling solution allows a massive reduction in\nthe integrated degree of polarization and thus the spatial depolarization of\nany incident linear polarization, while allowing easier integration into the\ninstrument design and reducing the impact on its image quality.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T13:11:40Z"}
{"aid":"http://arxiv.org/abs/2504.20732v1","title":"Bayesian Inference in Quantum Programs","summary":"Conditioning is a key feature in probabilistic programming to enable modeling\nthe influence of data (also known as observations) to the probability\ndistribution described by such programs. Determining the posterior distribution\nis also known as Bayesian inference. This paper equips a quantum while-language\nwith conditioning, defines its denotational and operational semantics over\ninfinite-dimensional Hilbert spaces, and shows their equivalence. We provide\nsufficient conditions for the existence of weakest (liberal)\nprecondition-transformers and derive inductive characterizations of these\ntransformers. It is shown how w(l)p-transformers can be used to assess the\neffect of Bayesian inference on (possibly diverging) quantum programs.","main_category":"cs.LO","categories":"cs.LO,quant-ph","published":"2025-04-29T13:15:54Z"}
{"aid":"http://arxiv.org/abs/2504.20737v1","title":"Path-connectedness of incompressible Euler solutions","summary":"We study the incompressible Euler equation and prove that the set of weak\nsolutions is path-connected. More precisely, we construct paths of H\\\"older\nregularity $C^{1/2}$, valued in $C^0_{t, loc} L^2_x$ endowed with the strong\ntopology. The main result relies on a convex integration construction adapted\nfrom the seminal work of De Lellis and Sz\\'ekelyhidi [14, The Euler equations\nas a differential inclusion], extending it to a more broader geometric\nframework, replacing balls with arbitrary convex compact sets.","main_category":"math.AP","categories":"math.AP","published":"2025-04-29T13:21:25Z"}
{"aid":"http://arxiv.org/abs/2504.20738v1","title":"EDD-NSTE: Edge Data Distribution as a Network Steiner Tree Estimation in\n  Edge Computing","summary":"Edge computing is a distributed computing paradigm that brings computation\nand data storage closer to the user's geographical location to improve response\ntimes and save bandwidth. It also helps to power a variety of applications\nrequiring low latency. These application data hosted on the cloud needs to be\ntransferred to the respective edge servers in a specific area to help provide\nlow-latency app functionalities to the users of that area. Meanwhile, these\narbitrary heavy data transactions from the cloud to the edge servers result in\nhigh cost and time penalties. Thus, we need an application data distribution\nstrategy that minimizes these penalties within the app vendors' specific\nlatency constraint. In this work, we provide a refined formulation of an\noptimal approach to solve this Edge Data Distribution (EDD) problem using\nInteger Programming (IP) technique. Due to the time complexity limitation of\nthe IP approach, we suggest an O(k) approximation algorithm based on network\nSteiner tree estimation (EDD-NSTE) for estimating solutions to dense,\nlarge-scale EDD problems. Integer Programming and EDD-NSTE are evaluated on a\nstandard real-world EUA data set and the result demonstrates that EDD-NSTE\nsignificantly outperforms with a performance margin of 86.67% over the other\nthree representative approaches and the state-of-the-art approach.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-29T13:21:27Z"}
{"aid":"http://arxiv.org/abs/2504.20741v1","title":"In defence of post-hoc explanations in medical AI","summary":"Since the early days of the Explainable AI movement, post-hoc explanations\nhave been praised for their potential to improve user understanding, promote\ntrust, and reduce patient safety risks in black box medical AI systems.\nRecently, however, critics have argued that the benefits of post-hoc\nexplanations are greatly exaggerated since they merely approximate, rather than\nreplicate, the actual reasoning processes that black box systems take to arrive\nat their outputs. In this article, we aim to defend the value of post-hoc\nexplanations against this recent critique. We argue that even if post-hoc\nexplanations do not replicate the exact reasoning processes of black box\nsystems, they can still improve users' functional understanding of black box\nsystems, increase the accuracy of clinician-AI teams, and assist clinicians in\njustifying their AI-informed decisions. While post-hoc explanations are not a\n\"silver bullet\" solution to the black box problem in medical AI, we conclude\nthat they remain a useful strategy for addressing the black box problem in\nmedical AI.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CY,cs.LG","published":"2025-04-29T13:24:21Z"}
{"aid":"http://arxiv.org/abs/2504.20753v1","title":"Vladimirov-Pearson Operators on $Î¶$-regular Ultrametric Cantor Sets","summary":"A new operator for certain types of ultrametric Cantor sets is constructed\nusing the measure coming from the spectral triple associated with the Cantor\nset, as well as its zeta function. Under certain mild conditions on that\nmeasure, it is shown that it is an integral operator similar to the\nVladimirov-Taibleson operator on the p-adic integers. Its spectral properties\nare studied, and the Markov property and kernel representation of the heat\nkernel generated by this so-called \\emph{Vladimirov-Pearson} operator is shown,\nviewed as acting on a certain Sobolev space. A large class of these operators\nhave a heat kernel and a Green function explicitly given by the ultrametric\nwavelets on the Cantor set, which are eigenfunctions of the operator.","main_category":"math.AP","categories":"math.AP,math.PR","published":"2025-04-29T13:33:59Z"}
{"aid":"http://arxiv.org/abs/2504.20789v1","title":"Evaluating Effects of Augmented SELFIES for Molecular Understanding\n  Using QK-LSTM","summary":"Identifying molecular properties, including side effects, is a critical yet\ntime-consuming step in drug development. Failing to detect these side effects\nbefore regulatory submission can result in significant financial losses and\nproduction delays, and overlooking them during the regulatory review can lead\nto catastrophic consequences. This challenge presents an opportunity for\ninnovative machine learning approaches, particularly hybrid quantum-classical\nmodels like the Quantum Kernel-Based Long Short-Term Memory (QK-LSTM) network.\nThe QK-LSTM integrates quantum kernel functions into the classical LSTM\nframework, enabling the capture of complex, non-linear patterns in sequential\ndata. By mapping input data into a high-dimensional quantum feature space, the\nQK-LSTM model reduces the need for large parameter sets, allowing for model\ncompression without sacrificing accuracy in sequence-based tasks. Recent\nadvancements have been made in the classical domain using augmented variations\nof the Simplified Molecular Line-Entry System (SMILES). However, to the best of\nour knowledge, no research has explored the impact of augmented SMILES in the\nquantum domain, nor the role of augmented Self-Referencing Embedded Strings\n(SELFIES) in either classical or hybrid quantum-classical settings. This study\npresents the first analysis of these approaches, providing novel insights into\ntheir potential for enhancing molecular property prediction and side effect\nidentification. Results reveal that augmenting SELFIES yields in statistically\nsignificant improvements from SMILES by a 5.97% improvement for the classical\ndomain and a 5.91% improvement for the hybrid quantum-classical domain.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T14:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.20795v1","title":"Effective Index Construction Algorithm for Optimal $(k,Î·)$-cores\n  Computation","summary":"Computing $(k,\\eta)$-cores from uncertain graphs is a fundamental problem in\nuncertain graph analysis. UCF-Index is the state-of-the-art resolution to\nsupport $(k,\\eta)$-core queries, allowing the $(k,\\eta)$-core for any\ncombination of $k$ and $\\eta$ to be computed in an optimal time. However, this\nindex constructed by current algorithm is usually incorrect. During\ndecomposition, the key is to obtain the $k$-probabilities of its neighbors when\nthe vertex with minimum $k$-probability is deleted. Current method uses\nrecursive floating-point division to update it, which can lead to serious\nerrors. We propose a correct and efficient index construction algorithm to\naddress this issue. Firstly, we propose tight bounds on the $k$-probabilities\nof the vertices that need to be updated, and the accurate $k$-probabilities are\nrecalculated in an on-demand manner. Secondly, vertices partitioning and\nprogressive refinement strategy is devised to search the vertex with the\nminimum $k$-probability, thereby reducing initialization overhead for each $k$\nand avoiding unnecessary recalculations. Finally, extensive experiments\ndemonstrate the efficiency and scalability of our approach.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-29T14:10:39Z"}
{"aid":"http://arxiv.org/abs/2504.20799v1","title":"Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation,\n  and Challenges","summary":"Recent technical breakthroughs in large language models (LLMs) have enabled\nthem to fluently generate source code. Software developers often leverage both\ngeneral-purpose and code-specialized LLMs to revise existing code or even\ngenerate a whole function from scratch. These capabilities are also beneficial\nin no-code or low-code contexts, in which one can write programs without a\ntechnical background. However, due to their internal design, LLMs are prone to\ngenerating hallucinations, which are incorrect, nonsensical, and not\njustifiable information but difficult to identify its presence. This problem\nalso occurs when generating source code. Once hallucinated code is produced, it\nis often challenging for users to identify and fix it, especially when such\nhallucinations can be identified under specific execution paths. As a result,\nthe hallucinated code may remain unnoticed within the codebase. This survey\ninvestigates recent studies and techniques relevant to hallucinations generated\nby CodeLLMs. We categorize the types of hallucinations in the code generated by\nCodeLLMs, review existing benchmarks and mitigation strategies, and identify\nopen challenges. Based on these findings, this survey outlines further research\ndirections in the detection and removal of hallucinations produced by CodeLLMs.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-29T14:13:57Z"}
{"aid":"http://arxiv.org/abs/2504.20810v1","title":"Effective Metric Description of Charged Black Holes","summary":"Charged black holes arise as solutions of General Relativity (GR) coupled to\nMaxwell theory. As functions of the mass and charge, they can exhibit extremal\nbehavior, in which case they are stable against thermal decay. (Quantum)\ncorrections to GR are expected to alter the classical features of these\nobjects, especially near extremality. To capture such effects in a\nmodel-independent way, we extend the Effective Metric Description (EMD)\npreviously introduced in [Phys.Rev.D 109 (2024) 2, 024045, Eur.Phys.J.C 84\n(2024) 12, 1273] for spherically symmetric and static black holes. The EMD\nparametrizes deformations of the metric in terms of physical quantities, such\nas the radial spatial distance to the event horizon. While the latter is still\nviable for non-extremal charged black holes, we argue that the proper time of a\nfree-falling observer is better suited in the extremal case: we derive the\nnecessary conditions for the parameters of such an EMD for constructing a\nconsistent space-time in the vicinity of the (extremal) horizon. Finally, we\nillustrate our framework through a concrete example, and mention implications\nof the Weak Gravity Conjecture on the effective metric parameters.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-29T14:23:33Z"}
{"aid":"http://arxiv.org/abs/2504.20822v1","title":"An approach to melodic segmentation and classification based on\n  filtering with the Haar-wavelet","summary":"We present a novel method of classification and segmentation of melodies in\nsymbolic representation. The method is based on filtering pitch as a signal\nover time with the Haar-wavelet, and we evaluate it on two tasks. The filtered\nsignal corresponds to a single-scale signal ws from the continuous Haar wavelet\ntransform. The melodies are first segmented using local maxima or\nzero-crossings of w_s. The segments of w_s are then classified using the\nk-nearest neighbour algorithm with Euclidian and city-block distances. The\nmethod proves more effective than using unfiltered pitch signals and\nGestalt-based segmentation when used to recognize the parent works of segments\nfrom Bach's Two-Part Inventions (BWV 772-786). When used to classify 360 Dutch\nfolk tunes into 26 tune families, the performance of the method is comparable\nto the use of pitch signals, but not as good as that of string-matching methods\nbased on multiple features.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T14:41:03Z"}
{"aid":"http://arxiv.org/abs/2504.20823v1","title":"Hybrid Quantum Recurrent Neural Network For Remaining Useful Life\n  Prediction","summary":"Predictive maintenance in aerospace heavily relies on accurate estimation of\nthe remaining useful life of jet engines. In this paper, we introduce a Hybrid\nQuantum Recurrent Neural Network framework, combining Quantum Long Short-Term\nMemory layers with classical dense layers for Remaining Useful Life forecasting\non NASA's Commercial Modular Aero-Propulsion System Simulation dataset. Each\nQuantum Long Short-Term Memory gate replaces conventional linear\ntransformations with Quantum Depth-Infused circuits, allowing the network to\nlearn high-frequency components more effectively. Experimental results\ndemonstrate that, despite having fewer trainable parameters, the Hybrid Quantum\nRecurrent Neural Network achieves up to a 5% improvement over a Recurrent\nNeural Network based on stacked Long Short-Term Memory layers in terms of mean\nroot mean squared error and mean absolute error. Moreover, a thorough\ncomparison of our method with established techniques, including Random Forest,\nConvolutional Neural Network, and Multilayer Perceptron, demonstrates that our\napproach, which achieves a Root Mean Squared Error of 15.46, surpasses these\nbaselines by approximately 13.68%, 16.21%, and 7.87%, respectively.\nNevertheless, it remains outperformed by certain advanced joint architectures.\nOur findings highlight the potential of hybrid quantum-classical approaches for\nrobust time-series forecasting under limited data conditions, offering new\navenues for enhancing reliability in predictive maintenance tasks.","main_category":"cs.LG","categories":"cs.LG,quant-ph","published":"2025-04-29T14:41:41Z"}
{"aid":"http://arxiv.org/abs/2504.20835v1","title":"Enhancing Non-Core Language Instruction-Following in Speech LLMs via\n  Semi-Implicit Cross-Lingual CoT Reasoning","summary":"Large language models have been extended to the speech domain, leading to the\ndevelopment of speech large language models (SLLMs). While existing SLLMs\ndemonstrate strong performance in speech instruction-following for core\nlanguages (e.g., English), they often struggle with non-core languages due to\nthe scarcity of paired speech-text data and limited multilingual semantic\nreasoning capabilities. To address this, we propose the semi-implicit\nCross-lingual Speech Chain-of-Thought (XS-CoT) framework, which integrates\nspeech-to-text translation into the reasoning process of SLLMs. The XS-CoT\ngenerates four types of tokens: instruction and response tokens in both core\nand non-core languages, enabling cross-lingual transfer of reasoning\ncapabilities. To mitigate inference latency in generating target non-core\nresponse tokens, we incorporate a semi-implicit CoT scheme into XS-CoT, which\nprogressively compresses the first three types of intermediate reasoning tokens\nwhile retaining global reasoning logic during training. By leveraging the\nrobust reasoning capabilities of the core language, XS-CoT improves responses\nfor non-core languages by up to 45\\% in GPT-4 score when compared to direct\nsupervised fine-tuning on two representative SLLMs, Qwen2-Audio and SALMONN.\nMoreover, the semi-implicit XS-CoT reduces token delay by more than 50\\% with a\nslight drop in GPT-4 scores. Importantly, XS-CoT requires only a small amount\nof high-quality training data for non-core languages by leveraging the\nreasoning capabilities of core languages. To support training, we also develop\na data pipeline and open-source speech instruction-following datasets in\nJapanese, German, and French.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-04-29T14:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.20837v1","title":"RadSAM: Segmenting 3D radiological images with a 2D promptable model","summary":"Medical image segmentation is a crucial and time-consuming task in clinical\ncare, where mask precision is extremely important. The Segment Anything Model\n(SAM) offers a promising approach, as it provides an interactive interface\nbased on visual prompting and edition to refine an initial segmentation. This\nmodel has strong generalization capabilities, does not rely on predefined\nclasses, and adapts to diverse objects; however, it is pre-trained on natural\nimages and lacks the ability to process medical data effectively. In addition,\nthis model is built for 2D images, whereas a whole medical domain is based on\n3D images, such as CT and MRI. Recent adaptations of SAM for medical imaging\nare based on 2D models, thus requiring one prompt per slice to segment 3D\nobjects, making the segmentation process tedious. They also lack important\nfeatures such as editing. To bridge this gap, we propose RadSAM, a novel method\nfor segmenting 3D objects with a 2D model from a single prompt. In practice, we\ntrain a 2D model using noisy masks as initial prompts, in addition to bounding\nboxes and points. We then use this novel prompt type with an iterative\ninference pipeline to reconstruct the 3D mask slice-by-slice. We introduce a\nbenchmark to evaluate the model's ability to segment 3D objects in CT images\nfrom a single prompt and evaluate the models' out-of-domain transfer and\nedition capabilities. We demonstrate the effectiveness of our approach against\nstate-of-the-art models on this benchmark using the AMOS abdominal organ\nsegmentation dataset.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-29T15:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.20852v1","title":"Machine Learning (ML)-Physics Fusion Model Outperforms Both Physics-Only\n  and ML-Only Models in Typhoon Predictions","summary":"Data-driven machine learning (ML) models, such as FuXi, exhibit notable\nlimitations in forecasting typhoon intensity and structure. This study presents\na comprehensive evaluation of FuXi-SHTM, a hybrid ML-physics model, using all\n2024 western North Pacific typhoon cases. The FuXi-SHTM hybrid demonstrates\nclear improvements in both track and intensity forecasts compared to the\nstandalone SHTM, FuXi, and ECMWF HRES models. Compared to FuXi alone, FuXi-SHTM\nreduces typhoon track forecast errors by 16.5% and 5.2% at lead times of 72 h\nand 120 h, respectively, and reduces intensity forecast errors by 59.7% and\n47.6%. Furthermore, FuXi-SHTM simulates cloud structures more realistically\ncompared to SHTM, and achieves superior representation of the 10-m wind fields\nin both intensity and spatial structure compared to FuXi and SHTM. Increasing\nthe resolution of FuXi-SHTM from 9 km to 3 km further enhances intensity\nforecasts, highlighting the critical role of the resolution of the physical\nmodel in advancing hybrid forecasting capabilities.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-29T15:21:07Z"}
{"aid":"http://arxiv.org/abs/2504.20853v1","title":"Multiwavelength thermometry without a priori emissivity information:\n  from promise to disillusionment","summary":"Infrared (IR) thermography provides 2D radiance maps of the IR radiation\nleaving the surfaces of a scene, based on preliminary calibration. Then, to\nconvert radiance maps into temperature maps, we need to know the emissivity of\neach element of the scene conjugated to each of the detector elements in the\ncamera's focal plane. Compared to the single-band approach, can multispectral\nthermography help solve the inverse temperature-emissivity separation problem?\nMultiwavelength thermometry (MWT) is known to be an underdetermined problem\nhaving a continuous infinity of solutions. For this reason, and right from the\norigin of MWT, it appeared necessary to introduce information on emissivity to\nassess temperature, for example, by means of an analytical model. Overlooking\nthese recommendations, a number of papers appeared in the early 2000s exploring\nthe idea that we could do without any a priori knowledge of emissivity. Growth\nbecame exponential from 2020 onward, with the allegedly successful application\nof neural networks, genetic algorithms, and other novel optimization methods.\nThe aim of the present work is to recall the consequences of MWT as an\nunderdetermined inverse problem, to highlight the errors made by ignoring them,\nand to bring us back to harsh reality: we must introduce information on\nemissivity in order to evaluate temperature accurately. Furthermore, this\ninformation has to be fully consistent with the true spectral emissivity. To\nthis end, we propose a new method for optimal selection of the emissivity\nmodel. A series of blind tests was set up to benchmark different inversion\nalgorithms. The results confirm the failure of the temperature-emissivity\nseparation when no emissivity information is available, despite the\nmultiwavelength approach, which in any case comes as no surprise.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.ins-det,physics.optics","published":"2025-04-29T15:22:39Z"}
{"aid":"http://arxiv.org/abs/2504.20854v1","title":"Towards Easy and Realistic Network Infrastructure Testing for\n  Large-scale Machine Learning","summary":"This paper lays the foundation for Genie, a testing framework that captures\nthe impact of real hardware network behavior on ML workload performance,\nwithout requiring expensive GPUs. Genie uses CPU-initiated traffic over a\nhardware testbed to emulate GPU to GPU communication, and adapts the ASTRA-sim\nsimulator to model interaction between the network and the ML workload.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.DC,cs.SY,eess.SY","published":"2025-04-29T15:23:55Z"}
{"aid":"http://arxiv.org/abs/2504.20860v1","title":"FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language\n  Models","summary":"Textual prompt tuning adapts Vision-Language Models (e.g., CLIP) in federated\nlearning by tuning lightweight input tokens (or prompts) on local client data,\nwhile keeping network weights frozen. Post training, only the prompts are\nshared by the clients with the central server for aggregation. However, textual\nprompt tuning often struggles with overfitting to known concepts and may be\noverly reliant on memorized text features, limiting its adaptability to unseen\nconcepts. To address this limitation, we propose Federated Multimodal Visual\nPrompt Tuning (FedMVP) that conditions the prompts on comprehensive contextual\ninformation -- image-conditioned features and textual attribute features of a\nclass -- that is multimodal in nature. At the core of FedMVP is a PromptFormer\nmodule that synergistically aligns textual and visual features through\ncross-attention, enabling richer contexual integration. The dynamically\ngenerated multimodal visual prompts are then input to the frozen vision encoder\nof CLIP, and trained with a combination of CLIP similarity loss and a\nconsistency loss. Extensive evaluation on 20 datasets spanning three\ngeneralization settings demonstrates that FedMVP not only preserves performance\non in-distribution classes and domains, but also displays higher\ngeneralizability to unseen classes and domains when compared to\nstate-of-the-art methods. Codes will be released upon acceptance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T15:36:51Z"}
{"aid":"http://arxiv.org/abs/2504.20861v1","title":"Simulating Heterogeneity within Elastic and Inelastic Discrete\n  Mechanical Models","summary":"The study investigates the elastic and fracture behaviors of discrete,\nelastically homogeneous models of heterogeneous media. The homogeneity is\naccomplished either by volumetric-deviatoric decomposition of constitutive\nfunction or by an auxiliary stress homogenization method. The elastic\nparameters of the homogenized material models are randomly varied in space to\nintroduce heterogeneity independently of the geometric properties of the\ndiscrete model. Several forms of randomization are investigated using\nstatistical properties of nodal stress oscillations in periodic representative\nvolume elements (RVEs). It is found that the stress oscillations present in\ndiscrete models built on heterogeneous geometric structures with standard\nconstitutive models cannot be replicated by randomization of the elastically\nhomogeneous discrete system. The marginal distributions as well as dependencies\nbetween stress tensor components cannot be adequately matched.\n  With respect to quasi-brittle fracture behavior, the macroscopic response of\nthe different models is studied for the load case of uniaxial tension. The\nelastically homogenized material provides higher peak stress occurring at lower\nstrain levels and a steeper softening phase, compared to the standard material.\nRandomization of the elastic material parameters, as well as adjustment of\ninelastic material parameters, brings the macroscopic response of the\nhomogenized material close to that of the standard material, although the\ndamage distribution prior to the strain localization differs. These findings\nprovide insight into the potential for controlled, random assignment of\nheterogeneity in homogeneous models, using physically-based discretizations of\nmaterial structure with standard constitutive models for comparison.","main_category":"cs.CE","categories":"cs.CE,cond-mat.dis-nn,cond-mat.mtrl-sci","published":"2025-04-29T15:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.20863v1","title":"Bayesian Optimization-based Tire Parameter and Uncertainty Estimation\n  for Real-World Data","summary":"This work presents a methodology to estimate tire parameters and their\nuncertainty using a Bayesian optimization approach. The literature mainly\nconsiders the estimation of tire parameters but lacks an evaluation of the\nparameter identification quality and the required slip ratios for an adequate\nmodel fit. Therefore, we examine the use of Stochastical Variational Inference\nas a methodology to estimate both - the parameters and their uncertainties. We\nevaluate the method compared to a state-of-the-art Nelder-Mead algorithm for\ntheoretical and real-world application. The theoretical study considers\nparameter fitting at different slip ratios to evaluate the required excitation\nfor an adequate fitting of each parameter. The results are compared to a\nsensitivity analysis for a Pacejka Magic Formula tire model. We show the\napplication of the algorithm on real-world data acquired during the Abu Dhabi\nAutonomous Racing League and highlight the uncertainties in identifying the\ncurvature and shape parameters due to insufficient excitation. The gathered\ninsights can help assess the acquired data's limitations and instead utilize\nstandardized parameters until higher slip ratios are captured. We show that our\nproposed method can be used to assess the mean values and the uncertainties of\ntire model parameters in real-world conditions and derive actions for the tire\nmodeling based on our simulative study.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-29T15:39:10Z"}
{"aid":"http://arxiv.org/abs/2504.20874v1","title":"Diagnostic performance of echocardiography in detecting and\n  differentiating cardiac amyloidosis: a meta-analysis","summary":"Aims: This meta-analysis aimed to evaluate the diagnostic performance of\nechocardiographic parameters for cardiac amyloidosis (CA), with a focus on\nsubtype stratification and comparisons with healthy controls. Methods and\nResults: A comprehensive search identified 26 studies published before February\n2025, encompassing 3,802 patients. Compared to healthy individuals, CA patients\ndemonstrated significant echocardiographic abnormalities, including reduced\nleft ventricular ejection fraction (LVEF; WMD = -10.65, 95% CI: [-11.84,\n-9.46]), increased left atrial volume index (WMD = +15.87, 95% CI: [14.35,\n17.38]), and thickened posterior wall (WMD = +5.14, 95% CI: [4.85, 5.42]).\nSubtype analyses revealed that transthyretin cardiac amyloidosis (ATTR-CA) was\nassociated with more pronounced systolic dysfunction than light-chain cardiac\namyloidosis (AL-CA), evidenced by lower global longitudinal strain (WMD =\n-2.02, 95% CI: [-2.66, -1.37]), reduced LVEF (WMD = -5.31, 95% CI: [-6.63,\n-3.99]), and diminished tricuspid annular plane systolic excursion (WMD =\n-1.59, 95% CI: [-2.23, -0.95]). Additionally, ATTR-CA patients exhibited\ngreater ventricular wall thickening in both posterior wall (WMD = +1.87, 95%\nCI: [1.51, 2.23]) and interventricular septum (WMD = +2.24, 95% CI: [1.85,\n2.63]). Conclusion: Echocardiography plays a pivotal role in diagnosing CA and\ndistinguishing between AL-CA and ATTR-CA. Key indices such as LVEF and global\nlongitudinal strain are especially valuable for early detection, while\nsubtype-specific patterns highlight distinct underlying pathophysiologies,\noffering guidance for tailored diagnostic and therapeutic strategies.","main_category":"physics.med-ph","categories":"physics.med-ph,q-bio.TO","published":"2025-04-29T15:44:30Z"}
{"aid":"http://arxiv.org/abs/2504.20876v1","title":"Chaos Around the Kerr Black Hole: its Effects on Entropy and the Shadow","summary":"Massless or massive particles in unstable orbits around a Kerr black hole\nexhibit chaotic motion when perturbed. They either plunge into the black hole\nor escape to infinity after making some oscillations around the equatorial\nplane. In both of these cases, chaotic motion causes information production. In\nthe case of the photons that escape to infinity, it was recently suggested that\nthis information can be used to resolve the subring structure of the shadow\nimage and obtain more precise data about the black hole mass and spin. Here, we\nextend this method to obtain more precise results by including the\nnon-equatorial contributions to the Lyapunov exponents. In the other case of\nmassive particles that plunge into the Kerr black hole, we show that the\nassociated Kolmogorov-Sinai entropy derived from the Lyapunov exponents can be\ninterpreted in the context of black hole thermodynamics and that it obeys\nBekenstein's bound on the entropy of a physical material system. Thus, the\nperturbed unstable orbits, either ending inside the black hole or at the\nobserver's screen, have physical consequences.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th,math-ph,math.MP","published":"2025-04-29T15:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.20907v1","title":"MANILA: A Low-Code Application to Benchmark Machine Learning Models and\n  Fairness-Enhancing Methods","summary":"This paper presents MANILA, a web-based low-code application to benchmark\nmachine learning models and fairness-enhancing methods and select the one\nachieving the best fairness and effectiveness trade-off. It is grounded on an\nExtended Feature Model that models a general fairness benchmarking workflow as\na Software Product Line. The constraints defined among the features guide users\nin creating experiments that do not lead to execution errors. We describe the\narchitecture and implementation of MANILA and evaluate it in terms of\nexpressiveness and correctness.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-29T16:24:48Z"}
{"aid":"http://arxiv.org/abs/2504.20923v1","title":"End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based\n  Approach with Cross-Dataset Evaluation","summary":"Audio deepfakes represent a growing threat to digital security and trust,\nleveraging advanced generative models to produce synthetic speech that closely\nmimics real human voices. Detecting such manipulations is especially\nchallenging under open-world conditions, where spoofing methods encountered\nduring testing may differ from those seen during training. In this work, we\npropose an end-to-end deep learning framework for audio deepfake detection that\noperates directly on raw waveforms. Our model, RawNetLite, is a lightweight\nconvolutional-recurrent architecture designed to capture both spectral and\ntemporal features without handcrafted preprocessing. To enhance robustness, we\nintroduce a training strategy that combines data from multiple domains and\nadopts Focal Loss to emphasize difficult or ambiguous samples. We further\ndemonstrate that incorporating codec-based manipulations and applying\nwaveform-level audio augmentations (e.g., pitch shifting, noise, and time\nstretching) leads to significant generalization improvements under realistic\nacoustic conditions. The proposed model achieves over 99.7% F1 and 0.25% EER on\nin-domain data (FakeOrReal), and up to 83.4% F1 with 16.4% EER on a challenging\nout-of-distribution test set (AVSpoof2021 + CodecFake). These findings\nhighlight the importance of diverse training data, tailored objective functions\nand audio augmentations in building resilient and generalizable audio forgery\ndetectors. Code and pretrained models are available at\nhttps://iplab.dmi.unict.it/mfs/Deepfakes/PaperRawNet2025/.","main_category":"cs.SD","categories":"cs.SD,cs.CV,eess.AS","published":"2025-04-29T16:38:23Z"}
{"aid":"http://arxiv.org/abs/2504.20931v1","title":"Generalized cluster algebras are subquotients of cluster algebras","summary":"Generalized Cluster Algebras (GCA) are generalizations of Cluster Algebras\n(CA) with higher-order exchange relations. Previously, Chekhov-Shapiro\nconjectured that every GCA can be embedded into a CA. In this paper, we prove a\nmodified version of this conjecture by providing a construction that realizes a\ngiven GCA as subquotient of some CA, as an algebra over the ground ring of the\nGCA via restriction of scalars.","main_category":"math.RA","categories":"math.RA,math.AC","published":"2025-04-29T16:48:33Z"}
{"aid":"http://arxiv.org/abs/2504.20935v1","title":"Note about the complexity of the acyclic orientation with parity\n  constraint problem","summary":"Let $G = (V, E)$ be a connected graph, and let $T$ in $V$ be a subset of\nvertices. An orientation of $G$ is called $T$-odd if any vertex $v \\in V$ has\nodd in-degree if and only if it is in $T$. Finding a T -odd orientation of G\ncan be solved in polynomial time as shown by Chevalier, Jaeger, Payan and Xuong\n(1983). Since then, $T$-odd orientations have continued to attract interest,\nparticularly in the context of global constraints on the orientation. For\ninstance, Frank and Kir\\'aly (2002) investigated $k$-connected $T$-odd\norientations and raised questions about acyclic $T$-odd orientations. This\nproblem is now recognized as an Egres problem and is known as the \"Acyclic\norientation with parity constraints\" problem. Szegedy ( 005) proposed a\nrandomized polynomial algorithm to address this problem. An easy consequence of\nhis work provides a polynomial time algorithm for planar graphs whenever $|T |\n= |V | - 1$. Nevertheless, it remains unknown whether it exists in general. In\nthis paper we contribute to the understanding of the complexity of this problem\nby studying a more general one. We prove that finding a $T$-odd acyclic\norientation on graphs having some directed edges is NP-complete.","main_category":"cs.DM","categories":"cs.DM,math.CO","published":"2025-04-29T16:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.20946v1","title":"Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning\n  Distillation From Large to Small Language Models","summary":"As Large Language Models (LLMs) continue to be leveraged for daily tasks,\nprompt engineering remains an active field of contribution within computational\nlinguistics, particularly in domains requiring specialized knowledge such as\narithmetic reasoning. While these LLMs are optimized for a variety of tasks,\ntheir exhaustive employment may become computationally or financially\ncumbersome for small teams. Additionally, complete reliance on proprietary,\nclosed-source models often limits customization and adaptability, posing\nsignificant challenges in research and application scalability. Instead, by\nleveraging open-source models at or below 7 billion parameters, we can optimize\nour resource usage while still observing remarkable gains over standard\nprompting approaches. To cultivate this notion, we introduce Trace-of-Thought\nPrompting, a simple, zero-shot prompt engineering method that instructs LLMs to\ncreate observable subproblems using critical problem-solving, specifically\ndesigned to enhance arithmetic reasoning capabilities. When applied to\nopen-source models in tandem with GPT-4, we observe that Trace-of-Thought not\nonly allows novel insight into the problem-solving process but also introduces\nperformance gains as large as 125% on language models at or below 7 billion\nparameters. This approach underscores the potential of open-source initiatives\nin democratizing AI research and improving the accessibility of high-quality\ncomputational linguistics applications.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-29T17:14:54Z"}
{"aid":"http://arxiv.org/abs/2504.20955v1","title":"Egret-1: Pretrained Neural Network Potentials For Efficient and Accurate\n  Bioorganic Simulation","summary":"Accurate simulation of atomic systems has the potential to revolutionize the\ndesign of molecules and materials. Unfortunately, exact solutions of the\nSchr\\\"odinger equation scale as O(N!) and remain inaccessible for systems with\nmore than a handful of atoms, forcing scientists to accept steep tradeoffs\nbetween speed and accuracy and limiting the reliability and utility of the\nresultant simulations. Recent work in machine learning has demonstrated that\nneural network potentials (NNPs) can learn efficient approximations to quantum\nmechanics and resolve this tradeoff, but existing NNPs still suffer from\nlimited accuracy relative to state-of-the-art quantum-chemical methods. Here,\nwe present Egret-1, a family of large pre-trained NNPs based on the MACE\narchitecture with general applicability to main-group, organic, and\nbiomolecular chemistry. We find that the Egret-1 models equal or exceed the\naccuracy of routinely employed quantum-chemical methods on a variety of\nstandard tasks, including torsional scans, conformer ranking, and geometry\noptimization, while offering multiple-order-of-magnitude speedups relative to\nlegacy methods. We also highlight important lacunae for future NNP research to\ninvestigate, and suggest strategies for building future high-quality models\nwith increased scale and generality.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-29T17:26:21Z"}
{"aid":"http://arxiv.org/abs/2504.20965v1","title":"AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM\n  Security","summary":"We introduce AegisLLM, a cooperative multi-agent defense against adversarial\nattacks and information leakage. In AegisLLM, a structured workflow of\nautonomous agents - orchestrator, deflector, responder, and evaluator -\ncollaborate to ensure safe and compliant LLM outputs, while self-improving over\ntime through prompt optimization. We show that scaling agentic reasoning system\nat test-time - both by incorporating additional agent roles and by leveraging\nautomated prompt optimization (such as DSPy)- substantially enhances robustness\nwithout compromising model utility. This test-time defense enables real-time\nadaptability to evolving attacks, without requiring model retraining.\nComprehensive evaluations across key threat scenarios, including unlearning and\njailbreaking, demonstrate the effectiveness of AegisLLM. On the WMDP unlearning\nbenchmark, AegisLLM achieves near-perfect unlearning with only 20 training\nexamples and fewer than 300 LM calls. For jailbreaking benchmarks, we achieve\n51% improvement compared to the base model on StrongReject, with false refusal\nrates of only 7.9% on PHTest compared to 18-55% for comparable methods. Our\nresults highlight the advantages of adaptive, agentic reasoning over static\ndefenses, establishing AegisLLM as a strong runtime alternative to traditional\napproaches based on model modifications. Code is available at\nhttps://github.com/zikuicai/aegisllm","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T17:36:05Z"}
{"aid":"http://arxiv.org/abs/2504.20975v1","title":"Linear function of a poset","summary":"Stanley and Grinberg introduced a symmetric function associated with digraphs\nand named it the Redei-Berge symmetric function. This function arises from a\nsuitable combinatorial Hopf algebra on digraphs, which made it possible to\nassign the Redei-Berge function to posets. In this paper, we define a new\ncombinatorial Hopf algebra of posets whose character is a close cousin of the\nRedei-Berge character for posets. Further, we investigate the properties of the\nsymmetric function that arises from this algebra and explore its expansions in\nvarious natural bases of $QSym$ and $Sym$. Finally, we obtain an interesting\nmethod for decomposing a poset.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T17:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.20982v1","title":"Provably faster randomized and quantum algorithms for k-means clustering\n  via uniform sampling","summary":"The $k$-means algorithm (Lloyd's algorithm) is a widely used method for\nclustering unlabeled data. A key bottleneck of the $k$-means algorithm is that\neach iteration requires time linear in the number of data points, which can be\nexpensive in big data applications. This was improved in recent works proposing\nquantum and quantum-inspired classical algorithms to approximate the $k$-means\nalgorithm locally, in time depending only logarithmically on the number of data\npoints (along with data dependent parameters) [$q$-means: A quantum algorithm\nfor unsupervised machine learning; Kerenidis, Landman, Luongo, and Prakash,\nNeurIPS 2019; Do you know what $q$-means?, Doriguello, Luongo, Tang]. In this\nwork, we describe a simple randomized mini-batch $k$-means algorithm and a\nquantum algorithm inspired by the classical algorithm. We prove worse-case\nguarantees that significantly improve upon the bounds for previous algorithms.\nOur improvements are due to a careful use of uniform sampling, which preserves\ncertain symmetries of the $k$-means problem that are not preserved in previous\nalgorithms that use data norm-based sampling.","main_category":"quant-ph","categories":"quant-ph,cs.DS,cs.LG","published":"2025-04-29T17:51:29Z"}
{"aid":"http://arxiv.org/abs/2504.20991v1","title":"Quantum Hypothesis Testing Lemma for Deterministic Identification over\n  Quantum Channels","summary":"In our previous work, we presented the Hypothesis Testing Lemma, a key tool\nthat establishes sufficient conditions for the existence of good deterministic\nidentification (DI) codes for memoryless channels with finite output, but\narbitrary input alphabets. In this work, we provide a full quantum analogue of\nthis lemma, which shows that the existence of a DI code in the quantum setting\nfollows from a suitable packing in a modified space of output quantum states.\nSpecifically, we demonstrate that such a code can be constructed using product\nstates derived from this packing. This result enables us to tighten the\ncapacity lower bound for DI over quantum channels beyond the simultaneous\ndecoding approach. In particular, we can now express these bounds solely in\nterms of the Minkowski dimension of a certain state space, giving us new\ninsights to better understand the nature of the protocol, and the separation\nbetween simultaneous and non-simultaneous codes. We extend the discussion with\na particular channel example for which we can construct an optimum code.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-29T17:57:36Z"}
{"aid":"http://arxiv.org/abs/2504.20996v1","title":"X-Fusion: Introducing New Modality to Frozen Large Language Models","summary":"We propose X-Fusion, a framework that extends pretrained Large Language\nModels (LLMs) for multimodal tasks while preserving their language\ncapabilities. X-Fusion employs a dual-tower design with modality-specific\nweights, keeping the LLM's parameters frozen while integrating vision-specific\ninformation for both understanding and generation. Our experiments demonstrate\nthat X-Fusion consistently outperforms alternative architectures on both\nimage-to-text and text-to-image tasks. We find that incorporating\nunderstanding-focused data improves generation quality, reducing image data\nnoise enhances overall performance, and feature alignment accelerates\nconvergence for smaller models but has minimal impact on larger ones. Our\nfindings provide valuable insights into building efficient unified multimodal\nmodels.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T17:59:45Z"}
{"aid":"http://arxiv.org/abs/2504.21256v1","title":"Sales predictive analysis for improving supply chain drug sample","summary":"The delivery of drug samples allows increasing sales of pharmaceutical\nproducts [6]. However, we discovered some problems that can be improved in the\nsupply chain that delivers drug samples (used for the treatment of excess\nglucose). Databases were integrated; then we apply data extraction and\ntransformation; and finally we apply multiple regression analysis to explain\ndrug sales. The first analysis evaluates the integration of regional data and\nthe second analysis refers to data dis-aggregated by region. We identify the\nregion with the greatest impact on sales and the impact of the delivery of drug\nsamples in the Mexican market.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-30T02:11:38Z"}
{"aid":"http://arxiv.org/abs/2504.21258v1","title":"On a phase field model for binary mixtures of micropolar fluids with\n  non-matched densities and moving contact lines","summary":"We introduce a new phase field model for binary mixtures of incompressible\nmicropolar fluids, which are among the simplest categories of fluids exhibiting\ninternal rotations. The model fulfils local and global dissipation inequalities\nso that thermodynamic consistency is guaranteed. Our model consists of a\nNavier--Stokes--Cahn--Hilliard system for the fluid velocity, pressure, phase\nfield variable and chemical potential, coupled to an additional system of\nNavier--Stokes type for the micro-rotation. Our model accounts for non-matched\ndensities as well as moving contact line dynamics, and serve as a\ngeneralisation to earlier models for binary fluid flows based on a volume\naveraged velocity formulation. We also establish the existence of global weak\nsolutions in three spatial dimensions for the model equipped with singular\nlogarithmic and double obstacle potentials.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T02:17:19Z"}
{"aid":"http://arxiv.org/abs/2504.21259v1","title":"LSTM+Geo with xgBoost Filtering: A Novel Approach for Race and Ethnicity\n  Imputation with Reduced Bias","summary":"Accurate imputation of race and ethnicity (R&E) is crucial for analyzing\ndisparities and informing policy. Methods like Bayesian Improved Surname\nGeocoding (BISG) are widely used but exhibit limitations, including systematic\nmisclassification biases linked to socioeconomic status. This paper introduces\nLSTM+Geo, a novel approach enhancing Long Short-Term Memory (LSTM) networks\nwith census tract geolocation information. Using a large voter dataset, we\ndemonstrate that LSTM+Geo (88.7% accuracy) significantly outperforms standalone\nLSTM (86.4%) and Bayesian methods like BISG (82.9%) and BIFSG (86.8%) in\naccuracy and F1-score on a held-out validation set. LSTM+Geo reduces the rate\nat which non-White individuals are misclassified as White (White FPR 19.3%)\ncompared to name-only LSTMs (White FPR 24.6%). While sophisticated ensemble\nmethods incorporating XGBoost achieve the highest overall accuracy (up to\n89.4%) and lowest White FPR (17.8%), LSTM+Geo offers strong standalone\nperformance with improved bias characteristics compared to baseline models.\nIntegrating LSTM+Geo into an XGBoost ensemble further boosts accuracy,\nhighlighting its utility as both a standalone model and a component for\nadvanced systems. We give a caution at the end regarding the appropriate use of\nthese methods.","main_category":"cs.CY","categories":"cs.CY,cs.LG","published":"2025-04-30T02:20:08Z"}
{"aid":"http://arxiv.org/abs/2504.21260v1","title":"Power Flow Approximations for Multiphase Distribution Networks using\n  Gaussian Processes","summary":"Learning-based approaches are increasingly leveraged to manage and coordinate\nthe operation of grid-edge resources in active power distribution networks.\nAmong these, model-based techniques stand out for their superior data\nefficiency and robustness compared to model-free methods. However, effective\nmodel learning requires a learning-based approximator for the underlying power\nflow model. This study extends existing work by introducing a data-driven power\nflow method based on Gaussian Processes (GPs) to approximate the multiphase\npower flow model, by mapping net load injections to nodal voltages. Simulation\nresults using the IEEE 123-bus and 8500-node distribution test feeders\ndemonstrate that the trained GP model can reliably predict the nonlinear power\nflow solutions with minimal training data. We also conduct a comparative\nanalysis of the training efficiency and testing performance of the proposed\nGP-based power flow approximator against a deep neural network-based\napproximator, highlighting the advantages of our data-efficient approach.\nResults over realistic operating conditions show that despite an 85% reduction\nin the training sample size (corresponding to a 92.8% improvement in training\ntime), GP models produce a 99.9% relative reduction in mean absolute error\ncompared to the baselines of deep neural networks.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-30T02:26:31Z"}
{"aid":"http://arxiv.org/abs/2504.21265v1","title":"Quantifying Flat-Band Voltage in Si Metal-Oxide-Semiconductor\n  Structures: An Evaluation via Terahertz Emission Spectroscopy (TES)","summary":"Laser-induced Terahertz (THz) Emission Spectroscopy (TES) has demonstrated\nits potential utility in the realm of Metal-Oxide-Semiconductor (MOS) devices\nas an expedient and noncontact estimation methodology. Owing to its discerning\nresponse to the interface electric field, the amplitude of the THz emission\npeak in time-domain spectroscopy encapsulates rich information regarding MOS\nproperties, notably the flat-band voltage. This paper concentrates on the\nprecise quantitative estimation of the flat-band voltage within the Si MOS\nstructure, elucidating the intricacies of the estimation process through the\nTHz emission model.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-30T02:49:09Z"}
{"aid":"http://arxiv.org/abs/2504.21294v1","title":"Learning Multi-view Multi-class Anomaly Detection","summary":"The latest trend in anomaly detection is to train a unified model instead of\ntraining a separate model for each category. However, existing multi-class\nanomaly detection (MCAD) models perform poorly in multi-view scenarios because\nthey often fail to effectively model the relationships and complementary\ninformation among different views. In this paper, we introduce a Multi-View\nMulti-Class Anomaly Detection model (MVMCAD), which integrates information from\nmultiple views to accurately identify anomalies. Specifically, we propose a\nsemi-frozen encoder, where a pre-encoder prior enhancement mechanism is added\nbefore the frozen encoder, enabling stable cross-view feature modeling and\nefficient adaptation for improved anomaly detection. Furthermore, we propose an\nAnomaly Amplification Module (AAM) that models global token interactions and\nsuppresses normal regions to enhance anomaly signals, leading to improved\ndetection performance in multi-view settings. Finally, we propose a\nCross-Feature Loss that aligns shallow encoder features with deep decoder\nfeatures and vice versa, enhancing the model's sensitivity to anomalies at\ndifferent semantic levels under multi-view scenarios. Extensive experiments on\nthe Real-IAD dataset for multi-view multi-class anomaly detection validate the\neffectiveness of our approach, achieving state-of-the-art performance of\n91.0/88.6/82.1 and 99.1/43.9/48.2/95.2 for image-level and the pixel-level,\nrespectively.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T03:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.21303v1","title":"Confidence in Large Language Model Evaluation: A Bayesian Approach to\n  Limited-Sample Challenges","summary":"Large language models (LLMs) exhibit probabilistic output characteristics,\nyet conventional evaluation frameworks rely on deterministic scalar metrics.\nThis study introduces a Bayesian approach for LLM capability assessment that\nintegrates prior knowledge through probabilistic inference, addressing\nlimitations under limited-sample regimes. By treating model capabilities as\nlatent variables and leveraging a curated query set to induce discriminative\nresponses, we formalize model ranking as a Bayesian hypothesis testing problem\nover mutually exclusive capability intervals. Experimental evaluations with\nGPT-series models demonstrate that the proposed method achieves superior\ndiscrimination compared to conventional evaluation methods. Results indicate\nthat even with reduced sample sizes, the approach maintains statistical\nrobustness while providing actionable insights, such as probabilistic\nstatements about a model's likelihood of surpassing specific baselines. This\nwork advances LLM evaluation methodologies by bridging Bayesian inference with\npractical constraints in real-world deployment scenarios.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T04:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.21322v1","title":"Waveform Design Based on Mutual Information Upper Bound For Joint\n  Detection and Estimation","summary":"Adaptive radar waveform design grounded in information-theoretic principles\nis critical for advancing cognitive radar performance in complex environments.\nThis paper investigates the optimization of phase-coded waveforms under\nconstant modulus constraints to jointly enhance target detection and parameter\nestimation. We introduce a unified design framework based on maximizing a\nMutual Information Upper Bound (MIUB), which inherently reconciles the\ntrade-off between detection sensitivity and estimation precision without\nrelying on ad hoc weighting schemes. To model realistic, potentially\nnon-Gaussian statistics of target returns and clutter, we adopt Gaussian\nMixture Distributions (GMDs), enabling analytically tractable approximations of\nthe MIUB's constituent Kullback-Leibler divergence and mutual information\nterms. To address the resulting non-convex problem, we propose the Phase-Coded\nDream Optimization Algorithm (PC-DOA), a tailored metaheuristic that leverages\nhybrid initialization and adaptive exploration-exploitation mechanisms\nspecifically designed for phase-variable optimization. Numerical simulations\ndemonstrate the effectiveness of the proposed method in achieving modestly\nbetter detection-estimation trade-off.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-30T05:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.21323v1","title":"How to Backdoor the Knowledge Distillation","summary":"Knowledge distillation has become a cornerstone in modern machine learning\nsystems, celebrated for its ability to transfer knowledge from a large, complex\nteacher model to a more efficient student model. Traditionally, this process is\nregarded as secure, assuming the teacher model is clean. This belief stems from\nconventional backdoor attacks relying on poisoned training data with backdoor\ntriggers and attacker-chosen labels, which are not involved in the distillation\nprocess. Instead, knowledge distillation uses the outputs of a clean teacher\nmodel to guide the student model, inherently preventing recognition or response\nto backdoor triggers as intended by an attacker. In this paper, we challenge\nthis assumption by introducing a novel attack methodology that strategically\npoisons the distillation dataset with adversarial examples embedded with\nbackdoor triggers. This technique allows for the stealthy compromise of the\nstudent model while maintaining the integrity of the teacher model. Our\ninnovative approach represents the first successful exploitation of\nvulnerabilities within the knowledge distillation process using clean teacher\nmodels. Through extensive experiments conducted across various datasets and\nattack settings, we demonstrate the robustness, stealthiness, and effectiveness\nof our method. Our findings reveal previously unrecognized vulnerabilities and\npave the way for future research aimed at securing knowledge distillation\nprocesses against backdoor attacks.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.LG","published":"2025-04-30T05:19:23Z"}
{"aid":"http://arxiv.org/abs/2504.21334v1","title":"Simple Visual Artifact Detection in Sora-Generated Videos","summary":"The December 2024 release of OpenAI's Sora, a powerful video generation model\ndriven by natural language prompts, highlights a growing convergence between\nlarge language models (LLMs) and video synthesis. As these multimodal systems\nevolve into video-enabled LLMs (VidLLMs), capable of interpreting, generating,\nand interacting with visual content, understanding their limitations and\nensuring their safe deployment becomes essential. This study investigates\nvisual artifacts frequently found and reported in Sora-generated videos, which\ncan compromise quality, mislead viewers, or propagate disinformation. We\npropose a multi-label classification framework targeting four common artifact\nlabel types: label 1: boundary / edge defects, label 2: texture / noise issues,\nlabel 3: movement / joint anomalies, and label 4: object mismatches /\ndisappearances. Using a dataset of 300 manually annotated frames extracted from\n15 Sora-generated videos, we trained multiple 2D CNN architectures (ResNet-50,\nEfficientNet-B3 / B4, ViT-Base). The best-performing model trained by ResNet-50\nachieved an average multi-label classification accuracy of 94.14%. This work\nsupports the broader development of VidLLMs by contributing to (1) the creation\nof datasets for video quality evaluation, (2) interpretable artifact-based\nanalysis beyond language metrics, and (3) the identification of visual risks\nrelevant to factuality and safety.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T05:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.21341v1","title":"Model-Free Two-Degree-of-Freedom PID Controller Design for Unknown LTI\n  Systems","summary":"In this paper, we consider the set-point tracking problem in MIMO LTI systems\nwith unknown model parameters. The proposed method integrates (i) the\nfeedforward design and (ii) the PID gain tuning. We also establish a unified\ntheoretical analysis for both components. For the feedforward design, we\ndevelop an algorithm that constructs the feedforward controller directly from\nthe input/output data, and provide a theoretical analysis on the time horizon\nof the data. For the PID gain tuning, we formulate an optimization problem and\nsolve it by employing a model-free policy gradient method combined with a\nvariance reduction method. We further provide theoretical analyses on the\nrequired time horizon and the sample complexity of the input/output data. These\nanalyses incorporate the result of the feedforward design into that of the PID\ngain tuning. In the numerical experiments, the proposed method successfully\ndesigns a 2DOF PID controller in the model-free setting.","main_category":"math.OC","categories":"math.OC","published":"2025-04-30T06:02:07Z"}
{"aid":"http://arxiv.org/abs/2504.21343v1","title":"Analysis of $Î£^*$ via isospin selective reaction $K_Lp \\to\n  Ï€^+Î£^0$","summary":"The isospin-selective reaction $K_Lp \\to \\pi^+\\Sigma^0$ provides a clean\nprobe for investigating $I=1$ $\\Sigma^*$ resonances. In this work, we perform\nan analysis of this reaction using an effective Lagrangian approach for the\nfirst time, incorporating the well-established $\\Sigma(1189) 1/2^+$,\n$\\Sigma(1385) 3/2^+$, $\\Sigma(1670) 3/2^-$, $\\Sigma(1775) 5/2^-$ states, while\nalso exploring contributions from other unestablished states.\n  By fitting the available differential cross section and recoil polarization\ndata, adhering to partial-wave phase conventions same as PDG, we find that\nbesides the established resonances, contributions from $\\Sigma(1660) 1/2^+$,\n$\\Sigma(1580) 3/2^-$ and a $\\Sigma^*(1/2^-)$ improve the description.\n  Notably, a $\\Sigma^*(1/2^-)$ resonance with mass around 1.54 GeV, consistent\nwith $\\Sigma(1620)1/2^-$, is found to be essential for describing the data in\nthis channel, a stronger indication than found in previous analyses focusing on\n$\\pi\\Lambda$ final states.\n  While providing complementary support for $\\Sigma(1660) 1/2^+$ and\n$\\Sigma(1580) 3/2^-$, our results highlight the importance of the $\\Sigma(1620)\n1/2^-$ region in $K_Lp \\to \\pi^+\\Sigma^0$. Future high-precision measurements\nare needed to solidify these findings and further constrain the $\\Sigma^*$\nspectrum.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-30T06:04:55Z"}
{"aid":"http://arxiv.org/abs/2504.21353v1","title":"Generative QoE Modeling: A Lightweight Approach for Telecom Networks","summary":"Quality of Experience (QoE) prediction plays a crucial role in optimizing\nresource management and enhancing user satisfaction across both\ntelecommunication and OTT services. While recent advances predominantly rely on\ndeep learning models, this study introduces a lightweight generative modeling\nframework that balances computational efficiency, interpretability, and\npredictive accuracy. By validating the use of Vector Quantization (VQ) as a\npreprocessing technique, continuous network features are effectively\ntransformed into discrete categorical symbols, enabling integration with a\nHidden Markov Model (HMM) for temporal sequence modeling. This VQ-HMM pipeline\nenhances the model's capacity to capture dynamic QoE patterns while supporting\nprobabilistic inference on new and unseen data. Experimental results on\npublicly available time-series datasets incorporating both objective indicators\nand subjective QoE scores demonstrate the viability of this approach in\nreal-time and resource-constrained environments, where inference latency is\nalso critical. The framework offers a scalable alternative to complex deep\nlearning methods, particularly in scenarios with limited computational\nresources or where latency constraints are critical.","main_category":"cs.LG","categories":"cs.LG,cs.NI","published":"2025-04-30T06:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.21357v1","title":"Mining and Intervention of Social Networks Information Cocoon Based on\n  Multi-Layer Network Community Detection","summary":"With the rapid development of information technology and the widespread\nutilization of recommendation algorithms, users are able to access information\nmore conveniently, while the content they receive tends to be homogeneous.\nHomogeneous viewpoints and preferences tend to cluster users into sub-networks,\nleading to group polarization and increasing the likelihood of forming\ninformation cocoons. This paper aims to handle information cocoon phenomena in\ndebates on social media. In order to investigate potential user connections, we\nconstruct a double-layer network that incorporates two dimensions: relational\nties and feature-based similarity between users. Based on the structure of the\nmulti-layer network, we promote two graph auto-encoder (GAE) based community\ndetection algorithms, which can be applied to the partition and determination\nof information cocoons. This paper tests these two algorithms on Cora,\nCiteseer, and synthetic datasets, comparing them with existing multi-layer\nnetwork unsupervised community detection algorithms. Numerical experiments\nillustrate that the algorithms proposed in this paper significantly improve\nprediction accuracy indicator NMI (normalized mutual information) and network\ntopology indicator Q. Additionally, an influence-based intervention measure on\nwhich algorithms can operate is proposed. Through the Markov states transition\nmodel, we simulate the intervention effects, which illustrate that our\ncommunity detection algorithms play a vital role in partitioning and\ndetermining information cocoons. Simultaneously, our intervention strategy\nalleviates the polarization of viewpoints and the formation of information\ncocoons with minimal intervention effort.","main_category":"cs.SI","categories":"cs.SI,math.ST,stat.TH,62-11,F.2.2","published":"2025-04-30T06:31:05Z"}
{"aid":"http://arxiv.org/abs/2504.21370v1","title":"ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length\n  for Efficient Reasoning","summary":"Reasoning models such as OpenAI o3 and DeepSeek-R1 have demonstrated strong\nperformance on reasoning-intensive tasks through extended Chain-of-Thought\n(CoT) prompting. While longer reasoning traces can facilitate a more thorough\nexploration of solution paths for complex problems, researchers have observed\nthat these models often \"overthink\", leading to inefficient inference. In this\npaper, we introduce ShorterBetter, a simple yet effective reinforcement\nlearning methed that enables reasoning language models to discover their own\noptimal CoT lengths without human intervention. By sampling multiple outputs\nper problem and defining the Sample Optimal Length (SOL) as the shortest\ncorrect response among all the outputs, our method dynamically guides the model\ntoward optimal inference lengths. Applied to the DeepSeek-Distill-Qwen-1.5B\nmodel, ShorterBetter achieves up to an 80% reduction in output length on both\nin-domain and out-of-domain reasoning tasks while maintaining accuracy. Our\nanalysis shows that overly long reasoning traces often reflect loss of\nreasoning direction, and thus suggests that the extended CoT produced by\nreasoning models is highly compressible.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-30T07:04:19Z"}
{"aid":"http://arxiv.org/abs/2504.21383v1","title":"FAST-Q: Fast-track Exploration with Adversarially Balanced State\n  Representations for Counterfactual Action Estimation in Offline Reinforcement\n  Learning","summary":"Recent advancements in state-of-the-art (SOTA) offline reinforcement learning\n(RL) have primarily focused on addressing function approximation errors, which\ncontribute to the overestimation of Q-values for out-of-distribution actions, a\nchallenge that static datasets exacerbate. However, high stakes applications\nsuch as recommendation systems in online gaming, introduce further complexities\ndue to player's psychology (intent) driven by gameplay experiences and the\ninherent volatility on the platform. These factors create highly sparse,\npartially overlapping state spaces across policies, further influenced by the\nexperiment path selection logic which biases state spaces towards specific\npolicies. Current SOTA methods constrain learning from such offline data by\nclipping known counterfactual actions as out-of-distribution due to poor\ngeneralization across unobserved states. Further aggravating conservative\nQ-learning and necessitating more online exploration. FAST-Q introduces a novel\napproach that (1) leverages Gradient Reversal Learning to construct balanced\nstate representations, regularizing the policy-specific bias between the\nplayer's state and action thereby enabling counterfactual estimation; (2)\nsupports offline counterfactual exploration in parallel with static data\nexploitation; and (3) proposes a Q-value decomposition strategy for\nmulti-objective optimization, facilitating explainable recommendations over\nshort and long-term objectives. These innovations demonstrate superiority of\nFAST-Q over prior SOTA approaches and demonstrates at least 0.15 percent\nincrease in player returns, 2 percent improvement in lifetime value (LTV), 0.4\npercent enhancement in the recommendation driven engagement, 2 percent\nimprovement in the player's platform dwell time and an impressive 10 percent\nreduction in the costs associated with the recommendation, on our volatile\ngaming platform.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-30T07:32:40Z"}
{"aid":"http://arxiv.org/abs/2504.21385v1","title":"IDDM: Bridging Synthetic-to-Real Domain Gap from Physics-Guided\n  Diffusion for Real-world Image Dehazing","summary":"Due to the domain gap between real-world and synthetic hazy images, current\ndata-driven dehazing algorithms trained on synthetic datasets perform well on\nsynthetic data but struggle to generalize to real-world scenarios. To address\nthis challenge, we propose \\textbf{I}mage \\textbf{D}ehazing \\textbf{D}iffusion\n\\textbf{M}odels (IDDM), a novel diffusion process that incorporates the\natmospheric scattering model into noise diffusion. IDDM aims to use the gradual\nhaze formation process to help the denoising Unet robustly learn the\ndistribution of clear images from the conditional input hazy images. We design\na specialized training strategy centered around IDDM. Diffusion models are\nleveraged to bridge the domain gap from synthetic to real-world, while the\natmospheric scattering model provides physical guidance for haze formation.\nDuring the forward process, IDDM simultaneously introduces haze and noise into\nclear images, and then robustly separates them during the sampling process. By\ntraining with physics-guided information, IDDM shows the ability of domain\ngeneralization, and effectively restores the real-world hazy images despite\nbeing trained on synthetic datasets. Extensive experiments demonstrate the\neffectiveness of our method through both quantitative and qualitative\ncomparisons with state-of-the-art approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T07:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.21386v1","title":"Power Suppression and Lensing Anomaly -- A phenomenological\n  investigation","summary":"Primordial power spectra with low power at long wavelengths can alleviate\nlensing anomaly. However the extent to which data favours such a primordial\nspectra is not clear. In this work, we investigate power suppression and\nrelated mitigation of lensing anomaly with the help of phenomenological models\nwhich are valid over scales of interest. We consider simple extensions to\nnearly scale invariant power spectra such as those which includes running and\nrunning of running of spectral index. We perform Bayesian analysis of these\nmodels, which are agnostic about power suppression, with various data sets and\nshow that data tend to choose parameters which leads to power suppression at\nlow multipoles. We then analyse the significance of these findings using\ninformation criteria. Further, we investigate the ability of near-ultimate\nfuture CMB missions such as ECHO to put tighter constraints on these models. We\nconclude that we can make stronger conclusions about the presence of power\nsuppression in the future by studying such simple phenomenological models.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-30T07:37:11Z"}
{"aid":"http://arxiv.org/abs/2504.21388v1","title":"Electromagnetic Modelling of Extended Targets in a Distributed Antenna\n  System","summary":"Traditional radar and integrated sensing and communication (ISAC) systems\noften approximate targets as point sources, a simplification that fails to\ncapture the essential scattering characteristics for many applications. This\npaper presents a novel electromagnetic (EM)-based framework to accurately model\nthe near-field (NF) scattering response of extended targets, which is then\napplied to three canonical shapes : a flat rectangular plate, a sphere and a\ncylinder. Mathematical expressions for the received signal are provided in each\ncase. Based on this model, the influence of bandwidth, carrier frequency and\ntarget distance on localisation accuracy is analysed, showing how higher\nbandwidths and carrier frequencies improve resolution. Additionally, the impact\nof target curvature on localisation performance is studied. Results indicate\nthat detection performance is slightly enhanced when considering curved\nobjects. A comparative analysis between the extended and point target models\nshows significant similarities when targets are small and curved. However, as\nthe target size increases or becomes flatter, the point target model introduces\nestimation errors owing to model mismatch. The impact of this model mismatch as\na function of system parameters is analysed, and the operational zones where\nthe point abstraction remains valid and where it breaks down are identified.\nThese findings provide theoretical support for experimental results based on\npoint-target models in previous studies.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-30T07:40:27Z"}
{"aid":"http://arxiv.org/abs/2504.21411v1","title":"Galvatron: An Automatic Distributed System for Efficient Foundation\n  Model Training","summary":"Galvatron is a distributed system for efficiently training large-scale\nFoundation Models. It overcomes the complexities of selecting optimal\nparallelism strategies by automatically identifying the most efficient hybrid\nstrategy, incorporating data, tensor, pipeline, sharded data, and sequence\nparallelism, along with recomputation. The system's architecture includes a\nprofiler for hardware and model analysis, a search engine for strategy\noptimization using decision trees and dynamic programming, and a runtime for\nexecuting these strategies efficiently. Benchmarking on various clusters\ndemonstrates Galvatron's superior throughput compared to existing frameworks.\nThis open-source system offers user-friendly interfaces and comprehensive\ndocumentation, making complex distributed training accessible and efficient.\nThe source code of Galvatron is available at\nhttps://github.com/PKU-DAIR/Hetu-Galvatron.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.LG","published":"2025-04-30T08:11:45Z"}
{"aid":"http://arxiv.org/abs/2504.21413v1","title":"An Inversion Theorem for Buffered Linear Toeplitz (BLT) Matrices and\n  Applications to Streaming Differential Privacy","summary":"Buffered Linear Toeplitz (BLT) matrices are a family of parameterized\nlower-triangular matrices that play an important role in streaming differential\nprivacy with correlated noise. Our main result is a BLT inversion theorem: the\ninverse of a BLT matrix is itself a BLT matrix with different parameters. We\nalso present an efficient and differentiable $O(d^3)$ algorithm to compute the\nparameters of the inverse BLT matrix, where $d$ is the degree of the original\nBLT (typically $d < 10$). Our characterization enables direct optimization of\nBLT parameters for privacy mechanisms through automatic differentiation.","main_category":"cs.CR","categories":"cs.CR,eess.SP","published":"2025-04-30T08:14:09Z"}
{"aid":"http://arxiv.org/abs/2504.21422v1","title":"Ultralow-Temperature Thermodynamics and Optical Coherence of Narrow\n  Linewidth Optical Emitters","summary":"The coherence properties of optical emitters in crystals are critical for\nquantum technologies and optical frequency metrology. Cooling to sub-kelvin\ntemperatures can significantly enhance their coherence, making it essential to\nidentify the key parameters governing emitter and host crystal behavior in this\nultra cold regime. We investigate a Czochralski-grown europium doped yttrium\northosilicate crystal, and we report measurements of the heat capacity, a\nparameter fundamental to evaluating thermal noise limits in metrology schemes\nbased on spectral hole stabilization in such samples. In parallel, we\ncharacterize optical coherence via photon echo measurements as a function of\ntemperature. Below 1 K, where phonon contributions diminish, two-level systems\n(TLS) associated with crystal imperfections may emerge as a limiting factor. A\nlinear-in-temperature term in the heat capacity serves as a signature of TLS,\nand from our data, we establish an upper bound on this contribution. This,\ncombined with the optical homogeneous linewidth from photon-echo measurements\nbeing constant in the interval from 300 mK to 2 K demonstrates a minimal\nTLSrelated effects in our sample. These findings highlight the promise of\nultralow-temperature operation for enhancing the performance of optical quantum\ndevices based on doped crystals.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-30T08:27:58Z"}
{"aid":"http://arxiv.org/abs/2504.21432v1","title":"UAV-VLN: End-to-End Vision Language guided Navigation for UAVs","summary":"A core challenge in AI-guided autonomy is enabling agents to navigate\nrealistically and effectively in previously unseen environments based on\nnatural language commands. We propose UAV-VLN, a novel end-to-end\nVision-Language Navigation (VLN) framework for Unmanned Aerial Vehicles (UAVs)\nthat seamlessly integrates Large Language Models (LLMs) with visual perception\nto facilitate human-interactive navigation. Our system interprets free-form\nnatural language instructions, grounds them into visual observations, and plans\nfeasible aerial trajectories in diverse environments.\n  UAV-VLN leverages the common-sense reasoning capabilities of LLMs to parse\nhigh-level semantic goals, while a vision model detects and localizes\nsemantically relevant objects in the environment. By fusing these modalities,\nthe UAV can reason about spatial relationships, disambiguate references in\nhuman instructions, and plan context-aware behaviors with minimal task-specific\nsupervision. To ensure robust and interpretable decision-making, the framework\nincludes a cross-modal grounding mechanism that aligns linguistic intent with\nvisual context.\n  We evaluate UAV-VLN across diverse indoor and outdoor navigation scenarios,\ndemonstrating its ability to generalize to novel instructions and environments\nwith minimal task-specific training. Our results show significant improvements\nin instruction-following accuracy and trajectory efficiency, highlighting the\npotential of LLM-driven vision-language interfaces for safe, intuitive, and\ngeneralizable UAV autonomy.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-30T08:40:47Z"}
{"aid":"http://arxiv.org/abs/2504.21439v1","title":"Further results on arithmetic properties of biregular overpartitions","summary":"Recently there has been quite a bit of study carried out related to\narithmetic properties of overpartitions into non-multiples of two co-prime\nintegers. The paper [19] by Nadji et al. looked into congruences modulo $3$ and\npowers of $2$ for certain specific pairs of co-prime integers, while the paper\n[1] by Alanazi et al. investigated some congruences related to some similar and\nsome different pairs of co-prime integers. In this paper we propose some\nelegant and elementary proofs of a subset of the congruences given in [1] by\nusing only theta function and dissection identities. We also propose a generic\nmethod for proving congruences modulo $8$ which doesn't necessarily use any\nspecific $2$-dissection.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T08:55:25Z"}
{"aid":"http://arxiv.org/abs/2504.21444v1","title":"A Unified QoS-Aware Multiplexing Framework for Next Generation Immersive\n  Communication with Legacy Wireless Applications","summary":"Immersive communication, including emerging augmented reality, virtual\nreality, and holographic telepresence, has been identified as a key service for\nenabling next-generation wireless applications. To align with legacy wireless\napplications, such as enhanced mobile broadband or ultra-reliable low-latency\ncommunication, network slicing has been widely adopted. However, attempting to\nstatistically isolate the above types of wireless applications through\ndifferent network slices may lead to throughput degradation and increased queue\nbacklog. To address these challenges, we establish a unified QoS-aware\nframework that supports immersive communication and legacy wireless\napplications simultaneously. Based on the Lyapunov drift theorem, we transform\nthe original long-term throughput maximization problem into an equivalent\nshort-term throughput maximization weighted by virtual queue length. Moreover,\nto cope with the challenges introduced by the interaction between\nlarge-timescale network slicing and short-timescale resource allocation, we\npropose an adaptive adversarial slicing (Ad2S) scheme for networks with\ninvarying channel statistics. To track the network channel variations, we also\npropose a measurement extrapolation-Kalman filter (ME-KF)-based method and\nrefine our scheme into Ad2S-non-stationary refinement (Ad2S-NR). Through\nextended numerical examples, we demonstrate that our proposed schemes achieve\n3.86 Mbps throughput improvement and 63.96\\% latency reduction with 24.36\\%\nconvergence time reduction. Within our framework, the trade-off between total\nthroughput and user service experience can be achieved by tuning systematic\nparameters.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-30T08:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.21454v1","title":"SimPRIVE: a Simulation framework for Physical Robot Interaction with\n  Virtual Environments","summary":"The use of machine learning in cyber-physical systems has attracted the\ninterest of both industry and academia. However, no general solution has yet\nbeen found against the unpredictable behavior of neural networks and\nreinforcement learning agents. Nevertheless, the improvements of\nphoto-realistic simulators have paved the way towards extensive testing of\ncomplex algorithms in different virtual scenarios, which would be expensive and\ndangerous to implement in the real world.\n  This paper presents SimPRIVE, a simulation framework for physical robot\ninteraction with virtual environments, which operates as a vehicle-in-the-loop\nplatform, rendering a virtual world while operating the vehicle in the real\nworld.\n  Using SimPRIVE, any physical mobile robot running on ROS 2 can easily be\nconfigured to move its digital twin in a virtual world built with the Unreal\nEngine 5 graphic engine, which can be populated with objects, people, or other\nvehicles with programmable behavior.\n  SimPRIVE has been designed to accommodate custom or pre-built virtual worlds\nwhile being light-weight to contain execution times and allow fast rendering.\nIts main advantage lies in the possibility of testing complex algorithms on the\nfull software and hardware stack while minimizing the risks and costs of a test\ncampaign. The framework has been validated by testing a reinforcement learning\nagent trained for obstacle avoidance on an AgileX Scout Mini rover that\nnavigates a virtual office environment where everyday objects and people are\nplaced as obstacles. The physical rover moves with no collision in an indoor\nlimited space, thanks to a LiDAR-based heuristic.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-30T09:22:55Z"}
{"aid":"http://arxiv.org/abs/2504.21485v1","title":"Monolayer C$_{60}$ networks: A first-principles perspective","summary":"Monolayer fullerene (C$_{60}$) networks combine molecular-level rigidity with\ncrystalline connectivity, offering a promising platform for numerous\napplications. In this Feature article, we review the physical and chemical\nproperties of fullerene monolayers, focusing on first-principles studies. We\nfirst explore the structural stability of monolayer phases and investigate\ntheir thermal expansion behaviours. We then outline criteria for photocatalytic\nwater splitting and introduce theoretical predictions which are supported by\nrecent experimental verification. Finally, we show how interlayer stacking,\nmolecular size, and dimensional tuning (from 2D monolayers into 3D crystals, 1D\nchains, or nanoribbons) offer versatile approaches to modulate their chemical\nfunctionality. Together, these insights establish fullerene networks as a novel\nclass of carbon-based materials with tailored properties for catalysis,\nphotovoltaics, and flexible electronics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.app-ph,physics.atm-clus,physics.chem-ph","published":"2025-04-30T10:09:45Z"}
{"aid":"http://arxiv.org/abs/2504.21492v1","title":"Global solutions to the thin obstacle problem with superquadratic growth","summary":"We study rigidity/flexibility properties of global solutions to the thin\nobstacle problem. For solutions with bounded positive sets, we give a\nclassification in terms of their expansions at infinity. For solutions with\nbounded contact sets, we show that the contact sets are highly flexible and can\napproximate arbitrary compact sets.\n  These phenomena have no counterparts in the classical obstacle problem.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T10:23:10Z"}
{"aid":"http://arxiv.org/abs/2504.21500v1","title":"Visual Analytics Challenges and Trends in the Age of AI: The BigVis\n  Community Perspective","summary":"This report provides insights into the challenges, emerging topics, and\nopportunities related to human-data interaction and visual analytics in the AI\nera. The BigVis 2024 organizing committee conducted a survey among experts in\nthe field. They invite the Program Committee members and the authors of\naccepted papers to share their views. Thirty-two scientists from diverse\nresearch communities, including Databases, Information Visualization, and\nHuman-Computer Interaction, participated in the study. These scientists,\nrepresenting both industry and academia, provided valuable insights into the\ncurrent and future landscape of the field.\n  In this report, we analyze the survey responses and compare them to the\nfindings of a similar study conducted four years ago. The results reveal some\ninteresting insights. First, many of the critical challenges identified in the\nprevious survey remain highly relevant today, despite being unrelated to AI.\nMeanwhile, the field's landscape has significantly evolved, with most of\ntoday's vital challenges not even being mentioned in the earlier survey,\nunderscoring the profound impact of AI-related advancements.\n  By summarizing the perspectives of the research community, this report aims\nto shed light on the key challenges, emerging trends, and potential research\ndirections in human-data interaction and visual analytics in the AI era.","main_category":"cs.DB","categories":"cs.DB,cs.HC","published":"2025-04-30T10:41:52Z"}
{"aid":"http://arxiv.org/abs/2504.21507v1","title":"Efficient Conversational Search via Topical Locality in Dense Retrieval","summary":"Pre-trained language models have been widely exploited to learn dense\nrepresentations of documents and queries for information retrieval. While\nprevious efforts have primarily focused on improving effectiveness and user\nsatisfaction, response time remains a critical bottleneck of conversational\nsearch systems. To address this, we exploit the topical locality inherent in\nconversational queries, i.e., the tendency of queries within a conversation to\nfocus on related topics. By leveraging query embedding similarities, we\ndynamically restrict the search space to semantically relevant document\nclusters, reducing computational complexity without compromising retrieval\nquality. We evaluate our approach on the TREC CAsT 2019 and 2020 datasets using\nmultiple embedding models and vector indexes, achieving improvements in\nprocessing speed of up to 10.4X with little loss in performance (4.4X without\nany loss). Our results show that the proposed system effectively handles\ncomplex, multiturn queries with high precision and efficiency, offering a\npractical solution for real-time conversational search.","main_category":"cs.IR","categories":"cs.IR,cs.HC,H.3","published":"2025-04-30T10:56:34Z"}
{"aid":"http://arxiv.org/abs/2504.21510v1","title":"A simple approach for power density calculation of spontaneous radiation\n  emission from a finite emittance electron beam in planar undulators","summary":"We extend the angular power density formulae for spontaneous radiation\nemission from planar undulators to include finite emittance and angular\nmisalignment of the electron beam. Then we calculate and compare power\ndensities estimated from integral approach with Gaussian beam distribution and\nsummation approach with the macro-particle allocation covering the particle\nbeam phase space. After showing that both approaches converge to each other, we\napply the macro-particle approach to study power absorbed and transmitted by\nvarious apertures at the front end of the 9-ID beamline at the National\nSynchrotron Light Source-II. Our analysis indicate that the electron beam\nmisalignment could lead to unwarranted power deposition at tighter apertures\nthat would have been otherwise difficult to account in the aperture\ndesign/choice process using the geometric ray-tracing approach.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-30T10:58:36Z"}
{"aid":"http://arxiv.org/abs/2504.21519v1","title":"K-moduli of quasimaps and quasi-projectivity of moduli of K-stable\n  Calabi-Yau fibrations over curves","summary":"We construct a projective K-moduli space of quasimaps with a certain log Fano\ncondition.\n  Moreover, we investigate relationships between the K-moduli of quasimaps and\nthe K-moduli of Calabi-Yau fibrations over curves of negative Kodaira dimension\nconstructed by the authors [HaHa23] when general fibers are Abelian varieties\nor irreducible holomorphic symplectic manifolds.\n  We show that there is a quasi-finite morphism from the K-moduli of Calabi-Yau\nfibrations to the K-moduli of quasimaps and the CM line bundle of the K-moduli\nof Calabi-Yau fibrations converges to the CM line bundle of the K-moduli of\nquasimaps.\n  As a corollary, we obtain the entire quasi-projectivity of K-moduli of\nCalabi-Yau fibrations in this case.","main_category":"math.AG","categories":"math.AG,math.DG","published":"2025-04-30T11:14:58Z"}
{"aid":"http://arxiv.org/abs/2504.21520v1","title":"Padding Matters -- Exploring Function Detection in PE Files","summary":"Function detection is a well-known problem in binary analysis. While previous\nresearch has primarily focused on Linux/ELF, Windows/PE binaries have been\noverlooked or only partially considered. This paper introduces FuncPEval, a new\ndataset for Windows x86 and x64 PE files, featuring Chromium and the Conti\nransomware, along with ground truth data for 1,092,820 function starts.\nUtilizing FuncPEval, we evaluate five heuristics-based (Ghidra, IDA, Nucleus,\nrev.ng, SMDA) and three machine-learning-based (DeepDi, RNN, XDA) function\nstart detection tools. Among the tested tools, IDA achieves the highest\nF1-score (98.44%) for Chromium x64, while DeepDi closely follows (97%) but\nstands out as the fastest by a significant margin. Working towards\nexplainability, we examine the impact of padding between functions on the\ndetection results. Our analysis shows that all tested tools, except rev.ng, are\nsusceptible to randomized padding. The randomized padding significantly\ndiminishes the effectiveness for the RNN, XDA, and Nucleus. Among the\nlearning-based tools, DeepDi exhibits the least sensitivity and demonstrates\noverall the fastest performance, while Nucleus is the most adversely affected\namong non-learning-based tools. In addition, we improve the recurrent neural\nnetwork (RNN) proposed by Shin et al. and enhance the XDA tool, increasing the\nF1-score by approximately 10%.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-30T11:15:09Z"}
{"aid":"http://arxiv.org/abs/2504.21526v1","title":"Physics-Informed Priors Improve Gravitational-Wave Constraints on\n  Neutron-Star Matter","summary":"Gravitational-wave astronomy shows great promise in determining nuclear\nphysics in a regime not accessible to terrestrial experiments. We introduce\nphysics-informed priors constrained by nuclear theory and perturbative Quantum\nChromodynamics calculations, as well as astrophysical measurements of\nneutron-star masses and radii. When these priors are used in gravitational-wave\nastrophysical inference, we show a significant improvement on nuclear equation\nof state constraints. Applying these to the first observed gravitational-wave\nbinary neutron-star merger GW170817, the constraints on the radius of a\n$1.4\\,M_\\odot$ neutron star improve from $R_{1.4} ={12.54^{+1.05}_{-1.54}} \\,\n{\\rm km}$ to $R_{1.4} = 12.11^{+0.91}_{-1.11} \\,{\\rm km}$ and those on the\ntidal deformability from $\\tilde{\\Lambda}_{1.186} < 720$ to\n$\\tilde{\\Lambda}_{1.186} = 384^{+306}_{-158}$ ($90\\%$ confidence intervals) at\nthe events measured chirp mass $\\mathcal{M}=1.186\\,M_\\odot$. We also show these\npriors can be used to perform model selection between binary neutron star and\nneutron star-black hole mergers; in the case of GW190425, the results provide\nonly marginal evidence with a Bayes factor $\\mathcal{BF}=1.33$ in favour of the\nbinary neutron star merger hypothesis. Given their ability to improve the\nastrophysical inference of binary mergers involving neutron stars, we advocate\nfor these physics-informed priors to be used as standard in the literature and\nprovide open-source code for reproducibility and adaptation of the method.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc,nucl-th","published":"2025-04-30T11:19:52Z"}
{"aid":"http://arxiv.org/abs/2504.21530v1","title":"RoboGround: Robotic Manipulation with Grounded Vision-Language Priors","summary":"Recent advancements in robotic manipulation have highlighted the potential of\nintermediate representations for improving policy generalization. In this work,\nwe explore grounding masks as an effective intermediate representation,\nbalancing two key advantages: (1) effective spatial guidance that specifies\ntarget objects and placement areas while also conveying information about\nobject shape and size, and (2) broad generalization potential driven by\nlarge-scale vision-language models pretrained on diverse grounding datasets. We\nintroduce RoboGround, a grounding-aware robotic manipulation system that\nleverages grounding masks as an intermediate representation to guide policy\nnetworks in object manipulation tasks. To further explore and enhance\ngeneralization, we propose an automated pipeline for generating large-scale,\nsimulated data with a diverse set of objects and instructions. Extensive\nexperiments show the value of our dataset and the effectiveness of grounding\nmasks as intermediate guidance, significantly enhancing the generalization\nabilities of robot policies.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-30T11:26:40Z"}
{"aid":"http://arxiv.org/abs/2504.21531v1","title":"A Numerical scheme to approximate the solution of the planar Skorokhod\n  embedding problem","summary":"We present a numerical framework to approximate the $\\mu$-domain in the\nplanar Skorokhod embedding problem (PSEP), recently appeared in\n\\cite{gross2019}. Our approach investigates the continuity and convergence\nproperties of the solutions with respect to the underlying distribution $\\mu$.\nWe establish that, under weak convergence of a sequence of probability measures\n$(\\mu_n)$ with bounded support, the corresponding sequence of $\\mu_n$-domains\nconverges to the domain associated with $\\mu$, limit of $(\\mu_n)$. We derive\nexplicit convergence results in the $L^1$ norm, supported by a generalization\nusing the concept of $\\alpha_p$-convergence. Furthermore, we provide practical\nimplementation techniques, convergence rate estimates, and numerical\nsimulations using various distributions. The method proves robust and\nadaptable, offering a concrete computational pathway for approximating\n$\\mu$-domains in the PSEP.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T11:27:23Z"}
{"aid":"http://arxiv.org/abs/2504.21533v1","title":"Random Features for Grassmannian Kernels","summary":"The Grassmannian manifold G(k, n) serves as a fundamental tool in signal\nprocessing, computer vision, and machine learning, where problems often involve\nclassifying, clustering, or comparing subspaces. In this work, we propose a\nsketching-based approach to approximate Grassmannian kernels using random\nprojections. We introduce three variations of kernel approximation, including\ntwo that rely on binarised sketches, offering substantial memory gains. We\nestablish theoretical properties of our method in the special case of G(1, n)\nand extend it to general G(k, n). Experimental validation demonstrates that our\nsketched kernels closely match the performance of standard Grassmannian kernels\nwhile avoiding the need to compute or store the full kernel matrix. Our\napproach enables scalable Grassmannian-based methods for large-scale\napplications in machine learning and pattern recognition.","main_category":"eess.SP","categories":"eess.SP,eess.IV","published":"2025-04-30T11:28:14Z"}
{"aid":"http://arxiv.org/abs/2504.21553v1","title":"Precision Where It Matters: A Novel Spike Aware Mixed-Precision\n  Quantization Strategy for LLaMA-based Language Models","summary":"Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious natural language processing tasks. However, their size presents\nsignificant challenges for deployment and inference. This paper investigates\nthe quantization of LLMs, focusing on the LLaMA architecture and its\nderivatives. We challenge existing assumptions about activation outliers in\nLLMs and propose a novel mixed-precision quantization approach tailored for\nLLaMA-like models. Our method leverages the observation that activation spikes\nin LLaMA architectures are predominantly concentrated in specific projection\nlayers. By applying higher precision (FP16 or FP8) to these layers while\nquantizing the rest of the model to lower bit-widths, we achieve superior\nperformance compared to existing quantization techniques. Experimental results\non LLaMA2, LLaMA3, and Mistral models demonstrate significant improvements in\nperplexity and zero-shot accuracy, particularly for 8-bit per-tensor\nquantization. Our approach outperforms general-purpose methods designed to\nhandle outliers across all architecture types, highlighting the benefits of\narchitecture-specific quantization strategies. This research contributes to the\nongoing efforts to make LLMs more efficient and deployable, potentially\nenabling their use in resource-constrained environments. Our findings emphasize\nthe importance of considering model-specific characteristics in developing\neffective quantization pipelines for state-of-the-art language models by\nidentifying and targeting a small number of projections that concentrate\nactivation spikes.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T11:52:18Z"}
{"aid":"http://arxiv.org/abs/2504.21555v1","title":"Quantitative Matrix-Driven Diophantine approximation on $M_0$-sets","summary":"Let $E\\subset [0,1)^{d}$ be a set supporting a probability measure $\\mu$ with\nFourier decay $|\\widehat{\\mu}({\\bf{t}})|\\ll (\\log |{\\bf{t}}|)^{-s}$ for some\nconstant $s>d+1.$ Consider a sequence of expanding integral matrices\n$\\mathcal{A}=(A_n)_{n\\in\\N}$ such that the minimal singular values of\n$A_{n+1}A_{n}^{-1}$ are uniformly bounded below by $K>1$. We prove a\nquantitative Schmidt-type counting theorem under the following constraints: (1)\nthe points of interest are restricted to $E$; (2) the denominators of the\n``shifted'' rational approximations are drawn exclusively from $\\mathcal{A}$.\nOur result extends the work of Pollington, Velani, Zafeiropoulos, and Zorin\n(2022) to the matrix setting, advancing the study of Diophantine approximation\non fractals. Moreover, it strengthens the equidistribution property of the\nsequence $(A_n{\\bf x})_{n\\in\\N}$ for $\\mu$-almost every ${\\bf x}\\in E.$\nApplications include the normality of vectors and shrinking target problems on\nfractal sets.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T11:53:50Z"}
{"aid":"http://arxiv.org/abs/2504.21556v1","title":"On persistent energy currents at equilibrium in non-reciprocal systems","summary":"We investigate the properties of the mean Poynting vector in global thermal\nequilibrium, which can be non-zero in non-reciprocal electromagnetic systems.\nUsing dyadic Green's functions and the fluctuation-dissipation theorem, we\nprovide a general proof that the mean Poynting vector is divergence-free under\nequilibrium conditions. Relying on this proof, we explicitly demonstrate that\nfor systems where a normal mode expansion of the Green's function is\napplicable, the divergence of the equilibrium mean Poynting vector vanishes. As\nconcrete examples, we also examine the equilibrium mean Poynting vector near a\nplanar non-reciprocal substrate and in configurations involving an arbitrary\nnumber of dipolar non-reciprocal objects in free space. Finally, we argue that\nthe so-called persistent heat current, while present in equilibrium, cannot be\ndetected through out-of-equilibrium heat transfer measurements.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-30T11:54:41Z"}
{"aid":"http://arxiv.org/abs/2504.21570v1","title":"Extended self-similarity in two-dimensional complex plasmas","summary":"Self-similarity is a property of an object or process wherein a part is\nsimilar to the whole. Mathematically, it can often be expressed as a power-law\nscaling of the quantity of interest. Extended self-similarity is a concept\nwidely used in the field of turbulence and refers to the power-law scaling of\nthe longitudinal structure functions of the velocity field expressed through\nthe structure functions of different orders, rather than distance. Originally\ndiscovered by [R. Benzi et al., Phys. Rev. E 48, R29 (1993)] in fully developed\nturbulence, it was later found to hold in other situations and systems as well.\nIn this paper, we show that in an active-matter system, extended\nself-similarity is possible even without the presence of respective power-law\nscaling in the underlying structure functions of distance. The active-matter\nsystem used in this study was a single-layer suspension of active Janus\nparticles in a plasma. Janus particles are polymer microspheres with\nhemispherical metal coating. When dispersed in a plasma, they acquire\nself-propulsion and act as microswimmers. Extended self-similarity was also\nobserved in the velocity field of a single-layer suspension of laser-heated\nregular (passive) particles, where the underlying structure functions displayed\na hint of the power-law scaling near the mean interparticle distance.\nTherefore, it appears to be an inherent characteristic of complex plasmas.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-30T12:16:30Z"}
{"aid":"http://arxiv.org/abs/2504.21604v1","title":"Robust Misinformation Detection by Visiting Potential Commonsense\n  Conflict","summary":"The development of Internet technology has led to an increased prevalence of\nmisinformation, causing severe negative effects across diverse domains. To\nmitigate this challenge, Misinformation Detection (MD), aiming to detect online\nmisinformation automatically, emerges as a rapidly growing research topic in\nthe community. In this paper, we propose a novel plug-and-play augmentation\nmethod for the MD task, namely Misinformation Detection with Potential\nCommonsense Conflict (MD-PCC). We take inspiration from the prior studies\nindicating that fake articles are more likely to involve commonsense conflict.\nAccordingly, we construct commonsense expressions for articles, serving to\nexpress potential commonsense conflicts inferred by the difference between\nextracted commonsense triplet and golden ones inferred by the well-established\ncommonsense reasoning tool COMET. These expressions are then specified for each\narticle as augmentation. Any specific MD methods can be then trained on those\ncommonsense-augmented articles. Besides, we also collect a novel\ncommonsense-oriented dataset named CoMis, whose all fake articles are caused by\ncommonsense conflict. We integrate MD-PCC with various existing MD backbones\nand compare them across both 4 public benchmark datasets and CoMis. Empirical\nresults demonstrate that MD-PCC can consistently outperform the existing MD\nbaselines.","main_category":"cs.CL","categories":"cs.CL,cs.CY","published":"2025-04-30T13:03:17Z"}
{"aid":"http://arxiv.org/abs/2504.21613v1","title":"ODE and PDE models for COVID-19, with reinfection and vaccination\n  process for Cameroon and Germany","summary":"The goal of this work is to develop and analyze a reaction-diffusion model\nfor the transmission dynamics of the Coronavirus (COVID-19) that accounts for\nreinfection and vaccination, as well as to compare it to the ODE model. After\ndeveloping a time-dependent ODE model, we calculate the control reproduction\nnumber $\\mathcal{R}_c$ and demonstrate the global stability of the COVID-19\nfree equilibrium for $\\mathcal{R}_c<1$. We also show that when\n$\\mathcal{R}_c>1$, the free equilibrium of COVID-19 becomes unstable and\nco-exists with at least one endemic equilibrium point. We then used data from\nGermany and Cameroon to calibrate our model and estimate some of its\ncharacteristics. We find $\\mathcal{R}_c\\approx 1.13$ for Germany and $\\mathcal\nR_c \\approx 1.2554$ for Cameroon, indicating that the disease persists in both\npopulations. Following that, we modify the prior model into a\nreaction-diffusion PDE model to account for spatial mobility. We show that the\nsolutions to the final initial value boundary problem (IVBP) exist and are\nnonnegative and unique. We also show that the disease-free equilibrium is\nstable locally, and globally when $\\mathcal{R}_c<1$. In contrast, when\n$\\mathcal{R}_c>1$, the DFE is unstable and coexists with at least one endemic\nequilibrium point. We ran multiple numerical simulations to validate our\ntheoretical predictions. We then compare the ODE and the PDE models.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T13:09:44Z"}
{"aid":"http://arxiv.org/abs/2504.21627v1","title":"LSNIF: Locally-Subdivided Neural Intersection Function","summary":"Neural representations have shown the potential to accelerate ray casting in\na conventional ray-tracing-based rendering pipeline. We introduce a novel\napproach called Locally-Subdivided Neural Intersection Function (LSNIF) that\nreplaces bottom-level BVHs used as traditional geometric representations with a\nneural network. Our method introduces a sparse hash grid encoding scheme\nincorporating geometry voxelization, a scene-agnostic training data collection,\nand a tailored loss function. It enables the network to output not only\nvisibility but also hit-point information and material indices. LSNIF can be\ntrained offline for a single object, allowing us to use LSNIF as a replacement\nfor its corresponding BVH. With these designs, the network can handle hit-point\nqueries from any arbitrary viewpoint, supporting all types of rays in the\nrendering pipeline. We demonstrate that LSNIF can render a variety of scenes,\nincluding real-world scenes designed for other path tracers, while achieving a\nmemory footprint reduction of up to 106.2x compared to a compressed BVH.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-30T13:29:42Z"}
{"aid":"http://arxiv.org/abs/2504.21634v1","title":"Quantitative Auditing of AI Fairness with Differentially Private\n  Synthetic Data","summary":"Fairness auditing of AI systems can identify and quantify biases. However,\ntraditional auditing using real-world data raises security and privacy\nconcerns. It exposes auditors to security risks as they become custodians of\nsensitive information and targets for cyberattacks. Privacy risks arise even\nwithout direct breaches, as data analyses can inadvertently expose confidential\ninformation. To address these, we propose a framework that leverages\ndifferentially private synthetic data to audit the fairness of AI systems. By\napplying privacy-preserving mechanisms, it generates synthetic data that\nmirrors the statistical properties of the original dataset while ensuring\nprivacy. This method balances the goal of rigorous fairness auditing and the\nneed for strong privacy protections. Through experiments on real datasets like\nAdult, COMPAS, and Diabetes, we compare fairness metrics of synthetic and real\ndata. By analyzing the alignment and discrepancies between these metrics, we\nassess the capacity of synthetic data to preserve the fairness properties of\nreal data. Our results demonstrate the framework's ability to enable meaningful\nfairness evaluations while safeguarding sensitive information, proving its\napplicability across critical and sensitive domains.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.LG","published":"2025-04-30T13:36:27Z"}
{"aid":"http://arxiv.org/abs/2504.21650v1","title":"HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene\n  Generation","summary":"The rapid advancement of diffusion models holds the promise of\nrevolutionizing the application of VR and AR technologies, which typically\nrequire scene-level 4D assets for user experience. Nonetheless, existing\ndiffusion models predominantly concentrate on modeling static 3D scenes or\nobject-level dynamics, constraining their capacity to provide truly immersive\nexperiences. To address this issue, we propose HoloTime, a framework that\nintegrates video diffusion models to generate panoramic videos from a single\nprompt or reference image, along with a 360-degree 4D scene reconstruction\nmethod that seamlessly transforms the generated panoramic video into 4D assets,\nenabling a fully immersive 4D experience for users. Specifically, to tame video\ndiffusion models for generating high-fidelity panoramic videos, we introduce\nthe 360World dataset, the first comprehensive collection of panoramic videos\nsuitable for downstream 4D scene reconstruction tasks. With this curated\ndataset, we propose Panoramic Animator, a two-stage image-to-video diffusion\nmodel that can convert panoramic images into high-quality panoramic videos.\nFollowing this, we present Panoramic Space-Time Reconstruction, which leverages\na space-time depth estimation method to transform the generated panoramic\nvideos into 4D point clouds, enabling the optimization of a holistic 4D\nGaussian Splatting representation to reconstruct spatially and temporally\nconsistent 4D scenes. To validate the efficacy of our method, we conducted a\ncomparative analysis with existing approaches, revealing its superiority in\nboth panoramic video generation and 4D scene reconstruction. This demonstrates\nour method's capability to create more engaging and realistic immersive\nenvironments, thereby enhancing user experiences in VR and AR applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T13:55:28Z"}
{"aid":"http://arxiv.org/abs/2504.21651v1","title":"Pressure and strain effects on the $\\textit{ab initio}$ $GW$ electronic\n  structure of La$_3$Ni$_2$O$_7$","summary":"The recent discovery of superconductivity in La$_3$Ni$_2$O$_7$ at a critical\ntemperature above 80~K points to a non-conventional pairing mechanism in\nnickelates as in cuprates, possibly due to electronic correlations. We have\ncalculated from first principles the electronic structure of La$_3$Ni$_2$O$_7$\nunder the effect of pressure and epitaxial strain including correlations by the\n$GW$ approximation to the many-body self-energy. We find that the Fermi surface\nis composed of a characteristic cuprate-shape sheet $\\beta$ plus a\nnickelate-specific cylinder $\\alpha$, both from Ni $e_g$ orbitals, with a\nnon-negligible drop in the quasiparticle weight and an effective 1D character.\nThis topology results from a delicate balance between the Ni-3$d_{z^2}$ hole\npocket $\\gamma$, which is suppressed by correlations, and an emerging\nLa-5$d_{x^2-y^2}$ electron pocket induced by both correlation and\npressure/strain effects and whose role at low energy has been neglected so far.\nUnlike cuprates, the electronic structure of La$_3$Ni$_2$O$_7$ is already\ncorrectly described from ab initio and in agreement with the experiment without\nthe need to introduce Hubbard $U$ adjustable parameters or to invoke a strongly\ncorrelated physics.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-30T13:55:45Z"}
{"aid":"http://arxiv.org/abs/2504.21667v1","title":"From Precision to Perception: User-Centred Evaluation of Keyword\n  Extraction Algorithms for Internet-Scale Contextual Advertising","summary":"Keyword extraction is a foundational task in natural language processing,\nunderpinning countless real-world applications. A salient example is contextual\nadvertising, where keywords help predict the topical congruence between ads and\ntheir surrounding media contexts to enhance advertising effectiveness. Recent\nadvances in artificial intelligence, particularly large language models, have\nimproved keyword extraction capabilities but also introduced concerns about\ncomputational cost. Moreover, although the end-user experience is of vital\nimportance, human evaluation of keyword extraction performances remains\nunder-explored. This study provides a comparative evaluation of three prevalent\nkeyword extraction algorithms that vary in complexity: TF-IDF, KeyBERT, and\nLlama 2. To evaluate their effectiveness, a mixed-methods approach is employed,\ncombining quantitative benchmarking with qualitative assessments from 552\nparticipants through three survey-based experiments. Findings indicate a slight\nuser preference for KeyBERT, which offers a favourable balance between\nperformance and computational efficiency compared to the other two algorithms.\nDespite a strong overall preference for gold-standard keywords, differences\nbetween the algorithmic outputs are not statistically significant, highlighting\na long-overlooked gap between traditional precision-focused metrics and\nuser-perceived algorithm efficiency. The study highlights the importance of\nuser-centred evaluation methodologies and proposes analytical tools to support\ntheir implementation.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-30T14:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.21670v1","title":"Assimilation of SWOT Altimetry Data for Riverine Flood Reanalysis: From\n  Synthetic to Real Data","summary":"Floods are one of the most common and devastating natural disasters\nworldwide. The contribution of remote sensing is important for reducing the\nimpact of flooding both during the event itself and for improving hydrodynamic\nmodels by reducing their associated uncertainties. This article presents the\ninnovative capabilities of the Surface Water and Ocean Topography (SWOT)\nmission, especially its river node products, to enhance the accuracy of\nriverine flood reanalysis, performed on a 50-km stretch of the Garonne River.\nThe experiments incorporate various data assimilation strategies, based on the\nensemble Kalman filter (EnKF), which allows for sequential updates of model\nparameters based on available observations. The experimental results show that\nwhile SWOT data alone offers some improvements, combining it with in-situ water\nlevel measurements provides the most accurate representation of flood dynamics,\nboth at gauge stations and along the river. The study also investigates the\nimpact of different SWOT revisit frequencies on the models performance,\nrevealing that assimilating more frequent SWOT observations leads to more\nreliable flood reanalyses. In the real event, it was demonstrated that the\nassimilation of SWOT and in-situ data accurately reproduces the water level\ndynamics, offering promising prospects for future flood monitoring systems.\nOverall, this study emphasizes the complementary strengths of Earth Observation\ndata in improving the representation of the flood dynamics in the riverbed and\nthe floodplains.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-30T14:10:40Z"}
{"aid":"http://arxiv.org/abs/2504.21676v1","title":"Superstring amplitudes meet surfaceology","summary":"We reformulate tree-level amplitudes in open superstring theory (type-I) in\nterms of stringy Tr$(\\phi^3)$ amplitudes with various kinematical shifts in the\n\"curve-integral\" formulation: while the bosonic-string amplitude with $n$ pairs\nof \"scaffolding\" scalars comes from a particularly simple shift of the\nTr$(\\phi^3)$ one (corresponding to $n$ length-$2$ cycles), the analogous\nsuperstring amplitude requires \"correction\" terms given by bosonic-string\namplitudes with longer, even-length \"cycles\", which are also Tr$(\\phi^3)$ ones\nat shifted kinematics dictated by the cycles; in total it is expressed as a sum\nof $(2n{-}3)!!$ shifted amplitudes originated from the expansion of a reduced\nPfaffian. Upon taking $n$ scaffolding residues, this leads to a new formula of\nthe $n$-gluon superstring amplitude, which is manifestly symmetric in $n{-}1$\nlegs, as a gauge-invariant combination of mixed bosonic string amplitudes with\ngluons and scalars, which come from length-$2$ cycles and longer ones\nrespectively (the total sum is associated with the expansion a $n\\times n$\nsymmetrical determinant); the corresponding prefactors are nested commutators\nof $2n$-gon kinematical variables, which nicely become traces of\nfield-strengths for those legs corresponding to scalars in the mixed\namplitudes. These interesting linear combinations of bosonic string amplitudes\nmust guarantee the cancellation of tachyon poles and $F^3$ vertices ${\\it\netc.}$, and they give new relations between the superstring amplitude and its\nbosonic-string building blocks to all orders in the $\\alpha'$ expansion (the\nfirst order gives a new formula for gluon amplitudes with a single $F^3$\ninsertion in terms of Yang-Mills-scalar amplitudes). We provide both the\nworldsheet and \"curve-integral\" derivations, and discuss applications to\nheterotic and type II cases.","main_category":"hep-th","categories":"hep-th","published":"2025-04-30T14:16:01Z"}
{"aid":"http://arxiv.org/abs/2504.21689v1","title":"On the small mass limit of stochastic wave equation driven by\n  cylindrical stable process","summary":"We explore the small mass limit of a stochastic wave equation (SWE) driven by\ncylindrical $\\alpha$-stable noise, where $\\alpha\\in (1,2)$, and prove that it\nconverges to a stochastic heat equation. We establish its well-posedness, and\nin particular, the c\\`adl\\`ag property, which is not trivial in the infinite\ndimensional case. Using a splitting technique, we decompose the velocity\ncomponent into three parts, which gives convenience to the moment estimate. We\nshow the tightness of solution of SWE by verifying the infinite dimensional\nversion of Aldous condition. After these preparation, we pass the limit and\nderive the approximation equation.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T14:24:45Z"}
{"aid":"http://arxiv.org/abs/2504.21692v1","title":"Enhancing Self-Supervised Fine-Grained Video Object Tracking with\n  Dynamic Memory Prediction","summary":"Successful video analysis relies on accurate recognition of pixels across\nframes, and frame reconstruction methods based on video correspondence learning\nare popular due to their efficiency. Existing frame reconstruction methods,\nwhile efficient, neglect the value of direct involvement of multiple reference\nframes for reconstruction and decision-making aspects, especially in complex\nsituations such as occlusion or fast movement. In this paper, we introduce a\nDynamic Memory Prediction (DMP) framework that innovatively utilizes multiple\nreference frames to concisely and directly enhance frame reconstruction. Its\ncore component is a Reference Frame Memory Engine that dynamically selects\nframes based on object pixel features to improve tracking accuracy. In\naddition, a Bidirectional Target Prediction Network is built to utilize\nmultiple reference frames to improve the robustness of the model. Through\nexperiments, our algorithm outperforms the state-of-the-art self-supervised\ntechniques on two fine-grained video object tracking tasks: object segmentation\nand keypoint tracking.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-30T14:29:04Z"}
{"aid":"http://arxiv.org/abs/2504.21694v1","title":"Automatic Mapping of AutomationML Files to Ontologies for Graph Queries\n  and Validation","summary":"AutomationML has seen widespread adoption as an open data exchange format in\nthe automation domain. It is an open and vendor neutral standard based on the\nextensible markup language XML. However, AutomationML extends XML with\nadditional semantics, that limit the applicability of common XML-tools for\napplications like querying or data validation. This article provides\npractitioners with 1) an up-to-date ontology of the concepts in the\nAutomationML-standard, as well as 2) a declarative mapping to automatically\ntransform any AutomationML model into RDF triples. Together, these artifacts\nallow practitioners an easy integration of AutomationML information into\nindustrial knowledge graphs. A study on examples from the automation domain\nconcludes that transforming AutomationML to OWL opens up new powerful ways for\nquerying and validation that are impossible without transformation.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-30T14:34:56Z"}
{"aid":"http://arxiv.org/abs/2504.21702v1","title":"A Conversational Approach to Well-being Awareness Creation and\n  Behavioural Intention","summary":"The promotion of a healthy lifestyle is one of the main drivers of an\nindividual's overall physical and psycho-emotional well-being. Digital\ntechnologies are more and more adopted as ''facilitators'' for this goal, to\nraise awareness and solicit healthy lifestyle habits.\n  This study aims to experiment the effects of the adoption of a digital\nconversational tool to influence awareness creation and behavioural change in\nthe context of a well-being lifestyle. Our aim is to collect evidence of the\naspects that must be taken into account when designing and implementing such\ntools in well-being promotion campaigns.\n  To this end, we created a conversational application for promoting well-being\nand healthy lifestyles, which presents relevant information and asks specific\nquestions to its intended users within an interaction happening through a chat\ninterface; the conversational tool presents itself as a well-being counsellor\nnamed Allegra and follows a coaching approach to structure the interaction with\nthe user. In our user study, participants were asked to first interact with\nAllegra in one of three experimental conditions, corresponding to different\nconversational styles; then, they answered a questionnaire about their\nexperience. The questionnaire items were related to intrinsic motivation\nfactors as well as awareness creation and behavioural change. The collected\ndata allowed us to assess the hypotheses of our model that put in connection\nthose variables.\n  Our results confirm the positive effect of intrinsic motivation factors on\nboth awareness creation and behavioural intention in the context of well-being\nand healthy lifestyle; on the other hand, we did not record any statistically\nsignificant effect of different language and communication styles on the\noutcomes.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-30T14:45:20Z"}
{"aid":"http://arxiv.org/abs/2504.21715v1","title":"Entanglement-Enhanced Nanoscale Single-Spin Sensing","summary":"Detecting individual spins--including stable and metastable\nstates--represents a fundamental challenge in quantum sensing with broad\napplications across condensed matter physics, quantum chemistry, and\nsingle-molecule magnetic resonance imaging. While nitrogen-vacancy (NV) centers\nin diamond have emerged as powerful nanoscale sensors, their performance for\nsingle-spin detection remains constrained by substantial environmental noise\nand restricted sensing volume. Here, we propose and demonstrate an\nentanglement-enhanced sensing protocol that overcomes these limitations through\nthe strategic use of entangled NV pairs. Our approach achieves a 3.4-fold\nenhancement in sensitivity and a 1.6-fold reduction in spatial resolution\nrelative to single NV centers under ambient conditions. The protocol employs\ncarefully engineered entangled states that amplify target spin signals through\nquantum interference while suppressing environmental noise. Crucially, we\nextend these capabilities to resolve metastable single-spin dynamics, directly\nobserving stochastic transitions between different spin states by identifying\nstate-dependent coupling strengths. This dual functionality enables\nsimultaneous detection of static and dynamic spin species for studying complex\nquantum systems. The achieved performance establishes entanglement-enhanced\nsensing as a viable pathway toward atomic-scale characterization of quantum\nmaterials and interface.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T14:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.21723v1","title":"Task-Agnostic Semantic Communications Relying on Information Bottleneck\n  and Federated Meta-Learning","summary":"As a paradigm shift towards pervasive intelligence, semantic communication\n(SemCom) has shown great potentials to improve communication efficiency and\nprovide user-centric services by delivering task-oriented semantic meanings.\nHowever, the exponential growth in connected devices, data volumes, and\ncommunication demands presents significant challenges for practical SemCom\ndesign, particularly in resource-constrained wireless networks. In this work,\nwe first propose a task-agnostic SemCom (TASC) framework that can handle\ndiverse tasks with multiple modalities. Aiming to explore the interplay between\ncommunications and intelligent tasks from the information-theoretical\nperspective, we leverage information bottleneck (IB) theory and propose a\ndistributed multimodal IB (DMIB) principle to learn minimal and sufficient\nunimodal and multimodal information effectively by discarding redundancy while\npreserving task-related information. To further reduce the communication\noverhead, we develop an adaptive semantic feature transmission method under\ndynamic channel conditions. Then, TASC is trained based on federated\nmeta-learning (FML) for rapid adaptation and generalization in wireless\nnetworks. To gain deep insights, we rigorously conduct theoretical analysis and\ndevise resource management to accelerate convergence while minimizing the\ntraining latency and energy consumption. Moreover, we develop a joint user\nselection and resource allocation algorithm to address the non-convex problem\nwith theoretical guarantees. Extensive simulation results validate the\neffectiveness and superiority of the proposed TASC compared to baselines.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-30T15:09:07Z"}
{"aid":"http://arxiv.org/abs/2504.21739v1","title":"Bilateral Differentially Private Vertical Federated Boosted Decision\n  Trees","summary":"Federated learning is a distributed machine learning paradigm that enables\ncollaborative training across multiple parties while ensuring data privacy.\nGradient Boosting Decision Trees (GBDT), such as XGBoost, have gained\npopularity due to their high performance and strong interpretability.\nTherefore, there has been a growing interest in adapting XGBoost for use in\nfederated settings via cryptographic techniques. However, it should be noted\nthat these approaches may not always provide rigorous theoretical privacy\nguarantees, and they often come with a high computational cost in terms of time\nand space requirements. In this paper, we propose a variant of vertical\nfederated XGBoost with bilateral differential privacy guarantee: MaskedXGBoost.\nWe build well-calibrated noise to perturb the intermediate information to\nprotect privacy. The noise is structured with part of its ingredients in the\nnull space of the arithmetical operation for splitting score evaluation in\nXGBoost, helping us achieve consistently better utility than other perturbation\nmethods and relatively lower overhead than encryption-based techniques. We\nprovide theoretical utility analysis and empirically verify privacy\npreservation. Compared with other algorithms, our algorithm's superiority in\nboth utility and efficiency has been validated on multiple datasets.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-30T15:37:44Z"}
{"aid":"http://arxiv.org/abs/2504.21740v1","title":"The monodromy of compact Lagrangian fibrations","summary":"We study the monodromy representations underlying compact Lagrangian\nfibrations. In the case where the associated period map is generically\nimmersive, we prove that the mondromy representation is irreducible over\n\\(\\mathbb{C}\\). In the alternative case where the fibration is isotrivial, we\nrecover a result of \\cite{kim-laza-martin23}, proving that its fibers are\nisogeneous to a power of an elliptic curve. We show that over \\(\\mathbb{C}\\),\nthe monodromy representation underlying an isotrivial Lagrangian fibration is a\ndirect sum of two irreducible \\(\\mathbb{C}\\)-local systems.","main_category":"math.AG","categories":"math.AG","published":"2025-04-30T15:38:12Z"}
{"aid":"http://arxiv.org/abs/2504.21745v1","title":"Exponential advantage in quantum sensing of correlated parameters","summary":"Conventionally in quantum sensing, the goal is to estimate one or more\nunknown parameters that are assumed to be deterministic - that is, they do not\nchange between shots of the quantum-sensing protocol. We instead consider the\nsetting where the parameters are stochastic: each shot of the quantum-sensing\nprotocol senses parameter values that come from independent random draws. In\nthis work, we explore three examples where the stochastic parameters are\ncorrelated and show how using entanglement provides a benefit in classification\nor estimation tasks: (1) a two-parameter classification task, for which there\nis an advantage in the low-shot regime; (2) an $N$-parameter estimation task\nand a classification variant of it, for which an entangled sensor requires just\na constant number (independent of $N$) shots to achieve the same accuracy as an\nunentangled sensor using exponentially many (${\\sim}2^N$) shots; (3)\nclassifying the magnetization of a spin chain in thermal equilibrium, where the\nindividual spins fluctuate but the total spin in one direction is conserved -\nthis gives a practical setting in which stochastic parameters are correlated in\na way that an entangled sensor can be designed to exploit. We also present a\ntheoretical framework for assessing, for a given choice of entangled sensing\nprotocol and distributions to discriminate between, how much advantage the\nentangled sensor would have over an unentangled sensor. Our work motivates the\nfurther study of sensing correlated stochastic parameters using entangled\nquantum sensors - and since classical sensors by definition cannot be\nentangled, our work shows the possibility for entangled quantum sensors to\nachieve an exponential advantage over classical sensors, in contrast to the\ntypical quadratic advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T15:39:30Z"}
{"aid":"http://arxiv.org/abs/2504.21770v1","title":"LASHED: LLMs And Static Hardware Analysis for Early Detection of RTL\n  Bugs","summary":"While static analysis is useful in detecting early-stage hardware security\nbugs, its efficacy is limited because it requires information to form checks\nand is often unable to explain the security impact of a detected vulnerability.\nLarge Language Models can be useful in filling these gaps by identifying\nrelevant assets, removing false violations flagged by static analysis tools,\nand explaining the reported violations. LASHED combines the two approaches\n(LLMs and Static Analysis) to overcome each other's limitations for hardware\nsecurity bug detection. We investigate our approach on four open-source SoCs\nfor five Common Weakness Enumerations (CWEs) and present strategies for\nimprovement with better prompt engineering. We find that 87.5% of instances\nflagged by our recommended scheme are plausible CWEs. In-context learning and\nasking the model to 'think again' improves LASHED's precision.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-30T16:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.21771v1","title":"Anatomical Similarity as a New Metric to Evaluate Brain Generative\n  Models","summary":"Generative models enhance neuroimaging through data augmentation, quality\nimprovement, and rare condition studies. Despite advances in realistic\nsynthetic MRIs, evaluations focus on texture and perception, lacking\nsensitivity to crucial anatomical fidelity. This study proposes a new metric,\ncalled WASABI (Wasserstein-Based Anatomical Brain Index), to assess the\nanatomical realism of synthetic brain MRIs. WASABI leverages \\textit{SynthSeg},\na deep learning-based brain parcellation tool, to derive volumetric measures of\nbrain regions in each MRI and uses the multivariate Wasserstein distance to\ncompare distributions between real and synthetic anatomies. Based on controlled\nexperiments on two real datasets and synthetic MRIs from five generative\nmodels, WASABI demonstrates higher sensitivity in quantifying anatomical\ndiscrepancies compared to traditional image-level metrics, even when synthetic\nimages achieve near-perfect visual quality. Our findings advocate for shifting\nthe evaluation paradigm beyond visual inspection and conventional metrics,\nemphasizing anatomical fidelity as a crucial benchmark for clinically\nmeaningful brain MRI synthesis. Our code is available at\nhttps://github.com/BahramJafrasteh/wasabi-mri.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T16:16:14Z"}
{"aid":"http://arxiv.org/abs/2504.21775v1","title":"Learning Heterogeneous Performance-Fairness Trade-offs in Federated\n  Learning","summary":"Recent methods leverage a hypernet to handle the performance-fairness\ntrade-offs in federated learning. This hypernet maps the clients' preferences\nbetween model performance and fairness to preference-specifc models on the\ntrade-off curve, known as local Pareto front. However, existing methods\ntypically adopt a uniform preference sampling distribution to train the\nhypernet across clients, neglecting the inherent heterogeneity of their local\nPareto fronts. Meanwhile, from the perspective of generalization, they do not\nconsider the gap between local and global Pareto fronts on the global dataset.\nTo address these limitations, we propose HetPFL to effectively learn both local\nand global Pareto fronts. HetPFL comprises Preference Sampling Adaptation (PSA)\nand Preference-aware Hypernet Fusion (PHF). PSA adaptively determines the\noptimal preference sampling distribution for each client to accommodate\nheterogeneous local Pareto fronts. While PHF performs preference-aware fusion\nof clients' hypernets to ensure the performance of the global Pareto front. We\nprove that HetPFL converges linearly with respect to the number of rounds,\nunder weaker assumptions than existing methods. Extensive experiments on four\ndatasets show that HetPFL significantly outperforms seven baselines in terms of\nthe quality of learned local and global Pareto fronts.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-30T16:25:02Z"}
{"aid":"http://arxiv.org/abs/2504.21783v1","title":"Three-dimensional horseshoes near an unfolding of a Hopf-Hopf\n  singularity","summary":"Motivated by a certain type of unfolding of a Hopf-Hopf singularity, we\nconsider a one-parameter family $(f_\\gamma)_{\\gamma\\geq0}$ of $C^3$--vector\nfields in $\\mathbb{R}^4$ whose flows exhibit a heteroclinic cycle associated to\ntwo periodic solutions and a bifocus, all of them hyperbolic. It is formally\nproved that combining rotation with a generic condition concerning the\ntransverse intersection between the three-dimensional invariant manifolds of\nthe periodic solutions, all sets are highly distorted by the first return map\nand hyperbolic three-dimensional horseshoes emerge, accumulating on the\nnetwork. Infinitely many linked horseshoes prompt the coexistence of infinitely\nmany saddle-type invariant sets for all values of $\\gamma\\gtrsim 0$ belonging\nto the heteroclinic class of the two hyperbolic periodic solutions. We apply\nthe results to a particular unfolding of the Hopf-Hopf singularity, the so\ncalled \\emph{Gaspard-type unfolding}.","main_category":"math.DS","categories":"math.DS","published":"2025-04-30T16:39:06Z"}
{"aid":"http://arxiv.org/abs/2504.21792v1","title":"Serre's problem for multiple conics","summary":"We prove the refined Loughran--Smeets conjecture of Loughran--Rome--Sofos for\na wide class of varieties arising as products of conic bundles. One interesting\nfeature of our varieties is that the subordinate Brauer group may be\narbitrarily large.\n  As an application of our methods, we answer a question of Lenstra by giving\nan asymptotic for the triples of integers $(a, b, c)$ for which the R\\'edei\nsymbol $[a, b, c]$ takes a given value. We also make significant progress on a\nquestion of Serre on the zero loci of systems of quaternion algebras defined\nover $\\mathbb{Q}(t_1, \\dots, t_n)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T16:50:33Z"}
{"aid":"http://arxiv.org/abs/2504.21795v1","title":"Balancing Interpretability and Flexibility in Modeling Diagnostic\n  Trajectories with an Embedded Neural Hawkes Process Model","summary":"The Hawkes process (HP) is commonly used to model event sequences with\nself-reinforcing dynamics, including electronic health records (EHRs).\nTraditional HPs capture self-reinforcement via parametric impact functions that\ncan be inspected to understand how each event modulates the intensity of\nothers. Neural network-based HPs offer greater flexibility, resulting in\nimproved fit and prediction performance, but at the cost of interpretability,\nwhich is often critical in healthcare. In this work, we aim to understand and\nimprove upon this tradeoff. We propose a novel HP formulation in which impact\nfunctions are modeled by defining a flexible impact kernel, instantiated as a\nneural network, in event embedding space, which allows us to model large-scale\nevent sequences with many event types. This approach is more flexible than\ntraditional HPs yet more interpretable than other neural network approaches,\nand allows us to explicitly trade flexibility for interpretability by adding\ntransformer encoder layers to further contextualize the event embeddings.\nResults show that our method accurately recovers impact functions in\nsimulations, achieves competitive performance on MIMIC-IV procedure dataset,\nand gains clinically meaningful interpretation on XX-EHR with children\ndiagnosis dataset even without transformer layers. This suggests that our\nflexible impact kernel is often sufficient to capture self-reinforcing dynamics\nin EHRs and other data effectively, implying that interpretability can be\nmaintained without loss of performance.","main_category":"stat.ML","categories":"stat.ML,cs.LG,stat.AP","published":"2025-04-30T16:52:43Z"}
{"aid":"http://arxiv.org/abs/2504.21799v1","title":"A $p$-Converse theorem for Real Quadratic Fields","summary":"Let $E$ be an elliptic curve defined over a real quadratic field $F$. Let $p\n> 5$ be a rational prime that is inert in $F$ and assume that $E$ has split\nmultiplicative reduction at the prime $\\mathfrak{p}$ of $F$ dividing $p$. Let\n$\\underline{III}(E/F)$ denote the Tate-Shafarevich group of $E$ over $F$ and $\nL(E/F,s) $ be the Hasse-Weil complex $L$-function of $E$ over $F$. Under some\ntechnical assumptions, we show that when $rank_{\\mathbb{Z}} \\hspace{0.01mm}\n\\hspace{1mm} E(F) = 1$ and $\\#\\Big(\\underline{III}(E/F)_ {p^\\infty}\\Big) <\n\\infty$, then $ord_{s=1} \\ L(E/F,s) = 1$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T16:56:10Z"}
{"aid":"http://arxiv.org/abs/2504.21803v1","title":"An Empirical Study on the Effectiveness of Large Language Models for\n  Binary Code Understanding","summary":"Binary code analysis plays a pivotal role in the field of software security\nand is widely used in tasks such as software maintenance, malware detection,\nsoftware vulnerability discovery, patch analysis, etc. However, unlike source\ncode, reverse engineers face significant challenges in understanding binary\ncode due to the lack of intuitive semantic information. Although traditional\nreverse tools can convert binary code into C-like pseudo code, the lack of code\ncomments and symbolic information such as function names still makes code\nunderstanding difficult. In recent years, two groups of techniques have shown\npromising prospects: (1) Deep learning-based techniques have demonstrated\ncompetitive results in tasks related to binary code understanding, furthermore,\n(2) Large Language Models (LLMs) have been extensively pre-trained at the\nsource-code level for tasks such as code understanding and generation. This has\nleft participants wondering about the capabilities of LLMs in binary code\nunderstanding. To this end, this work proposes a benchmark to evaluate the\neffectiveness of LLMs in real-world reverse engineering scenarios, which covers\ntwo key binary code understanding tasks, i.e., function name recovery and\nbinary code summarization. To more comprehensively evaluate, we include\nbinaries with multiple target architectures as well as different optimization\noptions. We gain valuable insights into the capabilities and limitations\nthrough extensive empirical studies of popular LLMs using our benchmark. Our\nevaluations reveal that existing LLMs can understand binary code to a certain\nextent, thereby improving the efficiency of binary code analysis. Our results\nhighlight the great potential of the LLMs in advancing the field of binary code\nunderstanding, and provide new directions for binary code analysis techniques.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-30T17:02:06Z"}
{"aid":"http://arxiv.org/abs/2504.21806v1","title":"The embedding space of a Hopf link","summary":"We study the unparametrised smooth embedding space of a Hopf link in\n$\\mathbb{R}^3$, and prove that it is homotopy equivalent to the closed\n3-manifold $S^3/\\mathbb{Q}_8$. As an intermediate step in the proof, we show\nthat the inclusion of the subspace of round embeddings is a homotopy\nequivalence. We provide analogous results for the unparametrised smooth\nembedding space of a Hopf link in $S^3$.","main_category":"math.GT","categories":"math.GT","published":"2025-04-30T17:08:27Z"}
{"aid":"http://arxiv.org/abs/2504.21807v1","title":"Nonautonomous control systems and skew product flows","summary":"For nonautonomous control systems with compact control range, associated\ncontrol flows are introduced. This leads to several skew product flows with\nvarious base spaces. The controllability and chain controllability properties\nare studied and related to properties of the associated skew product flows.","main_category":"math.OC","categories":"math.OC","published":"2025-04-30T17:08:58Z"}
{"aid":"http://arxiv.org/abs/2504.21810v1","title":"A simple and effective approach for body part recognition on CT scans\n  based on projection estimation","summary":"It is well known that machine learning models require a high amount of\nannotated data to obtain optimal performance. Labelling Computed Tomography\n(CT) data can be a particularly challenging task due to its volumetric nature\nand often missing and$/$or incomplete associated meta-data. Even inspecting one\nCT scan requires additional computer software, or in the case of programming\nlanguages $-$ additional programming libraries. This study proposes a simple,\nyet effective approach based on 2D X-ray-like estimation of 3D CT scans for\nbody region identification. Although body region is commonly associated with\nthe CT scan, it often describes only the focused major body region neglecting\nother anatomical regions present in the observed CT. In the proposed approach,\nestimated 2D images were utilized to identify 14 distinct body regions,\nproviding valuable information for constructing a high-quality medical dataset.\nTo evaluate the effectiveness of the proposed method, it was compared against\n2.5D, 3D and foundation model (MI2) based approaches. Our approach outperformed\nthe others, where it came on top with statistical significance and F1-Score for\nthe best-performing model EffNet-B0 of 0.980 $\\pm$ 0.016 in comparison to the\n0.840 $\\pm$ 0.114 (2.5D DenseNet-161), 0.854 $\\pm$ 0.096 (3D VoxCNN), and 0.852\n$\\pm$ 0.104 (MI2 foundation model). The utilized dataset comprised three\ndifferent clinical centers and counted 15,622 CT scans (44,135 labels).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T17:13:44Z"}
{"aid":"http://arxiv.org/abs/2504.21813v1","title":"Turning a negative neutrino mass into a positive optical depth","summary":"Under $\\Lambda$CDM, recent baryon acoustic oscillation (BAO) distance\nmeasures from DESI, which favor a low matter density $\\Omega_m$, are in\nmoderate $2-3\\sigma$ tension with cosmic microwave background (CMB)\nobservations. This tension appears alternately as a preference for the sum of\nneutrino masses dropping below the $\\sum m_\\nu = 0.06$eV value required by\nneutrino oscillation measurements to formally negative values; a discrepant\nvalue of $\\Omega_m$ at 0.06eV; or preference for dynamical dark energy beyond\n$\\Lambda$CDM. We show that this tension largely arises from the CMB lensing\nconstraints on the calibration of the sound horizon for geometric measurements\nand relies on the measurement of the reionization optical depth $\\tau$ from\nlarge-angle CMB polarization to set the lensing amplitude. Dropping these\nconstraints removes the neutrino tension at $\\sum m_\\nu=0.06$eV entirely,\nfavoring $\\tau = 0.091\\pm 0.011$ in $\\Lambda$CDM. Beyond $\\Lambda$CDM, it\nbrings the preference for $w_0-w_a$ dynamical dark energy to below $95\\%$ CL.\nWe explore the freedom in interpreting the low-$\\ell$ EE polarization\nconstraint due to analysis choices and reionization modeling beyond the\nstandard step-function assumption and find that this drops the neutrino tension\nin $\\Lambda$CDM to below $95\\%$ CL. Alternately, this raising of $\\tau$ can\nalso be achieved by the same reduction in large-scale curvature fluctuations\nthat also ameliorates the low-$\\ell$ temperature anomaly.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-30T17:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.21820v1","title":"Two lock-in amplifiers based $3Ï‰$ technique: a practical guide for\n  thermal conductivity experiments in bulk samples","summary":"The accurate determination of thermal conductivity $\\kappa(T)$ in bulk\nmaterials is essential to assess their performance as candidates for specific\napplications. The 3$\\omega$ technique is an established methodology for\nstudying the thermal conductivity of thin films and becomes particularly\nsuitable in the case of bulk specimens at room temperature and above, where\nstandard stationary techniques require significant corrections for radiative\nlosses. Although this method has been employed in several works, it remains not\nwidely adopted because its implementation demands considerable sophistication,\nincluding experiment design, thin film deposition techniques and choices of the\ngeometry of the current/heat transducer, electronics, and analytical treatment\nof the signals. This work reviews the technique's most crucial technical\naspects, providing practical support for a quick and user-friendly\nimplementation, from the design phase to the execution and analysis. We release\na Python-based graphical user interface that supports a quick quantitative\nestimation of the investigated temperature profiles based on the geometrical\nparameters (width/length) of the deposited transducer (heater/thermometer metal\nline) before an experiment, guaranteeing an optimal engineering of the\nexperimental conditions for each given material under scrutiny.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.ins-det","published":"2025-04-30T17:24:55Z"}
{"aid":"http://arxiv.org/abs/2504.21823v1","title":"A Sequoia stellar candidate with very high 7Li and 9Be","summary":"Aims. The metal-poor star BPM 3066 belongs to the retrograde halo and\npresents unexpectedly strong spectral features of lithium. To gain insight into\nthe origin of this peculiar abundance, we investigate the chemistry and\nkinematic properties of this star. Methods. We performed a local thermodynamic\nequilibrium chemical abundance analysis of UVES/VLT high-resolution spectra of\nBPM 3066 using ATLAS9 and ATLAS12 model atmospheres and the MyGIsFOS code. We\nfurther characterised the orbital properties of the star by integrating its\norbit and analysing its integrals of motion using the galpy code. Results. The\nstar BPM 3066 shows an exceptional overabundance of both lithium and beryllium.\nThe abundances are A(Li) = 3.0 and A(Be) = 2.1, which are respectively about\n0.8 and 2.2 dex higher than the Li and Be abundances expected at [Fe/H] = -1.5,\nthe metallicity of the star. The observed ratio 7Li/9Be is 7.9, which is close\nto that expected from a synthesis by spallation processes. Overabundances of\nSi, Al, and of the neutron capture elements Sr,Y, Zr, and Ba are also measured.\nKinematically, BPM 3066 has an eccentric, strongly retrograde orbit, confined\nto a height lower than 1 kpc from the galactic plane, and it is a candidate\nmember of the Sequoia/Thamnos accreted galaxy. Conclusions. The processes\nleading to the 7Li and 9Be synthesis could have occurred in the environment of\na hypernova. This is supported by some abundance anomalies like the high value\nof Si, [Si/Fe]=1.2 and [Si/O]=1.1. However, the simultaneous high values of N,\nNa, Al, Sc, Ti, and Cu are at odds with the expectations from a hypernova.\nAlternatively, the abundances of BPM 3066 could result from the engulfing of\nrocky planets that were rich in spallated Li and Be. In both cases, it is\nremarkable that such an extreme abundance pattern has been found in a star\nbelonging to the Sequoia/Thamnos accreted galaxy.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-30T17:26:59Z"}
{"aid":"http://arxiv.org/abs/2504.21828v1","title":"A Path to Quantum Simulations of Topological Phases: (2+1)D Wilson\n  Fermions Coupled To U(1) Background Gauge Fields","summary":"Quantum simulation offers a powerful approach to studying quantum field\ntheories, particularly (2+1)D quantum electrodynamics (QED$_3$), which hosts a\nrich landscape of physical phenomena. A key challenge in lattice formulations\nis the proper realization of topological phases and the Chern-Simons terms,\nwhere fermion discretization plays a crucial role. In this work, we analyze\nstaggered and Wilson fermions coupled to $\\text{U}(1)$ background gauge fields\nin the Hamiltonian formulation and demonstrate that staggered fermions fail to\ninduce (2+1)D topological phases, while Wilson fermions admit a variety of\ntopological phases including Chern insulator and quantum spin Hall phases. We\nadditionally uncover a rich phase diagram for the two-flavor Wilson fermion\nmodel in the presence of a chemical potential. Our findings resolve existing\nambiguities in Hamiltonian formulations and provide a theoretical foundation\nfor future quantum simulations of gauge theories with topological phases. We\nfurther outline connections to experimental platforms, offering guidance for\nimplementations on near-term quantum computing architectures.","main_category":"hep-lat","categories":"hep-lat,hep-th,quant-ph","published":"2025-04-30T17:33:01Z"}
{"aid":"http://arxiv.org/abs/2504.21829v1","title":"On strong Euler-homogeneity and Saito-holonomicity for complex\n  hypersurfaces","summary":"Based on previous work on linear free divisors by Granger et al., we develop\nnecessary and sufficient conditions for a general divisor to be strongly\nEuler-homogeneous in terms of some Fitting ideals.\n  We also define the notions of weak and strong Saito-holonomicity for a\ngeneral divisor in such a way that they extend the definitions of\nSaito-holonomicity and weak and strong Koszul-freeness. Then, we characterize\nthese properties using the Fitting ideals previously defined. Finally, we\ngeneralize some results regarding Koszul-freeness and strong Euler-homogeneity\nto the non-free case.","main_category":"math.AG","categories":"math.AG,math.CV","published":"2025-04-30T17:34:27Z"}
{"aid":"http://arxiv.org/abs/2504.21834v1","title":"Advances on a conjecture about free divisors","summary":"In 2002, it was conjectured that a free divisor satisfying the so-called\nLogarithmic Comparison Theorem (LCT) must be strongly Euler-homogeneous. Today,\nit is known to be true only in ambient dimension less or equal than three or\nassuming Koszul-freeness. Thanks to our advances in the comprehension of strong\nEuler-homogeneity, we are able to prove the conjecture in the following new\ncases: assuming strong Euler-homogeneity on a punctured neighbourhood of a\npoint; assuming the divisor is weakly Koszul-free; for ambient dimension $n=4$;\nfor linear free divisors in ambient dimension $n=5$. We also refute a\nconjecture that states that all linear free divisors satisfy LCT and are\nstrongly Euler-homogeneous.","main_category":"math.AG","categories":"math.AG,math.CV","published":"2025-04-30T17:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.21851v1","title":"TRUST: An LLM-Based Dialogue System for Trauma Understanding and\n  Structured Assessments","summary":"Objectives: While Large Language Models (LLMs) have been widely used to\nassist clinicians and support patients, no existing work has explored dialogue\nsystems for standard diagnostic interviews and assessments. This study aims to\nbridge the gap in mental healthcare accessibility by developing an LLM-powered\ndialogue system that replicates clinician behavior. Materials and Methods: We\nintroduce TRUST, a framework of cooperative LLM modules capable of conducting\nformal diagnostic interviews and assessments for Post-Traumatic Stress Disorder\n(PTSD). To guide the generation of appropriate clinical responses, we propose a\nDialogue Acts schema specifically designed for clinical interviews.\nAdditionally, we develop a patient simulation approach based on real-life\ninterview transcripts to replace time-consuming and costly manual testing by\nclinicians. Results: A comprehensive set of evaluation metrics is designed to\nassess the dialogue system from both the agent and patient simulation\nperspectives. Expert evaluations by conversation and clinical specialists show\nthat TRUST performs comparably to real-life clinical interviews. Discussion:\nOur system performs at the level of average clinicians, with room for future\nenhancements in communication styles and response appropriateness. Conclusions:\nOur TRUST framework shows its potential to facilitate mental healthcare\navailability.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-30T17:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.21855v1","title":"ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D\n  Physics Modeling for Complex Motion and Interaction","summary":"In recent years, video generation has seen significant advancements. However,\nchallenges still persist in generating complex motions and interactions. To\naddress these challenges, we introduce ReVision, a plug-and-play framework that\nexplicitly integrates parameterized 3D physical knowledge into a pretrained\nconditional video generation model, significantly enhancing its ability to\ngenerate high-quality videos with complex motion and interactions.\nSpecifically, ReVision consists of three stages. First, a video diffusion model\nis used to generate a coarse video. Next, we extract a set of 2D and 3D\nfeatures from the coarse video to construct a 3D object-centric representation,\nwhich is then refined by our proposed parameterized physical prior model to\nproduce an accurate 3D motion sequence. Finally, this refined motion sequence\nis fed back into the same video diffusion model as additional conditioning,\nenabling the generation of motion-consistent videos, even in scenarios\ninvolving complex actions and interactions. We validate the effectiveness of\nour approach on Stable Video Diffusion, where ReVision significantly improves\nmotion fidelity and coherence. Remarkably, with only 1.5B parameters, it even\noutperforms a state-of-the-art video generation model with over 13B parameters\non complex video generation by a substantial margin. Our results suggest that,\nby incorporating 3D physical knowledge, even a relatively small video diffusion\nmodel can generate complex motions and interactions with greater realism and\ncontrollability, offering a promising solution for physically plausible video\ngeneration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2505.00251v1","title":"Multi-start Optimization Method via Scalarization based on Target\n  Point-based Tchebycheff Distance for Multi-objective Optimization","summary":"Multi-objective optimization is crucial in scientific and industrial\napplications where solutions must balance trade-offs among conflicting\nobjectives. State-of-the-art methods, such as NSGA-III and MOEA/D, can handle\nmany objectives but struggle with coverage issues, particularly in cases\ninvolving inverted triangular Pareto fronts or strong nonlinearity. Moreover,\nNSGA-III often relies on simulated binary crossover, which deteriorates in\nproblems with variable dependencies. In this study, we propose a novel\nmulti-start optimization method that addresses these challenges. Our approach\nintroduces a newly introduced scalarization technique, the Target Point-based\nTchebycheff Distance (TPTD) method, which significantly improves coverage on\nproblems with inverted triangular Pareto fronts. For efficient multi-start\noptimization, TPTD leverages a target point defined in the objective space,\nwhich plays a critical role in shaping the scalarized function. The position of\nthe target point is adaptively determined according to the shape of the Pareto\nfront, ensuring improvement in coverage. Furthermore, the flexibility of this\nscalarization allows seamless integration with powerful single-objective\noptimization methods, such as natural evolution strategies, to efficiently\nhandle variable dependencies. Experimental results on benchmark problems,\nincluding those with inverted triangular Pareto fronts, demonstrate that our\nmethod outperforms NSGA-II, NSGA-III, and MOEA/D-DE in terms of the Hypervolume\nindicator. Notably, our approach achieves computational efficiency improvements\nof up to 474 times over these baselines.","main_category":"cs.NE","categories":"cs.NE","published":"2025-05-01T02:27:25Z"}
{"aid":"http://arxiv.org/abs/2505.00253v1","title":"Functional Multidimensional Scaling","summary":"This article introduces a functional method for lower-dimensional smooth\nrepresentations in terms of time-varying dissimilarities. The method\nincorporates dissimilarity representation in multidimensional scaling and\nsmoothness approach of functional data analysis by using cubic B-spline basis\nfunctions. The model is designed to arrive at optimal representations with an\niterative procedure such that dissimilarities evaluated by estimated\nrepresentations are almost the same as original dissimilarities of objects in a\nlow dimension which is easier for people to recognize. To solve expensive\ncomputation in optimization, we propose a computationally efficient method by\ntaking gradient steps with respect to individual sub-functions of target\nfunctions using a Stochastic Gradient Descent algorithm. Keywords:\nMultidimensional Scaling, Functional Data Analysis, Statistical Modeling,\nQuasi-Newton Method, Stochastic Gradient Descent","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-01T02:38:20Z"}
{"aid":"http://arxiv.org/abs/2505.00256v1","title":"Policy Learning with $Î±$-Expected Welfare","summary":"This paper proposes an optimal policy that targets the average welfare of the\nworst-off $\\alpha$-fraction of the post-treatment outcome distribution. We\nrefer to this policy as the $\\alpha$-Expected Welfare Maximization\n($\\alpha$-EWM) rule, where $\\alpha \\in (0,1]$ denotes the size of the\nsubpopulation of interest. The $\\alpha$-EWM rule interpolates between the\nexpected welfare ($\\alpha=1$) and the Rawlsian welfare ($\\alpha\\rightarrow 0$).\nFor $\\alpha\\in (0,1)$, an $\\alpha$-EWM rule can be interpreted as a\ndistributionally robust EWM rule that allows the target population to have a\ndifferent distribution than the study population. Using the dual formulation of\nour $\\alpha$-expected welfare function, we propose a debiased estimator for the\noptimal policy and establish its asymptotic upper regret bounds. In addition,\nwe develop asymptotically valid inference for the optimal welfare based on the\nproposed debiased estimator. We examine the finite sample performance of the\ndebiased estimator and inference via both real and synthetic data.","main_category":"econ.EM","categories":"econ.EM","published":"2025-05-01T02:42:13Z"}
{"aid":"http://arxiv.org/abs/2505.00262v1","title":"Certain residual properties of HNN-extensions with normal associated\n  subgroups","summary":"Let $\\mathbb{E}$ be the HNN-extension of a group $B$ with subgroups $H$ and\n$K$ associated according to an isomorphism $\\varphi\\colon H \\to K$. Suppose\nthat $H$ and $K$ are normal in $B$ and $(H \\cap K)\\varphi = H \\cap K$. Under\nthese assumptions, we prove necessary and sufficient conditions for\n$\\mathbb{E}$ to be residually a $\\mathcal{C}$-group, where $\\mathcal{C}$ is a\nclass of groups closed under taking subgroups, quotient groups, and\nunrestricted wreath products. Among other things, these conditions give new\nfacts on the residual finiteness and the residual $p$-finiteness of the group\n$\\mathbb{E}$.","main_category":"math.GR","categories":"math.GR","published":"2025-05-01T03:05:25Z"}
{"aid":"http://arxiv.org/abs/2505.00277v1","title":"Elephant random walk with polynomially decaying steps","summary":"In this paper, we introduce a variation of the elephant random walk whose\nsteps are polynomially decaying. At each time $k$, the walker's step size is\n$k^{-\\gamma}$ with $\\gamma>0$. We investigate effects of the step size exponent\n$\\gamma$ and the memory parameter $\\alpha\\in [-1,1]$ on the long-time behavior\nof the walker. For fixed $\\alpha$, it admits phase transition from divergence\nto convergence (localization) at $\\gamma_{c}(\\alpha)=\\max \\{\\alpha,1/2\\}$. This\nmeans that large enough memory effect can shift the critical point for\nlocalization. Moreover, we obtain quantitative limit theorems which provide a\ndetailed picture of the long-time behavior of the walker.","main_category":"math.PR","categories":"math.PR","published":"2025-05-01T03:57:55Z"}
{"aid":"http://arxiv.org/abs/2505.00301v1","title":"Evidence for Core-Core Collision in Barnard 68","summary":"The prestellar core Barnard 68 (B68) is a prototypical source to study the\ninitial conditions and chemical processes of star formation. A previous\nnumerical simulation suggested the southeastern bullet is impacting on the main\nbody of B68. In order to obtain more observational evidence, mapping\nobservations of the ground state SO ($1_0-0_1$) emission line at 30 GHz were\nmade with the Effelsberg 100 m telescope. Based on the velocity field and\nchannel maps derived from SO, three velocity components were clearly detected.\nThe velocity field of the main body indicates rotation and is well fitted by a\nsolid-body rotation model. The measured radial velocity difference between the\nbullet and the main core is about 0.4 km s$^{-1}$, which is almost equal to the\nvelocity obtained by the previous numerical simulation. Therefore, the bullet\nis most likely impacting onto the rotating main body of B68. A 1D spherical\nnon-LTE Monte-Carlo radiation transfer RATRAN code is performed to derive the\nradial abundance profile of SO by analyzing the observed velocity-integrated\nintensity. SO is depleted inside a 60$^{\\prime\\prime}$ (0.02 pc) radius from\nthe core. The abundance stays constant at 2.0$\\times$10$^{-9}$ for radii larger\nthan 60$^{\\prime\\prime}$ from the center of the main core. The abundance is\nenhanced at the interface of the bullet and the main core indicating that shock\nwaves were produced by the collision between the bullet and the main core. In\nconclusion, based on the kinematical and chemical analysis, our observational\nresults support the previously proposed core-core collision scenario in B68.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-01T04:44:52Z"}
{"aid":"http://arxiv.org/abs/2505.00304v1","title":"Reinforcement Learning with Continuous Actions Under Unmeasured\n  Confounding","summary":"This paper addresses the challenge of offline policy learning in\nreinforcement learning with continuous action spaces when unmeasured\nconfounders are present. While most existing research focuses on policy\nevaluation within partially observable Markov decision processes (POMDPs) and\nassumes discrete action spaces, we advance this field by establishing a novel\nidentification result to enable the nonparametric estimation of policy value\nfor a given target policy under an infinite-horizon framework. Leveraging this\nidentification, we develop a minimax estimator and introduce a\npolicy-gradient-based algorithm to identify the in-class optimal policy that\nmaximizes the estimated policy value. Furthermore, we provide theoretical\nresults regarding the consistency, finite-sample error bound, and regret bound\nof the resulting optimal policy. Extensive simulations and a real-world\napplication using the German Family Panel data demonstrate the effectiveness of\nour proposed methodology.","main_category":"stat.ML","categories":"stat.ML,cs.LG,stat.ME","published":"2025-05-01T04:55:29Z"}
{"aid":"http://arxiv.org/abs/2505.00305v1","title":"Iterations of Meromorphic Functions involving Sine","summary":"In this article, the dynamics of a one-parameter family of functions\n$f_{\\lambda}(z) = \\frac{\\sin{z}}{z^2 + \\lambda},$ $\\lambda>0$, are studied. It\nshows the existence of parameters $0< \\lambda_{1}< \\lambda_{2}$ such that\nbifurcations occur at $\\lambda_1$ and $\\lambda_2$ for $f_{\\lambda}$. It is\nproved that the Fatou set $\\mathcal{F}(f_{\\lambda})$ is the union of basins of\nattraction in the complex plane for $\\lambda \\in (\\lambda_1, \\lambda_2) \\cup\n(\\lambda_2, \\infty)$. Further, every Fatou component of $f_{\\lambda}$ is simply\nconnected for $\\lambda \\geq \\lambda_1$. The boundary of the Fatou set\n$\\mathcal{F}(f_{\\lambda})$ is the Julia set $\\mathcal{J}(f_{\\lambda})$ in the\nextended complex plane for $\\lambda> 1$. Interestingly, it is found that\n$f_{\\lambda}$ has only one completely invariant Fatou component, say\n$U_\\lambda$ such that $\\mathcal{F}(f_{\\lambda}) = U_{\\lambda}$ for $\\lambda\n>\\lambda_2$. Moreover, the characterization of the Julia set of $f_{\\lambda}$\nis seen for $\\lambda \\in (\\lambda_1, \\infty)\\setminus \\{\\lambda_2\\}$.","main_category":"math.DS","categories":"math.DS","published":"2025-05-01T04:57:20Z"}
{"aid":"http://arxiv.org/abs/2505.00311v1","title":"PDCS: A Primal-Dual Large-Scale Conic Programming Solver with GPU\n  Enhancements","summary":"In this paper, we introduce the \"Primal-Dual Conic Programming Solver\"\n(PDCS), a large-scale conic programming solver with GPU enhancements. Problems\nthat PDCS currently supports include linear programs, second-order cone\nprograms, convex quadratic programs, and exponential cone programs. PDCS\nachieves scalability to large-scale problems by leveraging sparse matrix-vector\nmultiplication as its core computational operation, which is both\nmemory-efficient and well-suited for GPU acceleration. The solver is based on\nthe restarted primal-dual hybrid gradient method but further incorporates\nseveral enhancements, including adaptive reflected Halpern restarts, adaptive\nstep-size selection, adaptive weight adjustment, and diagonal rescaling.\nAdditionally, PDCS employs a bijection-based method to compute projections onto\nrescaled cones. Furthermore, cuPDCS is a GPU implementation of PDCS and it\nimplements customized computational schemes that utilize different levels of\nGPU architecture to handle cones of different types and sizes. Numerical\nexperiments demonstrate that cuPDCS is generally more efficient than\nstate-of-the-art commercial solvers and other first-order methods on\nlarge-scale conic program applications, including Fisher market equilibrium\nproblems, Lasso regression, and multi-period portfolio optimization.\nFurthermore, cuPDCS also exhibits better scalability, efficiency, and\nrobustness compared to other first-order methods on the conic program benchmark\ndataset CBLIB. These advantages are more pronounced in large-scale,\nlower-accuracy settings.","main_category":"math.OC","categories":"math.OC,cs.MS","published":"2025-05-01T05:13:48Z"}
{"aid":"http://arxiv.org/abs/2505.00330v1","title":"A topological constraint on clean Lagrangian intersections from\n  $\\mathbb{Q}$-valued augmentations","summary":"For a knot $K$ in $\\mathbb{R}^3$, consider its conormal bundle $L_K$ in\n$T^*\\mathbb{R}^3$. We prove that if $K$ is the connected sum $K' \\# 3_1$ of an\narbitrary knot $K'$ and the trefoil knot $3_1$ (or its mirror), then there is\nno compactly supported Hamiltonian diffeomorphism $\\varphi$ on\n$T^*\\mathbb{R}^3$ such that $\\varphi(L_K)$ and the zero section $\\mathbb{R}^3$\nintersect cleanly along the unknot in $\\mathbb{R}^3$. For the proof, we utilize\nthe knot DGA, whose homology was proved to be isomorphic to the knot contact\nhomology by Ekholm, Etnyre, Ng and Sullivan, with coefficients in\n$\\mathbb{Z}[\\lambda^{\\pm},\\mu^{\\pm},U^{\\pm}]$. We discover a certain algebraic\nconstraint imposed on any augmentation of the knot DGA of $K = K'\\# 3_1$ to a\nfield $\\mathbf{k}$. This constraint is non-trivial for $\\mathbf{k}=\\mathbb{Q}$\nand plays a key role in the proof, but trivial if $\\mathbf{k}$ is quadratically\nclosed or if an augmentation factors through the knot DGA with coefficients in\n$\\mathbb{Z}[\\lambda^{\\pm},\\mu^{\\pm}]$ obtained by setting $U=1$.","main_category":"math.SG","categories":"math.SG,math.GT","published":"2025-05-01T05:58:44Z"}
{"aid":"http://arxiv.org/abs/2505.00331v1","title":"Geodesic Synthetic Control Methods for Random Objects and Functional\n  Data","summary":"We introduce a geodesic synthetic control method for causal inference that\nextends existing synthetic control methods to scenarios where outcomes are\nelements in a geodesic metric space rather than scalars. Examples of such\noutcomes include distributions, compositions, networks, trees and functional\ndata, among other data types that can be viewed as elements of a geodesic\nmetric space given a suitable metric. We extend this further to geodesic\nsynthetic difference-in-differences that builds on the established synthetic\ndifference-in-differences for Euclidean outcomes. This estimator generalizes\nboth the geodesic synthetic control method and a previously proposed geodesic\ndifference-in-differences method and exhibits a double robustness property. The\nproposed geodesic synthetic control method is illustrated through comprehensive\nsimulation studies and applications to the employment composition changes\nfollowing the 2011 Great East Japan Earthquake, and the impact of abortion\nliberalization policy on fertility patterns in East Germany. We illustrate the\nproposed geodesic synthetic difference-in-differences by studying the\nconsequences of the Soviet Union's collapse on age-at-death distributions for\nmales and females.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-01T06:12:35Z"}
{"aid":"http://arxiv.org/abs/2505.00332v1","title":"Active Contact Engagement for Aerial Navigation in Unknown Environments\n  with Glass","summary":"Autonomous aerial robots are increasingly being deployed in real-world\nscenarios, where transparent glass obstacles present significant challenges to\nreliable navigation. Researchers have investigated the use of non-contact\nsensors and passive contact-resilient aerial vehicle designs to detect glass\nsurfaces, which are often limited in terms of robustness and efficiency. In\nthis work, we propose a novel approach for robust autonomous aerial navigation\nin unknown environments with transparent glass obstacles, combining the\nstrengths of both sensor-based and contact-based glass detection. The proposed\nsystem begins with the incremental detection and information maintenance about\npotential glass surfaces using visual sensor measurements. The vehicle then\nactively engages in touch actions with the visually detected potential glass\nsurfaces using a pair of lightweight contact-sensing modules to confirm or\ninvalidate their presence. Following this, the volumetric map is efficiently\nupdated with the glass surface information and safe trajectories are replanned\non the fly to circumvent the glass obstacles. We validate the proposed system\nthrough real-world experiments in various scenarios, demonstrating its\neffectiveness in enabling efficient and robust autonomous aerial navigation in\ncomplex real-world environments with glass obstacles.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T06:14:53Z"}
{"aid":"http://arxiv.org/abs/2505.00337v1","title":"T2VPhysBench: A First-Principles Benchmark for Physical Consistency in\n  Text-to-Video Generation","summary":"Text-to-video generative models have made significant strides in recent\nyears, producing high-quality videos that excel in both aesthetic appeal and\naccurate instruction following, and have become central to digital art creation\nand user engagement online. Yet, despite these advancements, their ability to\nrespect fundamental physical laws remains largely untested: many outputs still\nviolate basic constraints such as rigid-body collisions, energy conservation,\nand gravitational dynamics, resulting in unrealistic or even misleading\ncontent. Existing physical-evaluation benchmarks typically rely on automatic,\npixel-level metrics applied to simplistic, life-scenario prompts, and thus\noverlook both human judgment and first-principles physics. To fill this gap, we\nintroduce \\textbf{T2VPhysBench}, a first-principled benchmark that\nsystematically evaluates whether state-of-the-art text-to-video systems, both\nopen-source and commercial, obey twelve core physical laws including Newtonian\nmechanics, conservation principles, and phenomenological effects. Our benchmark\nemploys a rigorous human evaluation protocol and includes three targeted\nstudies: (1) an overall compliance assessment showing that all models score\nbelow 0.60 on average in each law category; (2) a prompt-hint ablation\nrevealing that even detailed, law-specific hints fail to remedy physics\nviolations; and (3) a counterfactual robustness test demonstrating that models\noften generate videos that explicitly break physical rules when so instructed.\nThe results expose persistent limitations in current architectures and offer\nconcrete insights for guiding future research toward truly physics-aware video\ngeneration.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,cs.CV","published":"2025-05-01T06:34:55Z"}
{"aid":"http://arxiv.org/abs/2505.00348v1","title":"Validation of a 24-hour-ahead Prediction model for a Residential\n  Electrical Load under diverse climate","summary":"Accurate household electrical energy demand prediction is essential for\neffectively managing sustainable Energy Communities. Integrated with the Energy\nManagement System, these communities aim to optimise operational costs.\nHowever, most existing forecasting models are region-specific and depend on\nlarge datasets, limiting their applicability across different climates and\ngeographical areas. These models often lack flexibility and may not perform\nwell in regions with limited historical data, leading to inaccurate\npredictions. This paper proposes a global model for 24-hour-ahead hourly\nelectrical energy demand prediction that is designed to perform effectively\nacross diverse climate conditions and datasets. The model's efficiency is\ndemonstrated using data from two distinct regions: Ireland, with a maritime\nclimate and Vietnam, with a tropical climate. Remarkably, the model achieves\nhigh accuracy even with a limited dataset spanning only nine months. Its\nrobustness is further validated across different seasons in Ireland (summer and\nwinter) and Vietnam (dry and wet). The proposed model is evaluated against\nstate-of-the-art machine learning and deep learning methods. Simulation results\nindicate that the model consistently outperforms benchmark models, showcasing\nits capability to provide reliable forecasts globally, regardless of varying\nclimatic conditions and data availability. This research underscores the\nmodel's potential to enhance the efficiency and sustainability of Energy\nCommunities worldwide. The proposed model achieves a Mean Absolute Percentage\nError of 8.0% and 4.0% on the full Irish and Vietnamese datasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T06:48:26Z"}
{"aid":"http://arxiv.org/abs/2505.00359v1","title":"TNStream: Applying Tightest Neighbors to Micro-Clusters to Define\n  Multi-Density Clusters in Streaming Data","summary":"In data stream clustering, systematic theory of stream clustering algorithms\nremains relatively scarce. Recently, density-based methods have gained\nattention. However, existing algorithms struggle to simultaneously handle\narbitrarily shaped, multi-density, high-dimensional data while maintaining\nstrong outlier resistance. Clustering quality significantly deteriorates when\ndata density varies complexly. This paper proposes a clustering algorithm based\non the novel concept of Tightest Neighbors and introduces a data stream\nclustering theory based on the Skeleton Set. Based on these theories, this\npaper develops a new method, TNStream, a fully online algorithm. The algorithm\nadaptively determines the clustering radius based on local similarity,\nsummarizing the evolution of multi-density data streams in micro-clusters. It\nthen applies a Tightest Neighbors-based clustering algorithm to form final\nclusters. To improve efficiency in high-dimensional cases, Locality-Sensitive\nHashing (LSH) is employed to structure micro-clusters, addressing the challenge\nof storing k-nearest neighbors. TNStream is evaluated on various synthetic and\nreal-world datasets using different clustering metrics. Experimental results\ndemonstrate its effectiveness in improving clustering quality for multi-density\ndata and validate the proposed data stream clustering theory.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE","published":"2025-05-01T07:15:20Z"}
{"aid":"http://arxiv.org/abs/2505.00366v1","title":"Primordial black hole formation from a type II perturbation in the\n  absence and presence of pressure","summary":"We investigate primordial black holes (PBHs) formed from extremely large\namplitudes of primordial curvature fluctuations, classified as type II. Type II\nfluctuations differ from type I by the presence of a stationary point on the\ninitial time slice, when we see the areal radius as a function of the radial\ncoordinate. Starting from these type II perturbations to form black holes, the\nnonlinear evolution governed by the Einstein equations generally results in two\ndistinct types, A and B, of horizon configurations, respectively characterized\nby the absence and presence of a bifurcating trapping horizon where past and\nfuture trapping horizons meet. In this paper, we use the Lemaitre-Tolman-Bondi\nsolution to show that type I/II and type A/B classifications are equivalent for\na spherically symmetric dust fluid system, regardless of the fluctuation\nprofile. However, this equivalence does not generally hold in the presence of\npressure.","main_category":"gr-qc","categories":"gr-qc","published":"2025-05-01T07:37:06Z"}
{"aid":"http://arxiv.org/abs/2505.00368v1","title":"Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic\n  Approach","summary":"Urban Air Mobility (UAM) is an emerging System of System (SoS) that faces\nchallenges in system architecture, planning, task management, and execution.\nTraditional architectural approaches struggle with scalability, adaptability,\nand seamless resource integration within dynamic and complex environments. This\npaper presents an intelligent holonic architecture that incorporates Large\nLanguage Model (LLM) to manage the complexities of UAM. Holons function semi\nautonomously, allowing for real time coordination among air taxis, ground\ntransport, and vertiports. LLMs process natural language inputs, generate\nadaptive plans, and manage disruptions such as weather changes or airspace\nclosures.Through a case study of multimodal transportation with electric\nscooters and air taxis, we demonstrate how this architecture enables dynamic\nresource allocation, real time replanning, and autonomous adaptation without\ncentralized control, creating more resilient and efficient urban transportation\nnetworks. By advancing decentralized control and AI driven adaptability, this\nwork lays the groundwork for resilient, human centric UAM ecosystems, with\nfuture efforts targeting hybrid AI integration and real world validation.","main_category":"cs.AI","categories":"cs.AI,cs.ET,cs.MA,cs.RO","published":"2025-05-01T07:39:11Z"}
{"aid":"http://arxiv.org/abs/2505.00375v1","title":"Learning to Estimate Package Delivery Time in Mixed Imbalanced Delivery\n  and Pickup Logistics Services","summary":"Accurately estimating package delivery time is essential to the logistics\nindustry, which enables reasonable work allocation and on-time service\nguarantee. This becomes even more necessary in mixed logistics scenarios where\ncouriers handle a high volume of delivery and a smaller number of pickup\nsimultaneously. However, most of the related works treat the pickup and\ndelivery patterns on couriers' decision behavior equally, neglecting that the\npickup has a greater impact on couriers' decision-making compared to the\ndelivery due to its tighter time constraints. In such context, we have three\nmain challenges: 1) multiple spatiotemporal factors are intricately\ninterconnected, significantly affecting couriers' delivery behavior; 2) pickups\nhave stricter time requirements but are limited in number, making it\nchallenging to model their effects on couriers' delivery process; 3) couriers'\nspatial mobility patterns are critical determinants of their delivery behavior,\nbut have been insufficiently explored. To deal with these, we propose TransPDT,\na Transformer-based multi-task package delivery time prediction model. We first\nemploy the Transformer encoder architecture to capture the spatio-temporal\ndependencies of couriers' historical travel routes and pending package sets.\nThen we design the pattern memory to learn the patterns of pickup in the\nimbalanced dataset via attention mechanism. We also set the route prediction as\nan auxiliary task of delivery time prediction, and incorporate the prior\ncourier spatial movement regularities in prediction. Extensive experiments on\nreal industry-scale datasets demonstrate the superiority of our method. A\nsystem based on TransPDT is deployed internally in JD Logistics to track more\nthan 2000 couriers handling hundreds of thousands of packages per day in\nBeijing.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-01T08:00:22Z"}
{"aid":"http://arxiv.org/abs/2505.00379v1","title":"Vintage-Based Formulations in Multi-Year Investment Modelling for Energy\n  Systems","summary":"This paper reviews two established formulations for modelling multi-year\nenergy investments: the simple method, which aggregates all capacity regardless\nof commissioning year, and the vintage method, which explicitly tracks\ninvestments by year to capture differences in technical parameters over time.\nWhile the vintage method improves modelling fidelity, it significantly\nincreases model size. To address this, we propose a novel compact formulation\nthat maintains the ability to represent year-specific characteristics while\nreducing the dimensionality of the model. The proposed compact formulation is\nimplemented in the open-source model TulipaEnergyModel.jl and offers a\ntractable alternative for detailed long-term energy system planning.","main_category":"math.OC","categories":"math.OC","published":"2025-05-01T08:14:19Z"}
{"aid":"http://arxiv.org/abs/2505.00380v1","title":"The Invisible Threat: Evaluating the Vulnerability of Cross-Spectral\n  Face Recognition to Presentation Attacks","summary":"Cross-spectral face recognition systems are designed to enhance the\nperformance of facial recognition systems by enabling cross-modal matching\nunder challenging operational conditions. A particularly relevant application\nis the matching of near-infrared (NIR) images to visible-spectrum (VIS) images,\nenabling the verification of individuals by comparing NIR facial captures\nacquired with VIS reference images. The use of NIR imaging offers several\nadvantages, including greater robustness to illumination variations, better\nvisibility through glasses and glare, and greater resistance to presentation\nattacks. Despite these claimed benefits, the robustness of NIR-based systems\nagainst presentation attacks has not been systematically studied in the\nliterature. In this work, we conduct a comprehensive evaluation into the\nvulnerability of NIR-VIS cross-spectral face recognition systems to\npresentation attacks. Our empirical findings indicate that, although these\nsystems exhibit a certain degree of reliability, they remain vulnerable to\nspecific attacks, emphasizing the need for further research in this area.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T08:15:48Z"}
{"aid":"http://arxiv.org/abs/2505.00394v1","title":"SOTA: Spike-Navigated Optimal TrAnsport Saliency Region Detection in\n  Composite-bias Videos","summary":"Existing saliency detection methods struggle in real-world scenarios due to\nmotion blur and occlusions. In contrast, spike cameras, with their high\ntemporal resolution, significantly enhance visual saliency maps. However, the\ncomposite noise inherent to spike camera imaging introduces discontinuities in\nsaliency detection. Low-quality samples further distort model predictions,\nleading to saliency bias. To address these challenges, we propose\nSpike-navigated Optimal TrAnsport Saliency Region Detection (SOTA), a framework\nthat leverages the strengths of spike cameras while mitigating biases in both\nspatial and temporal dimensions. Our method introduces Spike-based Micro-debias\n(SM) to capture subtle frame-to-frame variations and preserve critical details,\neven under minimal scene or lighting changes. Additionally, Spike-based\nGlobal-debias (SG) refines predictions by reducing inconsistencies across\ndiverse conditions. Extensive experiments on real and synthetic datasets\ndemonstrate that SOTA outperforms existing methods by eliminating composite\nnoise bias. Our code and dataset will be released at\nhttps://github.com/lwxfight/sota.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T08:30:40Z"}
{"aid":"http://arxiv.org/abs/2505.00395v1","title":"GAN-based Generator of Adversarial Attack on Intelligent End-to-End\n  Autoencoder-based Communication System","summary":"Deep neural networks have been applied in wireless communications system to\nintelligently adapt to dynamically changing channel conditions, while the users\nare still under the threat of the malicious attacks due to the broadcasting\nproperty of wireless channels. However, most attack models require the\nknowledge of the target details, which is difficult to be implemented in real\nsystems. Our objective is to develop an attack model with no requirement for\nthe target information, while enhancing the block error rate. In our design, we\npropose a novel Generative Adversarial Networks(GANs) based attack\narchitecture, which exploits the property of deep learning models being\nvulnerable to perturbations induced by dynamically changing channel conditions.\nIn the proposed generator, the attack network is composed of convolution layer,\nconvolution transpose layer and linear layer. Then we present the training\nstrategy and the details of the training algorithm. Subsequently, we propose\nthe validation strategy to evaluate the performance of the generator.\nSimulations are conducted and the results show that our proposed adversarial\nattack generator achieve better block error rate attack performance than that\nof benchmark schemes over Additive White Gaussian Noise (AWGN) channel,\nRayleigh channel and High-Speed Railway channel.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-01T08:31:54Z"}
{"aid":"http://arxiv.org/abs/2505.00397v1","title":"Relativistic orbital-free kinetic energy density functional for\n  one-particle nuclear systems","summary":"This letter aims to derive the exact relativistic orbital-free kinetic energy\ndensity functional for one-particle nuclear systems in one-dimensional case.\n  The kinetic energy is expressed as a functional of both vector and scalar\ndensities.\n  The functional derivatives of the kinetic energy density functional are also\nderived.\n  Both the kinetic energy density functional and its functional derivatives are\nvalidated to be correct.\n  This serves as a foundation for further exploration of more general\nrelativistic orbital-free kinetic energy density functionals.","main_category":"nucl-th","categories":"nucl-th,quant-ph","published":"2025-05-01T08:37:39Z"}
{"aid":"http://arxiv.org/abs/2505.00400v1","title":"Holistic Optimization of Modular Robots","summary":"Modular robots have the potential to revolutionize automation as one can\noptimize their composition for any given task. However, finding optimal\ncompositions is non-trivial. In addition, different compositions require\ndifferent base positions and trajectories to fully use the potential of modular\nrobots. We address this problem holistically for the first time by jointly\noptimizing the composition, base placement, and trajectory, to minimize the\ncycle time of a given task. Our approach is evaluated on over 300 industrial\nbenchmarks requiring point-to-point movements. Overall, we reduce cycle time by\nup to 25% and find feasible solutions in twice as many benchmarks compared to\noptimizing the module composition alone. In the first real-world validation of\nmodular robots optimized for point-to-point movement, we find that the\noptimized robot is successfully deployed in nine out of ten cases in less than\nan hour.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T08:43:58Z"}
{"aid":"http://arxiv.org/abs/2505.00403v1","title":"Characterizing the dissolution states of a fluorescent probe within a\n  lipid bilayer using molec ular dynamics simulations","summary":"The physicochemical properties of lipid bilayers (membranes) are closely\nassociated with various cellular functions and are often evaluated using\nabsorption and fluorescence spectroscopies. For instance, by employing\nfluorescent probes that exhibit spectra reflective of the surrounding membrane\nenvironment, one can estimate the membrane polarity. Thus, elucidating how such\nprobes are dissolved within the membranes would be beneficial for enabling a\ndeeper interpretation of the spectra. Here, we apply molecular dynamics (MD)\nsimulation with an enhanced sampling method to investigate the dissolution\nstate of 6-propionyl-2-dimethylaminonaphthalene (Prodan) within a membrane\ncomposed of 1,2-dioleoyl-\\textit{sn}-glycero-3-phosphocholine (DOPC), as well\nas its variation upon the addition of ethanol as a cosolvent to the aqueous\nphase. In the absence of ethanol, it is found that the bulky moieties of Prodan\n(propionyl and dimethylamine groups) prefer to be oriented toward the membrane\ncenter owing to the voids existing near the center. The structural change in\nthe membrane induced by the addition of ethanol causes a reduction in the void\npopulation near the center, resulting in a diminished orientation preference of\nProdan.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-05-01T08:52:10Z"}
{"aid":"http://arxiv.org/abs/2505.00406v1","title":"Quantum Littlewood correspondences","summary":"In the 1940s Littlewood formulated three fundamental correspondences for the\nimmanants and Schur symmetric functions on the general linear group, which\nestablish deep connections between representation theory of the symmetric group\nand the general linear group parallel to the Schur-Weyl duality. In this paper,\nwe introduce the notion of quantum immanants in the quantum coordinate algebra\nusing primitive idempotents of the Hecke algebra. By employing $R$-matrix\ntechniques, we establish the quantum analog of Littlewood correspondences\nbetween quantum immanants and Schur functions for the quantum coordinate\nalgebra. In the setting of the Schur-Weyl-Jimbo duality, we construct an exact\ncorrespondence between the Gelfand-Tsetlin bases of the irreducible\nrepresentations of the quantum enveloping algebra $U_q(\\mathfrak{gl}(n))$ and\nYoung's orthonormal basis of an irreducible representation of the Hecke algebra\n$\\mathcal H_m$. This isomorphism leads to our trace formula for the quantum\nimmanants, which settled the generalization problem\n  of $q$-analog of Kostant's formular for $\\lambda$-immanants. As applications,\nwe also derive general $q$-Littlewood-Merris-Watkins identities and\n$q$-Goulden-Jackson identities as special cases of the quantum Littlewood\ncorrespondence III.","main_category":"math.RT","categories":"math.RT,math.CO,math.QA","published":"2025-05-01T08:56:33Z"}
{"aid":"http://arxiv.org/abs/2505.00411v1","title":"Affine matrix scrambling achieves smoothness-dependent convergence rates","summary":"We study the convergence rate of the median estimator for affine matrix\nscrambled digital nets applied to integrands over the unit hypercube $[0,\n1]^s$. By taking the median of $(2r-1)$ independent randomized quasi-Monte\nCarlo (RQMC) samples, we demonstrate that the desired convergence rates can be\nachieved without increasing the number of randomizations $r$ as the quadrature\nsize $N$ grows for both bounded and unbounded integrands. For unbounded\nintegrands, our analysis assumes a boundary growth condition on the weak\nderivatives and also considers singularities such as kinks and jump\ndiscontinuities. Notably, when $r = 1$, the median estimator reduces to the\nstandard RQMC estimator. By applying analytical techniques developed for median\nestimators, we prove that the affine matrix scrambled estimator achieves a\nconvergence rate depending on the integrand's smoothness, and is therefore not\nlimited by the canonical rate $\\mathcal{O}(N^{-3/2})$. However, this\nsmoothness-dependent theoretical rate is not observed empirically in numerical\nexperiments when the affine matrix scrambling yields a heavy-tailed sampling\ndistribution. In contrast, the median estimator consistently reveals the\ntheoretical rates and yields smaller integration errors than mean estimators,\nfurther highlighting its advantages.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-01T09:09:58Z"}
{"aid":"http://arxiv.org/abs/2505.00414v1","title":"Ladders and Squares","summary":"In 1984, Ditor asked two questions: (1) For each $n\\in\\omega$ and infinite\ncardinal $\\kappa$, is there a join-semilattice of breadth $n+1$ and cardinality\n$\\kappa^{+n}$ whose principal ideals have cardinality $< \\kappa$? (2) For each\n$n \\in \\omega$, is there a lower-finite lattice of cardinality $\\aleph_{n}$\nwhose elements have at most $n+1$ lower covers? We show that both questions\nhave positive answers under the axiom of constructibility, and hence\nconsistently with $\\mathsf{ZFC}$. More specifically, we derive the positive\nanswers from assuming that $\\square_\\kappa$ holds for enough $\\kappa$'s.","main_category":"math.LO","categories":"math.LO,math.CO","published":"2025-05-01T09:24:41Z"}
{"aid":"http://arxiv.org/abs/2505.00425v1","title":"A census of face-transitive surfaces","summary":"A face-transitive surface is a triangulated 2-dimensional manifold whose\nautomorphism group acts transitively on its set of triangles. In this paper, we\ninvestigate this class of highly symmetric surface triangulations. We identify\nseven types of such face-transitive surfaces, splitting up further into a total\nof thirteen sub-types, distinguished by how their automorphism groups act on\nthem. We use these theoretical results to compute a census of face-transitive\nsurfaces with up to 1280 faces by constructing suitable cycle double covers of\ncubic node-transitive graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-05-01T09:52:10Z"}
{"aid":"http://arxiv.org/abs/2505.00429v1","title":"On the structure of big bang singularities in spatially homogenous\n  solutions to the Einstein non-linear scalar field equations","summary":"The subject of this article is the structure of big bang singularities in\nspatially homogeneous solutions to the Einstein non-linear scalar field\nequations. In particular, we focus on Bianchi class A; i.e., developments\narising from left invariant initial data on unimodular $3$-dimensional Lie\ngroups. We prove that solutions are either vacuum or matter dominated,\ndepending on whether the limit of an expansion normalised normal derivative of\nthe scalar field is zero or not, respectively. The main result concerning the\nasymptotics in the direction of the singularity is, essentially, that solutions\ninduce data on the singularity, with two exceptions: vacuum dominated Bianchi\ntype VIII and IX without additional symmetries (they are neither isotropic nor\nlocally rotationally symmetric) exhibit BKL-type oscillations. Disregarding the\nexceptions, there is in fact a bijection between initial data on the\nsingularity and developments. Initial data on the singularity thus play a\ncentral role in the analysis; they both parameterise developments and give\noptimal asymptotic information. However, the main point of the article is to\nprove that the set of isometry classes of initial data on the singularity (of a\nfixed Bianchi type and symmetry (such as isotropy, local rotational symmetry\netc.)) has a smooth structure; that the set of isometry classes of developments\n(similarly restricted) has a smooth structure which fits together with the\nnatural smooth structure of isometry classes of regular initial data with fixed\nmean curvature; and that the Einstein flow generates a diffeomorphism between\nthe two sets. However, the article contains substantial additional information,\nsuch as, e.g., the construction of a large class of spatially locally\nhomogeneous solutions that can be demonstrated to be globally non-linearly\nstable (in the absence of symmetries) both to the future and to the past.","main_category":"gr-qc","categories":"gr-qc,math-ph,math.MP","published":"2025-05-01T09:58:07Z"}
{"aid":"http://arxiv.org/abs/2505.00430v1","title":"Over-the-Air Inference over Multi-hop MIMO Networks","summary":"A novel over-the-air machine learning framework over multi-hop multiple-input\nand multiple-output (MIMO) networks is proposed. The core idea is to imitate\nfully connected (FC) neural network layers using multiple MIMO channels by\ncarefully designing the precoding matrices at the transmitting nodes. A neural\nnetwork dubbed PrototypeNet is employed consisting of multiple FC layers, with\nthe number of neurons of each layer equal to the number of antennas of the\ncorresponding terminal. To achieve satisfactory performance, we train\nPrototypeNet based on a customized loss function consisting of classification\nerror and the power of latent vectors to satisfy transmit power constraints,\nwith noise injection during training. Precoding matrices for each hop are then\nobtained by solving an optimization problem. We also propose a multiple-block\nextension when the number of antennas is limited. Numerical results verify that\nthe proposed over-the-air transmission scheme can achieve satisfactory\nclassification accuracy under a power constraint. The results also show that\nhigher classification accuracy can be achieved with an increasing number of\nhops at a modest signal-to-noise ratio (SNR).","main_category":"eess.SP","categories":"eess.SP,cs.LG","published":"2025-05-01T09:59:32Z"}
{"aid":"http://arxiv.org/abs/2505.00434v1","title":"Stability of the first-order unified gas-kinetic scheme based on a\n  linear kinetic model","summary":"The unified gas-kinetic scheme (UGKS) is becoming increasingly popular for\nmultiscale simulations in all flow regimes. This paper provides the first\nanalytical study on the stability of the UGKS applied to a linear kinetic\nmodel, which is able to reproduce the one-dimensional linear scalar\nadvection-diffusion equation via the Chapman-Enskog expansion method. Adopting\nperiodic boundary conditions and neglecting the error from numerical\nintegration, this paper rigorously proves the weighted $L^2$-stability of the\nfirst-order UGKS under the Courant-Friedrichs-Lewy (CFL) conditions. It is\nshown that the time step of the method is not constrained by being less than\nthe particle collision time, nor is it limited by parabolic type CFL conditions\ntypically applied in solving diffusion equations. The novelty of the proof lies\nin that based on the ratio of the time step to the particle collision time, the\nupdate of distribution functions is viewed as a convex combinations of\nsub-methods related to various physics processes, such as the particle free\ntransport and collisions. The weighted $L^2$-stability of the sub-methods is\nobtained by considering them as discretizations to corresponding linear\nhyperbolic systems and utilizing the associated Riemann invariants. Finally,\nthe strong stability preserving property of the UGKS leads to the desired\nweighted $L^2$-stability.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-01T10:12:07Z"}
{"aid":"http://arxiv.org/abs/2505.00447v1","title":"Deterministic Scheduling over Wi-Fi 6 using Target Wake Time: An\n  Experimental Approach","summary":"Wi-Fi networks traditionally use Distributed Coordination Function (DCF) that\nemploys CSMA/CA along with the binary backoff mechanism for channel access.\nThis causes unavoidable contention overheads and does not provide performance\nguarantees. In this work, we outline some issues that occur with the\nprobabilistic channel access in highly congested scenarios and how those can be\nmitigated using deterministic scheduling. Towards this, we propose to use\nTarget Wake Time (TWT) - a feature introduced in Wi-Fi 6 as a power-saving\nmechanism, to improve the performance of Wi-Fi. To gain insights into the\nworkings of the TWT over commercially available off-the-shelf components and to\nanalyze the factors that affect its performance, we carry out various\nexperiments with it over our Wi-Fi 6 testbed. Using these insights and\nanalysis, we formulate and solve an optimization problem to synthesize\ndeterministic schedules and obtain the optimal values of various system\nparameters. Lastly, we configure our testbed with these optimal parameter\nvalues and show that the TWT based deterministic scheduling consistently\nresults in better performance of the TWT-capable clients and overall system\nperformance compared to traditional CSMA/CA based scheduling.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-01T10:43:01Z"}
{"aid":"http://arxiv.org/abs/2505.00448v1","title":"NApy: Efficient Statistics in Python for Large-Scale Heterogeneous Data\n  with Enhanced Support for Missing Data","summary":"Existing Python libraries and tools lack the ability to efficiently compute\nstatistical test results for large datasets in the presence of missing values.\nThis presents an issue as soon as constraints on runtime and memory\navailability become essential considerations for a particular usecase. Relevant\nresearch areas where such limitations arise include interactive tools and\ndatabases for exploratory analysis of biomedical data. To address this problem,\nwe present the Python package NApy, which relies on a Numba and C++ backend\nwith OpenMP parallelization to enable scalable statistical testing for\nmixed-type datasets in the presence of missing values. Both with respect to\nruntime and memory consumption, NApy outperforms competitor tools and baseline\nimplementations with naive Python-based parallelization by orders of magnitude,\nthereby enabling on-the-fly analyses in interactive applications. NApy is\npublicly available at https://github.com/DyHealthNet/NApy.","main_category":"cs.MS","categories":"cs.MS,cs.DC,cs.PF","published":"2025-05-01T10:45:37Z"}
{"aid":"http://arxiv.org/abs/2505.00473v1","title":"Interpretable Spatial-Temporal Fusion Transformers: Multi-Output\n  Prediction for Parametric Dynamical Systems with Time-Varying Inputs","summary":"We explore the promising performance of a transformer model in predicting\noutputs of parametric dynamical systems with external time-varying input\nsignals. The outputs of such systems vary not only with physical parameters but\nalso with external time-varying input signals. Accurately catching the dynamics\nof such systems is challenging. We have adapted and extended an existing\ntransformer model for single output prediction to a multiple-output transformer\nthat is able to predict multiple output responses of these systems. The\nmultiple-output transformer generalizes the interpretability of the original\ntransformer. The generalized interpretable attention weight matrix explores not\nonly the temporal correlations in the sequence, but also the interactions\nbetween the multiple outputs, providing explanation for the spatial correlation\nin the output domain. This multiple-output transformer accurately predicts the\nsequence of multiple outputs, regardless of the nonlinearity of the system and\nthe dimensionality of the parameter space.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-05-01T11:55:42Z"}
{"aid":"http://arxiv.org/abs/2505.00480v1","title":"Decentralized Vulnerability Disclosure via Permissioned Blockchain: A\n  Secure, Transparent Alternative to Centralized CVE Management","summary":"This paper proposes a decentralized, blockchain-based system for the\npublication of Common Vulnerabilities and Exposures (CVEs), aiming to mitigate\nthe limitations of the current centralized model primarily overseen by MITRE.\nThe proposed architecture leverages a permissioned blockchain, wherein only\nauthenticated CVE Numbering Authorities (CNAs) are authorized to submit\nentries. This ensures controlled write access while preserving public\ntransparency. By incorporating smart contracts, the system supports key\nfeatures such as embargoed disclosures and decentralized governance. We\nevaluate the proposed model in comparison with existing practices, highlighting\nits advantages in transparency, trust decentralization, and auditability. A\nprototype implementation using Hyperledger Fabric is presented to demonstrate\nthe feasibility of the approach, along with a discussion of its implications\nfor the future of vulnerability disclosure.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-01T12:12:08Z"}
{"aid":"http://arxiv.org/abs/2505.00503v1","title":"Variational OOD State Correction for Offline Reinforcement Learning","summary":"The performance of Offline reinforcement learning is significantly impacted\nby the issue of state distributional shift, and out-of-distribution (OOD) state\ncorrection is a popular approach to address this problem. In this paper, we\npropose a novel method named Density-Aware Safety Perception (DASP) for OOD\nstate correction. Specifically, our method encourages the agent to prioritize\nactions that lead to outcomes with higher data density, thereby promoting its\noperation within or the return to in-distribution (safe) regions. To achieve\nthis, we optimize the objective within a variational framework that\nconcurrently considers both the potential outcomes of decision-making and their\ndensity, thus providing crucial contextual information for safe\ndecision-making. Finally, we validate the effectiveness and feasibility of our\nproposed method through extensive experimental evaluations on the offline\nMuJoCo and AntMaze suites.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.RO","published":"2025-05-01T13:14:07Z"}
{"aid":"http://arxiv.org/abs/2505.00504v1","title":"Equating three degrees of graphs","summary":"In this paper, we prove that, for every graph with at least 5 vertices, one\ncan delete at most 3 vertices such that the subgraph obtained has at least\nthree vertices with the same degree. This solves an open problem of Caro,\nShapira and Yuster [Electron. J. Combin. 21 (2014) P1.24].","main_category":"math.CO","categories":"math.CO","published":"2025-05-01T13:21:15Z"}
{"aid":"http://arxiv.org/abs/2505.00515v1","title":"Safety-Critical Traffic Simulation with Guided Latent Diffusion Model","summary":"Safety-critical traffic simulation plays a crucial role in evaluating\nautonomous driving systems under rare and challenging scenarios. However,\nexisting approaches often generate unrealistic scenarios due to insufficient\nconsideration of physical plausibility and suffer from low generation\nefficiency. To address these limitations, we propose a guided latent diffusion\nmodel (LDM) capable of generating physically realistic and adversarial\nsafety-critical traffic scenarios. Specifically, our model employs a\ngraph-based variational autoencoder (VAE) to learn a compact latent space that\ncaptures complex multi-agent interactions while improving computational\nefficiency. Within this latent space, the diffusion model performs the\ndenoising process to produce realistic trajectories. To enable controllable and\nadversarial scenario generation, we introduce novel guidance objectives that\ndrive the diffusion process toward producing adversarial and behaviorally\nrealistic driving behaviors. Furthermore, we develop a sample selection module\nbased on physical feasibility checks to further enhance the physical\nplausibility of the generated scenarios. Extensive experiments on the nuScenes\ndataset demonstrate that our method achieves superior adversarial effectiveness\nand generation efficiency compared to existing baselines while maintaining a\nhigh level of realism. Our work provides an effective tool for realistic\nsafety-critical scenario simulation, paving the way for more robust evaluation\nof autonomous driving systems.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.MA","published":"2025-05-01T13:33:34Z"}
{"aid":"http://arxiv.org/abs/2505.00536v1","title":"Ground Orthogonal Arrays and Their Applications","summary":"In computer experiments, it has become a standard practice to select the\ninputs that spread out as uniformly as possible over the design space. The\nresulting designs are called space-filling designs and they are undoubtedly\ndesirable choices when there is no prior knowledge on how the input variables\naffect the response and the objective of experiments is global fitting. When\nthere is some prior knowledge on the underlying true function of the system or\nwhat statistical models are more appropriate, a natural question is, are there\nmore suitable designs than vanilla space-filling designs? In this article, we\nprovide an answer for the cases where there are no interactions between the\nfactors from disjoint groups of variables. In other words, we consider the\ndesign issue when the underlying functional form of the system or the\nstatistical model to be used is additive where each component depends on one\ngroup of variables from a set of disjoint groups. For such cases, we recommend\nusing {\\em grouped orthogonal arrays.} Several construction methods are\nprovided and many designs are tabulated for practical use. Compared with\nexisting techniques in the literature, our construction methods can generate\nmany more designs with flexible run sizes and better within-group projection\nproperties for any prime power number of levels.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-01T14:02:35Z"}
{"aid":"http://arxiv.org/abs/2505.00539v1","title":"Unified QMF equation of state for neutron star matter: Static and\n  dynamic properties","summary":"We construct a set of unified equations of state based on the quark mean\nfield (QMF) model, calibrated to different values of nuclear symmetry energy\nslope at the saturation density ($L_0$), with the aim of exploring both the\nstatic properties and dynamical behavior of neutron stars (NSs), and building a\ncoherent picture of their internal structure. We assess the performance of\nthese QMF models in describing the mass-radius relation, the cooling evolution\nof isolated NSs and X-ray transients, and the instabilities (e.g., the r-mode).\nIn comparison to relativistic mean field (RMF) models formulated at the\nhadronic level, the QMF model predicts heavier nuclear clusters and larger\nWigner-Seitz cell sizes in the NS crust, while the density of the free neutron\ngas remains largely similar between the two approaches. For the cooling of\nisolated NSs, the thermal evolution is found to be insensitive to both the\nmany-body model and the symmetry energy slope in the absence of the direct Urca\n(dUrca) process. However, when rapid cooling via the dUrca process is allowed,\nin the case of large $L_0$ values (e.g., $L_0 \\gtrsim 80$ MeV) in our study,\nthe QMF model predicts a longer thermal relaxation time. Both the QMF and RMF\nmodels can reproduce cooling curves consistent with observations of X-ray\ntransients (e.g., KS 1731--260) during their crustal cooling phase, although\nstellar parameters show slight variations depending on the model and symmetry\nenergy slope. Within our unified framework, a larger $L_0$ value generally\nresults in a wider instability window, while increasing the stellar mass tends\nto suppress the instability window. We also provide simple power-law\nparameterizations that quantify the dependence of bulk and shear viscosities on\nthe symmetry energy slope for nuclear matter at saturation density.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-05-01T14:05:15Z"}
{"aid":"http://arxiv.org/abs/2505.00543v1","title":"Two-Qubit Gate Synthesis via Linear Programming for Heterogeneous\n  Instruction Sets","summary":"We present GULPS (Global Unitary Linear Programming Synthesis), a segmented\nCartan trajectory method that compiles arbitrary two-qubit unitaries into\nnative gate sets by decomposing the synthesis problem into locally solvable\nsub-problems. Each segment corresponds to a depth-2 circuit synthesized from a\nlinear program over canonical gate invariants, subject to quantum\nLittlewood-Richardson (QLR) constraints. The intermediate invariants are\nstitched together via nonlinear least-squares optimization to recover the local\noperations between segments. This hybrid LP-numerical method enables robust\nsynthesis across parameterized instruction sets. As quantum hardware continues\nto evolve, GULPS provides a scalable, ISA-aware compilation strategy suitable\nfor integration into platforms like Qiskit.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T14:13:13Z"}
{"aid":"http://arxiv.org/abs/2505.00549v1","title":"Sum Rate Maximization for NOMA-Assisted Uplink Pinching-Antenna Systems","summary":"In this paper, we investigate an uplink communication scenario in which\nmultiple users communicate with an access point (AP) employing non-orthogonal\nmultiple access (NOMA). A pinching antenna, which can be activated at an\narbitrary point along a dielectric waveguide, is deployed at the AP to\ndynamically reconfigure user channels. The objective is to maximize the system\nsum rate by jointly optimizing the pinching-antenna's position and the users'\ntransmit powers. The formulated optimization problem is non-convex, and\naddressed using the particle swarm optimization (PSO) algorithm. For\nperformance benchmarking, two time division multiple access (TDMA) schemes are\nconsidered: one based on the pinching antenna individually activated for each\nuser, and the other based on the single-pinching-antenna configuration serving\nall users. Numerical results demonstrate that the use of the pinching antenna\nsignificantly enhances the system sum rate compared to conventional antenna\narchitectures. Moreover, the NOMA-based scheme outperforms the TDMA-based\nscheme with a single pinching antenna but is outperformed by the TDMA-based\napproach when the pinching antenna is adaptively configured for each user.\nFinally, the proposed PSO-based method is shown to achieve near-optimal\nperformance for both NOMA and TDMA with a common pinching-antenna\nconfiguration.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-05-01T14:27:02Z"}
{"aid":"http://arxiv.org/abs/2505.00552v1","title":"Graph Spectral Filtering with Chebyshev Interpolation for Recommendation","summary":"Graph convolutional networks have recently gained prominence in collaborative\nfiltering (CF) for recommendations. However, we identify potential bottlenecks\nin two foundational components. First, the embedding layer leads to a latent\nspace with limited capacity, overlooking locally observed but potentially\nvaluable preference patterns. Also, the widely-used neighborhood aggregation is\nlimited in its ability to leverage diverse preference patterns in a\nfine-grained manner. Building on spectral graph theory, we reveal that these\nlimitations stem from graph filtering with a cut-off in the frequency spectrum\nand a restricted linear form. To address these issues, we introduce ChebyCF, a\nCF framework based on graph spectral filtering. Instead of a learned embedding,\nit takes a user's raw interaction history to utilize the full spectrum of\nsignals contained in it. Also, it adopts Chebyshev interpolation to effectively\napproximate a flexible non-linear graph filter, and further enhances it by\nusing an additional ideal pass filter and degree-based normalization. Through\nextensive experiments, we verify that ChebyCF overcomes the aforementioned\nbottlenecks and achieves state-of-the-art performance across multiple\nbenchmarks and reasonably fast inference. Our code is available at\nhttps://github.com/chanwoo0806/ChebyCF.","main_category":"cs.IR","categories":"cs.IR,cs.LG","published":"2025-05-01T14:28:44Z"}
{"aid":"http://arxiv.org/abs/2505.00555v1","title":"On the Mechanistic Interpretability of Neural Networks for Causality in\n  Bio-statistics","summary":"Interpretable insights from predictive models remain critical in\nbio-statistics, particularly when assessing causality, where classical\nstatistical and machine learning methods often provide inherent clarity. While\nNeural Networks (NNs) offer powerful capabilities for modeling complex\nbiological data, their traditional \"black-box\" nature presents challenges for\nvalidation and trust in high-stakes health applications. Recent advances in\nMechanistic Interpretability (MI) aim to decipher the internal computations\nlearned by these networks. This work investigates the application of MI\ntechniques to NNs within the context of causal inference for bio-statistics.\n  We demonstrate that MI tools can be leveraged to: (1) probe and validate the\ninternal representations learned by NNs, such as those estimating nuisance\nfunctions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)\ndiscover and visualize the distinct computational pathways employed by the\nnetwork to process different types of inputs, potentially revealing how\nconfounders and treatments are handled; and (3) provide methodologies for\ncomparing the learned mechanisms and extracted insights across statistical,\nmachine learning, and NN models, fostering a deeper understanding of their\nrespective strengths and weaknesses for causal bio-statistical analysis.","main_category":"stat.AP","categories":"stat.AP,cs.AI","published":"2025-05-01T14:30:34Z"}
{"aid":"http://arxiv.org/abs/2505.00560v1","title":"Efficient Recommendation with Millions of Items by Dynamic Pruning of\n  Sub-Item Embeddings","summary":"A large item catalogue is a major challenge for deploying modern sequential\nrecommender models, since it makes the memory footprint of the model large and\nincreases inference latency. One promising approach to address this is RecJPQ,\nwhich replaces item embeddings with sub-item embeddings. However, slow\ninference remains problematic because finding the top highest-scored items\nusually requires scoring all items in the catalogue, which may not be feasible\nfor large catalogues. By adapting dynamic pruning concepts from document\nretrieval, we propose the RecJPQPrune dynamic pruning algorithm to efficiently\nfind the top highest-scored items without computing the scores of all items in\nthe catalogue. Our RecJPQPrune algorithm is safe-up-to-rank K since it\ntheoretically guarantees that no potentially high-scored item is excluded from\nthe final top K recommendation list, thereby ensuring no impact on\neffectiveness. Our experiments on two large datasets and three recommendation\nmodels demonstrate the efficiency achievable using RecJPQPrune: for instance,\non the Tmall dataset with 2.2M items, we can reduce the median model scoring\ntime by 64 times compared to the Transformer Default baseline, and 5.3 times\ncompared to a recent scoring approach called PQTopK. Overall, this paper\ndemonstrates the effective and efficient inference of Transformer-based\nrecommendation models at catalogue scales not previously reported in the\nliterature. Indeed, our RecJPQPrune algorithm can score 2 million items in\nunder 10 milliseconds without GPUs, and without relying on Approximate Nearest\nNeighbour (ANN) techniques.","main_category":"cs.IR","categories":"cs.IR","published":"2025-05-01T14:36:33Z"}
{"aid":"http://arxiv.org/abs/2505.00561v1","title":"Learning to Learn with Quantum Optimization via Quantum Neural Networks","summary":"Quantum Approximate Optimization Algorithms (QAOA) promise efficient\nsolutions to classically intractable combinatorial optimization problems by\nharnessing shallow-depth quantum circuits. Yet, their performance and\nscalability often hinge on effective parameter optimization, which remains\nnontrivial due to rugged energy landscapes and hardware noise. In this work, we\nintroduce a quantum meta-learning framework that combines quantum neural\nnetworks, specifically Quantum Long Short-Term Memory (QLSTM) architectures,\nwith QAOA. By training the QLSTM optimizer on smaller graph instances, our\napproach rapidly generalizes to larger, more complex problems, substantially\nreducing the number of iterations required for convergence. Through\ncomprehensive benchmarks on Max-Cut and Sherrington-Kirkpatrick model\ninstances, we demonstrate that QLSTM-based optimizers converge faster and\nachieve higher approximation ratios compared to classical baselines, thereby\noffering a robust pathway toward scalable quantum optimization in the NISQ era.","main_category":"quant-ph","categories":"quant-ph,cs.AI","published":"2025-05-01T14:39:26Z"}
{"aid":"http://arxiv.org/abs/2505.00571v1","title":"Hypothesis-free discovery from epidemiological data by automatic\n  detection and local inference for tree-based nonlinearities and interactions","summary":"In epidemiological settings, Machine Learning (ML) is gaining popularity for\nhypothesis-free discovery of risk (or protective) factors. Although ML is\nstrong at discovering non-linearities and interactions, this power is currently\ncompromised by a lack of reliable inference. Although local measures of feature\neffect can be combined with tree ensembles, uncertainty quantifications for\nthese measures remain only partially available and oftentimes unsatisfactory.\nWe propose RuleSHAP, a framework for using rule-based, hypothesis-free\ndiscovery that combines sparse Bayesian regression, tree ensembles and Shapley\nvalues in a one-step procedure that both detects and tests complex patterns at\nthe individual level. To ease computation, we derive a formula that computes\nmarginal Shapley values more efficiently for our setting. We demonstrate the\nvalidity of our framework on simulated data. To illustrate, we apply our\nmachinery to data from an epidemiological cohort to detect and infer several\neffects for high cholesterol and blood pressure, such as nonlinear interaction\neffects between features like age, sex, ethnicity, BMI and glucose level.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-05-01T14:55:22Z"}
{"aid":"http://arxiv.org/abs/2505.00572v1","title":"A Bioinformatic Study of Genetics Involved in Determining Mild Traumatic\n  Brain Injury Severity and Recovery","summary":"Aim: This in silico study sought to identify specific biomarkers for mild\ntraumatic brain injury (mTBI) through the analysis of publicly available gene\nand miRNA databases, hypothesizing their influence on neuronal structure,\naxonal integrity, and regeneration. Methods: This study implemented a\nthree-step process: (1) Data searching for mTBI-related genes in Gene and\nMalaCard databases and literature review ; (2) Data analysis involved\nperforming functional annotation through GO and KEGG, identifying hub genes\nusing Cytoscape, mapping protein-protein interactions via DAVID and STRING, and\npredicting miRNA targets using miRSystem, miRWalk2.0, and mirDIP (3)\nRNA-sequencing analysis applied to the mTBI dataset GSE123336. Results: Eleven\ncandidate hub genes associated with mTBI outcome were identified: APOE, S100B,\nGFAP, BDNF, AQP4, COMT, MBP, UCHL1, DRD2, ASIC1, and CACNA1A. Enrichment\nanalysis linked these genes to neuron projection regeneration and synaptic\nplasticity. miRNAs linked to the mTBI candidate genes were hsa-miR-9-5p,\nhsa-miR-204-5p, hsa-miR-1908-5p, hsa-miR-16-5p, hsa-miR-10a-5p, has-miR-218-5p,\nhas-miR-34a-5p, and has-miR-199b-5p. The RNA sequencing revealed 2664\ndifferentially expressed miRNAs post-mTBI, with 17 showing significant changes\nat the time of injury and 48 hours post-injury. Two miRNAs were positively\ncorrelated with direct head hits. Conclusion: Our study indicates that specific\ngenes and miRNAs, particularly hsa-miR-10a-5p, may influence mTBI outcomes. Our\nresearch may guide future mTBI diagnostics, emphasizing the need to measure and\ntrack these specific genes and miRNAs in diverse cohorts.","main_category":"q-bio.GN","categories":"q-bio.GN,q-bio.NC","published":"2025-05-01T14:56:46Z"}
{"aid":"http://arxiv.org/abs/2505.00575v1","title":"Unveiling competitions between carrier recombination pathways in\n  semiconductors via mechanical damping","summary":"The total rate of carrier recombination in semiconductors has conventionally\nbeen expressed using an additive model, r_total = \\Sigma r_i , which rules out\nthe interactions between carrier recombination pathways. Here we challenge this\nparadigm by demonstrating pathway competitions using our newly developed\nlight-induced mechanical absorption spectroscopy (LIMAS), which allows us to\nprobe genuine recombination dynamics in semiconductors via mechanical damping.\nWe show that the total recombination rate in zinc sulfide (ZnS), a model\nsemiconductor material, follows a multiplicative weighting model, r_total\n\\propto \\Pi r_i ^(w_i) with \\Sigma w_i=1. Under both steady-state and switch-on\nilluminations, the weighting factors w_i for each recombination pathway-direct,\ntrap-assisted, and sublinear-are dictated by the carrier generation mechanism:\n(i) interband transition favors direct recombination; (ii) single-defect\nlevel-mediated generation promotes trap-assisted recombination; (iii)\ngeneration involving multiple saturated defect levels gives rise to sublinear\nrecombination. Upon light switch-off, localized state changes drive a dynamic\nevolution of w_i, altering pathway competitions. These findings reshape our\nfundamental understanding of carrier dynamics and provide a new strategy to\noptimize next-generation optoelectronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-01T15:01:38Z"}
{"aid":"http://arxiv.org/abs/2505.00576v1","title":"Narrow Inhomogeneous Distribution and Charge State Stabilization of\n  Lead-Vacancy Centers in Diamond","summary":"Lead-vacancy (PbV) centers in diamond with a large ground state splitting are\nexpected to be a building block of quantum network nodes. Due to the heaviness\nof the Pb atom, it is challenging to fabricate high-quality PbV centers with a\nnarrow inhomogeneous distribution and stable charge state. In this study, for\nthe formation of the PbV centers, high temperature anneal up to 2300{\\deg}C is\nperformed after Pb ion implantation. At a lower temperature of 1800{\\deg}C, the\nPbV centers show a large inhomogeneous distribution and spectral diffusion,\nwhile higher temperatures of 2200-2300{\\deg}C leads to narrow inhomogeneous\ndistributions with standard deviations of ~5 GHz. The charge state transition\nof the PbV centers formed at 2200{\\deg}C occurs by capturing photo-carriers\ngenerated from surrounding defects under 532 nm laser irradiation. Finally,\nmultiple stable PbV centers with nearly identical photon frequencies are\nobtained, which is essential for applications in quantum information\nprocessing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T15:02:10Z"}
{"aid":"http://arxiv.org/abs/2505.00578v1","title":"AI-Driven High-Resolution Cell Segmentation and Quantitative Analysis","summary":"Studying the growth and metabolism of microbes provides critical insights\ninto their evolutionary adaptations to harsh environments, which are essential\nfor microbial research and biotechnology applications. In this study, we\ndeveloped an AI-driven image analysis system to efficiently segment individual\ncells and quantitatively analyze key cellular features. This system is\ncomprised of four main modules. First, a denoising algorithm enhances contrast\nand suppresses noise while preserving fine cellular details. Second, the\nSegment Anything Model (SAM) enables accurate, zero-shot segmentation of cells\nwithout additional training. Third, post-processing is applied to refine\nsegmentation results by removing over-segmented masks. Finally, quantitative\nanalysis algorithms extract essential cellular features, including average\nintensity, length, width, and volume. The results show that denoising and\npost-processing significantly improved the segmentation accuracy of SAM in this\nnew domain. Without human annotations, the AI-driven pipeline automatically and\nefficiently outlines cellular boundaries, indexes them, and calculates key\ncellular parameters with high accuracy. This framework will enable efficient\nand automated quantitative analysis of high-resolution fluorescence microscopy\nimages to advance research into microbial adaptations to grow and metabolism\nthat allow extremophiles to thrive in their harsh habitats.","main_category":"eess.IV","categories":"eess.IV,q-bio.QM","published":"2025-05-01T15:09:03Z"}
{"aid":"http://arxiv.org/abs/2505.00591v1","title":"Explainable AI in Spatial Analysis","summary":"This chapter discusses the opportunities of eXplainable Artificial\nIntelligence (XAI) within the realm of spatial analysis. A key objective in\nspatial analysis is to model spatial relationships and infer spatial processes\nto generate knowledge from spatial data, which has been largely based on\nspatial statistical methods. More recently, machine learning offers scalable\nand flexible approaches that complement traditional methods and has been\nincreasingly applied in spatial data science. Despite its advantages, machine\nlearning is often criticized for being a black box, which limits our\nunderstanding of model behavior and output. Recognizing this limitation, XAI\nhas emerged as a pivotal field in AI that provides methods to explain the\noutput of machine learning models to enhance transparency and understanding.\nThese methods are crucial for model diagnosis, bias detection, and ensuring the\nreliability of results obtained from machine learning models. This chapter\nintroduces key concepts and methods in XAI with a focus on Shapley value-based\napproaches, which is arguably the most popular XAI method, and their\nintegration with spatial analysis. An empirical example of county-level voting\nbehaviors in the 2020 Presidential election is presented to demonstrate the use\nof Shapley values and spatial analysis with a comparison to multi-scale\ngeographically weighted regression. The chapter concludes with a discussion on\nthe challenges and limitations of current XAI techniques and proposes new\ndirections.","main_category":"cs.LG","categories":"cs.LG,econ.EM","published":"2025-05-01T15:25:23Z"}
{"aid":"http://arxiv.org/abs/2505.00597v1","title":"Closed-form expressions for the centroid-tilt error due to scintillation","summary":"In adaptive optics, the tracker and wavefront sensor commonly measure\nirradiance centroids (in their respective focal planes) to estimate the\nturbulence-degraded wavefront in the pupil plane. Several factors affect the\naccuracy of these centroid measurements, including noise, speckle, and\nscintillation. The centroid-tilt or ``C-tilt'' errors due to these factors have\nbeen studied by numerous researchers; however, to our knowledge, closed-form\nexpressions for the C-tilt error due to scintillation have not been found.\n  In this paper, we derive such expressions, assuming spherical-wave\nillumination of the pupil, a path-invariant index of refraction structure\nconstant $C_n^2$, and Kolmogorov turbulence. We compare the analytically\npredicted C-tilt values to those obtained by wave-optics simulations. The\nagreement, at large, is quite good over a wide range of conditions. As a\nresult, researchers and engineers will find this analysis useful when\nquantifying the performance of centroid-based trackers and wavefront sensors,\nboth of which are critical adaptive-optics components.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-01T15:30:33Z"}
{"aid":"http://arxiv.org/abs/2505.00599v1","title":"Visual Trajectory Prediction of Vessels for Inland Navigation","summary":"The future of inland navigation increasingly relies on autonomous systems and\nremote operations, emphasizing the need for accurate vessel trajectory\nprediction. This study addresses the challenges of video-based vessel tracking\nand prediction by integrating advanced object detection methods, Kalman\nfilters, and spline-based interpolation. However, existing detection systems\noften misclassify objects in inland waterways due to complex surroundings. A\ncomparative evaluation of tracking algorithms, including BoT-SORT, Deep\nOC-SORT, and ByeTrack, highlights the robustness of the Kalman filter in\nproviding smoothed trajectories. Experimental results from diverse scenarios\ndemonstrate improved accuracy in predicting vessel movements, which is\nessential for collision avoidance and situational awareness. The findings\nunderline the necessity of customized datasets and models for inland\nnavigation. Future work will expand the datasets and incorporate vessel\nclassification to refine predictions, supporting both autonomous systems and\nhuman operators in complex environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T15:31:15Z"}
{"aid":"http://arxiv.org/abs/2505.00601v1","title":"A stochastic epidemic model with memory of the last infection and waning\n  immunity","summary":"We adapt the article of Forien, Pang, Pardoux and Zotsa: Arxiv preprint\nArxiv2210.04667(2022), on epidemic models with varying infectivity and waning\nimmunity, to incorporate the memory of the last infection. To this end, we\nintroduce a parametric approach and consider a piecewise deterministic Markov\nprocess modeling both the evolution of the parameter, also called the trait,\nand the age of infection of individuals over time. At each new infection, a new\ntrait is randomly chosen for the infected individual according to a Markov\nkernel, and their age is reset to zero. In the large population limit, we\nderive a partial differential equation (PDE) that describes the density of\ntraits and ages. The main goal is to study the conditions under which endemic\nequilibria exist for the deterministic PDE model and to establish an endemicity\nthreshold that depends on the model parameters. The local stability of these\nequilibria is also analyzed. The endemicity threshold is computed for several\nexamples, including models that incorporate a vaccination policy, and a local\nstability result is obtained for a memory-free SIS-type model.","main_category":"math.PR","categories":"math.PR,q-bio.PE","published":"2025-05-01T15:32:48Z"}
{"aid":"http://arxiv.org/abs/2505.00610v1","title":"Combining LLMs with Logic-Based Framework to Explain MCTS","summary":"In response to the lack of trust in Artificial Intelligence (AI) for\nsequential planning, we design a Computational Tree Logic-guided large language\nmodel (LLM)-based natural language explanation framework designed for the Monte\nCarlo Tree Search (MCTS) algorithm. MCTS is often considered challenging to\ninterpret due to the complexity of its search trees, but our framework is\nflexible enough to handle a wide range of free-form post-hoc queries and\nknowledge-based inquiries centered around MCTS and the Markov Decision Process\n(MDP) of the application domain. By transforming user queries into logic and\nvariable statements, our framework ensures that the evidence obtained from the\nsearch tree remains factually consistent with the underlying environmental\ndynamics and any constraints in the actual stochastic control process. We\nevaluate the framework rigorously through quantitative assessments, where it\ndemonstrates strong performance in terms of accuracy and factual consistency.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-01T15:40:58Z"}
{"aid":"http://arxiv.org/abs/2505.00622v1","title":"Neural Network Verification for Gliding Drone Control: A Case Study","summary":"As machine learning is increasingly deployed in autonomous systems,\nverification of neural network controllers is becoming an active research\ndomain. Existing tools and annual verification competitions suggest that soon\nthis technology will become effective for real-world applications. Our\napplication comes from the emerging field of microflyers that are passively\ntransported by the wind, which may have various uses in weather or pollution\nmonitoring. Specifically, we investigate centimetre-scale bio-inspired gliding\ndrones that resemble Alsomitra macrocarpa diaspores. In this paper, we propose\na new case study on verifying Alsomitra-inspired drones with neural network\ncontrollers, with the aim of adhering closely to a target trajectory. We show\nthat our system differs substantially from existing VNN and ARCH competition\nbenchmarks, and show that a combination of tools holds promise for verifying\nsuch systems in the future, if certain shortcomings can be overcome. We propose\na novel method for robust training of regression networks, and investigate\nformalisations of this case study in Vehicle and CORA. Our verification results\nsuggest that the investigated training methods do improve performance and\nrobustness of neural network controllers in this application, but are limited\nin scope and usefulness. This is due to systematic limitations of both Vehicle\nand CORA, and the complexity of our system reducing the scale of reachability,\nwhich we investigate in detail. If these limitations can be overcome, it will\nenable engineers to develop safe and robust technologies that improve people's\nlives and reduce our impact on the environment.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.SY,eess.SY","published":"2025-05-01T16:03:38Z"}
{"aid":"http://arxiv.org/abs/2505.00633v1","title":"Strong Rigidity and Elementary Embeddings","summary":"We present a method for producing elementary embeddings from homomorphisms.\nThis method is utilized in the study of the \"strongly rigid relation principle\"\nas defined by Hamkins and Palumbo in their paper \"The Rigid Relation Principle,\na New Weak Choice Principle.\" We establish that the strongly rigid relation\nprinciple is also a weak choice principle that is independent of ZF. Finally,\nwe characterize proto Berkeley cardinals in terms of a strong failure of the\nstrongly rigid relation principle.","main_category":"math.LO","categories":"math.LO","published":"2025-05-01T16:17:49Z"}
{"aid":"http://arxiv.org/abs/2505.00639v1","title":"Probing excited-state dynamics of transmon ionization","summary":"The fidelity and quantum nondemolition character of the dispersive readout in\ncircuit QED are limited by unwanted transitions to highly excited states at\nspecific photon numbers in the readout resonator. This observation can be\nexplained by multiphoton resonances between computational states and highly\nexcited states in strongly driven nonlinear systems, analogous to multiphoton\nionization in atoms and molecules. In this work, we utilize the multilevel\nnature of high-$E_J/E_C$ transmons to probe the excited-state dynamics induced\nby strong drives during readout. With up to 10 resolvable states, we quantify\nthe critical photon number of ionization, the resulting state after ionization,\nand the fraction of the population transferred to highly excited states.\nMoreover, using pulse-shaping to control the photon number in the readout\nresonator in the high-power regime, we tune the adiabaticity of the transition\nand verify that transmon ionization is a Landau-Zener-type transition. Our\nexperimental results agree well with the theoretical prediction from a\nsemiclassical driven transmon model and may guide future exploration of\nstrongly driven nonlinear oscillators.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T16:28:03Z"}
{"aid":"http://arxiv.org/abs/2505.00646v1","title":"The Whitehead group and stably trivial $G$-smoothings","summary":"A closed manifold $M$ of dimension at least $5$ has only finitely many smooth\nstructures. Moreover, smooth structures of $M$ are in bijection with smooth\nstructures of $M\\times\\mathbb{R}$. Both of these statements are false\nequivariantly. In this paper, we use controlled $h$-cobordisms to construct\ninfinitely many $G$-smoothings of a $G$-manifold $X$. Moreover, these\n$G$-smoothings are isotopic after taking a product with $\\mathbb{R}$.","main_category":"math.GT","categories":"math.GT,math.AT,math.KT","published":"2025-05-01T16:36:49Z"}
{"aid":"http://arxiv.org/abs/2505.00654v1","title":"Large Language Models Understanding: an Inherent Ambiguity Barrier","summary":"A lively ongoing debate is taking place, since the extraordinary emergence of\nLarge Language Models (LLMs) with regards to their capability to understand the\nworld and capture the meaning of the dialogues in which they are involved.\nArguments and counter-arguments have been proposed based upon thought\nexperiments, anecdotal conversations between LLMs and humans, statistical\nlinguistic analysis, philosophical considerations, and more. In this brief\npaper we present a counter-argument based upon a thought experiment and\nsemi-formal considerations leading to an inherent ambiguity barrier which\nprevents LLMs from having any understanding of what their amazingly fluent\ndialogues mean.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T16:55:44Z"}
{"aid":"http://arxiv.org/abs/2505.00661v1","title":"On the generalization of language models from in-context learning and\n  finetuning: a controlled study","summary":"Large language models exhibit exciting capabilities, yet can show\nsurprisingly narrow generalization from finetuning -- from failing to\ngeneralize to simple reversals of relations they are trained on, to missing\nlogical deductions that can be made from trained information. These failures to\ngeneralize from fine-tuning can hinder practical application of these models.\nHowever, language models' in-context learning shows different inductive biases,\nand can generalize better in some of these cases. Here, we explore these\ndifferences in generalization between in-context- and fine-tuning-based\nlearning. To do so, we constructed several novel datasets to evaluate and\nimprove models' ability to generalize from finetuning data. The datasets are\nconstructed to isolate the knowledge in the dataset from that in pretraining,\nto create clean tests of generalization. We expose pretrained large models to\ncontrolled subsets of the information in these datasets -- either in context,\nor through fine-tuning -- and evaluate their performance on test sets that\nrequire various types of generalization. We find overall that in data-matched\nsettings, in-context learning can generalize more flexibly than fine-tuning\n(though we also find some qualifications of prior findings, such as cases when\nfine-tuning can generalize to reversals embedded in a larger structure of\nknowledge). We build on these findings to propose a method to enable improved\ngeneralization from fine-tuning: adding in-context inferences to finetuning\ndata. We show that this method improves generalization across various splits of\nour datasets and other benchmarks. Our results have implications for\nunderstanding the inductive biases of different modes of learning in language\nmodels, and practically improving their performance.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-05-01T17:02:27Z"}
{"aid":"http://arxiv.org/abs/2505.00681v1","title":"MINERVA: Evaluating Complex Video Reasoning","summary":"Multimodal LLMs are turning their focus to video benchmarks, however most\nvideo benchmarks only provide outcome supervision, with no intermediate or\ninterpretable reasoning steps. This makes it challenging to assess if models\nare truly able to combine perceptual and temporal information to reason about\nvideos, or simply get the correct answer by chance or by exploiting linguistic\nbiases. To remedy this, we provide a new video reasoning dataset called MINERVA\nfor modern multimodal models. Each question in the dataset comes with 5 answer\nchoices, as well as detailed, hand-crafted reasoning traces. Our dataset is\nmultimodal, diverse in terms of video domain and length, and consists of\ncomplex multi-step questions. Extensive benchmarking shows that our dataset\nprovides a challenge for frontier open-source and proprietary models. We\nperform fine-grained error analysis to identify common failure modes across\nvarious models, and create a taxonomy of reasoning errors. We use this to\nexplore both human and LLM-as-a-judge methods for scoring video reasoning\ntraces, and find that failure modes are primarily related to temporal\nlocalization, followed by visual perception errors, as opposed to logical or\ncompleteness errors. The dataset, along with questions, answer candidates and\nreasoning traces will be publicly available under\nhttps://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-05-01T17:41:49Z"}
{"aid":"http://arxiv.org/abs/2505.00684v1","title":"Visual Test-time Scaling for GUI Agent Grounding","summary":"We introduce RegionFocus, a visual test-time scaling approach for Vision\nLanguage Model Agents. Understanding webpages is challenging due to the visual\ncomplexity of GUI images and the large number of interface elements, making\naccurate action selection difficult. Our approach dynamically zooms in on\nrelevant regions, reducing background clutter and improving grounding accuracy.\nTo support this process, we propose an image-as-map mechanism that visualizes\nkey landmarks at each step, providing a transparent action record and enables\nthe agent to effectively choose among action candidates. Even with a simple\nregion selection strategy, we observe significant performance gains of 28+\\% on\nScreenspot-pro and 24+\\% on WebVoyager benchmarks on top of two\nstate-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL,\nhighlighting the effectiveness of visual test-time scaling in interactive\nsettings. We achieve a new state-of-the-art grounding performance of 61.6\\% on\nthe ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model.\nOur code will be released publicly at https://github.com/tiangeluo/RegionFocus.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-05-01T17:45:59Z"}
{"aid":"http://arxiv.org/abs/2505.00701v1","title":"A log-depth in-place quantum Fourier transform that rarely needs\n  ancillas","summary":"When designing quantum circuits for a given unitary, it can be much cheaper\nto achieve a good approximation on most inputs than on all inputs. In this work\nwe formalize this idea, and propose that such \"optimistic quantum circuits\" are\noften sufficient in the context of larger quantum algorithms. For the rare\nalgorithm in which a subroutine needs to be a good approximation on all inputs,\nwe provide a reduction which transforms optimistic circuits into general ones.\nApplying these ideas, we build an optimistic circuit for the in-place quantum\nFourier transform (QFT). Our circuit has depth $O(\\log (n / \\epsilon))$ for\ntunable error parameter $\\epsilon$, uses $n$ total qubits, i.e. no ancillas, is\nlogarithmically local for input qubits arranged in 1D, and is measurement-free.\nThe circuit's error is bounded by $\\epsilon$ on all input states except an\n$O(\\epsilon)$-sized fraction of the Hilbert space. The circuit is also rather\nsimple and thus may be practically useful. Combined with recent QFT-based fast\narithmetic constructions [arXiv:2403.18006], the optimistic QFT yields\nfactoring circuits of nearly linear depth using only $2n + O(n/\\log n)$ total\nqubits. Applying our reduction technique, we also construct the first\napproximate QFT to achieve the asymptotically optimal depth of $O(\\log\n(n/\\epsilon))$ with a sublinear number of ancilla qubits, well-controlled error\non all inputs, and no intermediate measurements.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T17:58:36Z"}
{"aid":"http://arxiv.org/abs/2505.00702v1","title":"RayZer: A Self-supervised Large View Synthesis Model","summary":"We present RayZer, a self-supervised multi-view 3D Vision model trained\nwithout any 3D supervision, i.e., camera poses and scene geometry, while\nexhibiting emerging 3D awareness. Concretely, RayZer takes unposed and\nuncalibrated images as input, recovers camera parameters, reconstructs a scene\nrepresentation, and synthesizes novel views. During training, RayZer relies\nsolely on its self-predicted camera poses to render target views, eliminating\nthe need for any ground-truth camera annotations and allowing RayZer to be\ntrained with 2D image supervision. The emerging 3D awareness of RayZer is\nattributed to two key factors. First, we design a self-supervised framework,\nwhich achieves 3D-aware auto-encoding of input images by disentangling camera\nand scene representations. Second, we design a transformer-based model in which\nthe only 3D prior is the ray structure, connecting camera, pixel, and scene\nsimultaneously. RayZer demonstrates comparable or even superior novel view\nsynthesis performance than ``oracle'' methods that rely on pose annotations in\nboth training and testing. Project: https://hwjiang1510.github.io/RayZer/","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T17:59:34Z"}
{"aid":"http://arxiv.org/abs/2505.07176v1","title":"Internet of Agents: Fundamentals, Applications, and Challenges","summary":"With the rapid proliferation of large language models and vision-language\nmodels, AI agents have evolved from isolated, task-specific systems into\nautonomous, interactive entities capable of perceiving, reasoning, and acting\nwithout human intervention. As these agents proliferate across virtual and\nphysical environments, from virtual assistants to embodied robots, the need for\na unified, agent-centric infrastructure becomes paramount. In this survey, we\nintroduce the Internet of Agents (IoA) as a foundational framework that enables\nseamless interconnection, dynamic discovery, and collaborative orchestration\namong heterogeneous agents at scale. We begin by presenting a general IoA\narchitecture, highlighting its hierarchical organization, distinguishing\nfeatures relative to the traditional Internet, and emerging applications. Next,\nwe analyze the key operational enablers of IoA, including capability\nnotification and discovery, adaptive communication protocols, dynamic task\nmatching, consensus and conflict-resolution mechanisms, and incentive models.\nFinally, we identify open research directions toward building resilient and\ntrustworthy IoA ecosystems.","main_category":"cs.MA","categories":"cs.MA,cs.AI","published":"2025-05-12T02:04:37Z"}
{"aid":"http://arxiv.org/abs/2505.07181v1","title":"Nonuniqueness in law of stochastic 3d navierstokes equations with\n  general multiplicative noise","summary":"We are concerned with the three dimensional navier-stokes equations driven by\na general multiplicative noise. For every divergence free and mean free initial\ncondition in L2, we establish existence of infinitely many global-in-time\nprobabilistically strong and analytically weak solutions, which implies\nnon-uniqueness in law. Moreover, we prove the existence of infinitely many\nergodic stationary solutions. Our results are based on a stochastic version of\nthe convex integration and the Ito calculus.","main_category":"math.PR","categories":"math.PR","published":"2025-05-12T02:14:28Z"}
{"aid":"http://arxiv.org/abs/2505.07188v1","title":"Securing Genomic Data Against Inference Attacks in Federated Learning\n  Environments","summary":"Federated Learning (FL) offers a promising framework for collaboratively\ntraining machine learning models across decentralized genomic datasets without\ndirect data sharing. While this approach preserves data locality, it remains\nsusceptible to sophisticated inference attacks that can compromise individual\nprivacy. In this study, we simulate a federated learning setup using synthetic\ngenomic data and assess its vulnerability to three key attack vectors:\nMembership Inference Attack (MIA), Gradient-Based Membership Inference Attack,\nand Label Inference Attack (LIA). Our experiments reveal that Gradient-Based\nMIA achieves the highest effectiveness, with a precision of 0.79 and F1-score\nof 0.87, underscoring the risk posed by gradient exposure in federated updates.\nAdditionally, we visualize comparative attack performance through radar plots\nand quantify model leakage across clients. The findings emphasize the\ninadequacy of na\\\"ive FL setups in safeguarding genomic privacy and motivate\nthe development of more robust privacy-preserving mechanisms tailored to the\nunique sensitivity of genomic data.","main_category":"cs.CR","categories":"cs.CR,cs.CL","published":"2025-05-12T02:36:50Z"}
{"aid":"http://arxiv.org/abs/2505.07205v1","title":"Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward\n  Systemic Governance under Healthy China 2030","summary":"Large Language Models (LLMs) are poised to transform healthcare under China's\nHealthy China 2030 initiative, yet they introduce new ethical and\npatient-safety challenges. We present a novel 12,000-item Q&A benchmark\ncovering 11 ethics and 9 safety dimensions in medical contexts, to\nquantitatively evaluate these risks. Using this dataset, we assess\nstate-of-the-art Chinese medical LLMs (e.g., Qwen 2.5-32B, DeepSeek), revealing\nmoderate baseline performance (accuracy 42.7% for Qwen 2.5-32B) and significant\nimprovements after fine-tuning on our data (up to 50.8% accuracy). Results show\nnotable gaps in LLM decision-making on ethics and safety scenarios, reflecting\ninsufficient institutional oversight. We then identify systemic governance\nshortfalls-including the lack of fine-grained ethical audit protocols, slow\nadaptation by hospital IRBs, and insufficient evaluation tools-that currently\nhinder safe LLM deployment. Finally, we propose a practical governance\nframework for healthcare institutions (embedding LLM auditing teams, enacting\ndata ethics guidelines, and implementing safety simulation pipelines) to\nproactively manage LLM risks. Our study highlights the urgent need for robust\nLLM governance in Chinese healthcare, aligning AI innovation with patient\nsafety and ethical standards.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-12T03:28:05Z"}
{"aid":"http://arxiv.org/abs/2505.07214v1","title":"Towards user-centered interactive medical image segmentation in VR with\n  an assistive AI agent","summary":"Crucial in disease analysis and surgical planning, manual segmentation of\nvolumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and\nchallenging to master, while fully automatic algorithms can benefit from\nuser-feedback. Therefore, with the complementary power of the latest\nradiological AI foundation models and virtual reality (VR)'s intuitive data\ninteraction, we propose SAMIRA, a novel conversational AI agent that assists\nusers with localizing, segmenting, and visualizing 3D medical concepts in VR.\nThrough speech-based interaction, the agent helps users understand radiological\nfeatures, locate clinical targets, and generate segmentation masks that can be\nrefined with just a few point prompts. The system also supports true-to-scale\n3D visualization of segmented pathology to enhance patient-specific anatomical\nunderstanding. Furthermore, to determine the optimal interaction paradigm under\nnear-far attention-switching for refining segmentation masks in an immersive,\nhuman-in-the-loop workflow, we compare VR controller pointing, head pointing,\nand eye tracking as input modes. With a user study, evaluations demonstrated a\nhigh usability score (SUS=90.0 $\\pm$ 9.0), low overall task load, as well as\nstrong support for the proposed VR system's guidance, training potential, and\nintegration of AI in radiological segmentation tasks.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CV","published":"2025-05-12T03:47:05Z"}
{"aid":"http://arxiv.org/abs/2505.07218v1","title":"Efficiently Computable Limits on EPR Pair Generation in Quantum\n  Broadcast Channels","summary":"We investigate the generation of EPR pairs between three observers in a\ngeneral causally structured setting, where communication occurs via a noisy\nquantum broadcast channel. The most general quantum codes for this setup take\nthe form of tripartite quantum channels. Since the receivers are constrained by\ncausal ordering, additional temporal relationships naturally emerge between the\nparties. These causal constraints enforce intrinsic no-signalling conditions on\nany tripartite operation, ensuring that it constitutes a physically realizable\nquantum code for a quantum broadcast channel. We analyze these constraints and,\nmore broadly, characterize the most general quantum codes for communication\nover such channels. We examine the capabilities of codes that are fully\nno-signalling among the three parties, positive partial transpose\n(PPT)-preserving, or both, and derive simple semidefinite programs to compute\nthe achievable entanglement fidelity. We then establish a hierarchy of\nsemidefinite programming converse bounds -- both weak and strong -- for the\ncapacity of quantum broadcast channels for EPR pair generation, in both\none-shot and asymptotic regimes. Notably, in the special case of a\npoint-to-point channel, our strong converse bound recovers and strengthens\nexisting results. Finally, we demonstrate how the PPT-preserving codes we\ndevelop can be leveraged to construct PPT-preserving entanglement combing\nschemes, and vice versa.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-12T04:15:21Z"}
{"aid":"http://arxiv.org/abs/2505.07227v1","title":"CVTree for 16S rRNA: Constructing Taxonomy-Compatible All-Species Living\n  Tree Effectively and Efficiently","summary":"The Composition Vector Tree (CVTree) method, developed under the leadership\nof Professor Hao Bailin, is an alignment-free algorithm for constructing\nphylogenetic trees. Although initially designed for studying prokaryotic\nevolution based on whole-genome, it has demonstrated broad applicability across\ndiverse biological systems and gene sequences. In this study, we employed two\nmethods, InterList and Hao, of CVTree to investigate the phylogeny and taxonomy\nof prokaryote based on the 16S rRNA sequences from All-Species Living Tree\nProject. We have established a comprehensive phylogenetic tree that\nincorporates the majority of species documented in human scientific knowledge\nand compared it with the taxonomy of prokaryotes. And the performance of CVTree\nwere also compared with multiple sequence alignment-based approaches. Our\nresults revealed that CVTree methods achieve computational speeds 1-3 orders of\nmagnitude faster than conventional alignment methods while maintaining high\nconsistency with established taxonomic relationships, even outperforming some\nmultiple sequence alignment methods. These findings confirm CVTree's\neffectiveness and efficiency not only for whole-genome evolutionary studies but\nalso for phylogenetic and taxonomic investigations based on genes.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.bio-ph","published":"2025-05-12T04:55:17Z"}
{"aid":"http://arxiv.org/abs/2505.07232v1","title":"Spatial Confounding in Multivariate Areal Data Analysis","summary":"We investigate spatial confounding in the presence of multivariate disease\ndependence. In the \"analysis model perspective\" of spatial confounding, adding\na spatially dependent random effect can lead to significant variance inflation\nof the posterior distribution of the fixed effects. The \"data generation\nperspective\" views covariates as stochastic and correlated with an unobserved\nspatial confounder, leading to inferior statistical inference over multiple\nrealizations. While multiple methods have been proposed for adjusting\nstatistical models to mitigate spatial confounding in estimating regression\ncoefficients, results on interactions between spatial confounding and\nmultivariate dependence are very limited. We contribute to this domain by\ninvestigating spatial confounding from the analysis and data generation\nperspectives in a Bayesian coregionalized areal regression model. We derive\nnovel results that distinguish variance inflation due to spatial confounding\nfrom inflation based on multicollinearity between predictors and provide\ninsights into the estimation efficiency of a spatial estimator under a\nspatially confounded data generation model. We demonstrate favorable\nperformance of spatial analysis compared to a non-spatial model in our\nsimulation experiments even in the presence of spatial confounding and a\nmisspecified spatial structure. In this regard, we align with several other\nauthors in the defense of traditional hierarchical spatial models (Gilbert et\nal., 2025; Khan and Berrett, 2023; Zimmerman and Ver Hoef, 2022) and extend\nthis defense to multivariate areal models. We analyze county-level data from\nthe US on obesity / diabetes prevalence and diabetes-related cancer mortality,\ncomparing the results with and without spatial random effects.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-12T05:14:38Z"}
{"aid":"http://arxiv.org/abs/2505.07244v1","title":"The Influence of the Memory Capacity of Neural DDEs on the Universal\n  Approximation Property","summary":"Neural Ordinary Differential Equations (Neural ODEs), which are the\ncontinuous-time analog of Residual Neural Networks (ResNets), have gained\nsignificant attention in recent years. Similarly, Neural Delay Differential\nEquations (Neural DDEs) can be interpreted as an infinite depth limit of\nDensely Connected Residual Neural Networks (DenseResNets). In contrast to\ntraditional ResNet architectures, DenseResNets are feed-forward networks that\nallow for shortcut connections across all layers. These additional connections\nintroduce memory in the network architecture, as typical in many modern\narchitectures. In this work, we explore how the memory capacity in neural DDEs\ninfluences the universal approximation property. The key parameter for studying\nthe memory capacity is the product $K \\tau$ of the Lipschitz constant and the\ndelay of the DDE. In the case of non-augmented architectures, where the network\nwidth is not larger than the input and output dimensions, neural ODEs and\nclassical feed-forward neural networks cannot have the universal approximation\nproperty. We show that if the memory capacity $K\\tau$ is sufficiently small,\nthe dynamics of the neural DDE can be approximated by a neural ODE.\nConsequently, non-augmented neural DDEs with a small memory capacity also lack\nthe universal approximation property. In contrast, if the memory capacity\n$K\\tau$ is sufficiently large, we can establish the universal approximation\nproperty of neural DDEs for continuous functions. If the neural DDE\narchitecture is augmented, we can expand the parameter regions in which\nuniversal approximation is possible. Overall, our results show that by\nincreasing the memory capacity $K\\tau$, the infinite-dimensional phase space of\nDDEs with positive delay $\\tau>0$ is not sufficient to guarantee a direct jump\ntransition to universal approximation, but only after a certain memory\nthreshold, universal approximation holds.","main_category":"math.DS","categories":"math.DS,cs.LG,cs.NE","published":"2025-05-12T05:36:39Z"}
{"aid":"http://arxiv.org/abs/2505.07248v1","title":"Koszul property and finite linearity defect over $g$-stretched local\n  rings","summary":"The linearity defect is a measure for the non-linearity of minimal free\nresolutions of modules over noetherian local rings. A tantalizing open question\ndue to Herzog and Iyengar asks whether a noetherian local ring\n$(R,\\mathfrak{m})$ is Koszul if its residue field $R/\\mathfrak{m}$ has a finite\nlinearity defect. We provide a positive answer to this question when $R$ is a\nCohen--Macaulay local ring of almost minimal multiplicity with the residue\nfield of characteristic zero. The proof depends on the study of noetherian\nlocal rings $(R,\\mathfrak{m})$ such that $\\mathfrak{m}^2$ is a principal ideal,\nwhich we call $g$-$stretched$ local rings. The class of $g$-stretched local\nrings subsumes stretched artinian local rings studied by Sally, and generic\nartinian reductions of Cohen--Macaulay local rings of almost minimal\nmultiplicity. An essential part in the proof of our main result is a complete\ncharacterization of one-dimensional complete $g$-stretched local rings. Beside\npartial progress on Herzog--Iyengar's question, another consequence of our\nstudy is a numerical characterization of all $g$-stretched Koszul rings,\nstrengthening previous work of Avramov, Iyengar, and \\c{S}ega.","main_category":"math.AC","categories":"math.AC","published":"2025-05-12T05:44:15Z"}
{"aid":"http://arxiv.org/abs/2505.07262v1","title":"Lepton mass textures from non-invertible multiplication rules","summary":"We study the lepton mass textures, which are derived by $\\mathbb{Z}_2$\ngauging of $\\mathbb{Z}_M$ symmetries. We can obtain various textures for the\nYukawa couplings in the charged lepton sector, but the patterns of neutrino\nmass matrices are limited. All the obtained textures can not be realized by\ngroup-theoretical symmetries, and certain textures can lead to realistic\nresults.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-12T06:23:05Z"}
{"aid":"http://arxiv.org/abs/2505.07263v1","title":"Skywork-VL Reward: An Effective Reward Model for Multimodal\n  Understanding and Reasoning","summary":"We propose Skywork-VL Reward, a multimodal reward model that provides reward\nsignals for both multimodal understanding and reasoning tasks. Our technical\napproach comprises two key components: First, we construct a large-scale\nmultimodal preference dataset that covers a wide range of tasks and scenarios,\nwith responses collected from both standard vision-language models (VLMs) and\nadvanced VLM reasoners. Second, we design a reward model architecture based on\nQwen2.5-VL-7B-Instruct, integrating a reward head and applying multi-stage\nfine-tuning using pairwise ranking loss on pairwise preference data.\nExperimental evaluations show that Skywork-VL Reward achieves state-of-the-art\nresults on multimodal VL-RewardBench and exhibits competitive performance on\nthe text-only RewardBench benchmark. Furthermore, preference data constructed\nbased on our Skywork-VL Reward proves highly effective for training Mixed\nPreference Optimization (MPO), leading to significant improvements in\nmultimodal reasoning capabilities. Our results underscore Skywork-VL Reward as\na significant advancement toward general-purpose, reliable reward models for\nmultimodal alignment. Our model has been publicly released to promote\ntransparency and reproducibility.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T06:23:08Z"}
{"aid":"http://arxiv.org/abs/2505.07264v1","title":"Carleman estimates for the Korteweg-de Vries equation with piecewise\n  constant main coefficient","summary":"In this article, we investigate observability-related properties of the\nKorteweg-de Vries equation with a discontinuous main coefficient, coupled by\nsuitable interface conditions. The main result is a novel two-parameter\nCarleman estimate for the linear equation with internal observation, assuming a\nmonotonicity condition on the main coefficient. As a primary application, we\nestablish the local exact controllability to the trajectories by employing a\nduality argument for the linear case and a local inversion theorem for the\nnonlinear equation. Secondly, we establish the Lipschitz-stability of the\ninverse problem of retrieving an unknown potential using the\nBukhge{\\u\\i}m-Klibanov method, when some further assumptions on the interface\nare made. We conclude with some remarks on the boundary observability.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-05-12T06:28:48Z"}
{"aid":"http://arxiv.org/abs/2505.07269v1","title":"Crossed pseudopotential$-$functional calculations made simple: An\n  extended Kohn-Sham framework","summary":"Modern density-functional-theory (DFT) calculations rely heavily on\npseudopotentials, yet their impact on accuracy is barely addressed. In this\nwork, we derive from the Kohn-Sham equation that the use of pseudopotentials\ninvariably introduces a ``dropping\" error, which leads to a deviation from the\nHohenberg-Kohn theorem. Crossed pseudopotential-functional calculations provide\na pragmatic way to balance accuracy and efficiency, enabling the right results\nfor the right reasons. This paradigm goes beyond the (generalized) Kohn-Sham\nframework, which we name the extended Kohn-Sham framework. We support our\nassertion with a bandgap study on 54 monovalent-Cu semiconductors. The crossed\ncalculations, compared to consistent ones, not only remove all 11 erroneous\nmetal predictions, but also drastically reduce the mean relative error from\n80\\% to 20\\%. The accuracy even exceeds that of the hybrid functionals and GW\ndue to the role of pseudopotentials in modelling the external potentials of\nCu-valence electrons that cannot be compensated by exchange-correlation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-05-12T06:47:13Z"}
{"aid":"http://arxiv.org/abs/2505.07277v1","title":"On some classification problems of multiplicative functions","summary":"We prove that a multiplicative function $f:\\mathbb{N}\\to\\mathbb{C}$ is\nToeplitz if and only if there are a Dirichlet character $\\chi$ and a finite\nsubset $F$ of prime numbers such that $f(n)=\\chi(n)$ for each $n$ which is\ncoprime to all numbers from $F$. All such functions bounded by~1 are\nnecessarily pretentious and they have exactly one Furstenberg system. Moreover,\nwe characterize the class of pretentious functions that have precisely one\nFurstenberg system as those being Besicovitch (rationally) almost periodic. As\na consequence, we show that the corrected Elliott's conjecture implies\nFrantzikinakis-Host's conjecture on the uniqueness of Furstenberg system for\nall real-valued bounded by~1 multiplicative functions. We also clarify\nrelations between different classes of aperiodic multiplicative functions.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-05-12T07:00:10Z"}
{"aid":"http://arxiv.org/abs/2505.07280v1","title":"Predicting Music Track Popularity by Convolutional Neural Networks on\n  Spotify Features and Spectrogram of Audio Waveform","summary":"In the digital streaming landscape, it's becoming increasingly challenging\nfor artists and industry experts to predict the success of music tracks. This\nstudy introduces a pioneering methodology that uses Convolutional Neural\nNetworks (CNNs) and Spotify data analysis to forecast the popularity of music\ntracks. Our approach takes advantage of Spotify's wide range of features,\nincluding acoustic attributes based on the spectrogram of audio waveform,\nmetadata, and user engagement metrics, to capture the complex patterns and\nrelationships that influence a track's popularity. Using a large dataset\ncovering various genres and demographics, our CNN-based model shows impressive\neffectiveness in predicting the popularity of music tracks. Additionally, we've\nconducted extensive experiments to assess the strength and adaptability of our\nmodel across different musical styles and time periods, with promising results\nyielding a 97\\% F1 score. Our study not only offers valuable insights into the\ndynamic landscape of digital music consumption but also provides the music\nindustry with advanced predictive tools for assessing and predicting the\nsuccess of music tracks.","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-05-12T07:03:17Z"}
{"aid":"http://arxiv.org/abs/2505.07286v1","title":"Piloting Structure-Based Drug Design via Modality-Specific Optimal\n  Schedule","summary":"Structure-Based Drug Design (SBDD) is crucial for identifying bioactive\nmolecules. Recent deep generative models are faced with challenges in geometric\nstructure modeling. A major bottleneck lies in the twisted probability path of\nmulti-modalities -- continuous 3D positions and discrete 2D topologies -- which\njointly determine molecular geometries. By establishing the fact that noise\nschedules decide the Variational Lower Bound (VLB) for the twisted probability\npath, we propose VLB-Optimal Scheduling (VOS) strategy in this under-explored\narea, which optimizes VLB as a path integral for SBDD. Our model effectively\nenhances molecular geometries and interaction modeling, achieving\nstate-of-the-art PoseBusters passing rate of 95.9% on CrossDock, more than 10%\nimprovement upon strong baselines, while maintaining high affinities and robust\nintramolecular validity evaluated on held-out test set.","main_category":"q-bio.BM","categories":"q-bio.BM,cs.AI,cs.LG","published":"2025-05-12T07:18:09Z"}
{"aid":"http://arxiv.org/abs/2505.07296v1","title":"Karmarkar-Tolman Embedded Charged Anisotropic Stars in f(R) Gravity","summary":"We investigate various anisotropic spherical distributions of charged\ncelestial bodies within the context of f(R) gravity, where R represents the\nRicci scalar. The properties of specific charged compact objects are analyzed\nby using the Karmarkar-Tolman spacetime and three distinct gravitational\nmodels. The behavior of the structural parameters is examined via graphical\nmethods. Energy constraints are applied to assess how well the results align\nwith the Karmarkar-Tolman spacetime model. The physical acceptability of the\nstellar models is evaluated by checking the energy conditions and the equation\nof state parameter. Additionally, we explore the influence of anisotropy on the\nstability and internal structure of the models. Our findings are compared with\npredictions from general relativity to highlight the effects of f(R) gravity on\ncharged compact stars. The obtained results are useful to enhance our\nunderstanding of how modified gravity theories affect the properties of compact\nastrophysical objects.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-05-12T07:34:25Z"}
{"aid":"http://arxiv.org/abs/2505.07305v1","title":"Inertia, Independence and Expanders","summary":"Let $G$ be a graph with $n$ vertices, independence number $\\alpha(G)$ and\nLov\\'{a}sz theta function $\\vartheta(G)$. We define $n_{\\ge0}(G)$ to be the\nminimum number of non-negative eigenvalues taken over all Hermitian weighted\nadjacency matrices of $G$. It is well known that $\\alpha(G) \\le \\vartheta(G)$\nand $\\alpha(G) \\le n_{\\ge0}(G)$. We also let $n_{\\ge0}(A_G)$ denote the number\nof non-negative eigenvalues of the unweighted adjacency matrix of $G$.\n  Continuing a long line of works, we investigate the relationships between $\n\\alpha(G) $, $ \\vartheta(G) $, and $ n_{\\ge 0}(G) $. We prove a conjecture of\nKwan and Wigderson, showing that for every integer $ k $, there exists a graph\n$ G $ with $ \\alpha(G) \\leq 2 $ and $ n_{\\ge 0}(G) \\ge k $. Our proof relies on\na new observation: if the complement of $G$ contains a good spectral expander,\nthen $n_{\\geq 0}(G)$ must be large.\n  We also show that $ \\vartheta(G) $ can be exponentially larger than $ n_{\\ge\n0}(G) $, improving a recent result of Ihringer. Finally, we revisit a\nNordhaus--Gaddum type bound for $ n_{\\ge 0}(A_G) $ due to Elphick and Wocjan,\nand conjecture that $ n_{\\ge 0}(A_G) \\cdot n_{\\ge 0}(A_{\\overline{G}}) \\ge n $\nholds for all graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-05-12T07:48:50Z"}
{"aid":"http://arxiv.org/abs/2505.07314v1","title":"Sparsity for dynamic inverse problems on Wasserstein curves with bounded\n  variation","summary":"We investigate a dynamic inverse problem using a regularization which\nimplements the so-called Wasserstein-$1$ distance. It naturally extends\nwell-known static problems such as lasso or total variation regularized\nproblems to a (temporally) dynamic setting. Further, the decision variables,\nrealized as BV curves, are allowed to exhibit discontinuities, in contrast to\nthe design variables in classical optimal transport based regularization\ntechniques. We prove the existence and a characterization of a sparse solution.\nFurther, we use an adaption of the fully-corrective generalized conditional\ngradient method to experimentally justify that the determination of BV curves\nin the Wasserstein-$1$ space is numerically implementable.","main_category":"math.OC","categories":"math.OC","published":"2025-05-12T07:59:40Z"}
{"aid":"http://arxiv.org/abs/2505.07334v1","title":"Three results on holonomic D-modules","summary":"In this text, we illustrate the use of local methods in the theory of\n(irregular) holonomic D-modules. I. (The Euler characteristic of the de~Rham\ncomplex) We show the invariance of the global or local Euler characteristic of\nthe de~Rham complex after localization and dual localization of a holonomic\nD-module along a hypersurface, as well as after tensoring with a rank one\nmeromorphic connection with regular singularities. II. (Local generic vanishing\ntheorems for holonomic D-modules) We prove that the natural morphism from the\nproper pushforward to the total pushforward of an algebraic holonomic D-module\nby an open inclusion is an isomorphism if we first twist the D-module structure\nby suitable closed algebraic differential forms. III. (Laplace transform of a\nStokes-filtered constructible sheaf of exponential type) Motivated by the\nconstruction in [YZ24], we~propose a slightly different construction of the\nLaplace transform of a Stokes-perverse sheaf on the projective line and show\ndirectly that it corresponds to the Laplace transform of the corresponding\nholonomic D-module via the Riemann-Hilbert-Birkhoff-Deligne-Malgrange\ncorrespondence. This completes the presentation given in [Sab13, Chap. 7]},\nwhere only the other direction of the Laplace transformation is analyzed.\nWe~also compare our approach with the construction made previously in [YZ24].","main_category":"math.AG","categories":"math.AG","published":"2025-05-12T08:19:27Z"}
{"aid":"http://arxiv.org/abs/2505.07337v1","title":"An approach to the Tate conjecture for surfaces over a finite field","summary":"We give a reformuation of the Tate conjecture for a surface over a finite\nfield in terms of suitable affine open subsets. We then present three attempts\nto prove this reformulation, each of them falling short. Interestingly, the\nlast two are related to techniques used in proofs of Gersten's conjecture.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-05-12T08:22:48Z"}
{"aid":"http://arxiv.org/abs/2505.07339v1","title":"Laypeople's Attitudes Towards Fair, Affirmative, and Discriminatory\n  Decision-Making Algorithms","summary":"Affirmative algorithms have emerged as a potential answer to algorithmic\ndiscrimination, seeking to redress past harms and rectify the source of\nhistorical injustices. We present the results of two experiments ($N$$=$$1193$)\ncapturing laypeople's perceptions of affirmative algorithms -- those which\nexplicitly prioritize the historically marginalized -- in hiring and criminal\njustice. We contrast these opinions about affirmative algorithms with folk\nattitudes towards algorithms that prioritize the privileged (i.e.,\ndiscriminatory) and systems that make decisions independently of demographic\ngroups (i.e., fair). We find that people -- regardless of their political\nleaning and identity -- view fair algorithms favorably and denounce\ndiscriminatory systems. In contrast, we identify disagreements concerning\naffirmative algorithms: liberals and racial minorities rate affirmative systems\nas positively as their fair counterparts, whereas conservatives and those from\nthe dominant racial group evaluate affirmative algorithms as negatively as\ndiscriminatory systems. We identify a source of these divisions: people have\nvarying beliefs about who (if anyone) is marginalized, shaping their views of\naffirmative algorithms. We discuss the possibility of bridging these\ndisagreements to bring people together towards affirmative algorithms.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC","published":"2025-05-12T08:25:15Z"}
{"aid":"http://arxiv.org/abs/2505.07349v1","title":"Multi-Plane Vision Transformer for Hemorrhage Classification Using Axial\n  and Sagittal MRI Data","summary":"Identifying brain hemorrhages from magnetic resonance imaging (MRI) is a\ncritical task for healthcare professionals. The diverse nature of MRI\nacquisitions with varying contrasts and orientation introduce complexity in\nidentifying hemorrhage using neural networks. For acquisitions with varying\norientations, traditional methods often involve resampling images to a fixed\nplane, which can lead to information loss. To address this, we propose a 3D\nmulti-plane vision transformer (MP-ViT) for hemorrhage classification with\nvarying orientation data. It employs two separate transformer encoders for\naxial and sagittal contrasts, using cross-attention to integrate information\nacross orientations. MP-ViT also includes a modality indication vector to\nprovide missing contrast information to the model. The effectiveness of the\nproposed model is demonstrated with extensive experiments on real world\nclinical dataset consists of 10,084 training, 1,289 validation and 1,496 test\nsubjects. MP-ViT achieved substantial improvement in area under the curve\n(AUC), outperforming the vision transformer (ViT) by 5.5% and CNN-based\narchitectures by 1.8%. These results highlight the potential of MP-ViT in\nimproving performance for hemorrhage detection when different orientation\ncontrasts are needed.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-12T08:43:43Z"}
{"aid":"http://arxiv.org/abs/2505.07374v1","title":"AIS Data-Driven Maritime Monitoring Based on Transformer: A\n  Comprehensive Review","summary":"With the increasing demands for safety, efficiency, and sustainability in\nglobal shipping, Automatic Identification System (AIS) data plays an\nincreasingly important role in maritime monitoring. AIS data contains\nspatial-temporal variation patterns of vessels that hold significant research\nvalue in the marine domain. However, due to its massive scale, the full\npotential of AIS data has long remained untapped. With its powerful sequence\nmodeling capabilities, particularly its ability to capture long-range\ndependencies and complex temporal dynamics, the Transformer model has emerged\nas an effective tool for processing AIS data. Therefore, this paper reviews the\nresearch on Transformer-based AIS data-driven maritime monitoring, providing a\ncomprehensive overview of the current applications of Transformer models in the\nmarine field. The focus is on Transformer-based trajectory prediction methods,\nbehavior detection, and prediction techniques. Additionally, this paper\ncollects and organizes publicly available AIS datasets from the reviewed\npapers, performing data filtering, cleaning, and statistical analysis. The\nstatistical results reveal the operational characteristics of different vessel\ntypes, providing data support for further research on maritime monitoring\ntasks. Finally, we offer valuable suggestions for future research, identifying\ntwo promising research directions. Datasets are available at\nhttps://github.com/eyesofworld/Maritime-Monitoring.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-05-12T09:17:43Z"}
{"aid":"http://arxiv.org/abs/2505.07378v1","title":"Undecidability of Polynomial Inequalities in Subset Densities and\n  Additive Energies","summary":"Many results in extremal graph theory can be formulated as certain polynomial\ninequalities in graph homomorphism densities. Answering fundamental questions\nraised by Lov{\\'a}sz, Szegedy and Razborov, Hatami and Norine proved that\ndetermining the validity of an arbitrary such polynomial inequality in graph\nhomomorphism densities is undecidable. We observe that many results in additive\ncombinatorics can also be formulated as polynomial inequalities in subset's\ndensity and its variants. Based on techniques introduced in Hatami and Norine,\ntogether with algebraic and graph construction and Fourier analysis, we prove\nsimilarly two theorems of undecidability, thus showing that establishing such\npolynomial inequalities in additive combinatorics are inherently difficult in\ntheir full generality.","main_category":"math.CO","categories":"math.CO,cs.CC,math.LO","published":"2025-05-12T09:23:53Z"}
{"aid":"http://arxiv.org/abs/2505.07385v1","title":"On the internal architecture of lightweight negative Poisson's ratio\n  (auxetic) metastructures: a review","summary":"Development of lightweight materials with enhanced mechanical properties has\nbeen a long-standing challenge in science and engineering. Lightweight auxetic\nmetastructures (AMSs) provide attractive solutions to this problem. AMSs'\nnegative Poisson's ratio is a unique characteristic which results in very\ninteresting practical properties such as high energy absorption and improved\ntoughness. Different properties of metastrcutures, including anisotropy, are\ndependent, in addition to their original material, on the unit cell shape and\ngeometrical features which have very high variations. Over the past few years,\nresearchers have developed AMSs with various unit cells, either introducing new\ninternal architecture or enhancing and optimizing the existing ones. Despite\nthe progress made in this field, there is no comprehensive review of the AMS\nunit cells. This review describes the cellular AMSs associated with a\nclassified set of metastructures, comprising more than 100 distinct auxetic\nrepetitive unit cells. Besides, achievable range of negative Poisson's ratios\nare provided for different categories of AMSs. Finally, the future perspective\nof the research field and potential developments and applications in this field\nare discussed.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-05-12T09:30:57Z"}
{"aid":"http://arxiv.org/abs/2505.07392v1","title":"Simulating many-engine spacecraft: Exceeding 100 trillion grid points\n  via information~geometric regularization and the MFC flow solver","summary":"This work proposes a method and optimized implementation for exascale\nsimulations of high-speed compressible fluid flows, enabling the simulation of\nmulti-engine rocket craft at an unprecedented scale. We significantly improve\nupon the state-of-the-art in terms of computational cost and memory footprint\nthrough a carefully crafted implementation of the recently proposed information\ngeometric regularization, which eliminates the need for numerical shock\ncapturing. Unified addressing on tightly coupled CPU--GPU platforms increases\nthe total problem size with negligible performance hit. Despite linear stencil\nalgorithms being memory-bound, we achieve wall clock times that are four times\nfaster than optimized baseline numerics. This enables the execution of CFD\nsimulations at more than 100 trillion grid points, surpassing the largest\nstate-of-the-art publicly available simulations by an order of magnitude. Ideal\nweak scaling is demonstrated on OLCF Frontier and CSCS Alps using the full\nsystem, entailing 37.8K AMD MI250X GPUs (Frontier) or 9.2K NVIDIA GH200\nsuperchips (Alps).","main_category":"physics.comp-ph","categories":"physics.comp-ph,cs.CE,physics.flu-dyn","published":"2025-05-12T09:35:38Z"}
{"aid":"http://arxiv.org/abs/2505.07401v1","title":"Role of non-reciprocity in spin-wave channeling","summary":"The extent to which non-reciprocal waves can be guided in arbitrary\ndirections is an interesting question. We address one aspect of this problem by\nstudying the propagation of acoustic spin waves in a narrow physical conduit\nmade of a synthetic antiferromagnet. Through a combination of Brillouin Light\nScattering microscopy and modeling, we demonstrate that even when attempting to\nguide waves in the reciprocal direction of the material, the system still\nexhibits strong signatures of non-reciprocity. This includes the excitation of\nhigh wavevector waves in the direction perpendicular to the intended\nchanneling, as well as energy transfer in directions that often neither aligns\nwith the physical conduit nor with the symmetry axes of the magnetic\nproperties. These findings have implications for the modeling of propagating\nwave spectroscopy in non-reciprocal materials and their potential applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-05-12T09:54:29Z"}
{"aid":"http://arxiv.org/abs/2505.07414v1","title":"Integrating Machine Learning with Triboelectric Nanogenerators:\n  Optimizing Electrode Materials and Doping Strategies for Intelligent Energy\n  Harves","summary":"The integration of machine learning techniques with triboelectric\nnanogenerators (TENGs) offers a transformative pathway for optimizing energy\nharvesting technologies. In this study, we propose a comprehensive framework\nthat utilizes graph neural networks to predict and enhance the performance of\nTENG electrode materials and doping strategies. By leveraging an extensive\ndataset of experimental and computational results, the model effectively\nclassifies electrode materials, predicts optimal doping ratios, and establishes\nrobust structure-property relationships. Key findings include a 65.7\\% increase\nin energy density for aluminum-doped PTFE and an 85.7\\% improvement for\nfluorine-doped PTFE, highlighting the critical influence of doping materials\nand their concentrations. The model further identifies PTFE as a highly\neffective negative electrode material, achieving a maximum energy density of\n1.12~J/cm$^2$ with 7\\% silver (Ag) doping when copper (Cu) is used as the\npositive electrode. This data-driven approach not only accelerates material\ndiscovery but also significantly reduces experimental costs, providing novel\ninsights into the fundamental factors influencing TENG performance. The\nproposed methodology establishes a robust platform for intelligent material\ndesign, advancing the development of sustainable energy technologies and\nself-powered systems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-12T10:08:10Z"}
{"aid":"http://arxiv.org/abs/2505.07415v1","title":"Extended inverse results for restricted h-fold sumset in integers","summary":"Let $A$ be a finite set of $k$ integers. For $h \\leq k$, the restricted\n$h$-fold sumset $h^{\\wedge} A$ is the set of all sums of $h$ distinct elements\nof $A$. In additive combinatorics, much of the focus has traditionally been on\nfinite integer sets whose sumsets are unusually small (cf.\\ Freiman's theorem\nand its extensions). More recently, Nathanson posed the inverse problem for the\nrestricted sumset $h^{\\wedge} A$ when $|h^{\\wedge} A|$ is small. For $h \\in\n\\{2, 3, 4\\}$, this question has already been studied by Mohan and Pandey. In\nthis article, we study the inverse problems for $h^{\\wedge} A$ with arbitrary\n$h \\geq 3$ and characterize all possible sets $A$ for certain cardinalities of\n$h^{\\wedge} A$.","main_category":"math.CO","categories":"math.CO","published":"2025-05-12T10:08:55Z"}
{"aid":"http://arxiv.org/abs/2505.07427v1","title":"A Value of Information-based assessment of strain-based thickness loss\n  monitoring in ship hull structures","summary":"Recent advances in Structural Health Monitoring (SHM) have attracted industry\ninterest, yet real-world applications, such as in ship structures remain\nscarce. Despite SHM's potential to optimise maintenance, its adoption in ships\nis limited due to the lack of clearly quantifiable benefits for hull\nmaintenance. This study employs a Bayesian pre-posterior decision analysis to\nquantify the value of information (VoI) from SHM systems monitoring\ncorrosion-induced thickness loss (CITL) in ship hulls, in a first-of-its-kind\nanalysis for ship structures. We define decision-making consequence cost\nfunctions based on exceedance probabilities relative to a target CITL\nthreshold, which can be set by the decision-maker. This introduces a practical\naspect to our framework, that enables implicitly modelling the decision-maker's\nrisk perception. We apply this framework to a large-scale, high-fidelity\nnumerical model of a commercial vessel and examine the relative benefits of\ndifferent CITL monitoring strategies, including strain-based SHM and\ntraditional on-site inspections.","main_category":"stat.AP","categories":"stat.AP","published":"2025-05-12T10:34:41Z"}
{"aid":"http://arxiv.org/abs/2505.07430v1","title":"Comparative sentiment analysis of public perception: Monkeypox vs.\n  COVID-19 behavioral insights","summary":"The emergence of global health crises, such as COVID-19 and Monkeypox (mpox),\nhas underscored the importance of understanding public sentiment to inform\neffective public health strategies. This study conducts a comparative sentiment\nanalysis of public perceptions surrounding COVID-19 and mpox by leveraging\nextensive datasets of 147,475 and 106,638 tweets, respectively. Advanced\nmachine learning models, including Logistic Regression, Naive Bayes, RoBERTa,\nDistilRoBERTa and XLNet, were applied to perform sentiment classification, with\nresults indicating key trends in public emotion and discourse. The analysis\nhighlights significant differences in public sentiment driven by disease\ncharacteristics, media representation, and pandemic fatigue. Through the lens\nof sentiment polarity and thematic trends, this study offers valuable insights\ninto tailoring public health messaging, mitigating misinformation, and\nfostering trust during concurrent health crises. The findings contribute to\nadvancing sentiment analysis applications in public health informatics, setting\nthe groundwork for enhanced real-time monitoring and multilingual analysis in\nfuture research.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-05-12T10:37:33Z"}
{"aid":"http://arxiv.org/abs/2505.07439v1","title":"Isotropy Test with Quasars Using Method of Smoothed Residuals","summary":"To assess the significance and scale dependence of anomalous large scale\nmodes in the CatWISE quasar data, we generate smoothed number density fields on\nthe sphere and study their extreme values -- maximum, minimum, maximum\nantipodal difference. By comparing these summary statistics to those obtained\nfrom random isotropic realisations of the data, we determine the statistical\nsignificance of large scale modes as a function of smoothing scale. We perform\nour analysis using five different versions of the data -- the original quasar\nmap, the maps after separately subtracting the ecliptic bias and the CMB\ndipole, the map obtained after subtracting both, and the map after subtracting\nthe ecliptic bias and anomalous dipole inferred in \\cite{Secrest2021}. We find\nthat the ecliptic-corrected, CMB dipole-removed map exhibits large scale modes\nthat are in tension with random realisations of the data (p-values $p \\sim\n10^{-4}$), over a wide range of smoothing scales $\\pi/8 \\leq \\delta \\leq\n\\pi/2$. The most prominent feature in the data is an underdensity in the\nsouthern galactic plane at $(b,\\ell) = (-31^\\circ,78^\\circ)$, which reaches its\nhighest statistical significance when smoothed on scales $\\delta = \\pi/6$ ($p\n\\ll 10^{-5}$). Notably, the minima statistics align with the maximum antipodal\ndifference statistics, whereas the maxima do not. This suggests that the\nobserved dipole-like behavior in the data is primarily driven by the\nunderdensity in the southern sky. The ecliptic corrected, anomalous dipole\nsubtracted map reduces the significance of any residual anisotropic features,\nbut an underdensity in the south sky persists with p-value $p =0.0018$.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-05-12T11:01:47Z"}
{"aid":"http://arxiv.org/abs/2505.07449v1","title":"Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video\n  Generation Model","summary":"In ophthalmic surgery, developing an AI system capable of interpreting\nsurgical videos and predicting subsequent operations requires numerous\nophthalmic surgical videos with high-quality annotations, which are difficult\nto collect due to privacy concerns and labor consumption. Text-guided video\ngeneration (T2V) emerges as a promising solution to overcome this issue by\ngenerating ophthalmic surgical videos based on surgeon instructions. In this\npaper, we present Ophora, a pioneering model that can generate ophthalmic\nsurgical videos following natural language instructions. To construct Ophora,\nwe first propose a Comprehensive Data Curation pipeline to convert narrative\nophthalmic surgical videos into a large-scale, high-quality dataset comprising\nover 160K video-instruction pairs, Ophora-160K. Then, we propose a Progressive\nVideo-Instruction Tuning scheme to transfer rich spatial-temporal knowledge\nfrom a T2V model pre-trained on natural video-text datasets for\nprivacy-preserved ophthalmic surgical video generation based on Ophora-160K.\nExperiments on video quality evaluation via quantitative analysis and\nophthalmologist feedback demonstrate that Ophora can generate realistic and\nreliable ophthalmic surgical videos based on surgeon instructions. We also\nvalidate the capability of Ophora for empowering downstream tasks of ophthalmic\nsurgical workflow understanding. Code is available at\nhttps://github.com/mar-cry/Ophora.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-12T11:23:37Z"}
{"aid":"http://arxiv.org/abs/2505.07454v1","title":"From Brain to Motion: Harnessing Higher-Derivative Mechanics for Neural\n  Control","summary":"Optimal Feedback Control (OFC) provides a theoretical framework for\ngoal-directed movements, where the nervous system adjusts actions based on\nsensory feedback. In OFC, the central nervous system (CNS) not only reacts to\nstimuli but proactively predicts and adjusts motor commands, minimizing errors\nand (often energetic) costs through internal models. OFC theory assumes that\nthere exists a cost function that is optimized throughout one's movement. It is\nnatural to assume that mechanical quantities should be involved in cost\nfunctions. This does not imply that the mechanical principles that govern human\nvoluntary movements are necessarily Newtonian. Indeed, the undisputed\nefficiency of Newtonian mechanics to model and predict the motion of non-living\nsystems does not guarantee its relevance to model human behavior. We propose\nthat integrating principles from Lagrangian and Hamiltonian higher-derivative\nmechanics, i.e. dynamical models that go beyond Newtonian mechanics, provides a\nmore natural framework to study the constraints hidden in human voluntary\nmovement within OFC theory.","main_category":"q-bio.NC","categories":"q-bio.NC,physics.class-ph","published":"2025-05-12T11:37:12Z"}
{"aid":"http://arxiv.org/abs/2505.07455v1","title":"GelFusion: Enhancing Robotic Manipulation under Visual Constraints via\n  Visuotactile Fusion","summary":"Visuotactile sensing offers rich contact information that can help mitigate\nperformance bottlenecks in imitation learning, particularly under\nvision-limited conditions, such as ambiguous visual cues or occlusions.\nEffectively fusing visual and visuotactile modalities, however, presents\nongoing challenges. We introduce GelFusion, a framework designed to enhance\npolicies by integrating visuotactile feedback, specifically from\nhigh-resolution GelSight sensors. GelFusion using a vision-dominated\ncross-attention fusion mechanism incorporates visuotactile information into\npolicy learning. To better provide rich contact information, the framework's\ncore component is our dual-channel visuotactile feature representation,\nsimultaneously leveraging both texture-geometric and dynamic interaction\nfeatures. We evaluated GelFusion on three contact-rich tasks: surface wiping,\npeg insertion, and fragile object pick-and-place. Outperforming baselines,\nGelFusion shows the value of its structure in improving the success rate of\npolicy learning.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-12T11:37:35Z"}
{"aid":"http://arxiv.org/abs/2505.07462v1","title":"Large-area topological wireless power transfer","summary":"Topological wireless power transfer (WPT) technologies have attracted\nconsiderable interest due to their high transmission efficiency and robustness\nin coupled array configurations. However, conventional periodic and\nquasi-periodic topological chains exhibit limited adaptability in complex\napplication scenarios, such as large-area simultaneous multi-load charging. In\nthis work, we experimentally demonstrate a large-area topological defect state\nby constructing a gapless chain of uniformly coupled resonators at the\ninterface of two topologically distinct Su-Schrieffer-Heeger (SSH)\nconfigurations. This topological defect state exhibits strong localization at\nmultiple target sites, enabling efficient and concurrent wireless power\ndelivery to spatially distributed loads. Furthermore, the unique wavefunction\ndistribution enhances robustness against positional variations, ensuring stable\nenergy transfer despite fluctuations in device placement. The proposed\nlarge-area topological framework offers fundamental insights into harnessing\ndiverse topological states for advanced WPT applications, particularly in\nscenarios demanding spatial flexibility and multi-target energy delivery.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-05-12T11:49:09Z"}
{"aid":"http://arxiv.org/abs/2505.07474v1","title":"Statistical analysis of Bell tests via generalized measurements","summary":"We provide a fully statistical analysis of the results of a Bell test beyond\nmean values. This is possible in a practical scheme where all the observables\ninvolved in the test are simultaneously measured at the expense of unavoidably\nadditional noise. To deal with this noise we can follow two strategies leading\nto the same results. These are to adapt the Bell bound to include the noise, or\nto remove the additional noise via suitable data inversion.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-12T12:06:29Z"}
{"aid":"http://arxiv.org/abs/2505.07477v1","title":"You Only Look One Step: Accelerating Backpropagation in Diffusion\n  Sampling with Gradient Shortcuts","summary":"Diffusion models (DMs) have recently demonstrated remarkable success in\nmodeling large-scale data distributions. However, many downstream tasks require\nguiding the generated content based on specific differentiable metrics,\ntypically necessitating backpropagation during the generation process. This\napproach is computationally expensive, as generating with DMs often demands\ntens to hundreds of recursive network calls, resulting in high memory usage and\nsignificant time consumption. In this paper, we propose a more efficient\nalternative that approaches the problem from the perspective of parallel\ndenoising. We show that full backpropagation throughout the entire generation\nprocess is unnecessary. The downstream metrics can be optimized by retaining\nthe computational graph of only one step during generation, thus providing a\nshortcut for gradient propagation. The resulting method, which we call Shortcut\nDiffusion Optimization (SDO), is generic, high-performance, and computationally\nlightweight, capable of optimizing all parameter types in diffusion sampling.\nWe demonstrate the effectiveness of SDO on several real-world tasks, including\ncontrolling generation by optimizing latent and aligning the DMs by fine-tuning\nnetwork parameters. Compared to full backpropagation, our approach reduces\ncomputational costs by $\\sim 90\\%$ while maintaining superior performance. Code\nis available at https://github.com/deng-ai-lab/SDO.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-05-12T12:09:11Z"}
{"aid":"http://arxiv.org/abs/2505.07484v1","title":"Integrated Localization and Path Planning for an Ocean Exploring Team of\n  Autonomous Underwater Vehicles with Consensus Graph Model Predictive Control","summary":"Navigation of a team of autonomous underwater vehicles (AUVs) coordinated by\nan unmanned surface vehicle (USV) is efficient and reliable for deep ocean\nexploration. AUVs depart from and return to the USV after collaborative\nnavigation, data collection, and ocean exploration missions. Efficient path\nplanning and accurate localization are essential, the latter of which is\ncritical due to the lack of global localization signals and poor radio\nfrequency (RF) communication in deep waters. Inertial navigation and acoustic\ncommunication are common solutions for localization. However, the former is\nsubject to odometry drifts, and the latter is limited to short distances. This\npaper proposes a systematic approach for localization-aware energy-efficient\ncollision-free path planning for a USV-AUVs team. Path planning is formulated\nas finite receding horizon model predictive control (MPC) optimization. A\ndynamic-aware linear kinodynamic motion equation is developed. The mathematical\nformulation for the MPC optimization is effectively developed where\nlocalization is integrated as consensus graph optimization among AUV nodes.\nEdges in the optimized AUV-to-USV (A2U) and AUV-to-AUV (A2A) graphs are\nconstrained to the sonar range of acoustic modems. The time complexity of the\nconsensus MPC optimization problem is analyzed, revealing a nonconvex NP-hard\nproblem, which is solved using sequential convex programming. Numerical\nsimulation results are provided to evaluate the proposed method.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-12T12:14:50Z"}
{"aid":"http://arxiv.org/abs/2505.07487v1","title":"Linux Kernel Configurations at Scale: A Dataset for Performance and\n  Evolution Analysis","summary":"Configuring the Linux kernel to meet specific requirements, such as binary\nsize, is highly challenging due to its immense complexity-with over 15,000\ninterdependent options evolving rapidly across different versions. Although\nseveral studies have explored sampling strategies and machine learning methods\nto understand and predict the impact of configuration options, the literature\nstill lacks a comprehensive and large-scale dataset encompassing multiple\nkernel versions along with detailed quantitative measurements. To bridge this\ngap, we introduce LinuxData, an accessible collection of kernel configurations\nspanning several kernel releases, specifically from versions 4.13 to 5.8. This\ndataset, gathered through automated tools and build processes, comprises over\n240,000 kernel configurations systematically labeled with compilation outcomes\nand binary sizes. By providing detailed records of configuration evolution and\ncapturing the intricate interplay among kernel options, our dataset enables\ninnovative research in feature subset selection, prediction models based on\nmachine learning, and transfer learning across kernel versions. Throughout this\npaper, we describe how the dataset has been made easily accessible via OpenML\nand illustrate how it can be leveraged using only a few lines of Python code to\nevaluate AI-based techniques, such as supervised machine learning. We\nanticipate that this dataset will significantly enhance reproducibility and\nfoster new insights into configuration-space analysis at a scale that presents\nunique opportunities and inherent challenges, thereby advancing our\nunderstanding of the Linux kernel's configurability and evolution.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-05-12T12:19:46Z"}
{"aid":"http://arxiv.org/abs/2505.07500v1","title":"Learning to Reason and Navigate: Parameter Efficient Action Planning\n  with Large Language Models","summary":"The remote embodied referring expression (REVERIE) task requires an agent to\nnavigate through complex indoor environments and localize a remote object\nspecified by high-level instructions, such as \"bring me a spoon\", without\npre-exploration. Hence, an efficient navigation plan is essential for the final\nsuccess. This paper proposes a novel parameter-efficient action planner using\nlarge language models (PEAP-LLM) to generate a single-step instruction at each\nlocation. The proposed model consists of two modules, LLM goal planner (LGP)\nand LoRA action planner (LAP). Initially, LGP extracts the goal-oriented plan\nfrom REVERIE instructions, including the target object and room. Then, LAP\ngenerates a single-step instruction with the goal-oriented plan, high-level\ninstruction, and current visual observation as input. PEAP-LLM enables the\nembodied agent to interact with LAP as the path planner on the fly. A simple\ndirect application of LLMs hardly achieves good performance. Also, existing\nhard-prompt-based methods are error-prone in complicated scenarios and need\nhuman intervention. To address these issues and prevent the LLM from generating\nhallucinations and biased information, we propose a novel two-stage method for\nfine-tuning the LLM, consisting of supervised fine-tuning (STF) and direct\npreference optimization (DPO). SFT improves the quality of generated\ninstructions, while DPO utilizes environmental feedback. Experimental results\nshow the superiority of our proposed model on REVERIE compared to the previous\nstate-of-the-art.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T12:38:20Z"}
{"aid":"http://arxiv.org/abs/2505.07526v1","title":"Saturation theorems for neural network operators by solving elliptic and\n  hyperbolic PDEs with analytical and semi-analytical inverse problems","summary":"This paper addresses inverse problems (in a broad sense) for two classes of\nmultivariate neural network (NN) operators, with particular emphasis on\nsaturation results, and both analytical and semi-analytical inverse theorems.\nOne of the key aspects in addressing these issues is solving of certain\nelliptic and hyperbolic partial differential equations (PDEs), as well as\nsuitable asymptotic formulas for the NN operators based on sufficiently smooth\nfunctions; the connection between these two topics lies in the application of\nthe so-called generalized parabola technique by Ditzian. From the saturation\ntheorems characterizations of the saturation classes are derived; these are\nrespectively related to harmonic functions and to the solution of a certain\ntransport equation. Analytical inverse theorems, on the other hand, are related\nto sub-harmonic functions as well as to functions in the Sobolev space\n$W^2_\\infty$. Finally, the problem of reconstructing data affected by noise is\naddressed, along with a semi-analytical inverse problem. The latter serves as\nthe starting point for deriving a retrieval procedure that may be useful in\nreal world applications.","main_category":"math.FA","categories":"math.FA","published":"2025-05-12T13:09:04Z"}
{"aid":"http://arxiv.org/abs/2505.07528v1","title":"SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via\n  Semantic Entropy and Context-Parameter Fusion","summary":"Retrieval-Augmented Generation (RAG) models frequently encounter\nhallucination phenomena when integrating external information with internal\nparametric knowledge. Empirical studies demonstrate that the disequilibrium\nbetween external contextual information and internal parametric knowledge\nconstitutes a primary factor in hallucination generation. Existing\nhallucination detection methodologies predominantly emphasize either the\nexternal or internal mechanism in isolation, thereby overlooking their\nsynergistic effects. The recently proposed ReDeEP framework decouples these\ndual mechanisms, identifying two critical contributors to hallucinations:\nexcessive reliance on parametric knowledge encoded in feed-forward networks\n(FFN) and insufficient utilization of external information by attention\nmechanisms (particularly copy heads). ReDeEP quantitatively assesses these\nfactors to detect hallucinations and dynamically modulates the contributions of\nFFNs and copy heads to attenuate their occurrence. Nevertheless, ReDeEP and\nnumerous other hallucination detection approaches have been employed at\nlogit-level uncertainty estimation or language-level self-consistency\nevaluation, inadequately address the semantic dimensions of model responses,\nresulting in inconsistent hallucination assessments in RAG implementations.\nBuilding upon ReDeEP's foundation, this paper introduces SEReDeEP, which\nenhances computational processes through semantic entropy captured via trained\nlinear probes, thereby achieving hallucination assessments that more accurately\nreflect ground truth evaluations.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-12T13:10:46Z"}
{"aid":"http://arxiv.org/abs/2505.07533v1","title":"IKrNet: A Neural Network for Detecting Specific Drug-Induced Patterns in\n  Electrocardiograms Amidst Physiological Variability","summary":"Monitoring and analyzing electrocardiogram (ECG) signals, even under varying\nphysiological conditions, including those influenced by physical activity,\ndrugs and stress, is crucial to accurately assess cardiac health. However,\ncurrent AI-based methods often fail to account for how these factors interact\nand alter ECG patterns, ultimately limiting their applicability in real-world\nsettings. This study introduces IKrNet, a novel neural network model, which\nidentifies drug-specific patterns in ECGs amidst certain physiological\nconditions. IKrNet's architecture incorporates spatial and temporal dynamics by\nusing a convolutional backbone with varying receptive field size to capture\nspatial features. A bi-directional Long Short-Term Memory module is also\nemployed to model temporal dependencies. By treating heart rate variability as\na surrogate for physiological fluctuations, we evaluated IKrNet's performance\nacross diverse scenarios, including conditions with physical stress, drug\nintake alone, and a baseline without drug presence. Our assessment follows a\nclinical protocol in which 990 healthy volunteers were administered 80mg of\nSotalol, a drug which is known to be a precursor to Torsades-de-Pointes, a\nlife-threatening arrhythmia. We show that IKrNet outperforms state-of-the-art\nmodels' accuracy and stability in varying physiological conditions,\nunderscoring its clinical viability.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-12T13:14:47Z"}
{"aid":"http://arxiv.org/abs/2505.07547v1","title":"Space-Time Beamforming for LEO Satellite Communications","summary":"Inter-beam interference poses a significant challenge in low Earth orbit\n(LEO) satellite communications due to dense satellite constellations. To\naddress this issue, we introduce spacetime beamforming, a novel paradigm that\nleverages the spacetime channel vector, uniquely determined by the angle of\narrival (AoA) and relative Doppler shift, to optimize beamforming between a\nmoving satellite transmitter and a ground station user. We propose two\nspace-time beamforming techniques: spacetime zero-forcing (ST-ZF) and\nspace-time signal-to-leakage-plus-noise ratio (ST-SLNR) maximization. In a\npartially connected interference channel, ST-ZF achieves a 3dB SNR gain over\nthe conventional interference avoidance method using maximum ratio transmission\nbeamforming. Moreover, in general interference networks, ST-SLNR beamforming\nsignificantly enhances sum spectral efficiency compared to conventional\ninterference management approaches. These results demonstrate the effectiveness\nof space-time beamforming in improving spectral efficiency and interference\nmitigation for next-generation LEO satellite networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-12T13:28:09Z"}
{"aid":"http://arxiv.org/abs/2505.07567v1","title":"Superstring entanglement at finite temperature and its Hagedorn behavior","summary":"In this work it is shown that at finite temperature there is entanglement\nbetween the coordinates of the string. Using a real-time approach, the\nentanglement entropy for the vacuum state is computed and written in terms of\nmodular functions whose properties are used to study its Hagedorn behavior.","main_category":"hep-th","categories":"hep-th","published":"2025-05-12T13:50:19Z"}
{"aid":"http://arxiv.org/abs/2505.07582v1","title":"Modelling higher education dropouts using sparse and interpretable\n  post-clustering logistic regression","summary":"Higher education dropout constitutes a critical challenge for tertiary\neducation systems worldwide. While machine learning techniques can achieve high\npredictive accuracy on selected datasets, their adoption by policymakers\nremains limited and unsatisfactory, particularly when the objective is the\nunsupervised identification and characterization of student subgroups at\nelevated risk of dropout. The model introduced in this paper is a specialized\nform of logistic regression, specifically adapted to the context of university\ndropout analysis. Logistic regression continues to serve as a foundational tool\namong reliable statistical models, primarily due to the ease with which its\nparameters can be interpreted in terms of odds ratios. Our approach\nsignificantly extends this framework by incorporating heterogeneity within the\nstudent population. This is achieved through the application of a preliminary\nclustering algorithm that identifies latent subgroups, each characterized by\ndistinct dropout propensities, which are then modeled via cluster-specific\neffects. We provide a detailed interpretation of the model parameters within\nthis extended framework and enhance interpretability by imposing sparsity\nthrough a tailored variant of the LASSO algorithm. To demonstrate the practical\napplicability of the proposed methodology, we present an extensive case study\nbased on the Italian university system, in which all the developed tools are\nsystematically applied","main_category":"stat.AP","categories":"stat.AP,stat.ML","published":"2025-05-12T14:05:23Z"}
{"aid":"http://arxiv.org/abs/2505.07587v1","title":"Performance and Design Validation of CMS Phase-2 Pixel Modules","summary":"In view of the High Luminosity LHC, the current CMS tracking detector will\nhave to be replaced during Long Shutdown 3 to cope with the higher radiation\nenvironment and to withstand an increased data rate. To prepare for the\nso-called CMS Phase-2 upgrade, multiple studies were carried out to\ncharacterize the pixel module design and its performance with a particular\nfocus on the Quality Control (QC) and Assurance. For this purpose, different\naspects were put together to establish a module full-performance test\nprocedure, and novel techniques became part of the module design validation\nprocess for the full-size readout chip (CROCv1). Based on the results collected\non CROCv1 prototype modules and according to the module selection criteria the\ncommunity agreed on, some changes were introduced in the module design to\nimprove the performance. This resulted in multiple prototype versions,\nincluding the production of the definitive chip (CROCv2). This study presents\nthe quality control test flow performed, both for the dual and quad-chip module\ndesigns, on a big sample of CROCv1 prototypes and on several Kick-off and\nCROCv2 pre-production modules. In particular, the validation process includes\nmeasurements of the readout chip powering, sensor IV bias and open bump bonds\nidentification. Thermal stress tests in extended temperature ranges were\nperformed only on a subset of pixel modules to ensure the integrity of the\nsensor and to provide quick feedback on the quality of the bump bond\nconnectivity after harsh temperature cycles.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-05-12T14:15:09Z"}
{"aid":"http://arxiv.org/abs/2505.07591v1","title":"A Multi-Dimensional Constraint Framework for Evaluating and Improving\n  Instruction Following in Large Language Models","summary":"Instruction following evaluates large language models (LLMs) on their ability\nto generate outputs that adhere to user-defined constraints. However, existing\nbenchmarks often rely on templated constraint prompts, which lack the diversity\nof real-world usage and limit fine-grained performance assessment. To fill this\ngap, we propose a multi-dimensional constraint framework encompassing three\nconstraint patterns, four constraint categories, and four difficulty levels.\nBuilding on this framework, we develop an automated instruction generation\npipeline that performs constraint expansion, conflict detection, and\ninstruction rewriting, yielding 1,200 code-verifiable instruction-following\ntest samples. We evaluate 19 LLMs across seven model families and uncover\nsubstantial variation in performance across constraint forms. For instance,\naverage performance drops from 77.67% at Level I to 32.96% at Level IV.\nFurthermore, we demonstrate the utility of our approach by using it to generate\ndata for reinforcement learning, achieving substantial gains in instruction\nfollowing without degrading general performance. In-depth analysis indicates\nthat these gains stem primarily from modifications in the model's attention\nmodules parameters, which enhance constraint recognition and adherence. Code\nand data are available in https://github.com/Junjie-Ye/MulDimIF.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-12T14:16:55Z"}
{"aid":"http://arxiv.org/abs/2505.07601v1","title":"Characterizing the Investigative Methods of Fictional Detectives with\n  Large Language Models","summary":"Detective fiction, a genre defined by its complex narrative structures and\ncharacter-driven storytelling, presents unique challenges for computational\nnarratology, a research field focused on integrating literary theory into\nautomated narrative generation. While traditional literary studies have offered\ndeep insights into the methods and archetypes of fictional detectives, these\nanalyses often focus on a limited number of characters and lack the scalability\nneeded for the extraction of unique traits that can be used to guide narrative\ngeneration methods. In this paper, we present an AI-driven approach for\nsystematically characterizing the investigative methods of fictional\ndetectives. Our multi-phase workflow explores the capabilities of 15 Large\nLanguage Models (LLMs) to extract, synthesize, and validate distinctive\ninvestigative traits of fictional detectives. This approach was tested on a\ndiverse set of seven iconic detectives - Hercule Poirot, Sherlock Holmes,\nWilliam Murdoch, Columbo, Father Brown, Miss Marple, and Auguste Dupin -\ncapturing the distinctive investigative styles that define each character. The\nidentified traits were validated against existing literary analyses and further\ntested in a reverse identification phase, achieving an overall accuracy of\n91.43%, demonstrating the method's effectiveness in capturing the distinctive\ninvestigative approaches of each detective. This work contributes to the\nbroader field of computational narratology by providing a scalable framework\nfor character analysis, with potential applications in AI-driven interactive\nstorytelling and automated narrative generation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-12T14:24:58Z"}
{"aid":"http://arxiv.org/abs/2505.07615v1","title":"Diffused Responsibility: Analyzing the Energy Consumption of Generative\n  Text-to-Audio Diffusion Models","summary":"Text-to-audio models have recently emerged as a powerful technology for\ngenerating sound from textual descriptions. However, their high computational\ndemands raise concerns about energy consumption and environmental impact. In\nthis paper, we conduct an analysis of the energy usage of 7 state-of-the-art\ntext-to-audio diffusion-based generative models, evaluating to what extent\nvariations in generation parameters affect energy consumption at inference\ntime. We also aim to identify an optimal balance between audio quality and\nenergy consumption by considering Pareto-optimal solutions across all selected\nmodels. Our findings provide insights into the trade-offs between performance\nand environmental impact, contributing to the development of more efficient\ngenerative audio models.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.LG,cs.SD","published":"2025-05-12T14:36:47Z"}
{"aid":"http://arxiv.org/abs/2505.07621v1","title":"Bang for the Buck: Vector Search on Cloud CPUs","summary":"Vector databases have emerged as a new type of systems that support efficient\nquerying of high-dimensional vectors. Many of these offer their database as a\nservice in the cloud. However, the variety of available CPUs and the lack of\nvector search benchmarks across CPUs make it difficult for users to choose one.\nIn this study, we show that CPU microarchitectures available in the cloud\nperform significantly differently across vector search scenarios. For instance,\nin an IVF index on float32 vectors, AMD's Zen4 gives almost 3x more queries per\nsecond (QPS) compared to Intel's Sapphire Rapids, but for HNSW indexes, the\ntables turn. However, when looking at the number of queries per dollar (QP$),\nGraviton3 is the best option for most indexes and quantization settings, even\nover Graviton4 (Table 1). With this work, we hope to guide users in getting the\nbest \"bang for the buck\" when deploying vector search systems.","main_category":"cs.DB","categories":"cs.DB,cs.AI","published":"2025-05-12T14:44:21Z"}
{"aid":"http://arxiv.org/abs/2505.07622v1","title":"A Unified Hierarchical Framework for Fine-grained Cross-view\n  Geo-localization over Large-scale Scenarios","summary":"Cross-view geo-localization is a promising solution for large-scale\nlocalization problems, requiring the sequential execution of retrieval and\nmetric localization tasks to achieve fine-grained predictions. However,\nexisting methods typically focus on designing standalone models for these two\ntasks, resulting in inefficient collaboration and increased training overhead.\nIn this paper, we propose UnifyGeo, a novel unified hierarchical\ngeo-localization framework that integrates retrieval and metric localization\ntasks into a single network. Specifically, we first employ a unified learning\nstrategy with shared parameters to jointly learn multi-granularity\nrepresentation, facilitating mutual reinforcement between these two tasks.\nSubsequently, we design a re-ranking mechanism guided by a dedicated loss\nfunction, which enhances geo-localization performance by improving both\nretrieval accuracy and metric localization references. Extensive experiments\ndemonstrate that UnifyGeo significantly outperforms the state-of-the-arts in\nboth task-isolated and task-associated settings. Remarkably, on the challenging\nVIGOR benchmark, which supports fine-grained localization evaluation, the\n1-meter-level localization recall rate improves from 1.53\\% to 39.64\\% and from\n0.43\\% to 25.58\\% under same-area and cross-area evaluations, respectively.\nCode will be made publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T14:44:31Z"}
{"aid":"http://arxiv.org/abs/2505.07628v1","title":"On the RG flow of the Newton and cosmological constant","summary":"In this note we comment on the RG flow of the Newton and cosmological\nconstants, also in view of some recent claims [1] that would rise some doubts\non the validity of our recent work [2,3]. Here we show that the arguments and\nclaims of [1] are seriously flawed and cannot be trusted.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-05-12T14:53:33Z"}
{"aid":"http://arxiv.org/abs/2505.07629v1","title":"Enhancing Federated Learning with Kolmogorov-Arnold Networks: A\n  Comparative Study Across Diverse Aggregation Strategies","summary":"Multilayer Perceptron (MLP), as a simple yet powerful model, continues to be\nwidely used in classification and regression tasks. However, traditional MLPs\noften struggle to efficiently capture nonlinear relationships in load data when\ndealing with complex datasets. Kolmogorov-Arnold Networks (KAN), inspired by\nthe Kolmogorov-Arnold representation theorem, have shown promising capabilities\nin modeling complex nonlinear relationships. In this study, we explore the\nperformance of KANs within federated learning (FL) frameworks and compare them\nto traditional Multilayer Perceptrons. Our experiments, conducted across four\ndiverse datasets demonstrate that KANs consistently outperform MLPs in terms of\naccuracy, stability, and convergence efficiency. KANs exhibit remarkable\nrobustness under varying client numbers and non-IID data distributions,\nmaintaining superior performance even as client heterogeneity increases.\nNotably, KANs require fewer communication rounds to converge compared to MLPs,\nhighlighting their efficiency in FL scenarios. Additionally, we evaluate\nmultiple parameter aggregation strategies, with trimmed mean and FedProx\nemerging as the most effective for optimizing KAN performance. These findings\nestablish KANs as a robust and scalable alternative to MLPs for federated\nlearning tasks, paving the way for their application in decentralized and\nprivacy-preserving environments.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-12T14:56:27Z"}
{"aid":"http://arxiv.org/abs/2505.07643v1","title":"Approximate MLE of High-Dimensional STAP Covariance Matrices with Banded\n  & Spiked Structure -- A Convex Relaxation Approach","summary":"Estimating the clutter-plus-noise covariance matrix in high-dimensional STAP\nis challenging in the presence of Internal Clutter Motion (ICM) and a high\nnoise floor. The problem becomes more difficult in low-sample regimes, where\nthe Sample Covariance Matrix (SCM) becomes ill-conditioned. To capture the ICM\nand high noise floor, we model the covariance matrix using a ``Banded+Spiked''\nstructure. Since the Maximum Likelihood Estimation (MLE) for this model is\nnon-convex, we propose a convex relaxation which is formulated as a Frobenius\nnorm minimization with non-smooth convex constraints enforcing banded sparsity.\nThis relaxation serves as a provable upper bound for the non-convex likelihood\nmaximization and extends to cases where the covariance matrix dimension exceeds\nthe number of samples. We derive a variational inequality-based bound to assess\nits quality. We introduce a novel algorithm to jointly estimate the banded\nclutter covariance and noise power. Additionally, we establish conditions\nensuring the estimated covariance matrix remains positive definite and the\nbandsize is accurately recovered. Numerical results using the high-fidelity\nRFView radar simulation environment demonstrate that our algorithm achieves a\nhigher Signal-to-Clutter-plus-Noise Ratio (SCNR) than state-of-the-art methods,\nincluding TABASCO, Spiked Covariance Stein Shrinkage, and Diagonal Loading,\nparticularly when the covariance matrix dimension exceeds the number of\nsamples.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-12T15:13:22Z"}
{"aid":"http://arxiv.org/abs/2505.07659v1","title":"Using Information Theory to Characterize Prosodic Typology: The Case of\n  Tone, Pitch-Accent and Stress-Accent","summary":"This paper argues that the relationship between lexical identity and prosody\n-- one well-studied parameter of linguistic variation -- can be characterized\nusing information theory. We predict that languages that use prosody to make\nlexical distinctions should exhibit a higher mutual information between word\nidentity and prosody, compared to languages that don't. We test this hypothesis\nin the domain of pitch, which is used to make lexical distinctions in tonal\nlanguages, like Cantonese. We use a dataset of speakers reading sentences aloud\nin ten languages across five language families to estimate the mutual\ninformation between the text and their pitch curves. We find that, across\nlanguages, pitch curves display similar amounts of entropy. However, these\ncurves are easier to predict given their associated text in the tonal\nlanguages, compared to pitch- and stress-accent languages, and thus the mutual\ninformation is higher in these languages, supporting our hypothesis. Our\nresults support perspectives that view linguistic typology as gradient, rather\nthan categorical.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-12T15:25:17Z"}
{"aid":"http://arxiv.org/abs/2505.07662v1","title":"An investigation of air pollution-induced temperature sensitivity and\n  susceptibility to heat-related hospitalization in the Medicare population","summary":"Background: With rising temperatures and an aging US population,\nunderstanding how to prevent heat-related illness among older Americans will be\nan increasingly critical objective. Despite biological plausibility, no study\nto date has investigated how exposure to fine particulate matter air pollution\n(PM$_{2.5}$) may contribute to risk of heat-related hospitalization.\n  Methods: We identified Medicare fee-for-service beneficiaries who experienced\na heat-related hospitalization between 2008 and 2016. Using a case-crossover\ndesign and fitting Bayesian conditional logistic regression models, we\ncharacterized the association between heat-related hospitalization and\ntemperature and PM$_{2.5}$ exposures. We estimated the relative excess risk due\nto interaction (RERI) to quantify the additive-scale interaction of\nsimultaneous exposure to heat and PM$_{2.5}$.\n  Results: We observed 112,969 heat-related hospitalizations. Fixing PM$_{2.5}$\nat the case day median, increasing temperature from its case day median to the\n95th percentile was associated with an odds ratio of 1.045 (95% CI: 1.026,\n1.063). Fixing temperature at the case day median and increasing PM$_{2.5}$\nfrom its median to the 95th percentile was associated with an odds ratio of\n1.014 (95% CI: 0.993, 1.037). We estimated the RERI associated with\nsimultaneous median-to-95th percentile increases in temperature and PM$_{2.5}$\nto be 0.032 (0.007, 0.057).\n  Conclusion: Using nationwide Medicare claims and a self-matched study design,\nwe found evidence supporting synergism between temperature and PM$_{2.5}$\nexposures on the risk of heat-related hospitalization.","main_category":"stat.AP","categories":"stat.AP","published":"2025-05-12T15:30:06Z"}
{"aid":"http://arxiv.org/abs/2505.07668v1","title":"Intuitive Human-Robot Interfaces Leveraging on Autonomy Features for the\n  Control of Highly-redundant Robots","summary":"[...] With the TelePhysicalOperation interface, the user can teleoperate the\ndifferent capabilities of a robot (e.g., single/double arm manipulation,\nwheel/leg locomotion) by applying virtual forces on selected robot body parts.\nThis approach emulates the intuitiveness of physical human-robot interaction,\nbut at the same time it permits to teleoperate the robot from a safe distance,\nin a way that resembles a \"Marionette\" interface. The system is further\nenhanced with wearable haptic feedback functions to align better with the\n\"Marionette\" metaphor, and a user study has been conducted to validate its\nefficacy with and without the haptic channel enabled. Considering the\nimportance of robot independence, the TelePhysicalOperation interface\nincorporates autonomy modules to face, for example, the teleoperation of\ndual-arm mobile base robots for bimanual object grasping and transportation\ntasks.\n  With the laser-guided interface, the user can indicate points of interest to\nthe robot through the utilization of a simple but effective laser emitter\ndevice. With a neural network-based vision system, the robot tracks the laser\nprojection in real time, allowing the user to indicate not only fixed goals,\nlike objects, but also paths to follow. With the implemented autonomous\nbehavior, a mobile manipulator employs its locomanipulation abilities to follow\nthe indicated goals. The behavior is modeled using Behavior Trees, exploiting\ntheir reactivity to promptly respond to changes in goal positions, and their\nmodularity to adapt the motion planning to the task needs. The proposed laser\ninterface has also been employed in an assistive scenario. In this case, users\nwith upper limbs impairments can control an assistive manipulator by directing\na head-worn laser emitter to the point of interests, to collaboratively address\nactivities of everyday life. [...]","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-12T15:33:43Z"}
{"aid":"http://arxiv.org/abs/2505.07670v1","title":"DATAMUt: Deterministic Algorithms for Time-Delay Attack Detection in\n  Multi-Hop UAV Networks","summary":"Unmanned Aerial Vehicles (UAVs), also known as drones, have gained popularity\nin various fields such as agriculture, emergency response, and search and\nrescue operations. UAV networks are susceptible to several security threats,\nsuch as wormhole, jamming, spoofing, and false data injection. Time Delay\nAttack (TDA) is a unique attack in which malicious UAVs intentionally delay\npacket forwarding, posing significant threats, especially in time-sensitive\napplications. It is challenging to distinguish malicious delay from benign\nnetwork delay due to the dynamic nature of UAV networks, intermittent wireless\nconnectivity, or the Store-Carry-Forward (SCF) mechanism during multi-hop\ncommunication. Some existing works propose machine learning-based centralized\napproaches to detect TDA, which are computationally intensive and have large\nmessage overheads. This paper proposes a novel approach DATAMUt, where the\ntemporal dynamics of the network are represented by a weighted time-window\ngraph (TWiG), and then two deterministic polynomial-time algorithms are\npresented to detect TDA when UAVs have global and local network knowledge.\nSimulation studies show that the proposed algorithms have reduced message\noverhead by a factor of five and twelve in global and local knowledge,\nrespectively, compared to existing approaches. Additionally, our approaches\nachieve approximately 860 and 1050 times less execution time in global and\nlocal knowledge, respectively, outperforming the existing methods.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-12T15:34:23Z"}
{"aid":"http://arxiv.org/abs/2505.07675v1","title":"Simple Semi-supervised Knowledge Distillation from Vision-Language\n  Models via $\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead\n  $\\mathbf{\\texttt{O}}$ptimization","summary":"Vision-language models (VLMs) have achieved remarkable success across diverse\ntasks by leveraging rich textual information with minimal labeled data.\nHowever, deploying such large models remains challenging, particularly in\nresource-constrained environments. Knowledge distillation (KD) offers a\nwell-established solution to this problem; however, recent KD approaches from\nVLMs often involve multi-stage training or additional tuning, increasing\ncomputational overhead and optimization complexity. In this paper, we propose\n$\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead\n$\\mathbf{\\texttt{O}}$ptimization ($\\mathbf{\\texttt{DHO}}$) -- a simple yet\neffective KD framework that transfers knowledge from VLMs to compact,\ntask-specific models in semi-supervised settings. Specifically, we introduce\ndual prediction heads that independently learn from labeled data and teacher\npredictions, and propose to linearly combine their outputs during inference. We\nobserve that $\\texttt{DHO}$ mitigates gradient conflicts between supervised and\ndistillation signals, enabling more effective feature learning than single-head\nKD baselines. As a result, extensive experiments show that $\\texttt{DHO}$\nconsistently outperforms baselines across multiple domains and fine-grained\ndatasets. Notably, on ImageNet, it achieves state-of-the-art performance,\nimproving accuracy by 3% and 0.1% with 1% and 10% labeled data, respectively,\nwhile using fewer parameters.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-05-12T15:39:51Z"}
{"aid":"http://arxiv.org/abs/2505.07676v1","title":"Transfer Learning Across Fixed-Income Product Classes","summary":"We propose a framework for transfer learning of discount curves across\ndifferent fixed-income product classes. Motivated by challenges in estimating\ndiscount curves from sparse or noisy data, we extend kernel ridge regression\n(KR) to a vector-valued setting, formulating a convex optimization problem in a\nvector-valued reproducing kernel Hilbert space (RKHS). Each component of the\nsolution corresponds to the discount curve implied by a specific product class.\nWe introduce an additional regularization term motivated by economic\nprinciples, promoting smoothness of spread curves between product classes, and\nshow that it leads to a valid separable kernel structure. A main theoretical\ncontribution is a decomposition of the vector-valued RKHS norm induced by\nseparable kernels. We further provide a Gaussian process interpretation of\nvector-valued KR, enabling quantification of estimation uncertainty.\nIllustrative examples demonstrate that transfer learning significantly improves\nextrapolation performance and tightens confidence intervals compared to\nsingle-curve estimation.","main_category":"stat.ML","categories":"stat.ML,cs.LG,q-fin.CP,q-fin.MF","published":"2025-05-12T15:43:29Z"}
{"aid":"http://arxiv.org/abs/2505.07689v1","title":"Anatomical Attention Alignment representation for Radiology Report\n  Generation","summary":"Automated Radiology report generation (RRG) aims at producing detailed\ndescriptions of medical images, reducing radiologists' workload and improving\naccess to high-quality diagnostic services. Existing encoder-decoder models\nonly rely on visual features extracted from raw input images, which can limit\nthe understanding of spatial structures and semantic relationships, often\nresulting in suboptimal text generation. To address this, we propose Anatomical\nAttention Alignment Network (A3Net), a framework that enhance visual-textual\nunderstanding by constructing hyper-visual representations. Our approach\nintegrates a knowledge dictionary of anatomical structures with patch-level\nvisual features, enabling the model to effectively associate image regions with\ntheir corresponding anatomical entities. This structured representation\nimproves semantic reasoning, interpretability, and cross-modal alignment,\nultimately enhancing the accuracy and clinical relevance of generated reports.\nExperimental results on IU X-Ray and MIMIC-CXR datasets demonstrate that A3Net\nsignificantly improves both visual perception and text generation quality. Our\ncode is available at \\href{https://github.com/Vinh-AI/A3Net}{GitHub}.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T15:54:50Z"}
{"aid":"http://arxiv.org/abs/2505.07693v1","title":"Belief Injection for Epistemic Control in Linguistic State Space","summary":"This work introduces belief injection, a proactive epistemic control\nmechanism for artificial agents whose cognitive states are structured as\ndynamic ensembles of linguistic belief fragments. Grounded in the Semantic\nManifold framework, belief injection directly incorporates targeted linguistic\nbeliefs into an agent's internal cognitive state, influencing reasoning and\nalignment proactively rather than reactively. We delineate various injection\nstrategies, such as direct, context-aware, goal-oriented, and reflective\napproaches, and contrast belief injection with related epistemic control\nmechanisms, notably belief filtering. Additionally, this work discusses\npractical applications, implementation considerations, ethical implications,\nand outlines promising directions for future research into cognitive governance\nusing architecturally embedded belief injection.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-12T15:58:56Z"}
{"aid":"http://arxiv.org/abs/2505.07694v1","title":"FD-RIO: Fast Dense Radar Inertial Odometry","summary":"Radar-based odometry is a popular solution for ego-motion estimation in\nconditions where other exteroceptive sensors may degrade, whether due to poor\nlighting or challenging weather conditions; however, scanning radars have the\ndownside of relatively lower sampling rate and spatial resolution. In this\nwork, we present FD-RIO, a method to alleviate this problem by fusing noisy,\ndrift-prone, but high-frequency IMU data with dense radar scans. To the best of\nour knowledge, this is the first attempt to fuse dense scanning radar odometry\nwith IMU using a Kalman filter. We evaluate our methods using two publicly\navailable datasets and report accuracies using standard KITTI evaluation\nmetrics, in addition to ablation tests and runtime analysis. Our phase\ncorrelation -based approach is compact, intuitive, and is designed to be a\npractical solution deployable on a realistic hardware setup of a mobile\nplatform. Despite its simplicity, FD-RIO is on par with other state-of-the-art\nmethods and outperforms in some test sequences.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-12T16:03:14Z"}
{"aid":"http://arxiv.org/abs/2505.07698v1","title":"A Likelihood Ratio Framework for Highly Motivated Subdominant Signals","summary":"In particle physics and cosmology, distinguishing subtle new physics signals\nfrom established backgrounds is always a fundamental challenge for individual\nphenomenologists. This paper presents a simple and robust statistical framework\nto evaluate the compatibility of highly motivated (HM) theoretical models with\nthe residual of the experimental results, focusing on scenarios where data\nappears consistent with background predictions. We develop a likelihood ratio\ntest procedure that compares null and alternative hypotheses, emphasizing cases\nwhere new physics introduces small deviations from the background. We\ndemonstrate the approach through two concrete examples, a localized excess and\na modulation over an oscillatory background. We derive explicit conditions\nunder which the effect of the background on the residual of the data must be\naccounted for. The framework's practicality is highlighted and in addition to\nthe limitation, strategies to simplify complex background modeling are\ndiscussed.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-05-12T16:05:53Z"}
{"aid":"http://arxiv.org/abs/2505.07704v1","title":"Through the Looking Glass: Common Sense Consistency Evaluation of Weird\n  Images","summary":"Measuring how real images look is a complex task in artificial intelligence\nresearch. For example, an image of a boy with a vacuum cleaner in a desert\nviolates common sense. We introduce a novel method, which we call Through the\nLooking Glass (TLG), to assess image common sense consistency using Large\nVision-Language Models (LVLMs) and Transformer-based encoder. By leveraging\nLVLMs to extract atomic facts from these images, we obtain a mix of accurate\nfacts. We proceed by fine-tuning a compact attention-pooling classifier over\nencoded atomic facts. Our TLG has achieved a new state-of-the-art performance\non the WHOOPS! and WEIRD datasets while leveraging a compact fine-tuning\ncomponent.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-05-12T16:12:11Z"}
{"aid":"http://arxiv.org/abs/2505.07709v1","title":"ISAC: An Invertible and Stable Auditory Filter Bank with Customizable\n  Kernels for ML Integration","summary":"This paper introduces ISAC, an invertible and stable, perceptually-motivated\nfilter bank that is specifically designed to be integrated into machine\nlearning paradigms. More precisely, the center frequencies and bandwidths of\nthe filters are chosen to follow a non-linear, auditory frequency scale, the\nfilter kernels have user-defined maximum temporal support and may serve as\nlearnable convolutional kernels, and there exists a corresponding filter bank\nsuch that both form a perfect reconstruction pair. ISAC provides a powerful and\nuser-friendly audio front-end suitable for any application, including\nanalysis-synthesis schemes.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-05-12T16:15:59Z"}
{"aid":"http://arxiv.org/abs/2505.07713v1","title":"Routing Attacks in Ethereum PoS: A Systematic Exploration","summary":"With the promise of greater decentralization and sustainability, Ethereum\ntransitioned from a Proof-of-Work (PoW) to a Proof-of-Stake (PoS) consensus\nmechanism. The new consensus protocol introduces novel vulnerabilities that\nwarrant further investigation. The goal of this paper is to investigate the\nsecurity of Ethereum's PoS system from an Internet routing perspective.\n  To this end, this paper makes two contributions: First, we devise a novel\nframework for inferring the distribution of validators on the Internet without\ndisturbing the real network. Second, we introduce a class of network-level\nattacks on Ethereum's PoS system that jointly exploit Internet routing\nvulnerabilities with the protocol's reward and penalty mechanisms. We describe\ntwo representative attacks: StakeBleed, where the attacker triggers an\ninactivity leak, halting block finality and causing financial losses for all\nvalidators; and KnockBlock, where the attacker increases her expected MEV gains\nby preventing targeted blocks from being included in the chain. We find that\nboth attacks are practical and effective. An attacker executing StakeBleed can\ninflict losses of almost 300 ETH in just 2 hours by hijacking as few as 30 IP\nprefixes. An attacker implementing KnockBlock could increase their MEV expected\ngains by 44.5% while hijacking a single prefix for less than 2 minutes.\n  Our paper serves as a call to action for validators to reinforce their\nInternet routing infrastructure and for the Ethereum P2P protocol to implement\nstronger mechanisms to conceal validator locations.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-12T16:19:03Z"}
{"aid":"http://arxiv.org/abs/2505.07725v1","title":"Quantum Process Tomography with Digital Twins of Error Matrices","summary":"Accurate and robust quantum process tomography (QPT) is crucial for verifying\nquantum gates and diagnosing implementation faults in experiments aimed at\nbuilding universal quantum computers. However, the reliability of QPT protocols\nis often compromised by faulty probes, particularly state preparation and\nmeasurement (SPAM) errors, which introduce fundamental inconsistencies in\ntraditional QPT algorithms. We propose and investigate enhanced QPT for\nmulti-qubit systems by integrating the error matrix in a digital twin of the\nidentity process matrix, enabling statistical refinement of SPAM error learning\nand improving QPT precision. Through numerical simulations, we demonstrate that\nour approach enables highly accurate and faithful process characterization. We\nfurther validate our method experimentally using superconducting quantum gates,\nachieving at least an order-of-magnitude fidelity improvement over standard\nQPT. Our results provide a practical and precise method for assessing quantum\ngate fidelity and enhancing QPT on a given hardware.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-12T16:34:41Z"}
{"aid":"http://arxiv.org/abs/2505.07728v1","title":"Guiding Data Collection via Factored Scaling Curves","summary":"Generalist imitation learning policies trained on large datasets show great\npromise for solving diverse manipulation tasks. However, to ensure\ngeneralization to different conditions, policies need to be trained with data\ncollected across a large set of environmental factor variations (e.g., camera\npose, table height, distractors) $-$ a prohibitively expensive undertaking, if\ndone exhaustively. We introduce a principled method for deciding what data to\ncollect and how much to collect for each factor by constructing factored\nscaling curves (FSC), which quantify how policy performance varies as data\nscales along individual or paired factors. These curves enable targeted data\nacquisition for the most influential factor combinations within a given budget.\nWe evaluate the proposed method through extensive simulated and real-world\nexperiments, across both training-from-scratch and fine-tuning settings, and\nshow that it boosts success rates in real-world tasks in new environments by up\nto 26% over existing data-collection strategies. We further demonstrate how\nfactored scaling curves can effectively guide data collection using an offline\nmetric, without requiring real-world evaluation at scale.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-05-12T16:36:35Z"}
{"aid":"http://arxiv.org/abs/2505.07740v1","title":"Pan-genome Analysis of Plastomes from Lamiales using PGR-TK","summary":"Chloroplast sequences from the Lamiales order were analyzed using the\nPangenome Research Toolkit (PGR-TK). Overall, most genera and families\nexhibited a high degree of sequence uniformity. However, at the genus level,\nUtricularia, Incarvillea, and Orobanche stood out as particularly divergent. At\nthe family level, Orobanchaceae, Bignoniaceae and Lentibulariaceae displayed\nnotably complex patterns in the generated plots. The PGR-TK algorithm\nsuccessfully distinguished most genera within their respective families and\noften recognized misclassified plants.","main_category":"q-bio.GN","categories":"q-bio.GN,q-bio.PE","published":"2025-05-12T16:49:38Z"}
{"aid":"http://arxiv.org/abs/2505.07743v1","title":"When Near Becomes Far: From Rayleigh to Optimal Near-Field and Far-Field\n  Boundaries","summary":"The transition toward 6G is pushing wireless communication into a regime\nwhere the classical plane-wave assumption no longer holds. Millimeter-wave and\nsub-THz frequencies shrink wavelengths to millimeters, while meter-scale arrays\nfeaturing hundreds of antenna elements dramatically enlarge the aperture.\nTogether, these trends collapse the classical Rayleigh far-field boundary from\nkilometers to mere single-digit meters. Consequently, most practical 6G indoor,\nvehicular, and industrial deployments will inherently operate within the\nradiating near-field, where reliance on the plane-wave approximation leads to\nsevere array-gain losses, degraded localization accuracy, and excessive pilot\noverhead. This paper re-examines the fundamental question: Where does the\nfar-field truly begin? Rather than adopting purely geometric definitions, we\nintroduce an application-oriented approach based on user-defined error budgets\nand a rigorous Fresnel-zone analysis that fully accounts for both amplitude and\nphase curvature. We propose three practical mismatch metrics: worst-case\nelement mismatch, worst-case normalized mean square error, and spectral\nefficiency loss. For each metric, we derive a provably optimal transition\ndistance--the minimal range beyond which mismatch permanently remains below a\ngiven tolerance--and provide closed-form solutions. Extensive numerical\nevaluations across diverse frequencies and antenna-array dimensions show that\nour proposed thresholds can exceed the Rayleigh distance by more than an order\nof magnitude. By transforming the near-field from a design nuisance into a\nprecise, quantifiable tool, our results provide a clear roadmap for enabling\nreliable and resource-efficient near-field communications and sensing in\nemerging 6G systems.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-12T16:51:22Z"}
{"aid":"http://arxiv.org/abs/2505.07745v1","title":"Spatio-temporal spin transport from first principles","summary":"We introduce a computational framework for first-principles density matrix\ntransport within the Wigner function formalism to predict transport of\nquantum-mechanical degrees of freedom such as spin over long time and length\nscales. This framework facilitates simulation of spin dynamics and transport\nfrom first principles, while accounting for electron-phonon scattering at\ndevice length scales. We demonstrate this framework to elucidate the impact of\nvarious spin-orbit field profiles, such as Rashba and persistent spin helix, on\ncoherent spin transport in several materials. Using graphene under an electric\nfield as an example to illustrate the impact of electron-phonon scattering on\nincoherent transport, we show how the transport changes with the strength of\nscattering. We identify three distinct regimes of incoherent spin transport\ncorresponding to the free induction decay, Dyakonov-Perel and Elliott-Yafet\nregimes of spin relaxation. In particular, we show that the spin diffusion\nlength is insensitive to the strength of scattering within the Dyakonov-Perel\nregime.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,physics.comp-ph","published":"2025-05-12T16:54:30Z"}
{"aid":"http://arxiv.org/abs/2505.07764v1","title":"Why is the Star Formation Rate Proportional to Dense Gas Mass?","summary":"One of the most profound empirical laws of star formation is the Gao-Solomon\nrelation, a linear correlation between the star formation rate (SFR) and the\ndense molecular gas mass. It is puzzling how the complicated physics in\nstar-formation results in this surprisingly simple proportionality. Using\narchival Herschel and Atacama Large Millimeter/submillimeter Array\nObservations, we derived the masses of the most massive cores ($M^{\\rm\nmax}_{\\rm core}$) and masses of the gravitationally bound gas ($ M_{\\rm\ngas}^{\\rm bound}$) in the parent molecular clouds for a sample of low-mass and\nhigh-mass star-forming regions. We discovered a significant correlation\n$\\log(M^{\\rm max}_{\\rm core}/M_{\\odot}) = 0.506 \\log(M_{\\rm gas}^{\\rm\nbound}/M_{\\odot})-0.32$. Our discovered $M^{\\rm max}_{\\rm core}$-$M_{\\rm\ngas}^{\\rm bound}$ correlation can be approximately converted to the Gao-Solomon\nrelation if there is (1) a constant 30% efficiency of converting $M^{\\rm\nmax}_{\\rm core}$ to the mass of the most massive star ($m^{\\rm max}_{\\rm\nstar}$), and (2) if SFR and $m^{\\rm max}_{\\rm star}$ are tightly related\nthrough $\\log({\\rm SFR}/(M_{\\odot} {\\rm yr}^{-1})) = 2.04 \\log(m^{\\rm max}_{\\rm\nstar}/M_{\\odot})-5.80$. Intriguingly, both requirements have been suggested by\nprevious theoretical studies (c.f. Yan et al. 2017). Based on this result, we\nhypothesize that the Gao-Solomon relation is a consequence of combining the\nfollowing three non-trivial relations (i) SFR vs. $m^{\\rm max}_{\\rm star}$,\n(ii) $m^{\\rm max}_{\\rm star}$ vs. $M^{\\rm max}_{\\rm core}$, and (iii) $M^{\\rm\nmax}_{\\rm core}$ vs. $M_{\\rm gas}^{\\rm bound}$. This finding may open a new\npossibility to understand the Gao-Solomon relation in an analytic sense.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-12T17:10:36Z"}
{"aid":"http://arxiv.org/abs/2505.07767v1","title":"Non-linear flow of two-dimensional viscous electron fluid in moderate\n  magnetic fields","summary":"In two-dimensional (2D) electron systems, the inter-particle interaction can\nlead to the formation of a viscous electron fluid and realization of the\nhydrodynamic regime of electron transport. Here a nonlinear model of the\nelectron hydrodynamic transport is constructed based on the accounting of pair\ncorrelations in the electron dynamics. When describing these systems within the\nframework of classical kinetics, such correlations represent subsequent\n``extended'' collisions of the same electrons temporarily joined into pairs. We\nstudy their influence on stationary magnetotransport for large-amplitude fluid\nflows in long samples. Current profiles in the nonlinear regime and the\ncorresponding differential magnetoresistance are calculated. Pair correlations\nlead to a characteristic nonmonotonic dependence of the differential resistance\non magnetic field. We compare our results with experimental data on\nmagnetoresistance of 2D electrons in high-purity GaAs quantum wells; our model\ncan be responsible for a part of the observed features of the differential\nmagnetoresistance.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-05-12T17:18:18Z"}
{"aid":"http://arxiv.org/abs/2505.07776v1","title":"Robo-Taxi Fleet Coordination with Accelerated High-Capacity Ridepooling","summary":"Rapid urbanization has led to a surge of customizable mobility demand in\nurban areas, which makes on-demand services increasingly popular. On-demand\nservices are flexible while reducing the need for private cars, thus mitigating\ncongestion and parking issues in limited urban space. While the coordination of\nhigh-capacity ridepooling on-demand service requires effective control to\nensure efficiency, the emergence of the paradigm of robo-taxi opens the\nopportunity for centralized fleet control for an improved service quality. In\nthis work, we propose two acceleration algorithms for the most advanced\nlarge-scale high-capacity algorithm proposed in [1]. We prove the improvement\nin the real-time performance of the algorithm by using real-world on-demand\ndata from Manhattan, NYC.","main_category":"math.OC","categories":"math.OC","published":"2025-05-12T17:26:32Z"}
{"aid":"http://arxiv.org/abs/2505.07783v1","title":"Relative Overfitting and Accept-Reject Framework","summary":"Currently, the scaling law of Large Language Models (LLMs) faces challenges\nand bottlenecks. This paper posits that noise effects, stemming from changes in\nthe signal-to-noise ratio under diminishing marginal returns, are the root\ncause of these issues. To control this noise, we investigated the differences\nbetween models with performance advantages and disadvantages, introducing the\nconcept of \"relative overfitting.\" Based on their complementary strengths, we\nhave proposed an application framework, Accept-Reject (AR). In Natural Language\nProcessing (NLP), we use LLMs and Small Language Models (SLMs) as the medium\nfor discussion. This framework enables SLMs to exert a universal positive\ninfluence on LLM decision outputs, rather than the intuitively expected\nnegative influence. We validated our approach using self-built models based on\nmainstream architectures and pre-trained mainstream models across multiple\ndatasets, including basic language modeling, long-context tasks, subject\nexamination, and question-answering (QA) benchmarks. The results demonstrate\nthat through our structure, compared to increasing the LLM's parameters, we can\nachieve better performance improvements with significantly lower parameter and\ncomputational costs in many scenarios. These improvements are universal,\nstable, and effective. Furthermore, we explore the potential of \"relative\noverfitting\" and the AR framework in other machine learning domains, such as\ncomputer vision (CV) and AI for science. We hope the proposed approach can help\nscale laws overcome existing bottlenecks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-12T17:36:14Z"}
{"aid":"http://arxiv.org/abs/2505.07792v1","title":"Analytic theory of dropout regularization","summary":"Dropout is a regularization technique widely used in training artificial\nneural networks to mitigate overfitting. It consists of dynamically\ndeactivating subsets of the network during training to promote more robust\nrepresentations. Despite its widespread adoption, dropout probabilities are\noften selected heuristically, and theoretical explanations of its success\nremain sparse. Here, we analytically study dropout in two-layer neural networks\ntrained with online stochastic gradient descent. In the high-dimensional limit,\nwe derive a set of ordinary differential equations that fully characterize the\nevolution of the network during training and capture the effects of dropout. We\nobtain a number of exact results describing the generalization error and the\noptimal dropout probability at short, intermediate, and long training times.\nOur analysis shows that dropout reduces detrimental correlations between hidden\nnodes, mitigates the impact of label noise, and that the optimal dropout\nprobability increases with the level of noise in the data. Our results are\nvalidated by extensive numerical simulations.","main_category":"stat.ML","categories":"stat.ML,cond-mat.dis-nn,cond-mat.stat-mech,cs.LG","published":"2025-05-12T17:45:02Z"}
{"aid":"http://arxiv.org/abs/2505.07807v1","title":"Two-step phase transitions in Fe(Se,Te)","summary":"In the studied crystals of FeSe0.7 Te0.3 , a structural phase transition\noccurs in two stages. At higher temperatures, the electronic subsystem\nundergoes a reconstruction, leading to a significant increase in\nelastoresistance. 77 Se NMR data show an abrupt change in the relaxation rate\nduring this transition. The final transition occurs at a temperature several\ndegrees below and is also accompanied by anomalies in the electronic\nproperties. Thus, in the Fe(Se,Te) series, similarly to the behavior of pure\nFeSe under pressure, the type of transition changes and intermediate state\nappear before the structural transition is suppressed. This similarity between\nthe corresponding phase diagrams is explained by the same deformation of the\niron coordination environment in Fe(Se,Te) compounds and in FeSe under\npressure. Our findings provide new and significant information on the phase\ndiagram of Fe(Se,Te) compounds and in particular suggest the possible existence\nof a triple point near the quantum critical point.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-05-12T17:55:28Z"}
{"aid":"http://arxiv.org/abs/2505.07812v1","title":"Continuous Visual Autoregressive Generation via Score Maximization","summary":"Conventional wisdom suggests that autoregressive models are used to process\ndiscrete data. When applied to continuous modalities such as visual data,\nVisual AutoRegressive modeling (VAR) typically resorts to quantization-based\napproaches to cast the data into a discrete space, which can introduce\nsignificant information loss. To tackle this issue, we introduce a Continuous\nVAR framework that enables direct visual autoregressive generation without\nvector quantization. The underlying theoretical foundation is strictly proper\nscoring rules, which provide powerful statistical tools capable of evaluating\nhow well a generative model approximates the true distribution. Within this\nframework, all we need is to select a strictly proper score and set it as the\ntraining objective to optimize. We primarily explore a class of training\nobjectives based on the energy score, which is likelihood-free and thus\novercomes the difficulty of making probabilistic predictions in the continuous\nspace. Previous efforts on continuous autoregressive generation, such as GIVT\nand diffusion loss, can also be derived from our framework using other strictly\nproper scores. Source code: https://github.com/shaochenze/EAR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T17:58:14Z"}
{"aid":"http://arxiv.org/abs/2505.07815v1","title":"Imagine, Verify, Execute: Memory-Guided Agentic Exploration with\n  Vision-Language Models","summary":"Exploration is essential for general-purpose robotic learning, especially in\nopen-ended environments where dense rewards, explicit goals, or task-specific\nsupervision are scarce. Vision-language models (VLMs), with their semantic\nreasoning over objects, spatial relations, and potential outcomes, present a\ncompelling foundation for generating high-level exploratory behaviors. However,\ntheir outputs are often ungrounded, making it difficult to determine whether\nimagined transitions are physically feasible or informative. To bridge the gap\nbetween imagination and execution, we present IVE (Imagine, Verify, Execute),\nan agentic exploration framework inspired by human curiosity. Human exploration\nis often driven by the desire to discover novel scene configurations and to\ndeepen understanding of the environment. Similarly, IVE leverages VLMs to\nabstract RGB-D observations into semantic scene graphs, imagine novel scenes,\npredict their physical plausibility, and generate executable skill sequences\nthrough action tools. We evaluate IVE in both simulated and real-world tabletop\nenvironments. The results show that IVE enables more diverse and meaningful\nexploration than RL baselines, as evidenced by a 4.1 to 7.8x increase in the\nentropy of visited states. Moreover, the collected experience supports\ndownstream learning, producing policies that closely match or exceed the\nperformance of those trained on human-collected demonstrations.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.LG","published":"2025-05-12T17:59:11Z"}
{"aid":"http://arxiv.org/abs/2505.08197v1","title":"Visual Watermarking in the Era of Diffusion Models: Advances and\n  Challenges","summary":"As generative artificial intelligence technologies like Stable Diffusion\nadvance, visual content becomes more vulnerable to misuse, raising concerns\nabout copyright infringement. Visual watermarks serve as effective protection\nmechanisms, asserting ownership and deterring unauthorized use. Traditional\ndeepfake detection methods often rely on passive techniques that struggle with\nsophisticated manipulations. In contrast, diffusion models enhance detection\naccuracy by allowing for the effective learning of features, enabling the\nembedding of imperceptible and robust watermarks. We analyze the strengths and\nchallenges of watermark techniques related to diffusion models, focusing on\ntheir robustness and application in watermark generation. By exploring the\nintegration of advanced diffusion models and watermarking security, we aim to\nadvance the discourse on preserving watermark robustness against evolving\nforgery threats. It emphasizes the critical importance of developing innovative\nsolutions to protect digital content and ensure the preservation of ownership\nrights in the era of generative AI.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T03:14:18Z"}
{"aid":"http://arxiv.org/abs/2505.08200v1","title":"A Head to Predict and a Head to Question: Pre-trained Uncertainty\n  Quantification Heads for Hallucination Detection in LLM Outputs","summary":"Large Language Models (LLMs) have the tendency to hallucinate, i.e., to\nsporadically generate false or fabricated information. This presents a major\nchallenge, as hallucinations often appear highly convincing and users generally\nlack the tools to detect them. Uncertainty quantification (UQ) provides a\nframework for assessing the reliability of model outputs, aiding in the\nidentification of potential hallucinations. In this work, we introduce\npre-trained UQ heads: supervised auxiliary modules for LLMs that substantially\nenhance their ability to capture uncertainty compared to unsupervised UQ\nmethods. Their strong performance stems from the powerful Transformer\narchitecture in their design and informative features derived from LLM\nattention maps. Experimental evaluation shows that these heads are highly\nrobust and achieve state-of-the-art performance in claim-level hallucination\ndetection across both in-domain and out-of-domain prompts. Moreover, these\nmodules demonstrate strong generalization to languages they were not explicitly\ntrained on. We pre-train a collection of UQ heads for popular LLM series,\nincluding Mistral, Llama, and Gemma 2. We publicly release both the code and\nthe pre-trained heads.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-13T03:30:26Z"}
{"aid":"http://arxiv.org/abs/2505.08204v1","title":"LM-Scout: Analyzing the Security of Language Model Integration in\n  Android Apps","summary":"Developers are increasingly integrating Language Models (LMs) into their\nmobile apps to provide features such as chat-based assistants. To prevent LM\nmisuse, they impose various restrictions, including limits on the number of\nqueries, input length, and allowed topics. However, if the LM integration is\ninsecure, attackers can bypass these restrictions and gain unrestricted access\nto the LM, potentially harming developers' reputations and leading to\nsignificant financial losses.\n  This paper presents the first systematic study of insecure usage of LMs by\nAndroid apps. We first manually analyze a preliminary dataset of apps to\ninvestigate LM integration methods, construct a taxonomy that categorizes the\nLM usage restrictions implemented by the apps, and determine how to bypass\nthem. Alarmingly, we can bypass restrictions in 127 out of 181 apps. Then, we\ndevelop LM-Scout, a fully automated tool to detect on a large-scale vulnerable\nusage of LMs in 2,950 mobile apps. LM-Scout shows that, in many cases (i.e.,\n120 apps), it is possible to find and exploit such security issues\nautomatically. Finally, we identify the root causes for the identified issues\nand offer recommendations for secure LM integration.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-13T03:37:23Z"}
{"aid":"http://arxiv.org/abs/2505.08206v1","title":"Accelerating Fermionic System Simulation on Quantum Computers","summary":"A potential approach for demonstrating quantum advantage is using quantum\ncomputers to simulate fermionic systems. Quantum algorithms for fermionic\nsystem simulation usually involve the Hamiltonian evolution and measurements.\nHowever, in the second quantization representation, the number of terms in many\nfermion-system Hamiltonians, such as molecular Hamiltonians, is substantial,\napproximately $\\mathcal{O}(N^4)$, where $N$ is the number of molecular\norbitals. Due to this, the computational resources required for Hamiltonian\nevolution and expectation value measurements could be excessively large. To\naddress this, we introduce a grouping strategy that partitions these\n$\\mathcal{O}(N^4)$ Hamiltonian terms into $\\mathcal{O}(N^2)$ groups, with the\nterms in each group mutually commuting. Based on this grouping method, we\npropose a parallel Hamiltonian evolution scheme that reduces the circuit depth\nof Hamiltonian evolution by a factor of $N$. Moreover, our grouping measurement\nstrategy reduces the number of measurements needed to $\\mathcal{O}(N^2)$,\nwhereas the current best grouping measurement schemes require\n$\\mathcal{O}(N^3)$ measurements. Additionally, we find that measuring the\nexpectation value of a group of Hamiltonian terms requires fewer repetitions\nthan measuring a single term individually, thereby reducing the number of\nquantum circuit executions. Our approach saves a factor of $N^3$ in the overall\ntime for Hamiltonian evolution and measurements, significantly decreasing the\ntime required for quantum computers to simulate fermionic systems.","main_category":"quant-ph","categories":"quant-ph,physics.chem-ph","published":"2025-05-13T03:44:07Z"}
{"aid":"http://arxiv.org/abs/2505.08226v1","title":"Bang-bang preparation of a quantum many-body ground state in a finite\n  lattice: optimization of the algorithm with a tensor network","summary":"A bang-bang (BB) algorithm prepares the ground state of a lattice quantum\nmany-body Hamiltonian $H=H_1+H_2$ by evolving an initial product state\nalternating between $H_1$ and $H_2$. We optimize the algorithm with tensor\nnetworks in one and two dimensions. The optimization has two stages. In stage\none, a shallow translationally-invariant circuit is optimized in an infinite\nlattice. In stage two, the infinite-lattice gate sequence is used as a starting\npoint for a finite lattice where it remains optimal in the bulk. The prepared\nstate requires optimization only at its boundary, within a healing length from\nlattice edges, and the gate sequence needs to be modified only within the\ncausal cone of the boundary. We test the procedure in the 1D and 2D quantum\nIsing model near its quantum critical point employing, respectively, the matrix\nproduct state (MPS) and the pair-entangled projected state (PEPS). At the\nboundary already the infinite-lattice sequence turns out to provide a more\naccurate state than in the bulk.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas","published":"2025-05-13T05:01:49Z"}
{"aid":"http://arxiv.org/abs/2505.08230v1","title":"SKiD-SLAM: Robust, Lightweight, and Distributed Multi-Robot LiDAR SLAM\n  in Resource-Constrained Field Environments","summary":"Distributed LiDAR SLAM is crucial for achieving efficient robot autonomy and\nimproving the scalability of mapping. However, two issues need to be considered\nwhen applying it in field environments: one is resource limitation, and the\nother is inter/intra-robot association. The resource limitation issue arises\nwhen the data size exceeds the processing capacity of the network or memory,\nespecially when utilizing communication systems or onboard computers in the\nfield. The inter/intra-robot association issue occurs due to the narrow\nconvergence region of ICP under large viewpoint differences, triggering many\nfalse positive loops and ultimately resulting in an inconsistent global map for\nmulti-robot systems. To tackle these problems, we propose a distributed LiDAR\nSLAM framework designed for versatile field applications, called SKiD-SLAM.\nExtending our previous work that solely focused on lightweight place\nrecognition and fast and robust global registration, we present a multi-robot\nmapping framework that focuses on robust and lightweight inter-robot loop\nclosure in distributed LiDAR SLAM. Through various environmental experiments,\nwe demonstrate that our method is more robust and lightweight compared to other\nstate-of-the-art distributed SLAM approaches, overcoming resource limitation\nand inter/intra-robot association issues. Also, we validated the field\napplicability of our approach through mapping experiments in real-world\nplanetary emulation terrain and cave environments, which are in-house datasets.\nOur code will be available at https://sparolab.github.io/research/skid_slam/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-13T05:17:26Z"}
{"aid":"http://arxiv.org/abs/2505.08233v1","title":"G-MSGINet: A Grouped Multi-Scale Graph-Involution Network for\n  Contactless Fingerprint Recognition","summary":"This paper presents G-MSGINet, a unified and efficient framework for robust\ncontactless fingerprint recognition that jointly performs minutiae localization\nand identity embedding directly from raw input images. Existing approaches rely\non multi-branch architectures, orientation labels, or complex preprocessing\nsteps, which limit scalability and generalization across real-world acquisition\nscenarios. In contrast, the proposed architecture introduces the GMSGI layer, a\nnovel computational module that integrates grouped pixel-level involution,\ndynamic multi-scale kernel generation, and graph-based relational modelling\ninto a single processing unit. Stacked GMSGI layers progressively refine both\nlocal minutiae-sensitive features and global topological representations\nthrough end-to-end optimization. The architecture eliminates explicit\norientation supervision and adapts graph connectivity directly from learned\nkernel descriptors, thereby capturing meaningful structural relationships among\nfingerprint regions without fixed heuristics. Extensive experiments on three\nbenchmark datasets, namely PolyU, CFPose, and Benchmark 2D/3D, demonstrate that\nG-MSGINet consistently achieves minutiae F1-scores in the range of\n$0.83\\pm0.02$ and Rank-1 identification accuracies between 97.0% and 99.1%,\nwhile maintaining an Equal Error Rate (EER) as low as 0.5%. These results\ncorrespond to improvements of up to 4.8% in F1-score and 1.4% in Rank-1\naccuracy when compared to prior methods, using only 0.38 million parameters and\n6.63 giga floating-point operations, which represents up to ten times fewer\nparameters than competitive baselines. This highlights the scalability and\neffectiveness of G-MSGINet in real-world contactless biometric recognition\nscenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T05:24:24Z"}
{"aid":"http://arxiv.org/abs/2505.08234v1","title":"Removing Watermarks with Partial Regeneration using Semantic Information","summary":"As AI-generated imagery becomes ubiquitous, invisible watermarks have emerged\nas a primary line of defense for copyright and provenance. The newest\nwatermarking schemes embed semantic signals - content-aware patterns that are\ndesigned to survive common image manipulations - yet their true robustness\nagainst adaptive adversaries remains under-explored. We expose a previously\nunreported vulnerability and introduce SemanticRegen, a three-stage, label-free\nattack that erases state-of-the-art semantic and invisible watermarks while\nleaving an image's apparent meaning intact. Our pipeline (i) uses a\nvision-language model to obtain fine-grained captions, (ii) extracts foreground\nmasks with zero-shot segmentation, and (iii) inpaints only the background via\nan LLM-guided diffusion model, thereby preserving salient objects and style\ncues. Evaluated on 1,000 prompts across four watermarking systems - TreeRing,\nStegaStamp, StableSig, and DWT/DCT - SemanticRegen is the only method to defeat\nthe semantic TreeRing watermark (p = 0.10 > 0.05) and reduces bit-accuracy\nbelow 0.75 for the remaining schemes, all while maintaining high perceptual\nquality (masked SSIM = 0.94 +/- 0.01). We further introduce masked SSIM (mSSIM)\nto quantify fidelity within foreground regions, showing that our attack\nachieves up to 12 percent higher mSSIM than prior diffusion-based attackers.\nThese results highlight an urgent gap between current watermark defenses and\nthe capabilities of adaptive, semantics-aware adversaries, underscoring the\nneed for watermarking algorithms that are resilient to content-preserving\nregenerative attacks.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-05-13T05:25:06Z"}
{"aid":"http://arxiv.org/abs/2505.08236v1","title":"Critical dynamics of three-dimensional $Z_N$ gauge models and the\n  inverted XY universality class","summary":"We investigate the critical relaxational dynamics of the three-dimensional\n(3D) lattice $Z_N$ gauge models with $N=6$ and $N=8$, whose equilibrium\ncritical behavior at their topological transitions belongs to the inverted XY\n(IXY) universality class (this is also the universality class of the continuous\ntransitions of the 3D lattice U(1) gauge Higgs models with a one-component\ncomplex scalar field), which is connected to the standard XY universality class\nby a nonlocal duality relation of the partition functions. Specifically, we\nconsider the purely relaxational dynamics realized by a locally reversible\nMetropolis dynamics, as commonly used in Monte Carlo simulations. To determine\nthe corresponding dynamic exponent $z$, we focus on the out-of-equilibrium\ncritical relaxational flows arising from instantaneous quenches to the critical\npoint, which are analyzed within an out-of-equilibrium finite-size scaling\nframework. We obtain the estimate $z=2.59(3)$. A numerical analysis of the\nequilibrium critical dynamics give consistent, but less accurate, results. This\ndynamic exponent is expected to characterize the critical slowing down of the\npurely relaxational dynamics of all topological transitions that belong to the\n3D IXY universality class. We note that this result implies that the critical\nrelaxational dynamics of the 3D IXY universality class is slower than that of\nthe standard 3D XY universality class, whose relaxational dynamic exponent\n$z\\approx 2.02$ is significantly smaller, although they share the same\nlength-scale critical exponent $\\nu\\approx 0.6717$.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,hep-lat","published":"2025-05-13T05:29:59Z"}
{"aid":"http://arxiv.org/abs/2505.08253v1","title":"Evaluating LLM Metrics Through Real-World Capabilities","summary":"As generative AI becomes increasingly embedded in everyday workflows, it is\nimportant to evaluate its performance in ways that reflect real-world usage\nrather than abstract notions of intelligence. Unlike many existing benchmarks\nthat assess general intelligence, our approach focuses on real-world utility,\nevaluating how well models support users in everyday tasks. While current\nbenchmarks emphasize code generation or factual recall, users rely on AI for a\nmuch broader range of activities-from writing assistance and summarization to\ncitation formatting and stylistic feedback. In this paper, we analyze\nlarge-scale survey data and usage logs to identify six core capabilities that\nrepresent how people commonly use Large Language Models (LLMs): Summarization,\nTechnical Assistance, Reviewing Work, Data Structuring, Generation, and\nInformation Retrieval. We then assess the extent to which existing benchmarks\ncover these capabilities, revealing significant gaps in coverage, efficiency\nmeasurement, and interpretability. Drawing on this analysis, we use\nhuman-centered criteria to identify gaps in how well current benchmarks reflect\ncommon usage that is grounded in five practical criteria: coherence, accuracy,\nclarity, relevance, and efficiency. For four of the six capabilities, we\nidentify the benchmarks that best align with real-world tasks and use them to\ncompare leading models. We find that Google Gemini outperforms other\nmodels-including OpenAI's GPT, xAI's Grok, Meta's LLaMA, Anthropic's Claude,\nDeepSeek, and Qwen from Alibaba-on these utility-focused metrics.","main_category":"cs.AI","categories":"cs.AI,I.2.7","published":"2025-05-13T06:02:37Z"}
{"aid":"http://arxiv.org/abs/2505.08254v1","title":"Efficient, simulation-free estimators of firing rates with Markovian\n  surrogates","summary":"Spiking neural networks (SNNs) are powerful mathematical models that\nintegrate the biological details of neural systems, but their complexity often\nmakes them computationally expensive and analytically untractable. The firing\nrate of an SNN is a crucial first-order statistic to characterize network\nactivity. However, estimating firing rates analytically from even simplified\nSNN models is challenging due to 1) the intricate dependence between the\nnonlinear network dynamics and parameters, and 2) the singularity and\nirreversibility of spikes. In this Letter, we propose a class of\ncomputationally efficient, simulation-free estimators of firing rates. This is\nbased on a hierarchy of Markovian approximations that reduces the complexity of\nSNN dynamics. We show that while considering firing rates alone is insufficient\nfor accurate estimations of themselves, the information of spiking synchrony\ndramatically improves the estimator's accuracy. This approach provides a\npractical tool for brain modelers, directly mapping biological parameters to\nfiring rate.","main_category":"q-bio.NC","categories":"q-bio.NC,math.PR","published":"2025-05-13T06:04:02Z"}
{"aid":"http://arxiv.org/abs/2505.08255v1","title":"Where the Devil Hides: Deepfake Detectors Can No Longer Be Trusted","summary":"With the advancement of AI generative techniques, Deepfake faces have become\nincredibly realistic and nearly indistinguishable to the human eye. To counter\nthis, Deepfake detectors have been developed as reliable tools for assessing\nface authenticity. These detectors are typically developed on Deep Neural\nNetworks (DNNs) and trained using third-party datasets. However, this protocol\nraises a new security risk that can seriously undermine the trustfulness of\nDeepfake detectors: Once the third-party data providers insert poisoned\n(corrupted) data maliciously, Deepfake detectors trained on these datasets will\nbe injected ``backdoors'' that cause abnormal behavior when presented with\nsamples containing specific triggers. This is a practical concern, as\nthird-party providers may distribute or sell these triggers to malicious users,\nallowing them to manipulate detector performance and escape accountability.\n  This paper investigates this risk in depth and describes a solution to\nstealthily infect Deepfake detectors. Specifically, we develop a trigger\ngenerator, that can synthesize passcode-controlled, semantic-suppression,\nadaptive, and invisible trigger patterns, ensuring both the stealthiness and\neffectiveness of these triggers. Then we discuss two poisoning scenarios,\ndirty-label poisoning and clean-label poisoning, to accomplish the injection of\nbackdoors. Extensive experiments demonstrate the effectiveness, stealthiness,\nand practicality of our method compared to several baselines.","main_category":"cs.CR","categories":"cs.CR,cs.CV","published":"2025-05-13T06:09:34Z"}
{"aid":"http://arxiv.org/abs/2505.08258v1","title":"Hybrid Wi-Fi/PDR Indoor Localization with Fingerprint Matching","summary":"Indoor position technology has become one of the research highlights in the\nInternet of Things (IoT), but there is still a lack of universal, low-cost, and\nhigh-precision solutions. This paper conducts research on indoor position\ntechnology based on location fingerprints and proposes a practical hybrid\nindoor positioning system. In this experiment, the location fingerprint\ndatabase is established by using RSS signal in the offline stage, the location\nalgorithm is improved and innovated in the online stage. The weighted k-nearest\nneighbor algorithm is used for location fingerprint matching and pedestrian\ndead reckoning technology is used for trajectory tracking. This paper designs\nand implements an indoor position system that performs the functions of data\ncollection, positioning, and position tracking. Through the test, it is found\nthat it can meet the requirements of indoor positioning.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-13T06:15:01Z"}
{"aid":"http://arxiv.org/abs/2505.08259v1","title":"CNN and ViT Efficiency Study on Tiny ImageNet and DermaMNIST Datasets","summary":"This study evaluates the trade-offs between convolutional and\ntransformer-based architectures on both medical and general-purpose image\nclassification benchmarks. We use ResNet-18 as our baseline and introduce a\nfine-tuning strategy applied to four Vision Transformer variants (Tiny, Small,\nBase, Large) on DermatologyMNIST and TinyImageNet. Our goal is to reduce\ninference latency and model complexity with acceptable accuracy degradation.\nThrough systematic hyperparameter variations, we demonstrate that appropriately\nfine-tuned Vision Transformers can match or exceed the baseline's performance,\nachieve faster inference, and operate with fewer parameters, highlighting their\nviability for deployment in resource-constrained environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T06:17:18Z"}
{"aid":"http://arxiv.org/abs/2505.08262v1","title":"Super-fast rates of convergence for Neural Networks Classifiers under\n  the Hard Margin Condition","summary":"We study the classical binary classification problem for hypothesis spaces of\nDeep Neural Networks (DNNs) with ReLU activation under Tsybakov's low-noise\ncondition with exponent $q>0$, and its limit-case $q\\to\\infty$ which we refer\nto as the \"hard-margin condition\". We show that DNNs which minimize the\nempirical risk with square loss surrogate and $\\ell_p$ penalty can achieve\nfinite-sample excess risk bounds of order $\\mathcal{O}\\left(n^{-\\alpha}\\right)$\nfor arbitrarily large $\\alpha>0$ under the hard-margin condition, provided that\nthe regression function $\\eta$ is sufficiently smooth. The proof relies on a\nnovel decomposition of the excess risk which might be of independent interest.","main_category":"cs.LG","categories":"cs.LG,math.ST,stat.TH","published":"2025-05-13T06:26:04Z"}
{"aid":"http://arxiv.org/abs/2505.08279v1","title":"The ErdÅ‘s--Ko--Rado Theorem in $\\ell_2$-Norm","summary":"The codegree squared sum ${\\rm co}_2(\\cal F)$ of a family (hypergraph) $\\cal\nF \\subseteq \\binom{[n]} k$ is defined to be the sum of codegrees squared\n$d(E)^2$ over all $E\\in \\binom{[n]}{k-1}$, where $d(E)=|\\{F\\in \\cal F:\nE\\subseteq F\\}|$. Given a family of $k$-uniform families $\\mathscr H$, Balogh,\nClemen and Lidick\\'y recently introduced the problem to determine the maximum\ncodegree squared sum ${\\rm co}_2(\\cal F)$ over all $\\mathscr H$-free $\\cal F$.\nIn the present paper, we consider the families which has as forbidden\nconfigurations all pairs of sets with intersection sizes less than $t$,\n  that is, the well-known $t$-intersecting families. We prove the following\nErd\\H{o}s--Ko--Rado Theorem in $\\ell_2$-norm, which confirms a conjecture of\nBrooks and Linz.\n  Let $t,k,n$ be positive integers such that $t\\leq k\\leq n$. If a family\n$\\mathcal F\\subseteq \\binom{[n]}{k}$ is $t$-intersecting, then for $n\\ge\n(t+1)(k-t+1)$, we have \\[{\\rm co}_2(\\cal F)\\le\n{\\binom{n-t}{k-t}}(t+(n-k+1)(k-t)),\\] equality holds if and only if\n$\\mathcal{F}=\\{F\\in {\\binom{[n]}{k}}: T\\subset F\\}$ for some $t$-subset $T$ of\n$[n]$.\n  In addition, we prove a Frankl--Hilton--Milner Theorem in $\\ell_2$-norm for\n$t\\ge 2$, and a generalized Tur\\'an result, i.e., we determine the maximum\nnumber of copies of tight path of length 2 in $t$-intersecting families.","main_category":"math.CO","categories":"math.CO","published":"2025-05-13T06:49:30Z"}
{"aid":"http://arxiv.org/abs/2505.08284v1","title":"Disruptive Transformation of Artworks in Master-Disciple Relationships:\n  The Case of Ukiyo-e Artworks","summary":"Artwork research has long relied on human sensibility and subjective\njudgment, but recent developments in machine learning have enabled the\nquantitative assessment of features that humans could not discover. In Western\npaintings, comprehensive analyses have been conducted from various perspectives\nin conjunction with large databases, but such extensive analysis has not been\nsufficiently conducted for Eastern paintings. Then, we focus on Ukiyo-e, a\ntraditional Japanese art form, as a case study of Eastern paintings, and\nconduct a quantitative analysis of creativity in works of art using 11,000\nhigh-resolution images. This involves using the concept of calculating\ncreativity from networks to analyze both the creativity of the artwork and that\nof the artists. As a result, In terms of Ukiyo-e as a whole, it was found that\nthe creativity of its appearance has declined with the maturation of culture,\nbut in terms of style, it has become more segmented with the maturation of\nculture and has maintained a high level of creativity. This not only provides\nnew insights into the study of Ukiyo-e but also shows how Ukiyo-e has evolved\nwithin the ongoing cultural history, playing a culturally significant role in\nthe analysis of Eastern art.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-05-13T06:55:53Z"}
{"aid":"http://arxiv.org/abs/2505.08285v1","title":"Limit theorems for elephant random walks remembering the recent past,\n  with applications to the Takagi-van der Waerden class functions","summary":"We study the Takagi-van der Waerden functions $f_r(x)$, a well-known class of\ncontinuous but nowhere differentiable functions, from probabilistic point of\nview. As an application of elephant random walks remembering the recent past\n(ERWRP, a.k.a. symmetric correlated random walks), we obtain precise estimates\nfor the oscillations of $f_r(x)$. We also establish a result on the necessary\nand sufficient condition for localization of the ERWRP with variable step\nlength, which can be applied to obtain a complete description of the\ndifferentiability properties of the Takagi-van der Waerden class functions.","main_category":"math.PR","categories":"math.PR,math.CA","published":"2025-05-13T06:58:43Z"}
{"aid":"http://arxiv.org/abs/2505.08297v1","title":"Capacity of Entanglement in Lifshitz Theories","summary":"We study the capacity of entanglement in certain integrable scale-invariant\ntheories which exhibit Lifshitz scaling symmetry with a generic dynamical\nexponent z at the critical point. This measure characterizes the width of the\neigenvalue spectrum of the reduced density matrix and is a quantum\ninformational counterpart of heat capacity. We explore various aspects of\ncapacity of entanglement, such as the corresponding universal terms for the\nground state, its z-dependence and also its temporal evolution after a global\nquantum quench in two dimensions. We carefully examine the existence of a\nconvenient entropic c-function based on this quantity both in bosonic and\nfermionic theories. While in the relativistic case the corresponding c-function\ndisplays a monotonic behavior under the RG flow, this is not the case for the\nnonrelativistic theories. We also investigate the dynamics of capacity of\nentanglement after a mass quench and show that it follows the quasiparticle\ninterpretation for the spreading of entanglement. Finally, we discuss how these\nresults are consistent with the behavior of other entanglement measures\nincluding the entanglement entropy.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech","published":"2025-05-13T07:22:01Z"}
{"aid":"http://arxiv.org/abs/2505.08300v1","title":"Exploring Challenges in Test Mocking: Developer Questions and Insights\n  from StackOverflow","summary":"Mocking is a common unit testing technique that is used to simplify tests,\nreduce flakiness, and improve coverage by replacing real dependencies with\nsimplified implementations. Despite its widespread use in Open Source Software\nprojects, there is limited understanding of how and why developers use mocks\nand the challenges they face. In this collaborative study, we have analyzed\n25,302 questions related to Mocking on STACKOVERFLOW to identify the challenges\nfaced by developers. We have used Latent Dirichlet Allocation for topic\nmodeling, identified 30 key topics, and grouped the topics into five key\ncategories. Consequently, we analyzed the annual and relative probabilities of\neach category to understand the evolution of mocking-related discussions. Trend\nanalysis reveals that category like Advanced Programming peaked between 2009\nand 2012 but have since declined, while categories such as Mocking Techniques\nand External Services have remained consistently dominant, highlighting\nevolving developer priorities and ongoing technical challenges. Our findings\nalso show an inverse relationship between a topic's popularity and its\ndifficulty. Popular topics like Framework Selection tend to have lower\ndifficulty and faster resolution times, while complex topics like HTTP Requests\nand Responses are more likely to remain unanswered and take longer to resolve.\nA classification of questions into How, Why, What, and Other revealed that over\n70% are How questions, particularly in practical domains like file access and\nAPIs, indicating a strong need for implementation guidance. Why questions are\nmore prevalent in error-handling contexts, reflecting conceptual challenges in\ndebugging, while What questions are rare and mostly tied to theoretical\ndiscussions. These insights offer valuable guidance for improving developer\nsupport, tooling, and educational content in the context of mocking and unit\ntesting.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-13T07:23:49Z"}
{"aid":"http://arxiv.org/abs/2505.08303v1","title":"Evaluating the Effectiveness of Black-Box Prompt Optimization as the\n  Scale of LLMs Continues to Grow","summary":"Black-Box prompt optimization methods have emerged as a promising strategy\nfor refining input prompts to better align large language models (LLMs),\nthereby enhancing their task performance. Although these methods have\ndemonstrated encouraging results, most studies and experiments have primarily\nfocused on smaller-scale models (e.g., 7B, 14B) or earlier versions (e.g.,\nGPT-3.5) of LLMs. As the scale of LLMs continues to increase, such as with\nDeepSeek V3 (671B), it remains an open question whether these black-box\noptimization techniques will continue to yield significant performance\nimprovements for models of such scale. In response to this, we select three\nwell-known black-box optimization methods and evaluate them on large-scale LLMs\n(DeepSeek V3 and Gemini 2.0 Flash) across four NLU and NLG datasets. The\nresults show that these black-box prompt optimization methods offer only\nlimited improvements on these large-scale LLMs. Furthermore, we hypothesize\nthat the scale of the model is the primary factor contributing to the limited\nbenefits observed. To explore this hypothesis, we conducted experiments on LLMs\nof varying sizes (Qwen 2.5 series, ranging from 7B to 72B) and observed an\ninverse scaling law, wherein the effectiveness of black-box optimization\nmethods diminished as the model size increased.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-13T07:26:56Z"}
{"aid":"http://arxiv.org/abs/2505.08306v1","title":"Rapid Overfitting of Multi-Pass Stochastic Gradient Descent in\n  Stochastic Convex Optimization","summary":"We study the out-of-sample performance of multi-pass stochastic gradient\ndescent (SGD) in the fundamental stochastic convex optimization (SCO) model.\nWhile one-pass SGD is known to achieve an optimal $\\Theta(1/\\sqrt{n})$ excess\npopulation loss given a sample of size $n$, much less is understood about the\nmulti-pass version of the algorithm which is widely used in practice. Somewhat\nsurprisingly, we show that in the general non-smooth case of SCO, just a few\nepochs of SGD can already hurt its out-of-sample performance significantly and\nlead to overfitting. In particular, using a step size $\\eta =\n\\Theta(1/\\sqrt{n})$, which gives the optimal rate after one pass, can lead to\npopulation loss as large as $\\Omega(1)$ after just one additional pass. More\ngenerally, we show that the population loss from the second pass onward is of\nthe order $\\Theta(1/(\\eta T) + \\eta \\sqrt{T})$, where $T$ is the total number\nof steps. These results reveal a certain phase-transition in the out-of-sample\nbehavior of SGD after the first epoch, as well as a sharp separation between\nthe rates of overfitting in the smooth and non-smooth cases of SCO.\nAdditionally, we extend our results to with-replacement SGD, proving that the\nsame asymptotic bounds hold after $O(n \\log n)$ steps. Finally, we also prove a\nlower bound of $\\Omega(\\eta \\sqrt{n})$ on the generalization gap of one-pass\nSGD in dimension $d = \\smash{\\widetilde O}(n)$, improving on recent results of\nKoren et al.(2022) and Schliserman et al.(2024).","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-13T07:32:48Z"}
{"aid":"http://arxiv.org/abs/2505.08328v1","title":"AI-Driven Digital Twins: Optimizing 5G/6G Network Slicing with NTNs","summary":"Network slicing in 5G/6G Non-Terrestrial Network (NTN) is confronted with\nmobility and traffic variability. An artificial intelligence (AI)-based digital\ntwin (DT) architecture with deep reinforcement learning (DRL) using Deep\ndeterministic policy gradient (DDPG) is proposed for dynamic optimization of\nresource allocation. DT virtualizes network states to enable predictive\nanalysis, while DRL changes bandwidth for eMBB slice. Simulations show a 25\\%\nlatency reduction compared to static methods, with enhanced resource\nutilization. This scalable solution supports 5G/6G NTN applications like\ndisaster recovery and urban blockage.","main_category":"cs.NI","categories":"cs.NI,eess.SP","published":"2025-05-13T08:09:13Z"}
{"aid":"http://arxiv.org/abs/2505.08330v1","title":"Structural-Temporal Coupling Anomaly Detection with Dynamic Graph\n  Transformer","summary":"Detecting anomalous edges in dynamic graphs is an important task in many\napplications over evolving triple-based data, such as social networks,\ntransaction management, and epidemiology. A major challenge with this task is\nthe absence of structural-temporal coupling information, which decreases the\nability of the representation to distinguish anomalies from normal instances.\nExisting methods focus on handling independent structural and temporal features\nwith embedding models, which ignore the deep interaction between these two\ntypes of information. In this paper, we propose a structural-temporal coupling\nanomaly detection architecture with a dynamic graph transformer model.\nSpecifically, we introduce structural and temporal features from two\nintegration levels to provide anomaly-aware graph evolutionary patterns. Then,\na dynamic graph transformer enhanced by two-dimensional positional encoding is\nimplemented to capture both discrimination and contextual consistency signals.\nExtensive experiments on six datasets demonstrate that our method outperforms\ncurrent state-of-the-art models. Finally, a case study illustrates the strength\nof our method when applied to a real-world task.","main_category":"cs.LG","categories":"cs.LG,cs.SI","published":"2025-05-13T08:10:41Z"}
{"aid":"http://arxiv.org/abs/2505.08344v1","title":"A spherical amplitude-phase formulation for 3-D adaptive line-of-sight\n  (ALOS) guidance with USGES stability guarantees","summary":"A recently proposed 3-D adaptive line-of-sight (ALOS) path-following\nalgorithm addressed coupled motion dynamics of marine craft, aircraft, and\nuncrewed vehicles under environmental disturbances such as wind, waves, and\nocean currents. Stability analysis established uniform semiglobal exponential\nstability (USGES) of the cross- and vertical-track errors using a\nbody-velocity-based amplitude-phase representation of the North-East-Down (NED)\nkinematic differential equations. In this brief paper, we revisit the ALOS\nframework and introduce a novel spherical amplitude-phase representation. This\nformulation yields a more geometrically intuitive and physically observable\ndescription of the guidance errors and enables a significantly simplified\nstability proof. Unlike the previous model, which relied on a vertical crab\nangle derived from body-frame velocities, the new representation uses an\nalternative vertical crab angle and retains the USGES property. It also removes\nrestrictive assumptions such as constant altitude/depth or zero horizontal crab\nangle, and remains valid for general 3-D maneuvers with nonzero roll, pitch,\nand flight-path angles.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY,math.OC","published":"2025-05-13T08:41:52Z"}
{"aid":"http://arxiv.org/abs/2505.08346v1","title":"Quantum computational speedup and retrocausality","summary":"Involving only the measurements of commuting observables (the setting and the\ncorresponding solution of the problem), quantum algorithms should be subject to\nclassical logic. Under this assumption, their customary quantum description can\nbe flunked by a classical logic description. This creates a new perspective\nunder which to see them. The classical logic description of an optimal quantum\nalgorithm shows that the sheer existence of its quantum speedup logically\nimplies the mutually exclusive or of causal loops. In each of them, it is as if\nthe problem-solver knew in advance, before beginning her problem-solving\naction, one of the possible halves of the information that specifies the\nsolution of the problem she will produce and measure in the future. Then, she\ncan use this knowledge in the best logical way to produce the solution with\nexactly the number of computation steps of the optimal quantum algorithm. Since\nthe quantum and classical logic descriptions of the quantum algorithm must go\nalong, this tells us that their customary quantum description, which says\nnothing of the sort, must be incomplete. It is indeed completed by\ntime-symmetrizing it. This leaves the unitary part of the customary quantum\ndescription mathematically unaltered but changes the description of the\nbehavior of causality along it. Its single causal process is replaced by the\nquantum superposition of the causal loops whose mutually exclusive or is\nlogically implied by the sheer existence of the quantum speedup.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T08:44:13Z"}
{"aid":"http://arxiv.org/abs/2505.08356v1","title":"Lorentzian-Constrained Holographic Beamforming Optimization in\n  Multi-user Networks with Dynamic Metasurface Antennas","summary":"Dynamic metasurface antennas (DMAs) are promising alternatives to fully\ndigital (FD) architectures, enabling hybrid beamforming via low-cost\nreconfigurable metasurfaces. In DMAs, holographic beamforming is achieved\nthrough tunable elements by Lorentzian-constrained holography (LCH),\nsignificantly reducing the need for radio-frequency (RF) chains and analog\ncircuitry. However, the Lorentzian constraints and limited RF chains introduce\na trade-off between reduced system complexity and beamforming performance,\nespecially in dense network scenarios. This paper addresses resource allocation\nin multi-user multiple-input-single-output (MISO) networks under the\nSignal-to-Interference-plus-Noise Ratio (SINR) constraints, aiming to minimize\ntotal transmit power. We propose a holographic beamforming algorithm based on\nthe Generalized Method of Lorentzian-Constrained Holography (GMLCH), which\noptimizes DMA weights, yielding flexibility for using various LCH techniques to\ntackle the aforementioned trade-offs. Building upon GMLCH, we further propose a\nnew algorithm, Adaptive Radius Lorentzian Constrained Holography (ARLCH), which\nachieves optimization of DMA weights with additional degree of freedom in a\ngreater optimization space, and provides lower transmitted power, while\nimproving scalability for higher number of users. Numerical results show that\nARLCH reduces power consumption by over 20% compared to benchmarks, with\nincreasing effectiveness as the number of users grows.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-05-13T08:58:23Z"}
{"aid":"http://arxiv.org/abs/2505.08362v1","title":"Localization of Impacts on Thin-Walled Structures by Recurrent Neural\n  Networks: End-to-end Learning from Real-World Data","summary":"Today, machine learning is ubiquitous, and structural health monitoring (SHM)\nis no exception. Specifically, we address the problem of impact localization on\nshell-like structures, where knowledge of impact locations aids in assessing\nstructural integrity. Impacts on thin-walled structures excite Lamb waves,\nwhich can be measured with piezoelectric sensors. Their dispersive\ncharacteristics make it difficult to detect and localize impacts by\nconventional methods. In the present contribution, we explore the localization\nof impacts using neural networks. In particular, we propose to use {recurrent\nneural networks} (RNNs) to estimate impact positions end-to-end, i.e., directly\nfrom {sequential sensor data}. We deal with comparatively long sequences of\nthousands of samples, since high sampling rate are needed to accurately capture\nelastic waves. For this reason, the proposed approach builds upon Gated\nRecurrent Units (GRUs), which are less prone to vanishing gradients as compared\nto conventional RNNs. Quality and quantity of data are crucial when training\nneural networks. Often, synthetic data is used, which inevitably introduces a\nreality gap. Here, by contrast, we train our networks using {physical data from\nexperiments}, which requires automation to handle the large number of\nexperiments needed. For this purpose, a {robot is used to drop steel balls}\nonto an {aluminum plate} equipped with {piezoceramic sensors}. Our results show\nremarkable accuracy in estimating impact positions, even with a comparatively\nsmall dataset.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-13T09:08:47Z"}
{"aid":"http://arxiv.org/abs/2505.08364v1","title":"Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive\n  Difficulty Curriculum Learning and Expert-Guided Self-Reformulation","summary":"Despite impressive progress in areas like mathematical reasoning, large\nlanguage models still face significant challenges in consistently solving\ncomplex problems. Drawing inspiration from key human learning strategies, we\npropose two novel strategies to enhance the capability of large language models\nto solve these complex problems. First, Adaptive Difficulty Curriculum Learning\n(ADCL) is a novel curriculum learning strategy that tackles the Difficulty\nShift phenomenon (i.e., a model's perception of problem difficulty dynamically\nchanges during training) by periodically re-estimating difficulty within\nupcoming data batches to maintain alignment with the model's evolving\ncapabilities. Second, Expert-Guided Self-Reformulation (EGSR) is a novel\nreinforcement learning strategy that bridges the gap between imitation learning\nand pure exploration by guiding models to reformulate expert solutions within\ntheir own conceptual framework, rather than relying on direct imitation,\nfostering deeper understanding and knowledge assimilation. Extensive\nexperiments on challenging mathematical reasoning benchmarks, using Qwen2.5-7B\nas the base model, demonstrate that these human-inspired strategies\nsynergistically and significantly enhance performance. Notably, their combined\napplication improves performance over the standard Zero-RL baseline by 10% on\nthe AIME24 benchmark and 16.6% on AIME25.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-13T09:10:48Z"}
{"aid":"http://arxiv.org/abs/2505.08366v1","title":"Non-contact Vital Signs Detection in Dynamic Environments","summary":"Accurate phase demodulation is critical for vital sign detection using\nmillimeter-wave radar. However, in complex environments, time-varying DC\noffsets and phase imbalances can severely degrade demodulation performance. To\naddress this, we propose a novel DC offset calibration method alongside a\nHilbert and Differential Cross-Multiply (HADCM) demodulation algorithm. The\napproach estimates time-varying DC offsets from neighboring signal peaks and\nvalleys, then employs both differential forms and Hilbert transforms of the I/Q\nchannel signals to extract vital sign information. Simulation and experimental\nresults demonstrate that the proposed method maintains robust performance under\nlow signal-to-noise ratios. Compared to existing demodulation techniques, it\noffers more accurate signal recovery in challenging scenarios and effectively\nsuppresses noise interference.","main_category":"eess.SP","categories":"eess.SP,cs.AI","published":"2025-05-13T09:11:48Z"}
{"aid":"http://arxiv.org/abs/2505.08372v1","title":"MeerKAT discovery of a hyperactive repeating fast radio burst source","summary":"We present the discovery and localisation of a repeating fast radio burst\n(FRB) source from the MeerTRAP project, a commensal fast radio transient search\nprogramme using the MeerKAT telescope. FRB 20240619D was first discovered on\n2024 June 19 with three bursts being detected within two minutes in the MeerKAT\nL-band (856 - 1712MHz). We conducted follow-up observations of FRB 20240619D\nwith MeerKAT using the Ultra-High Frequency (UHF; 544 - 1088MHz), L-band and\nS-band (1968 - 2843MHz) receivers one week after its discovery, and recorded a\ntotal of 249 bursts. The MeerKAT-detected bursts exhibit band-limited emission\nwith an average fractional bandwidth of 0.31, 0.34 and 0.48 in the UHF, L-band\nand S-band, respectively. We find our observations are complete down to a\nfluence limit of ~1Jy ms, above which the cumulative burst rate follows a power\nlaw $R (>F)\\propto (F/1\\,\\text{Jy}\\,\\text{ms})^\\gamma$ with $\\gamma=-1.6\\pm0.1$\nand $-1.7\\pm0.1$ in the UHF and L-band, respectively. The near-simultaneous\nL-band, UHF and S-band observations reveal a frequency dependent burst rate\nwith $3\\times$ more bursts being detected in the L-band than in the UHF and\nS-band, suggesting a spectral turnover in the burst energy distribution of FRB\n20240619D. Our polarimetric analysis demonstrates that most of the bursts have\n$\\sim100\\%$ linear polarisation fractions and $\\sim10\\%\\text{--}20\\%$ circular\npolarisation fractions. We find no optical counterpart of FRB 20240619D in the\nMeerLICHT optical observations simultaneous to the radio observations and set a\nfluence upper limit in MeerLICHT's q-band of 0.76Jy ms and an optical-to-radio\nfluence ratio limit of 0.034 for a 15s exposure.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-13T09:19:14Z"}
{"aid":"http://arxiv.org/abs/2505.08376v1","title":"Adaptive Diffusion Policy Optimization for Robotic Manipulation","summary":"Recent studies have shown the great potential of diffusion models in\nimproving reinforcement learning (RL) by modeling complex policies, expressing\na high degree of multi-modality, and efficiently handling high-dimensional\ncontinuous control tasks. However, there is currently limited research on how\nto optimize diffusion-based polices (e.g., Diffusion Policy) fast and stably.\nIn this paper, we propose an Adam-based Diffusion Policy Optimization (ADPO), a\nfast algorithmic framework containing best practices for fine-tuning\ndiffusion-based polices in robotic control tasks using the adaptive gradient\ndescent method in RL. Adaptive gradient method is less studied in training RL,\nlet alone diffusion-based policies. We confirm that ADPO outperforms other\ndiffusion-based RL methods in terms of overall effectiveness for fine-tuning on\nstandard robotic tasks. Concretely, we conduct extensive experiments on\nstandard robotic control tasks to test ADPO, where, particularly, six popular\ndiffusion-based RL methods are provided as benchmark methods. Experimental\nresults show that ADPO acquires better or comparable performance than the\nbaseline methods. Finally, we systematically analyze the sensitivity of\nmultiple hyperparameters in standard robotics tasks, providing guidance for\nsubsequent practical applications. Our video demonstrations are released in\nhttps://github.com/Timeless-lab/ADPO.git.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-05-13T09:21:45Z"}
{"aid":"http://arxiv.org/abs/2505.08381v1","title":"Elastic properties of silicene: Spinodal instabilities","summary":"Silicene, a two-dimensional (2D) allotrope of silicon, has attracted\nsignificant interest for its electronic and mechanical properties, alongside\nits compatibility with various substrates. In this study, we investigate the\nstructural and elastic characteristics of silicene using molecular dynamics\nsimulations based on a tight-binding Hamiltonian, calibrated to align with\ndensity-functional theory calculations. We focus particularly on the material's\nelastic properties and mechanical stability, analyzing its behavior under\nextensive compressive and tensile in-plane stresses and across temperatures up\nto 1000 K. Key properties examined include in-plane area, Si--Si bond length,\natomic mean-square displacements, elastic constants, and 2D compression\nmodulus. Our findings reveal a notable reduction in stiffness elastic\nconstants, Poisson's ratio, and compression modulus with increasing\ntemperature. Additionally, we identify mechanical instabilities in the silicene\nstructure at specific compressive and tensile biaxial stresses, signaling the\nmaterial's stability limits or spinodal points. At the corresponding spinodal\npressures, structural and elastic properties exhibit anomalies or divergences.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.chem-ph,physics.comp-ph","published":"2025-05-13T09:28:47Z"}
{"aid":"http://arxiv.org/abs/2505.08385v1","title":"TikTok Search Recommendations: Governance and Research Challenges","summary":"Like other social media, TikTok is embracing its use as a search engine,\ndeveloping search products to steer users to produce searchable content and\nengage in content discovery. Their recently developed product search\nrecommendations are preformulated search queries recommended to users on\nvideos. However, TikTok provides limited transparency about how search\nrecommendations are generated and moderated, despite requirements under\nregulatory frameworks like the European Union's Digital Services Act. By\nsuggesting that the platform simply aggregates comments and common searches\nlinked to videos, it sidesteps responsibility and issues that arise from\ncontextually problematic recommendations, reigniting long-standing concerns\nabout platform liability and moderation. This position paper addresses the\nnovelty of search recommendations on TikTok by highlighting the challenges that\nthis feature poses for platform governance and offering a computational\nresearch agenda, drawing on preliminary qualitative analysis. It sets out the\nneed for transparency in platform documentation, data access and research to\nstudy search recommendations.","main_category":"cs.IR","categories":"cs.IR,cs.CY","published":"2025-05-13T09:32:09Z"}
{"aid":"http://arxiv.org/abs/2505.08391v1","title":"Block-Decomposition for 3-Parameter Persistence Modules","summary":"In 2020, Cochoy and Oudot got the necessary and sufficient condition of the\nblock-decomposition of 2-parameter persistence modules $\\mathbb{R}^2 \\to\n\\textbf{Vec}_{\\Bbbk}$. And in 2024, Lebovici, Lerch and Oudot resolve the\nproblem of block-decomposability for multi-parameter persistence modules.\nFollowing the approach of Cochoy and Oudot's proof of block-decomposability for\n2-parameter persistence modules, we rediscuss the necessary and sufficient\nconditions for the block decomposition of the 3-parameter persistence modules\n$\\mathbb{R}^3 \\to \\textbf{Vec}_{\\Bbbk}$. Our most important contribution is to\ngeneralize the strong exactness of 2-parameter persistence modules to the case\nof 3-parameter persistence modules. What's more, the generalized method allows\nus to understand why there is no block decomposition in general persistence\nmodules to some extent.","main_category":"math.AT","categories":"math.AT,math.RT","published":"2025-05-13T09:38:25Z"}
{"aid":"http://arxiv.org/abs/2505.08395v1","title":"Bayesian Estimation of Causal Effects Using Proxies of a Latent\n  Interference Network","summary":"Network interference occurs when treatments assigned to some units affect the\noutcomes of others. Traditional approaches often assume that the observed\nnetwork correctly specifies the interference structure. However, in practice,\nresearchers frequently only have access to proxy measurements of the\ninterference network due to limitations in data collection or potential\nmismatches between measured networks and actual interference pathways. In this\npaper, we introduce a framework for estimating causal effects when only proxy\nnetworks are available. Our approach leverages a structural causal model that\naccommodates diverse proxy types, including noisy measurements, multiple data\nsources, and multilayer networks, and defines causal effects as interventions\non population-level treatments. Since the true interference network is latent,\nestimation poses significant challenges. To overcome them, we develop a\nBayesian inference framework. We propose a Block Gibbs sampler with Locally\nInformed Proposals to update the latent network, thereby efficiently exploring\nthe high-dimensional posterior space composed of both discrete and continuous\nparameters. We illustrate the performance of our method through numerical\nexperiments, demonstrating its accuracy in recovering causal effects even when\nonly proxies of the interference network are available.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.CO,stat.ML,stat.OT","published":"2025-05-13T09:46:30Z"}
{"aid":"http://arxiv.org/abs/2505.08406v1","title":"Radiative $Î¼-Ï„$ Corrections and Renormalization of Neutrino Mass\n  Operators in Type II Seesaw Models","summary":"We explore the impact of radiative $\\mu-\\tau$ corrections on the\nrenormalization of neutrino mass operators in the Type II Seesaw framework,\nincorporating both dimension-five and dimension-six operators. Using\nrenormalization group equations (RGE), we analyze the evolution of flavor\ncoupling matrices and their deviations from $\\mu-\\tau$ symmetric configurations\ndue to quantum corrections. Given the stringent constraints from the Large\nHadron Collider (LHC) on the triplet scalar masses and couplings, we examine\nhow these bounds influence the viability of $\\mu-\\tau$ symmetric seesaw models.\nOur analysis highlights the interplay between high-scale $\\mu-\\tau$ symmetry\npredictions and low-scale phenomenology, revealing whether radiative\ncorrections remain within experimentally allowed limits.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-13T10:02:47Z"}
{"aid":"http://arxiv.org/abs/2505.08413v1","title":"Improved delta-kick cooling with multiple non-ideal kicks","summary":"Delta-kick cooling is a technique employed to achieve low kinetic\ntemperatures by decreasing momentum width at the cost of increased position\nwidth. In an ideal implementation, this method uses a harmonic potential to\ndeliver a single near-instantaneous momentum kick. In practice, potentials that\nare approximately harmonic near their center are commonly used. As a result,\nthe breakdown of the harmonic approximation far from the center limits the\ncooling performance. Inspired by aberration cancellation in optics, we propose\nto use compound matter-wave lens systems for $\\delta-$kick cooling with\nGaussian potentials. By strategically combining attractive and repulsive kicks,\nwe show that it is possible to mimic the effect of a harmonic potential. For a\ntest case with reasonable experimental parameters, our method suggests a\nreduction in kinetic temperature by a factor of $2.5$ using a 2-pulse sequence\nand by a factor of $3.2$ using a 3-pulse sequence.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T10:12:24Z"}
{"aid":"http://arxiv.org/abs/2505.08414v1","title":"An integrated language-vision foundation model for conversational\n  diagnostics and triaging in primary eye care","summary":"Current deep learning models are mostly task specific and lack a\nuser-friendly interface to operate. We present Meta-EyeFM, a multi-function\nfoundation model that integrates a large language model (LLM) with vision\nfoundation models (VFMs) for ocular disease assessment. Meta-EyeFM leverages a\nrouting mechanism to enable accurate task-specific analysis based on text\nqueries. Using Low Rank Adaptation, we fine-tuned our VFMs to detect ocular and\nsystemic diseases, differentiate ocular disease severity, and identify common\nocular signs. The model achieved 100% accuracy in routing fundus images to\nappropriate VFMs, which achieved $\\ge$ 82.2% accuracy in disease detection,\n$\\ge$ 89% in severity differentiation, $\\ge$ 76% in sign identification.\nMeta-EyeFM was 11% to 43% more accurate than Gemini-1.5-flash and ChatGPT-4o\nLMMs in detecting various eye diseases and comparable to an ophthalmologist.\nThis system offers enhanced usability and diagnostic performance, making it a\nvaluable decision support tool for primary eye care or an online LLM for fundus\nevaluation.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-13T10:13:26Z"}
{"aid":"http://arxiv.org/abs/2505.08420v1","title":"Improved ion bunch quality of conical target irradiated by ultra-intense\n  and ultra-short laser","summary":"We conduct particle-in-cell simulations to estimate the effects of circularly\nand linearly polarized SEL 100 PW lasers on flat Th targets with thicknesses of\n50 nm, 100 nm and 250 nm, as well as easy to manufacture conical Th targets\nwith angularity either on the left or right. As the thickness of the three\ntypes of targets increases and under the same polarized laser, the average\nenergy, maximum energy and energy conversion efficiency of Th ions decrease as\nit is well-known, and except for the circularly polarized laser hit on the\nconical target with angularity on the left, the Th ion beam emittance also\ndecreases, while its beam intensity increases conversely. The linearly\npolarized laser, compared to the circularly polarized laser with the same laser\nintensity, exhibits higher beam intensity, beam emittance and energy conversion\nefficiency for the same type and thickness of Th target. The conical Th target\nwith angularity on the left and intermediate thickness, compared to the flat\ntarget and conical target with angularity on the right of the same thickness,\npossesses both higher ion average energy up to 7 GeV and virtually the same\nbeam intensity up to 0.8 MA under the linearly polarized laser. The results\nlead us to an easier way of controlling laser-accelerated high-quality heavy\nion beam by switching to an optimal laser-target configuration scheme, which\nmay enable the synthesis of superheavy nuclei in a high-temperature and\nhigh-density extreme plasma environment in astronuclear physics.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,nucl-ex","published":"2025-05-13T10:24:23Z"}
{"aid":"http://arxiv.org/abs/2505.08424v1","title":"CMOS-Compatible, Wafer-Scale Processed Superconducting Qubits Exceeding\n  Energy Relaxation Times of 200us","summary":"We present the results of an industry-grade fabrication of superconducting\nqubits on 200 mm wafers utilizing CMOS-established processing methods. By\nautomated waferprober resistance measurements at room temperature, we\ndemonstrate a Josephson junction fabrication yield of 99.7% (shorts and opens)\nacross more than 10000 junctions and a qubit frequency prediction accuracy of\n1.6%. In cryogenic characterization, we provide statistical results regarding\nenergy relaxation times of the qubits with a median T1 of up to 100 us and\nindividual devices consistently approaching 200 us in long-term measurements.\nThis represents the best performance reported so far for superconducting qubits\nfabricated by industry-grade, wafer-level subtractive processes.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T10:36:20Z"}
{"aid":"http://arxiv.org/abs/2505.08434v1","title":"Explicit formulas for Euler's totient function and the number of\n  divisors","summary":"In this article, we present relations for the Euler totient function\n$\\varphi(n)$ and the number of divisors $\\tau(n)$ in terms of finite sums of\ninteger parts of rational numbers or greatest common divisors of pairs of\nintegers. Some of the formulas are obtained using a relation due to Menon and\nthe connections with the Pillai arithmetic function are outlined. The reported\nexpressions may be useful to derive new bounds for the usual arithmetical\nfunctions.","main_category":"math.NT","categories":"math.NT","published":"2025-05-13T10:56:15Z"}
{"aid":"http://arxiv.org/abs/2505.08442v1","title":"Robust Î¼-distortion constraints on primordial supermassive black\n  holes from cubic (gNL) non-Gaussian perturbations","summary":"We make the first calculation of the spectral distortion constraints on the\nprimordial curvature power spectrum in the limit of large cubic\nnon-Gaussianity. This calculation involves computing a 2-loop integral, which\nwe perform analytically. Despite being non-perturbatively non-Gaussian, we show\nthat the constraints only change significantly from the case of Gaussian\nperturbations in the high-k tail, where spectral distortions become weak. We\nconclude that generating primordial supermassive black holes requires even more\nextreme forms of non-Gaussianity. We also argue why the mu-distortion\nconstraint is unlikely to significantly change even in the presence of more\nextreme local non-Gaussianity.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-13T11:09:21Z"}
{"aid":"http://arxiv.org/abs/2505.08448v1","title":"Scalable UAV Multi-Hop Networking via Multi-Agent Reinforcement Learning\n  with Large Language Models","summary":"In disaster scenarios, establishing robust emergency communication networks\nis critical, and unmanned aerial vehicles (UAVs) offer a promising solution to\nrapidly restore connectivity. However, organizing UAVs to form multi-hop\nnetworks in large-scale dynamic environments presents significant challenges,\nincluding limitations in algorithmic scalability and the vast exploration space\nrequired for coordinated decision-making. To address these issues, we propose\nMRLMN, a novel framework that integrates multi-agent reinforcement learning\n(MARL) and large language models (LLMs) to jointly optimize UAV agents toward\nachieving optimal networking performance. The framework incorporates a grouping\nstrategy with reward decomposition to enhance algorithmic scalability and\nbalance decision-making across UAVs. In addition, behavioral constraints are\napplied to selected key UAVs to improve the robustness of the network.\nFurthermore, the framework integrates LLM agents, leveraging knowledge\ndistillation to transfer their high-level decision-making capabilities to MARL\nagents. This enhances both the efficiency of exploration and the overall\ntraining process. In the distillation module, a Hungarian algorithm-based\nmatching scheme is applied to align the decision outputs of the LLM and MARL\nagents and define the distillation loss. Extensive simulation results validate\nthe effectiveness of our approach, demonstrating significant improvements in\nnetwork performance, including enhanced coverage and communication quality.","main_category":"cs.MA","categories":"cs.MA","published":"2025-05-13T11:23:25Z"}
{"aid":"http://arxiv.org/abs/2505.08471v1","title":"Interest Changes: Considering User Interest Life Cycle in Recommendation\n  System","summary":"In recommendation systems, user interests are always in a state of constant\nflux. Typically, a user interest experiences a emergent phase, a stable phase,\nand a declining phase, which are referred to as the \"user interest life-cycle\".\nRecent papers on user interest modeling have primarily focused on how to\ncompute the correlation between the target item and user's historical\nbehaviors, without thoroughly considering the life-cycle features of user\ninterest. In this paper, we propose an effective method called Deep Interest\nLife-cycle Network (DILN), which not only captures the interest life-cycle\nfeatures efficiently, but can also be easily integrated to existing ranking\nmodels. DILN contains two key components: Interest Life-cycle Encoder Module\nconstructs historical activity histograms of the user interest and then encodes\nthem into dense representation. Interest Life-cycle Fusion Module injects the\nencoded dense representation into multiple expert networks, with the aim of\nenabling the specific phase of interest life-cycle to activate distinct\nexperts. Online A/B testing reveals that DILN achieves significant improvements\nof +0.38% in CTR, +1.04% in CVR and +0.25% in duration per user, which\ndemonstrates its effectiveness. In addition, DILN inherently increase the\nexposure of users' emergent and stable interests while decreasing the exposure\nof declining interests. DILN has been deployed on the Lofter App.","main_category":"cs.IR","categories":"cs.IR","published":"2025-05-13T11:53:26Z"}
{"aid":"http://arxiv.org/abs/2505.08476v1","title":"Dilation on an annulus and von Neumann's inequality on certain varieties\n  in the biball","summary":"We give an alternative proof to Agler's famous result on success of rational\ndilation on an annulus by an application of a result due to Dritschel and\nMcCullough. We show interplay between operators associated with an annulus,\n$C_{1,r}$ or quantum annulus and operator pairs living on a certain variety in\n$\\mathbb C^2$ and its intersection with the biball. It is shown that the\nminimal spectral sets and von Neumann's inequality for these classes $C_{1,r}$,\nquantum annulus can also be studied via appropriate operator pairs associated\nwith the biball.","main_category":"math.FA","categories":"math.FA,math.CV,math.OA","published":"2025-05-13T12:04:28Z"}
{"aid":"http://arxiv.org/abs/2505.08480v1","title":"The insertion encoding of Cayley permutations","summary":"We introduce the vertical and horizontal insertion encodings for Cayley\npermutations which naturally generalise the insertion encoding for\npermutations. In both cases, we fully classify the Cayley permutation classes\nfor which these languages are regular, and provide an algorithm for computing\nthe rational generating functions. We use our algorithm to solve an open\nproblem of Cerbai by enumerating the hare pop-stack sortable Cayley\npermutations.","main_category":"math.CO","categories":"math.CO,G.2.1","published":"2025-05-13T12:06:43Z"}
{"aid":"http://arxiv.org/abs/2505.08486v1","title":"Nonlinear Evolution Toward the Linear Diffusive Profile in the Presence\n  of Couette Flow","summary":"In this paper, we investigate the long-time behavior of solutions to the\ntwo-dimensional Navier-Stokes equations with initial data evolving under the\ninfluence of the planar Couette flow. We focus on general perturbations, which\nmay be large and of low regularity, including singular configurations such as\npoint vortices, and show that the vorticity asymptotically approaches a\nconstant multiple of the fundamental solution of the corresponding linearized\nvorticity equation after a long-time evolution determined by the relative\nReynolds number.","main_category":"math.AP","categories":"math.AP","published":"2025-05-13T12:16:21Z"}
{"aid":"http://arxiv.org/abs/2505.08504v1","title":"Reassessing Graph Linearization for Sequence-to-sequence AMR Parsing: On\n  the Advantages and Limitations of Triple-Based Encoding","summary":"Sequence-to-sequence models are widely used to train Abstract Meaning\nRepresentation (Banarescu et al., 2013, AMR) parsers. To train such models, AMR\ngraphs have to be linearized into a one-line text format. While Penman encoding\nis typically used for this purpose, we argue that it has limitations: (1) for\ndeep graphs, some closely related nodes are located far apart in the linearized\ntext (2) Penman's tree-based encoding necessitates inverse roles to handle node\nre-entrancy, doubling the number of relation types to predict. To address these\nissues, we propose a triple-based linearization method and compare its\nefficiency with Penman linearization. Although triples are well suited to\nrepresent a graph, our results suggest room for improvement in triple encoding\nto better compete with Penman's concise and explicit representation of a nested\ngraph structure.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-13T12:36:02Z"}
{"aid":"http://arxiv.org/abs/2505.08508v1","title":"TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation\n  System to Streamline Patient-to-Trial Matching","summary":"Patient recruitment remains a major bottleneck in clinical trials, calling\nfor scalable and automated solutions. We present TrialMatchAI, an AI-powered\nrecommendation system that automates patient-to-trial matching by processing\nheterogeneous clinical data, including structured records and unstructured\nphysician notes. Built on fine-tuned, open-source large language models (LLMs)\nwithin a retrieval-augmented generation framework, TrialMatchAI ensures\ntransparency and reproducibility and maintains a lightweight deployment\nfootprint suitable for clinical environments. The system normalizes biomedical\nentities, retrieves relevant trials using a hybrid search strategy combining\nlexical and semantic similarity, re-ranks results, and performs criterion-level\neligibility assessments using medical Chain-of-Thought reasoning. This pipeline\ndelivers explainable outputs with traceable decision rationales. In real-world\nvalidation, 92 percent of oncology patients had at least one relevant trial\nretrieved within the top 20 recommendations. Evaluation across synthetic and\nreal clinical datasets confirmed state-of-the-art performance, with expert\nassessment validating over 90 percent accuracy in criterion-level eligibility\nclassification, particularly excelling in biomarker-driven matches. Designed\nfor modularity and privacy, TrialMatchAI supports Phenopackets-standardized\ndata, enables secure local deployment, and allows seamless replacement of LLM\ncomponents as more advanced models emerge. By enhancing efficiency and\ninterpretability and offering lightweight, open-source deployment, TrialMatchAI\nprovides a scalable solution for AI-driven clinical trial matching in precision\nmedicine.","main_category":"cs.AI","categories":"cs.AI,cs.LG,q-bio.QM","published":"2025-05-13T12:39:06Z"}
{"aid":"http://arxiv.org/abs/2505.08515v1","title":"CoVoL: A Cooperative Vocabulary Learning Game for Children with Autism","summary":"Children with Autism commonly face difficulties in vocabulary acquisition,\nwhich can have an impact on their social communication. Using digital tools for\nvocabulary learning can prove beneficial for these children, as they can\nprovide a predictable environment and effective individualized feedback. While\nexisting work has explored the use of technology-assisted vocabulary learning\nfor children with Autism, no study has incorporated turn-taking to facilitate\nlearning and use of vocabulary similar to that used in real-world social\ncontexts. To address this gap, we propose the design of a cooperative\ntwo-player vocabulary learning game, CoVoL. CoVoL allows children to engage in\ngame-based vocabulary learning useful for real-world social communication\nscenarios. We discuss our first prototype and its evaluation. Additionally, we\npresent planned features which are based on feedback obtained through ten\ninterviews with researchers and therapists, as well as an evaluation plan for\nthe final release of CoVoL.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-05-13T12:48:02Z"}
{"aid":"http://arxiv.org/abs/2505.08517v1","title":"A Deep Learning-Driven Framework for Inhalation Injury Grading Using\n  Bronchoscopy Images","summary":"Inhalation injuries face a challenge in clinical diagnosis and grading due to\nthe limitations of traditional methods, such as Abbreviated Injury Score (AIS),\nwhich rely on subjective assessments and show weak correlations with clinical\noutcomes. This study introduces a novel deep learning-based framework for\ngrading inhalation injuries using bronchoscopy images with the duration of\nmechanical ventilation as an objective metric. To address the scarcity of\nmedical imaging data, we propose enhanced StarGAN, a generative model that\nintegrates Patch Loss and SSIM Loss to improve synthetic images' quality and\nclinical relevance. The augmented dataset generated by enhanced StarGAN\nsignificantly improved classification performance when evaluated using the Swin\nTransformer, achieving an accuracy of 77.78%, an 11.11% improvement over the\noriginal dataset. Image quality was assessed using the Fr\\'echet Inception\nDistance (FID), where Enhanced StarGAN achieved the lowest FID of 30.06,\noutperforming baseline models. Burn surgeons confirmed the realism and clinical\nrelevance of the generated images, particularly the preservation of bronchial\nstructures and color distribution. These results highlight the potential of\nenhanced StarGAN in addressing data limitations and improving classification\naccuracy for inhalation injury grading.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-05-13T12:48:36Z"}
{"aid":"http://arxiv.org/abs/2505.08521v1","title":"Max-Min Fairness in Stacked Intelligent Metasurface-Aided Rate Splitting\n  Networks","summary":"This paper investigates a downlink multiuser multiple-input single-output\nsystem that integrates rate-splitting multiple access (RSMA) with a stacked\nintelligent metasurface (SIM) to enable wave-domain beamforming. Unlike\nconventional digital beamforming, the proposed system leverages the\nprogrammable phase shifts of the SIM to perform beamforming entirely in the\nwave domain. In contrast to existing literature, this work introduces a\nfairness-centric SIM-RSMA design that shifts the emphasis from maximizing\nsum-rate to ensuring fair allocation of resources. In particular, we formulate\na max-min rate optimization problem that jointly optimizes transmit power\ncoefficients at the base station and SIM phase shifts. Given the non-convex\nnature of this problem, we develop an alternating optimization framework, where\nthe power allocation is optimized through successive convex approximation and\nSIM beamforming is optimized using the Riemannian conjugate gradient method.\nSimulation results indicate that combining SIM with RSMA yields superior\nmax-min performance compared to its integration with space division multiple\naccess or non-orthogonal multiple access.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-13T12:52:41Z"}
{"aid":"http://arxiv.org/abs/2505.08524v1","title":"Attention-based Generative Latent Replay: A Continual Learning Approach\n  for WSI Analysis","summary":"Whole slide image (WSI) classification has emerged as a powerful tool in\ncomputational pathology, but remains constrained by domain shifts, e.g., due to\ndifferent organs, diseases, or institution-specific variations. To address this\nchallenge, we propose an Attention-based Generative Latent Replay Continual\nLearning framework (AGLR-CL), in a multiple instance learning (MIL) setup for\ndomain incremental WSI classification. Our method employs Gaussian Mixture\nModels (GMMs) to synthesize WSI representations and patch count distributions,\npreserving knowledge of past domains without explicitly storing original data.\nA novel attention-based filtering step focuses on the most salient patch\nembeddings, ensuring high-quality synthetic samples. This privacy-aware\nstrategy obviates the need for replay buffers and outperforms other buffer-free\ncounterparts while matching the performance of buffer-based solutions. We\nvalidate AGLR-CL on clinically relevant biomarker detection and molecular\nstatus prediction across multiple public datasets with diverse centers, organs,\nand patient cohorts. Experimental results confirm its ability to retain prior\nknowledge and adapt to new domains, offering an effective, privacy-preserving\navenue for domain incremental continual learning in WSI classification.","main_category":"cs.CV","categories":"cs.CV,cs.ET","published":"2025-05-13T12:55:46Z"}
{"aid":"http://arxiv.org/abs/2505.08527v1","title":"Leveraging Segment Anything Model for Source-Free Domain Adaptation via\n  Dual Feature Guided Auto-Prompting","summary":"Source-free domain adaptation (SFDA) for segmentation aims at adapting a\nmodel trained in the source domain to perform well in the target domain with\nonly the source model and unlabeled target data.Inspired by the recent success\nof Segment Anything Model (SAM) which exhibits the generality of segmenting\nimages of various modalities and in different domains given human-annotated\nprompts like bounding boxes or points, we for the first time explore the\npotentials of Segment Anything Model for SFDA via automatedly finding an\naccurate bounding box prompt. We find that the bounding boxes directly\ngenerated with existing SFDA approaches are defective due to the domain gap.To\ntackle this issue, we propose a novel Dual Feature Guided (DFG) auto-prompting\napproach to search for the box prompt. Specifically, the source model is first\ntrained in a feature aggregation phase, which not only preliminarily adapts the\nsource model to the target domain but also builds a feature distribution\nwell-prepared for box prompt search. In the second phase, based on two feature\ndistribution observations, we gradually expand the box prompt with the guidance\nof the target model feature and the SAM feature to handle the class-wise\nclustered target features and the class-wise dispersed target features,\nrespectively. To remove the potentially enlarged false positive regions caused\nby the over-confident prediction of the target model, the refined pseudo-labels\nproduced by SAM are further postprocessed based on connectivity analysis.\nExperiments on 3D and 2D datasets indicate that our approach yields superior\nperformance compared to conventional methods. Code is available at\nhttps://github.com/zheangh/DFG.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T13:00:48Z"}
{"aid":"http://arxiv.org/abs/2505.08528v1","title":"GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in\n  Class-Incremental Learning","summary":"In the context of continual learning, acquiring new knowledge while\nmaintaining previous knowledge presents a significant challenge. Existing\nmethods often use experience replay techniques that store a small portion of\nprevious task data for training. In experience replay approaches, data\naugmentation has emerged as a promising strategy to further improve the model\nperformance by mixing limited previous task data with sufficient current task\ndata. However, we theoretically and empirically analyze that training with\nmixed samples from random sample pairs may harm the knowledge of previous tasks\nand cause greater catastrophic forgetting. We then propose GradMix, a robust\ndata augmentation method specifically designed for mitigating catastrophic\nforgetting in class-incremental learning. GradMix performs gradient-based\nselective mixup using a class-based criterion that mixes only samples from\nhelpful class pairs and not from detrimental class pairs for reducing\ncatastrophic forgetting. Our experiments on various real datasets show that\nGradMix outperforms data augmentation baselines in accuracy by minimizing the\nforgetting of previous knowledge.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-05-13T13:01:38Z"}
{"aid":"http://arxiv.org/abs/2505.08533v1","title":"How are research data referenced? The use case of the research data\n  repository RADAR","summary":"Publishing research data aims to improve the transparency of research results\nand facilitate the reuse of datasets. In both cases, referencing the datasets\nthat were used is recommended. Research data repositories can support data\nreferencing through various measures and also benefit from it, for example\nusing this information to demonstrate their impact. However, the literature\nshows that the practice of formally citing research data is not widespread,\ndata metrics are not yet established, and effective incentive structures are\nlacking. This article examines how often and in what form datasets published\nvia the research data repository RADAR are referenced. For this purpose, the\ndata sources Google Scholar, DataCite Event Data and the Data Citation Corpus\nwere analyzed. The analysis shows that 27.9 % of the datasets in the repository\nwere referenced at least once. 21.4 % of these references were (also) present\nin the reference lists and are therefore considered data citations. Datasets\nwere referenced often in data availability statements. A comparison of the\nthree data sources showed that there was little overlap in the coverage of\nreferences. In most cases (75.8 %), data and referencing objects were published\nin the same year. Two definition approaches were considered to investigate data\nreuse. 118 RADAR datasets were referenced more than once. Only 21 references\nhad no overlaps in the authorship information -- these datasets were referenced\nby researchers that were not involved in data collection.","main_category":"cs.DL","categories":"cs.DL","published":"2025-05-13T13:03:49Z"}
{"aid":"http://arxiv.org/abs/2505.08535v1","title":"Diffusion-assisted Model Predictive Control Optimization for Power\n  System Real-Time Operation","summary":"This paper presents a modified model predictive control (MPC) framework for\nreal-time power system operation. The framework incorporates a diffusion model\ntailored for time series generation to enhance the accuracy of the load\nforecasting module used in the system operation. In the absence of explicit\nstate transition law, a model-identification procedure is leveraged to derive\nthe system dynamics, thereby eliminating a barrier when applying MPC to a\nrenewables-dominated power system. Case study results on an industry park\nsystem and the IEEE 30-bus system demonstrate that using the diffusion model to\naugment the training dataset significantly improves load-forecasting accuracy,\nand the inferred system dynamics are applicable to the real-time grid operation\nwith solar and wind.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-05-13T13:04:46Z"}
{"aid":"http://arxiv.org/abs/2505.08538v1","title":"Dynamics of weakly elastic sphere translating parallel to a rigid wall","summary":"We analyse the dynamics of a weakly elastic spherical particle translating\nparallel to a rigid wall in a quiescent Newtonian fluid in the Stokes limit.\nThe particle motion is constrained parallel to the wall by applying a point\nforce and a point torque at the centre of its undeformed shape. The particle is\nmodelled using the Navier elasticity equations. The series solutions to the\nNavier and the Stokes equations are utilised to obtain the displacement and\nvelocity fields in the solid and fluid, respectively. The point force and the\npoint torque are calculated as series in small parameters $\\alpha$ and $1/H$,\nusing the domain perturbation method and the method of reflections. Here,\n$\\alpha$ is the ratio of viscous fluid stress to elastic solid stress, and $H$\nis the non-dimensional gap width, defined as the ratio of the distance of the\nparticle centre from the wall to its radius. The results are presented up to\n$\\textit{O}(1/H^3)$ and $\\textit{O}(1/H^2)$, assuming $\\alpha \\sim 1/H$, for\ncases where gravity is aligned and non-aligned with the particle velocity,\nrespectively. The deformed shape of the particle is determined by the force\ndistribution acting on it. %In both cases, the particle experiences a\nhydrodynamic drag due to elastic effects at \\textit{O}($\\alpha^2/H$). The\nhydrodynamic lift due to elastic effects (acting away from the wall) appears at\n$\\textit{O}(\\alpha/H^2)$, in the former case. In an unbounded domain, the\nelastic effects in the latter case generate a hydrodynamic torque at\n\\textit{O}($\\alpha$) and a drag at \\textit{O}($\\alpha^2$). Conversely, in the\nformer case, the torque is zero, while the drag still appears at\n\\textit{O}($\\alpha^2$).","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-05-13T13:09:23Z"}
{"aid":"http://arxiv.org/abs/2505.08547v1","title":"SAR-GTR: Attributed Scattering Information Guided SAR Graph Transformer\n  Recognition Algorithm","summary":"Utilizing electromagnetic scattering information for SAR data interpretation\nis currently a prominent research focus in the SAR interpretation domain. Graph\nNeural Networks (GNNs) can effectively integrate domain-specific physical\nknowledge and human prior knowledge, thereby alleviating challenges such as\nlimited sample availability and poor generalization in SAR interpretation. In\nthis study, we thoroughly investigate the electromagnetic inverse scattering\ninformation of single-channel SAR and re-examine the limitations of applying\nGNNs to SAR interpretation. We propose the SAR Graph Transformer Recognition\nAlgorithm (SAR-GTR). SAR-GTR carefully considers the attributes and\ncharacteristics of different electromagnetic scattering parameters by\ndistinguishing the mapping methods for discrete and continuous parameters,\nthereby avoiding information confusion and loss. Furthermore, the GTR combines\nGNNs with the Transformer mechanism and introduces an edge information\nenhancement channel to facilitate interactive learning of node and edge\nfeatures, enabling the capture of robust and global structural characteristics\nof targets. Additionally, the GTR constructs a hierarchical topology-aware\nsystem through global node encoding and edge position encoding, fully\nexploiting the hierarchical structural information of targets. Finally, the\neffectiveness of the algorithm is validated using the ATRNet-STAR large-scale\nvehicle dataset.","main_category":"eess.IV","categories":"eess.IV","published":"2025-05-13T13:20:03Z"}
{"aid":"http://arxiv.org/abs/2505.08548v1","title":"From Seeing to Doing: Bridging Reasoning and Decision for Robotic\n  Manipulation","summary":"Achieving generalization in robotic manipulation remains a critical\nchallenge, particularly for unseen scenarios and novel tasks. Current\nVision-Language-Action (VLA) models, while building on top of general\nVision-Language Models (VLMs), still fall short of achieving robust zero-shot\nperformance due to the scarcity and heterogeneity prevalent in embodied\ndatasets. To address these limitations, we propose FSD (From Seeing to Doing),\na novel vision-language model that generates intermediate representations\nthrough spatial relationship reasoning, providing fine-grained guidance for\nrobotic manipulation. Our approach combines a hierarchical data pipeline for\ntraining with a self-consistency mechanism that aligns spatial coordinates with\nvisual signals. Through extensive experiments, we comprehensively validated\nFSD's capabilities in both \"seeing\" and \"doing,\" achieving outstanding\nperformance across 8 benchmarks for general spatial reasoning and embodied\nreference abilities, as well as on our proposed more challenging benchmark\nVABench. We also verified zero-shot capabilities in robot manipulation,\ndemonstrating significant performance improvements over baseline methods in\nboth SimplerEnv and real robot settings. Experimental results show that FSD\nachieves 54.1% success rate in SimplerEnv and 72% success rate across 8\nreal-world tasks, outperforming the strongest baseline by 30%.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-05-13T13:20:46Z"}
{"aid":"http://arxiv.org/abs/2505.08559v1","title":"Synthesis of safety certificates for discrete-time uncertain systems via\n  convex optimization","summary":"We study the problem of co-designing control barrier functions and linear\nstate feedback controllers for discrete-time linear systems affected by\nadditive disturbances. For disturbances of bounded magnitude, we provide a\nsemi-definite program whose feasibility implies the existence of a control law\nand a certificate ensuring safety in the infinite horizon with respect to the\nworst-case disturbance realization in the uncertainty set. For disturbances\nwith unbounded support, we rely on martingale theory to derive a second\nsemi-definite program whose feasibility provides probabilistic safety\nguarantees holding joint-in-time over a finite time horizon. We examine several\nextensions, including (i) encoding of different types of input constraints,\n(ii) robustification against distributional ambiguity around the true\ndistribution, (iii) design of safety filters, and (iv) extension to general\nsafety specifications such as obstacle avoidance.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-05-13T13:34:32Z"}
{"aid":"http://arxiv.org/abs/2505.08569v1","title":"Influence of Silicon Interlayers on Transition Layer Formation in Ti/Ni\n  Multilayer Structures of Different Thicknesses","summary":"This study presents a comprehensive investigation of chemical, structural,\nand magnetic properties of Ti/Ni multilayer systems with period thicknesses of\n4 nm and 10 nm. Particular attention was paid to the characterization of the\ntransition layers at Ni-Ti interfaces and the influence of thin silicon barrier\nlayers on their formation. A combination of X-ray photoelectron spectroscopy\n(XPS), X-ray diffraction (XRD), X-ray reflectometry (XRR), and SQUID\nmagnetometry was employed for analysis. Extended transition layers up to 1.2 nm\nin thickness were identified at the Ni-Ti interfaces, primarily composed of the\nintermetallic Ni3Ti phase. The insertion of ultra-thin silicon buffer layers at\nthe interfaces significantly suppressed the formation of intermetallic\ncompounds, most likely due to the formation of titanium silicides.\nAdditionally, it was observed that the use of Si layer on the sample surface\nleads to the formation of silicon oxide after exposure to the ambient\nenvironment, which acts as a passivation layer and inhibits oxidation of Ni and\nTi layers within the topmost period of the multilayer structure.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-13T13:45:11Z"}
{"aid":"http://arxiv.org/abs/2505.08570v1","title":"On the CM exception to a generalization of the StÃ©phanois theorem","summary":"There are two classical theorems related to algebraic values of the\nj-invariant: Schneider's theorem and the St\\'ephanois theorem. Schneider's\ntheorem for the j-invariant states that the transcendence degree\n$\\operatorname{trdeg} \\mathbb{Q}(\\tau, j(\\tau)) \\geq 1$ with the sole exception\nof CM points. In contrast, CM points do not constitute an exception to the\nSt\\'ephanois theorem, which states $\\operatorname{trdeg} \\mathbb{Q}(q,j(q))\\geq\n1$ for the Fourier expansion ($q$-expansion) of the j-invariant, for any $q$.\nSchneider's theorem has been generalized to higher dimensions, and in\nparticular holds for the Igusa invariants of a genus 2 curve. These functions\nhave Fourier expansions, but a result of St\\'ephanois type is unknown. In this\npaper, we find that there are positive dimensional sources of exceptions to the\ngeneric behaviour expected in genus 2, and we discuss their relation to CM\npoints. We utilize Humbert singular relations, putting them into the\ntranscendental framework. The computations of the transcendence degree for CM\npoints are conditional to Schanuel's conjecture.","main_category":"math.NT","categories":"math.NT","published":"2025-05-13T13:45:36Z"}
{"aid":"http://arxiv.org/abs/2505.08571v1","title":"Analysis of gesture-sound decorrelation in electronic drumming","summary":"Drumming belongs to a family of musical instruments whose practice, whether\nas an amateur or at a high level, is associated with an increased risk of\nmusculoskeletal disorders (MSD), particularly of the upper limbs and lumbar\nspine. The vast majority of drummers learn to play on acoustic instruments, the\nsound intensity of which is proportional to the striking force developed. This\ncorrelation is disrupted when playing the electronic version of the instrument,\nwhich is often purchased by musicians seeking to reduce the sound produced\n(e.g. playing in apartments). The aim of this study was therefore to analyze\nwhether drumming on electronic equipment would lead to a change in the\nkinematics and feel of drummers. To this end, several drummers were recruited\nto perform repeated rhythms at different pitches on acoustic and electric drums\nunder two sound conditions (sound on and sound off with noise-canceling\nheadphones). The sound produced and the kinematics of the upper limbs were\nmeasured by video motion capture during the beats. In addition,\nself-confrontation interviews were conducted after each condition. The\ndrummers, confronted with video recordings of their actions, were asked to\ndescribe, explain and comment step by step on their performance. These\ninterviews were also used to assess their ability to maintain a constant strike\nforce. A questionnaire was used to obtain subjective information on how they\nfelt. The results showed a lower sound power of electronic drums, despite a\nsimilar striking speed. This gesture-sound decorrelation could explain the\nincrease in MSD among drummers when switching from an acoustic to an electronic\ninstrument.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-05-13T13:46:07Z"}
{"aid":"http://arxiv.org/abs/2505.08572v1","title":"Entropy numbers of classes defined by integral operators","summary":"In this paper we develop the following general approach. We study asymptotic\nbehavior of the entropy numbers not for an individual smoothness class, how it\nis usually done, but for the collection of classes, which are defined by\nintegral operators with kernels coming from a given class of functions.\nEarlier, such approach was realized for the Kolmogorov widths.","main_category":"math.NA","categories":"math.NA,cs.NA,math.FA","published":"2025-05-13T13:46:08Z"}
{"aid":"http://arxiv.org/abs/2505.08585v1","title":"A Large-scale Benchmark on Geological Fault Delineation Models: Domain\n  Shift, Training Dynamics, Generalizability, Evaluation and Inferential\n  Behavior","summary":"Machine learning has taken a critical role in seismic interpretation\nworkflows, especially in fault delineation tasks. However, despite the recent\nproliferation of pretrained models and synthetic datasets, the field still\nlacks a systematic understanding of the generalizability limits of these models\nacross seismic data representing a variety of geologic, acquisition and\nprocessing settings. Distributional shifts between different data sources,\nlimitations in fine-tuning strategies and labeled data accessibility, and\ninconsistent evaluation protocols all represent major roadblocks in the\ndeployment of reliable and robust models in real-world exploration settings. In\nthis paper, we present the first large-scale benchmarking study explicitly\ndesigned to provide answers and guidelines for domain shift strategies in\nseismic interpretation. Our benchmark encompasses over $200$ models trained and\nevaluated on three heterogeneous datasets (synthetic and real data) including\nFaultSeg3D, CRACKS, and Thebe. We systematically assess pretraining,\nfine-tuning, and joint training strategies under varying degrees of domain\nshift. Our analysis highlights the fragility of current fine-tuning practices,\nthe emergence of catastrophic forgetting, and the challenges of interpreting\nperformance in a systematic manner. We establish a robust experimental baseline\nto provide insights into the tradeoffs inherent to current fault delineation\nworkflows, and shed light on directions for developing more generalizable,\ninterpretable and effective machine learning models for seismic interpretation.\nThe insights and analyses reported provide a set of guidelines on the\ndeployment of fault delineation models within seismic interpretation workflows.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T13:56:43Z"}
{"aid":"http://arxiv.org/abs/2505.08587v1","title":"Two-Level Sketching Alternating Anderson acceleration for Complex\n  Physics Applications","summary":"We present a novel two-level sketching extension of the Alternating\nAnderson-Picard (AAP) method for accelerating fixed-point iterations in\nchallenging single- and multi-physics simulations governed by discretized\npartial differential equations. Our approach combines a static, physics-based\nprojection that reduces the least-squares problem to the most informative field\n(e.g., via Schur-complement insight) with a dynamic, algebraic sketching stage\ndriven by a backward stability analysis under Lipschitz continuity. We\nintroduce inexpensive estimators for stability thresholds and cache-aware\nrandomized selection strategies to balance computational cost against\nmemory-access overhead. The resulting algorithm solves reduced least-squares\nsystems in place, minimizes memory footprints, and seamlessly alternates\nbetween low-cost Picard updates and Anderson mixing. Implemented in Julia, our\ntwo-level sketching AAP achieves up to 50% time-to-solution reductions compared\nto standard Anderson acceleration-without degrading convergence rates-on\nbenchmark problems including Stokes, p-Laplacian, Bidomain, and Navier-Stokes\nformulations at varying problem sizes. These results demonstrate the method's\nrobustness, scalability, and potential for integration into high-performance\nscientific computing frameworks. Our implementation is available open-source in\nthe AAP.jl library.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-13T13:58:22Z"}
{"aid":"http://arxiv.org/abs/2505.08592v1","title":"Communication-Efficient Distributed Online Nonconvex Optimization with\n  Time-Varying Constraints","summary":"This paper considers distributed online nonconvex optimization with\ntime-varying inequality constraints over a network of agents, where the\nnonconvex local loss and convex local constraint functions can vary arbitrarily\nacross iterations, and the information of them is privately revealed to each\nagent at each iteration. For a uniformly jointly strongly connected\ntime-varying directed graph, we propose two distributed bandit online\nprimal--dual algorithm with compressed communication to efficiently utilize\ncommunication resources in the one-point and two-point bandit feedback\nsettings, respectively. In nonconvex optimization, finding a globally optimal\ndecision is often NP-hard. As a result, the standard regret metric used in\nonline convex optimization becomes inapplicable. To measure the performance of\nthe proposed algorithms, we use a network regret metric grounded in the\nfirst-order optimality condition associated with the variational inequality. We\nshow that the compressed algorithms establish sublinear network regret and\ncumulative constraint violation bounds. Finally, a simulation example is\npresented to validate the theoretical results.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-05-13T14:04:12Z"}
{"aid":"http://arxiv.org/abs/2505.08596v1","title":"Information Leakage in Data Linkage","summary":"The process of linking databases that contain sensitive information about\nindividuals across organisations is an increasingly common requirement in the\nhealth and social science research domains, as well as with governments and\nbusinesses. To protect personal data, protocols have been developed to limit\nthe leakage of sensitive information. Furthermore, privacy-preserving record\nlinkage (PPRL) techniques have been proposed to conduct linkage on encoded\ndata. While PPRL techniques are now being employed in real-world applications,\nthe focus of PPRL research has been on the technical aspects of linking\nsensitive data (such as encoding methods and cryptanalysis attacks), but not on\norganisational challenges when employing such techniques in practice. We\nanalyse what sensitive information can possibly leak, either unintentionally or\nintentionally, in traditional data linkage as well as PPRL protocols, and what\na party that participates in such a protocol can learn from the data it obtains\nlegitimately within the protocol. We also show that PPRL protocols can still\nresult in the unintentional leakage of sensitive information. We provide\nrecommendations to help data custodians and other parties involved in a data\nlinkage project to identify and prevent vulnerabilities and make their project\nmore secure.","main_category":"cs.CR","categories":"cs.CR,cs.DB","published":"2025-05-13T14:09:47Z"}
{"aid":"http://arxiv.org/abs/2505.08613v1","title":"Quantum State Readout via Overlap-Based Feature Extraction","summary":"In this study, a method for quantum state readout and feature extraction is\ndeveloped using quantum overlap-based fitting of function expansions. The\napproach involves the quantum calculation of quantum overlaps between a target\nquantum state and a linear combination of basis functions, such as Lorentzian\nfunctions, via measurements, and classical optimization of the parameters in\nthe function expansion. This method is particularly effective in scenarios\nwhere the quantum state is approximately represented as a continuous function\nand expressed as a combination of localized functions. The proposed method\ninvolves a quantum state readout for both the raw and absolute values of the\namplitudes in the quantum state. Preliminary numerical simulations were\nperformed to reconstruct the grid-based wave function and X-ray absorption\nspectra from a quantum state, and the results show that our proposed method\nrequires fewer measurements compared to conventional quantum state measurement\ntechniques.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T14:30:42Z"}
{"aid":"http://arxiv.org/abs/2505.08615v1","title":"On Selection of Cross-Section Averages in Non-stationary Environments","summary":"Information criteria (IC) are important tools in the literature of factor\nmodels that allow one to estimate a typically unknown number of latent factors.\nAlthough first proposed for the Principal Components setting in the seminal\nwork by Bai and Ng (2002), it has recently been shown that IC perform extremely\nwell in Common Correlated Effects (CCE) and related setups with stationary\nfactors. In particular, they can consistently select a sufficient set of\ncross-section averages (CAs) to approximate the factor space. Given that CAs\ncan proxy nonstationary factors, it is tempting to believe that the consistency\nof IC continues to hold under such generality. This study is a cautionary tale\nfor practitioners. We demonstrate formally and in simulations that IC has a\nsevere underselection issue even under very mild forms of factor\nnon-stationarity, which goes against the sentiment in the CAs literature.","main_category":"econ.EM","categories":"econ.EM","published":"2025-05-13T14:32:37Z"}
{"aid":"http://arxiv.org/abs/2505.08622v1","title":"Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with\n  Language Models","summary":"Text-to-image generative models like DALL-E and Stable Diffusion have\nrevolutionized visual content creation across various applications, including\nadvertising, personalized media, and design prototyping. However, crafting\neffective textual prompts to guide these models remains challenging, often\nrequiring extensive trial and error. Existing prompt inversion approaches, such\nas soft and hard prompt techniques, are not so effective due to the limited\ninterpretability and incoherent prompt generation. To address these issues, we\npropose Visually Guided Decoding (VGD), a gradient-free approach that leverages\nlarge language models (LLMs) and CLIP-based guidance to generate coherent and\nsemantically aligned prompts. In essence, VGD utilizes the robust text\ngeneration capabilities of LLMs to produce human-readable prompts. Further, by\nemploying CLIP scores to ensure alignment with user-specified visual concepts,\nVGD enhances the interpretability, generalization, and flexibility of prompt\ngeneration without the need for additional training. Our experiments\ndemonstrate that VGD outperforms existing prompt inversion techniques in\ngenerating understandable and contextually relevant prompts, facilitating more\nintuitive and controllable interactions with text-to-image models.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV","published":"2025-05-13T14:40:22Z"}
{"aid":"http://arxiv.org/abs/2505.08635v1","title":"Augmenting Density Matrix Renormalization Group with Matchgates and\n  Clifford circuits","summary":"Matchgates and Clifford circuits are two types of quantum circuits which can\nbe efficiently simulated classically, though the underlying reasons are quite\ndifferent. Matchgates are essentially the single particle basis transformations\nin the Majorana fermion representation which can be easily handled classically,\nwhile the Clifford circuits can be efficiently simulated using the tableau\nmethod according to the Gottesman-Knill theorem. In this work, we propose a new\nwave-function ansatz in which matrix product states are augmented with the\ncombination of Matchgates and Clifford circuits (dubbed MCA-MPS) to take\nadvantage of the representing power of all of them. Moreover, the optimization\nof MCA-MPS can be efficiently implemented within the Density Matrix\nRenormalization Group method. Our benchmark results on one-dimensional hydrogen\nchain show that MCA-MPS can improve the accuracy of the ground-state\ncalculation by several orders of magnitude over MPS with the same bond\ndimension. This new method provides us a useful approach to study quantum\nmany-body systems. The MCA-MPS ansatz also expands our understanding of\nclassically simulatable quantum many-body states.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-05-13T14:53:09Z"}
{"aid":"http://arxiv.org/abs/2505.08648v1","title":"Enhancing Software Development with Context-Aware Conversational Agents:\n  A User Study on Developer Interactions with Chatbots","summary":"Software development is a cognitively intensive process requiring\nmultitasking, adherence to evolving workflows, and continuous learning. With\nthe rise of large language model (LLM)-based tools, such as conversational\nagents (CAs), there is growing interest in supporting developers through\nnatural language interaction. However, little is known about the specific\nfeatures developers seek in these systems. We conducted a user study with 29\ndevelopers using a prototype text-based chatbot to investigate preferred\nfunctionalities. Our findings reveal strong interest in task automation,\nversion control support, and contextual adaptability, especially the need to\ntailor assistance for both novice and experienced users. We highlight the\nimportance of deep contextual understanding, historical interaction awareness,\nand personalized support in CA design. This study contributes to the\ndevelopment of context-aware chatbots that enhance productivity and\nsatisfaction, and it outlines opportunities for future research on human-AI\ncollaboration in software engineering.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-05-13T15:08:55Z"}
{"aid":"http://arxiv.org/abs/2505.08655v1","title":"Impartial removing games on grid graphs","summary":"A subset of the vertex set of a graph is geodetically convex if it contains\nevery vertex on any shortest path between two elements of the subset. The\nconvex hull of a set of vertices is the smallest convex set containing the set.\nWe study two games in which two players take turns selecting vertices of a\ngraph until the convex hull of the remaining unselected vertices is too small.\nThe last player to move is the winner. The achievement game ends when the\nconvex hull of the unselected vertices does not contain every vertex in the\ngraph. In the avoidance game, the convex hull of the remaining vertices must\ncontain every vertex. We determine the nim-number of these games for the family\nof grid graphs. We also provide some results for lattice graphs. Key tools in\nthis analysis are delayed gamegraphs, option preserving maps, and case analysis\ndiagrams.","main_category":"math.CO","categories":"math.CO","published":"2025-05-13T15:15:53Z"}
{"aid":"http://arxiv.org/abs/2505.08662v1","title":"Revealing economic facts: LLMs know more than they say","summary":"We investigate whether the hidden states of large language models (LLMs) can\nbe used to estimate and impute economic and financial statistics. Focusing on\ncounty-level (e.g. unemployment) and firm-level (e.g. total assets) variables,\nwe show that a simple linear model trained on the hidden states of open-source\nLLMs outperforms the models' text outputs. This suggests that hidden states\ncapture richer economic information than the responses of the LLMs reveal\ndirectly. A learning curve analysis indicates that only a few dozen labelled\nexamples are sufficient for training. We also propose a transfer learning\nmethod that improves estimation accuracy without requiring any labelled data\nfor the target variable. Finally, we demonstrate the practical utility of\nhidden-state representations in super-resolution and data imputation tasks.","main_category":"cs.CL","categories":"cs.CL,cs.LG,econ.GN,q-fin.EC,I.2.7","published":"2025-05-13T15:24:08Z"}
{"aid":"http://arxiv.org/abs/2505.08663v1","title":"Runtime Quantum Advantage with Digital Quantum Optimization","summary":"We demonstrate experimentally that the bias-field digitized counterdiabatic\nquantum optimization (BF-DCQO) algorithm on IBM's 156-qubit devices can\noutperform simulated annealing (SA) and CPLEX in time-to-approximate solutions\nfor specific higher-order unconstrained binary optimization (HUBO) problems. We\nsuitably select problem instances that are challenging for classical methods,\nrunning in fractions of minutes even with multicore processors. On the other\nhand, our counterdiabatic quantum algorithms obtain similar or better results\nin at most a few seconds on quantum hardware, achieving runtime quantum\nadvantage. Our analysis reveals that the performance improvement becomes\nincreasingly evident as the system size grows. Given the rapid progress in\nquantum hardware, we expect that this improvement will become even more\npronounced, potentially leading to a quantum advantage of several orders of\nmagnitude. Our results indicate that available digital quantum processors, when\ncombined with specific-purpose quantum algorithms, exhibit a runtime quantum\nadvantage even in the absence of quantum error correction.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-05-13T15:24:17Z"}
{"aid":"http://arxiv.org/abs/2505.08669v1","title":"Uniform-in-time propagation of chaos for Consensus-Based Optimization","summary":"We study the derivative-free global optimization algorithm Consensus-Based\nOptimization (CBO), establishing uniform-in-time propagation of chaos as well\nas an almost uniform-in-time stability result for the microscopic particle\nsystem. The proof of these results is based on a novel stability estimate for\nthe weighted mean and on a quantitative concentration inequality for the\nmicroscopic particle system around the empirical mean. Our propagation of chaos\nresult recovers the classical Monte Carlo rate, with a prefactor that depends\nexplicitly on the parameters of the problem. Notably, in the case of CBO with\nanisotropic noise, this prefactor is independent of the problem dimension.","main_category":"math.PR","categories":"math.PR,math.AP,math.OC","published":"2025-05-13T15:30:57Z"}
{"aid":"http://arxiv.org/abs/2505.08671v1","title":"How spatial patterns can lead to less resilient ecosystems","summary":"Several theoretical models predict that spatial patterning increases\necosystem resilience. However, these predictions rely on strong simplifying\nassumptions, such as isotropic and infinite ecosystems, and we lack empirical\nevidence directly linking spatial patterning to enhanced resilience. We\nintroduce a unifying framework, encompassing existing models for vegetation\npattern formation in water-stressed ecosystems, that relaxes these assumptions.\nThis framework incorporates finite vegetated areas surrounded by desert and\nanisotropic environmental conditions that induce non-reciprocal plant\ninteractions. Under these more realistic conditions, we identify a novel\ndesertification mechanism, known as convective instability in physics but\nlargely overlooked in ecology. These instabilities form when non-reciprocal\ninteractions destabilize the vegetation-desert interface and can trigger\ndesertification fronts even under stress levels where isotropic models predict\nstability. Importantly, ecosystems with periodic vegetation patterns are more\nvulnerable to convective instabilities than those with homogeneous vegetation,\nsuggesting that spatial patterning may reduce, rather than enhance, resilience.\nThese findings challenge the view of self-organized patterns as indicators of\nresilience and provide a new framework to investigate how spatial dynamics\ndetermine the stability and resilience of ecological systems across scales.","main_category":"q-bio.PE","categories":"q-bio.PE,nlin.AO","published":"2025-05-13T15:32:42Z"}
{"aid":"http://arxiv.org/abs/2505.08674v1","title":"Nonlinear Dynamics in the Formation of Molecular Polariton Condensates","summary":"Exciton-polaritons - hybrid light-matter quasiparticles - can undergo\nBose-Einstein-like condensation at elevated temperatures owing to their lower\neffective mass. This becomes even more pronounced in the context of molecular\npolariton condensates where the large exciton binding energy of Frenkel\nexcitons facilitates condensation at room temperature. While widely studied as\nlow-threshold coherent light sources, the dynamics of their condensation remain\npoorly understood, partly due to the limitations of existing kinetic models.\nHere, we use excitation correlation photoluminescence (ECPL), a nonlinear\noptical technique with 220fs resolution, to probe molecular polariton\ncondensation in Rhodamine-B-doped small-molecule ionic isolation lattices\n(SMILES). This platform promotes dipole alignment and suppresses detrimental\nintermolecular interactions. ECPL reveals condensate formation within hundreds\nof femtoseconds, driven by radiative scattering from the reservoir. A sustained\npopulation beyond the polariton lifetime suggests an additional feeding\nmechanism from higher momentum states in the lower polariton dispersion. These\nresults provide quantitative insight into condensation timescales and\nmechanisms, advancing our control over polariton dynamics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-13T15:35:58Z"}
{"aid":"http://arxiv.org/abs/2505.08685v1","title":"Calibration and Uncertainty for multiRater Volume Assessment in\n  multiorgan Segmentation (CURVAS) challenge results","summary":"Deep learning (DL) has become the dominant approach for medical image\nsegmentation, yet ensuring the reliability and clinical applicability of these\nmodels requires addressing key challenges such as annotation variability,\ncalibration, and uncertainty estimation. This is why we created the Calibration\nand Uncertainty for multiRater Volume Assessment in multiorgan Segmentation\n(CURVAS), which highlights the critical role of multiple annotators in\nestablishing a more comprehensive ground truth, emphasizing that segmentation\nis inherently subjective and that leveraging inter-annotator variability is\nessential for robust model evaluation. Seven teams participated in the\nchallenge, submitting a variety of DL models evaluated using metrics such as\nDice Similarity Coefficient (DSC), Expected Calibration Error (ECE), and\nContinuous Ranked Probability Score (CRPS). By incorporating consensus and\ndissensus ground truth, we assess how DL models handle uncertainty and whether\ntheir confidence estimates align with true segmentation performance. Our\nfindings reinforce the importance of well-calibrated models, as better\ncalibration is strongly correlated with the quality of the results.\nFurthermore, we demonstrate that segmentation models trained on diverse\ndatasets and enriched with pre-trained knowledge exhibit greater robustness,\nparticularly in cases deviating from standard anatomical structures. Notably,\nthe best-performing models achieved high DSC and well-calibrated uncertainty\nestimates. This work underscores the need for multi-annotator ground truth,\nthorough calibration assessments, and uncertainty-aware evaluations to develop\ntrustworthy and clinically reliable DL-based medical image segmentation models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T15:45:44Z"}
{"aid":"http://arxiv.org/abs/2505.08692v1","title":"Constructor theory of time","summary":"Constructor theory asserts that the laws of physics are expressible as\nspecifications of which transformations of physical systems can or cannot be\nbrought about with unbounded accuracy by devices capable of operating in a\ncycle ('constructors'). Hence, in particular, such specifications cannot refer\nto time. Thus, laws expressed in constructor-theoretic form automatically avoid\nthe anomalous properties of time in traditional formulations of fundamental\ntheories. But that raises the problem of how they can nevertheless give meaning\nto duration and dynamics, and thereby be compatible with traditionally\nformulated laws. Here we show how.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T15:50:46Z"}
{"aid":"http://arxiv.org/abs/2505.08695v1","title":"SPAST: Arbitrary Style Transfer with Style Priors via Pre-trained\n  Large-scale Model","summary":"Given an arbitrary content and style image, arbitrary style transfer aims to\nrender a new stylized\n  image which preserves the content image's structure and possesses the style\nimage's style. Existing\n  arbitrary style transfer methods are based on either small models or\npre-trained large-scale models.\n  The small model-based methods fail to generate high-quality stylized images,\nbringing artifacts and\n  disharmonious patterns. The pre-trained large-scale model-based methods can\ngenerate high-quality\n  stylized images but struggle to preserve the content structure and cost long\ninference time. To this\n  end, we propose a new framework, called SPAST, to generate high-quality\nstylized images with\n  less inference time. Specifically, we design a novel Local-global Window Size\nStylization Module\n  (LGWSSM)tofuse style features into content features. Besides, we introduce a\nnovel style prior loss,\n  which can dig out the style priors from a pre-trained large-scale model into\nthe SPAST and motivate\n  the SPAST to generate high-quality stylized images with short inference\ntime.We conduct abundant\n  experiments to verify that our proposed method can generate high-quality\nstylized images and less\n  inference time compared with the SOTA arbitrary style transfer methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T15:54:36Z"}
{"aid":"http://arxiv.org/abs/2505.08697v1","title":"A topos for extended Weihrauch degrees","summary":"Weihrauch reducibility is a notion of reducibility between computational\nproblems that is useful to calibrate the uniform computational strength of a\nmultivalued function. It complements the analysis of mathematical theorems done\nin reverse mathematics, as multi-valued functions on represented spaces can be\nconsidered as realizers of theorems in a natural way. Despite the rich\nliterature and the relevance of the applications of category theory in logic\nand realizability, actually there are just a few works starting to study the\nWeihrauch reducibility from a categorical point of view. The main purpose of\nthis work is to provide a full categorical account to the notion of extended\nWeihrauch reducibility introduced by A. Bauer, which generalizes the original\nnotion of Weihrauch reducibility. In particular, we present a tripos and a\ntopos for extended Weihrauch degrees. We start by defining a new tripos,\nabstracting the notion of extended Weihrauch degrees, and then we apply the\ntripos-to-topos construction to obtain the desired topos. Then we show that the\nKleene-Vesley topos is a topos of $j$-sheaves for a certain Lawvere-Tierney\ntopology over the topos of extended Weihrauch degrees.","main_category":"math.CT","categories":"math.CT,math.LO","published":"2025-05-13T15:56:30Z"}
{"aid":"http://arxiv.org/abs/2505.08705v1","title":"Controllable Image Colorization with Instance-aware Texts and Masks","summary":"Recently, the application of deep learning in image colorization has received\nwidespread attention. The maturation of diffusion models has further advanced\nthe development of image colorization models. However, current mainstream image\ncolorization models still face issues such as color bleeding and color binding\nerrors, and cannot colorize images at the instance level. In this paper, we\npropose a diffusion-based colorization method MT-Color to achieve precise\ninstance-aware colorization with use-provided guidance. To tackle color\nbleeding issue, we design a pixel-level mask attention mechanism that\nintegrates latent features and conditional gray image features through\ncross-attention. We use segmentation masks to construct cross-attention masks,\npreventing pixel information from exchanging between different instances. We\nalso introduce an instance mask and text guidance module that extracts instance\nmasks and text representations of each instance, which are then fused with\nlatent features through self-attention, utilizing instance masks to form\nself-attention masks to prevent instance texts from guiding the colorization of\nother areas, thus mitigating color binding errors. Furthermore, we apply a\nmulti-instance sampling strategy, which involves sampling each instance region\nseparately and then fusing the results. Additionally, we have created a\nspecialized dataset for instance-level colorization tasks, GPT-color, by\nleveraging large visual language models on existing image datasets. Qualitative\nand quantitative experiments show that our model and dataset outperform\nprevious methods and datasets.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-13T16:13:06Z"}
{"aid":"http://arxiv.org/abs/2505.08707v1","title":"Universal electronic synthesis by microresonator-soliton photomixing","summary":"Access to electrical signals across the millimeter-wave (mmW) and terahertz\n(THz) bands offers breakthroughs for high-performance applications. Despite\ngenerations of revolutionary development, integrated electronics are\nchallenging to operate beyond 100 GHz. Therefore, new technologies that\ngenerate wideband and tunable electronic signals would advance wireless\ncommunication, high-resolution imaging and scanning, spectroscopy, and network\nformation. Photonic approaches have been demonstrated for electronic signal\ngeneration, but at the cost of increased size and power consumption. Here, we\ndescribe a chip-scale, universal mmW frequency synthesizer, which uses\nintegrated nonlinear photonics and high-speed photodetection to exploit the\nnearly limitless bandwidth of light. We use a photonic-integrated circuit to\ngenerate dual, microresonator-soliton frequency combs whose interferogram is\nfundamentally composed of harmonic signals spanning the mmW and THz bands. By\nphase coherence of the dual comb, we precisely stabilize and synthesize the\ninterferogram to generate any output frequency from DC to >1000 GHz. Across\nthis entire range, the synthesizer exhibits exceptional absolute fractional\nfrequency accuracy and precision, characterized by an Allan deviation of\n3*10^(-12) in 1 s measurements. We use a modified uni-traveling-carrier (MUTC)\nphotodiode with an operating frequency range to 500 GHz to convert the\ninterferogram to an electrical signal, generating continuously tunable tones\nacross the entire mmW band. The synthesizer phase noise at a reference\nfrequency of 150 GHz is -83 dBc/Hz at 100 kHz offset, which exceeds the\nintrinsic performance of state-of-the-art CMOS electronics. Our work harnesses\nthe coherence, bandwidth, and integration of photonics to universally extend\nthe frequency range of current, advanced-node CMOS microwave electronics to the\nmmW and THz bands.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-13T16:13:43Z"}
{"aid":"http://arxiv.org/abs/2505.08739v1","title":"Probability Consistency in Large Language Models: Theoretical\n  Foundations Meet Empirical Discrepancies","summary":"Can autoregressive large language models (LLMs) learn consistent probability\ndistributions when trained on sequences in different token orders? We prove\nformally that for any well-defined probability distribution, sequence\nperplexity is invariant under any factorization, including forward, backward,\nor arbitrary permutations. This result establishes a rigorous theoretical\nfoundation for studying how LLMs learn from data and defines principled\nprotocols for empirical evaluation. Applying these protocols, we show that\nprior studies examining ordering effects suffer from critical methodological\nflaws. We retrain GPT-2 models across forward, backward, and arbitrary permuted\norders on scientific text. We find systematic deviations from theoretical\ninvariance across all orderings with arbitrary permutations strongly deviating\nfrom both forward and backward models, which largely (but not completely)\nagreed with one another. Deviations were traceable to differences in\nself-attention, reflecting positional and locality biases in processing. Our\ntheoretical and empirical results provide novel avenues for understanding\npositional biases in LLMs and suggest methods for detecting when LLMs'\nprobability distributions are inconsistent and therefore untrustworthy.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-13T16:52:19Z"}
{"aid":"http://arxiv.org/abs/2505.08751v1","title":"Aya Vision: Advancing the Frontier of Multilingual Multimodality","summary":"Building multimodal language models is fundamentally challenging: it requires\naligning vision and language modalities, curating high-quality instruction\ndata, and avoiding the degradation of existing text-only capabilities once\nvision is introduced. These difficulties are further magnified in the\nmultilingual setting, where the need for multimodal data in different languages\nexacerbates existing data scarcity, machine translation often distorts meaning,\nand catastrophic forgetting is more pronounced. To address the aforementioned\nchallenges, we introduce novel techniques spanning both data and modeling.\nFirst, we develop a synthetic annotation framework that curates high-quality,\ndiverse multilingual multimodal instruction data, enabling Aya Vision models to\nproduce natural, human-preferred responses to multimodal inputs across many\nlanguages. Complementing this, we propose a cross-modal model merging technique\nthat mitigates catastrophic forgetting, effectively preserving text-only\ncapabilities while simultaneously enhancing multimodal generative performance.\nAya-Vision-8B achieves best-in-class performance compared to strong multimodal\nmodels such as Qwen-2.5-VL-7B, Pixtral-12B, and even much larger\nLlama-3.2-90B-Vision. We further scale this approach with Aya-Vision-32B, which\noutperforms models more than twice its size, such as Molmo-72B and\nLLaMA-3.2-90B-Vision. Our work advances multilingual progress on the\nmulti-modal frontier, and provides insights into techniques that effectively\nbend the need for compute while delivering extremely high performance.","main_category":"cs.CL","categories":"cs.CL,cs.CV,cs.LG","published":"2025-05-13T17:03:48Z"}
{"aid":"http://arxiv.org/abs/2505.08768v1","title":"SPAT: Sensitivity-based Multihead-attention Pruning on Time Series\n  Forecasting Models","summary":"Attention-based architectures have achieved superior performance in\nmultivariate time series forecasting but are computationally expensive.\nTechniques such as patching and adaptive masking have been developed to reduce\ntheir sizes and latencies. In this work, we propose a structured pruning\nmethod, SPAT ($\\textbf{S}$ensitivity $\\textbf{P}$runer for\n$\\textbf{At}$tention), which selectively removes redundant attention mechanisms\nand yields highly effective models. Different from previous approaches, SPAT\naims to remove the entire attention module, which reduces the risk of\noverfitting and enables speed-up without demanding specialized hardware. We\npropose a dynamic sensitivity metric, $\\textbf{S}$ensitivity\n$\\textbf{E}$nhanced $\\textbf{N}$ormalized $\\textbf{D}$ispersion (SEND) that\nmeasures the importance of each attention module during the pre-training phase.\nExperiments on multivariate datasets demonstrate that SPAT-pruned models\nachieve reductions of 2.842% in MSE, 1.996% in MAE, and 35.274% in FLOPs.\nFurthermore, SPAT-pruned models outperform existing lightweight, Mamba-based\nand LLM-based SOTA methods in both standard and zero-shot inference,\nhighlighting the importance of retaining only the most effective attention\nmechanisms. We have made our code publicly available\nhttps://anonymous.4open.science/r/SPAT-6042.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-13T17:39:31Z"}
{"aid":"http://arxiv.org/abs/2505.08787v1","title":"UniSkill: Imitating Human Videos via Cross-Embodiment Skill\n  Representations","summary":"Mimicry is a fundamental learning mechanism in humans, enabling individuals\nto learn new tasks by observing and imitating experts. However, applying this\nability to robots presents significant challenges due to the inherent\ndifferences between human and robot embodiments in both their visual appearance\nand physical capabilities. While previous methods bridge this gap using\ncross-embodiment datasets with shared scenes and tasks, collecting such aligned\ndata between humans and robots at scale is not trivial. In this paper, we\npropose UniSkill, a novel framework that learns embodiment-agnostic skill\nrepresentations from large-scale cross-embodiment video data without any\nlabels, enabling skills extracted from human video prompts to effectively\ntransfer to robot policies trained only on robot data. Our experiments in both\nsimulation and real-world environments show that our cross-embodiment skills\nsuccessfully guide robots in selecting appropriate actions, even with unseen\nvideo prompts. The project website can be found at:\nhttps://kimhanjung.github.io/UniSkill.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-05-13T17:59:22Z"}
{"aid":"http://arxiv.org/abs/2505.08789v1","title":"Modelling the impact of quasar redshift errors on the full-shape\n  analysis of correlations in the Lyman-$Î±$ forest","summary":"In preparation for the first cosmological measurements from the full-shape of\nthe Lyman-$\\alpha$ (Ly$\\alpha$) forest from DESI, we must carefully model all\nrelevant systematics that might bias our analysis. It was shown in Youles et\nal. (2022) that random quasar redshift errors produce a smoothing effect on the\nmean quasar continuum in the Ly$\\alpha$ forest region. This in turn gives rise\nto spurious features in the Ly$\\alpha$ auto-correlation, and its\ncross-correlation with quasars. Using synthetic data sets based on the DESI\nsurvey, we confirm that the impact on BAO measurements is small, but that a\nbias is introduced to parameters which depend on the full-shape of our\ncorrelations. We combine a model of this contamination in the cross-correlation\n(Youles et al. 2022) with a new model we introduce here for the\nauto-correlation. These are parametrised by 3 parameters, which when included\nin a joint fit to both correlation functions, successfully eliminate any impact\nof redshift errors on our full-shape constraints. We also present a strategy\nfor removing this contamination from real data, by removing $\\sim$0.3% of\ncorrelating pairs.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-13T17:59:51Z"}
