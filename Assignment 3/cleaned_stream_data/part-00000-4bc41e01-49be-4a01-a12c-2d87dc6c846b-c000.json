{"aid":"http://arxiv.org/abs/2504.09897v1","title":"TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language\n  Models","summary":"Multimodal Large Language Models (MLLMs) have shown remarkable versatility in\nunderstanding diverse multimodal data and tasks. However, these capabilities\ncome with an increased model scale. While post-training pruning reduces model\nsize in unimodal models, its application to MLLMs often yields limited success.\nOur analysis discovers that conventional methods fail to account for the unique\ntoken attributes across layers and modalities inherent to MLLMs. Inspired by\nthis observation, we propose TAMP, a simple yet effective pruning framework\ntailored for MLLMs, featuring two key components: (1) Diversity-Aware Sparsity,\nwhich adjusts sparsity ratio per layer based on diversities among multimodal\noutput tokens, preserving more parameters in high-diversity layers; and (2)\nAdaptive Multimodal Input Activation, which identifies representative\nmultimodal input tokens using attention scores to guide unstructured weight\npruning. We validate our method on two state-of-the-art MLLMs: LLaVA-NeXT,\ndesigned for vision-language tasks, and VideoLLaMA2, capable of processing\naudio, visual, and language modalities. Empirical experiments across various\nmultimodal evaluation benchmarks demonstrate that each component of our\napproach substantially outperforms existing pruning techniques.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T05:44:38Z"}
{"aid":"http://arxiv.org/abs/2504.09918v1","title":"Berry curvature-induced intrinsic spin Hall effect in\n  light-element-based CrN system for magnetization switching","summary":"The current-induced spin-orbit torque-based devices for magnetization\nswitching are commonly relied on the 4d and 5d heavy metals owing to their\nstrong spin-orbit coupling (SOC) to produce large spin current via spin Hall\neffect (SHE). Here we present the sizable SHE in CrN, a light element-based\nsystem and demonstrate the current-induced magnetization switching in the\nadjacent ferromagnetic layer [Co(0.35nm)/Pt(0.3nm)]3, which exhibits\nperpendicular magnetic anisotropy. We found the switching current density of\n2.6 MA/cm2. The first principles calculation gives the spin Hall conductivity\n(SHC) to be 120 (hcross/e) S/cm due to intrinsic Berry curvature arising from\nSOC induced band splitting near Fermi-energy. The theoretically calculated\nintrinsic SHC is close to the experimental SHC extracted from second harmonic\nHall measurement. We estimated spin Hall angle to be 0.09, demonstrating\nefficient charge-to-spin conversion in CrN system.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T06:26:39Z"}
{"aid":"http://arxiv.org/abs/2504.09931v1","title":"A posteriori estimates for problems with monotone operators","summary":"We propose a method of obtaining a posteriori estimates which does not use\nthe duality theory and which applies to variational inequalities with monotone\noperators, without assuming the potentiality of operators. The effectiveness of\nthe method is demonstrated on problems driven by nonlinear operators of the\n$p$-Laplacian type, including the anisotropic $p$-Laplacian, polyharmonic\n$p$-Laplacian, and fractional $p$-Laplacian.","main_category":"math.AP","categories":"math.AP,cs.NA,math.NA","published":"2025-04-14T06:45:20Z"}
{"aid":"http://arxiv.org/abs/2504.09932v1","title":"A Theory of Universal Rate-Distortion-Classification Representations for\n  Lossy Compression","summary":"In lossy compression, Blau and Michaeli [5] introduced the information\nrate-distortion-perception (RDP) function, extending traditional\nrate-distortion theory by incorporating perceptual quality. More recently, this\nframework was expanded by defining the\nrate-distortion-perception-classification (RDPC) function, integrating\nmulti-task learning that jointly optimizes generative tasks such as perceptual\nquality and classification accuracy alongside reconstruction tasks [28]. To\nthat end, motivated by the concept of a universal RDP encoder introduced in\n[34], we investigate universal representations that enable diverse\ndistortion-classification tradeoffs through a single fixed encoder combined\nwith multiple decoders. Specifically, theoretical analysis and numerical\nexperiment demonstrate that for the Gaussian source under mean squared error\n(MSE) distortion, the entire distortion-classification tradeoff region can be\nachieved using one universal encoder. In addition, this paper characterizes\nachievable distortion-classification regions for fixed universal\nrepresentations in general source distributions, identifying conditions that\nensure minimal distortion penalty when reusing encoders across varying tradeoff\npoints. Experimental results using MNIST and SVHN datasets validate our\ntheoretical insights, showing that universal encoders can obtain distortion\nperformance comparable to task-specific encoders, thus supporting the\npracticality and effectiveness of our proposed universal representations.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T06:46:02Z"}
{"aid":"http://arxiv.org/abs/2504.09944v1","title":"On the mean value of $\\mathrm{GL}_1$ and $\\mathrm{GL}_2$ $L$-functions,\n  with applications to murmurations","summary":"We determine the mean value of $L$-functions attached to quadratic twists of\nautomorphic representations on $\\mathrm{GL}_1$ or $\\mathrm{GL}_2$ in large\nregions of the critical strip. In the case of $\\mathrm{GL}_1$, we go on to\nexhibit a recently discovered type of fine structure called \"murmurations\"\nunconditionally for all of our families. Our main tool is a new variant of the\napproximate functional equation imbued with a mechanism for dynamically\nrebalancing error terms while preserving holomorphicity.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T07:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.09950v1","title":"Constrained Error-Correcting Codes for Efficient DNA Synthesis","summary":"DNA synthesis is considered as one of the most expensive components in\ncurrent DNA storage systems. In this paper, focusing on a common synthesis\nmachine, which generates multiple DNA strands in parallel following a fixed\nsupersequence,we propose constrained codes with polynomial-time encoding and\ndecoding algorithms. Compared to the existing works, our codes simultaneously\nsatisfy both l-runlength limited and {\\epsilon}-balanced constraints. By\nenumerating all valid sequences, our codes achieve the maximum rate, matching\nthe capacity. Additionally, we design constrained error-correcting codes\ncapable of correcting one insertion or deletion in the obtained DNA sequence\nwhile still adhering to the constraints.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T07:25:18Z"}
{"aid":"http://arxiv.org/abs/2504.09951v1","title":"Towards Weaker Variance Assumptions for Stochastic Optimization","summary":"We revisit a classical assumption for analyzing stochastic gradient\nalgorithms where the squared norm of the stochastic subgradient (or the\nvariance for smooth problems) is allowed to grow as fast as the squared norm of\nthe optimization variable. We contextualize this assumption in view of its\ninception in the 1960s, its seemingly independent appearance in the recent\nliterature, its relationship to weakest-known variance assumptions for\nanalyzing stochastic gradient algorithms, and its relevance in deterministic\nproblems for non-Lipschitz nonsmooth convex optimization. We build on and\nextend a connection recently made between this assumption and the Halpern\niteration. For convex nonsmooth, and potentially stochastic, optimization, we\nanalyze horizon-free, anytime algorithms with last-iterate rates. For problems\nbeyond simple constrained optimization, such as convex problems with functional\nconstraints or regularized convex-concave min-max problems, we obtain rates for\noptimality measures that do not require boundedness of the feasible set.","main_category":"math.OC","categories":"math.OC,cs.LG,stat.ML","published":"2025-04-14T07:26:34Z"}
{"aid":"http://arxiv.org/abs/2504.09953v1","title":"Efficient 2D to Full 3D Human Pose Uplifting including Joint Rotations","summary":"In sports analytics, accurately capturing both the 3D locations and rotations\nof body joints is essential for understanding an athlete's biomechanics. While\nHuman Mesh Recovery (HMR) models can estimate joint rotations, they often\nexhibit lower accuracy in joint localization compared to 3D Human Pose\nEstimation (HPE) models. Recent work addressed this limitation by combining a\n3D HPE model with inverse kinematics (IK) to estimate both joint locations and\nrotations. However, IK is computationally expensive. To overcome this, we\npropose a novel 2D-to-3D uplifting model that directly estimates 3D human\nposes, including joint rotations, in a single forward pass. We investigate\nmultiple rotation representations, loss functions, and training strategies -\nboth with and without access to ground truth rotations. Our models achieve\nstate-of-the-art accuracy in rotation estimation, are 150 times faster than the\nIK-based approach, and surpass HMR models in joint localization precision.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T07:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.09958v1","title":"C-MTCSD: A Chinese Multi-Turn Conversational Stance Detection Dataset","summary":"Stance detection has become an essential tool for analyzing public\ndiscussions on social media. Current methods face significant challenges,\nparticularly in Chinese language processing and multi-turn conversational\nanalysis. To address these limitations, we introduce C-MTCSD, the largest\nChinese multi-turn conversational stance detection dataset, comprising 24,264\ncarefully annotated instances from Sina Weibo, which is 4.2 times larger than\nthe only prior Chinese conversational stance detection dataset. Our\ncomprehensive evaluation using both traditional approaches and large language\nmodels reveals the complexity of C-MTCSD: even state-of-the-art models achieve\nonly 64.07% F1 score in the challenging zero-shot setting, while performance\nconsistently degrades with increasing conversation depth. Traditional models\nparticularly struggle with implicit stance detection, achieving below 50% F1\nscore. This work establishes a challenging new benchmark for Chinese stance\ndetection research, highlighting significant opportunities for future\nimprovements.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T07:55:47Z"}
{"aid":"http://arxiv.org/abs/2504.09962v1","title":"Static Magnetic Properties of Cryogel$^{\\tiny{\\circledR}}$ and\n  Pyrogel$^{\\tiny{\\circledR}}$ at Low Temperatures and in High Magnetic Fields","summary":"The static magnetic properties of the silica-based aergoels of\nCryogel$^{\\tiny{\\circledR}}$ and Pyrogel$^{\\tiny{\\circledR}}$, manufactured by\nAspen Aerogels$^{\\tiny{\\circledR}}$, were measured over a range of temperatures\n(2 K $\\leq$ T $\\leq$ 400 K) and in magnetic fields up to 70 kG. These data and\na model of the responses are reported so these properties are familiar to\nothers who may benefit from knowing them before the materials are employed in\npotential applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T07:59:19Z"}
{"aid":"http://arxiv.org/abs/2504.09964v1","title":"Characterizing the Palomar 5 Stream: HDBSCAN Analysis and Galactic Halo\n  Constraints","summary":"We utilize the DESI Legacy Imaging Surveys DR10 to investigate the previously\nundetected faint extension of the Palomar 5 stellar stream. By applying the\nHDBSCAN clustering algorithm, we identify stream members and successfully\nextend the leading arm of the stream to approximately $\\mathrm{DEC} \\sim\n-15^\\circ$. Combining the fully detected stream with a suite of mock stream\nsimulations, we conduct a detailed comparison to constrain both the intrinsic\nproperties of the stream and the dynamical parameters of the Milky Way (MW)\nhalo. Our analysis yields a best-fit model characterized by eight parameters:\n$M_{\\mathrm{halo}} = 5.67\\times10^{11}\\ M_{\\odot}$, $r_{s,\\mathrm{halo}} =\n28.94\\ \\mathrm{kpc}$, $q_z = 0.93$, $M_{\\mathrm{gc}} = 4.31\\times10^{3}\\\nM_{\\odot}$, $dM_{\\mathrm{gc}}/dt = 1.81\\ M_{\\odot}\\ \\mathrm{Myr}^{-1}$,\n$\\mu_{\\alpha}\\cos\\delta = -2.28\\ \\mathrm{mas\\ yr}^{-1}$, $\\mu_{\\delta} = -2.26\\\n\\mathrm{mas\\ yr}^{-1}$, and $D = 23.25\\ \\mathrm{kpc}$. Notably, our constraints\non the halo shape indicate that the MW's dark matter halo exhibits a flattened\npotential, with a minor-to-major axis ratio of $q_z = 0.93$. This finding\naligns well with theoretical expectations and previous observational estimates.\nAdditionally, the best-fit model accurately reproduces the observed stream\nmorphology and dynamics, providing a more precise understanding of both the\nevolution of the stream and the overall structure of the Galactic halo.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-14T08:05:19Z"}
{"aid":"http://arxiv.org/abs/2504.09967v1","title":"Enhancing Multi-task Learning Capability of Medical Generalist\n  Foundation Model via Image-centric Multi-annotation Data","summary":"The emergence of medical generalist foundation models has revolutionized\nconventional task-specific model development paradigms, aiming to better handle\nmultiple tasks through joint training on large-scale medical datasets. However,\nrecent advances prioritize simple data scaling or architectural component\nenhancement, while neglecting to re-examine multi-task learning from a\ndata-centric perspective. Critically, simply aggregating existing data\nresources leads to decentralized image-task alignment, which fails to cultivate\ncomprehensive image understanding or align with clinical needs for\nmulti-dimensional image interpretation. In this paper, we introduce the\nimage-centric multi-annotation X-ray dataset (IMAX), the first attempt to\nenhance the multi-task learning capabilities of medical multi-modal large\nlanguage models (MLLMs) from the data construction level. To be specific, IMAX\nis featured from the following attributes: 1) High-quality data curation. A\ncomprehensive collection of more than 354K entries applicable to seven\ndifferent medical tasks. 2) Image-centric dense annotation. Each X-ray image is\nassociated with an average of 4.10 tasks and 7.46 training entries, ensuring\nmulti-task representation richness per image. Compared to the general\ndecentralized multi-annotation X-ray dataset (DMAX), IMAX consistently\ndemonstrates significant multi-task average performance gains ranging from\n3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs.\nMoreover, we investigate differences in statistical patterns exhibited by IMAX\nand DMAX training processes, exploring potential correlations between\noptimization dynamics and multi-task performance. Finally, leveraging the core\nconcept of IMAX data construction, we propose an optimized DMAX-based training\nstrategy to alleviate the dilemma of obtaining high-quality IMAX data in\npractical scenarios.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-14T08:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.09973v1","title":"Beyond Degradation Redundancy: Contrastive Prompt Learning for\n  All-in-One Image Restoration","summary":"All-in-one image restoration, addressing diverse degradation types with a\nunified model, presents significant challenges in designing task-specific\nprompts that effectively guide restoration across multiple degradation\nscenarios. While adaptive prompt learning enables end-to-end optimization, it\noften yields overlapping or redundant task representations. Conversely,\nexplicit prompts derived from pretrained classifiers enhance discriminability\nbut may discard critical visual information for reconstruction. To address\nthese limitations, we introduce Contrastive Prompt Learning (CPL), a novel\nframework that fundamentally enhances prompt-task alignment through two\ncomplementary innovations: a \\emph{Sparse Prompt Module (SPM)} that efficiently\ncaptures degradation-specific features while minimizing redundancy, and a\n\\emph{Contrastive Prompt Regularization (CPR)} that explicitly strengthens task\nboundaries by incorporating negative prompt samples across different\ndegradation types. Unlike previous approaches that focus primarily on\ndegradation classification, CPL optimizes the critical interaction between\nprompts and the restoration model itself. Extensive experiments across five\ncomprehensive benchmarks demonstrate that CPL consistently enhances\nstate-of-the-art all-in-one restoration models, achieving significant\nimprovements in both standard multi-task scenarios and challenging composite\ndegradation settings. Our framework establishes new state-of-the-art\nperformance while maintaining parameter efficiency, offering a principled\nsolution for unified image restoration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.09974v1","title":"Towards Resilient Tracking in Autonomous Vehicles: A Distributionally\n  Robust Input and State Estimation Approach","summary":"This paper proposes a novel framework for the distributionally robust input\nand state estimation (DRISE) for autonomous vehicles operating under model\nuncertainties and measurement outliers. The proposed framework improves the\ninput and state estimation (ISE) approach by integrating distributional\nrobustness, enhancing the estimator's resilience and robustness to adversarial\ninputs and unmodeled dynamics. Moment-based ambiguity sets capture\nprobabilistic uncertainties in both system dynamics and measurement noise,\noffering analytical tractability and efficiently handling uncertainties in mean\nand covariance. In particular, the proposed framework minimizes the worst-case\nestimation error, ensuring robustness against deviations from nominal\ndistributions. The effectiveness of the proposed approach is validated through\nsimulations conducted in the CARLA autonomous driving simulator, demonstrating\nimproved performance in state estimation accuracy and robustness in dynamic and\nuncertain environments.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-14T08:26:06Z"}
{"aid":"http://arxiv.org/abs/2504.09978v1","title":"New exponential law for real networks","summary":"In this article we have shown that the distributions of ksi satisfy an\nexponential law for real networks while the distributions of ksi for random\nnetworks are bell-shaped and closer to the normal distribution. The ksi\ndistributions for Barabasi-Albert and Watts-Strogatz networks are similar to\nthe ksi distributions for random networks (bell-shaped) for most parameters,\nbut when these parameters become small enough, the Barabasi-Albert and\nWatts-Strogatz networks become more realistic with respect to the ksi\ndistributions.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-14T08:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.09990v1","title":"Correlative and Discriminative Label Grouping for Multi-Label Visual\n  Prompt Tuning","summary":"Modeling label correlations has always played a pivotal role in multi-label\nimage classification (MLC), attracting significant attention from researchers.\nHowever, recent studies have overemphasized co-occurrence relationships among\nlabels, which can lead to overfitting risk on this overemphasis, resulting in\nsuboptimal models. To tackle this problem, we advocate for balancing\ncorrelative and discriminative relationships among labels to mitigate the risk\nof overfitting and enhance model performance. To this end, we propose the\nMulti-Label Visual Prompt Tuning framework, a novel and parameter-efficient\nmethod that groups classes into multiple class subsets according to label\nco-occurrence and mutual exclusivity relationships, and then models them\nrespectively to balance the two relationships. In this work, since each group\ncontains multiple classes, multiple prompt tokens are adopted within Vision\nTransformer (ViT) to capture the correlation or discriminative label\nrelationship within each group, and effectively learn correlation or\ndiscriminative representations for class subsets. On the other hand, each group\ncontains multiple group-aware visual representations that may correspond to\nmultiple classes, and the mixture of experts (MoE) model can cleverly assign\nthem from the group-aware to the label-aware, adaptively obtaining label-aware\nrepresentation, which is more conducive to classification. Experiments on\nmultiple benchmark datasets show that our proposed approach achieves\ncompetitive results and outperforms SOTA methods on multiple pre-trained\nmodels.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.10004v1","title":"An Image is Worth $K$ Topics: A Visual Structural Topic Model with\n  Pretrained Image Embeddings","summary":"Political scientists are increasingly interested in analyzing visual content\nat scale. However, the existing computational toolbox is still in need of\nmethods and models attuned to the specific challenges and goals of social and\npolitical inquiry. In this article, we introduce a visual Structural Topic\nModel (vSTM) that combines pretrained image embeddings with a structural topic\nmodel. This has important advantages compared to existing approaches. First,\npretrained embeddings allow the model to capture the semantic complexity of\nimages relevant to political contexts. Second, the structural topic model\nprovides the ability to analyze how topics and covariates are related, while\nmaintaining a nuanced representation of images as a mixture of multiple topics.\nIn our empirical application, we show that the vSTM is able to identify topics\nthat are interpretable, coherent, and substantively relevant to the study of\nonline political communication.","main_category":"cs.CV","categories":"cs.CV,cs.CY,stat.AP,stat.ME","published":"2025-04-14T09:07:11Z"}
{"aid":"http://arxiv.org/abs/2504.10019v1","title":"Sagbi bases, defining ideals and algebra of minors","summary":"This paper extends the article of the Bruns and Conca on SAGBI bases and\ntheir computation (J. Symb. Comput. 120 (2024)) in two directions. (i) We\ndescribe the extension of the Singular library sagbiNormaliz.sing to the\ncomputation of defining ideals of subalgebras of polynomial rings. (ii) We give\na complete classification of the algebras of minors for which the generating\nset is a SAGBI basis with respect to a suitable monomial order and we identify\nuniversal SAGBI basis in three cases. The investigation is illustrated by\nseveral examples.","main_category":"math.AC","categories":"math.AC","published":"2025-04-14T09:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.10020v1","title":"The Mirage of Performance Gains: Why Contrastive Decoding Fails to\n  Address Multimodal Hallucination","summary":"Contrastive decoding strategies are widely used to reduce hallucinations in\nmultimodal large language models (MLLMs). These methods work by constructing\ncontrastive samples to induce hallucinations and then suppressing them in the\noutput distribution. However, this paper demonstrates that such approaches fail\nto effectively mitigate the hallucination problem. The performance improvements\nobserved on POPE Benchmark are largely driven by two misleading factors: (1)\ncrude, unidirectional adjustments to the model's output distribution and (2)\nthe adaptive plausibility constraint, which reduces the sampling strategy to\ngreedy search. To further illustrate these issues, we introduce a series of\nspurious improvement methods and evaluate their performance against contrastive\ndecoding techniques. Experimental results reveal that the observed performance\ngains in contrastive decoding are entirely unrelated to its intended goal of\nmitigating hallucinations. Our findings challenge common assumptions about the\neffectiveness of contrastive decoding strategies and pave the way for\ndeveloping genuinely effective solutions to hallucinations in MLLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CV","published":"2025-04-14T09:25:37Z"}
{"aid":"http://arxiv.org/abs/2504.10021v1","title":"Masked Autoencoder Self Pre-Training for Defect Detection in\n  Microelectronics","summary":"Whereas in general computer vision, transformer-based architectures have\nquickly become the gold standard, microelectronics defect detection still\nheavily relies on convolutional neural networks (CNNs). We hypothesize that\nthis is due to the fact that a) transformers have an increased need for data\nand b) labelled image generation procedures for microelectronics are costly,\nand labelled data is therefore sparse. Whereas in other domains, pre-training\non large natural image datasets can mitigate this problem, in microelectronics\ntransfer learning is hindered due to the dissimilarity of domain data and\nnatural images. Therefore, we evaluate self pre-training, where models are\npre-trained on the target dataset, rather than another dataset. We propose a\nvision transformer (ViT) pre-training framework for defect detection in\nmicroelectronics based on masked autoencoders (MAE). In MAE, a large share of\nimage patches is masked and reconstructed by the model during pre-training. We\nperform pre-training and defect detection using a dataset of less than 10.000\nscanning acoustic microscopy (SAM) images labelled using transient thermal\nanalysis (TTA). Our experimental results show that our approach leads to\nsubstantial performance gains compared to a) supervised ViT, b) ViT pre-trained\non natural image datasets, and c) state-of-the-art CNN-based defect detection\nmodels used in the literature. Additionally, interpretability analysis reveals\nthat our self pre-trained models, in comparison to ViT baselines, correctly\nfocus on defect-relevant features such as cracks in the solder material. This\ndemonstrates that our approach yields fault-specific feature representations,\nmaking our self pre-trained models viable for real-world defect detection in\nmicroelectronics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10027v1","title":"Deconfined Quantum Critical Point: A Review of Progress","summary":"Deconfined quantum critical points (DQCPs) have been proposed as a class of\ncontinuous quantum phase transitions occurring between two ordered phases with\ndistinct symmetry-breaking patterns, beyond the conventional framework of\nLandau-Ginzburg-Wilson (LGW) theory. At the DQCP, the system exhibits emergent\ngauge fields, fractionalized excitations, and enhanced symmetries. Here we\nreview recent theoretical and experimental progress on exploring DQCPs in\ncondensed matter systems. We first introduce theoretical advancements in the\nstudy of DQCPs over the past twenty years, particularly in magnetic models on\nsquare lattices, honeycomb lattices, kagome lattices, and one-dimensional spin\nchains. We then discuss recent progress on experimental realization of DQCP in\nquantum magnetic systems. Experimentally, the Shastry-Sutherland model,\nrealized in SrCu$_2$(BO$_3$)$_2$, offers a particularly promising platform for\nrealizing DQCPs. The magnetic frustration inherent to this model drives phase\ntransitions between two distinct symmetry-breaking states: a valence bond solid\n(VBS) phase and a N\\'{e}el antiferromagnetic phase. Remarkably,\nSrCu$_2$(BO$_3$)$_2$ has provided the first experimental evidence of a\nproximate DQCP through a field-induced Bose-Einstein condensation,\ntransitioning from the VBS state to the N\\'{e}el state. Nevertheless, the\ndirect experimental realization of a DQCP remains a significant challenge.\nDespite this, it offers a promising platform for exploring emergent phenomena\nthrough quantum phase transition in low-dimensional quantum systems.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-14T09:31:58Z"}
{"aid":"http://arxiv.org/abs/2504.10030v1","title":"EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical\n  Challenge in Multi-Robot Control","summary":"This paper introduces EmbodiedAgent, a hierarchical framework for\nheterogeneous multi-robot control. EmbodiedAgent addresses critical limitations\nof hallucination in impractical tasks. Our approach integrates a next-action\nprediction paradigm with a structured memory system to decompose tasks into\nexecutable robot skills while dynamically validating actions against\nenvironmental constraints. We present MultiPlan+, a dataset of more than 18,000\nannotated planning instances spanning 100 scenarios, including a subset of\nimpractical cases to mitigate hallucination. To evaluate performance, we\npropose the Robot Planning Assessment Schema (RPAS), combining automated\nmetrics with LLM-aided expert grading. Experiments demonstrate EmbodiedAgent's\nsuperiority over state-of-the-art models, achieving 71.85% RPAS score.\nReal-world validation in an office service task highlights its ability to\ncoordinate heterogeneous robots for long-horizon objectives.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T09:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.10054v1","title":"Implementation and Performance Evaluation of TCP over QUIC Tunnels","summary":"QUIC, a UDP-based transport protocol, addresses several limitations of TCP by\noffering built-in encryption, stream multiplexing, and improved loss recovery.\nTo extend these benefits to legacy TCP-based applications, this paper explores\nthe implementation and evaluation of a TCP over QUIC tunneling approach. A\nlightweight, stream-based tunnel is constructed using the Rust-based Quinn\nlibrary, enabling TCP traffic to traverse QUIC connections transparently.\nPerformance is evaluated under varying network conditions, including packet\nloss, high latency, and out-of-order delivery. Results indicate that TCP over\nQUIC maintains significantly higher throughput than native TCP in lossy or\nunstable environments, with up to a high improvement under 20\\% packet loss.\nHowever, under ideal network conditions, tunneling introduces modest overhead\ndue to encryption and user-space processing. These findings provide insights\ninto the trade-offs of TCP over QUIC tunneling and its suitability for\ndeployment in dynamic or impaired networks.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-14T09:57:35Z"}
{"aid":"http://arxiv.org/abs/2504.10056v1","title":"CMOS-compatible vanadium dioxide via Pulsed Laser and Atomic Layer\n  deposition: towards ultra-thin film phase-change layers","summary":"Vanadium dioxide, a well-known Mott insulator, is a highly studied electronic\nmaterial with promising applications in information processing and storage.\nWhile fully crystalline layers exhibit exceptional properties, such as a sharp\nand abrupt conductivity change at the metal-insulator transition, fabricating\npoly-crystalline films on silicon substrates often involves trade-offs in\ntransport characteristics and switching performance, especially for ultra-thin\nlayers required in advanced gate applications. In this study, we explore the\ngrowth of vanadium dioxide films on standard wet-oxidized silicon wafers using\ntwo established deposition techniques with pulsed laser deposition and atomic\nlayer deposition. Thin films, ranging in thickness from 200 to 10 nano meters,\nwere systematically characterized through structural and electrical analyses to\noptimize key growth parameters. Temperature and pressure were identified as the\nprimary factors affecting film quality, and the optimal growth conditions\nacross the entire thickness range are discussed in detail. We demonstrate that\nboth pulsed laser deposition and atomic layer deposition methods can\nsuccessfully produce ultra-thin vanadium dioxide layers down to 8 nano meters\nwith functional properties suitable for practical applications. This work\nunderscores the potential of vanadium dioxide for fully industry compatible\nphase-change switching devices and provides valuable insights into optimizing\ngrowth processes for poly-crystalline films.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-14T09:59:24Z"}
{"aid":"http://arxiv.org/abs/2504.10074v1","title":"MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation\n  Framework","summary":"Recent advancements in large language models (LLMs) and multi-modal LLMs have\nbeen remarkable. However, these models still rely solely on their parametric\nknowledge, which limits their ability to generate up-to-date information and\nincreases the risk of producing erroneous content. Retrieval-Augmented\nGeneration (RAG) partially mitigates these challenges by incorporating external\ndata sources, yet the reliance on databases and retrieval systems can introduce\nirrelevant or inaccurate documents, ultimately undermining both performance and\nreasoning quality. In this paper, we propose Multi-Modal Knowledge-Based\nRetrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework\nthat leverages the inherent knowledge boundaries of models to dynamically\ngenerate semantic tags for the retrieval process. This strategy enables the\njoint filtering of retrieved documents, retaining only the most relevant and\naccurate references. Extensive experiments on knowledge-based visual\nquestion-answering tasks demonstrate the efficacy of our approach: on the E-VQA\ndataset, our method improves performance by +4.2\\% on the Single-Hop subset and\n+0.4\\% on the full dataset, while on the InfoSeek dataset, it achieves gains of\n+7.8\\% on the Unseen-Q subset, +8.2\\% on the Unseen-E subset, and +8.1\\% on the\nfull dataset. These results highlight significant enhancements in both accuracy\nand robustness over the current state-of-the-art MLLM and RAG frameworks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-14T10:19:47Z"}
{"aid":"http://arxiv.org/abs/2504.10092v1","title":"Bayesian optimal experimental design with Wasserstein information\n  criteria","summary":"Bayesian optimal experimental design (OED) provides a principled framework\nfor selecting the most informative observational settings in experiments. With\nrapid advances in computational power, Bayesian OED has become increasingly\nfeasible for inference problems involving large-scale simulations, attracting\ngrowing interest in fields such as inverse problems. In this paper, we\nintroduce a novel design criterion based on the expected Wasserstein-$p$\ndistance between the prior and posterior distributions. Especially, for $p=2$,\nthis criterion shares key parallels with the widely used expected information\ngain (EIG), which relies on the Kullback--Leibler divergence instead. First,\nthe Wasserstein-2 criterion admits a closed-form solution for Gaussian\nregression, a property which can be also leveraged for approximative schemes.\nSecond, it can be interpreted as maximizing the information gain measured by\nthe transport cost incurred when updating the prior to the posterior. Our main\ncontribution is a stability analysis of the Wasserstein-1 criterion, where we\nprovide a rigorous error analysis under perturbations of the prior or\nlikelihood. We partially extend this study also to the Wasserstein-2 criterion.\nIn particular, these results yield error rates when empirical approximations of\npriors are used. Finally, we demonstrate the computability of the Wasserstein-2\ncriterion and demonstrate our approximation rates through simulations.","main_category":"stat.ME","categories":"stat.ME,cs.NA,math.NA,stat.CO","published":"2025-04-14T10:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.10116v1","title":"Application of nanodiamond-polymer composite holographic gratings in a\n  very cold neutron interferometer","summary":"In recent decades, photosensitive materials have been used for the\ndevelopment of optical devices not only for light, but also for cold and very\ncold neutrons. We show that holographically recorded gratings in\nnanodiamond-polymer composites (nDPC) form ideal diffraction elements for very\ncold neutrons. Their advantage of high diffraction efficiency, combined with\nlow angular selectivity as a two-port beam splitter, meets the necessary\nconditions for application in a very cold neutron interferometer. We provide an\noverview of the latest achievements in the construction of such a triple Laue\ninterferometer. A first operational test of the interferometer is planned\nimmediately after this conference in May 2025.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T11:26:03Z"}
{"aid":"http://arxiv.org/abs/2504.10119v1","title":"Non-intrusive Auto-detecting and Adaptive Hybrid Scheme for Multiscale\n  Heat Transfer: Thermal Runaway in a Battery Pack","summary":"Accurately capturing and simulating multiscale systems is a formidable\nchallenge, as both spatial and temporal scales can span many orders of\nmagnitude. Rigorous upscaling methods not only ensure efficient computation,\nbut also maintains errors within a priori prescribed limits. This provides a\nbalance between computational costs and accuracy. However, the most significant\ndifficulties arise when the conditions under which upscaled models can be\napplied cease to hold. To address this, we develop an automatic-detecting and\nadaptive, nonintrusive two-sided hybrid method for multiscale heat transfer and\napply it to thermal runaway in a battery pack. To allow adaptive hybrid\nsimulations, two kernels are developed to dynamically map the values between\nthe fine-scale and the upscaled subdomains in a single simulation. The accuracy\nof the developed hybrid method is demonstrated through conducting a series of\nthermal runaway test cases in a battery pack. Our results show that the maximum\nspatial errors consistently remain below the threshold bounded by upscaling\nerrors.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-14T11:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.10122v1","title":"Design Optimization of Flip FET Standard Cells with Dual-sided Pins for\n  Ultimate Scaling","summary":"Recently, we proposed a novel transistor architecture for 3D stacked FETs\ncalled Flip FET (FFET), featuring N/P transistors back-to-back stacked and\ndual-sided interconnects. With dual-sided power rails and signal tracks, FFET\ncan achieve an aggressive 2.5T cell height. As a tradeoff, the complex\nstructure and limited numbers of M0 tracks could limit the standard cell\ndesign. As a solution, multiple innovations were introduced and examined in\nthis work. Based on an advanced node design rule, several unique building\nblocks in FFET such as drain merge (DM), gate merge (GM), field drain merge\n(FDM) and buried signal track (BST) were investigated. Other key design\nconcepts of multi-row, split gate and dummy gate insertion (DG) were also\ncarefully studied, delivering around 35.6% area reduction compared with 3T\nCFET. Furthermore, the symmetric design of FFET has unique superiority over\nCFET thanks to the separate N/P logic on two sides of the wafer and their\nconnections using DM and GM. New routing scheme with dual-sided output pins on\nboth wafer frontside (FS) and backside (BS) was proposed for the first time.\nFinally, we conducted a comprehensive evaluation on complex cell design, taking\nAOI22 as an example. New strategies were proposed and examined. The FDM design\nis identified as the best, outperforming the BST and dummy gate design by 1.93%\nand 5.13% for the transition delay.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T11:31:44Z"}
{"aid":"http://arxiv.org/abs/2504.10128v1","title":"Probing Binary Lens Caustics with Gravitational Waves: A Uniform\n  Approximation Approach","summary":"We present a new framework for modeling gravitational wave diffraction near\nfold caustics using the Uniform Approximation (UA), focusing on binary mass\nlenses-axially asymmetric systems with complex caustic structures. Full-wave\nmethods based on the Kirchhoff integral become impractical in this regime due\nto highly oscillatory integrands. The UA provides a robust and accurate\ndescription of the wave field near folds, resolving the breakdown of\nGeometrical Optics at caustics and improving upon Transitional\nAsymptotics-based on Airy function approximations-which lack global validity.\nCentral to our approach is the concept of the caustic width, $d_c$, a\ncharacteristic length scale defining the region where diffraction significantly\nalters wave propagation. We find that $d_c$ scales universally with the\ngravitational wavelength as ~ $ \\lambda^{2/3}$ and inversely with the\nredshifted lens mass as ~ $ M_{Lz}^{-2/3}$. The wave amplification near the\nfold grows as ~ $ d_c^{-1/4}$, substantially enhancing the signal and\npotentially playing a key role in the detection of gravitational waves lensed\nnear caustics. Notably, for lens masses below the galactic scale, the caustic\nwidth for gravitational waves is not negligible compared to the Einstein\nradius-as it is in electromagnetic lensing-making the UA essential for\naccurately capturing wave effects.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T11:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.10140v1","title":"The topology of synergy: linking topological and information-theoretic\n  approaches to higher-order interactions in complex systems","summary":"The study of irreducible higher-order interactions has become a core topic of\nstudy in complex systems. Two of the most well-developed frameworks,\ntopological data analysis and multivariate information theory, aim to provide\nformal tools for identifying higher-order interactions in empirical data.\nDespite similar aims, however, these two approaches are built on markedly\ndifferent mathematical foundations and have been developed largely in parallel.\nIn this study, we present a head-to-head comparison of topological data\nanalysis and information-theoretic approaches to describing higher-order\ninteractions in multivariate data; with the aim of assessing the similarities\nand differences between how the frameworks define ``higher-order structures.\"\nWe begin with toy examples with known topologies, before turning to\nnaturalistic data: fMRI signals collected from the human brain. We find that\nintrinsic, higher-order synergistic information is associated with\nthree-dimensional cavities in a point cloud: shapes such as spheres are\nsynergy-dominated. In fMRI data, we find strong correlations between\nsynergistic information and both the number and size of three-dimensional\ncavities. Furthermore, we find that dimensionality reduction techniques such as\nPCA preferentially represent higher-order redundancies, and largely fail to\npreserve both higher-order information and topological structure, suggesting\nthat common manifold-based approaches to studying high-dimensional data are\nsystematically failing to identify important features of the data. These\nresults point towards the possibility of developing a rich theory of\nhigher-order interactions that spans topological and information-theoretic\napproaches while simultaneously highlighting the profound limitations of more\nconventional methods.","main_category":"cs.IT","categories":"cs.IT,math.IT,q-bio.NC","published":"2025-04-14T11:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.10143v1","title":"Negate or Embrace: On How Misalignment Shapes Multimodal Representation\n  Learning","summary":"Multimodal representation learning, exemplified by multimodal contrastive\nlearning (MMCL) using image-text pairs, aims to learn powerful representations\nby aligning cues across modalities. This approach relies on the core assumption\nthat the exemplar image-text pairs constitute two representations of an\nidentical concept. However, recent research has revealed that real-world\ndatasets often exhibit misalignment. There are two distinct viewpoints on how\nto address this issue: one suggests mitigating the misalignment, and the other\nleveraging it. We seek here to reconcile these seemingly opposing perspectives,\nand to provide a practical guide for practitioners. Using latent variable\nmodels we thus formalize misalignment by introducing two specific mechanisms:\nselection bias, where some semantic variables are missing, and perturbation\nbias, where semantic variables are distorted -- both affecting latent variables\nshared across modalities. Our theoretical analysis demonstrates that, under\nmild assumptions, the representations learned by MMCL capture exactly the\ninformation related to the subset of the semantic variables invariant to\nselection and perturbation biases. This provides a unified perspective for\nunderstanding misalignment. Based on this, we further offer actionable insights\ninto how misalignment should inform the design of real-world ML systems. We\nvalidate our theoretical findings through extensive empirical studies on both\nsynthetic data and real image-text datasets, shedding light on the nuanced\nimpact of misalignment on multimodal representation learning.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-14T11:54:19Z"}
{"aid":"http://arxiv.org/abs/2504.10151v1","title":"Continual learning for rotating machinery fault diagnosis with\n  cross-domain environmental and operational variations","summary":"Although numerous machine learning models exist to detect issues like rolling\nbearing strain and deformation, typically caused by improper mounting,\noverloading, or poor lubrication, these models often struggle to isolate faults\nfrom the noise of real-world operational and environmental variability.\nConditions such as variable loads, high temperatures, stress, and rotational\nspeeds can mask early signs of failure, making reliable detection challenging.\nTo address these limitations, this work proposes a continual deep learning\napproach capable of learning across domains that share underlying structure\nover time. This approach goes beyond traditional accuracy metrics by addressing\nfour second-order challenges: catastrophic forgetting (where new learning\noverwrites past knowledge), lack of plasticity (where models fail to adapt to\nnew data), forward transfer (using past knowledge to improve future learning),\nand backward transfer (refining past knowledge with insights from new domains).\nThe method comprises a feature generator and domain-specific classifiers,\nallowing capacity to grow as new domains emerge with minimal interference,\nwhile an experience replay mechanism selectively revisits prior domains to\nmitigate forgetting. Moreover, nonlinear dependencies across domains are\nexploited by prioritizing replay from those with the highest prior errors,\nrefining models based on most informative past experiences. Experiments show\nhigh average domain accuracy (up to 88.96%), with forgetting measures as low as\n.0027 across non-stationary class-incremental environments.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T12:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.10168v1","title":"HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for\n  Hallucination Detection","summary":"In this paper, we present HalluSearch, a multilingual pipeline designed to\ndetect fabricated text spans in Large Language Model (LLM) outputs. Developed\nas part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and\nRelated Observable Overgeneration Mistakes, HalluSearch couples\nretrieval-augmented verification with fine-grained factual splitting to\nidentify and localize hallucinations in fourteen different languages. Empirical\nevaluations show that HalluSearch performs competitively, placing fourth in\nboth English (within the top ten percent) and Czech. While the system's\nretrieval-based strategy generally proves robust, it faces challenges in\nlanguages with limited online coverage, underscoring the need for further\nresearch to ensure consistent hallucination detection across diverse linguistic\ncontexts.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.10175v1","title":"Global-in-time Well-posedness of Classical Solutions to the Vacuum Free\n  Boundary Problem for the Viscous Saint-Venant System with Large Data","summary":"We establish the global well-posedness of classical solutions to the vacuum\nfree boundary problem of the 1-D viscous Saint-Venant system with large data.\nSince the depth $\\rho$ of the fluid vanishes on the moving boundary, the\nmomentum equations become degenerate both in the time evolution and spatial\ndissipation, which may lead to singularities for the derivatives of the\nvelocity u of the fluid and then makes it challenging to study classical\nsolutions. By exploiting the intrinsic degenerate-singular structures of this\nsystem, we are able to identify two classes of admissible initial depth profile\nand obtain the global well-posedness theory here: $\\rho_0^\\alpha\\in H^3$\n$(\\frac{1}{3}<\\alpha<1)$ vanishes as the distance to the moving boundary, which\nsatisfies the BD entropy condition; while $\\rho_0\\in H^3$ vanishes as the\ndistance to the moving boundary, which satisfies the physical vacuum boundary\ncondition, but violates the BD entropy condition. Further, it is shown that for\narbitrarily large time, the solutions obtained here are smooth (in Sobolev\nspaces) all the way up to the moving boundary. One of the key ingredients of\nthe analysis here is to establish some degenerate weighted estimates for the\neffective velocity $v=u+ (\\log\\rho)_y$ (y is the Eulerian spatial coordinate)\nvia its transport properties, which enables one to obtain the upper bounds for\nthe first order derivatives of the flow map $\\eta$. Then the global regularity\nuniformly up to the vacuum boundary can be obtained by carrying out a series of\nweighted energy estimates carefully designed for this system. It is worth\npointing out that the result here seems to be the first global existence theory\nof classical solutions with large data that is independent of the BD entropy\nfor such degenerate systems, and the methodology developed here can be applied\nto more general degenerate CNS.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T12:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.10179v1","title":"The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental\n  Evaluation of Prompt Engineering Methods for Robust Multimodal Performance","summary":"Multimodal Large Language Models (MLLMs) are set to transform how machines\nprocess and generate human-like responses by integrating diverse modalities\nsuch as text, images, and code. Yet, effectively harnessing their capabilities\nhinges on optimal prompt engineering. We present a comprehensive experimental\nevaluation of seven prompt engineering methods applied to 13 open-source MLLMs\nover 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding\nand Alignment, Complex Code Generation and Execution, and Knowledge Retrieval\nand Integration. Our approach stratifies models by parameter count into Small\n(<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting\ntechniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought,\nAnalogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel\nin structured tasks such as code generation, achieving accuracies up to 96.88%\nunder Few-Shot prompting, all models struggle with complex reasoning and\nabstract understanding, often yielding accuracies below 60% and high\nhallucination rates. Structured reasoning prompts frequently increased\nhallucination up to 75% in small models and led to longer response times (over\n20 seconds in Large MLLMs), while simpler prompting methods provided more\nconcise and efficient outputs. No single prompting method uniformly optimises\nall task types. Instead, adaptive strategies combining example-based guidance\nwith selective structured reasoning are essential to enhance robustness,\nefficiency, and factual accuracy. Our findings offer practical recommendations\nfor prompt engineering and support more reliable deployment of MLLMs across\napplications including AI-assisted coding, knowledge retrieval, and multimodal\ncontent understanding.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.ET","published":"2025-04-14T12:31:39Z"}
{"aid":"http://arxiv.org/abs/2504.10191v1","title":"Localized Cultural Knowledge is Conserved and Controllable in Large\n  Language Models","summary":"Just as humans display language patterns influenced by their native tongue\nwhen speaking new languages, LLMs often default to English-centric responses\neven when generating in other languages. Nevertheless, we observe that local\ncultural information persists within the models and can be readily activated\nfor cultural customization. We first demonstrate that explicitly providing\ncultural context in prompts significantly improves the models' ability to\ngenerate culturally localized responses. We term the disparity in model\nperformance with versus without explicit cultural context the explicit-implicit\nlocalization gap, indicating that while cultural knowledge exists within LLMs,\nit may not naturally surface in multilingual interactions if cultural context\nis not explicitly provided. Despite the explicit prompting benefit, however,\nthe answers reduce in diversity and tend toward stereotypes. Second, we\nidentify an explicit cultural customization vector, conserved across all\nnon-English languages we explore, which enables LLMs to be steered from the\nsynthetic English cultural world-model toward each non-English cultural world.\nSteered responses retain the diversity of implicit prompting and reduce\nstereotypes to dramatically improve the potential for customization. We discuss\nthe implications of explicit cultural customization for understanding the\nconservation of alternative cultural world models within LLMs, and their\ncontrollable utility for translation, cultural customization, and the\npossibility of making the explicit implicit through soft control for expanded\nLLM function and appeal.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.10206v1","title":"Approximation by Neural Network Sampling Operators in Mixed Lebesgue\n  Spaces","summary":"In this paper, we prove the rate of approximation for the Neural Network\nSampling Operators activated by sigmoidal functions with mixed Lebesgue norm in\nterms of averaged modulus of smoothness for a bounded measurable functions on\nbounded domain. In order to achieve the above result, we first establish that\nthe averaged modulus of smoothness is finite for certain suitable subspaces of\n$L^{p,q}(\\mathbb{R}\\times\\mathbb{R}).$ Using the properties of averaged modulus\nof smoothness, we estimate the rate of approximation of certain linear\noperators in mixed Lebesgue norm. Then, as an application of these linear\noperators, we obtain the Jackson type approximation theorem, in order to give a\ncharacterization for the rate of approximation of neural network operators\nin-terms of averaged modulus of smoothness in mixed norm. Lastly, we discuss\nsome examples of sigmoidal functions and using these sigmoidal functions, we\nshow the implementation of continuous and discontinuous functions by neural\nnetwork operators.","main_category":"math.FA","categories":"math.FA","published":"2025-04-14T13:16:17Z"}
{"aid":"http://arxiv.org/abs/2504.10211v1","title":"Energy-preserving iteration schemes for Gauss collocation integrators","summary":"In this work, we develop energy-preserving iterative schemes for the\n(non-)linear systems arising in the Gauss integration of Poisson systems with\nquadratic Hamiltonian. Exploiting the relation between Gauss collocation\nintegrators and diagonal Pad\\'e approximations, we establish a Krylov-subspace\niteration scheme based on a $Q$-Arnoldi process for linear systems that\nprovides energy conservation not only at convergence --as standard iteration\nschemes do--, but also at the level of the individual iterates. It is\ncompetitive with GMRES in terms of accuracy and cost for a single iteration\nstep and hence offers significant efficiency gains, when it comes to time\nintegration of high-dimensional Poisson systems within given error tolerances.\nOn top of the linear results, we consider non-linear Poisson systems and design\nnon-linear solvers for the implicit midpoint rule (Gauss integrator of second\norder), using the fact that the associated Pad\\'e approximation is a Cayley\ntransformation. For the non-linear systems arising at each time step, we\npropose fixed-point and Newton-type iteration schemes that inherit the\nconvergence order with comparable cost from their classical versions, but have\nenergy-preserving iterates.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T13:26:38Z"}
{"aid":"http://arxiv.org/abs/2504.10213v1","title":"The HYDRA pion-tracker for hypernuclei studies at R3B","summary":"The HYpernuclei-Decay at R3B Apparatus (HYDRA) tracker is a novel time\nprojection chamber combined with a plastic scintillator wall for timing and\ntrigger purposes. This detector is a low radiation length tracker dedicated to\nmeasuring pions from the weak decay of light hypernuclei produced from ion-ion\ncollisions at few GeV/nucleon in the magnetic field of the large-acceptance\ndipole magnet GLAD at the Reactions with Relativistic Radioactive Beams (R3B)\nexperiment at GSI-FAIR. In this paper, we describe the design of the detector\nand provide the results of its first characterizations.","main_category":"physics.ins-det","categories":"physics.ins-det,nucl-ex","published":"2025-04-14T13:29:59Z"}
{"aid":"http://arxiv.org/abs/2504.10223v1","title":"A proof of the Krzyz conjecture","summary":"A proof of the Krzyz conjecture is presented, based on the application of the\nvariational method, as well as on the use of two classical results and some of\ntheir consequences. The mentioned results are the Caratheodory-Toeplitz\ncriterion of continuing a polynomial to a Caratheodory class function, and the\nRiesz-Fejer theorem about trigonometric polynomials. This is an English\ntranslation of a preprint originally published in Russian:\nhttps://preprints.ru/article/1799","main_category":"math.CV","categories":"math.CV","published":"2025-04-14T13:44:52Z"}
{"aid":"http://arxiv.org/abs/2504.10224v1","title":"Simulation and Experimental Validation of Optical Camera Communication","summary":"While simulation tools for visible light communication (VLC) with photo\ndetectors (PDs) have been widely investigated, similar tools for optical camera\ncommunication (OCC) with complementary metal oxide semiconductor (CMOS) sensors\nare lacking in this regard. Camera based VLC systems have much lower data rates\nowing to camera exposure times. Among the few extant OCC simulation tools, none\nallow for simulation of images when exposure time is greater than the signal\nperiod. An accurate simulation of the OCC system can be used to improve the\ndata rate and quality of performance. We propose a simple simulation technique\nfor OCC which allows to test for system performance at frequencies beyond the\ncamera shutter speed. This will allow much needed data rate improvement by\noperating at the actual frequency a decoding algorithm ceases detection instead\nof the exposure limit used now. We have tested the accuracy of simulation by\ncomparing the detection success rates of simulated images with experimental\nimages. The proposed simulation technique was shown to be accurate through\nexperimental validation for two different cameras.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T13:45:09Z"}
{"aid":"http://arxiv.org/abs/2504.10228v1","title":"Magneto-Hydrodynamic Simulations of Eccentric Binary Neutron Star\n  Mergers","summary":"Highly eccentric binary neutron star mergers exhibit unique dynamical and\nobservational signatures compared to quasi-circular ones in terms of their\ngravitational wave signal and the ejection of matter, leading to different\nelectromagnetic counterparts. In this article, we present general relativistic\nmagneto-hydrodynamic simulations of binary neutron star systems on highly\neccentric orbits. While in quasi-circular binaries, the influence of the\nmagnetic field is too weak to affect the general pre-merger dynamics, the close\nencounters in eccentric systems could potentially trigger magneto-hydrodynamic\ninstabilities. Therefore, we investigate possible effects before, during, and\nafter the merger for a total of three different systems with varying initial\neccentricity.\n  We study the f-mode oscillations excited by tidal interaction in close\nencounters and find good agreement with predicted f-mode frequency estimates.\nHowever, our simulations reveal no significant differences compared to results\nneglecting the magnetic field. Although we observe a rearrangement of the\npoloidal structure of the magnetic field inside the stars, there is no relevant\nincrease in the magnetic energy during the encounters. Also, during the merger,\nthe amplification of the magnetic field seems to be largely independent of the\neccentricity in our systems. Consistent with studies of merging non-magnetized\nbinary neutron stars, we find a correlation between eccentricity and mass\nejection, with a higher impact parameter leading to a larger amount of unbound\nmaterial.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-14T13:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.10237v1","title":"Tailoring Neel orders in Layered Topological Antiferromagnets","summary":"In the two-dimensional limit, the interplay between Neel order and band\ntopology in van der Waals topological antiferromagnets can give rise to novel\nquantum phenomena in the quantum anomalous Hall state, including the cascaded\nquantum phase transition and spin-modulation effect. However, due to the\nabsence of net magnetization in antiferromagnets, probing the energetically\ndegenerate Neel orders has long remained a significant challenge. Inspired by\nrecent advances in realizing the quantum anomalous Hall effect in AlOx-capped\nlayered topological antiferromagnet MnBi2Te4, we demonstrate deterministic\ncontrol over the Neel order through surface anisotropy engineering enabled by\nthe AlOx capping layer. By tuning the surface anisotropy, we uncover\nparitydependent symmetry breaking states that manifest as distinct odd-even\nboundary architectures, including 180 degree domain walls or continuous spin\nstructures. Comparative studies between AlOx-capped and pristine odd-layer\nMnBi2Te4 flakes using domain-resolved magnetic force microscopy reveal\npronounced differences in coercivity and magnetization-reversal dynamics.\nNotably, an unconventional giant exchange bias, which arises from perpendicular\nmagnetic anisotropy rather than traditional interface pinning mechanisms, is\nobserved for the first time. Our findings establish a pathway for manipulating\nNeel order through surface modification in A-type antiferromagnets, offering\nnew opportunities for spintronic devices and quantum information technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T14:01:21Z"}
{"aid":"http://arxiv.org/abs/2504.10240v1","title":"GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction","summary":"Circuit link prediction identifying missing component connections from\nincomplete netlists is crucial in automating analog circuit design. However,\nexisting methods face three main challenges: 1) Insufficient use of topological\npatterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to\nthe complexity of annotations hinders model generalization; 3) Limited\nadaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural\nNetworks (GNNs) based framework featuring three innovations to tackle these\nchallenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes\nfor Link Prediction) framework and achieve port-level accuracy in circuit link\nprediction. Second, we propose Netlist Babel Fish, a netlist format conversion\ntool leveraging retrieval-augmented generation (RAG) with large language model\n(LLM) to enhance the compatibility of netlist formats. Finally, we construct\nSpiceNetlist, a comprehensive dataset that contains 775 annotated circuits\nacross 10 different classes of components. The experimental results demonstrate\nan improvement of 15.05% on the SpiceNetlist dataset and 12.01% on the\nImage2Net dataset over the existing approach.","main_category":"cs.AR","categories":"cs.AR,cs.LG","published":"2025-04-14T14:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.10246v1","title":"Simplified and Verified: A Second Look at a Proof-Producing Union-Find\n  Algorithm","summary":"Using Isabelle/HOL, we verify a union-find data structure with an explain\noperation due to Nieuwenhuis and Oliveras. We devise a simpler, more naive\nversion of the explain operation whose soundness and completeness is easy to\nverify. Then, we prove the original formulation of the explain operation to be\nequal to our version. Finally, we refine this data structure to Imperative HOL,\nenabling us to export efficient imperative code. The formalisation provides a\nstepping stone towards the verification of proof-producing congruence closure\nalgorithms which are a core ingredient of Satisfiability Modulo Theories (SMT)\nsolvers.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T14:09:09Z"}
{"aid":"http://arxiv.org/abs/2504.10250v1","title":"MURR: Model Updating with Regularized Replay for Searching a Document\n  Stream","summary":"The Internet produces a continuous stream of new documents and user-generated\nqueries. These naturally change over time based on events in the world and the\nevolution of language. Neural retrieval models that were trained once on a\nfixed set of query-document pairs will quickly start misrepresenting\nnewly-created content and queries, leading to less effective retrieval.\nTraditional statistical sparse retrieval can update collection statistics to\nreflect these changes in the use of language in documents and queries. In\ncontrast, continued fine-tuning of the language model underlying neural\nretrieval approaches such as DPR and ColBERT creates incompatibility with\npreviously-encoded documents. Re-encoding and re-indexing all\npreviously-processed documents can be costly. In this work, we explore updating\na neural dual encoder retrieval model without reprocessing past documents in\nthe stream. We propose MURR, a model updating strategy with regularized replay,\nto ensure the model can still faithfully search existing documents without\nreprocessing, while continuing to update the model for the latest topics. In\nour simulated streaming environments, we show that fine-tuning models using\nMURR leads to more effective and more consistent retrieval results than other\nstrategies as the stream of documents and queries progresses.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-14T14:13:03Z"}
{"aid":"http://arxiv.org/abs/2504.10257v1","title":"Spectral estimation for high-dimensional linear processes","summary":"We propose a novel estimation procedure for certain spectral distributions\nassociated with a class of high dimensional linear time series. The processes\nunder consideration are of the form $X_t = \\sum_{\\ell=0}^\\infty \\mathbf{A}_\\ell\nZ_{t-\\ell}$ with iid innovations $(Z_t)$. The key structural assumption is that\nthe coefficient matrices and the variance of the innovations are simultaneously\ndiagonalizable in a common orthonormal basis. We develop a strategy for\nestimating the joint spectral distribution of the coefficient matrices and the\ninnovation variance by making use of the asymptotic behavior of the eigenvalues\nof appropriately weighted integrals of the sample periodogram. Throughout we\nwork under the asymptotic regime $p,n \\to \\infty$, such that $p/n\\to c \\in\n(0,\\infty)$, where $p$ is the dimension and $n$ is the sample size. Under this\nsetting, we first establish a weak limit for the empirical distribution of\neigenvalues of the aforementioned integrated sample periodograms. This result\nis proved using techniques from random matrix theory, in particular the\ncharacterization of weak convergence by means of the Stieltjes transform of\nrelevant distributions. We utilize this result to develop an estimator of the\njoint spectral distribution of the coefficient matrices, by minimizing an\n$L^\\kappa$ discrepancy measure, for $\\kappa \\geq 1$, between the empirical and\nlimiting Stieltjes transforms of the integrated sample periodograms. This is\naccomplished by assuming that the joint spectral distribution is a discrete\nmixture of point masses. We also prove consistency of the estimator\ncorresponding to the $L^2$ discrepancy measure. We illustrate the methodology\nthrough simulations and an application to stock price data from the S\\&P 500\nseries.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-14T14:19:43Z"}
{"aid":"http://arxiv.org/abs/2504.10259v1","title":"Dual-grid parameter choice method with application to image deblurring","summary":"Variational regularization of ill-posed inverse problems is based on\nminimizing the sum of a data fidelity term and a regularization term. The\nbalance between them is tuned using a positive regularization parameter, whose\nautomatic choice remains an open question in general. A novel approach for\nparameter choice is introduced, based on the use of two slightly different\ncomputational models for the same inverse problem. Small parameter values\nshould give two very different reconstructions due to amplification of noise.\nLarge parameter values lead to two identical but trivial reconstructions.\nOptimal parameter is chosen between the extremes by matching image similarity\nof the two reconstructions with a pre-defined value. Efficacy of the new method\nis demonstrated with image deblurring using measured data and two different\nregularizers.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T14:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.10261v1","title":"Universality, Robustness, and Limits of the Eigenstate Thermalization\n  Hypothesis in Open Quantum Systems","summary":"The eigenstate thermalization hypothesis (ETH) underpins much of our modern\nunderstanding of the thermalization of closed quantum many-body systems. Here,\nwe investigate the statistical properties of observables in the eigenbasis of\nthe Lindbladian operator of a Markovian open quantum system. We demonstrate the\nvalidity of a Lindbladian ETH ansatz through extensive numerical simulations of\nseveral physical models. To highlight the robustness of Lindbladian ETH, we\nconsider what we dub the dilute-click regime of the model, in which one\npostselects only quantum trajectories with a finite fraction of quantum jumps.\nThe average dynamics are generated by a non-trace-preserving Liouvillian, and\nwe show that the Lindbladian ETH ansatz still holds in this case. On the other\nhand, the no-click limit is a singular point at which the Lindbladian reduces\nto a doubled non-Hermitian Hamiltonian and Lindbladian ETH breaks down.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.dis-nn,nlin.CD,quant-ph","published":"2025-04-14T14:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.10263v1","title":"Quantized Axial Charge in the Hamiltonian Approach to Wilson Fermions","summary":"We investigate the Hamiltonian formulation of 1+1~D staggered fermions and\nreconstruct vector and axial charge operators, found by Arkya Chatterjee et\nal., using the Wilson fermion formalism. These operators commute with the\nHamiltonian and become the generators of vector and axial $\\mathrm{U}(1)$\nsymmetries in the continuum limit. An interesting feature of the axial charge\noperator is that it acts locally on operators and has quantized eigenvalues in\nmomentum space. Therefore, the eigenstates of this operator can be interpreted\nas fermion states with a well-defined integer chirality, analogous to those in\nthe continuum theory. This allows us to realize a gauge theory where the axial\n$\\mathrm{U}(1)_A$ symmetry acts as a gauge symmetry. We construct a Hamiltonian\nusing the eigenstates of the axial charge operator, preserving exact axial\nsymmetry on the lattice and vector symmetry in the continuum. As applications,\nwe examine the implementation of the Symmetric Mass Generation (SMG) mechanism\nin the $1^4(-1)^4$ and 3-4-5-0 models. Our formulation supports\nsymmetry-preserving interactions with quantized chiral charges, although\nfurther numerical studies are required to verify the SMG mechanism in\ninteracting models.","main_category":"hep-lat","categories":"hep-lat,hep-th","published":"2025-04-14T14:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.10270v1","title":"Affine and cyclotomic $q$-Schur categories via webs","summary":"We formulate two new $\\mathbb Z[q,q^{-1}]$-linear diagrammatic monoidal\ncategories, the affine $q$-web category and the affine $q$-Schur category, as\nwell as their respective cyclotomic quotient categories. Diagrammatic integral\nbases for the Hom-spaces of all these categories are established. In addition,\nwe establish the following isomorphisms, providing diagrammatic presentations\nof these $q$-Schur algebras for the first time: (i)~ the path algebras of the\naffine $q$-web category to R.~Green's affine $q$-Schur algebras, (ii)~ the path\nalgebras of the affine $q$-Schur category to Maksimau-Stroppel's higher level\naffine $q$-Schur algebras, and most significantly, (iii)~ the path algebras of\nthe cyclotomic $q$-Schur categories to Dipper-James-Mathas' cyclotomic\n$q$-Schur algebras.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-04-14T14:34:52Z"}
{"aid":"http://arxiv.org/abs/2504.10280v1","title":"Look-to-Touch: A Vision-Enhanced Proximity and Tactile Sensor for\n  Distance and Geometry Perception in Robotic Manipulation","summary":"Camera-based tactile sensors provide robots with a high-performance tactile\nsensing approach for environment perception and dexterous manipulation.\nHowever, achieving comprehensive environmental perception still requires\ncooperation with additional sensors, which makes the system bulky and limits\nits adaptability to unstructured environments. In this work, we present a\nvision-enhanced camera-based dual-modality sensor, which realizes full-scale\ndistance sensing from 50 cm to -3 mm while simultaneously keeping\nultra-high-resolution texture sensing and reconstruction capabilities. Unlike\nconventional designs with fixed opaque gel layers, our sensor features a\npartially transparent sliding window, enabling mechanical switching between\ntactile and visual modes. For each sensing mode, a dynamic distance sensing\nmodel and a contact geometry reconstruction model are proposed. Through\nintegration with soft robotic fingers, we systematically evaluate the\nperformance of each mode, as well as in their synergistic operation.\nExperimental results show robust distance tracking across various speeds,\nnanometer-scale roughness detection, and sub-millimeter 3D texture\nreconstruction. The combination of both modalities improves the robot's\nefficiency in executing grasping tasks. Furthermore, the embedded mechanical\ntransmission in the sensor allows for fine-grained intra-hand adjustments and\nprecise manipulation, unlocking new capabilities for soft robotic hands.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T14:49:09Z"}
{"aid":"http://arxiv.org/abs/2504.10284v1","title":"Can LLMs Generate Tabular Summaries of Science Papers? Rethinking the\n  Evaluation Protocol","summary":"Literature review tables are essential for summarizing and comparing\ncollections of scientific papers. We explore the task of generating tables that\nbest fulfill a user's informational needs given a collection of scientific\npapers. Building on recent work (Newman et al., 2024), we extend prior\napproaches to address real-world complexities through a combination of\nLLM-based methods and human annotations. Our contributions focus on three key\nchallenges encountered in real-world use: (i) User prompts are often\nunder-specified; (ii) Retrieved candidate papers frequently contain irrelevant\ncontent; and (iii) Task evaluation should move beyond shallow text similarity\ntechniques and instead assess the utility of inferred tables for\ninformation-seeking tasks (e.g., comparing papers). To support reproducible\nevaluation, we introduce ARXIV2TABLE, a more realistic and challenging\nbenchmark for this task, along with a novel approach to improve literature\nreview table generation in real-world scenarios. Our extensive experiments on\nthis benchmark show that both open-weight and proprietary LLMs struggle with\nthe task, highlighting its difficulty and the need for further advancements.\nOur dataset and code are available at https://github.com/JHU-CLSP/arXiv2Table.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T14:52:28Z"}
{"aid":"http://arxiv.org/abs/2504.10290v1","title":"Maximizing subgraph density in graphs of bounded degree and clique\n  number","summary":"We asymptotically determine the maximum density of subgraphs isomorphic to\n$H$, where $H$ is any graph containing a dominating vertex, in graphs $G$ on\n$n$ vertices with bounded maximum degree and bounded clique number. That is, we\nasymptotically determine the constant $c=c(H,\\Delta,\\omega)$ such that\nex$(n,H,\\{K_{1,\\Delta+1},K_{\\omega+1}\\})=(1-o_n(1))cn$. More generally, if $H$\nhas at least $u$ dominating vertices, then we find the maximum density of\nsubgraphs isomorphic to $H$ in graphs $G$ that have $p$ cliques of size $u$,\nhave bounded clique number, and are $K_u\\vee I_{\\Delta+1}$-free. For example,\nwe asymptotically determine the constant $d=d(H,\\Delta,\\omega)$ such that\nmex$(m,H,\\{K_{1,1,\\Delta+1},K_{\\omega+1}\\})=(1-o_m(1))dm$. Then we localize\nthese results, proving a tight inequality involving the sizes of the locally\nlargest cliques and complete split graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T15:02:24Z"}
{"aid":"http://arxiv.org/abs/2504.10306v1","title":"Global existence of measure-valued solutions to the multicomponent\n  Smoluchowski coagulation equation","summary":"Global solutions to the multicomponent Smoluchowski coagulation equation are\nconstructed for measure-valued initial data with minimal assumptions on the\nmoments. The framework is based on an abstract formulation of the\nArzel\\`a-Ascoli theorem for uniform spaces. The result holds for a large class\nof coagulation rate kernels, satisfying a power-law upper bound with possibly\ndifferent singularities at small-small, small-large and large-large coalescence\npairs. This includes in particular both mass-conserving and gelling kernels, as\nwell as interpolation kernels used in applications. We also provide short\nproofs of mass-conservation and gelation results for any weak solution, which\nextends previous results for one-component systems.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-14T15:14:22Z"}
{"aid":"http://arxiv.org/abs/2504.10315v1","title":"An energy optimization method based on mixed-integer model and\n  variational quantum computing algorithm for faster IMPT","summary":"Intensity-modulated proton therapy (IMPT) offers superior dose conformity\nwith reduced exposure to surrounding healthy tissues compared to conventional\nphoton therapy. Improving IMPT delivery efficiency reduces motion-related\nuncertainties, enhances plan robustness, and benefits breath-hold techniques by\nshortening treatment time. Among various factors, energy switching time plays a\ncritical role, making energy layer optimization (ELO) essential. This work\ndevelops an energy layer optimization method based on mixed integer model and\nvariational quantum computing algorithm to enhance the efficiency of IMPT. The\nenergy layer optimization problem is modeled as a mixed-integer program, where\ncontinuous variables optimize the dose distribution and binary variables\nindicate energy layer selection. To solve it, iterative convex relaxation\ndecouples the dose-volume constraints, followed by the alternating direction\nmethod of multipliers (ADMM) to separate mixed-variable optimization and the\nminimum monitor unit (MMU) constraint. The resulting beam intensity subproblem,\nsubject to MMU, either admits a closed-form solution or is efficiently solvable\nvia conjugate gradient. The binary subproblem is cast as a quadratic\nunconstrained binary optimization (QUBO) problem, solvable using variational\nquantum computing algorithms. With nearly the same plan quality, the proposed\nmethod noticeable reduces the number of the used energies. For example,\ncompared to conventional IMPT, QC can reduce the number of energy layers from\n61 to 35 in HN case, from 56 to 35 in lung case, and from 59 to 32 to abdomen\ncase. The reduced number of energies also results in fewer delivery time, e.g.,\nthe delivery time is reduced from 100.6, 232.0, 185.3 seconds to 90.7, 215.4,\n154.0 seconds, respectively.","main_category":"physics.med-ph","categories":"physics.med-ph,math.OC","published":"2025-04-14T15:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.10323v1","title":"Rel: A Programming Language for Relational Data","summary":"From the moment of their inception, languages for relational data have been\ndescribed as sublanguages embedded in a host programming language. Rel is a new\nrelational language whose key design goal is to go beyond this paradigm with\nfeatures that allow for programming in the large, making it possible to fully\ndescribe end to end application semantics. With the new approach we can model\nthe semantics of entire enterprise applications relationally, which helps\nsignificantly reduce architecture complexity and avoid the well-known impedance\nmismatch problem. This paradigm shift is enabled by 50 years of database\nresearch, making it possible to revisit the sublanguage/host language paradigm,\nstarting from the fundamental principles. We present the main features of Rel:\nthose that give it the power to express traditional query language operations\nand those that are designed to grow the language and allow programming in the\nlarge.","main_category":"cs.DB","categories":"cs.DB,cs.PL","published":"2025-04-14T15:32:47Z"}
{"aid":"http://arxiv.org/abs/2504.10337v1","title":"Heimdall: test-time scaling on the generative verification","summary":"An AI system can create and maintain knowledge only to the extent that it can\nverify that knowledge itself. Recent work on long Chain-of-Thought reasoning\nhas demonstrated great potential of LLMs on solving competitive problems, but\ntheir verification ability remains to be weak and not sufficiently\ninvestigated. In this paper, we propose Heimdall, the long CoT verification LLM\nthat can accurately judge the correctness of solutions. With pure reinforcement\nlearning, we boost the verification accuracy from 62.5% to 94.5% on competitive\nmath problems. By scaling with repeated sampling, the accuracy further\nincreases to 97.5%. Through human evaluation, Heimdall demonstrates impressive\ngeneralization capabilities, successfully detecting most issues in challenging\nmath proofs, the type of which is not included during training. Furthermore, we\npropose Pessimistic Verification to extend the functionality of Heimdall to\nscaling up the problem solving. It calls Heimdall to judge the solutions from a\nsolver model and based on the pessimistic principle, selects the most likely\ncorrect solution with the least uncertainty. Taking\nDeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification\nimproves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute\nbudget and to 83.3% with more compute budget. With the stronger solver Gemini\n2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge\ndiscovery system, a ternary system where one poses questions, another provides\nsolutions, and the third verifies the solutions. Using the data synthesis work\nNuminaMath for the first two components, Heimdall effectively identifies\nproblematic records within the dataset and reveals that nearly half of the data\nis flawed, which interestingly aligns with the recent ablation studies from\nNuminaMath.","main_category":"cs.AI","categories":"cs.AI,I.2.7","published":"2025-04-14T15:46:33Z"}
{"aid":"http://arxiv.org/abs/2504.10344v1","title":"ALMTokenizer: A Low-bitrate and Semantic-rich Audio Codec Tokenizer for\n  Audio Language Modeling","summary":"Recent advancements in audio language models have underscored the pivotal\nrole of audio tokenization, which converts audio signals into discrete tokens,\nthereby facilitating the application of language model architectures to the\naudio domain. In this study, we introduce ALMTokenizer, a novel low-bitrate and\nsemantically rich audio codec tokenizer for audio language models. Prior\nmethods, such as Encodec, typically encode individual audio frames into\ndiscrete tokens without considering the use of context information across\nframes. Unlike these methods, we introduce a novel query-based compression\nstrategy to capture holistic information with a set of learnable query tokens\nby explicitly modeling the context information across frames. This design not\nonly enables the codec model to capture more semantic information but also\nencodes the audio signal with fewer token sequences. Additionally, to enhance\nthe semantic information in audio codec models, we introduce the following: (1)\nA masked autoencoder (MAE) loss, (2) Vector quantization based on semantic\npriors, and (3) An autoregressive (AR) prediction loss. As a result,\nALMTokenizer achieves competitive reconstruction performance relative to\nstate-of-the-art approaches while operating at a lower bitrate. Within the same\naudio language model framework, ALMTokenizer outperforms previous tokenizers in\naudio understanding and generation tasks.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-14T15:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.10353v1","title":"Patch and Shuffle: A Preprocessing Technique for Texture Classification\n  in Autonomous Cementitious Fabrication","summary":"Autonomous fabrication systems are transforming construction and\nmanufacturing, yet they remain vulnerable to print errors. Texture\nclassification is a key component of computer vision systems that enable\nreal-time monitoring and adjustment during cementitious fabrication.\nTraditional classification methods often rely on global image features, which\ncan bias the model toward semantic content rather than low-level textures. In\nthis paper, we introduce a novel preprocessing technique called \"patch and\nshuffle,\" which segments input images into smaller patches, shuffles them, and\nreconstructs a jumbled image before classification. This transformation removes\nsemantic context, forcing the classifier to rely on local texture features.\n  We evaluate this approach on a dataset of extruded cement images, using a\nResNet-18-based architecture. Our experiments compare the patch and shuffle\nmethod to a standard pipeline, holding all other factors constant. Results show\na significant improvement in accuracy: the patch and shuffle model achieved\n90.64% test accuracy versus 72.46% for the baseline. These findings suggest\nthat disrupting global structure enhances performance in texture-based\nclassification tasks.\n  This method has implications for broader vision tasks where low-level\nfeatures matter more than high-level semantics. The technique may improve\nclassification in applications ranging from fabrication monitoring to medical\nimaging.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:03:21Z"}
{"aid":"http://arxiv.org/abs/2504.10355v1","title":"A geometric analysis of the Bazykin-Berezovskaya predator-prey model\n  with Allee effect in an economic framework","summary":"We study a fast-slow version of the Bazykin-Berezovskaya predator-prey model\nwith Allee effect evolving on two timescales, through the lenses of Geometric\nSingular Perturbation Theory (GSPT). The system we consider is in non-standard\nform. We completely characterize its dynamics, providing explicit threshold\nquantities to distinguish between a rich variety of possible asymptotic\nbehaviors. Moreover, we propose numerical results to illustrate our findings.\nLastly, we comment on the real-world interpretation of these results, in an\neconomic framework and in the context of predator-prey models.","main_category":"math.DS","categories":"math.DS,q-bio.PE","published":"2025-04-14T16:04:03Z"}
{"aid":"http://arxiv.org/abs/2504.10359v1","title":"DICE: A Framework for Dimensional and Contextual Evaluation of Language\n  Models","summary":"Language models (LMs) are increasingly being integrated into a wide range of\napplications, yet the modern evaluation paradigm does not sufficiently reflect\nhow they are actually being used. Current evaluations rely on benchmarks that\noften lack direct applicability to the real-world contexts in which LMs are\nbeing deployed. To address this gap, we propose Dimensional and Contextual\nEvaluation (DICE), an approach that evaluates LMs on granular,\ncontext-dependent dimensions. In this position paper, we begin by examining the\ninsufficiency of existing LM benchmarks, highlighting their limited\napplicability to real-world use cases. Next, we propose a set of granular\nevaluation parameters that capture dimensions of LM behavior that are more\nmeaningful to stakeholders across a variety of application domains.\nSpecifically, we introduce the concept of context-agnostic parameters - such as\nrobustness, coherence, and epistemic honesty - and context-specific parameters\nthat must be tailored to the specific contextual constraints and demands of\nstakeholders choosing to deploy LMs into a particular setting. We then discuss\npotential approaches to operationalize this evaluation framework, finishing\nwith the opportunities and challenges DICE presents to the LM evaluation\nlandscape. Ultimately, this work serves as a practical and approachable\nstarting point for context-specific and stakeholder-relevant evaluation of LMs.","main_category":"cs.CL","categories":"cs.CL,cs.HC","published":"2025-04-14T16:08:13Z"}
{"aid":"http://arxiv.org/abs/2504.10360v1","title":"Reactive power flow optimization in AC drive systems","summary":"This paper explores a limit avoidance approach in the case of input\n(modulation) and output (current) constraints with the aim of enhancing system\navailability of AC drives. Drawing on the observation that, in a certain range\nof reactive power, there exists a trade-off between current and modulation\nmagnitude, we exploit this freedom and define a constrained optimization\nproblem. We propose two approaches, one in the form of an activation-function\nwhich drives the reactive power set-point towards safety, and an approach which\nuses online feedback optimization to set the reactive power dynamically. Both\nmethods compromise reactive power tracking accuracy for increased system\nrobustness. Through a high fidelity simulation, we compare the benefits of the\ntwo methods, highlighting their effectiveness in industrial applications.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-14T16:08:32Z"}
{"aid":"http://arxiv.org/abs/2504.10369v1","title":"SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired\n  Symbolic Reasoning","summary":"Optimizing Register Transfer Level (RTL) code is crucial for improving the\npower, performance, and area (PPA) of digital circuits in the early stages of\nsynthesis. Manual rewriting, guided by synthesis feedback, can yield\nhigh-quality results but is time-consuming and error-prone. Most existing\ncompiler-based approaches have difficulty handling complex design constraints.\nLarge Language Model (LLM)-based methods have emerged as a promising\nalternative to address these challenges. However, LLM-based approaches often\nface difficulties in ensuring alignment between the generated code and the\nprovided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL\noptimization framework that seamlessly integrates LLM-based code rewriting with\nsymbolic reasoning techniques. Our method incorporates a retrieval-augmented\ngeneration (RAG) system of optimization rules and Abstract Syntax Tree\n(AST)-based templates, enabling LLM-based rewriting that maintains syntactic\ncorrectness while minimizing undesired circuit behaviors. A symbolic module is\nproposed for analyzing and optimizing finite state machine (FSM) logic,\nallowing fine-grained state merging and partial specification handling beyond\nthe scope of pattern-based compilers. Furthermore, a fast verification\npipeline, combining formal equivalence checks with test-driven validation,\nfurther reduces the complexity of verification. Experiments on the RTL-Rewriter\nbenchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves\npower, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%,\nrespectively, compared to the state-of-the-art methods.","main_category":"cs.AR","categories":"cs.AR,cs.AI,cs.LG,cs.PL","published":"2025-04-14T16:15:55Z"}
{"aid":"http://arxiv.org/abs/2504.10372v1","title":"Simple physical systems as a reference for multivariate information\n  dynamics","summary":"Understanding a complex system entails capturing the non-trivial collective\nphenomena that arise from interactions between its different parts. Information\ntheory is a flexible and robust framework to study such behaviours, with\nseveral measures designed to quantify and characterise the interdependencies\namong the system's components. However, since these estimators rely on the\nstatistical distributions of observed quantities, it is crucial to examine the\nrelationships between information-theoretic measures and the system's\nunderlying mechanistic structure. To this end, here we present an\ninformation-theoretic analytical investigation of an elementary system of\ninteractive random walkers subject to Gaussian noise. Focusing on partial\ninformation decomposition, causal emergence, and integrated information, our\nresults help us develop some intuitions on their relationship with the physical\nparameters of the system. For instance, we observe that uncoupled systems can\nexhibit emergent properties, in a way that we suggest may be better described\nas ''statistically autonomous''. Overall, we observe that in this simple\nscenario information measures align more reliably with the system's mechanistic\nproperties when calculated at the level of microscopic components, rather than\ntheir coarse-grained counterparts, and over timescales comparable with the\nsystem's intrinsic dynamics. Moreover, we show that approaches that separate\nthe contributions of the system's dynamics and steady-state distribution (e.g.\nvia causal perturbations) may help strengthen the interpretation of\ninformation-theoretic analyses.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T16:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.10381v1","title":"Abstract simplicial complexes in {\\tt Macaulay2}","summary":"{\\tt AbstractSimplicialComplexes.m2} is a computer algebra package written\nfor the computer algebra system {\\tt Macaulay2} \\cite{M2}. It provides new\ninfrastructure to work with abstract simplicial complexes and related\nhomological constructions. Its key novel feature is to implement each given\nabstract simplicial complex as a certain graded list in the form of a hash\ntable with integer keys. Among other features, this allows for a direct\nimplementation of the associated reduced and non-reduced simplicial chain\ncomplexes. Further, it facilitates construction of random simplicial complexes.\nThe approach that we employ here builds on the {\\tt Macaulay2} package {\\tt\nComplexes.m2} \\cite{Stillman:Smith:Complexes.m2}. It complements and is\nentirely different from the existing {\\tt Macaulay2} simplicial complexes\nframework that is made possible by the package {\\tt SimplicialComplexes.m2}\n\\cite{Smith:et:al:SimplicialComplexes.m2:jsag}.","main_category":"math.AG","categories":"math.AG,math.AC,math.AT,math.CO,math.KT","published":"2025-04-14T16:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10422v1","title":"Foundation models for electronic health records: representation dynamics\n  and transferability","summary":"Foundation models (FMs) trained on electronic health records (EHRs) have\nshown strong performance on a range of clinical prediction tasks. However,\nadapting these models to local health systems remains challenging due to\nlimited data availability and resource constraints. In this study, we\ninvestigated what these models learn and evaluated the transferability of an FM\ntrained on MIMIC-IV to an institutional EHR dataset at the University of\nChicago Medical Center. We assessed their ability to identify outlier patients\nand examined representation-space patient trajectories in relation to future\nclinical outcomes. We also evaluated the performance of supervised fine-tuned\nclassifiers on both source and target datasets. Our findings offer insights\ninto the adaptability of FMs across different healthcare systems, highlight\nconsiderations for their effective implementation, and provide an empirical\nanalysis of the underlying factors that contribute to their predictive\nperformance.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T17:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.10424v1","title":"Lowering the Cost of Diamond Open Access Journals","summary":"Many scholarly societies face challenges in adapting their publishing to an\nopen access model where neither authors nor readers pay any fees. Some have\nargued that one of the main barriers is the actual cost of publishing. The goal\nof this paper is to show that the actual costs can be extremely low while still\nmaintaining scholarly quality. We accomplish this by building a journal\npublishing workflow that minimizes the amount of required human labor. We\nrecently built a software system for this and launched a journal using the\nsystem, and we estimate estimate our cost to publish this journal is\napproximately \\$705 per year, plus \\$1 per article and about 10 minutes of\nvolunteer labor per article. We benefited from two factors, namely the fact\nthat authors in our discipline use LaTeX to prepare their manuscripts, and we\nhad volunteer labor to develop software and run the journal. We have made most\nof this software open source in the hopes that it can help others.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-14T17:13:45Z"}
{"aid":"http://arxiv.org/abs/2504.10452v1","title":"Integrating Vision and Location with Transformers: A Multimodal Deep\n  Learning Framework for Medical Wound Analysis","summary":"Effective recognition of acute and difficult-to-heal wounds is a necessary\nstep in wound diagnosis. An efficient classification model can help wound\nspecialists classify wound types with less financial and time costs and also\nhelp in deciding on the optimal treatment method. Traditional machine learning\nmodels suffer from feature selection and are usually cumbersome models for\naccurate recognition. Recently, deep learning (DL) has emerged as a powerful\ntool in wound diagnosis. Although DL seems promising for wound type\nrecognition, there is still a large scope for improving the efficiency and\naccuracy of the model. In this study, a DL-based multimodal classifier was\ndeveloped using wound images and their corresponding locations to classify them\ninto multiple classes, including diabetic, pressure, surgical, and venous\nulcers. A body map was also created to provide location data, which can help\nwound specialists label wound locations more effectively. The model uses a\nVision Transformer to extract hierarchical features from input images, a\nDiscrete Wavelet Transform (DWT) layer to capture low and high frequency\ncomponents, and a Transformer to extract spatial features. The number of\nneurons and weight vector optimization were performed using three swarm-based\noptimization techniques (Monster Gorilla Toner (MGTO), Improved Gray Wolf\nOptimization (IGWO), and Fox Optimization Algorithm). The evaluation results\nshow that weight vector optimization using optimization algorithms can increase\ndiagnostic accuracy and make it a very effective approach for wound detection.\nIn the classification using the original body map, the proposed model was able\nto achieve an accuracy of 0.8123 using image data and an accuracy of 0.8007\nusing a combination of image data and wound location. Also, the accuracy of the\nmodel in combination with the optimization models varied from 0.7801 to 0.8342.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:39:18Z"}
{"aid":"http://arxiv.org/abs/2504.10465v1","title":"Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding","summary":"Multimodal Large Language Models (MLLMs) achieve remarkable performance for\nfine-grained pixel-level understanding tasks. However, all the works rely\nheavily on extra components, such as vision encoder (CLIP), segmentation\nexperts, leading to high system complexity and limiting model scaling. In this\nwork, our goal is to explore a highly simplified MLLM without introducing extra\ncomponents. Our work is motivated by the recent works on Single trAnsformer as\na unified vIsion-Language Model (SAIL) design, where these works jointly learn\nvision tokens and text tokens in transformers. We present Pixel-SAIL, a single\ntransformer for pixel-wise MLLM tasks. In particular, we present three\ntechnical improvements on the plain baseline. First, we design a learnable\nupsampling module to refine visual token features. Secondly, we propose a novel\nvisual prompt injection strategy to enable the single transformer to understand\nvisual prompt inputs and benefit from the early fusion of visual prompt\nembeddings and vision tokens. Thirdly, we introduce a vision expert\ndistillation strategy to efficiently enhance the single transformer's\nfine-grained feature extraction capability. In addition, we have collected a\ncomprehensive pixel understanding benchmark (PerBench), using a manual check.\nIt includes three tasks: detailed object description, visual prompt-based\nquestion answering, and visual-text referring segmentation. Extensive\nexperiments on four referring segmentation benchmarks, one visual prompt\nbenchmark, and our PerBench show that our Pixel-SAIL achieves comparable or\neven better results with a much simpler pipeline. Code and model will be\nreleased at https://github.com/magic-research/Sa2VA.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.10480v1","title":"Probing Long-Range Forces in Neutrino Oscillations at the ESSnuSB\n  Experiment","summary":"Neutrino oscillations constitute an excellent tool to probe physics beyond\nthe Standard Model. In this paper, we investigate the potential of the \\ess\nexperiment to constrain the effects of flavour-dependent long-range forces\n(LRFs) in neutrino oscillations, which may arise due to the extension of the\nStandard Model gauge group by introducing new $U(1)$ symmetries. Focusing on\nthree specific $U(1)$ symmetries -- $L_e - L_\\mu$, $L_e - L_\\tau$, and $L_\\mu -\nL_\\tau$, we demonstrate that \\ess offers a favourable environment to search for\nLRF effects. Our analyses reveal that \\ess can set 90\\% confidence level bounds\nof $V_{e\\mu} < 2.99 \\times 10^{-14} \\, \\text{eV}$, $V_{e\\tau} < 2.05 \\times\n10^{-14} \\, \\text{eV}$, and $V_{\\mu\\tau} < 1.81 \\times 10^{-14} \\, \\text{eV}$,\nwhich are competitive to the upcoming Deep Underground Neutrino Experiment\n(DUNE). It is also observed that reducing the systematic uncertainties from\n$5\\%$ to $2\\%$ improves the \\ess limits on $V_{\\alpha\\beta}$. Interestingly, we\nfind limited correlations between LRF parameters and the less constrained\nlepton mixing parameters $\\theta_{23}$ and $\\delta_{\\text{CP}}$, preserving the\nrobustness of ESSnuSB's sensitivity to CP violation. Even under extreme LRF\npotentials ($V_{\\alpha\\beta} \\gg 10^{-13} \\, \\text{eV}$), the CP-violation\nsensitivity and $\\delta_{\\text{CP}}$ precision remain largely unaffected. These\nresults establish ESSnuSB as a competitive experimental setup for probing LRF\neffects, complementing constraints from other neutrino sources and offering\ncritical insights into the physics of long-range forces.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-14T17:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.10829v1","title":"LayoutCoT: Unleashing the Deep Reasoning Potential of Large Language\n  Models for Layout Generation","summary":"Conditional layout generation aims to automatically generate visually\nappealing and semantically coherent layouts from user-defined constraints.\nWhile recent methods based on generative models have shown promising results,\nthey typically require substantial amounts of training data or extensive\nfine-tuning, limiting their versatility and practical applicability.\nAlternatively, some training-free approaches leveraging in-context learning\nwith Large Language Models (LLMs) have emerged, but they often suffer from\nlimited reasoning capabilities and overly simplistic ranking mechanisms, which\nrestrict their ability to generate consistently high-quality layouts. To this\nend, we propose LayoutCoT, a novel approach that leverages the reasoning\ncapabilities of LLMs through a combination of Retrieval-Augmented Generation\n(RAG) and Chain-of-Thought (CoT) techniques. Specifically, LayoutCoT transforms\nlayout representations into a standardized serialized format suitable for\nprocessing by LLMs. A Layout-aware RAG is used to facilitate effective\nretrieval and generate a coarse layout by LLMs. This preliminary layout,\ntogether with the selected exemplars, is then fed into a specially designed CoT\nreasoning module for iterative refinement, significantly enhancing both\nsemantic coherence and visual quality. We conduct extensive experiments on five\npublic datasets spanning three conditional layout generation tasks.\nExperimental results demonstrate that LayoutCoT achieves state-of-the-art\nperformance without requiring training or fine-tuning. Notably, our CoT\nreasoning module enables standard LLMs, even those without explicit deep\nreasoning abilities, to outperform specialized deep-reasoning models such as\ndeepseek-R1, highlighting the potential of our approach in unleashing the deep\nreasoning capabilities of LLMs for layout generation tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T03:12:01Z"}
{"aid":"http://arxiv.org/abs/2504.10840v1","title":"XRD study of the magnetization plateau above 40 T in the frustrated\n  helimagnet CuGaCr$_{4}$S$_{8}$","summary":"CuGaCr$_{4}$S$_{8}$, which contains a chromium breathing pyrochlore network,\nexhibits diverse magnetic phases, including an incommensurate helical state\nbelow 31 K and a 1/2-magnetization plateau above 40 T, owing to the interplay\nbetween magnetic frustration and spin-lattice coupling. Here, we perform a\nsingle-shot powder x-ray diffraction experiment on CuGaCr$_{4}$S$_{8}$ in a\npulsed high magnetic field of 55 T, revealing an orthorhombic-to-cubic (or\npseudocubic) structural transition upon entering the 1/2-magnetization plateau\nphase at low temperatures. This observation suggests the emergence of a\ncommensurate ferrimagnetic order, where a 3-up-1-down spin configuration is\nrealized in each small tetrahedron, and the all-up or all-down in each large\ntetrahedron. We propose two types of 16-sublattice magnetic structures, which\nare degenerate within exchange interactions between the first, second, and\nthird nearest neighbors.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-15T03:55:12Z"}
{"aid":"http://arxiv.org/abs/2504.10850v1","title":"How to Enhance Downstream Adversarial Robustness (almost) without\n  Touching the Pre-Trained Foundation Model?","summary":"With the rise of powerful foundation models, a pre-training-fine-tuning\nparadigm becomes increasingly popular these days: A foundation model is\npre-trained using a huge amount of data from various sources, and then the\ndownstream users only need to fine-tune and adapt it to specific downstream\ntasks. However, due to the high computation complexity of adversarial training,\nit is not feasible to fine-tune the foundation model to improve its robustness\non the downstream task. Observing the above challenge, we want to improve the\ndownstream robustness without updating/accessing the weights in the foundation\nmodel. Inspired from existing literature in robustness inheritance (Kim et al.,\n2020), through theoretical investigation, we identify a close relationship\nbetween robust contrastive learning with the adversarial robustness of\nsupervised learning. To further validate and utilize this theoretical insight,\nwe design a simple-yet-effective robust auto-encoder as a data pre-processing\nmethod before feeding the data into the foundation model. The proposed approach\nhas zero access to the foundation model when training the robust auto-encoder.\nExtensive experiments demonstrate the effectiveness of the proposed method in\nimproving the robustness of downstream tasks, verifying the connection between\nthe feature robustness (implied by small adversarial contrastive loss) and the\nrobustness of the downstream task.","main_category":"cs.LG","categories":"cs.LG,cs.CR","published":"2025-04-15T04:17:37Z"}
{"aid":"http://arxiv.org/abs/2504.10852v1","title":"Enhancing Features in Long-tailed Data Using Large Vision Mode","summary":"Language-based foundation models, such as large language models (LLMs) or\nlarge vision-language models (LVLMs), have been widely studied in long-tailed\nrecognition. However, the need for linguistic data is not applicable to all\npractical tasks. In this study, we aim to explore using large vision models\n(LVMs) or visual foundation models (VFMs) to enhance long-tailed data features\nwithout any language information. Specifically, we extract features from the\nLVM and fuse them with features in the baseline network's map and latent space\nto obtain the augmented features. Moreover, we design several prototype-based\nlosses in the latent space to further exploit the potential of the augmented\nfeatures. In the experimental section, we validate our approach on two\nbenchmark datasets: ImageNet-LT and iNaturalist2018.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T04:21:50Z"}
{"aid":"http://arxiv.org/abs/2504.10866v1","title":"Gaussian Approximation for High-Dimensional $U$-statistics with\n  Size-Dependent Kernels","summary":"Motivated by small bandwidth asymptotics for kernel-based semiparametric\nestimators in econometrics, this paper establishes Gaussian approximation\nresults for high-dimensional fixed-order $U$-statistics whose kernels depend on\nthe sample size. Our results allow for a situation where the dominant component\nof the Hoeffding decomposition is absent or unknown, including cases with known\ndegrees of degeneracy as special forms. The obtained error bounds for Gaussian\napproximations are sharp enough to almost recover the weakest bandwidth\ncondition of small bandwidth asymptotics in the fixed-dimensional setting when\napplied to a canonical semiparametric estimation problem. We also present an\napplication to an adaptive goodness-of-fit testing, along with discussions\nabout several potential applications.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-15T04:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.10872v1","title":"Design and Fabrication of a lightweight three-lens corrector system for\n  the 2.34-m Vainu Bappu Telescope","summary":"The Vainu Bappu Telescope (VBT) is a 2.34-m reflector, primarily supported\non-axis field of view, offering high-resolution and low-to-medium resolution\nspectroscopic observations in its prime and Cassegrain configurations. This\nstudy presents the design and fabrication of a compact, lightweight,\nthree-element wide-field corrector (WFC) utilizing three spherical lenses to\ncover a polychromatic wavelength range over a 30$'$ FoV at prime focus. The WFC\ndesign was optimized using ZEMAX, ensuring precision in aberrations,\ntolerances, and atmospheric dispersion. The fabricated lenses met stringent\ntolerances, with a $\\pm$1 mm deviation in radius of curvature and 2 mm\ndeviation in center thickness. A mechanical mount was developed to integrate\nall the WFC lenses, and wavefront error testing for the WFC system was\nperformed using ZYGO interferometry, yielding a Wavefront Error of 0.05\n$\\lambda$. Laboratory performance tests were designed and conducted using a\ndedicated setup with achromatic lenses and 100 $\\mu m$ fiber-coupled\npolychromatic light source showed a deviation of 0.1 pixel on-axis and 0.5\npixel at the extreme off-axis field compared to the ZEMAX design, demonstrating\nthat the optical performance of WFC is with minimal aberrations across the\nentire FoV. The successful integration of the WFC at the VBT prime focus will\nincrease the FoV, enabling the multi-fiber, multi-spectrograph setup in 30\narcmin field that will facilitate both OMR and Echelle spectrograph to be used\non the same night along with the addition of new multi-object spectrograph and\nan integral field unit instrument. This will mark a significant upgrade for the\nVBT, broadening its research potential, and expanding its observational\nversatility.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-15T05:03:00Z"}
{"aid":"http://arxiv.org/abs/2504.10887v1","title":"Fisher information approximation of random orthogonal matrices by\n  Gaussian matrices","summary":"Let ${\\Gamma}_n$ be an $n\\times n$ Haar-invariant orthogonal matrix. Let ${\nZ}_n$ be the $p\\times q$ upper-left submatrix of ${\\Gamma}_n$ and ${G}_n$ be a\n$p\\times q$ matrix whose $pq$ entries are independent standard normals, where\n$p$ and $q$ are two positive integers. Let $\\mathcal{L}(\\sqrt{n} {Z}_n)$ and\n$\\mathcal{L}({G}_n)$ be their joint distribution, respectively. Consider the\nFisher information $I(\\mathcal{L}(\\sqrt{n} { Z}_n)|\\mathcal{L}(G_n))$ between\nthe distributions of $\\sqrt{n} {Z}_n$ and ${ G}_n.$ In this paper, we conclude\nthat $$I(\\mathcal{L}(\\sqrt{n} {Z}_n)|\\mathcal{L}(G_n))\\longrightarrow 0 $$ as\n$n\\to\\infty$ if $pq=o(n)$ and it does not tend to zero if\n$c=\\lim\\limits_{n\\to\\infty}\\frac{pq}{n}\\in(0, +\\infty).$ Precisely, we obtain\nthat $$I(\\mathcal{L}(\\sqrt{n}\n{Z}_n)|\\mathcal{L}(G_n))=\\frac{p^2q(q+1)}{4n^2}(1+o(1))$$ when $p=o(n).$","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T05:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.10894v1","title":"Infinite temperature spin dynamics in the asymmetric Hatsugai-Kohmoto\n  model","summary":"We focus on the infinite temperature dynamical spin structure factor of the\nasymmetric Hatsugai-Kohmoto model, the relative of the asymmetric Hubbard\nmodel. It is characterized by distinct single particle energies for the two\nspin species, which interact with each other through a contact interaction in\nmomentum space. We evaluate its spin structure factor exactly and follow the\nevolution of its excitation spectrum for all fillings and interactions,\nidentify signatures of the Mott transition and fingerprints of the asymmetric\nhoppings. The longitudinal spin structure factor exhibits sound like and\ninteraction induced gapped excitations, whose number gets doubled in the\npresence of hopping asymmetry. The transverse response displays the competition\nof interaction and asymmetry induced gaps and results in a quadratic excitation\nbranch at their transition. The complete asymmetric case features\nmomentum-independent dynamical structure factor, characteristic to transitions\ninvolving a flat band.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech","published":"2025-04-15T06:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.10930v1","title":"Dark Matter and Electroweak Phase Transition in the $Z_2$ Symmetric\n  Georgi-Machacek Model","summary":"We present a comprehensive investigation of the $Z_2$ symmetric\nGeorgi-Machacek (GM) model, focusing on the dark matter (DM) in the model and\nthe electroweak phase transition (EWPT). Our analysis encompasses multiple\ndetections for the DM candidates, including collider searches at the LHC and\nLEP, the direct detection and indirect detection. Furthermore, we also explore\nthe possibility of a first-order EWPT in this framework. The gravitational wave\n(GW) generated from the first-order EWPT also provides a detection method for\nthe parameter space in the $Z_2$ symmetric GM model providing viable DM\ncandidate. It is found that the current DM searches, especially the direct\ndetection, provide strong constraints on the parameter space, while the GW\nsignal can be complementary around the Higgs resonant region.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T07:17:44Z"}
{"aid":"http://arxiv.org/abs/2504.10931v1","title":"A Highly Efficient Cross-matching Scheme using Learned Index Structure","summary":"Spatial data fusion is a bottleneck when it meets the scale of 10 billion\nrecords. Cross-matching celestial catalogs is just one example of this. To\nchallenge this, we present a framework that enables efficient cross-matching\nusing Learned Index Structures. Our approach involves a data transformation\nmethod to map multi-dimensional data into easily learnable distributions,\ncoupled with a novel search algorithm that leverages the advantages of model\npairs, significantly enhancing the efficiency of nearest-neighbor search. In\nthis study, we utilized celestial catalog data derived from astronomical\nsurveys to construct the index and evaluated the speed of the cross-matching\nprocess. Using the HEALPix segmentation scheme, we built an independent model\nobject for each tile and developed an end-to-end pipeline to construct a\nframework with semantic guarantees for record retrieval in query and range\nsearch. Our results show that the proposed method improves cross-matching speed\nby more than four times compared to KD-trees for a radius range between 1\nmilli-arcseconds and 100 arcseconds.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-15T07:19:15Z"}
{"aid":"http://arxiv.org/abs/2504.10939v1","title":"Formation of Ba stars : impact of wind Roche lobe overflow and\n  circumbinary disk in shaping the orbital parameters","summary":"After more than three decades of investigation, the distribution of Ba stars\nin the e-log P diagram still defies our understanding. Recent smooth particle\nhydrodynamic simulations involving an asymptotic giant branch (AGB) primary\nhave shown that a circumbinary disk (CB) can form around the binary and that\nthe presence of dust in the wind of evolved low- and intermediate-mass stars\ncan significantly affect the systemic angular momentum loss and mass accretion\nonto the companion through the wind Roche lobe overflow (WRLOF) phase. We used\nthe binary evolution code BINSTAR, where we updated the modeling of the\nprogenitors of Ba stars including a CB disk, the WRLOF, tidally enhanced wind\nmass loss, and non-conservative RLOF with their effects on the orbital\nevolution. In our approach, we considered that a CB disk forms when WRLOF is\nactivated. The coupling between the CB disk and the binary follows the standard\nresonant interaction theory. We constructed grids of 2.0 + 1.0 $M_\\odot{}$ and\n1.2 + 0.8 $M_\\odot{}$ binaries for initial orbital parameters that result in\nWRLOF, and evolved these systems until the end of the primary's AGB phase.\nWRLOF resulted in a significant shrinkage of the orbital separation during the\nAGB phase, leading to binaries with initial periods on the order of $\\lesssim\n12000$ d undergoing Roche lobe overflow (RLOF). The combination of WRLOF,\neccentricity pumping from the CB disk, and/or tidally enhanced wind mass loss\ncan lead to RLOF on eccentric orbits down to periods of $P_\\mathrm{orb} \\sim\n3000$d. Non-conservative RLOF enabled a reduction of the period before\ncircularization down to $\\sim 2000$d, provided at least 50 percent of the\ntransferred mass left the system. Our models still cannot account for the\neccentricity distribution of Ba stars with periods shorter than $P_\\mathrm{orb}\n\\lesssim 2000$d, where a common envelope evolution appears unavoidable.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-15T07:39:51Z"}
{"aid":"http://arxiv.org/abs/2504.10954v1","title":"Offset-free Nonlinear MPC with Koopman-based Surrogate Models","summary":"In this paper, we design offset-free nonlinear Model Predictive Control (MPC)\nfor surrogate models based on Extended Dynamic Mode Decomposition (EDMD). The\nmodel used for prediction in MPC is augmented with a disturbance term, that is\nestimated by an observer. If the full information about the equilibrium of the\nreal system is not available, a reference calculator is introduced in the\nalgorithm to compute the MPC state and input references. The control algorithm\nguarantees offset-free tracking of the controlled output under the assumption\nthat the modeling errors are asymptotically constant. The effectiveness of the\nproposed approach is showcased with numerical simulations for two popular\nbenchmark systems: the van-der-Pol oscillator and the four-tanks process.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T08:00:15Z"}
{"aid":"http://arxiv.org/abs/2504.10967v1","title":"An Efficient and Mixed Heterogeneous Model for Image Restoration","summary":"Image restoration~(IR), as a fundamental multimedia data processing task, has\na significant impact on downstream visual applications. In recent years,\nresearchers have focused on developing general-purpose IR models capable of\nhandling diverse degradation types, thereby reducing the cost and complexity of\nmodel development. Current mainstream approaches are based on three\narchitectural paradigms: CNNs, Transformers, and Mambas. CNNs excel in\nefficient inference, whereas Transformers and Mamba excel at capturing\nlong-range dependencies and modeling global contexts. While each architecture\nhas demonstrated success in specialized, single-task settings, limited efforts\nhave been made to effectively integrate heterogeneous architectures to jointly\naddress diverse IR challenges. To bridge this gap, we propose RestorMixer, an\nefficient and general-purpose IR model based on mixed-architecture fusion.\nRestorMixer adopts a three-stage encoder-decoder structure, where each stage is\ntailored to the resolution and feature characteristics of the input. In the\ninitial high-resolution stage, CNN-based blocks are employed to rapidly extract\nshallow local features. In the subsequent stages, we integrate a refined\nmulti-directional scanning Mamba module with a multi-scale window-based\nself-attention mechanism. This hierarchical and adaptive design enables the\nmodel to leverage the strengths of CNNs in local feature extraction, Mamba in\nglobal context modeling, and attention mechanisms in dynamic feature\nrefinement. Extensive experimental results demonstrate that RestorMixer\nachieves leading performance across multiple IR tasks while maintaining high\ninference efficiency. The official code can be accessed at\nhttps://github.com/ClimBin/RestorMixer.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.10970v1","title":"Mountain pass solution to the Brézis-Nirenberg problem with\n  logarithmic perturbation","summary":"In this paper we give a positive answer to the conjecture raised by Hajaiej\net al. (J. Geom. Anal., 2024, 34(6): No. 182, 44 pp) on the existence of a\nmountain pass solution at positive energy level to the Br\\'{e}zis-Nirenberg\nproblem with logarithmic perturbation. To be a little more precise, by taking\nfull advantage of the local minimum solution and some very delicate estimates\non the logarithmic term and the critical term, we prove that the following\nproblem \\begin{eqnarray*} \\begin{cases} -\\Delta u= \\lambda u+\\mu|u|^2u+\\theta\nu\\log u^2, &x\\in\\Omega,\\\\ u=0, &x\\in\\partial\\Omega \\end{cases} \\end{eqnarray*}\npossesses a positive mountain pass solution at positive energy level, where\n$\\Omega\\subset \\mathbb{R}^4$ is a bounded domain with smooth boundary\n$\\partial\\Omega$, $\\lambda\\in \\mathbb{R}$, $\\mu>0$ and $\\theta<0$. A key step\nin the proof is to control the mountain pass level around the local minimum\nsolution from above by a proper constant to ensure the local compactness.\nMoreover, this result is also extended to three-dimensional and\nfive-dimensional cases.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T08:25:16Z"}
{"aid":"http://arxiv.org/abs/2504.10981v1","title":"X-ray polarization of accreting black holes: Cyg X-1 and Swift\n  J1727.8-1613","summary":"The Imaging X-ray Polarimetry Explorer is an X-ray observatory measuring the\nX-ray polarization in the 2-8 keV energy range. Highly sensitive to the\nsystem's geometry, X-ray polarization is a unique method to probe the structure\nof X-ray binaries. The Imaging X-ray Polarimetry Explorer observed the\nHigh-Mass X-ray Binary Cygnus X-1 and the Low-Mass X-ray Binary Swift\nJ1727.8-1613 in different accretion states: in the hard state and in the soft\nstate. The X-ray polarimetry analysis of both sources shows a linear\npolarization degree increasing with energy, with higher values in the hard\nstate than in the soft state. However, the linear polarization angle stays\nsimilar in both states and is aligned with the radio jet within $5^\\circ$.\nFurthermore, the Low-Mass X-ray Binary Swift J1727.8-1613 has a lower optical\nintrinsic polarization and a lower X-ray polarization degree for a softer\nspectrum. The similarities observed in this analysis between the X-ray\npolarization results of different types of X-ray Binaries show that the\ninnermost accretion processes are independent of the companion star's type.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T08:45:07Z"}
{"aid":"http://arxiv.org/abs/2504.10982v1","title":"Exploring the Role of KG-Based RAG in Japanese Medical Question\n  Answering with Small-Scale LLMs","summary":"Large language models (LLMs) perform well in medical QA, but their\neffectiveness in Japanese contexts is limited due to privacy constraints that\nprevent the use of commercial models like GPT-4 in clinical settings. As a\nresult, recent efforts focus on instruction-tuning open-source LLMs, though the\npotential of combining them with retrieval-augmented generation (RAG) remains\nunderexplored. To bridge this gap, we are the first to explore a knowledge\ngraph-based (KG) RAG framework for Japanese medical QA small-scale open-source\nLLMs. Experimental results show that KG-based RAG has only a limited impact on\nJapanese medical QA using small-scale open-source LLMs. Further case studies\nreveal that the effectiveness of the RAG is sensitive to the quality and\nrelevance of the external retrieved content. These findings offer valuable\ninsights into the challenges and potential of applying RAG in Japanese medical\nQA, while also serving as a reference for other low-resource languages.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T08:46:39Z"}
{"aid":"http://arxiv.org/abs/2504.10997v1","title":"Engineering cm-scale true push-pull electro-optic modulators in a\n  suspended GaAs photonic integrated circuit platform by exploiting the\n  orientation induced asymmetry of the Pockels $r_{41}$ coefficient","summary":"Electro-optic modulators (EOMs) underpin a wide range of critical\napplications in both classical and quantum information processing. While\ntraditionally the focus has been on building these devices in materials with\nlarge Pockels coefficient (mainly ferroelectric insulators like lithium\nniobate), there is a need to engineer EOMs in a semiconductor platform with a\nview towards device stability (in radiation-hard environments),\nmanufacturability (wafer size and foundry compatibility) and integration (with\nactive electronics and quantum confined structures). Here, we demonstrate true\npush-pull EOMs in a suspended GaAs photonic integrated circuit (PIC) platform\nby exploiting the orientation induced asymmetry of the Pockels $r_{41}$\ncoefficient, and folding the two arms of a cm-scale Mach-Zehnder interferometer\n(MZI) modulator along two orthogonal crystal axes. Our work also shows the\npotential of incorporating ideas from micro-electro-mechanical systems (MEMS)\nin integrated photonics by demonstrating high-performance active devices built\naround cm-scale suspended waveguides with sub-${\\mu}$m optical mode\nconfinement.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-15T09:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.11003v1","title":"3D Gabor Splatting: Reconstruction of High-frequency Surface Texture\n  using Gabor Noise","summary":"3D Gaussian splatting has experienced explosive popularity in the past few\nyears in the field of novel view synthesis. The lightweight and differentiable\nrepresentation of the radiance field using the Gaussian enables rapid and\nhigh-quality reconstruction and fast rendering. However, reconstructing objects\nwith high-frequency surface textures (e.g., fine stripes) requires many skinny\nGaussian kernels because each Gaussian represents only one color if viewed from\none direction. Thus, reconstructing the stripes pattern, for example, requires\nGaussians for at least the number of stripes. We present 3D Gabor splatting,\nwhich augments the Gaussian kernel to represent spatially high-frequency\nsignals using Gabor noise. The Gabor kernel is a combination of a Gaussian term\nand spatially fluctuating wave functions, making it suitable for representing\nspatial high-frequency texture. We demonstrate that our 3D Gabor splatting can\nreconstruct various high-frequency textures on the objects.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-15T09:20:37Z"}
{"aid":"http://arxiv.org/abs/2504.11009v1","title":"MMC: Iterative Refinement of VLM Reasoning via MCTS-based Multimodal\n  Critique","summary":"Visual language models (VLMs) have demonstrated strong performance across\ndiverse multimodal reasoning tasks but still face challenges such as\nhallucinations, resulting in incorrect reasoning outcomes. Inspired by recent\nresearch on external feedback mechanisms in large language models (LLMs), we\npropose a multimodal actor-critic framework to enhance VLM reasoning\ncapabilities. Specifically, the actor model generates step-by-step reasoning\npaths based on image and text inputs, while the critic model evaluates these\nreasoning paths and provides corrective feedback. The actor model iteratively\nrefines its reasoning based on the feedback until the reasoning outcome is\ndeemed satisfactory by the critic model. To reduce reliance on costly manual\nannotations, we introduce an automated method for constructing multimodal\ncritique datasets. By leveraging Monte Carlo Tree Search (MCTS), we\nsystematically guide the actor model to explore diverse reasoning paths. To\nobtain critique data for correcting erroneous reasoning steps, we prompt an\nannotator model to compare pairs of reasoning paths diverging from a shared\nancestor node - one leading to a correct conclusion and the other to an\nincorrect one. This approach enables us to construct the MMC (MCTS-based\nMultimodal Critique) dataset, upon which we further develop a comprehensive\ntraining and inference pipeline. Extensive experiments conducted on several\npublic benchmark datasets and mainstream VLMs demonstrate that our approach\nsignificantly improves the performance of VLM on complex multimodal reasoning\ntasks, underscoring its effectiveness and wide applicability.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-15T09:29:08Z"}
{"aid":"http://arxiv.org/abs/2504.11010v1","title":"New Constructions of Binary Cyclic Codes with Both Relatively Large\n  Minimum Distance and Dual Distance","summary":"Binary cyclic codes are worth studying due to their applications and\ntheoretical importance. It is an important problem to construct an infinite\nfamily of cyclic codes with large minimum distance $d$ and dual distance\n$d^{\\perp}$. In recent years, much research has been devoted to improving the\nlower bound on $d$, some of which have exceeded the square-root bound. The\nconstructions presented recently seem to indicate that when the minimum\ndistance increases, the minimum distance of its dual code decreases. In this\npaper, we focus on the new constructions of binary cyclic codes with length\n$n=2^m-1$, dimension near $n/2$, and both relatively large minimum distance and\ndual distance. For $m$ is even, we construct a family of binary cyclic codes\nwith parameters $[2^m-1,2^{m-1}\\pm1,d]$, where $d\\ge 2^{m/2}-1$ and\n$d^\\perp\\ge2^{m/2}$. Both the minimum distance and the dual distance are\nsignificantly better than the previous results. When $m$ is the product of two\ndistinct primes, we construct some cyclic codes with dimensions $k=(n+1)/2$ and\n$d>\\frac{n}{\\log_2n},$ where the lower bound on the minimum distance is much\nlarger than the square-root bound. For $m$ is odd, we present two families of\nbinary $[2^m-1,2^{m-1},d]$ cyclic codes with $d\\ge2^{(m+1)/2}-1$,\n$d^\\perp\\ge2^{(m+1)/2}$ and $d\\ge2^{(m+3)/2}-15$, $d^\\perp\\ge2^{(m-1)/2}$\nrespectively, which leads that $d\\cdot d^\\perp$ can reach $2n$ asymptotically.\nTo the best of our knowledge, except for the punctured binary Reed-Muller\ncodes, there is no other construction of binary cyclic codes that reaches this\nbound.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-15T09:29:41Z"}
{"aid":"http://arxiv.org/abs/2504.11015v1","title":"AnimeDL-2M: Million-Scale AI-Generated Anime Image Detection and\n  Localization in Diffusion Era","summary":"Recent advances in image generation, particularly diffusion models, have\nsignificantly lowered the barrier for creating sophisticated forgeries, making\nimage manipulation detection and localization (IMDL) increasingly challenging.\nWhile prior work in IMDL has focused largely on natural images, the anime\ndomain remains underexplored-despite its growing vulnerability to AI-generated\nforgeries. Misrepresentations of AI-generated images as hand-drawn artwork,\ncopyright violations, and inappropriate content modifications pose serious\nthreats to the anime community and industry. To address this gap, we propose\nAnimeDL-2M, the first large-scale benchmark for anime IMDL with comprehensive\nannotations. It comprises over two million images including real, partially\nmanipulated, and fully AI-generated samples. Experiments indicate that models\ntrained on existing IMDL datasets of natural images perform poorly when applied\nto anime images, highlighting a clear domain gap between anime and natural\nimages. To better handle IMDL tasks in anime domain, we further propose\nAniXplore, a novel model tailored to the visual characteristics of anime\nimagery. Extensive evaluations demonstrate that AniXplore achieves superior\nperformance compared to existing methods. Dataset and code can be found in\nhttps://flytweety.github.io/AnimeDL2M/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:41:08Z"}
{"aid":"http://arxiv.org/abs/2504.11017v1","title":"Floquet realization of prethermal Meissner phase in a two-leg flux\n  ladder","summary":"We show that a periodically driven two-leg flux ladder hosting interacting\nhardcore bosons exhibits a prethermal Meissner phase for large drive amplitudes\nand at special drive frequencies. Such a prethermal Meissner phase is\ncharacterized by a finite time-averaged chiral current. We find an analytic\nexpression of these frequencies using Floquet perturbation theory. Our analysis\nreveals that the presence of the prethermal Meissner phase is tied to the\nemergence of strong Hilbert space fragmentation in these driven ladders. We\nsupport our analytical results by numerical study of finite-size flux ladders\nusing exact diagonalization and discuss experiments using ultracold dipolar\natom platforms that may test our theory.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,cond-mat.other","published":"2025-04-15T09:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.11018v1","title":"Cavity cooling using ultrafast electrons","summary":"We propose a method to cool a thermal photonic state in a cavity by passing\nelectrons through it. Electrons are coherently split into two paths, with one\npath traversing the cavity, becoming entangled with its photonic state. A\nsequence of such entanglement interactions can achieve cooling of the cavity:\ne.g., a twofold reduction in thermal photon number with a 25% post-selection\nprobability. This ``which-path''-based approach extends to other qubit\noscillator systems, such as phonons in crystals or optomechanical resonators,\noffering a general framework for quantum oscillator cooling.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T09:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.11031v1","title":"Acquisition of high-quality images for camera calibration in robotics\n  applications via speech prompts","summary":"Accurate intrinsic and extrinsic camera calibration can be an important\nprerequisite for robotic applications that rely on vision as input. While there\nis ongoing research on enabling camera calibration using natural images, many\nsystems in practice still rely on using designated calibration targets with\ne.g. checkerboard patterns or April tag grids. Once calibration images from\ndifferent perspectives have been acquired and feature descriptors detected,\nthose are typically used in an optimization process to minimize the geometric\nreprojection error. For this optimization to converge, input images need to be\nof sufficient quality and particularly sharpness; they should neither contain\nmotion blur nor rolling-shutter artifacts that can arise when the calibration\nboard was not static during image capture. In this work, we present a novel\ncalibration image acquisition technique controlled via voice commands recorded\nwith a clip-on microphone, that can be more robust and user-friendly than e.g.\ntriggering capture with a remote control, or filtering out blurry frames from a\nvideo sequence in postprocessing. To achieve this, we use a state-of-the-art\nspeech-to-text transcription model with accurate per-word timestamping to\ncapture trigger words with precise temporal alignment. Our experiments show\nthat the proposed method improves user experience by being fast and efficient,\nallowing us to successfully calibrate complex multi-camera setups.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-15T09:54:43Z"}
{"aid":"http://arxiv.org/abs/2504.11034v1","title":"Defending Against Frequency-Based Attacks with Diffusion Models","summary":"Adversarial training is a common strategy for enhancing model robustness\nagainst adversarial attacks. However, it is typically tailored to the specific\nattack types it is trained on, limiting its ability to generalize to unseen\nthreat models. Adversarial purification offers an alternative by leveraging a\ngenerative model to remove perturbations before classification. Since the\npurifier is trained independently of both the classifier and the threat models,\nit is better equipped to handle previously unseen attack scenarios. Diffusion\nmodels have proven highly effective for noise purification, not only in\ncountering pixel-wise adversarial perturbations but also in addressing\nnon-adversarial data shifts. In this study, we broaden the focus beyond\npixel-wise robustness to explore the extent to which purification can mitigate\nboth spectral and spatial adversarial attacks. Our findings highlight its\neffectiveness in handling diverse distortion patterns across low- to\nhigh-frequency regions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:57:17Z"}
{"aid":"http://arxiv.org/abs/2504.11049v1","title":"A quantum algorithm for estimating the determinant","summary":"We present a quantum algorithm for estimating the matrix determinant based on\nquantum spectral sampling. The algorithm estimates the logarithm of the\ndeterminant of an $n \\times n$ positive sparse matrix to an accuracy $\\epsilon$\nin time ${\\cal O}(\\log n/\\epsilon^3)$, exponentially faster than previously\nexisting classical or quantum algorithms that scale linearly in $n$. The\nquantum spectral sampling algorithm generalizes to estimating any quantity\n$\\sum_j f(\\lambda_j)$, where $\\lambda_j$ are the matrix eigenvalues. For\nexample, the algorithm allows the efficient estimation of the partition\nfunction $Z(\\beta) =\\sum_j e^{-\\beta E_j}$ of a Hamiltonian system with energy\neigenvalues $E_j$, and of the entropy $ S =-\\sum_j p_j \\log p_j$ of a density\nmatrix with eigenvalues $p_j$.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T10:32:36Z"}
{"aid":"http://arxiv.org/abs/2504.11054v1","title":"Zero-Shot Whole-Body Humanoid Control via Behavioral Foundation Models","summary":"Unsupervised reinforcement learning (RL) aims at pre-training agents that can\nsolve a wide range of downstream tasks in complex environments. Despite recent\nadvancements, existing approaches suffer from several limitations: they may\nrequire running an RL process on each downstream task to achieve a satisfactory\nperformance, they may need access to datasets with good coverage or\nwell-curated task-specific samples, or they may pre-train policies with\nunsupervised losses that are poorly correlated with the downstream tasks of\ninterest. In this paper, we introduce a novel algorithm regularizing\nunsupervised RL towards imitating trajectories from unlabeled behavior\ndatasets. The key technical novelty of our method, called Forward-Backward\nRepresentations with Conditional-Policy Regularization, is to train\nforward-backward representations to embed the unlabeled trajectories to the\nsame latent space used to represent states, rewards, and policies, and use a\nlatent-conditional discriminator to encourage policies to ``cover'' the states\nin the unlabeled behavior dataset. As a result, we can learn policies that are\nwell aligned with the behaviors in the dataset, while retaining zero-shot\ngeneralization capabilities for reward-based and imitation tasks. We\ndemonstrate the effectiveness of this new approach in a challenging humanoid\ncontrol problem: leveraging observation-only motion capture datasets, we train\nMeta Motivo, the first humanoid behavioral foundation model that can be\nprompted to solve a variety of whole-body tasks, including motion tracking,\ngoal reaching, and reward optimization. The resulting model is capable of\nexpressing human-like behaviors and it achieves competitive performance with\ntask-specific methods while outperforming state-of-the-art unsupervised RL and\nmodel-based baselines.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T10:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.11064v1","title":"A Multi-UAV Formation Obstacle Avoidance Method Combined Improved\n  Simulated Annealing and Adaptive Artificial Potential Field","summary":"The traditional Artificial Potential Field (APF) method exhibits limitations\nin its force distribution: excessive attraction when UAVs are far from the\ntarget may cause collisions with obstacles, while insufficient attraction near\nthe goal often results in failure to reach the target. Furthermore, APF is\nhighly susceptible to local minima, compromising motion reliability in complex\nenvironments. To address these challenges, this paper presents a novel hybrid\nobstacle avoidance algorithm-Deflected Simulated Annealing-Adaptive Artificial\nPotential Field (DSA-AAPF)-which combines an improved simulated annealing\nmechanism with an enhanced APF model. The proposed approach integrates a\nLeader-Follower distributed formation strategy with the APF framework, where\nthe resultant force formulation is redefined to smooth UAV trajectories. An\nadaptive gravitational gain function is introduced to dynamically adjust UAV\nvelocity based on environmental context, and a fast-converging controller\nensures accurate and efficient convergence to the target. Moreover, a\ndirectional deflection mechanism is embedded within the simulated annealing\nprocess, enabling UAVs to escape local minima caused by semi-enclosed obstacles\nthrough continuous rotational motion. The simulation results, covering\nformation reconfiguration, complex obstacle avoidance, and entrapment escape,\ndemonstrate the feasibility, robustness, and superiority of the proposed\nDSA-AAPF algorithm.","main_category":"cs.MA","categories":"cs.MA,cs.RO,cs.SY,eess.SY","published":"2025-04-15T10:53:51Z"}
{"aid":"http://arxiv.org/abs/2504.11065v1","title":"Electronic transport properties of titanium nitride grown by molecular\n  beam epitaxy","summary":"This study investigates the molecular beam epitaxial (MBE) growth of titanium\nnitride (TiN) thin films, achieving a high residual resistivity ratio (RRR) of\n15.8. We observed a strong correlation between growth temperature and\ncrystalline quality, as reflected in both RRR values and lattice parameter\nvariations. Characterization of superconductivity yielded a Ginzburg-Landau\ncoherence length of 60.4 $\\pm$ 0.6 nm, significantly higher than typical\nsputtered films, suggesting improved superconducting coherence.\nFirst-principles calculations, in conjunction with experimental data, provided\ndetailed insights into the electronic structure and transport properties of the\nTiN films. Temperature-dependent Hall coefficient measurements further revealed\nthe influence of anisotropic scattering mechanisms. These findings establish a\npromising route for the development of nitride-based superconducting materials\nfor advanced quantum computing technologies.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-15T10:57:14Z"}
{"aid":"http://arxiv.org/abs/2504.11074v1","title":"Dynamical errors in machine learning forecasts","summary":"In machine learning forecasting, standard error metrics such as mean absolute\nerror (MAE) and mean squared error (MSE) quantify discrepancies between\npredictions and target values. However, these metrics do not directly evaluate\nthe physical and/or dynamical consistency of forecasts, an increasingly\ncritical concern in scientific and engineering applications.\n  Indeed, a fundamental yet often overlooked question is whether machine\nlearning forecasts preserve the dynamical behavior of the underlying system.\nAddressing this issue is essential for assessing the fidelity of machine\nlearning models and identifying potential failure modes, particularly in\napplications where maintaining correct dynamical behavior is crucial.\n  In this work, we investigate the relationship between standard forecasting\nerror metrics, such as MAE and MSE, and the dynamical properties of the\nunderlying system. To achieve this goal, we use two recently developed\ndynamical indices: the instantaneous dimension ($d$), and the inverse\npersistence ($\\theta$). Our results indicate that larger forecast errors --\ne.g., higher MSE -- tend to occur in states with higher $d$ (higher complexity)\nand higher $\\theta$ (lower persistence). To further assess dynamical\nconsistency, we propose error metrics based on the dynamical indices that\nmeasure the discrepancy of the forecasted $d$ and $\\theta$ versus their correct\nvalues. Leveraging these dynamical indices-based metrics, we analyze direct and\nrecursive forecasting strategies for three canonical datasets -- Lorenz,\nKuramoto-Sivashinsky equation, and Kolmogorov flow -- as well as a real-world\nweather forecasting task. Our findings reveal substantial distortions in\ndynamical properties in ML forecasts, especially for long forecast lead times\nor long recursive simulations, providing complementary information on ML\nforecast fidelity that can be used to improve ML models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,physics.comp-ph","published":"2025-04-15T11:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.11083v1","title":"QAMA: Quantum annealing multi-head attention operator with classical\n  deep learning framework","summary":"As large language models scale up, the conventional attention mechanism faces\ncritical challenges of exponential growth in memory consumption and energy\ncosts. Quantum annealing computing, with its inherent advantages in\ncomputational efficiency and low energy consumption, offers an innovative\ndirection for constructing novel deep learning architectures. This study\nproposes the first Quantum Annealing-based Multi-head Attention (QAMA)\nmechanism, achieving seamless compatibility with classical attention\narchitectures through quadratic unconstrained binary optimization (QUBO)\nmodeling of forward propagation and energy-based backpropagation. The method\ninnovatively leverages the quantum bit interaction characteristics of Ising\nmodels to optimize the conventional $O(n^2)$ spatiotemporal complexity into\nlinear resource consumption. Integrated with the optical computing advantages\nof coherent Ising machines (CIM), the system maintains millisecond-level\nreal-time responsiveness while significantly reducing energy consumption. Our\nkey contributions include: Theoretical proofs establish QAMA mathematical\nequivalence to classical attention mechanisms; Dual optimization of multi-head\nspecificity and long-range information capture via QUBO constraints; Explicit\ngradient proofs for the Ising energy equation are utilized to implement\ngradient conduction as the only path in the computational graph as a layer;\nProposed soft selection mechanism overcoming traditional binary attention\nlimitations to approximate continuous weights. Experiments on QBoson CPQC\nquantum computer show QAMA achieves comparable accuracy to classical operators\nwhile reducing inference time to millisecond level and improving solution\nquality. This work pioneers architectural-level integration of quantum\ncomputing and deep learning, applicable to any attention-based model, driving\nparadigm innovation in AI foundational computing.","main_category":"quant-ph","categories":"quant-ph,cs.AI","published":"2025-04-15T11:29:09Z"}
{"aid":"http://arxiv.org/abs/2504.11091v1","title":"AI-guided Antibiotic Discovery Pipeline from Target Selection to\n  Compound Identification","summary":"Antibiotic resistance presents a growing global health crisis, demanding new\ntherapeutic strategies that target novel bacterial mechanisms. Recent advances\nin protein structure prediction and machine learning-driven molecule generation\noffer a promising opportunity to accelerate drug discovery. However, practical\nguidance on selecting and integrating these models into real-world pipelines\nremains limited. In this study, we develop an end-to-end, artificial\nintelligence-guided antibiotic discovery pipeline that spans target\nidentification to compound realization. We leverage structure-based clustering\nacross predicted proteomes of multiple pathogens to identify conserved,\nessential, and non-human-homologous targets. We then systematically evaluate\nsix leading 3D-structure-aware generative models$\\unicode{x2014}$spanning\ndiffusion, autoregressive, graph neural network, and language model\narchitectures$\\unicode{x2014}$on their usability, chemical validity, and\nbiological relevance. Rigorous post-processing filters and commercial analogue\nsearches reduce over 100 000 generated compounds to a focused, synthesizable\nset. Our results highlight DeepBlock and TamGen as top performers across\ndiverse criteria, while also revealing critical trade-offs between model\ncomplexity, usability, and output quality. This work provides a comparative\nbenchmark and blueprint for deploying artificial intelligence in early-stage\nantibiotic development.","main_category":"q-bio.BM","categories":"q-bio.BM,cs.AI,cs.LG","published":"2025-04-15T11:36:27Z"}
{"aid":"http://arxiv.org/abs/2504.11093v1","title":"Interstellar scintillation of sources B0821+394 and B1812+412 as\n  observed by the LPA LPI radio telescope","summary":"The search for long-term variability of compact components of radio sources\nB0821+394 and B1812+412 over an interval of 10 years was carried out. The LPA\nLPI radio telescope with an operating frequency of 111 MHz was used for\nobservations. According to our estimates, the characteristic time of\nvariability for both sources is 1.5-2.5 years. It is shown that the observed\nvariability is not related to intrinsic variations in the radiation flux, but\nis due to refractive scintillation on inhomogeneities of the interstellar\nmedium. From the obtained upper estimates of the apparent angular dimensions of\nthe sources, it follows that the main contribution to the scattering of radio\nemission is made by turbulent plasma concentrated in sufficiently thin screens,\nthe distance to which does not exceed 300-400 pc.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T11:39:44Z"}
{"aid":"http://arxiv.org/abs/2504.11097v1","title":"Steering Feedback in Dynamic Driving Simulators: Road-Induced and\n  Non-Road-Induced Harshness","summary":"Steering feedback plays a substantial role in the validity of driving\nsimulators for the virtual development of modern vehicles. Established\nobjective steering characteristics typically assess the feedback behavior in\nthe frequency range of up to 30 Hz while factors such as steering wheel and\nvehicle body vibrations at higher frequencies are mainly approached as comfort\nissues. This work investigates the influence of steering wheel and vehicle body\nexcitations in the frequency range between 30 and 100 Hz on the subjective\nevaluation of steering feedback in a dynamic driving simulator. A controlled\nsubject study with 42 participants was performed to compare a reference vehicle\nwith an electrical power steering system to four variants of its virtual\nrepresentation on a dynamic driving simulator. The effects of road-induced\nexcitations were investigated by comparing a semi-empirical and a physics-based\ntire model, while the influence of non-road-induced excitations was\ninvestigated by implementing engine and wheel orders. The simulator variants\nwere evaluated in comparison to the reference vehicle during closed-loop\ndriving on a country road in a single-blind within-subjects design. The\nsubjective evaluation focused on the perception of road feedback compared to\nthe reference vehicle. The statistical analysis of subjective results shows\nthat there is a strong effect of non-road-induced steering and vehicle body\nexcitations, while the effect of road-induced excitations is considerably less\npronounced.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T11:42:55Z"}
{"aid":"http://arxiv.org/abs/2504.11100v1","title":"Uncertainty modeling method for wind and solar power output in building\n  integrated energy systems under continuous anomalous weather","summary":"The increasing occurrence of continuous anomalous weather events has\nintensified the uncertainty in wind and photovoltaic power generation, posing\nsignificant challenges to the operation and optimization of building integrated\nenergy systems. Existing studies often neglect the interdependence between\nsuccessive anomalous weather events and their collective impact on wind and\nsolar power output. Additionally, conventional modeling approaches struggle to\naccurately capture the nonlinear fluctuations induced by these weather\nconditions. To address this gap, this study proposes an uncertainty modeling\nmethod based on stochastic optimization and scenario generation. The Weibull\nand Beta distributions characterize the probabilistic properties of wind speed\nand solar irradiance, respectively, while the Copula function captures the\ndependence between wind speed and precipitation, enabling the construction of a\nwind-solar power uncertainty model that incorporates the joint distribution of\nconsecutive anomalous weather events. A Monte Carlo-based scenario generation\napproach is employed to construct a dataset representing anomalous weather\ncharacteristics, followed by a probabilistic distance-based scenario reduction\ntechnique to enhance modeling efficiency. Furthermore, the unscented\ntransformation method is introduced to mitigate nonlinear propagation errors in\nwind and solar power state estimation. Case studies demonstrate that the\nproposed method effectively characterizes the fluctuation patterns of wind and\nsolar power under continuous anomalous weather conditions while preserving the\nstatistical properties of the original data. These findings provide a reliable\nbasis for improving the operational resilience of building integrated energy\nsystems under extreme weather scenarios.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T11:48:55Z"}
{"aid":"http://arxiv.org/abs/2504.11119v1","title":"Integration of a high-fidelity model of quantum sensors with a\n  map-matching filter for quantum-enhanced navigation","summary":"Harnessing the potential of quantum sensors to assist in navigation requires\nenabling their operation in complex, dynamic environments and integrating them\nwithin existing navigation systems. While cross-couplings from platform\ndynamics generally degrade quantum measurements in a complex manner, navigation\nfilters would need to be designed to handle such complex quantum sensor data.\nIn this work, we report on the realization of a high-fidelity model of an\natom-interferometry-based gravity gradiometer and demonstrate its integration\nwith a map-matching navigation filter. Relying on the ability of our model to\nsimulate the sensor behaviour across various dynamic platform environments, we\nshow that aiding navigation via map matching using quantum gravity gradiometry\nresults in stable trajectories, and highlight the importance of non-Gaussian\nerrors arising from platform dynamics as a key challenge to map-matching\nnavigation. We derive requirements for mitigating these errors, such as\nmaintaining sensor tilt below 3.3 degrees, to inform future sensor development\npriorities. This work demonstrates the value of an end-to-end approach that\ncould support future optimization of the overall navigation system. Beyond\nnavigation, our atom interferometer modelling framework could be relevant to\ncurrent research and innovation endeavours with quantum gravimeters,\ngradiometers and inertial sensors.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-15T12:07:21Z"}
{"aid":"http://arxiv.org/abs/2504.11122v1","title":"What it takes to break a liquid: analysis of the cavitation threshold in\n  various media","summary":"Cavitation has historically been related to parameters measured at\nequilibrium, such as vapor pressure and surface tension. However, nucleation\nmight occur when the liquid is metastable, especially for fast phenomena such\nas cavitation induced by high-frequency acoustic waves. This is one of the\nreasons for the large discrepancy between the experimental estimate of the\ncavitation threshold and the theory's predictions.\n  Our investigation aims to identify nucleation thresholds in various\nsubstances characterized by different physical properties. The experiments were\nperformed by initiating nucleation through ultrasound at 24 kHz. The cavitation\nonset was studied using a novel procedure based on high-speed imaging and\nacoustic measurements with a hydrophone. Combining these two techniques allowed\nus to define the exact instant cavitation occurred in the liquid medium. The\nbubble nucleation was framed at 200,000 fps with a spatial resolution in the\norder of micrometers. Such fine temporal and spatial resolutions allowed us to\ntrack the expansion of the cavitation bubble right after its onset. We tested\nfive different substances and tracked the amplitude of the transducer\noscillation to reconstruct the pressure field when cavitation occurs. This\nallows us to identify the liquid's acoustic cavitation threshold (tensile\nstrength). The data collected confirmed that the vapor pressure is not a good\nindicator of the occurrence of cavitation for acoustic systems. Furthermore,\nall substances exhibit similar behavior despite their different physical\nproperties. This might seem counterintuitive, but it sheds light on the\nnucleation mechanism that originates cavitation in a lab-scale acoustic system.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-15T12:09:58Z"}
{"aid":"http://arxiv.org/abs/2504.11128v1","title":"K-means Enhanced Density Gradient Analysis for Urban and Transport\n  Metrics Using Multi-Modal Satellite Imagery","summary":"This paper presents a novel computational approach for evaluating urban\nmetrics through density gradient analysis using multi-modal satellite imagery,\nwith applications including public transport and other urban systems. By\ncombining optical and Synthetic Aperture Radar (SAR) data, we develop a method\nto segment urban areas, identify urban centers, and quantify density gradients.\nOur approach calculates two key metrics: the density gradient coefficient\n($\\alpha$) and the minimum effective distance (LD) at which density reaches a\ntarget threshold. We further employ machine learning techniques, specifically\nK-means clustering, to objectively identify uniform and high-variability\nregions within density gradient plots. We demonstrate that these metrics\nprovide an effective screening tool for public transport analyses by revealing\nthe underlying urban structure. Through comparative analysis of two\nrepresentative cities with contrasting urban morphologies (monocentric vs\npolycentric), we establish relationships between density gradient\ncharacteristics and public transport network topologies. Cities with clear\ndensity peaks in their gradient plots indicate distinct urban centers requiring\ndifferent transport strategies than those with more uniform density\ndistributions. This methodology offers urban planners a cost-effective,\nglobally applicable approach to preliminary public transport assessment using\nfreely available satellite data. The complete implementation, with additional\nexamples and documentation, is available in an open-source repository under the\nMIT license at https://github.com/nexri/Satellite-Imagery-Urban-Analysis.","main_category":"cs.CV","categories":"cs.CV,cs.LG,eess.IV","published":"2025-04-15T12:25:42Z"}
{"aid":"http://arxiv.org/abs/2504.11129v1","title":"$R$-matrix type parametrization of the Jost function for extracting the\n  resonance parameters from scattering data","summary":"A new method is proposed for fitting non-relativistic binary-scattering data\nand for extracting the parameters of possible quantum resonances in the\ncompound system that is formed during the collision. The method combines the\nwell-known $R$-matrix approach with the analysis based on the semi-analytic\nrepresentation of the Jost functions. It is shown that such a combination has\nthe advantages of both these approaches, namely, the number of the fitting\nparameters remains relatively small (as for the $R$-matrix approach) and the\nproper analytic structure of the $S$-matrix is preserved (as for the Jost\nfunction method). It is also shown that the new formalism, although closely\nrelated to the $R$-matrix method, has the benefit of no dependence on an\narbitrary channel radius. The efficiency and accuracy of the proposed method\nare tested using a model single-channel potential. Artificial ``experimental''\ndata generated with this potential are fitted, and its known resonances are\nsuccessfully recovered as zeros of the Jost function on the appropriate sheet\nof the Riemann surface of the energy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T12:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.11136v1","title":"Structure of some mapping spaces","summary":"We prove that the path space of a differentiable manifold is diffeomorphic to\na Fr\\'echet space, endowing the path space with a linear structure.\nFurthermore, the base point preserving mapping space consisting of maps from a\ncube to a differentiable manifold is also diffeomorphic to a Fr\\'echet space.\nAs a corollary of a more general theorem, we prove that the path fibration\nbecomes a fibre bundle for manifolds M. Additionally, we discuss the mapping\nspace from a compact topological space to a differentiable manifold,\ndemonstrating that this space admits the structure of a smooth Banach manifold.","main_category":"math.DG","categories":"math.DG","published":"2025-04-15T12:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.11147v1","title":"Robust Bayesian Inference for Censored Survival Models","summary":"This paper proposes a robust Bayesian accelerated failure time model for\ncensored survival data. We develop a new family of life-time distributions\nusing a scale mixture of the generalized gamma distributions, where we propose\na novel super heavy-tailed distribution as a mixing density. We theoretically\nshow that, under some conditions, the proposed method satisfies the full\nposterior robustness, which guarantees robustness of point estimation as well\nas uncertainty quantification. For posterior computation, we employ an integral\nexpression of the proposed heavy-tailed distribution to develop an efficient\nposterior computation algorithm based on the Markov chain Monte Carlo. The\nperformance of the proposed method is illustrated through numerical experiments\nand real data example.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-15T12:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.11148v1","title":"Super time-resolved tomography","summary":"Understanding 3D fundamental processes is crucial for academic and industrial\napplications. Nowadays, X-ray time-resolved tomography, or tomoscopy, is a\nleading technique for in-situ and operando 4D (3D+time) characterization.\nDespite its ability to achieve 1000 tomograms per second at large-scale X-ray\nfacilities, its applicability is limited by the centrifugal forces exerted on\nsamples and the challenges of developing suitable environments for such\nhigh-speed studies. Here, we introduce STRT, an approach that has the potential\nto enhance the temporal resolution of tomoscopy by at least an order of\nmagnitude while preserving spatial resolution. STRT exploits a 4D DL\nreconstruction algorithm to produce high-fidelity 3D reconstructions at each\ntime point, retrieved from a significantly reduced angular range of a few\ndegrees compared to the 0-180 degrees of traditional tomoscopy. Thus, STRT\nenhances the temporal resolution compared to tomoscopy by a factor equal to the\nratio between 180 degrees and the angular ranges used by STRT. In this work, we\nvalidate the 4D capabilities of STRT through simulations and experiments on\ndroplet collision simulations and additive manufacturing processes. We\nanticipate that STRT will significantly expand the capabilities of 4D X-ray\nimaging, enabling previously unattainable studies in both academic and\nindustrial contexts, such as materials formation and mechanical testing.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T12:49:19Z"}
{"aid":"http://arxiv.org/abs/2504.11151v1","title":"Magnetic uniform resolvent estimates","summary":"We establish uniform $L^{p}-L^{q}$ resolvent estimates for magnetic\nSchr\\\"odinger operators $H=(i\\partial+A(x))^2+V(x)$ in dimension $n \\geq 3$.\nUnder suitable decay conditions on the electromagnetic potentials, we prove\nthat for all $z \\in \\mathbb{C}\\setminus[0,+\\infty)$ with $|\\Im z| \\leq 1$, the\nresolvent satisfies \\begin{equation*}\n\\|(H-z)^{-1}\\phi\\|_{L^{q}}\\lesssim|z|^{\\theta(p,q)} (1+|z|^{\\frac 12\n\\frac{n-1}{n+1}}) \\|\\phi\\|_{L^{p}} \\end{equation*} where\n$\\theta(p,q)=\\frac{n}{2}(\\frac{1}{p}-\\frac{1}{q})-1$. This extends previous\nresults by providing estimates valid for all frequencies with explicit\ndependence on $z$, covering the same optimal range of indices as the free\nLaplacian case, and including weak endpoint estimates. We also derive a variant\nwith less stringent decay assumptions when restricted to a smaller parameter\nrange. As an application, we establish the first $L^p-L^{p'}$ bounds for the\nspectral measure of magnetic Schr\\\"odinger operators.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-15T12:53:09Z"}
{"aid":"http://arxiv.org/abs/2504.11166v1","title":"Adjustable Molecular Cross-Linkage of MXene Layers for Tunable Charge\n  Transport and VOC Sensing","summary":"MXenes, two-dimensional transition metal carbides, nitrides or carbonitrides,\nare emerging as highly promising materials due to their remarkable charge\ntransport characteristics and their versatile surface chemistry. Herein, we\ndemonstrate the tunability of interfaces and the inter-layer spacing between\nTi$_3$C$_2$T$_X$ MXene flakes through molecular cross-linking via ligand\nexchange with homologous diamines. Oleylamine was initially introduced as a\nligand, to facilitate the delamination and stable dispersion of pristine\nTi$_3$C$_2$T$_X$ flakes in chloroform. Subsequently, controlled cross-linkage\nof the flakes was achieved using diamine ligands with varying aliphatic chain\nlengths, enabling the precise tuning of the inter-layer spacing. Grazing\nincidence X-ray scattering (GIXRD / GIWAXS) confirmed the correlation between\nligand chain length and inter-layer spacing, which was further supported by\nDensity Functional Theory (DFT) calculations. Furthermore, we investigated the\ncharge transport properties of thin films consisting of these diamine\ncross-linked MXenes and observed a strong dependence of the conductivity on the\ninterlayer spacing. Finally, we probed chemiresistive vapor sensing properties\nof the MXene composites and observed a pronounced sensitivity and selectivity\ntowards water vapor, highlighting their potential for use in humidity sensors.\nProviding significant insights into molecular cross-linking of MXenes to form\nhybrid inorganic/organic composites and its consequences for charge transport,\nthis study opens avenues for the development of next-generation MXene-based\nelectronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-15T13:14:32Z"}
{"aid":"http://arxiv.org/abs/2504.11180v1","title":"Discontinuous depinning/yielding transition of elastic manifolds with\n  tailored internal elasticity","summary":"We consider elastic manifolds evolving on disordered energy potentials under\nthe action of an external uniform driving. This scenario includes the cases of\n{\\em depinning} and {\\em yielding}, which provide paradigmatic examples of out\nof equilibrium phase transitions. In both cases, velocity of the manifold is\nzero at low driving force, and increases smoothly when a critical driving is\nexceeded,defining a continuous flow-curve for these systems. We show that when\nmore general forms of the manifold elasticity are considered, the flow curve\nmay become reentrant, and the transition hysteretic, or discontinuous. This\nconstitutes a novel scenario for a discontinuous transition out of equilibrium.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-15T13:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.11201v1","title":"Projected Gradient Descent Method for Tropical Principal Component\n  Analysis over Tree Space","summary":"In 2019, Yoshida et al. developed tropical Principal Component Analysis\n(PCA), that is, an analogue of the classical PCA in the setting of tropical\ngeometry and applied it to visualize a set of gene trees over a space of\nphylogenetic trees which is an union of lower dimensional polyhedral cones in\nan Euclidean space with its dimension $m(m-1)/2$ where $m$ is the number of\nleaves. In this paper, we introduce a projected gradient descent method to\nestimate the tropical principal polytope over the space of phylogenetic trees\nand we apply it to apicomplexa dataset. With computational experiment against\nMCMC samplers, we show that our projected gradient descent works very well.","main_category":"math.CO","categories":"math.CO,q-bio.PE","published":"2025-04-15T14:00:32Z"}
{"aid":"http://arxiv.org/abs/2504.11208v1","title":"Slice+Slice Baby: Generating Last-Level Cache Eviction Sets in the Blink\n  of an Eye","summary":"An essential step for mounting cache attacks is finding eviction sets,\ncollections of memory locations that contend on cache space. On Intel\nprocessors, one of the main challenges for identifying contending addresses is\nthe sliced cache design, where the processor hashes the physical address to\ndetermine where in the cache a memory location is stored. While past works have\ndemonstrated that the hash function can be reversed, they also showed that it\ndepends on physical address bits that the adversary does not know.\n  In this work, we make three main contributions to the art of finding eviction\nsets. We first exploit microarchitectural races to compare memory access times\nand identify the cache slice to which an address maps. We then use the known\nhash function to both reduce the error rate in our slice identification method\nand to reduce the work by extrapolating slice mappings to untested memory\naddresses. Finally, we show how to propagate information on eviction sets\nacross different page offsets for the hitherto unexplored case of non-linear\nhash functions.\n  Our contributions allow for entire LLC eviction set generation in 0.7 seconds\non the Intel i7-9850H and 1.6 seconds on the i9-10900K, both using non-linear\nfunctions. This represents a significant improvement compared to\nstate-of-the-art techniques taking 9x and 10x longer, respectively.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-15T14:11:38Z"}
{"aid":"http://arxiv.org/abs/2504.11211v1","title":"Instability of the Standing Pulse in Skew-Gradient Systems and Its\n  Application to FitzHugh-Nagumo Type Systems","summary":"In this paper, we use the Maslov index to obtain a lower bound on the number\nof unstable eigenvalues associated with standing pulse solutions in\nskew-gradient systems. Based on this, we establish an instability criterion for\nthe standing pulse. As an application, the results are applied to\nFitzHugh-Nagumo type systems, in which the activator and inhibitor reaction\nterms exhibit inherent nonlinear structures.","main_category":"math.AP","categories":"math.AP,math.DS","published":"2025-04-15T14:13:21Z"}
{"aid":"http://arxiv.org/abs/2504.11229v1","title":"The Forward-Forward Algorithm: Characterizing Training Behavior","summary":"The Forward-Forward algorithm is an alternative learning method which\nconsists of two forward passes rather than a forward and backward pass employed\nby backpropagation. Forward-Forward networks employ layer local loss functions\nwhich are optimized based on the layer activation for each forward pass rather\nthan a single global objective function. This work explores the dynamics of\nmodel and layer accuracy changes in Forward-Forward networks as training\nprogresses in pursuit of a mechanistic understanding of their internal\nbehavior. Treatments to various system characteristics are applied to\ninvestigate changes in layer and overall model accuracy as training progresses,\nhow accuracy is impacted by layer depth, and how strongly individual layer\naccuracy is correlated with overall model accuracy. The empirical results\npresented suggest that layers deeper within Forward-Forward networks experience\na delay in accuracy improvement relative to shallower layers and that shallower\nlayer accuracy is strongly correlated with overall model accuracy.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T14:30:18Z"}
{"aid":"http://arxiv.org/abs/2504.11232v1","title":"Leveraging multimodal explanatory annotations for video interpretation\n  with Modality Specific Dataset","summary":"We examine the impact of concept-informed supervision on multimodal video\ninterpretation models using MOByGaze, a dataset containing human-annotated\nexplanatory concepts. We introduce Concept Modality Specific Datasets (CMSDs),\nwhich consist of data subsets categorized by the modality (visual, textual, or\naudio) of annotated concepts. Models trained on CMSDs outperform those using\ntraditional legacy training in both early and late fusion approaches. Notably,\nthis approach enables late fusion models to achieve performance close to that\nof early fusion models. These findings underscore the importance of\nmodality-specific annotations in developing robust, self-explainable video\nmodels and contribute to advancing interpretable multimodal learning in complex\nvideo analysis.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-15T14:33:25Z"}
{"aid":"http://arxiv.org/abs/2504.11244v1","title":"Multireference covariant density functional theory for shape coexistence\n  and isomerism in $^{43}$S","summary":"We extend the multireference covariant density functional theory (MR-CDFT) to\ndescribe the low-lying states of the odd-mass nucleus $^{43}$S near the neutron\nmagic number $N=28$ with shape coexistence. The wave functions of the low-lying\nstates are constructed as superpositions of configurations with different\nintrinsic shapes and $K$ quantum numbers, projected onto good particle numbers\nand angular momenta. The MR-CDFT successfully reproduces the main features of\nthe low-energy structure in $^{43}$S. Our results indicate that the ground\nstate, $3/2^-_1$, is predominantly composed of the intruder prolate\none-quasiparticle (1qp) configuration $\\nu1/2^-[321]$. In contrast, the\n$7/2^-_1$ state is identified as a high-$K$ isomer, primarily built on the\nprolate 1qp configuration $\\nu7/2^-[303]$. Additionally, the $3/2^-_2$ state is\nfound to be an admixture dominated by an oblate configuration with $K^\\pi =\n1/2^-$, along with a small contribution from a prolate configuration with\n$K^\\pi = 3/2^-$. These results demonstrate the capability of MR-CDFT to capture\nthe intricate interplay among shape coexistence, $K$-mixing, and isomerism in\nthe low-energy structure of odd-mass nuclei around $N = 28$.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-15T14:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.11251v1","title":"Easy repair via codes with simplex locality","summary":"In the context of distributed storage systems, locally repairable codes have\nbecome important. In this paper we focus on codes that allow for multi-erasure\npattern decoding with low computational effort. Different optimality\nrequirements, measured by the code's rate, minimum distance, locality,\navailability as well as field size, influence each other and can not all be\nmaximized at the same time. We focus on the notion of easy repair, more\nspecifically on the construction of codes that can repair correctable erasure\npatterns with minimal computational effort. In particular, we introduce the\neasy repair property and then present codes of different rates that possess\nthis property. The presented codes are all in some way related to simplex codes\nand comprise block codes as well as unit-memory convolutional codes. We also\nformulate conditions under which the easy repairs can be performed in parallel,\nthus improving access speed of the distributed storage system.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-15T14:47:22Z"}
{"aid":"http://arxiv.org/abs/2504.11252v1","title":"Gravitationally Induced Explosive Outflows","summary":"Over the past decade, there has been a significant increase in the reporting\nof extensive and luminous star-forming regions associated with explosive\noutflows. Nevertheless, there is still a lack of understanding of the possible\nphysical mechanisms that produce such energetic and isotropic events. Then, we\npropose a gravitational interaction as a likely mechanism that could trigger\nexplosive outflows in dense star-forming regions. This could constrain the\nphysical conditions that generate an explosive outflow produced by the close\ndynamical encounter of a runaway star with a clump cluster in dynamical\nequilibrium. Then, we have produced a set of $N$-body simulations that account\nfor the collision of a 10M$_\\odot$ stellar object with a cluster of particles\nwith a mass that ranges from 0 to 50 \\msun. We propose a parameter to describe\nthe interaction, the evaporation parameter, that represents the fraction of\nstars that become unbound. The main result is that, when the cluster mass is\nless than, or up to a few times the stellar mass, the collision will produce an\nexplosive outflow, ejecting a significant fraction of the cluster members with\nvelocities larger than the impact velocity. All of our models produce an\nexplosive outflow, with different characteristics, which increases the\nprobability that a close encounter could be responsible for producing the\nobserved flows.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-15T14:48:06Z"}
{"aid":"http://arxiv.org/abs/2504.11256v1","title":"Covering Approximate Shortest Paths with DAGs","summary":"We define and study analogs of probabilistic tree embedding and tree cover\nfor directed graphs. We define the notion of a DAG cover of a general directed\ngraph $G$: a small collection $D_1,\\dots D_g$ of DAGs so that for all pairs of\nvertices $s,t$, some DAG $D_i$ provides low distortion for $dist(s,t)$; i.e. $\ndist_G(s, t) \\le \\min_{i \\in [g]} dist_{D_i}(s, t) \\leq \\alpha \\cdot dist_G(s,\nt)$, where $\\alpha$ is the distortion.\n  As a trivial upper bound, there is a DAG cover with $n$ DAGs and $\\alpha=1$\nby taking the shortest-paths tree from each vertex. When each DAG is restricted\nto be a subgraph of $G$, there is a matching lower bound (via a directed cycle)\nthat $n$ DAGs are necessary, even to preserve reachability. Thus, we allow the\nDAGs to include a limited number of additional edges not in the original graph.\n  When $n^2$ additional edges are allowed, there is a simple upper bound of two\nDAGs and $\\alpha=1$. Our first result is an almost-matching lower bound that\neven for $n^{2-o(1)}$ additional edges, at least $n^{1-o(1)}$ DAGs are needed,\neven to preserve reachability. However, the story is different when the number\nof additional edges is $\\tilde{O}(m)$, a natural setting where the sparsity of\nthe DAG collection nearly matches the original graph. Our main upper bound is\nthat there is a near-linear time algorithm to construct a DAG cover with\n$\\tilde{O}(m)$ additional edges, polylogarithmic distortion, and only $O(\\log\nn)$ DAGs. This is similar to known results for undirected graphs: the\nwell-known FRT probabilistic tree embedding implies a tree cover where both the\nnumber of trees and the distortion are logarithmic. Our algorithm also extends\nto a certain probabilistic embedding guarantee. Lastly, we complement our upper\nbound with a lower bound showing that achieving a DAG cover with no distortion\nand $\\tilde{O}(m)$ additional edges requires a polynomial number of DAGs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-15T14:55:26Z"}
{"aid":"http://arxiv.org/abs/2504.11263v1","title":"Discovery of a bimodal luminosity distribution in persistent Be/X-ray\n  pulsar 2RXP J130159.6-635806","summary":"We present a comprehensive analysis of 2RXP J130159.6-635806, a persistent\nlow-luminosity Be/X-ray pulsar, focusing on its transition to a spin\nequilibrium state and the discovery of a bimodal luminosity distribution\nrevealing possibly a new accretion regime. Using data from NuSTAR, Swift,\nXMM-Newton, and Chandra observatories, we investigate changes in the pulsar's\ntiming and spectral properties. After more than 20 years of continuous spin-up,\nthe pulsar's spin period stabilized, marking the onset of spin equilibrium.\nThis transition was accompanied by the emergence of a previously unobserved\naccretion regime at $L_{\\rm bol} = (2.0_{-1.0}^{+2.3})\\times 10^{34}$ erg\ns$^{-1}$, an order of magnitude lower than its earlier quiescent state. After\nthat, the source occasionally switched between these regimes, remaining in each\nstate for extended periods, with the transition time from a luminosity of\n$10^{35}$ erg s$^{-1}$ to $10^{34}$ erg s$^{-1}$ taking less than 2.3 day. The\nanalysis of the spectral data collected during this new low-luminosity state\nrevealed a two-hump shape which is different from the cutoff power-law spectra\nobserved at higher luminosities. The discovery of pulsations in this state,\ntogether with the hard spectral shape, demonstrates ongoing accretion. We\nestimate the magnetic field strength to be $\\sim 10^{13}$ G based on indirect\nmethods. Additionally, we report a hint of a previously undetected $\\sim$90-day\norbital period in the system.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T15:04:03Z"}
{"aid":"http://arxiv.org/abs/2504.11266v1","title":"Prescribing hyperbolic bordered surfaces via combinatorial flows","summary":"The aim of this paper is to investigate the fractional combinatorial Calabi\nflow for hyperbolic bordered surfaces. By Lyapunov theory, it is proved that\nthe flow exists for all time and converges exponentially to a conformal factor\nthat generates a hyperbolic surface whose lengths of boundary components are\nprescribed positive numbers. Furthermore, a generalized combinatorial Yamabe\nflow is introduced in the same geometry setting, with the long time existence\nand convergence established. This result yields an algorithm for searching\nbordered surfaces, which may accelerate convergence speed.","main_category":"math.CV","categories":"math.CV,math.DG","published":"2025-04-15T15:05:30Z"}
{"aid":"http://arxiv.org/abs/2504.11273v1","title":"Hybrid Compton-PET Imaging for ion-range verification:A Preclinical\n  Study for Proton-, Helium-, and Carbon-Therapy at HIT","summary":"Enhanced-accuracy ion-range verification in real time shall enable a\nsignificant step forward in the use of therapeutic ion beams. Positron-emission\ntomography (PET) and prompt-gamma imaging (PGI) are two of the most promising\nand researched methodologies, both of them with their own advantages and\nchallenges. Thus far, both of them have been explored for ion-range\nverification in an independent way. However, the simultaneous combination of\nPET and PGI within the same imaging framework may open-up the possibility to\nexploit more efficiently all radiative emissions excited in the tissue by the\nion beam. Here we report on the first pre-clinical implementation of an hybrid\nPET-PGI imaging system, hereby exploring its performance over several ion-beam\nspecies (H, He and C), energies (55 MeV to 275 MeV) and intensities\n(10$^7$-10$^9$ ions/spot), which are representative of clinical conditions. The\nmeasurements were carried out using the pencil-beam scanning technique at the\nsynchrotron accelerator of the Heavy Ion Therapy centre in Heidelberg utilizing\nan array of four Compton cameras in a twofold front-to-front configuration. The\nresults demonstrate that the hybrid PET-PGI technique can be well suited for\nrelatively low energies (55-155 MeV) and beams of protons. On the other hand,\nfor heavier beams of helium and carbon ions at higher energies (155-275 MeV),\nrange monitoring becomes more challenging owing to large backgrounds from\nadditional nuclear processes. The experimental results are well understood on\nthe basis of realistic Monte Carlo (MC) calculations, which show a satisfactory\nagreement with the measured data. This work can guide further upgrades of the\nhybrid PET-PGI system towards a clinical implementation of this innovative\ntechnique.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.ins-det","published":"2025-04-15T15:14:28Z"}
{"aid":"http://arxiv.org/abs/2504.11278v1","title":"Towards dimensions and granularity in a unified workflow and data\n  provenance framework","summary":"Provenance information are essential for the traceability of scientific\nstudies or experiments and thus crucial for ensuring the credibility and\nreproducibility of research findings. This paper discusses a comprehensive\nprovenance framework combining the two types 1. workflow provenance, and 2.\ndata provenance as well as their dimensions and granularity, which enables the\nanswering of W7+1 provenance questions. We demonstrate the applicability by\nemploying a biomedical research use case, that can be easily transferred into\nother scientific fields. An integration of these concepts into a unified\nframework enables credibility and reproducibility of the research findings.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T15:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.11280v1","title":"PGU-SGP: A Pheno-Geno Unified Surrogate Genetic Programming For\n  Real-life Container Terminal Truck Scheduling","summary":"Data-driven genetic programming (GP) has proven highly effective in solving\ncombinatorial optimization problems under dynamic and uncertain environments. A\ncentral challenge lies in fast fitness evaluations on large training datasets,\nespecially for complex real-world problems involving time-consuming\nsimulations. Surrogate models, like phenotypic characterization (PC)-based\nK-nearest neighbors (KNN), have been applied to reduce computational cost.\nHowever, the PC-based similarity measure is confined to behavioral\ncharacteristics, overlooking genotypic differences, which can limit surrogate\nquality and impair performance. To address these issues, this paper proposes a\npheno-geno unified surrogate GP algorithm, PGU-SGP, integrating phenotypic and\ngenotypic characterization (GC) to enhance surrogate sample selection and\nfitness prediction. A novel unified similarity metric combining PC and GC\ndistances is proposed, along with an effective and efficient GC representation.\nExperimental results of a real-life vehicle scheduling problem demonstrate that\nPGU-SGP reduces training time by approximately 76% while achieving comparable\nperformance to traditional GP. With the same training time, PGU-SGP\nsignificantly outperforms traditional GP and the state-of-the-art algorithm on\nmost datasets. Additionally, PGU-SGP shows faster convergence and improved\nsurrogate quality by maintaining accurate fitness rankings and appropriate\nselection pressure, further validating its effectiveness.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-15T15:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.11289v1","title":"UniAnimate-DiT: Human Image Animation with Large-Scale Video Diffusion\n  Transformer","summary":"This report presents UniAnimate-DiT, an advanced project that leverages the\ncutting-edge and powerful capabilities of the open-source Wan2.1 model for\nconsistent human image animation. Specifically, to preserve the robust\ngenerative capabilities of the original Wan2.1 model, we implement Low-Rank\nAdaptation (LoRA) technique to fine-tune a minimal set of parameters,\nsignificantly reducing training memory overhead. A lightweight pose encoder\nconsisting of multiple stacked 3D convolutional layers is designed to encode\nmotion information of driving poses. Furthermore, we adopt a simple\nconcatenation operation to integrate the reference appearance into the model\nand incorporate the pose information of the reference image for enhanced pose\nalignment. Experimental results show that our approach achieves visually\nappearing and temporally consistent high-fidelity animations. Trained on 480p\n(832x480) videos, UniAnimate-DiT demonstrates strong generalization\ncapabilities to seamlessly upscale to 720P (1280x720) during inference. The\ntraining and inference code is publicly available at\nhttps://github.com/ali-vilab/UniAnimate-DiT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.11295v1","title":"Autoregressive Distillation of Diffusion Transformers","summary":"Diffusion models with transformer architectures have demonstrated promising\ncapabilities in generating high-fidelity images and scalability for high\nresolution. However, iterative sampling process required for synthesis is very\nresource-intensive. A line of work has focused on distilling solutions to\nprobability flow ODEs into few-step student models. Nevertheless, existing\nmethods have been limited by their reliance on the most recent denoised samples\nas input, rendering them susceptible to exposure bias. To address this\nlimitation, we propose AutoRegressive Distillation (ARD), a novel approach that\nleverages the historical trajectory of the ODE to predict future steps. ARD\noffers two key benefits: 1) it mitigates exposure bias by utilizing a predicted\nhistorical trajectory that is less susceptible to accumulated errors, and 2) it\nleverages the previous history of the ODE trajectory as a more effective source\nof coarse-grained information. ARD modifies the teacher transformer\narchitecture by adding token-wise time embedding to mark each input from the\ntrajectory history and employs a block-wise causal attention mask for training.\nFurthermore, incorporating historical inputs only in lower transformer layers\nenhances performance and efficiency. We validate the effectiveness of ARD in a\nclass-conditioned generation on ImageNet and T2I synthesis. Our model achieves\na $5\\times$ reduction in FID degradation compared to the baseline methods while\nrequiring only 1.1\\% extra FLOPs on ImageNet-256. Moreover, ARD reaches FID of\n1.84 on ImageNet-256 in merely 4 steps and outperforms the publicly available\n1024p text-to-image distilled models in prompt adherence score with a minimal\ndrop in FID compared to the teacher. Project page:\nhttps://github.com/alsdudrla10/ARD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.11303v1","title":"Energy-resolved tip-orbital fingerprint in scanning tunneling\n  spectroscopy based on the revised Chen's derivative rule","summary":"The revised Chen's derivative rule for electron tunneling is implemented to\nenable computationally efficient first-principles-based calculations of the\ndifferential conductance dI/dV for scanning tunneling spectroscopy (STS)\nsimulations. The probing tip is included through a single tip apex atom, and\nits electronic structure can be modeled as a linear combination of electron\norbitals of various symmetries, or can be directly transferred from\nfirst-principles electronic structure calculations. By taking pristine and\nboron- or nitrogen-doped graphene sheets as sample surfaces, the reliability of\nour implementation is demonstrated by comparing its results to those obtained\nby the Tersoff-Hamann and Bardeen's electron tunneling models. It is\nhighlighted that the energy-resolved direct and interference contributions to\ndI/dV arising from the tip's electron orbitals result in a fingerprint of the\nparticular combined surface-tip system. The significant difference between the\nelectron acceptor boron and donor nitrogen dopants in graphene is reflected in\ntheir dI/dV fingerprints. The presented theoretical method allows for an\nunprecedented physical understanding of the electron tunneling process in terms\nof tip-orbital-resolved energy-dependent dI/dV maps, that is anticipated to be\nextremely useful for investigating the local electronic properties of novel\nmaterial surfaces in the future.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-15T15:45:41Z"}
{"aid":"http://arxiv.org/abs/2504.11305v1","title":"CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable\n  Wood Defect Detection","summary":"Wood defect detection is critical for ensuring quality control in the wood\nprocessing industry. However, current industrial applications face two major\nchallenges: traditional methods are costly, subjective, and labor-intensive,\nwhile mainstream deep learning models often struggle to balance detection\naccuracy and computational efficiency for edge deployment. To address these\nissues, this study proposes CFIS-YOLO, a lightweight object detection model\noptimized for edge devices. The model introduces an enhanced C2f structure, a\ndynamic feature recombination module, and a novel loss function that\nincorporates auxiliary bounding boxes and angular constraints. These\ninnovations improve multi-scale feature fusion and small object localization\nwhile significantly reducing computational overhead. Evaluated on a public wood\ndefect dataset, CFIS-YOLO achieves a mean Average Precision (mAP@0.5) of\n77.5\\%, outperforming the baseline YOLOv10s by 4 percentage points. On SOPHON\nBM1684X edge devices, CFIS-YOLO delivers 135 FPS, reduces power consumption to\n17.3\\% of the original implementation, and incurs only a 0.5 percentage point\ndrop in mAP. These results demonstrate that CFIS-YOLO is a practical and\neffective solution for real-world wood defect detection in resource-constrained\nenvironments.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T15:45:59Z"}
{"aid":"http://arxiv.org/abs/2504.11306v1","title":"Context-Aware Palmprint Recognition via a Relative Similarity Metric","summary":"We propose a new approach to matching mechanism for palmprint recognition by\nintroducing a Relative Similarity Metric (RSM) that enhances the robustness and\ndiscriminability of existing matching frameworks. While conventional systems\nrely on direct pairwise similarity measures, such as cosine or Euclidean\ndistances, these metrics fail to capture how a pairwise similarity compares\nwithin the context of the entire dataset. Our method addresses this by\nevaluating the relative consistency of similarity scores across up to all\nidentities, allowing for better suppression of false positives and negatives.\nApplied atop the CCNet architecture, our method achieves a new state-of-the-art\n0.000036% Equal Error Rate (EER) on the Tongji dataset, outperforming previous\nmethods and demonstrating the efficacy of incorporating relational structure\ninto the palmprint matching process.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:46:17Z"}
{"aid":"http://arxiv.org/abs/2504.11308v1","title":"Constraints on Generalized Gravity-Thermodynamic Cosmology from DESI DR2","summary":"We explore the cosmological implications of generalized entropic models\nwithin the framework of Gravity-Thermodynamics (GT) approaches. These models,\ncharacterized by three or four additional free parameters, are designed to\ncapture deviations from the standard Bekenstein-Hawking entropy and can\nreproduce well-known entropic formulations, including Tsallis, R\\'enyi,\nSharma-Mittal, Barrow, Kaniadakis, and Loop Quantum Gravity entropies in\nvarious analytical limits. We implement the corresponding cosmological models\nusing a fully numerical GT approach to constrain the model parameters and to\nstudy the evolution of the dark energy equation of state as a function of the\nscale factor. Our Bayesian analysis, which incorporates the Pantheon+ and DESy5\nsupernovae data alongside the recently released DESI-DR2/DR1 Baryon Acoustic\nOscillation (BAO) measurements, shows that the data favor the standard\nBekenstein-Hawking entropy, leading to a $\\Lambda$CDM-like late-time behavior.\nIn this context, the three-parameter ($\\mathcal{S}_3$) entropic model appears\nto be sufficient to capture the observed dark energy phenomenology.\nFurthermore, a direct comparison of the Bayesian evidence indicates that the\nthree-parameter model is preferred over the four-parameter ($\\mathcal{S}_4$)\nvariant by a factor of $\\Delta\\log\\mathcal{B} \\sim -6$, while the GT approach\nas a whole is significantly disfavored relative to the $\\Lambda$CDM model with\nat least $\\Delta\\log\\mathcal{B} \\sim -8$ ($\\mathcal{S}_3$) to\n$\\Delta\\log\\mathcal{B} \\sim -13$ ($\\mathcal{S}_4$), when using the DESy5 and\nDESI-DR2 datasets.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-15T15:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.11321v1","title":"Subset-Contrastive Multi-Omics Network Embedding","summary":"Motivation: Network-based analyses of omics data are widely used, and while\nmany of these methods have been adapted to single-cell scenarios, they often\nremain memory- and space-intensive. As a result, they are better suited to\nbatch data or smaller datasets. Furthermore, the application of network-based\nmethods in multi-omics often relies on similarity-based networks, which lack\nstructurally-discrete topologies. This limitation may reduce the effectiveness\nof graph-based methods that were initially designed for topologies with better\ndefined structures. Results: We propose Subset-Contrastive multi-Omics Network\nEmbedding (SCONE), a method that employs contrastive learning techniques on\nlarge datasets through a scalable subgraph contrastive approach. By exploiting\nthe pairwise similarity basis of many network-based omics methods, we\ntransformed this characteristic into a strength, developing an approach that\naims to achieve scalable and effective analysis. Our method demonstrates\nsynergistic omics integration for cell type clustering in single-cell data.\nAdditionally, we evaluate its performance in a bulk multi-omics integration\nscenario, where SCONE performs comparable to the state-of-the-art despite\nutilising limited views of the original data. We anticipate that our findings\nwill motivate further research into the use of subset contrastive methods for\nomics data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T16:01:39Z"}
{"aid":"http://arxiv.org/abs/2504.11329v1","title":"Hunting for Maxwell's Demon in the Wild","summary":"The apparent paradox of Maxwell's demon motivated the development of\ninformation thermodynamics and, more recently, engineering advances enabling\nthe creation of nanoscale information engines. From these advances, it is now\nunderstood that nanoscale machines like the molecular motors within cells can\nin principle operate as Maxwell demons. This motivates the question: does\ninformation help power molecular motors? Answering this would seemingly require\nsimultaneous measurement of all system degrees of freedom, which is generally\nintractable in single-molecule experiments. To overcome this limitation, we\nderive a statistical estimator to infer both the direction and magnitude of\nsubsystem heat flows, and thus to determine whether -- and how strongly -- a\nmotor operates as a Maxwell demon. The estimator uses only trajectory\nmeasurements for a single degree of freedom. We demonstrate the estimator by\napplying it to simulations of an experimental realization of an information\nengine and a kinesin molecular motor. Our results show that kinesin transitions\nto a Maxwell-demon mechanism in the presence of nonequilibrium noise, with a\ncorresponding increase in velocity consistent with experiments. These findings\nsuggest that molecular motors may have evolved to leverage active fluctuations\nwithin cells.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,physics.bio-ph","published":"2025-04-15T16:03:10Z"}
{"aid":"http://arxiv.org/abs/2504.11333v1","title":"Implicit dual time-stepping positivity-preserving entropy-stable schemes\n  for the compressible Navier-Stokes equations","summary":"We generalize the explicit high-order positivity-preserving entropy-stable\nspectral collocation schemes developed in [30, 34] for the three-dimensional\n(3D) compressible Navier Stokes equations to a time implicit formulation. The\ntime derivative terms are discretized by using the first- and second-order\nimplicit backward difference formulas (BDF1 and BDF2) that are well suited for\nsolving steady-state and time-dependent viscous flows at high Reynolds numbers,\nrespectively. The nonlinear system of discrete equations at each physical\ntimestep is solved by using a dual time-stepping technique. The proposed scheme\nis provably entropy-stable and positivity-preserving and provides unconditional\nstability properties in the physical time. Numerical results demonstrating\naccuracy and positivity-preserving properties of the new dual time-stepping\nscheme are presented for supersonic viscous flows with strong shock waves and\ncontact discontinuities.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T16:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.11347v1","title":"DeepWheel: Generating a 3D Synthetic Wheel Dataset for Design and\n  Performance Evaluation","summary":"Data-driven design is emerging as a powerful strategy to accelerate\nengineering innovation. However, its application to vehicle wheel design\nremains limited due to the lack of large-scale, high-quality datasets that\ninclude 3D geometry and physical performance metrics. To address this gap, this\nstudy proposes a synthetic design-performance dataset generation framework\nusing generative AI. The proposed framework first generates 2D rendered images\nusing Stable Diffusion, and then reconstructs the 3D geometry through 2.5D\ndepth estimation. Structural simulations are subsequently performed to extract\nengineering performance data. To further expand the design and performance\nspace, topology optimization is applied, enabling the generation of a more\ndiverse set of wheel designs. The final dataset, named DeepWheel, consists of\nover 6,000 photo-realistic images and 900 structurally analyzed 3D models. This\nmulti-modal dataset serves as a valuable resource for surrogate model training,\ndata-driven inverse design, and design space exploration. The proposed\nmethodology is also applicable to other complex design domains. The dataset is\nreleased under the Creative Commons Attribution-NonCommercial 4.0\nInternational(CC BY-NC 4.0) and is available on the\nhttps://www.smartdesignlab.org/datasets","main_category":"cs.CV","categories":"cs.CV,physics.app-ph","published":"2025-04-15T16:20:00Z"}
{"aid":"http://arxiv.org/abs/2504.11349v1","title":"Explicit and Implicit Representations in AI-based 3D Reconstruction for\n  Radiology: A systematic literature review","summary":"The demand for high-quality medical imaging in clinical practice and assisted\ndiagnosis has made 3D reconstruction in radiological imaging a key research\nfocus. Artificial intelligence (AI) has emerged as a promising approach to\nenhancing reconstruction accuracy while reducing acquisition and processing\ntime, thereby minimizing patient radiation exposure and discomfort and\nultimately benefiting clinical diagnosis. This review explores state-of-the-art\nAI-based 3D reconstruction algorithms in radiological imaging, categorizing\nthem into explicit and implicit approaches based on their underlying\nprinciples. Explicit methods include point-based, volume-based, and Gaussian\nrepresentations, while implicit methods encompass implicit prior embedding and\nneural radiance fields. Additionally, we examine commonly used evaluation\nmetrics and benchmark datasets. Finally, we discuss the current state of\ndevelopment, key challenges, and future research directions in this evolving\nfield. Our project available on: https://github.com/Bean-Young/AI4Med.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.GR,I.4.5","published":"2025-04-15T16:21:47Z"}
{"aid":"http://arxiv.org/abs/2504.11352v1","title":"Diagnostic Uncertainty Limits the Potential of Early Warning Signals to\n  Identify Epidemic Emergence","summary":"Methods to detect the emergence of infectious diseases, and approach to the\n\"critical transition\" RE = 1, have to potential to avert substantial disease\nburden by facilitating preemptive actions like vaccination campaigns. Early\nwarning signals (EWS), summary statistics of infection case time series, show\npromise in providing such advanced warnings. As EWS are computed on test\npositive case data, the accuracy of this underlying data is integral to their\npredictive ability, but will vary with changes in the diagnostic test accuracy\nand the incidence of the target disease relative to clinically-compatible\nbackground noise. We simulated emergent and null time series as the sum of an\nSEIR-generated measles time series, and background noise generated by either\nindependent draws from a Poisson distribution, or an SEIR simulation with\nrubella-like parameters. We demonstrate that proactive outbreak detection with\nEWS metrics is resilient to decreasing diagnostic accuracy, so long as\nbackground infections remain proportionally low. Under situations with large,\nepisodic, noise, imperfect diagnostic tests cannot appropriately discriminate\nbetween emergent and null periods. Not all EWS metrics performed equally: we\nfind that the mean was the least affected by changes to the noise structure and\nmagnitude, given a moderately accurate diagnostic test (>= to 95% sensitive and\nspecific), and the autocovariance and variance were the most predictive when\nthe noise incidence did not exhibit large temporal variations. In these\nsituations, diagnostic test accuracy should not be a precursor to the\nimplementation of an EWS metric-based alert system.","main_category":"q-bio.OT","categories":"q-bio.OT","published":"2025-04-15T16:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.11353v1","title":"An Adaptive Dropout Approach for High-Dimensional Bayesian Optimization","summary":"Bayesian optimization (BO) is a widely used algorithm for solving expensive\nblack-box optimization problems. However, its performance decreases\nsignificantly on high-dimensional problems due to the inherent\nhigh-dimensionality of the acquisition function. In the proposed algorithm, we\nadaptively dropout the variables of the acquisition function along the\niterations. By gradually reducing the dimension of the acquisition function,\nthe proposed approach has less and less difficulty to optimize the acquisition\nfunction. Numerical experiments demonstrate that AdaDropout effectively tackle\nhigh-dimensional challenges and improve solution quality where standard\nBayesian optimization methods often struggle. Moreover, it achieves superior\nresults when compared with state-of-the-art high-dimensional Bayesian\noptimization approaches. This work provides a simple yet efficient solution for\nhigh-dimensional expensive optimization.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-15T16:23:25Z"}
{"aid":"http://arxiv.org/abs/2504.11360v1","title":"Posterior Consistency in Parametric Models via a Tighter Notion of\n  Identifiability","summary":"We investigate Bayesian posterior consistency in the context of parametric\nmodels with proper priors. While typical state-of-the-art approaches rely on\nregularity conditions that are difficult to verify and often misaligned with\nthe actual mechanisms driving posterior consistency, we propose an alternative\nframework centered on a simple yet general condition we call ''sequential\nidentifiability''. This concept strengthens the usual identifiability\nassumption by requiring that any sequence of parameters whose induced\ndistributions converge to the true data-generating distribution must itself\nconverge to the true parameter value. We demonstrate that sequential\nidentifiability, combined with a standard Kullback--Leibler prior support\ncondition, is sufficient to ensure posterior consistency. Moreover, we show\nthat failure of this condition necessarily entails a specific and pathological\nform of oscillations of the model around the true density, which cannot exist\nwithout intentional design. This leads to the important insight that posterior\ninconsistency may be safely ruled out, except in the unrealistic scenario where\nthe modeler possesses precise knowledge of the data-generating distribution and\ndeliberately incorporates oscillatory pathologies into the model targeting the\ncorresponding density. Taken together, these results provide a unified\nperspective on both consistency and inconsistency in parametric settings,\nsignificantly expanding the class of models for which posterior consistency can\nbe rigorously established. To illustrate the strength and versatility of our\nframework, we construct a one-dimensional model that violates standard\nregularity conditions and fails to admit a consistent maximum likelihood\nestimator, yet supports a complete posterior consistency analysis via our\napproach.","main_category":"math.ST","categories":"math.ST,stat.TH,G.3","published":"2025-04-15T16:26:34Z"}
{"aid":"http://arxiv.org/abs/2504.11370v1","title":"A two-phase quenching-type problem for the p-Laplacian","summary":"We study minimizers of non-differentiable functionals of the Alp-Phillips\ntype with two-phases for the $p$-Laplacian , focusing on the geometric and\nanalytical properties of free boundaries. The main result establishes finite\n$(n-1)$-dimensional Hausdorff measure estimates, achieved through optimal\ngradient decay estimates, a $BV$-inequality and the known classifications of\nblow-up profiles of the linear case.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T16:36:19Z"}
{"aid":"http://arxiv.org/abs/2504.11372v1","title":"A Review of Traffic Wave Suppression Strategies: Variable Speed Limit\n  vs. Jam-Absorption Driving","summary":"The main form of freeway traffic congestion is the familiar stop-and-go wave,\ncharacterized by wide moving jams that propagate indefinitely upstream provided\nenough traffic demand. They cause severe, long-lasting adverse effects, such as\nreduced traffic efficiency, increased driving risks, and higher vehicle\nemissions. This underscores the crucial importance of artificial intervention\nin the propagation of stop-and-go waves. Over the past two decades, two\nprominent strategies for stop-and-go wave suppression have emerged: variable\nspeed limit (VSL) and jam-absorption driving (JAD). Although they share similar\nresearch motivations, objectives, and theoretical foundations, the development\nof these strategies has remained relatively disconnected. To synthesize\nfragmented advances and drive the field forward, this paper first provides a\ncomprehensive review of the achievements in the stop-and-go wave\nsuppression-oriented VSL and JAD, respectively. It then focuses on bridging the\ntwo areas and identifying research opportunities from the following\nperspectives: fundamental diagrams, traffic dynamics modeling, traffic state\nestimation and prediction, stochasticity, scenarios for strategy validation,\nand field tests and practical deployment. We expect that through this review,\none area can effectively address its limitations by identifying and leveraging\nthe strengths of the other, thus promoting the overall research goal of freeway\nstop-and-go wave suppression.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.SY,eess.SY,stat.AP","published":"2025-04-15T16:37:23Z"}
{"aid":"http://arxiv.org/abs/2504.11391v1","title":"Electroweak corrections to $τ^+τ^-$ production in ultraperipheral\n  heavy-ion collisions at the LHC","summary":"While the anomalous magnetic moments of the electron and the muon have been\nmeasured with remarkable precision, the magnetic moment of the $\\tau$-lepton is\nonly known to rather limited precision. A promising approach to measure it\nexploits $\\tau^+\\tau^-$ production in ultraperipheral collisions of lead ions\nat the LHC. In this article, a state-of-the-art theory prediction for\n$\\tau^+\\tau^-$ production including leptonic $\\tau$-decays is provided. The\nimpact of spin correlations between the $\\tau$-leptons, of the masses of\nfinal-state leptons, of next-to-leading-order electroweak corrections, and of\nthe parametrization of the photon flux are discussed.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-15T17:00:47Z"}
{"aid":"http://arxiv.org/abs/2504.11392v1","title":"Probing General Relativity-Induced Decoherence Using an on-chip Sagnac\n  Interferometer","summary":"The intersection of quantum mechanics and general relativity remains an open\nfrontier in fundamental physics, with few experimentally accessible phenomena\nconnecting the two. Recent theoretical proposals suggest that relativistic\nproper time can act as a source of decoherence in quantum systems, providing a\ntestable overlap between the two theories. Here, we propose a chip-integrated\nSagnac interferometer where rotation induces a proper time difference between\nclockwise and counterclockwise single-photon paths. When this time delay\nexceeds the photon's coherence time, interference visibility is predicted to\ndecrease, offering a direct signature of relativistic time dilation-induced\ndecoherence. We theoretically derive the proper time difference arising from\nthe Sagnac effect and estimate that for a loop radius of 18.9 cm and a rotation\nspeed of 1000 rad/s, decoherence should occur for single-photon wavepackets\nwith a coherence time of 10 femtoseconds. We also present a practical chip\ndesign that accommodates the required high-speed mechanical rotation and\nincludes an all-optical readout scheme to eliminate wiring constraints. This\napproach enables a stable, on-chip implementation using realistic parameters,\nwith rotation speed serving as a continuously tunable knob to control\ndecoherence. Our platform opens a new route for experimentally probing the\ninterplay between quantum coherence and relativistic proper time in a scalable\nand compact form.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-15T17:01:16Z"}
{"aid":"http://arxiv.org/abs/2504.11394v1","title":"Overrings of half-factorial orders","summary":"The behavior of factorization properties in various ring extensions is a\ncentral theme in commutative algebra. Classically, the UFDs are (completely)\nintegrally closed and tend to behave well in standard ring extensions, with the\nnotable exception of power series extension. The half-factorial property is not\nas robust; HFDs need not be integrally closed and the half-factorial property\nis not necessarily preserved in integral extensions or even localizations. Here\nwe exhibit classes of HFDs that behave well in (almost) integral extensions,\nresolve an open question on the behavior of the boundary map, and give a\nsqueeze theorem for elasticity in certain domains.","main_category":"math.AC","categories":"math.AC","published":"2025-04-15T17:05:28Z"}
{"aid":"http://arxiv.org/abs/2504.11395v1","title":"The frequent hypercyclicity of unbounded operator","summary":"We establish two Frequent Hypercyclicity Criteria for unbounded operators,\ninspired by the frameworks of Bayart Grivaux and deLaubenfels Emamirad Grosse\nErdmann. These criteria simplify the verification and construction of\nfrequently hypercyclic operators.","main_category":"math.FA","categories":"math.FA","published":"2025-04-15T17:06:03Z"}
{"aid":"http://arxiv.org/abs/2504.11400v1","title":"FlowUnits: Extending Dataflow for the Edge-to-Cloud Computing Continuum","summary":"This paper introduces FlowUnits, a novel programming and deployment model\nthat extends the traditional dataflow paradigm to address the unique challenges\nof edge-to-cloud computing environments. While conventional dataflow systems\noffer significant advantages for large-scale data processing in homogeneous\ncloud settings, they fall short when deployed across distributed, heterogeneous\ninfrastructures. FlowUnits addresses three critical limitations of current\napproaches: lack of locality awareness, insufficient resource adaptation, and\nabsence of dynamic update mechanisms. FlowUnits organize processing operators\ninto cohesive, independently manageable components that can be transparently\nreplicated across different regions, efficiently allocated on nodes with\nappropriate hardware capabilities, and dynamically updated without disrupting\nongoing computations. We implement and evaluate the FlowUnits model within\nRenoir, an existing dataflow system, demonstrating significant improvements in\ndeployment flexibility and resource utilization across the computing continuum.\nOur approach maintains the simplicity of dataflow while enabling seamless\nintegration of edge and cloud resources into unified data processing pipelines.","main_category":"cs.DC","categories":"cs.DC,cs.SE","published":"2025-04-15T17:14:08Z"}
{"aid":"http://arxiv.org/abs/2504.11402v1","title":"Complex multiannual cycles of Mycoplasma pneumoniae: persistence and the\n  role of stochasticity","summary":"The epidemiological dynamics of Mycoplasma pneumoniae are characterized by\ncomplex and poorly understood multiannual cycles, posing challenges for\nforecasting. Using Bayesian methods to fit a seasonally forced transmission\nmodel to long-term surveillance data from Denmark (1958-1995, 2010-2025), we\ninvestigate the mechanisms driving recurrent outbreaks of M. pneumoniae. The\nperiod of the multiannual cycles (predominantly approx. 5 years in Denmark) are\nexplained as a consequence of the interaction of two time-scales in the system,\none intrinsic and one extrinsic (seasonal). While it provides an excellent fit\nto shorter time series (a few decades), we find that the deterministic model\neventually settles into an annual cycle, failing to reproduce the observed\n4-5-year periodicity long-term. Upon further analysis, the system is found to\nexhibit transient chaos and thus high sensitivity to stochasticity. We show\nthat environmental (but not purely demographic) stochasticity can sustain the\nmulti-year cycles via stochastic resonance. The disruptive effects of COVID-19\nnon-pharmaceutical interventions (NPIs) on M. pneumoniae circulation constitute\na natural experiment on the effects of large perturbations. Consequently, the\neffects of NPIs are included in the model and medium-term predictions are\nexplored. Our findings highlight the intrinsic sensitivity of M. pneumoniae\ndynamics to perturbations and interventions, underscoring the limitations of\ndeterministic epidemic models for long-term prediction. More generally, our\nresults emphasize the potential role of stochasticity as a driver of complex\ncycles across endemic and recurring pathogens.","main_category":"q-bio.PE","categories":"q-bio.PE,nlin.CD","published":"2025-04-15T17:18:10Z"}
{"aid":"http://arxiv.org/abs/2504.11409v1","title":"Efficient Hybrid Language Model Compression through Group-Aware SSM\n  Pruning","summary":"Hybrid LLM architectures that combine Attention and State Space Models (SSMs)\nachieve state-of-the-art accuracy and runtime performance. Recent work has\ndemonstrated that applying compression and distillation to Attention-only\nmodels yields smaller, more accurate models at a fraction of the training cost.\nIn this work, we explore the effectiveness of compressing Hybrid architectures.\nWe introduce a novel group-aware pruning strategy that preserves the structural\nintegrity of SSM blocks and their sequence modeling capabilities. Furthermore,\nwe demonstrate the necessity of such SSM pruning to achieve improved accuracy\nand inference speed compared to traditional approaches. Our compression recipe\ncombines SSM, FFN, embedding dimension, and layer pruning, followed by\nknowledge distillation-based retraining, similar to the MINITRON technique.\nUsing this approach, we compress the Nemotron-H 8B Hybrid model down to 4B\nparameters with up to 40x fewer training tokens. The resulting model surpasses\nthe accuracy of similarly-sized models while achieving 2x faster inference,\nsignificantly advancing the Pareto frontier.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T17:26:29Z"}
{"aid":"http://arxiv.org/abs/2504.11410v1","title":"Randomized block proximal method with locally Lipschitz continuous\n  gradient","summary":"Block-coordinate algorithms are recognized to furnish efficient iterative\nschemes for addressing large-scale problems, especially when the computation of\nfull derivatives entails substantial memory requirements and computational\nefforts. In this paper, we investigate a randomized block proximal gradient\nalgorithm for minimizing the sum of a differentiable function and a separable\nproper lower-semicontinuous function, both possibly nonconvex. In contrast to\nprevious works, we only assume that the partial gradients of the differentiable\nfunction are locally Lipschitz continuous. At each iteration, the method\nadaptively selects a proximal stepsize to satisfy a sufficient decrease\ncondition without prior knowledge of the local Lipschitz moduli of the partial\ngradients of the differentiable function. In addition, we incorporate the\npossibility of conducting an additional linesearch to enhance the performance\nof the algorithm. Our main result establishes subsequential convergence to a\nstationary point of the problem almost surely. Finally, we provide numerical\nvalidation of the method in an experiment in image compression using a\nnonnegative matrix factorization model.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T17:26:40Z"}
{"aid":"http://arxiv.org/abs/2504.11414v1","title":"A magnetar powers the luminous supernova 2023pel, associated with a long\n  gamma-ray burst","summary":"We explore SN 2023pel, the most recent event associated with gamma-ray bursts\n(GRBs), specifically GRB 230812B. SN 2023pel has a high luminosity and low\nexpansion velocities compared to other GRB-SNe. These properties seem difficult\nto reconcile with a single nickel power source. We searched for models that can\nexplain the properties of this event. We calculated a grid of hydrodynamic\nmodels based on pre-SN structures derived from evolutionary calculations. We\ncompared our models with observations of SN~2023pel and selected our preferred\nmodel using statistical analysis, taking both light curves and expansion\nvelocities into account. This allowed us to derive a set of physical properties\nfor SN~2023pel. Our models suggest that the most probable scenario involves a\nmillisecond magnetar as the primary power source, supplemented by energy from\nradioactive decay. Our preferred model has a spin period of P = 3.2 ms, a\nmagnetic field of B = 28 x 10^14 G, an explosion energy of 2.3 foe, a nickel\nmass of M_Ni= 0.24 solar masses, and an ejected mass of 3.4 solar masses.\nAlternatively, we find that a purely nickel-powered model also provides a good\nmatch with the observations, though M_Ni > 0.8 solar masses are always\nrequired. However, the combination of such high values of M_Ni and low M_ej is\ndifficult to reconcile, indicating that this scenario is less probable. We have\nalso identified a specific region within the peak luminosity-velocity plane\nwhere an additional energy source beyond nickel may be necessary to power SNe\nwith characteristics similar to SN~2023pel. Our study indicates that an\nadditional energy source beyond radioactive decay is essential to explain the\nhigh brightness and relatively low expansion velocities of SN 2023pel. A\nmagnetar-powered model, similar to the models proposed for the very luminous\nGRB-SN 2011kl, aligns well with these characteristics.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-15T17:31:03Z"}
{"aid":"http://arxiv.org/abs/2504.11428v1","title":"Probing the Quantum Geometry of Correlated Metals using Optical\n  Conductivity","summary":"Recent studies have revealed that the quantum geometry of electronic bands\ndetermines the electromagnetic properties of non-interacting insulators and\nsemimetals. However, the role of quantum geometry in the optical responses of\ninteracting electron systems remains largely unexplored. Here we examine the\ninterplay between Coulomb interactions and Bloch-band quantum geometry in clean\nmetals. We demonstrate that the low-frequency optical conductivity of a\ncorrelated metal encodes the structure of Bloch wave functions at the Fermi\nsurface. This response originates from integrating out highly off-resonant\ninterband scattering processes enabled by Coulomb interactions. The resulting\nquantum-geometric contribution appears generically in multiband systems, but\nbecomes the dominant effect in the optical conductivity for a parabolic band.\nWe consider a dilute correlated metal near a topological band inversion and\nshow that the doping dependence of optical absorption can measure how the\norbital character of Bloch wave functions changes at the Fermi surface. Our\nresults illustrate how the confluence of quantum geometry and Coulomb\ninteractions can enable optical processes and enrich the physics of Fermi\nliquids.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall","published":"2025-04-15T17:39:13Z"}
{"aid":"http://arxiv.org/abs/2504.11430v1","title":"The 2D Lorentz-violating fermionic Casimir effect under thermal\n  conditions","summary":"In the present work, we explore the dimensional projection method applied to\na fermionic Lorentz invariance violation (LIV) theory with the CPT-even\ndimension-six extension. Due to the dimensional reduction of a fermionic system\nfrom $4D$ to $2D$, it is possible to study the influence of LIV on the Casimir\neffect under the MIT bag boundary condition model in a low-dimensional setting,\nwhere results are obtained without any approximations for a null-temperature\nsystem. Moreover, the Matsubara formalism is applied to derive closed\nexpressions for the influence of temperature on the physical observables:\nCasimir energy, Casimir force, and entropy associated with the system in a LIV\ncontext. For each thermal observable, the influence of the LIV correction term\nis considered in the analysis of both low- and high-temperature regimes.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-15T17:41:33Z"}
{"aid":"http://arxiv.org/abs/2504.11433v1","title":"Predicting Wave Dynamics using Deep Learning with Multistep Integration\n  Inspired Attention and Physics-Based Loss Decomposition","summary":"In this paper, we present a physics-based deep learning framework for\ndata-driven prediction of wave propagation in fluid media. The proposed\napproach, termed Multistep Integration-Inspired Attention (MI2A), combines a\ndenoising-based convolutional autoencoder for reduced latent representation\nwith an attention-based recurrent neural network with long-short-term memory\ncells for time evolution of reduced coordinates. This proposed architecture\ndraws inspiration from classical linear multistep methods to enhance stability\nand long-horizon accuracy in latent-time integration. Despite the efficiency of\nhybrid neural architectures in modeling wave dynamics, autoregressive\npredictions are often prone to accumulating phase and amplitude errors over\ntime. To mitigate this issue within the MI2A framework, we introduce a novel\nloss decomposition strategy that explicitly separates the training loss\nfunction into distinct phase and amplitude components. We assess the\nperformance of MI2A against two baseline reduced-order models trained with\nstandard mean-squared error loss: a sequence-to-sequence recurrent neural\nnetwork and a variant using Luong-style attention. To demonstrate the\neffectiveness of the MI2A model, we consider three benchmark wave propagation\nproblems of increasing complexity, namely one-dimensional linear convection,\nthe nonlinear viscous Burgers equation, and the two-dimensional Saint-Venant\nshallow water system. Our results demonstrate that the MI2A framework\nsignificantly improves the accuracy and stability of long-term predictions,\naccurately preserving wave amplitude and phase characteristics. Compared to the\nstandard long-short term memory and attention-based models, MI2A-based deep\nlearning exhibits superior generalization and temporal accuracy, making it a\npromising tool for real-time wave modeling.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA,physics.flu-dyn","published":"2025-04-15T17:47:20Z"}
{"aid":"http://arxiv.org/abs/2504.11445v1","title":"Pixel-level modelling of group-scale strong lens CASSOWARY 19","summary":"We present the first high-precision model for the group-scale strong lensing\nsystem CASSOWARY 19 (CSWA19), utilising images from the Hubble Space Telescope\n(HST). Sixteen member galaxies identified via the red-sequence method, and the\nmain halo, all modelled as the dual Pseudo Isothermal Elliptical profile\n(dPIE), are incorporated into a parametric lens model alongside an external\nshear field. To model the system, we adopt the PyAutoLens software package,\nemploying a progressive search chain strategy for realizing the transition of\nsource model from multiple S\\'ersic profiles to a brightness-adaptive\npixelization, which uses 1000 pixels in the source plane to reconstruct the\nbackground source corresponding to 177,144 image pixels in the image plane. Our\nresults indicate that the total mass within the Einstein radius is\n$M_{\\theta_\\mathrm{E}}$ $\\approx 1.41\\times10^{13}$M$_{\\odot}$ and the average\nslope of the total mass density $\\rho (r)\\propto r^{-\\gamma}$ is\n$\\tilde{\\gamma}=1.33$ within the effective radius. This slope is shallower than\nthose measured in galaxies and groups but is closer to those of galaxy\nclusters. In addition, our approach successfully resolves the two merging\ngalaxies in the background source and yields a total magnification of\n$\\mu=103.18^{+0.23}_{-0.19}$, which is significantly higher than the outcomes\nfrom previous studies of CSWA19. In summary, our research demonstrates the\neffectiveness of the brightness-adaptive pixelization source reconstruction\ntechnique for modelling group-scale strong lensing systems. It can serve as a\ntechnical reference for future investigations into pixel-level modelling of the\ngroup- and cluster-scale strong lensing systems.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T17:56:11Z"}
{"aid":"http://arxiv.org/abs/2504.11452v1","title":"The universal profile of the invariant factors of $({\\mathbb\n  Z}/n{\\mathbb Z})^\\times$","summary":"The structure of the multiplicative group $M_n = ({\\mathbb Z}/n{\\mathbb\nZ})^\\times$ encodes a great deal of arithmetic information about the integer\n$n$ (examples include $\\phi(n)$, the Carmichael function $\\lambda(n)$, and the\nnumber $\\omega(n)$ of distinct prime factors of $n$). We examine the invariant\nfactor structure of $M_n$ for typical integers $n$, that is, the decomposition\n$M_n \\cong {\\mathbb Z}/d_1{\\mathbb Z} \\times {\\mathbb Z}/d_2{\\mathbb Z} \\times\n\\cdots \\times {\\mathbb Z}/d_k{\\mathbb Z}$ where $d_1\\mid d_2\\mid\\cdots\\mid\nd_k$. We show that almost all integers have asymptotically the same invariant\nfactors for all but the largest factors; for example, asymptotically $1/2$ of\nthe invariant factors equal ${\\mathbb Z}/2{\\mathbb Z}$, asymptotically $1/4$ of\nthem equal ${\\mathbb Z}/12{\\mathbb Z}$, asymptotically $1/12$ of them equal\n${\\mathbb Z}/120{\\mathbb Z}$, and so on. Furthermore, for positive integers\n$k$, we establish a theorem of Erd\\H{o}s-Kac type for the number of invariant\nfactors of $M_n$ that equal ${\\mathbb Z}/k{\\mathbb Z}$, except that the\ndistribution is not a normal distribution but rather a skew-normal or related\ndistribution.","main_category":"math.NT","categories":"math.NT","published":"2025-04-15T17:58:31Z"}
{"aid":"http://arxiv.org/abs/2504.11456v1","title":"DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and\n  Verifiable Mathematical Dataset for Advancing Reasoning","summary":"The capacity for complex mathematical reasoning is a key benchmark for\nartificial intelligence. While reinforcement learning (RL) applied to LLMs\nshows promise, progress is significantly hindered by the lack of large-scale\ntraining data that is sufficiently challenging, possesses verifiable answer\nformats suitable for RL, and is free from contamination with evaluation\nbenchmarks. To address these limitations, we introduce DeepMath-103K, a new,\nlarge-scale dataset comprising approximately 103K mathematical problems,\nspecifically designed to train advanced reasoning models via RL. DeepMath-103K\nis curated through a rigorous pipeline involving source analysis, stringent\ndecontamination against numerous benchmarks, and filtering for high difficulty\n(primarily Levels 5-9), significantly exceeding existing open resources in\nchallenge. Each problem includes a verifiable final answer, enabling rule-based\nRL, and three distinct R1-generated solutions suitable for diverse training\nparadigms like supervised fine-tuning or distillation. Spanning a wide range of\nmathematical topics, DeepMath-103K promotes the development of generalizable\nreasoning. We demonstrate that models trained on DeepMath-103K achieve\nsignificant improvements on challenging mathematical benchmarks, validating its\neffectiveness. We release DeepMath-103K publicly to facilitate community\nprogress in building more capable AI reasoning systems:\nhttps://github.com/zwhe99/DeepMath.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.12616v1","title":"Graph-based Path Planning with Dynamic Obstacle Avoidance for Autonomous\n  Parking","summary":"Safe and efficient path planning in parking scenarios presents a significant\nchallenge due to the presence of cluttered environments filled with static and\ndynamic obstacles. To address this, we propose a novel and computationally\nefficient planning strategy that seamlessly integrates the predictions of\ndynamic obstacles into the planning process, ensuring the generation of\ncollision-free paths. Our approach builds upon the conventional Hybrid A star\nalgorithm by introducing a time-indexed variant that explicitly accounts for\nthe predictions of dynamic obstacles during node exploration in the graph, thus\nenabling dynamic obstacle avoidance. We integrate the time-indexed Hybrid A\nstar algorithm within an online planning framework to compute local paths at\neach planning step, guided by an adaptively chosen intermediate goal. The\nproposed method is validated in diverse parking scenarios, including\nperpendicular, angled, and parallel parking. Through simulations, we showcase\nour approach's potential in greatly improving the efficiency and safety when\ncompared to the state of the art spline-based planning method for parking\nsituations.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-17T03:43:20Z"}
{"aid":"http://arxiv.org/abs/2504.12627v1","title":"Uncertainty Quantification in Graph Neural Networks with Shallow\n  Ensembles","summary":"Machine-learned potentials (MLPs) have revolutionized materials discovery by\nproviding accurate and efficient predictions of molecular and material\nproperties. Graph Neural Networks (GNNs) have emerged as a state-of-the-art\napproach due to their ability to capture complex atomic interactions. However,\nGNNs often produce unreliable predictions when encountering out-of-domain data\nand it is difficult to identify when that happens. To address this challenge,\nwe explore Uncertainty Quantification (UQ) techniques, focusing on Direct\nPropagation of Shallow Ensembles (DPOSE) as a computationally efficient\nalternative to deep ensembles. By integrating DPOSE into the SchNet model, we\nassess its ability to provide reliable uncertainty estimates across diverse\nDensity Functional Theory datasets, including QM9, OC20, and Gold Molecular\nDynamics. Our findings often demonstrate that DPOSE successfully distinguishes\nbetween in-domain and out-of-domain samples, exhibiting higher uncertainty for\nunobserved molecule and material classes. This work highlights the potential of\nlightweight UQ methods in improving the robustness of GNN-based materials\nmodeling and lays the foundation for future integration with active learning\nstrategies.","main_category":"cs.LG","categories":"cs.LG,physics.comp-ph","published":"2025-04-17T04:02:53Z"}
{"aid":"http://arxiv.org/abs/2504.12657v1","title":"Photon Calibration Performance of KAGRA during the 4th Joint Observing\n  Run (O4)","summary":"KAGRA is a kilometer-scale cryogenic gravitational-wave (GW) detector in\nJapan. It joined the 4th joint observing run (O4) in May 2023 in collaboration\nwith the Laser Interferometer GW Observatory (LIGO) in the USA, and Virgo in\nItaly. After one month of observations, KAGRA entered a break period to enhance\nits sensitivity to GWs, and it is planned to rejoin O4 before its scheduled end\nin October 2025. To accurately recover the information encoded in the GW\nsignals, it is essential to properly calibrate the observed signals. We employ\na photon calibration (Pcal) system as a reference signal injector to calibrate\nthe output signals obtained from the telescope. In ideal future conditions, the\nuncertainty in Pcal could dominate the uncertainty in the observed data. In\nthis paper, we present the methods used to estimate the uncertainty in the Pcal\nsystems employed during KAGRA O4 and report an estimated system uncertainty of\n0.79%, which is three times lower than the uncertainty achieved in the previous\n3rd joint observing run (O3) in 2020. Additionally, we investigate the\nuncertainty in the Pcal laser power sensors, which had the highest impact on\nthe Pcal uncertainty, and estimate the beam positions on the KAGRA main mirror,\nwhich had the second highest impact. The Pcal systems in KAGRA are the first\nfully functional calibration systems for a cryogenic GW telescope. To avoid\ninterference with the KAGRA cryogenic systems, the Pcal systems incorporate\nunique features regarding their placement and the use of telephoto cameras,\nwhich can capture images of the mirror surface at almost normal incidence. As\nfuture GW telescopes, such as the Einstein Telescope, are expected to adopt\ncryogenic techniques, the performance of the KAGRA Pcal systems can serve as a\nvaluable reference.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-17T05:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.12658v1","title":"Rare-Event-Induced Ergodicity Breaking in Logarithmic Aging Systems","summary":"Ergodicity breaking and aging effects are fundamental challenges in\nout-of-equilibrium systems. Various mechanisms have been proposed to understand\nthe non-ergodic and aging phenomena, possibly related to observations in\nsystems ranging from structural glass and Anderson glasses to biological\nsystems and mechanical systems. While anomalous diffusion described by Levy\nstatistics efficiently captures ergodicity breaking, the origin of aging and\nergodicity breaking in systems with ultraslow dynamics remain unclear. Here, we\nreport a novel mechanism of ergodicity breaking in systems exhibiting log-aging\ndiffusion. This mechanism, characterized by increasingly infrequent rare events\nwith aging, yields statistics deviating significantly from Levy distribution,\nbreaking ergodicity as shown by unequal time- and ensemble-averaged mean\nsquared displacements and two distinct asymptotic probability distribution\nfunctions. Notably, although these rare events contribute negligibly to\nstatistical averages, they dramatically change the system's characteristic\ntime. This work lays the groundwork for microscopic understanding of\nout-of-equilibrium systems and provides new perspectives on glasses and\nGriffiths-McCoy singularities.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.soft,cond-mat.stat-mech","published":"2025-04-17T05:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.12663v1","title":"Persona-judge: Personalized Alignment of Large Language Models via\n  Token-level Self-judgment","summary":"Aligning language models with human preferences presents significant\nchallenges, particularly in achieving personalization without incurring\nexcessive computational costs. Existing methods rely on reward signals and\nadditional annotated data, limiting their scalability and adaptability to\ndiverse human values. To address these challenges, we introduce Persona-judge,\na novel discriminative paradigm that enables training-free personalized\nalignment with unseen preferences. Instead of optimizing policy parameters\nthrough external reward feedback, Persona-judge leverages the intrinsic\npreference judgment capabilities of the model. Specifically, a draft model\ngenerates candidate tokens conditioned on a given preference, while a judge\nmodel, embodying another preference, cross-validates the predicted tokens\nwhether to be accepted. Experimental results demonstrate that Persona-judge,\nusing the inherent preference evaluation mechanisms of the model, offers a\nscalable and computationally efficient solution to personalized alignment,\npaving the way for more adaptive customized alignment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T05:50:13Z"}
{"aid":"http://arxiv.org/abs/2504.12669v1","title":"A novel fast sweeping method for computing the attenuation operator\n  $t^*$ in absorbing media","summary":"$t^*$ represents the total path attenuation and characterizes the amplitude\ndecay of a propagating seismic wave. Calculating the attenuation operator $t^*$\nis typically required in seismic attenuation tomography. Traditional methods\nfor calculating $t^*$ require determining the ray path explicitly. However, ray\ntracing can be computationally intensive when processing large datasets, and\nconventional ray tracing techniques may fail even in mildly heterogeneous\nmedia. In this study, we propose a modified fast sweeping method (MFSM) to\nsolve the governing equation for $t^*$ without explicitly calculating the ray\npath. The approach consists of two main steps. First, the traveltime field is\ncalculated by numerically solving the eikonal equation using the fast sweeping\nmethod. Second, $t^*$ is computed by solving its governing equation with the\nMFSM, based on the discretization of the gradient of $t^*$ using an upwinding\nscheme derived from the traveltime gradient. The MFSM is rigorously validated\nthrough comparisons with analytical solutions and by examining $t^*$ errors\nunder grid refinement in both simple and complex models. Key performance\nmetrics, including convergence, number of iterations, and computation time, are\nevaluated. Two versions of the MFSM are developed for both Cartesian and\nspherical coordinate systems. We demonstrate the practical applicability of the\ndeveloped MFSM in calculating $t^*$ in North Island, and discuss the method's\nefficiency in estimating earthquake response spectra.","main_category":"physics.geo-ph","categories":"physics.geo-ph,physics.comp-ph","published":"2025-04-17T05:54:55Z"}
{"aid":"http://arxiv.org/abs/2504.12670v1","title":"Temporal Attention Pooling for Frequency Dynamic Convolution in Sound\n  Event Detection","summary":"Recent advances in deep learning, particularly frequency dynamic convolution\n(FDY conv), have significantly improved sound event detection (SED) by enabling\nfrequency-adaptive feature extraction. However, FDY conv relies on temporal\naverage pooling, which treats all temporal frames equally, limiting its ability\nto capture transient sound events such as alarm bells, door knocks, and speech\nplosives. To address this limitation, we propose temporal attention pooling\nfrequency dynamic convolution (TFD conv) to replace temporal average pooling\nwith temporal attention pooling (TAP). TAP adaptively weights temporal features\nthrough three complementary mechanisms: time attention pooling (TA) for\nemphasizing salient features, velocity attention pooling (VA) for capturing\ntransient changes, and conventional average pooling for robustness to\nstationary signals. Ablation studies show that TFD conv improves average PSDS1\nby 3.02% over FDY conv with only a 14.8% increase in parameter count. Classwise\nANOVA and Tukey HSD analysis further demonstrate that TFD conv significantly\nenhances detection performance for transient-heavy events, outperforming\nexisting FDY conv models. Notably, TFD conv achieves a maximum PSDS1 score of\n0.456, surpassing previous state-of-the-art SED systems. We also explore the\ncompatibility of TAP with other FDY conv variants, including dilated FDY conv\n(DFD conv), partial FDY conv (PFD conv), and multi-dilated FDY conv (MDFD\nconv). Among these, the integration of TAP with MDFD conv achieves the best\nresult with a PSDS1 score of 0.459, validating the complementary strengths of\ntemporal attention and multi-scale frequency adaptation. These findings\nestablish TFD conv as a powerful and generalizable framework for enhancing both\ntransient sensitivity and overall feature robustness in SED.","main_category":"eess.AS","categories":"eess.AS,cs.SD","published":"2025-04-17T06:03:43Z"}
{"aid":"http://arxiv.org/abs/2504.12675v1","title":"Physics Informed Constrained Learning of Dynamics from Static Data","summary":"A physics-informed neural network (PINN) models the dynamics of a system by\nintegrating the governing physical laws into the architecture of a neural\nnetwork. By enforcing physical laws as constraints, PINN overcomes challenges\nwith data scarsity and potentially high dimensionality. Existing PINN\nframeworks rely on fully observed time-course data, the acquisition of which\ncould be prohibitive for many systems. In this study, we developed a new PINN\nlearning paradigm, namely Constrained Learning, that enables the approximation\nof first-order derivatives or motions using non-time course or partially\nobserved data. Computational principles and a general mathematical formulation\nof Constrained Learning were developed. We further introduced MPOCtrL (Message\nPassing Optimization-based Constrained Learning) an optimization approach\ntailored for the Constrained Learning framework that strives to balance the\nfitting of physical models and observed data. Its code is available at github\nlink: https://github.com/ptdang1001/MPOCtrL Experiments on synthetic and\nreal-world data demonstrated that MPOCtrL can effectively detect the nonlinear\ndependency between observed data and the underlying physical properties of the\nsystem. In particular, on the task of metabolic flux analysis, MPOCtrL\noutperforms all existing data-driven flux estimators.","main_category":"cs.LG","categories":"cs.LG,physics.bio-ph,q-bio.MN","published":"2025-04-17T06:06:53Z"}
{"aid":"http://arxiv.org/abs/2504.12679v1","title":"TongUI: Building Generalized GUI Agents by Learning from Multimodal Web\n  Tutorials","summary":"Building Graphical User Interface (GUI) agents is a promising research\ndirection, which simulates human interaction with computers or mobile phones to\nperform diverse GUI tasks. However, a major challenge in developing generalized\nGUI agents is the lack of sufficient trajectory data across various operating\nsystems and applications, mainly due to the high cost of manual annotations. In\nthis paper, we propose the TongUI framework that builds generalized GUI agents\nby learning from rich multimodal web tutorials. Concretely, we crawl and\nprocess online GUI tutorials (such as videos and articles) into GUI agent\ntrajectory data, through which we produce the GUI-Net dataset containing 143K\ntrajectory data across five operating systems and more than 200 applications.\nWe develop the TongUI agent by fine-tuning Qwen2.5-VL-3B/7B models on GUI-Net,\nwhich show remarkable performance improvements on commonly used grounding and\nnavigation benchmarks, outperforming baseline agents about 10\\% on multiple\nbenchmarks, showing the effectiveness of the GUI-Net dataset and underscoring\nthe significance of our TongUI framework. We will fully open-source the code,\nthe GUI-Net dataset, and the trained models soon.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.12680v1","title":"Embodied-R: Collaborative Framework for Activating Embodied Spatial\n  Reasoning in Foundation Models via Reinforcement Learning","summary":"Humans can perceive and reason about spatial relationships from sequential\nvisual observations, such as egocentric video streams. However, how pretrained\nmodels acquire such abilities, especially high-level reasoning, remains\nunclear. This paper introduces Embodied-R, a collaborative framework combining\nlarge-scale Vision-Language Models (VLMs) for perception and small-scale\nLanguage Models (LMs) for reasoning. Using Reinforcement Learning (RL) with a\nnovel reward system considering think-answer logical consistency, the model\nachieves slow-thinking capabilities with limited computational resources. After\ntraining on only 5k embodied video samples, Embodied-R with a 3B LM matches\nstate-of-the-art multimodal reasoning models (OpenAI-o1, Gemini-2.5-pro) on\nboth in-distribution and out-of-distribution embodied spatial reasoning tasks.\nEmbodied-R also exhibits emergent thinking patterns such as systematic analysis\nand contextual integration. We further explore research questions including\nresponse length, training on VLM, strategies for reward design, and differences\nin model generalization after SFT (Supervised Fine-Tuning) and RL training.","main_category":"cs.AI","categories":"cs.AI,cs.CV","published":"2025-04-17T06:16:11Z"}
{"aid":"http://arxiv.org/abs/2504.12686v1","title":"Rheology of dilute granular gases with hard-core and inverse power-law\n  potentials","summary":"The kinetic theory of dilute granular gases with hard-core and inverse\npower-law potentials is developed. The scattering process is studied\ntheoretically, which yields the relative speed and the impact parameter\ndependence of the scattering angle. The viscosity is derived from the Boltzmann\nequation and its temperature dependence is plotted. We also perform the direct\nsimulation Monte Carlo to check the validity of the theory.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-17T06:26:46Z"}
{"aid":"http://arxiv.org/abs/2504.12690v1","title":"Accessibility Recommendations for Designing Better Mobile Application\n  User Interfaces for Seniors","summary":"Seniors represent a growing user base for mobile applications; however, many\napps fail to adequately address their accessibility challenges and usability\npreferences. To investigate this issue, we conducted an exploratory focus group\nstudy with 16 senior participants, from which we derived an initial set of user\npersonas highlighting key accessibility and personalisation barriers. These\npersonas informed the development of a model-driven engineering toolset, which\nwas used to generate adaptive mobile app prototypes tailored to seniors' needs.\nWe then conducted a second focus group study with 22 seniors to evaluate these\nprototypes and validate our findings. Based on insights from both studies, we\ndeveloped a refined set of personas and a series of accessibility and\npersonalisation recommendations grounded in empirical data, prior research,\naccessibility standards, and developer resources, aimed at supporting software\npractitioners in designing more inclusive mobile applications.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-04-17T06:32:05Z"}
{"aid":"http://arxiv.org/abs/2504.12692v1","title":"On the Brun--Titchmarsh theorem. II","summary":"Denote by $\\pi(x;q,a)$ the number of primes $p\\leqslant x$ with $p\\equiv\na\\bmod q.$ We prove new upper bounds for $\\pi(x;q,a)$ when $q$ is a large prime\nvery close to $\\sqrt{x}$, improving upon the classical work of Iwaniec (1982).\nThe proof reduces to bounding a quintilinear sum of Kloosterman sums, to which\nwe introduce a new shifting argument inspired by\nVinogradov--Burgess--Karatsuba, going beyond the classical Fourier-analytic\napproach thanks to a deep algebro-geometric result of Kowalski--Michel--Sawin\non sums of products of Kloosterman sums.","main_category":"math.NT","categories":"math.NT","published":"2025-04-17T06:34:51Z"}
{"aid":"http://arxiv.org/abs/2504.12700v1","title":"A Two-Phase Perspective on Deep Learning Dynamics","summary":"We propose that learning in deep neural networks proceeds in two phases: a\nrapid curve fitting phase followed by a slower compression or coarse graining\nphase. This view is supported by the shared temporal structure of three\nphenomena: grokking, double descent and the information bottleneck, all of\nwhich exhibit a delayed onset of generalization well after training error\nreaches zero. We empirically show that the associated timescales align in two\nrather different settings. Mutual information between hidden layers and input\ndata emerges as a natural progress measure, complementing circuit-based metrics\nsuch as local complexity and the linear mapping number. We argue that the\nsecond phase is not actively optimized by standard training algorithms and may\nbe unnecessarily prolonged. Drawing on an analogy with the renormalization\ngroup, we suggest that this compression phase reflects a principled form of\nforgetting, critical for generalization.","main_category":"hep-th","categories":"hep-th,cond-mat.dis-nn,cs.LG","published":"2025-04-17T06:57:37Z"}
{"aid":"http://arxiv.org/abs/2504.12712v1","title":"Convergence and Implicit Bias of Gradient Descent on Continual Linear\n  Classification","summary":"We study continual learning on multiple linear classification tasks by\nsequentially running gradient descent (GD) for a fixed budget of iterations per\ntask. When all tasks are jointly linearly separable and are presented in a\ncyclic/random order, we show the directional convergence of the trained linear\nclassifier to the joint (offline) max-margin solution. This is surprising\nbecause GD training on a single task is implicitly biased towards the\nindividual max-margin solution for the task, and the direction of the joint\nmax-margin solution can be largely different from these individual solutions.\nAdditionally, when tasks are given in a cyclic order, we present a\nnon-asymptotic analysis on cycle-averaged forgetting, revealing that (1)\nalignment between tasks is indeed closely tied to catastrophic forgetting and\nbackward knowledge transfer and (2) the amount of forgetting vanishes to zero\nas the cycle repeats. Lastly, we analyze the case where the tasks are no longer\njointly separable and show that the model trained in a cyclic order converges\nto the unique minimum of the joint loss function.","main_category":"cs.LG","categories":"cs.LG,math.OC","published":"2025-04-17T07:35:48Z"}
{"aid":"http://arxiv.org/abs/2504.12717v1","title":"Post-pre-training for Modality Alignment in Vision-Language Foundation\n  Models","summary":"Contrastive language image pre-training (CLIP) is an essential component of\nbuilding modern vision-language foundation models. While CLIP demonstrates\nremarkable zero-shot performance on downstream tasks, the multi-modal feature\nspaces still suffer from a modality gap, which is a gap between image and text\nfeature clusters and limits downstream task performance. Although existing\nworks attempt to address the modality gap by modifying pre-training or\nfine-tuning, they struggle with heavy training costs with large datasets or\ndegradations of zero-shot performance. This paper presents CLIP-Refine, a\npost-pre-training method for CLIP models at a phase between pre-training and\nfine-tuning. CLIP-Refine aims to align the feature space with 1 epoch training\non small image-text datasets without zero-shot performance degradations. To\nthis end, we introduce two techniques: random feature alignment (RaFA) and\nhybrid contrastive-distillation (HyCD). RaFA aligns the image and text features\nto follow a shared prior distribution by minimizing the distance to random\nreference vectors sampled from the prior. HyCD updates the model with hybrid\nsoft labels generated by combining ground-truth image-text pair labels and\noutputs from the pre-trained CLIP model. This contributes to achieving both\nmaintaining the past knowledge and learning new knowledge to align features.\nOur extensive experiments with multiple classification and retrieval tasks show\nthat CLIP-Refine succeeds in mitigating the modality gap and improving the\nzero-shot performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-17T07:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.12725v1","title":"The $S$-resolvent estimates for the Dirac operator on hyperbolic and\n  spherical spaces","summary":"This seminal paper marks the beginning of our investigation into on the\nspectral theory based on $S$-spectrum applied to the Dirac operator on\nmanifolds. Specifically, we examine in detail the cases of the Dirac operator\n$\\mathcal{D}_H$ on hyperbolic space and the Dirac operator $\\mathcal{D}_S$ on\nthe spherical space, where these operators, and their squares $\\mathcal{D}_H^2$\nand $\\mathcal{D}_S^2$, can be written in a very explicit form. This fact is\nvery important for the application of the spectral theory on the $S$-spectrum.\nIn fact, let $T$ denote a (right) linear Clifford operator, the $S$-spectrum is\nassociated with a second-order polynomial in the operator $T$, specifically the\noperator defined as $ Q_s(T) := T^2 - 2s_0T + |s|^2. $ This allows us to\nassociate to the Dirac operator boundary conditions that can be of Dirichlet\ntype but also of Robin-like type. Moreover, our theory is not limited to\nHilbert modules; it is applicable to Banach modules as well. The spectral\ntheory based on the $S$-spectrum has gained increasing attention in recent\nyears, particularly as it aims to provide quaternionic quantum mechanics with a\nsolid mathematical foundation from the perspective of spectral theory. This\ntheory was extended to Clifford operators, and more recently, the spectral\ntheorem has been adapted to this broader context. The $S$-spectrum is crucial\nfor defining the so-called $S$-functional calculus for quaternionic and\nClifford operators in various forms. This includes bounded as well as unbounded\noperators, where suitable estimates of sectorial and bi-sectorial type for the\n$S$-resolvent operator are essential for the convergence of the Dunford\nintegrals in this setting.","main_category":"math.FA","categories":"math.FA","published":"2025-04-17T08:06:18Z"}
{"aid":"http://arxiv.org/abs/2504.12727v1","title":"Efficient Major Transition Exchange under Distributional and Dual\n  Priority-respecting Constraints","summary":"Many real matching markets encounter distributional and fairness constraints.\nMotivated by the Chinese Major Transition Program (CMT), this paper studies the\ndesign of exchange mechanisms within a fresh framework of both distributional\nand dual priority-respecting constraints. Specifically, each student has an\ninitial assigned major and applies to transfer to a more desirable one. A\nstudent can successfully transfer majors only if they obtain eligibility from\nboth their initial major and the applied major. Each major has a dual priority:\na strict priority over current students who wish to transfer out and a strict\npriority over students from other majors who wish to transfer in. Additionally,\neach major faces a ceiling constraint and a floor constraint to regulate\nstudent distribution. We show that the existing mechanisms of CMT result in\navoidable inefficiencies, and propose two mechanisms that can match students to\nmajors in an efficient way as well as respecting each major's distributional\nand dual priority. The efficient mechanisms are based on a proposed solution\nconcept: eligibility maximization (EM), and two processes for identifying\nimprovement cycles--specifically, transfer-in exchangeable cycles and\ntransfer-out exchangeable cycles.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-17T08:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.12728v1","title":"Seierstad Sufficient Conditions for Stochastic Optimal Control Problems\n  with Infinite Horizon","summary":"In this note we consider a problem of stochastic optimal control with the\ninfinite-time horizon. We present analogues of the Seierstad sufficient\nconditions of overtaking optimality based on the dual variables stochastic\ndescribed by BSDEs appeared in the Bismut-Pontryagin maximum principle.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T08:09:23Z"}
{"aid":"http://arxiv.org/abs/2504.12731v1","title":"Nonlinear spin dynamics across Néel phase transition in\n  ferromagnetic/antiferromagnetic multilayers","summary":"We observe strongly nonlinear spin dynamics in ferro-/antiferro-magnetic\nmultilayers, controlled by the number of bilayers in the system, layer\nthicknesses, as well as temperature, peaking in magnitude near the N\\'eel point\nof the antiferromagnetic layers just above room temperature. Well above the\nN\\'eel transition, the individual ferromagnetic layers are exchange decoupled\nand resonate independently. As the temperature is lowered toward the N\\'eel\npoint, the ferromagnetic proximity effect through the thin antiferromagnetic\nspacers transforms the system into a weakly coupled macrospin chain along the\nfilm normal, which exhibits pronounced standing spin-wave resonance modes,\ncomparable in intensity to the uniform resonance in the ferromagnetic layers.\nThese findings are supported by our micromagnetic simulations showing clear\nspin-wave profiles with precessional phase lag along the macrospin chain. Well\nbelow the N\\'eel transition, the FeMn layers order strongly\nantiferromagnetically and exchange-pin the ferromagnetic layers to effectively\nmake the multilayer one macrospin. The appearance and intensity of the\nhigh-frequency spin-wave modes can thus be conveniently controlled by thermal\ngating the multilayer. The nonlinearity in the microwave response of the\ndemonstrated material can approach 100\\%, large compared to nonlinear materials\nused in e.g. optics, with second-harmonic generation often at the single\npercentage level.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T08:14:01Z"}
{"aid":"http://arxiv.org/abs/2504.12741v1","title":"Chaos indicators for non-linear dynamics in circular particle\n  accelerators","summary":"The understanding of non-linear effects in circular storage rings and\ncolliders based on superconducting magnets is a key issue for the luminosity\nthe beam lifetime optimisation. A detailed analysis of the multidimensional\nphase space requires a large computing effort when many variants of the\nmagnetic lattice, representing the realisation of magnetic errors or\nconfigurations for performance optimisation, have to be considered. Dynamic\nindicators for chaos detection have proven to be very effective in finding and\ndistinguishing the weakly-chaotic regions of phase space where diffusion takes\nplace and regions that remain stable over time scales in the order of multiple\nhours of continuous operation. This paper explores the use of advanced chaos\nindicators, including the Fast Lyapunov Indicator with Birkhoff weights and the\nReverse Error Method, in realistic lattice models for the CERN Large Hadron\nCollider (LHC). Their convergence, predictive power, and potential to define a\nmagnetic lattice quality factor linked to long-term dynamic aperture are\nassessed. The results demonstrate the efficiency of these indicators in\nidentifying chaotic dynamics, offering valuable insights of these chaos\nindicators for optimising accelerator lattices with reduced computational cost\ncompared to the classical approach based on CPU-demanding long-term tracking\ncampaigns.","main_category":"physics.acc-ph","categories":"physics.acc-ph,nlin.CD","published":"2025-04-17T08:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.12743v1","title":"Quasinormal Modes and Greybody Factors of Scalar Field Perturbations in\n  the NED Corrected Charged Black Hole Spacetime","summary":"Inspired by the quark-antiquark confinement potential, Mazharimousavi et al.\n\\cite{Mazharimousavi:2023okd} proposed a nonlinear electrodynamics (NED) model,\nand based on this model, they constructed a charged black hole solution that\nincludes a logarithmic correction term ($\\propto \\frac{\\zeta \\ln r}{r}$). On\nthe basis of the Reissner-Nordstr\\\"om metric, this solution realizes a\nlong-range confinement correction by introducing the NED parameter $\\zeta$,\nproviding a new theoretical perspective for explaining the anomalies in galaxy\nrotation curves. To deeply explore the dynamic properties of this black hole\nsolution, this paper combines two complementary methods, namely, time-domain\nevolution and the WKB approximation, to calculate the quasinormal mode (QNM)\nspectrum of its scalar field perturbations. The research results show that the\noscillation frequencies and decay rates of the low-order QNM modes decrease\nmonotonically with the increase of the NED parameter $\\zeta$, and exhibit an\napproximately linear dependence. The analysis of the greybody factor (GF)\nindicates that as $\\zeta$ increases, the transmittance of the low-frequency\nscalar field also increases. The enhanced long-range confinement effect caused\nby the increase of $\\zeta$ makes low-frequency perturbations more likely to\nsurvive and propagate in space-time on the one hand, and at the same time\nenhances the transmission ability of the low-frequency scalar field. These\ncharacteristics provide key theoretical predictions and potential observational\nfeatures for testing and constraining such NED models in a strong gravitational\nfield environment in the future using the observational data of gravitational\nwave astronomy or Hawking radiation.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-17T08:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.12746v1","title":"A note on one-variable theorems for NSOP","summary":"We give an example of an SOP theory $T$, such that any $L(M)$-formula\n$\\varphi(x,y)$ with $|y|=1$ is NSOP. We show that any such $T$ must have the\nindependence property. We also give a simplified proof of Lachlan's theorem\nthat if every $L$-formula $\\varphi(x,y)$ with $|x|=1$ is NSOP, then $T$ is\nNSOP.","main_category":"math.LO","categories":"math.LO","published":"2025-04-17T08:38:02Z"}
{"aid":"http://arxiv.org/abs/2504.12749v1","title":"LAD-Reasoner: Tiny Multimodal Models are Good Reasoners for Logical\n  Anomaly Detection","summary":"Recent advances in industrial anomaly detection have highlighted the need for\ndeeper logical anomaly analysis, where unexpected relationships among objects,\ncounts, and spatial configurations must be identified and explained. Existing\napproaches often rely on large-scale external reasoning modules or elaborate\npipeline designs, hindering practical deployment and interpretability. To\naddress these limitations, we introduce a new task, Reasoning Logical Anomaly\nDetection (RLAD), which extends traditional anomaly detection by incorporating\nlogical reasoning. We propose a new framework, LAD-Reasoner, a customized tiny\nmultimodal language model built on Qwen2.5-VL 3B. Our approach leverages a\ntwo-stage training paradigm that first employs Supervised Fine-Tuning (SFT) for\nfine-grained visual understanding, followed by Group Relative Policy\nOptimization (GRPO) to refine logical anomaly detection and enforce coherent,\nhuman-readable reasoning. Crucially, reward signals are derived from both the\ndetection accuracy and the structural quality of the outputs, obviating the\nneed for building chain of thought (CoT) reasoning data. Experiments on the\nMVTec LOCO AD dataset show that LAD-Reasoner, though significantly smaller,\nmatches the performance of Qwen2.5-VL-72B in accuracy and F1 score, and further\nexcels in producing concise and interpretable rationales. This unified design\nreduces reliance on large models and complex pipelines, while offering\ntransparent and interpretable insights into logical anomaly detection. Code and\ndata will be released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:41:23Z"}
{"aid":"http://arxiv.org/abs/2504.12750v1","title":"Spatial Functional Deep Neural Network Model: A New Prediction Algorithm","summary":"Accurate prediction of spatially dependent functional data is critical for\nvarious engineering and scientific applications. In this study, a spatial\nfunctional deep neural network model was developed with a novel non-linear\nmodeling framework that seamlessly integrates spatial dependencies and\nfunctional predictors using deep learning techniques. The proposed model\nextends classical scalar-on-function regression by incorporating a spatial\nautoregressive component while leveraging functional deep neural networks to\ncapture complex non-linear relationships. To ensure a robust estimation, the\nmethodology employs an adaptive estimation approach, where the spatial\ndependence parameter was first inferred via maximum likelihood estimation,\nfollowed by non-linear functional regression using deep learning. The\neffectiveness of the proposed model was evaluated through extensive Monte Carlo\nsimulations and an application to Brazilian COVID-19 data, where the goal was\nto predict the average daily number of deaths. Comparative analysis with\nmaximum likelihood-based spatial functional linear regression and functional\ndeep neural network models demonstrates that the proposed algorithm\nsignificantly improves predictive performance. The results for the Brazilian\nCOVID-19 data showed that while all models achieved similar mean squared error\nvalues over the training modeling phase, the proposed model achieved the lowest\nmean squared prediction error in the testing phase, indicating superior\ngeneralization ability.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-17T08:44:29Z"}
{"aid":"http://arxiv.org/abs/2504.12757v1","title":"MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI\n  System","summary":"As Agentic AI gain mainstream adoption, the industry invests heavily in model\ncapabilities, achieving rapid leaps in reasoning and quality. However, these\nsystems remain largely confined to data silos, and each new integration\nrequires custom logic that is difficult to scale. The Model Context Protocol\n(MCP) addresses this challenge by defining a universal, open standard for\nsecurely connecting AI-based applications (MCP clients) to data sources (MCP\nservers). However, the flexibility of the MCP introduces new risks, including\nmalicious tool servers and compromised data integrity. We present MCP Guardian,\na framework that strengthens MCP-based communication with authentication,\nrate-limiting, logging, tracing, and Web Application Firewall (WAF) scanning.\nThrough real-world scenarios and empirical testing, we demonstrate how MCP\nGuardian effectively mitigates attacks and ensures robust oversight with\nminimal overheads. Our approach fosters secure, scalable data access for AI\nassistants, underscoring the importance of a defense-in-depth approach that\nenables safer and more transparent innovation in AI-driven environments.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-17T08:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.12760v1","title":"Analyzing multi-center randomized trials with covariate adjustment while\n  accounting for clustering","summary":"Augmented inverse probability weighting (AIPW) and G-computation with\ncanonical generalized linear models have become increasingly popular for\nestimating the average treatment effect in randomized experiments. These\nestimators leverage outcome prediction models to adjust for imbalances in\nbaseline covariates across treatment arms, improving statistical power compared\nto unadjusted analyses, while maintaining control over Type I error rates, even\nwhen the models are misspecified. Practical application of such estimators\noften overlooks the clustering present in multi-center clinical trials. Even\nwhen prediction models account for center effects, this neglect can degrade the\ncoverage of confidence intervals, reduce the efficiency of the estimators, and\ncomplicate the interpretation of the corresponding estimands. These issues are\nparticularly pronounced for estimators of counterfactual means, though less\nsevere for those of the average treatment effect, as demonstrated through Monte\nCarlo simulations and supported by theoretical insights. To address these\nchallenges, we develop efficient estimators of counterfactual means and the\naverage treatment effect in a random center. These extract information from\nbaseline covariates by relying on outcome prediction models, but remain\nunbiased in large samples when these models are misspecified. We also introduce\nan accompanying inference framework inspired by random-effects meta-analysis\nand relevant for settings where data from many small centers are being\nanalyzed. Adjusting for center effects yields substantial gains in efficiency,\nespecially when treatment effect heterogeneity across centers is large. Monte\nCarlo simulations and application to the WASH Benefits Bangladesh study\ndemonstrate adequate performance of the proposed methods.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T08:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.12767v1","title":"Out of Sight Out of Mind, Out of Sight Out of Mind: Measuring Bias in\n  Language Models Against Overlooked Marginalized Groups in Regional Contexts","summary":"We know that language models (LMs) form biases and stereotypes of minorities,\nleading to unfair treatments of members of these groups, thanks to research\nmainly in the US and the broader English-speaking world. As the negative\nbehavior of these models has severe consequences for society and individuals,\nindustry and academia are actively developing methods to reduce the bias in\nLMs. However, there are many under-represented groups and languages that have\nbeen overlooked so far. This includes marginalized groups that are specific to\nindividual countries and regions in the English speaking and Western world, but\ncrucially also almost all marginalized groups in the rest of the world. The UN\nestimates, that between 600 million to 1.2 billion people worldwide are members\nof marginalized groups and in need for special protection. If we want to\ndevelop inclusive LMs that work for everyone, we have to broaden our\nunderstanding to include overlooked marginalized groups and low-resource\nlanguages and dialects.\n  In this work, we contribute to this effort with the first study investigating\noffensive stereotyping bias in 23 LMs for 270 marginalized groups from Egypt,\nthe remaining 21 Arab countries, Germany, the UK, and the US. Additionally, we\ninvestigate the impact of low-resource languages and dialects on the study of\nbias in LMs, demonstrating the limitations of current bias metrics, as we\nmeasure significantly higher bias when using the Egyptian Arabic dialect versus\nModern Standard Arabic. Our results show, LMs indeed show higher bias against\nmany marginalized groups in comparison to dominant groups. However, this is not\nthe case for Arabic LMs, where the bias is high against both marginalized and\ndominant groups in relation to religion and ethnicity.\n  Our results also show higher intersectional bias against Non-binary, LGBTQIA+\nand Black women.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T09:05:50Z"}
{"aid":"http://arxiv.org/abs/2504.12780v1","title":"Tailoring Electromagnetic Fields in RF Cavities","summary":"Recent work introduced a systematic method for designing so-called\nazimuthally modulated RF cavities that support transverse magnetic modes\ncomposed of user-desired multipoles, enabling precision control of the\nmagnitude and orientation of multipolar components in RF cavity design. This\npaper extends this method to practical implementation by deriving the\nmultipolar expansion of the longitudinal electric field in such RF cavities\nwith beam pipes, as well as the momentum change of ultra-relativistic particles\ntraversing these modes. The derived equations explicitly show the radial\nvariation of the change in longitudinal and transverse momentum follows a\npolynomial rather than Bessel-function relationship. The expression for the\nlongitudinal electric field is then compared to a field map obtained from the\n3D electromagnetic simulation of an azimuthally modulated cavity designed to\nsupport a mode composed of monopole, dipole, and quadrupole components. Beam\ndynamics studies are presented to assess the derived expressions for the change\nin momentum, including the effects of relaxing the ultra-relativistic\nassumption. Finally, two example applications are presented: the first\ndemonstrates the removal of unwanted transverse multipoles to create a\nmultipole-free accelerating structure with a single-port coupler, whereas the\nsecond illustrates the synthesis of desired multipoles to create an RF cavity\nthat transforms the transverse distribution of a beam from Gaussian to uniform.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-17T09:25:35Z"}
{"aid":"http://arxiv.org/abs/2504.12803v1","title":"Enhancing Explainability and Reliable Decision-Making in Particle Swarm\n  Optimization through Communication Topologies","summary":"Swarm intelligence effectively optimizes complex systems across fields like\nengineering and healthcare, yet algorithm solutions often suffer from low\nreliability due to unclear configurations and hyperparameters. This study\nanalyzes Particle Swarm Optimization (PSO), focusing on how different\ncommunication topologies Ring, Star, and Von Neumann affect convergence and\nsearch behaviors. Using an adapted IOHxplainer , an explainable benchmarking\ntool, we investigate how these topologies influence information flow,\ndiversity, and convergence speed, clarifying the balance between exploration\nand exploitation. Through visualization and statistical analysis, the research\nenhances interpretability of PSO's decisions and provides practical guidelines\nfor choosing suitable topologies for specific optimization tasks. Ultimately,\nthis contributes to making swarm based optimization more transparent, robust,\nand trustworthy.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-17T10:05:10Z"}
{"aid":"http://arxiv.org/abs/2504.12816v1","title":"SMARTe: Slot-based Method for Accountable Relational Triple extraction","summary":"Relational Triple Extraction (RTE) is a fundamental task in Natural Language\nProcessing (NLP). However, prior research has primarily focused on optimizing\nmodel performance, with limited efforts to understand the internal mechanisms\ndriving these models. Many existing methods rely on complex preprocessing to\ninduce specific interactions, often resulting in opaque systems that may not\nfully align with their theoretical foundations. To address these limitations,\nwe propose SMARTe: a Slot-based Method for Accountable Relational Triple\nextraction. SMARTe introduces intrinsic interpretability through a slot\nattention mechanism and frames the task as a set prediction problem. Slot\nattention consolidates relevant information into distinct slots, ensuring all\npredictions can be explicitly traced to learned slot representations and the\ntokens contributing to each predicted relational triple. While emphasizing\ninterpretability, SMARTe achieves performance comparable to state-of-the-art\nmodels. Evaluations on the NYT and WebNLG datasets demonstrate that adding\ninterpretability does not compromise performance. Furthermore, we conducted\nqualitative assessments to showcase the explanations provided by SMARTe, using\nattention heatmaps that map to their respective tokens. We conclude with a\ndiscussion of our findings and propose directions for future research.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T10:21:15Z"}
{"aid":"http://arxiv.org/abs/2504.12818v1","title":"An etude on a renormalization","summary":"In this paper, we study renormalization, that is, the procedure for\neliminating singularities, for a special model using both combinatorial\ntechniques in the framework of working with formal series, and using a limit\ntransition in a standard multidimensional integral, taking into account the\nremoval of the singular components. Special attention is paid to the\ncomparative analysis of the two views on the problem. It is remarkably that the\ndivergences, which have the same form in one approach, acquire a different\nnature in another approach and lead to interesting consequences. A special\ndeformation of the spectrum is used as regularization.","main_category":"math-ph","categories":"math-ph,hep-th,math.CA,math.MP","published":"2025-04-17T10:22:01Z"}
{"aid":"http://arxiv.org/abs/2504.12823v1","title":"Trading Prophets: How to Trade Multiple Stocks Optimally","summary":"In the single stock trading prophet problem formulated by Correa et al.\\\n(2023), an online algorithm observes a sequence of prices of a stock. At each\nstep, the algorithm can either buy the stock by paying the current price if it\ndoesn't already hold the stock, or it can sell the currently held stock and\ncollect the current price as a reward. The goal of the algorithm is to maximize\nits overall profit.\n  In this work, we generalize the model and the results of Correa et al.\\ by\nallowing the algorithm to trade multiple stocks. First, we formulate the\n$(k,\\ell,\\ell')$-Trading Prophet Problem, wherein there are $k$ stocks in the\nmarket, and the online algorithm can hold up to $\\ell$ stocks at any time,\nwhere $\\ell\\leq k$. The online algorithm competes against an offline algorithm\nthat can hold at most $\\ell'\\leq\\ell$ stocks at any time. Under the assumption\nthat prices of different stocks are independent, we show that, for any $\\ell$,\n$\\ell'$, and $k$, the optimal competitive ratio of $(k,\\ell,\\ell')$-Trading\nProphet Problem is $\\min(1/2,\\ell/k)$.\n  We further introduce the more general $\\cal{M}$-Trading Prophet Problem over\na matroid $\\cal{M}$ on the set of $k$ stocks, wherein the stock prices at any\ngiven time are possibly correlated (but are independent across time). The\nalgorithm is allowed to hold only a feasible subset of stocks at any time. We\nprove a tight bound of $1/(1+d)$ on the competitive ratio of the\n$\\cal{M}$-Trading Prophet Problem, where $d$ is the density of the matroid.\n  We then consider the non-i.i.d.\\ random order setting over a matroid, wherein\nstock prices drawn independently from $n$ potentially different distributions\nare presented in a uniformly random order. In this setting, we achieve a\ncompetitive ratio of at least $1/(1+d)-\\cal{O}(1/n)$, where $d$ is the density\nof the matroid, matching the hardness result for i.i.d.\\ instances as $n$\napproaches $\\infty$.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-17T10:34:37Z"}
{"aid":"http://arxiv.org/abs/2504.12825v1","title":"TwoSquared: 4D Generation from 2D Image Pairs","summary":"Despite the astonishing progress in generative AI, 4D dynamic object\ngeneration remains an open challenge. With limited high-quality training data\nand heavy computing requirements, the combination of hallucinating unseen\ngeometry together with unseen movement poses great challenges to generative\nmodels. In this work, we propose TwoSquared as a method to obtain a 4D\nphysically plausible sequence starting from only two 2D RGB images\ncorresponding to the beginning and end of the action. Instead of directly\nsolving the 4D generation problem, TwoSquared decomposes the problem into two\nsteps: 1) an image-to-3D module generation based on the existing generative\nmodel trained on high-quality 3D assets, and 2) a physically inspired\ndeformation module to predict intermediate movements. To this end, our method\ndoes not require templates or object-class-specific prior knowledge and can\ntake in-the-wild images as input. In our experiments, we demonstrate that\nTwoSquared is capable of producing texture-consistent and geometry-consistent\n4D sequences only given 2D images.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T10:39:52Z"}
{"aid":"http://arxiv.org/abs/2504.12830v1","title":"Questions: A Taxonomy for Critical Reflection in Machine-Supported\n  Decision-Making","summary":"Decision-makers run the risk of relying too much on machine recommendations.\nExplainable AI, a common strategy for calibrating reliance, has mixed and even\nnegative effects, such as increasing overreliance. To cognitively engage the\ndecision-maker and to facilitate a deliberate decision-making process, we\npropose a potential `reflection machine' that supports critical reflection\nabout the pending decision, including the machine recommendation. Reflection\nhas been shown to improve critical thinking and reasoning, and thus\ndecision-making. One way to stimulate reflection is to ask relevant questions.\nTo systematically create questions, we present a question taxonomy inspired by\nSocratic questions and human-centred explainable AI. This taxonomy can\ncontribute to the design of such a `reflection machine' that asks\ndecision-makers questions. Our work is part of the growing research on\nhuman-machine collaborations that goes beyond the paradigm of machine\nrecommendations and explanations, and aims to enable greater human oversight as\nrequired by the European AI Act.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-17T10:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.12855v1","title":"Amplitudes and partial wave unitarity bounds","summary":"We develop a formalism, based on spinor-helicity techniques, to generalize\nthe formulation of partial wave unitarity bounds. We discuss unitarity bounds\nfor $N \\to M$ (with $N,M \\geq 2$) scattering processes -- relevant for\nhigh-energy future colliders -- and spin-2 or higher-spin theories -- relevant\nfor effective field theories of gravity -- that are not approachable by\nstandard methods. Moreover, we emphasize the power and complementarity of\npositivity and partial wave unitarity bounds to constrain the parameter space\nof effective field theories.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-17T11:22:34Z"}
{"aid":"http://arxiv.org/abs/2504.12863v1","title":"The impact of ram pressure on cluster galaxies, insights from GAEA and\n  TNG","summary":"Ram pressure stripping (RPS) has a non-negligible impact on the gas content\nof cluster galaxies. We use the semi-analytic model GAEA and the\nhydro-simulation TNG to investigate whether cluster galaxies suffer a strong\nRPS that is sufficient to remove a significant fraction of their gas during the\nfirst pericentric passage. We estimate that a ram pressure of $10^{-10.5}$,\n$10^{-12} $, $10^{-13.5} $ $g cm^{-1} s^{-2}$ can remove at most $90\\%$,\n$50\\%$, and $20\\%$ of the cold gas reservoir from low-mass galaxies with\n$9<\\log M_{\\star}/{\\rm M}_{\\odot} <9.5$, assuming the gas can be stripped\ninstantaneously. We then use this information to divide the phase space diagram\ninto `strong', `moderate', `weak', and `no' RPS zones. By tracing the orbit of\ngalaxies since $2.5R_{vir}$, we find in both GAEA and TNG that about half of\nthe galaxies in Virgo-like halos ($\\log M_h / M_{\\odot} \\sim 14 $) did not\nsuffer strong RPS during the first pericentric passage. In Coma-like halos\n($\\log M_h / M_{\\odot} \\sim 15$), almost all galaxies have suffered strong RPS\nduring the first pericentric passage, which can remove all gas from low-mass\ngalaxies but is insufficient to significantly reduce the gas content of more\nmassive galaxies. In general, results from TNG and GAEA are consistent, with\nthe RPS being only slightly stronger in TNG than in GAEA. Our findings suggest\nthat most cluster galaxies will maintain a notable fraction of their gas and\ncontinue forming stars after the first pericentric passage, except for those\nwith low stellar mass ($\\log M_{\\star}/{\\rm M}_{\\odot} <9.5$) in very massive\nhalos ($\\log M_{h}/{\\rm M}_{\\odot} > 15$).","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T11:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.12864v1","title":"Unbiased Quantum Error Mitigation Without Reliance on an Accurate Error\n  Model","summary":"Probabilistic error cancellation is a quantum error mitigation technique\ncapable of producing unbiased computation results but requires an accurate\nerror model. Constructing this model involves estimating a set of parameters,\nwhich, in the worst case, may scale exponentially with the number of qubits. In\nthis paper, we introduce a method called spacetime noise inversion, revealing\nthat unbiased quantum error mitigation can be achieved with just a single\naccurately measured error parameter and a sampler of Pauli errors. The error\nsampler can be efficiently implemented in conjunction with quantum error\ncorrection. We provide rigorous analyses of bias and cost, showing that the\ncost of measuring the parameter and sampling errors is low -- comparable to the\ncost of the computation itself. Moreover, our method is robust to the\nfluctuation of error parameters, a limitation of unbiased quantum error\nmitigation in practice. These findings highlight the potential of integrating\nquantum error mitigation with error correction as a promising approach to\nsuppress computational errors in the early fault-tolerant era.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T11:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.12877v1","title":"Market-Driven Flexibility Provision: A Tri-Level Optimization Approach\n  for Carbon Reduction","summary":"The integration of renewable energy resources (RES) in the power grid can\nreduce carbon intensity, but also presents certain challenges. The uncertainty\nand intermittent nature of RES emphasize the need for flexibility in power\nsystems. Moreover, there are noticeable mismatches between real-time\nelectricity prices and carbon intensity patterns throughout the day. These\ndiscrepancies may lead customers to schedule energy-intensive tasks during the\nearly hours of the day, a period characterized by lower electricity prices but\nhigher carbon intensity. This paper introduces a novel and comprehensive\nframework aimed at encouraging customer participation in electricity markets\nand aligning their flexibility with carbon intensity trends. The proposed\napproach integrates an incentive-based tariff with a tri-level optimization\nmodel, where customers are motivated to submit flexibility bids and, in return,\nreceive financial rewards based on their contributions. The tri-level model\nensures a dynamic interaction between the market operation platform (MOP) and\nend-users. Simulations are performed on a modified IEEE-33 bus system,\nsupported by two scenarios with different RES generations and customer\nbehaviors. Results demonstrate the effectiveness of the proposed framework in\nguiding the customers' consumption behaviors towards low carbon intensity.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-17T12:04:49Z"}
{"aid":"http://arxiv.org/abs/2504.12887v1","title":"A Novel View on the Inner Crusts of Neo-Neutron Stars: exotic light\n  nuclei, diffusional and thermodynamical stability","summary":"Based on an extended nuclear statistical equilibrium model, we investigate\nthe properties of non-accreted crusts of young and warm neo-neutron stars,\ni.e., of finite-temperature inhomogeneous dense matter in beta equilibrium. We\npresent two novel results and one known, but frequently ignored property of\nsuch matter. The first new feature is the appearance, in the deep inner crust,\nof an extensive and almost pure $^{14}$He layer that extends up to the density\nof the transition to homogeneous matter. This layer may challenge the idea of\nnuclear pasta phases, significantly impact the transport properties and the\ncrust crystallization process. Second, we raise the question of the\n(in)stability of the inner crust with respect to diffusion of ions (buoyancy)\nand demonstrate that our crust is stable, in contrast with the predictions of\nsome other models. Finally, we show that subsaturated stellar matter is\nthermodynamically stable with respect to density fluctuations, which rules out\na first-order phase transition between inhomogeneous and homogeneous phases.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-04-17T12:21:46Z"}
{"aid":"http://arxiv.org/abs/2504.12900v1","title":"FashionDPO:Fine-tune Fashion Outfit Generation Model using Direct\n  Preference Optimization","summary":"Personalized outfit generation aims to construct a set of compatible and\npersonalized fashion items as an outfit. Recently, generative AI models have\nreceived widespread attention, as they can generate fashion items for users to\ncomplete an incomplete outfit or create a complete outfit. However, they have\nlimitations in terms of lacking diversity and relying on the supervised\nlearning paradigm. Recognizing this gap, we propose a novel framework\nFashionDPO, which fine-tunes the fashion outfit generation model using direct\npreference optimization. This framework aims to provide a general fine-tuning\napproach to fashion generative models, refining a pre-trained fashion outfit\ngeneration model using automatically generated feedback, without the need to\ndesign a task-specific reward function. To make sure that the feedback is\ncomprehensive and objective, we design a multi-expert feedback generation\nmodule which covers three evaluation perspectives, \\ie quality, compatibility\nand personalization. Experiments on two established datasets, \\ie iFashion and\nPolyvore-U, demonstrate the effectiveness of our framework in enhancing the\nmodel's ability to align with users' personalized preferences while adhering to\nfashion compatibility principles. Our code and model checkpoints are available\nat https://github.com/Yzcreator/FashionDPO.","main_category":"cs.MM","categories":"cs.MM,cs.IR","published":"2025-04-17T12:41:41Z"}
{"aid":"http://arxiv.org/abs/2504.12901v1","title":"Control of blow-up profiles for the mass-critical focusing nonlinear\n  Schrödinger equation on bounded domains","summary":"In this paper, we consider the mass-critical focusing nonlinear Schr\\\"odinger\non bounded two-dimensional domains with Dirichlet boundary conditions. In the\nabsence of control, it is well-known that free solutions starting from initial\ndata sufficiently large can blow-up. More precisely, given a finite number of\npoints, there exists particular profiles blowing up exactly at these points at\nthe blow-up time. For pertubations of these profiles, we show that, with the\nhelp of an appropriate nonlinear feedback law located in an open set containing\nthe blow-up points, the blow-up can be prevented from happening. More\nspecifically, we construct a small-time control acting just before the blow-up\ntime. The solution may then be extended globally in time. This is the first\nresult of control for blow-up profiles for nonlinear Schr\\\"odinger type\nequations. Assuming further a geometrical control condition on the support of\nthe control, we are able to prove a null-controllability result for such\nblow-up profiles. Finally, we discuss possible extensions to three-dimensional\ndomains.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-17T12:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.12902v1","title":"The Rise of Bluesky","summary":"This study investigates the rapid growth and evolving network structure of\nBluesky from August 2023 to February 2025. Through multiple waves of user\nmigrations, the platform has reached a stable, persistently active user base.\nThe growth process has given rise to a dense follower network with clustering\nand hub features that favor viral information diffusion. These developments\nhighlight engagement and structural similarities between Bluesky and\nestablished platforms.","main_category":"cs.SI","categories":"cs.SI,cs.CY","published":"2025-04-17T12:46:44Z"}
{"aid":"http://arxiv.org/abs/2504.12912v1","title":"On the Geometry of Solutions of the Fully Nonlinear Inhomogeneous\n  One-Phase Stefan Problem","summary":"In this paper, we characterize the geometry of solutions to one-phase\ninhomogeneous fully nonlinear Stefan problem with flat free boundaries under a\nnew nondegeneracy assumption. This continues the study of regularity of flat\nfree boundaries for the linear inhomogeneous Stefan problem started in [9], as\nwell as justifies the definition of flatness assumed in [15].","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T13:02:29Z"}
{"aid":"http://arxiv.org/abs/2504.12915v1","title":"ConExion: Concept Extraction with Large Language Models","summary":"In this paper, an approach for concept extraction from documents using\npre-trained large language models (LLMs) is presented. Compared with\nconventional methods that extract keyphrases summarizing the important\ninformation discussed in a document, our approach tackles a more challenging\ntask of extracting all present concepts related to the specific domain, not\njust the important ones. Through comprehensive evaluations of two widely used\nbenchmark datasets, we demonstrate that our method improves the F1 score\ncompared to state-of-the-art techniques. Additionally, we explore the potential\nof using prompts within these models for unsupervised concept extraction. The\nextracted concepts are intended to support domain coverage evaluation of\nontologies and facilitate ontology learning, highlighting the effectiveness of\nLLMs in concept extraction tasks. Our source code and datasets are publicly\navailable at https://github.com/ISE-FIZKarlsruhe/concept_extraction.","main_category":"cs.CL","categories":"cs.CL,cs.IR","published":"2025-04-17T13:05:14Z"}
{"aid":"http://arxiv.org/abs/2504.12919v1","title":"Retarded Causal Set Propagator in 2D Anti de-Sitter Spacetime","summary":"We investigate the viability of Causal Set Theory (CST) as a framework for\ndiscretizing $(1+1)$-dimensional anti-de Sitter spacetime (AdS$_{1+1}$). In\nCST, spacetime is modeled as a locally finite, partially ordered set that\nreflects the causal structure of events. This fundamentally discrete\nperspective has shown promise in flat spacetime scenarios, while its\napplication to curved geometries is a current field of study. We address this\nby studying the retarded scalar field propagator on causal sets generated by\nPoisson sprinkling in AdS$_{1+1}$. We first show the solution of the continuum\npropagator using the Klein-Gordon equation, solved in terms of geodesic\ndistance. On the discrete side, we employ Shumans path sum method to derive the\ncorresponding propagator, emphasizing that it is valid even in curved\nmanifolds. By performing numerical simulations, we compare the discrete\npropagator to its continuum counterpart across various curvature scales. Our\nresults show strong agreement and confirm that the causal set propagator\naccurately captures the effects of curvature without requiring modifications to\nthe flat-space jump amplitudes. These findings affirm the robustness of CST in\napproximating field propagation in curved spacetimes and strongly support the\nability of causal sets to fully capture the geometry of Lorentzian manifolds.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-17T13:08:20Z"}
{"aid":"http://arxiv.org/abs/2504.12931v1","title":"Explainable AI in Usable Privacy and Security: Challenges and\n  Opportunities","summary":"Large Language Models (LLMs) are increasingly being used for automated\nevaluations and explaining them. However, concerns about explanation quality,\nconsistency, and hallucinations remain open research challenges, particularly\nin high-stakes contexts like privacy and security, where user trust and\ndecision-making are at stake. In this paper, we investigate these issues in the\ncontext of PRISMe, an interactive privacy policy assessment tool that leverages\nLLMs to evaluate and explain website privacy policies. Based on a prior user\nstudy with 22 participants, we identify key concerns regarding LLM judgment\ntransparency, consistency, and faithfulness, as well as variations in user\npreferences for explanation detail and engagement. We discuss potential\nstrategies to mitigate these concerns, including structured evaluation\ncriteria, uncertainty estimation, and retrieval-augmented generation (RAG). We\nidentify a need for adaptive explanation strategies tailored to different user\nprofiles for LLM-as-a-judge. Our goal is to showcase the application area of\nusable privacy and security to be promising for Human-Centered Explainable AI\n(HCXAI) to make an impact.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-17T13:28:01Z"}
{"aid":"http://arxiv.org/abs/2504.12945v1","title":"A resource theory of asynchronous quantum information processing","summary":"In standard quantum teleportation, the receiver must wait for a classical\nmessage from the sender before subsequently processing the transmitted quantum\ninformation. However, in port-based teleportation (PBT), this local processing\ncan begin before the classical message is received, thereby allowing for\nasynchronous quantum information processing. Motivated by resource-theoretic\nconsiderations and practical applications, we propose different communication\nmodels that progressively allow for more powerful decoding strategies while\nstill permitting asynchronous distributed quantum computation, a salient\nfeature of standard PBT. Specifically, we consider PBT protocols augmented by\nfree classical processing and/or different forms of quantum pre-processing, and\nwe investigate the maximum achievable teleportation fidelities under such\noperations. Our analysis focuses specifically on the PBT power of isotropic\nstates, bipartite graph states, and symmetrized EPR states, and we compute\ntight bounds on the optimal teleportation fidelities for such states. We\nfinally show that, among this hierarchy of communication models consistent with\nasynchronous quantum information processing, the strongest resource theory is\nequally as powerful as any one-way teleportation protocol for surpassing the\nclassical teleportation threshold. Thus, a bipartite state can break the\none-way classical teleportation threshold if and only if it can be done using\nthe trivial decoding map of discarding subsystems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T13:46:02Z"}
{"aid":"http://arxiv.org/abs/2504.12959v1","title":"Rethinking Temporal Fusion with a Unified Gradient Descent View for 3D\n  Semantic Occupancy Prediction","summary":"We present GDFusion, a temporal fusion method for vision-based 3D semantic\noccupancy prediction (VisionOcc). GDFusion opens up the underexplored aspects\nof temporal fusion within the VisionOcc framework, focusing on both temporal\ncues and fusion strategies. It systematically examines the entire VisionOcc\npipeline, identifying three fundamental yet previously overlooked temporal\ncues: scene-level consistency, motion calibration, and geometric\ncomplementation. These cues capture diverse facets of temporal evolution and\nmake distinct contributions across various modules in the VisionOcc framework.\nTo effectively fuse temporal signals across heterogeneous representations, we\npropose a novel fusion strategy by reinterpreting the formulation of vanilla\nRNNs. This reinterpretation leverages gradient descent on features to unify the\nintegration of diverse temporal information, seamlessly embedding the proposed\ntemporal cues into the network. Extensive experiments on nuScenes demonstrate\nthat GDFusion significantly outperforms established baselines. Notably, on\nOcc3D benchmark, it achieves 1.4\\%-4.8\\% mIoU improvements and reduces memory\nconsumption by 27\\%-72\\%.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T14:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.12968v1","title":"The Quantum Primordial Black Holes, Dimensionless Small Parameter,\n  Inflationary Cosmology and Non-Gaussianity","summary":"In the present work consideration is given to the primordial black holes\n({\\bf pbhs}) in the Schwarzschild-de Sitter Metric with small mass (ultralight)\nin the preinflationary epoch. Within the scope of natural assumptions, it has\nbeen shown that the quantum-gravitational corrections ({\\bf qgcs}) to the\ncharacteristics of such black holes can contribute to all the cosmological\nparameters, shifting them compared with the semiclassical consideration. These\ncontributions are determined by a series expansion in terms of a small\nparameter dependent on the hole mass (radius). For this pattern different cases\nhave been considered (stationary, black hole evaporation...). It has been\ndemonstrated that involvement of ({\\bf qgcs}) leads to a higher probability for\nthe occurrence of such {\\bf pbhs}. Besides, high-energy deformations of\nFriedmann Equations created on the basis of these corrections have been derived\nfor different patterns. In the last section of this work it is introduced a\nstudy into the contributions generated by the above-mentioned {\\bf qgcs} in\ninflationary cosmological perturbations. Besides, it has been shown that\nnon-Gaussianity of these perturbations is higher as compared to the\nsemi-classical pattern.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T14:19:30Z"}
{"aid":"http://arxiv.org/abs/2504.12969v1","title":"Lessons from commissioning of the cryogenic system for the\n  Short-Baseline Neutrino Detector at Fermilab","summary":"Results from commissioning and first year of operations of the cryogenic\nsystem of the Short-Baseline Neutrino Detector (SBND) and its membrane cryostat\ninstalled at the Fermi National Accelerator Laboratory are described. The SBND\ndetector is installed in a 200 m$^3$ membrane cryostat filled with liquid\nargon, which serves both as target and as active media. For the correct\noperation of the detector, the liquid argon must be kept in very stable thermal\nconditions while the contamination of electronegative impurities must be\nconsistently kept at the level of small fractions of parts per billion. The\ndetector is operated in Booster Neutrino Beams (BNB) at Fermilab for the search\nof sterile neutrinos and measurements of neutrino-argon cross sections. The\ncryostat and the cryogenic systems also serve as prototypes for the much larger\nequipment to be used for the LBNF/DUNE experiment. Since its installation in\n2018-2023 and cooldown in spring of 2024, the cryostat and the cryogenic system\nhave been commissioned to support the detector operations. The lessons learned\nthrough installation, testing, commissioning, cooldown, and initial operations\nare described.","main_category":"physics.ins-det","categories":"physics.ins-det,physics.acc-ph","published":"2025-04-17T14:19:34Z"}
{"aid":"http://arxiv.org/abs/2504.12972v1","title":"Estimating Optimal Context Length for Hybrid Retrieval-augmented\n  Multi-document Summarization","summary":"Recent advances in long-context reasoning abilities of language models led to\ninteresting applications in large-scale multi-document summarization. However,\nprior work has shown that these long-context models are not effective at their\nclaimed context windows. To this end, retrieval-augmented systems provide an\nefficient and effective alternative. However, their performance can be highly\nsensitive to the choice of retrieval context length. In this work, we present a\nhybrid method that combines retrieval-augmented systems with long-context\nwindows supported by recent language models. Our method first estimates the\noptimal retrieval length as a function of the retriever, summarizer, and\ndataset. On a randomly sampled subset of the dataset, we use a panel of LLMs to\ngenerate a pool of silver references. We use these silver references to\nestimate the optimal context length for a given RAG system configuration. Our\nresults on the multi-document summarization task showcase the effectiveness of\nour method across model classes and sizes. We compare against length estimates\nfrom strong long-context benchmarks such as RULER and HELMET. Our analysis also\nhighlights the effectiveness of our estimation method for very long-context LMs\nand its generalization to new classes of LMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T14:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.12984v1","title":"A Virtual Machine for Arbitrary Low-Precision GPGPU Computation in LLM\n  Serving","summary":"Serving Large Language Models (LLMs) is critical for AI-powered applications\nbut demands substantial computational resources, particularly in memory\nbandwidth and computational throughput. Low-precision computation has emerged\nas a key technique to improve efficiency while reducing resource consumption.\nExisting approaches for generating low-precision kernels are limited to weight\nbit widths that are powers of two and suffer from suboptimal performance due to\nhigh-level GPU programming abstractions. These abstractions restrict critical\noptimizations, such as fine-grained register management and optimized memory\naccess patterns, which are essential for efficient low-precision computations.\nIn this paper, we introduce a virtual machine (VM) designed for General-Purpose\nGPU (GPGPU) computing, enabling support for low-precision data types with\narbitrary bit widths while maintaining GPU programmability. The proposed VM\nfeatures a thread-block-level programming model, a hierarchical memory space, a\nnovel algebraic layout system, and extensive support for diverse low-precision\ndata types. VM programs are compiled into highly efficient GPU programs with\nautomatic vectorization and instruction selection. Extensive experiments\ndemonstrate that our VM efficiently supports a full spectrum of low-precision\ndata types, and outperforms state-of-the-art low-precision kernels on their\nsupported types. Compared to existing compilers like Triton and Ladder, as well\nas hand-optimized kernels such as QuantLLM and Marlin, our VM achieves\nperformance improvements of 1.75x, 2.61x, 1.29x and 1.03x, respectively.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.PL","published":"2025-04-17T14:45:03Z"}
{"aid":"http://arxiv.org/abs/2504.12999v1","title":"GSAC: Leveraging Gaussian Splatting for Photorealistic Avatar Creation\n  with Unity Integration","summary":"Photorealistic avatars have become essential for immersive applications in\nvirtual reality (VR) and augmented reality (AR), enabling lifelike interactions\nin areas such as training simulations, telemedicine, and virtual collaboration.\nThese avatars bridge the gap between the physical and digital worlds, improving\nthe user experience through realistic human representation. However, existing\navatar creation techniques face significant challenges, including high costs,\nlong creation times, and limited utility in virtual applications. Manual\nmethods, such as MetaHuman, require extensive time and expertise, while\nautomatic approaches, such as NeRF-based pipelines often lack efficiency,\ndetailed facial expression fidelity, and are unable to be rendered at a speed\nsufficent for real-time applications. By involving several cutting-edge modern\ntechniques, we introduce an end-to-end 3D Gaussian Splatting (3DGS) avatar\ncreation pipeline that leverages monocular video input to create a scalable and\nefficient photorealistic avatar directly compatible with the Unity game engine.\nOur pipeline incorporates a novel Gaussian splatting technique with customized\npreprocessing that enables the user of \"in the wild\" monocular video capture,\ndetailed facial expression reconstruction and embedding within a fully rigged\navatar model. Additionally, we present a Unity-integrated Gaussian Splatting\nAvatar Editor, offering a user-friendly environment for VR/AR application\ndevelopment. Experimental results validate the effectiveness of our\npreprocessing pipeline in standardizing custom data for 3DGS training and\ndemonstrate the versatility of Gaussian avatars in Unity, highlighting the\nscalability and practicality of our approach.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T15:10:14Z"}
{"aid":"http://arxiv.org/abs/2504.13007v1","title":"Detecting light dark matter with prompt-delayed events in neutrino\n  experiments","summary":"We demonstrate the prompt-delayed signals induced by knockout neutrons from\nthe quasi-elastic scattering in neutrino experiments provides a new avenue for\ndetecting light dark matter. As an illustration, we consider the detection of\natmospheric dark matter in the liquid scintillator detectors. The results show\nthat the constraint on the DM-nucleon interaction from KamLAND is approximately\none order of magnitude more stringent than those obtained from the elastic\nnuclear recoil signals in dark matter direct detection experiments.\nFurthermore, a larger volume neutrino experiment, such as JUNO, is expected to\nsignificantly enhance the light dark matter detection sensitivity through the\nquasi-elastic scattering.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-17T15:16:06Z"}
{"aid":"http://arxiv.org/abs/2504.13013v1","title":"Minkowski chirality: a measure of reflectional asymmetry of convex\n  bodies","summary":"Using an optimal containment approach, we quantify the asymmetry of convex\nbodies in $\\mathbb{R}^n$ with respect to reflections across affine subspaces of\na given dimension. We prove general inequalities relating these ''Minkowski\nchirality'' measures to Banach--Mazur distances and to each other, and prove\ntheir continuity with respect to the Hausdorff distance. In the planar case, we\ndetermine the reflection axes at which the Minkowski chirality of triangles and\nparallelograms is attained, and show that $\\sqrt{2}$ is a tight upper bound on\nthe chirality in both cases.","main_category":"math.MG","categories":"math.MG","published":"2025-04-17T15:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.13023v1","title":"ChatEXAONEPath: An Expert-level Multimodal Large Language Model for\n  Histopathology Using Whole Slide Images","summary":"Recent studies have made significant progress in developing large language\nmodels (LLMs) in the medical domain, which can answer expert-level questions\nand demonstrate the potential to assist clinicians in real-world clinical\nscenarios. Studies have also witnessed the importance of integrating various\nmodalities with the existing LLMs for a better understanding of complex\nclinical contexts, which are innately multi-faceted by nature. Although studies\nhave demonstrated the ability of multimodal LLMs in histopathology to answer\nquestions from given images, they lack in understanding of thorough clinical\ncontext due to the patch-level data with limited information from public\ndatasets. Thus, developing WSI-level MLLMs is significant in terms of the\nscalability and applicability of MLLMs in histopathology. In this study, we\nintroduce an expert-level MLLM for histopathology using WSIs, dubbed as\nChatEXAONEPath. We present a retrieval-based data generation pipeline using\n10,094 pairs of WSIs and histopathology reports from The Cancer Genome Atlas\n(TCGA). We also showcase an AI-based evaluation protocol for a comprehensive\nunderstanding of the medical context from given multimodal information and\nevaluate generated answers compared to the original histopathology reports. We\ndemonstrate the ability of diagnosing the given histopathology images using\nChatEXAONEPath with the acceptance rate of 62.9% from 1,134 pairs of WSIs and\nreports. Our proposed model can understand pan-cancer WSIs and clinical context\nfrom various cancer types. We argue that our proposed model has the potential\nto assist clinicians by comprehensively understanding complex morphology of\nWSIs for cancer diagnosis through the integration of multiple modalities.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-04-17T15:33:17Z"}
{"aid":"http://arxiv.org/abs/2504.13024v1","title":"Riemannian Patch Assignment Gradient Flows","summary":"This paper introduces patch assignment flows for metric data labeling on\ngraphs. Labelings are determined by regularizing initial local labelings\nthrough the dynamic interaction of both labels and label assignments across the\ngraph, entirely encoded by a dictionary of competing labeled patches and\nmediated by patch assignment variables. Maximal consistency of patch\nassignments is achieved by geometric numerical integration of a Riemannian\nascent flow, as critical point of a Lagrangian action functional. Experiments\nillustrate properties of the approach, including uncertainty quantification of\nlabel assignments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.13025v1","title":"Magnetism-Enhanced Strong Electron-Phonon Coupling in Infinite-Layer\n  Nickelate","summary":"Intriguing analogies between the nickelates and the cuprates provide a\npromising avenue for unraveling the microscopic mechanisms underlying\nhigh-$T_c$ superconductivity. While electron correlation effects in the\nnickelates have been extensively studied, the role of electron-phonon coupling\n(EPC) remains highly controversial. Here, by taking pristine LaNiO$_2$ as an\nexemplar nickelate, we present an in-depth study of EPC for both the\nnon-magnetic (NM) and the $C$-type antiferromagnetic ($C$-AFM) phase using\nadvanced density functional theory methods without invoking $U$ or other free\nparameters. The weak EPC strength $\\lambda$ in the NM phase is found to be\ngreatly enhanced ($\\sim$4$\\times$) due to the presence of magnetism in the\n$C$-AFM phase. This enhancement arises from strong interactions between the\nflat bands associated with the Ni-3$d_{z^2}$ orbitals and the low-frequency\nphonon modes driven by the vibrations of Ni and La atoms. The resulting phonon\nsoftening is shown to yield a distinctive kink in the electronic structure\naround 15 meV, which would provide an experimentally testable signature of our\npredictions. Our study highlights the critical role of local magnetic moments\nand interply EPC in the nickelate.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-17T15:35:10Z"}
{"aid":"http://arxiv.org/abs/2504.13031v1","title":"Degrees of Freedom of Holographic MIMO -- Fundamental Theory and\n  Analytical Methods","summary":"Holographic multiple-input multiple-output (MIMO) is envisioned as one of the\nmost promising technology enablers for future sixth-generation (6G) networks.\nThe use of electrically large holographic surface (HoloS) antennas has the\npotential to significantly boost the spatial multiplexing gain by increasing\nthe number of degrees of freedom (DoF), even in line-of-sight (LoS) channels.\nIn this context, the research community has shown a growing interest in\ncharacterizing the fundamental limits of this technology. In this paper, we\ncompare the two analytical methods commonly utilized in the literature for this\npurpose: the cut-set integral and the self-adjoint operator. We provide a\ndetailed description of both methods and discuss their advantages and\nlimitations.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-17T15:41:28Z"}
{"aid":"http://arxiv.org/abs/2504.13037v1","title":"Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular\n  Representations for Whole-Heart Assessment and Beyond","summary":"Cardiac magnetic resonance imaging is the gold standard for non-invasive\ncardiac assessment, offering rich spatio-temporal views of the cardiac anatomy\nand physiology. Patient-level health factors, such as demographics, metabolic,\nand lifestyle, are known to substantially influence cardiovascular health and\ndisease risk, yet remain uncaptured by CMR alone. To holistically understand\ncardiac health and to enable the best possible interpretation of an\nindividual's disease risk, CMR and patient-level factors must be jointly\nexploited within an integrated framework. Recent multi-modal approaches have\nbegun to bridge this gap, yet they often rely on limited spatio-temporal data\nand focus on isolated clinical tasks, thereby hindering the development of a\ncomprehensive representation for cardiac health evaluation. To overcome these\nlimitations, we introduce ViTa, a step toward foundation models that delivers a\ncomprehensive representation of the heart and a precise interpretation of\nindividual disease risk. Leveraging data from 42,000 UK Biobank participants,\nViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling\na complete capture of the cardiac cycle. These imaging data are then fused with\ndetailed tabular patient-level factors, enabling context-aware insights. This\nmulti-modal paradigm supports a wide spectrum of downstream tasks, including\ncardiac phenotype and physiological feature prediction, segmentation, and\nclassification of cardiac and metabolic diseases within a single unified\nframework. By learning a shared latent representation that bridges rich imaging\nfeatures and patient context, ViTa moves beyond traditional, task-specific\nmodels toward a universal, patient-specific understanding of cardiac health,\nhighlighting its potential to advance clinical utility and scalability in\ncardiac analysis.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-17T15:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.13044v1","title":"The Dissipation Theory of Aging: A Quantitative Analysis Using a\n  Cellular Aging Map","summary":"We propose a new theory for aging based on dynamical systems and provide a\ndata-driven computational method to quantify the changes at the cellular level.\nWe use ergodic theory to decompose the dynamics of changes during aging and\nshow that aging is fundamentally a dissipative process within biological\nsystems, akin to dynamical systems where dissipation occurs due to\nnon-conservative forces. To quantify the dissipation dynamics, we employ a\ntransformer-based machine learning algorithm to analyze gene expression data,\nincorporating age as a token to assess how age-related dissipation is reflected\nin the embedding space. By evaluating the dynamics of gene and age embeddings,\nwe provide a cellular aging map (CAM) and identify patterns indicative of\ndivergence in gene embedding space, nonlinear transitions, and entropy\nvariations during aging for various tissues and cell types. Our results provide\na novel perspective on aging as a dissipative process and introduce a\ncomputational framework that enables measuring age-related changes with\nmolecular resolution.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.LG,physics.bio-ph","published":"2025-04-17T15:59:15Z"}
{"aid":"http://arxiv.org/abs/2504.13046v1","title":"Variance-Reduced Fast Operator Splitting Methods for Stochastic\n  Generalized Equations","summary":"We develop two classes of variance-reduced fast operator splitting methods to\napproximate solutions of both finite-sum and stochastic generalized equations.\nOur approach integrates recent advances in accelerated fixed-point methods,\nco-hypomonotonicity, and variance reduction. First, we introduce a class of\nvariance-reduced estimators and establish their variance-reduction bounds. This\nclass covers both unbiased and biased instances and comprises common estimators\nas special cases, including SVRG, SAGA, SARAH, and Hybrid-SGD. Next, we design\na novel accelerated variance-reduced forward-backward splitting (FBS) algorithm\nusing these estimators to solve finite-sum and stochastic generalized\nequations. Our method achieves both $\\mathcal{O}(1/k^2)$ and $o(1/k^2)$\nconvergence rates on the expected squared norm $\\mathbb{E}[ \\|\nG_{\\lambda}x^k\\|^2]$ of the FBS residual $G_{\\lambda}$, where $k$ is the\niteration counter. Additionally, we establish, for the first time, almost sure\nconvergence rates and almost sure convergence of iterates to a solution in\nstochastic accelerated methods. Unlike existing stochastic fixed-point\nalgorithms, our methods accommodate co-hypomonotone operators, which\npotentially include nonmonotone problems arising from recent applications. We\nfurther specify our method to derive an appropriate variant for each stochastic\nestimator -- SVRG, SAGA, SARAH, and Hybrid-SGD -- demonstrating that they\nachieve the best-known complexity for each without relying on enhancement\ntechniques. Alternatively, we propose an accelerated variance-reduced\nbackward-forward splitting (BFS) method, which attains similar convergence\nrates and oracle complexity as our FBS method. Finally, we validate our results\nthrough several numerical experiments and compare their performance.","main_category":"math.OC","categories":"math.OC,stat.ML","published":"2025-04-17T16:02:20Z"}
{"aid":"http://arxiv.org/abs/2504.13058v1","title":"Neurodiversity in Computing Education Research: A Systematic Literature\n  Review","summary":"Ensuring equitable access to computing education for all students-including\nthose with autism, dyslexia, or ADHD-is essential to developing a diverse and\ninclusive workforce. To understand the state of disability research in\ncomputing education, we conducted a systematic literature review of research on\nneurodiversity in computing education. Our search resulted in 1,943 total\npapers, which we filtered to 14 papers based on our inclusion criteria. Our\nmixed-methods approach analyzed research methods, participants, contribution\ntypes, and findings. The three main contribution types included empirical\ncontributions based on user studies (57.1%), opinion contributions and position\npapers (50%), and survey contributions (21.4%). Interviews were the most common\nmethodology (75% of empirical contributions). There were often inconsistencies\nin how research methods were described (e.g., number of participants and\ninterview and survey materials). Our work shows that research on\nneurodivergence in computing education is still very preliminary. Most papers\nprovided curricular recommendations that lacked empirical evidence to support\nthose recommendations. Three areas of future work include investigating the\nimpacts of active learning, increasing awareness and knowledge about\nneurodiverse students' experiences, and engaging neurodivergent students in the\ndesign of pedagogical materials and computing education research.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-17T16:13:31Z"}
{"aid":"http://arxiv.org/abs/2504.13062v1","title":"Seeing Beyond Dark-Field RGB Capabilities: Deep Spectral Extrapolation\n  of Ultrasmall Plasmonic Nanogaps","summary":"Localized surface plasmons can confine light within a deep-subwavelength\nvolume comparable to the scale of atoms and molecules, enabling ultrasensitive\nresponses to near-field variations. On the other hand, this extreme\nlocalization also inevitably amplifies the unwanted noise from the response of\nlocal morphological imperfections, leading to complex spectral variations and\nreduced consistency across the plasmonic nanostructures. Seeking uniform\noptical responses has therefore long been a sought-after goal in\nnanoplasmonics. However, conventional probing techniques by dark-field (DF)\nconfocal microscopy, such as image analysis or spectral measurements, can be\ninaccurate and time-consuming, respectively. Here, we introduce SPARX, a\ndeep-learning-powered paradigm that surpasses conventional imaging and\nspectroscopic capabilities. In particular, SPARX can batch-predict broadband DF\nspectra (e.g., 500-1000 nm) of numerous nanoparticles simultaneously from an\ninformation-limited RGB image (i.e., below 700 nm). It achieves this\nextrapolative inference beyond the camera's capture capabilities by learning\nthe underlying physical relationships among multiple orders of optical\nresonances. The spectral predictions only take milliseconds, achieving a\nspeedup of three to four orders of magnitude compared to traditional spectral\nacquisition, which may take from hours to days. As a proof-of-principle\ndemonstration for screening identical resonances, the selection accuracy\nachieved by SPARX is comparable to that of conventional spectroscopy\ntechniques. This breakthrough paves the way for consistent plasmonic\napplications and next-generation microscopies.","main_category":"physics.optics","categories":"physics.optics,cond-mat.dis-nn,cond-mat.mes-hall","published":"2025-04-17T16:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.13064v1","title":"Minimal isometric immersions of flat n-tori into spheres","summary":"In 1985, Bryant stated that a flat $2$-torus admits a minimal isometric\nimmersion into some round sphere if and only if it satisfies a certain\nrationality condition. We extend this rationality criterion to arbitrary\ndimensional flat tori, providing a sufficient condition for minimal isometric\nimmersions of flat $n$-tori. For the case $n=3$, we prove that if a flat\n$3$-torus admits a minimal isometric immersion into some sphere, then its\nalgebraic irrationality degree must be no more than 4, and we construct\nexplicit embedded minimal irrational flat $3$-tori realizing each possible\ndegree. Furthermore, we establish the upper bound $n^2+n-1$ for the minimal\ntarget dimension of flat $n$-tori admitting minimal isometric immersions into\nspheres.","main_category":"math.DG","categories":"math.DG","published":"2025-04-17T16:18:58Z"}
{"aid":"http://arxiv.org/abs/2504.13076v1","title":"Extremal Lagrangian tori in toric domains","summary":"Let $L$ be a closed Lagrangian submanifold of a symplectic manifold\n$(X,\\omega)$. Cieliebak and Mohnke define the symplectic area of $L$ as the\nminimal positive symplectic area of a smooth $2$-disk in $X$ with boundary on\n$L$. An extremal Lagrangian torus in $(X,\\omega)$ is a Lagrangian torus that\nmaximizes the symplectic area among the Lagrangian tori in $(X,\\omega)$. We\nprove that every extremal Lagrangian torus in the symplectic unit ball\n$(\\bar{B}^{2n}(1),\\omega_{\\mathrm{std}})$ is contained entirely in the boundary\n$\\partial B^{2n}(1)$. This answers a question attributed to Lazzarini and\ncompletely settles a conjecture of Cieliebak and Mohnke in the affirmative. In\naddition, we prove the conjecture for a class of toric domains in\n$(\\mathbb{C}^n, \\omega_{\\mathrm{std}})$, which includes all compact strictly\nconvex four-dimensional toric domains. We explain with counterexamples that the\ngeneral conjecture does not hold for non-convex domains.","main_category":"math.SG","categories":"math.SG,math.DG","published":"2025-04-17T16:39:04Z"}
{"aid":"http://arxiv.org/abs/2504.13077v1","title":"Effective Dual-Region Augmentation for Reduced Reliance on Large Amounts\n  of Labeled Data","summary":"This paper introduces a novel dual-region augmentation approach designed to\nreduce reliance on large-scale labeled datasets while improving model\nrobustness and adaptability across diverse computer vision tasks, including\nsource-free domain adaptation (SFDA) and person re-identification (ReID). Our\nmethod performs targeted data transformations by applying random noise\nperturbations to foreground objects and spatially shuffling background patches.\nThis effectively increases the diversity of the training data, improving model\nrobustness and generalization. Evaluations on the PACS dataset for SFDA\ndemonstrate that our augmentation strategy consistently outperforms existing\nmethods, achieving significant accuracy improvements in both single-target and\nmulti-target adaptation settings. By augmenting training data through\nstructured transformations, our method enables model generalization across\ndomains, providing a scalable solution for reducing reliance on manually\nannotated datasets. Furthermore, experiments on Market-1501 and DukeMTMC-reID\ndatasets validate the effectiveness of our approach for person ReID, surpassing\ntraditional augmentation techniques.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T16:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.13085v1","title":"Tackling Social Bias against the Poor: A Dataset and Taxonomy on\n  Aporophobia","summary":"Eradicating poverty is the first goal in the United Nations Sustainable\nDevelopment Goals. However, aporophobia -- the societal bias against people\nliving in poverty -- constitutes a major obstacle to designing, approving and\nimplementing poverty-mitigation policies. This work presents an initial step\ntowards operationalizing the concept of aporophobia to identify and track\nharmful beliefs and discriminative actions against poor people on social media.\nIn close collaboration with non-profits and governmental organizations, we\nconduct data collection and exploration. Then we manually annotate a corpus of\nEnglish tweets from five world regions for the presence of (1) direct\nexpressions of aporophobia, and (2) statements referring to or criticizing\naporophobic views or actions of others, to comprehensively characterize the\nsocial media discourse related to bias and discrimination against the poor.\nBased on the annotated data, we devise a taxonomy of categories of aporophobic\nattitudes and actions expressed through speech on social media. Finally, we\ntrain several classifiers and identify the main challenges for automatic\ndetection of aporophobia in social networks. This work paves the way towards\nidentifying, tracking, and mitigating aporophobic views on social media at\nscale.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-04-17T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.13087v1","title":"The $h$-vectors of toric ideals of odd cycle compositions revisited","summary":"Let $G$ be a graph consisting of $s$ odd cycles that all share a common\nvertex. Bhaskara, Higashitani, and Shibu Deepthi recently computed the\n$h$-polynomial for the quotient ring $R/I_G$, where $I_G$ is the toric ideal of\n$G$, in terms of the number and sizes of odd cycles in the graph. The purpose\nof this note is to prove the stronger result that these toric ideals are\ngeometrically vertex decomposable, which allows us to deduce the result of\nBhaskara, Higashitani, and Shibu Deepthi about the $h$-polyhomial as a\ncorollary.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-17T16:55:17Z"}
{"aid":"http://arxiv.org/abs/2504.13094v1","title":"Symmetry classification and invariant solutions of the classical\n  geometric mean reversion process","summary":"Based on the Lie symmetry method, we investigate a Feynman-Kac formula for\nthe classical geometric mean reversion process, which effectively describing\nthe dynamics of short-term interest rates. The Lie algebra of infinitesimal\nsymmetries and the corresponding one-parameter symmetry groups of the equation\nare obtained. An optimal system of invariant solutions are constructed by a\nderived optimal system of one-dimensional subalgebras. Because of taking into\naccount a supply response to price rises, this equation provides for a more\nrealistic assumption than the geometric Brownian motion in many investment\nscenarios.","main_category":"math.DS","categories":"math.DS,math.AP,math.PR,q-fin.MF","published":"2025-04-17T16:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.13095v1","title":"Should We Tailor the Talk? Understanding the Impact of Conversational\n  Styles on Preference Elicitation in Conversational Recommender Systems","summary":"Conversational recommender systems (CRSs) provide users with an interactive\nmeans to express preferences and receive real-time personalized\nrecommendations. The success of these systems is heavily influenced by the\npreference elicitation process. While existing research mainly focuses on what\nquestions to ask during preference elicitation, there is a notable gap in\nunderstanding what role broader interaction patterns including tone, pacing,\nand level of proactiveness play in supporting users in completing a given task.\nThis study investigates the impact of different conversational styles on\npreference elicitation, task performance, and user satisfaction with CRSs. We\nconducted a controlled experiment in the context of scientific literature\nrecommendation, contrasting two distinct conversational styles, high\ninvolvement (fast paced, direct, and proactive with frequent prompts) and high\nconsiderateness (polite and accommodating, prioritizing clarity and user\ncomfort) alongside a flexible experimental condition where users could switch\nbetween the two. Our results indicate that adapting conversational strategies\nbased on user expertise and allowing flexibility between styles can enhance\nboth user satisfaction and the effectiveness of recommendations in CRSs.\nOverall, our findings hold important implications for the design of future\nCRSs.","main_category":"cs.HC","categories":"cs.HC,cs.IR","published":"2025-04-17T17:01:17Z"}
{"aid":"http://arxiv.org/abs/2504.13099v1","title":"RF-DETR Object Detection vs YOLOv12 : A Study of Transformer-based and\n  CNN-based Architectures for Single-Class and Multi-Class Greenfruit Detection\n  in Complex Orchard Environments Under Label Ambiguity","summary":"This study conducts a detailed comparison of RF-DETR object detection base\nmodel and YOLOv12 object detection model configurations for detecting\ngreenfruits in a complex orchard environment marked by label ambiguity,\nocclusions, and background blending. A custom dataset was developed featuring\nboth single-class (greenfruit) and multi-class (occluded and non-occluded\ngreenfruits) annotations to assess model performance under dynamic real-world\nconditions. RF-DETR object detection model, utilizing a DINOv2 backbone and\ndeformable attention, excelled in global context modeling, effectively\nidentifying partially occluded or ambiguous greenfruits. In contrast, YOLOv12\nleveraged CNN-based attention for enhanced local feature extraction, optimizing\nit for computational efficiency and edge deployment. RF-DETR achieved the\nhighest mean Average Precision (mAP50) of 0.9464 in single-class detection,\nproving its superior ability to localize greenfruits in cluttered scenes.\nAlthough YOLOv12N recorded the highest mAP@50:95 of 0.7620, RF-DETR\nconsistently outperformed in complex spatial scenarios. For multi-class\ndetection, RF-DETR led with an mAP@50 of 0.8298, showing its capability to\ndifferentiate between occluded and non-occluded fruits, while YOLOv12L scored\nhighest in mAP@50:95 with 0.6622, indicating better classification in detailed\nocclusion contexts. Training dynamics analysis highlighted RF-DETR's swift\nconvergence, particularly in single-class settings where it plateaued within 10\nepochs, demonstrating the efficiency of transformer-based architectures in\nadapting to dynamic visual data. These findings validate RF-DETR's\neffectiveness for precision agricultural applications, with YOLOv12 suited for\nfast-response scenarios. >Index Terms: RF-DETR object detection, YOLOv12,\nYOLOv13, YOLOv14, YOLOv15, YOLOE, YOLO World, YOLO, You Only Look Once,\nRoboflow, Detection Transformers, CNNs","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:08:11Z"}
{"aid":"http://arxiv.org/abs/2504.13112v1","title":"Hadamard product in deep learning: Introduction, Advances and Challenges","summary":"While convolution and self-attention mechanisms have dominated architectural\ndesign in deep learning, this survey examines a fundamental yet understudied\nprimitive: the Hadamard product. Despite its widespread implementation across\nvarious applications, the Hadamard product has not been systematically analyzed\nas a core architectural primitive. We present the first comprehensive taxonomy\nof its applications in deep learning, identifying four principal domains:\nhigher-order correlation, multimodal data fusion, dynamic representation\nmodulation, and efficient pairwise operations. The Hadamard product's ability\nto model nonlinear interactions with linear computational complexity makes it\nparticularly valuable for resource-constrained deployments and edge computing\nscenarios. We demonstrate its natural applicability in multimodal fusion tasks,\nsuch as visual question answering, and its effectiveness in representation\nmasking for applications including image inpainting and pruning. This\nsystematic review not only consolidates existing knowledge about the Hadamard\nproduct's role in deep learning architectures but also establishes a foundation\nfor future architectural innovations. Our analysis reveals the Hadamard product\nas a versatile primitive that offers compelling trade-offs between\ncomputational efficiency and representational power, positioning it as a\ncrucial component in the deep learning toolkit.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T17:26:29Z"}
{"aid":"http://arxiv.org/abs/2504.13114v1","title":"Supersymmetric Poisson and Poisson-supersymmetric sigma models","summary":"We revisit and construct new examples of supersymmetric 2D topological sigma\nmodels whose target space is a Poisson supermanifold. Inspired by the AKSZ\nconstruction of topological field theories, we follow a graded-geometric\napproach and identify two commuting homological vector fields compatible with\nthe graded symplectic structure, which control the gauge symmetries and the\nsupersymmetries of the sigma models. Exemplifying the general structure, we\nshow that two distinguished cases exist, one being the differential Poisson\nsigma model constructed before by Arias, Boulanger, Sundell and Torres-Gomez\nand the other a contravariant differential Poisson sigma model. The new model\nfeatures nonlinear supersymmetry transformations that are generated by the\nPoisson structure on the body of the target supermanifold, giving rise to a\nPoisson supersymmetry. Further examples are characterised by supersymmetry\ntransformations controlled by the anchor map of a Lie algebroid, when this map\nis invertible, in which case we determine the geometric conditions for\ninvariance under supersymmetry and closure of the supersymmetry algebra.\nMoreover, we show that the common thread through this type of models is that\ntheir supersymmetry-generating vector field is the coadjoint representation up\nto homotopy of a Lie algebroid.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-17T17:29:22Z"}
{"aid":"http://arxiv.org/abs/2504.13131v1","title":"NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and\n  Enhancement: Methods and Results","summary":"This paper presents a review for the NTIRE 2025 Challenge on Short-form UGC\nVideo Quality Assessment and Enhancement. The challenge comprises two tracks:\n(i) Efficient Video Quality Assessment (KVQ), and (ii) Diffusion-based Image\nSuper-Resolution (KwaiSR). Track 1 aims to advance the development of\nlightweight and efficient video quality assessment (VQA) models, with an\nemphasis on eliminating reliance on model ensembles, redundant weights, and\nother computationally expensive components in the previous IQA/VQA\ncompetitions. Track 2 introduces a new short-form UGC dataset tailored for\nsingle image super-resolution, i.e., the KwaiSR dataset. It consists of 1,800\nsynthetically generated S-UGC image pairs and 1,900 real-world S-UGC images,\nwhich are split into training, validation, and test sets using a ratio of\n8:1:1. The primary objective of the challenge is to drive research that\nbenefits the user experience of short-form UGC platforms such as Kwai and\nTikTok. This challenge attracted 266 participants and received 18 valid final\nsubmissions with corresponding fact sheets, significantly contributing to the\nprogress of short-form UGC VQA and image superresolution. The project is\npublicly available at https://github.com/lixinustc/KVQE-\nChallengeCVPR-NTIRE2025.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-17T17:45:34Z"}
{"aid":"http://arxiv.org/abs/2504.13144v1","title":"Bayesian model-data comparison incorporating theoretical uncertainties","summary":"Accurate comparisons between theoretical models and experimental data are\ncritical for scientific progress. However, inferred model parameters can vary\nsignificantly with the chosen physics model, highlighting the importance of\nproperly accounting for theoretical uncertainties. In this article, we\nexplicitly incorporate these uncertainties using Gaussian processes that model\nthe domain of validity of theoretical models, integrating prior knowledge about\nwhere a theory applies and where it does not. We demonstrate the effectiveness\nof this approach using two systems: a simple ball drop experiment and\nmulti-stage heavy-ion simulations. In both cases incorporating model\ndiscrepancy leads to improved parameter estimates, with systematic improvements\nobserved as additional experimental observables are integrated.","main_category":"hep-ph","categories":"hep-ph,nucl-th,physics.data-an","published":"2025-04-17T17:53:39Z"}
{"aid":"http://arxiv.org/abs/2504.13150v1","title":"Readable Twins of Unreadable Models","summary":"Creating responsible artificial intelligence (AI) systems is an important\nissue in contemporary research and development of works on AI. One of the\ncharacteristics of responsible AI systems is their explainability. In the\npaper, we are interested in explainable deep learning (XDL) systems. On the\nbasis of the creation of digital twins of physical objects, we introduce the\nidea of creating readable twins (in the form of imprecise information flow\nmodels) for unreadable deep learning models. The complete procedure for\nswitching from the deep learning model (DLM) to the imprecise information flow\nmodel (IIFM) is presented. The proposed approach is illustrated with an example\nof a deep learning classification model for image recognition of handwritten\ndigits from the MNIST data set.","main_category":"cs.AI","categories":"cs.AI,cs.CV","published":"2025-04-17T17:55:34Z"}
{"aid":"http://arxiv.org/abs/2504.13152v1","title":"St4RTrack: Simultaneous 4D Reconstruction and Tracking in the World","summary":"Dynamic 3D reconstruction and point tracking in videos are typically treated\nas separate tasks, despite their deep connection. We propose St4RTrack, a\nfeed-forward framework that simultaneously reconstructs and tracks dynamic\nvideo content in a world coordinate frame from RGB inputs. This is achieved by\npredicting two appropriately defined pointmaps for a pair of frames captured at\ndifferent moments. Specifically, we predict both pointmaps at the same moment,\nin the same world, capturing both static and dynamic scene geometry while\nmaintaining 3D correspondences. Chaining these predictions through the video\nsequence with respect to a reference frame naturally computes long-range\ncorrespondences, effectively combining 3D reconstruction with 3D tracking.\nUnlike prior methods that rely heavily on 4D ground truth supervision, we\nemploy a novel adaptation scheme based on a reprojection loss. We establish a\nnew extensive benchmark for world-frame reconstruction and tracking,\ndemonstrating the effectiveness and efficiency of our unified, data-driven\nframework. Our code, model, and benchmark will be released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:55:58Z"}
{"aid":"http://arxiv.org/abs/2504.13155v1","title":"Compact Kähler manifolds with partially semi-positive curvature","summary":"In this paper, we establish a structure theorem for a compact K\\\"{a}hler\nmanifold $X$ of rational dimension $\\mathrm{rd}(X)\\leq n-k$ under the mixed\npartially semi-positive curvature condition $\\mathcal{S}_{a,b,k} \\geq 0$, which\nis introduced as a unified framework for addressing two partially semi-positive\ncurvature conditions -- namely, $k$-semi-positive Ricci curvature and\nsemi-positive $k$-scalar curvature. As a main corollary, we show that a compact\nK\\\"{a}hler manifold $(X,g)$ with $k$-semi-positive Ricci curvature and\n$\\mathrm{rd}(X)\\leq n-k$ actually has semi-positive Ricci curvature and\n$\\mathrm{rd}(X)\\geq \\nu(-K_X)$. Of independent interest, we also confirm the\nrational connectedness of compact K\\\"{a}hler manifolds with positive orthogonal\nRicci curvature, among other results.","main_category":"math.DG","categories":"math.DG,math.AG,math.CV","published":"2025-04-17T17:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.13167v1","title":"ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from\n  Monocular Videos","summary":"Creating a photorealistic scene and human reconstruction from a single\nmonocular in-the-wild video figures prominently in the perception of a\nhuman-centric 3D world. Recent neural rendering advances have enabled holistic\nhuman-scene reconstruction but require pre-calibrated camera and human poses,\nand days of training time. In this work, we introduce a novel unified framework\nthat simultaneously performs camera tracking, human pose estimation and\nhuman-scene reconstruction in an online fashion. 3D Gaussian Splatting is\nutilized to learn Gaussian primitives for humans and scenes efficiently, and\nreconstruction-based camera tracking and human pose estimation modules are\ndesigned to enable holistic understanding and effective disentanglement of pose\nand appearance. Specifically, we design a human deformation module to\nreconstruct the details and enhance generalizability to out-of-distribution\nposes faithfully. Aiming to learn the spatial correlation between human and\nscene accurately, we introduce occlusion-aware human silhouette rendering and\nmonocular geometric priors, which further improve reconstruction quality.\nExperiments on the EMDB and NeuMan datasets demonstrate superior or on-par\nperformance with existing methods in camera tracking, human pose estimation,\nnovel view synthesis and runtime. Our project page is at\nhttps://eth-ait.github.io/ODHSR.","main_category":"cs.CV","categories":"cs.CV,I.4.5","published":"2025-04-17T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.14862v1","title":"FERMI: Flexible Radio Mapping with a Hybrid Propagation Model and\n  Scalable Autonomous Data Collection","summary":"Communication is fundamental for multi-robot collaboration, with accurate\nradio mapping playing a crucial role in predicting signal strength between\nrobots. However, modeling radio signal propagation in large and occluded\nenvironments is challenging due to complex interactions between signals and\nobstacles. Existing methods face two key limitations: they struggle to predict\nsignal strength for transmitter-receiver pairs not present in the training set,\nwhile also requiring extensive manual data collection for modeling, making them\nimpractical for large, obstacle-rich scenarios. To overcome these limitations,\nwe propose FERMI, a flexible radio mapping framework. FERMI combines\nphysics-based modeling of direct signal paths with a neural network to capture\nenvironmental interactions with radio signals. This hybrid model learns radio\nsignal propagation more efficiently, requiring only sparse training data.\nAdditionally, FERMI introduces a scalable planning method for autonomous data\ncollection using a multi-robot team. By increasing parallelism in data\ncollection and minimizing robot travel costs between regions, overall data\ncollection efficiency is significantly improved. Experiments in both simulation\nand real-world scenarios demonstrate that FERMI enables accurate signal\nprediction and generalizes well to unseen positions in complex environments. It\nalso supports fully autonomous data collection and scales to different team\nsizes, offering a flexible solution for creating radio maps. Our code is\nopen-sourced at https://github.com/ymLuo1214/Flexible-Radio-Mapping.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T05:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.14868v1","title":"Twin Co-Adaptive Dialogue for Progressive Image Generation","summary":"Modern text-to-image generation systems have enabled the creation of\nremarkably realistic and high-quality visuals, yet they often falter when\nhandling the inherent ambiguities in user prompts. In this work, we present\nTwin-Co, a framework that leverages synchronized, co-adaptive dialogue to\nprogressively refine image generation. Instead of a static generation process,\nTwin-Co employs a dynamic, iterative workflow where an intelligent dialogue\nagent continuously interacts with the user. Initially, a base image is\ngenerated from the user's prompt. Then, through a series of synchronized\ndialogue exchanges, the system adapts and optimizes the image according to\nevolving user feedback. The co-adaptive process allows the system to\nprogressively narrow down ambiguities and better align with user intent.\nExperiments demonstrate that Twin-Co not only enhances user experience by\nreducing trial-and-error iterations but also improves the quality of the\ngenerated images, streamlining the creative process across various\napplications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T05:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.14876v1","title":"Initiation Route of Coronal Mass Ejections: II. The Role of Filament\n  Mass","summary":"The thorough understanding on the initiation of coronal mass ejections\n(CMEs), which is manifested as a slow rise of pre-eruptive structures before\nthe impulsive ejection in kinematics, is the key for forecasting the solar\neruptions. In our previous work, we showed that the slow rise of a hot flux\nrope with coronal mass density is caused by the moderate magnetic reconnection\noccurring in the hyperbolic flux tube (HFT) combined with the torus\ninstability. However, it remains unclear how the initiation process varies when\na filament is present in the pre-eruptive flux rope. In this work, we reveal\nthe complete initiation route of a CME containing filament mass with a\nstate-of-the-art full-magnetohydrodynamics simulation. The comprehensive\nanalyses show that the filament mass has an important impact on the CME\ninitiation through triggering and driving the slow rise of flux rope with its\ndrainage, besides the contributions of HFT reconnection and torus instability.\nFinally, in combination with our previous work, we propose that the enhanced\ndrainage of filament mass and various features related to the HFT reconnection,\nsuch as, the split of pre-eruptive structure and the pre-flare loops and X-ray\nemissions, can serve as the precursors of CME initiation in observations.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T06:06:24Z"}
{"aid":"http://arxiv.org/abs/2504.14883v1","title":"Shock waves in classical dust collapse","summary":"During gravitational collapse of dust in spherical symmetry, matter particles\nmay collide forming shell crossing surfaces (SCS) on which the Einstein\nequations become indeterministic. We show that there is a unique evolution\nbeyond SCS such that a propagating shock wave forms, the metric remains\ncontinuous, and the stress-energy tensor dynamically becomes that of a thin\nshell. We give numerical simulations that exhibit this result.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-21T06:23:12Z"}
{"aid":"http://arxiv.org/abs/2504.14884v1","title":"Memory-Augmented Dual-Decoder Networks for Multi-Class Unsupervised\n  Anomaly Detection","summary":"Recent advances in unsupervised anomaly detection (UAD) have shifted from\nsingle-class to multi-class scenarios. In such complex contexts, the increasing\npattern diversity has brought two challenges to reconstruction-based\napproaches: (1) over-generalization: anomalies that are subtle or share\ncompositional similarities with normal patterns may be reconstructed with high\nfidelity, making them difficult to distinguish from normal instances; and (2)\ninsufficient normality reconstruction: complex normal features, such as\nintricate textures or fine-grained structures, may not be faithfully\nreconstructed due to the model's limited representational capacity, resulting\nin false positives. Existing methods typically focus on addressing the former,\nwhich unintentionally exacerbate the latter, resulting in inadequate\nrepresentation of intricate normal patterns. To concurrently address these two\nchallenges, we propose a Memory-augmented Dual-Decoder Networks (MDD-Net). This\nnetwork includes two critical components: a Dual-Decoder Reverse Distillation\nNetwork (DRD-Net) and a Class-aware Memory Module (CMM). Specifically, the\nDRD-Net incorporates a restoration decoder designed to recover normal features\nfrom synthetic abnormal inputs and an identity decoder to reconstruct features\nthat maintain the anomalous semantics. By exploiting the discrepancy between\nfeatures produced by two decoders, our approach refines anomaly scores beyond\nthe conventional encoder-decoder comparison paradigm, effectively reducing\nfalse positives and enhancing localization accuracy. Furthermore, the CMM\nexplicitly encodes and preserves class-specific normal prototypes, actively\nsteering the network away from anomaly reconstruction. Comprehensive\nexperimental results across several benchmarks demonstrate the superior\nperformance of our MDD-Net framework over current SoTA approaches in\nmulti-class UAD tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T06:29:04Z"}
{"aid":"http://arxiv.org/abs/2504.14887v1","title":"Quantitative Analysis of Cell Membrane Tension in Time-Series Imaging\n  and A Minimal Lattice Model of Single Cell Motion","summary":"Cell membrane tension directly influences various cellular functions. In this\nstudy, we developed a method to estimate surface tension from time-series data.\nWe obtained the curvature-velocity relationship from time-series of binarized\ncell shape images, and the effective surface tension term was calculated from\nlinear regression.\n  During the process, we observed an S-shaped pattern in the curvature-velocity\nrelationship. To understand the dynamics, we constructed a minimal lattice\nmodel describing single-cell motion. The model consists of surface tension and\nprotrusion formation, and the characteristic parameters are obtained from\nexperimental observations. We found that similar patterns emerged in the\ncurvature-velocity relationship.","main_category":"q-bio.CB","categories":"q-bio.CB","published":"2025-04-21T06:30:29Z"}
{"aid":"http://arxiv.org/abs/2504.14894v1","title":"Never too Cocky to Cooperate: An FIM and RL-based USV-AUV Collaborative\n  System for Underwater Tasks in Extreme Sea Conditions","summary":"This paper develops a novel unmanned surface vehicle (USV)-autonomous\nunderwater vehicle (AUV) collaborative system designed to enhance underwater\ntask performance in extreme sea conditions. The system integrates a dual\nstrategy: (1) high-precision multi-AUV localization enabled by Fisher\ninformation matrix-optimized USV path planning, and (2) reinforcement\nlearning-based cooperative planning and control method for multi-AUV task\nexecution. Extensive experimental evaluations in the underwater data collection\ntask demonstrate the system's operational feasibility, with quantitative\nresults showing significant performance improvements over baseline methods. The\nproposed system exhibits robust coordination capabilities between USV and AUVs\nwhile maintaining stability in extreme sea conditions. To facilitate\nreproducibility and community advancement, we provide an open-source simulation\ntoolkit available at: https://github.com/360ZMEM/USV-AUV-colab .","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-21T06:47:46Z"}
{"aid":"http://arxiv.org/abs/2504.14904v1","title":"VLM as Policy: Common-Law Content Moderation Framework for Short Video\n  Platform","summary":"Exponentially growing short video platforms (SVPs) face significant\nchallenges in moderating content detrimental to users' mental health,\nparticularly for minors. The dissemination of such content on SVPs can lead to\ncatastrophic societal consequences. Although substantial efforts have been\ndedicated to moderating such content, existing methods suffer from critical\nlimitations: (1) Manual review is prone to human bias and incurs high\noperational costs. (2) Automated methods, though efficient, lack nuanced\ncontent understanding, resulting in lower accuracy. (3) Industrial moderation\nregulations struggle to adapt to rapidly evolving trends due to long update\ncycles. In this paper, we annotate the first SVP content moderation benchmark\nwith authentic user/reviewer feedback to fill the absence of benchmark in this\nfield. Then we evaluate various methods on the benchmark to verify the\nexistence of the aforementioned limitations. We further propose our common-law\ncontent moderation framework named KuaiMod to address these challenges. KuaiMod\nconsists of three components: training data construction, offline adaptation,\nand online deployment & refinement. Leveraging large vision language model\n(VLM) and Chain-of-Thought (CoT) reasoning, KuaiMod adequately models video\ntoxicity based on sparse user feedback and fosters dynamic moderation policy\nwith rapid update speed and high accuracy. Offline experiments and large-scale\nonline A/B test demonstrates the superiority of KuaiMod: KuaiMod achieves the\nbest moderation performance on our benchmark. The deployment of KuaiMod reduces\nthe user reporting rate by 20% and its application in video recommendation\nincreases both Daily Active User (DAU) and APP Usage Time (AUT) on several\nKuaishou scenarios. We have open-sourced our benchmark at\nhttps://kuaimod.github.io.","main_category":"cs.SI","categories":"cs.SI,cs.AI,cs.CL,cs.MM","published":"2025-04-21T07:20:19Z"}
{"aid":"http://arxiv.org/abs/2504.14906v1","title":"OmniAudio: Generating Spatial Audio from 360-Degree Video","summary":"Traditional video-to-audio generation techniques primarily focus on\nfield-of-view (FoV) video and non-spatial audio, often missing the spatial cues\nnecessary for accurately representing sound sources in 3D environments. To\naddress this limitation, we introduce a novel task, 360V2SA, to generate\nspatial audio from 360-degree videos, specifically producing First-order\nAmbisonics (FOA) audio - a standard format for representing 3D spatial audio\nthat captures sound directionality and enables realistic 3D audio reproduction.\nWe first create Sphere360, a novel dataset tailored for this task that is\ncurated from real-world data. We also design an efficient semi-automated\npipeline for collecting and cleaning paired video-audio data. To generate\nspatial audio from 360-degree video, we propose a novel framework OmniAudio,\nwhich leverages self-supervised pre-training using both spatial audio data (in\nFOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a\ndual-branch framework that utilizes both panoramic and FoV video inputs to\ncapture comprehensive local and global information from 360-degree videos.\nExperimental results demonstrate that OmniAudio achieves state-of-the-art\nperformance across both objective and subjective metrics on Sphere360. Code and\ndatasets will be released at https://github.com/liuhuadai/OmniAudio. The demo\npage is available at https://OmniAudio-360V2SA.github.io.","main_category":"eess.AS","categories":"eess.AS,cs.CV,cs.SD","published":"2025-04-21T07:21:28Z"}
{"aid":"http://arxiv.org/abs/2504.14917v1","title":"POLYRAG: Integrating Polyviews into Retrieval-Augmented Generation for\n  Medical Applications","summary":"Large language models (LLMs) have become a disruptive force in the industry,\nintroducing unprecedented capabilities in natural language processing, logical\nreasoning and so on. However, the challenges of knowledge updates and\nhallucination issues have limited the application of LLMs in medical scenarios,\nwhere retrieval-augmented generation (RAG) can offer significant assistance.\nNevertheless, existing retrieve-then-read approaches generally digest the\nretrieved documents, without considering the timeliness, authoritativeness and\ncommonality of retrieval. We argue that these approaches can be suboptimal,\nespecially in real-world applications where information from different sources\nmight conflict with each other and even information from the same source in\ndifferent time scale might be different, and totally relying on this would\ndeteriorate the performance of RAG approaches. We propose PolyRAG that\ncarefully incorporate judges from different perspectives and finally integrate\nthe polyviews for retrieval augmented generation in medical applications. Due\nto the scarcity of real-world benchmarks for evaluation, to bridge the gap we\npropose PolyEVAL, a benchmark consists of queries and documents collected from\nreal-world medical scenarios (including medical policy, hospital & doctor\ninquiry and healthcare) with multiple tagging (e.g., timeliness,\nauthoritativeness) on them. Extensive experiments and analysis on PolyEVAL have\ndemonstrated the superiority of PolyRAG.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T07:35:24Z"}
{"aid":"http://arxiv.org/abs/2504.14919v1","title":"GenCLIP: Generalizing CLIP Prompts for Zero-shot Anomaly Detection","summary":"Zero-shot anomaly detection (ZSAD) aims to identify anomalies in unseen\ncategories by leveraging CLIP's zero-shot capabilities to match text prompts\nwith visual features. A key challenge in ZSAD is learning general prompts\nstably and utilizing them effectively, while maintaining both generalizability\nand category specificity. Although general prompts have been explored in prior\nworks, achieving their stable optimization and effective deployment remains a\nsignificant challenge. In this work, we propose GenCLIP, a novel framework that\nlearns and leverages general prompts more effectively through multi-layer\nprompting and dual-branch inference. Multi-layer prompting integrates\ncategory-specific visual cues from different CLIP layers, enriching general\nprompts with more comprehensive and robust feature representations. By\ncombining general prompts with multi-layer visual features, our method further\nenhances its generalization capability. To balance specificity and\ngeneralization, we introduce a dual-branch inference strategy, where a\nvision-enhanced branch captures fine-grained category-specific features, while\na query-only branch prioritizes generalization. The complementary outputs from\nboth branches improve the stability and reliability of anomaly detection across\nunseen categories. Additionally, we propose an adaptive text prompt filtering\nmechanism, which removes irrelevant or atypical class names not encountered\nduring CLIP's training, ensuring that only meaningful textual inputs contribute\nto the final vision-language alignment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T07:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.14931v1","title":"Point-transitive Steiner systems S(2,6,111/121/126), S(2,7,169/175)","summary":"In this paper new Steiner systems $S(2,6,111)$, $S(2,6,121)$, $S(2,6,126)$,\n$S(2,7,169)$, $S(2,7,175)$ and possibly others with point-transitive\n(commutative except $S(2,6,111)$ case) automorphism groups are introduced.","main_category":"math.CO","categories":"math.CO","published":"2025-04-21T07:50:57Z"}
{"aid":"http://arxiv.org/abs/2504.14958v1","title":"Advancing quantum process tomography through universal compilation","summary":"Quantum process tomography (QPT) is crucial for characterizing operations in\nquantum gates and circuits, however, existing methods face scalability and\nnoise sensitivity challenges. Here, we propose a QPT approach based on\nuniversal compilation, which systematically decomposes quantum processes into\noptimized Kraus operators and Choi matrices. This method utilizes efficient\nalgorithms to improve accuracy while reducing resource requirements. We\nbenchmark our approach through numerical simulations of random unitary gates,\ndemonstrating highly accurate quantum process characterization. Additionally,\nwe apply it to dephasing processes with time-homogeneous and time-inhomogeneous\nnoise, achieving improved fidelity and robustness. Our work further enables\nbroader applications in quantum error correction and device validation.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T08:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.14970v1","title":"Gapless behavior in a two-leg spin ladder with bond randomness","summary":"We successfully synthesized\n[Cu$_2$(AcO)$_4$($p$-Py-V-$p$-F)$_2$]$\\cdot$4CHCl$_3$, a verdazyl-based complex\nwith a paddlewheel structure comprising two Cu atoms, which induces strong\nantiferromagnetic (AF) exchange interactions between Cu spins, generating a\nnonmagnetic singlet state at low temperatures. Two primary exchange\ninteractions between radical spins generate a spin-1/2 AF two-leg ladder. In\naddition, two possible positional configurations of the F atom in the complex\ncreate four different overlap patterns of molecular orbitals, introducing bond\nrandomness in the spin ladder. The observed experimental behaviors, such as the\nCurie tail in the magnetic susceptibility and the gapless gradual increase in\nthe magnetization curve, are attributed to a broad distribution of excitation\nenergies and a few orphan spins in the random-singlet (RS) state that are\nstabilized by bond randomness. The low-temperature specific heat exhibits a\ntemperature dependence with $\\propto 1/|{\\rm{ln}}T|^3$, demonstrating the\nformation of the RS state in unfrustrated systems. We also consider the effect\nof restricted patterns of exchange interactions and one-dimensional nature of\nthe system on the RS state.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-21T08:57:57Z"}
{"aid":"http://arxiv.org/abs/2504.14976v1","title":"Effects of angular scattering and H+p, H+H collisions on the properties\n  of interstellar atoms in the heliosphere","summary":"Interstellar hydrogen atoms (H atoms) penetrate into the heliosphere through\nthe region of the solar wind interaction with the interstellar plasma due to\ntheir large mean free path. Resonant charge exchange of H atoms with protons\nhas been considered as the main interaction process between the components. In\nthe majority of models, other processes like elastic H-H and H-p collisions are\nnot included. Moreover, it has been assumed that the velocities of the\ncolliding particles remain unchanged during charge exchange. This corresponds\nto the scattering on the angle of $\\pi$ in the centre mass rest frame.\n  The goal of this paper is to explore effects of the elastic H-H and H-p\ncollisions as well as the angular scattering during charge exchange on the\ndistribution of the interstellar atoms in the heliosphere and at its boundary.\n  We present results of simple (and therefore, easily repeatable) kinetic model\nof the interstellar atom penetration through the region of the solar and\ninterstellar winds interaction into the heliosphere. As a result of the model\nwe compute the distribution function of the interstellar atoms at different\nheliospheric distances. Further, this distribution function is used to compute\nits moments and potentially observable features such as absorption and\nbackscattered spectra in the Lyman-alpha line.\n  Results show that there are differences in the behavior of the distribution\nfunction when considering elastic collisions and the changes in the moments of\nthe distribution achieve 10%. Therefore, in cases where precise calculation of\nH atom parameters is essential, such as in the modeling of backscattered\nLyman-$\\alpha$ emission, elastic collisions must be considered.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-21T09:07:39Z"}
{"aid":"http://arxiv.org/abs/2504.14985v1","title":"aiXamine: LLM Safety and Security Simplified","summary":"Evaluating Large Language Models (LLMs) for safety and security remains a\ncomplex task, often requiring users to navigate a fragmented landscape of ad\nhoc benchmarks, datasets, metrics, and reporting formats. To address this\nchallenge, we present aiXamine, a comprehensive black-box evaluation platform\nfor LLM safety and security. aiXamine integrates over 40 tests (i.e.,\nbenchmarks) organized into eight key services targeting specific dimensions of\nsafety and security: adversarial robustness, code security, fairness and bias,\nhallucination, model and data privacy, out-of-distribution (OOD) robustness,\nover-refusal, and safety alignment. The platform aggregates the evaluation\nresults into a single detailed report per model, providing a detailed breakdown\nof model performance, test examples, and rich visualizations. We used aiXamine\nto assess over 50 publicly available and proprietary LLMs, conducting over 2K\nexaminations. Our findings reveal notable vulnerabilities in leading models,\nincluding susceptibility to adversarial attacks in OpenAI's GPT-4o, biased\noutputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0.\nAdditionally, we observe that open-source models can match or exceed\nproprietary models in specific services such as safety alignment, fairness and\nbias, and OOD robustness. Finally, we identify trade-offs between distillation\nstrategies, model size, training methods, and architectural choices.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-21T09:26:05Z"}
{"aid":"http://arxiv.org/abs/2504.14986v1","title":"Layered semiconductors integrated with polyimide thin films for\n  high-quality valleytronic and quantum-photonic systems","summary":"Dielectric integration of layered semiconductors is a prerequisite for\nfabricating high-quality optoelectronic, valleytronic, and quantum-photonic\ndevices. While hexagonal boron nitride (hBN) is the current benchmark\ndielectric, exploration of the most suitable dielectric materials covering the\ncomplete substrates continues to expand. This work demonstrates the formation\nof high optical-quality excitons in two widely explored layered semiconductors,\nWSe$_2$ and WS$_2$, integrated into polyimide (PI) thin films of thicknesses\n$\\approx$500 nm. The photoluminescence (PL) studies at $T$ = 296 K show the\nformation of neutral excitons $\\left(X^0\\right)$ and trions in\nfully-PI-encapsulated 1L-WSe$_2$ with 2-sigma ($2\\sigma$) spatial-inhomogeneity\nof 4.5 (3.4) meV in $X^0$ emission energy (linewidth), which is $\\approx$1/3rd\n(1/5th), respectively, that of inhomogeneity measured in fully-hBN-encapsulated\n1L-WSe$_2$. A smaller $2\\sigma$ of 2.1 (2.3) meV in $X^0$ emission energy\n(linewidth) has been shown for fully-PI-encapsulated 1L-WS$_2$.\nPolarization-resolved and excitation power-dependent PL measurements of\nPI-isolated 1L-TMDs at $T$ = 4 K further reveal formations of high-quality\nneutral-biexcitons and negatively-charged biexcitons, with degrees of\nvalley-polarization up to 21$\\%$ under non-resonant excitation. Furthermore,\nthe fully-PI-encapsulated 1L-WSe$_2$ also hosts single quantum emitters with\nnarrow linewidths and high-spectral stability. This work indicates that PI thin\nfilms may serve the purpose of high-quality dielectric material for integrating\nthe layered materials on a wafer scale.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,physics.app-ph,physics.optics,quant-ph","published":"2025-04-21T09:29:43Z"}
{"aid":"http://arxiv.org/abs/2504.14988v1","title":"Benchmarking Large Vision-Language Models on Fine-Grained Image Tasks: A\n  Comprehensive Evaluation","summary":"Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated\nremarkable multimodal perception capabilities, garnering significant attention.\nWhile numerous evaluation studies have emerged, assessing LVLMs both\nholistically and on specialized tasks, fine-grained image tasks-fundamental to\ncomputer vision-remain largely unexplored. To fill this gap, we introduce a\ncomprehensive fine-grained evaluation benchmark, i.e., FG-BMK, comprising 3.49\nmillion questions and 3.32 million images. Our evaluation systematically\nexamines LVLMs from both human-oriented and machine-oriented perspectives,\nfocusing on their semantic recognition and fine-grained feature representation\ncapabilities. Through extensive experiments on eight representative LVLMs/VLMs,\nwe uncover key findings regarding the influence of training paradigms, modality\nalignment, perturbation susceptibility, and fine-grained category reasoning on\ntask performance. This work provides critical insights into the limitations of\ncurrent LVLMs and offers guidance for future data construction and model design\nin the development of more advanced LVLMs. Our code is open-source and\navailable at https://github.com/SEU-VIPGroup/FG-BMK.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T09:30:41Z"}
{"aid":"http://arxiv.org/abs/2504.15004v1","title":"The compliance of the molecular hydride superconductor $BiH_4$ with the\n  Migdal's theorem","summary":"The discovery of near-room-temperature superconductivity in H3S sparked\nexperimental and theoretical studies of highly compressed hydrides with the aim\nof obtaining room-temperature superconductivity. There are two dominant hydride\nclasses where the search is ongoing: the first class is the covalently bonded\nhydrides (which is represented by H3S), and the second class is the\nclathrate-type hydrides (which is represented by LaH10, YH6, CaH6). Recently,\nthe third class of superconducting hydrides, where the hydrogen remains its\nmolecular form, has been discovered. This class is represented by BaH12 and\nBiH4. Here, we analyzed experimental data for the BaH12 and BiH4. We found that\nthe BaH12 exhibits grains of an average size of 26 nm and a low level of\nmicrostrain 0.1%, in the range of 126 GPa < P < 160 GPa. We also derived the\nDebye $\\Theta_D$ and Einstein $\\Theta_E$ temperatures, and the electron-phonon\ncoupling constant $\\Lambda_{e-ph} $ in BaH12 and BiH4. The $\\Lambda_{e-ph} $ in\nBiH4 significantly differs from the values obtained by first-principles\ncalculations. The derived Fermi temperature $T_F = 20,000 K$ for BiH4 positions\nthis molecular hydride between the unconventional and conventional\nsuperconductors bands in the Uemura plot. This position is outside of the band\nwhere covalently bonded and clathrate hydrides are located. The ratio $\\Theta_D\n/ T_F = 0.026 $ of BiH4 is typical for pure metals and A-15 alloys. This\nimplies that the BiH4, is the first hydride superconductor which complains with\nthe Migdal's theorem.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-21T10:09:45Z"}
{"aid":"http://arxiv.org/abs/2504.15023v1","title":"Dust-obscured Galaxies with Broken Power-law Spectral Energy\n  Distributions Discovered by UNIONS","summary":"We report on the spectral energy distributions (SEDs) of infrared-bright\ndust-obscured galaxies (DOGs) with $(i - [22])_{\\rm AB} \\geq 7.0$. Using\nphotometry from the deep and wide Ultraviolet Near-Infrared Optical Northern\nSurvey, combined with near-IR and mid-IR data from the UKIRT Infrared Deep Sky\nSurvey and the Wide-field Infrared Survey Explorer, we successfully identified\n382 DOGs in $\\sim$ 170 deg$^2$. Among them, the vast majority (376 DOGs) were\nclassified into two subclasses: bump DOGs (132/376) and power-law (PL) DOGs\n(244/376), which are dominated by star formation and active galactic nucleus\n(AGN), respectively. Through the SED analysis, we found that roughly half\n(120/244) of the PL DOGs show ``broken'' power-law SEDs. The significant red\nslope from optical to near-IR in the SEDs of these ``broken power-law DOGs''\n(BPL DOGs) probably reflects their large amount of dust extinction. In other\nwords, BPL DOGs are more heavily obscured AGNs, compared to PL DOGs with\nnon-broken power-law SEDs.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T11:11:41Z"}
{"aid":"http://arxiv.org/abs/2504.15024v1","title":"Extending Collinear Density Functionals to Noncollinear Cases under\n  Periodic Boundary Condition","summary":"Accurate modeling of spin-orbit coupling and noncollinear magnetism in\nmaterials requires noncollinear density functionals within the two-component\ngeneralized Kohn-Sham (GKS) framework, yet constructing and implementing\nnoncollinear functionals remains challenging. Recently, a methodology was\nproposed to extend collinear functionals into noncollinear ones, successfully\ndefining noncollinear functionals and their derivatives. However, the initial\nimplementation involved a systematic approach to differentiate energy over\ndensity matrix elements rather than the derivatives of the energy functional\nwith respect to density, presenting challenges for integration with periodic\nboundary condition-density functional theory (PBC-DFT) software. We have\nderived a novel set of working equations based on the original methodology,\nwhich provides noncollinear energy functionals and their derivatives. These\nworking equations have been implemented in our noncollinear functional ensemble\nnamed NCXC, ensuring numerical stability and transferability without the need\nfor incorporating derivatives of basis functions. This implementation is\nexpected to facilitate compatibility with most DFT software packages. We\ndemonstrate some preliminary applications in periodic systems, including\nnoncollinear magnetism in spin spirals, band structures in topological\ninsulators, and band gaps in semiconducting inorganic materials, using NCXC.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T11:11:59Z"}
{"aid":"http://arxiv.org/abs/2504.15042v1","title":"Bayesian Sensing for Time-Varying Channels in ISAC Systems","summary":"Future mobile networks are projected to support integrated sensing and\ncommunications in high-speed communication scenarios. Nevertheless, large\nDoppler shifts induced by time-varying channels may cause severe inter-carrier\ninterference (ICI). Frequency domain shows the potential of reducing ISAC\ncomplexity as compared with other domains. However, parameter mismatching issue\nstill exists for such sensing. In this paper, we develop a novel sensing scheme\nbased on sparse Bayesian framework, where the delay and Doppler estimation\nproblem in time-varying channels is formulated as a 3D multiple\nmeasurement-sparse signal recovery (MM-SSR) problem. We then propose a novel\ntwo-layer variational Bayesian inference (VBI) method to decompose the 3D\nMM-SSR problem into two layers and estimate the Doppler in the first layer and\nthe delay in the second layer alternatively. Subsequently, as is benefited from\nnewly unveiled signal construction, a simplified two-stage multiple signal\nclassification (MUSIC)-based VBI method is proposed, where the delay and the\nDoppler are estimated by MUSIC and VBI, respectively. Additionally, the\nCram\\'er-Rao bound (CRB) of the considered sensing parameters is derived to\ncharacterize the lower bound for the proposed estimators. Corroborated by\nextensive simulation results, our proposed method can achieve improved mean\nsquare error (MSE) than its conventional counterparts and is robust against the\ntarget number and target speed, thereby validating its wide applicability and\nadvantages over prior arts.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T11:53:44Z"}
{"aid":"http://arxiv.org/abs/2504.15053v1","title":"One pathogen does not an epidemic make: A review of interacting\n  contagions, diseases, beliefs, and stories","summary":"From pathogens and computer viruses to genes and memes, contagion models have\nfound widespread utility across the natural and social sciences. Despite their\nsuccess and breadth of adoption, the approach and structure of these models\nremain surprisingly siloed by field. Given the siloed nature of their\ndevelopment and widespread use, one persistent assumption is that a given\ncontagion can be studied in isolation, independently from what else might be\nspreading in the population. In reality, countless contagions of biological and\nsocial nature interact within hosts (interacting with existing beliefs, or the\nimmune system) and across hosts (interacting in the environment, or affecting\ntransmission mechanisms). Additionally, from a modeling perspective, we know\nthat relaxing these assumptions has profound effects on the physics and\ntranslational implications of the models. Here, we review mechanisms for\ninteractions in social and biological contagions, as well as the models and\nframeworks developed to include these interactions in the study of the\ncontagions. We highlight existing problems related to the inference of\ninteractions and to the scalability of mathematical models and identify\npromising avenues of future inquiries. In doing so, we highlight the need for\ninterdisciplinary efforts under a unified science of contagions and for\nremoving a common dichotomy between social and biological contagions.","main_category":"physics.soc-ph","categories":"physics.soc-ph,q-bio.PE","published":"2025-04-21T12:26:27Z"}
{"aid":"http://arxiv.org/abs/2504.15056v1","title":"Semileptonic and nonleptonic $\\bar{B}_{s}\\to D_{sJ}$ decays in covariant\n  light-front approach","summary":"In this work, we investigate the $\\bar{B}_{s}\\to D_{sJ}$ transitions in\ncovariant light-front approach, where $D_{sJ}$ denotes an s-wave or p-wave\n$c\\bar{s}$ meson state. We first obtain the transition form factors within the\nframework of the quark model, and then apply the obtained form factors to\nobtain the branching fractions of semileptonic and nonleptonic decays. We also\ncompare our results with experimental data and other theoretical predictions.\nWe find that some branching fractions are sizable and might be accessible at\nthe LHC and future $e^{+}$-$e^{-}$ colliders. Our work is expected to be of\ngreat value for establishing corresponding decay channels, and also be helpful\nin understanding the non-perturbative QCD dynamics.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-21T12:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.15063v1","title":"Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle\n  Stages","summary":"Smart contracts are the cornerstone of decentralized applications and\nfinancial protocols, which extend the application of digital currency\ntransactions. The applications and financial protocols introduce significant\nsecurity challenges, resulting in substantial economic losses. Existing\nsolutions predominantly focus on code vulnerabilities within smart contracts,\naccounting for only 50% of security incidents. Therefore, a more comprehensive\nstudy of security issues related to smart contracts is imperative. The existing\nempirical research realizes the static analysis of smart contracts from the\nperspective of the lifecycle and gives the corresponding measures for each\nstage. However, they lack the characteristic analysis of vulnerabilities in\neach stage and the distinction between the vulnerabilities. In this paper, we\npresent the first empirical study on the security of smart contracts throughout\ntheir lifecycle, including deployment and execution, upgrade, and destruction\nstages. It delves into the security issues at each stage and provides at least\nseven feature descriptions. Finally, utilizing these seven features, five\nmachine-learning classification models are used to identify vulnerabilities at\ndifferent stages. The classification results reveal that vulnerable contracts\nexhibit distinct transaction features and ego network properties at various\nstages.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-21T12:42:59Z"}
{"aid":"http://arxiv.org/abs/2504.15089v1","title":"Robust Planning and Control of Omnidirectional MRAVs for Aerial\n  Communications in Wireless Networks","summary":"A new class of Multi-Rotor Aerial Vehicles (MRAVs), known as omnidirectional\nMRAVs (o-MRAVs), has gained attention for their ability to independently\ncontrol 3D position and orientation. This capability enhances robust planning\nand control in aerial communication networks, enabling more adaptive trajectory\nplanning and precise antenna alignment without additional mechanical\ncomponents. These features are particularly valuable in uncertain environments,\nwhere disturbances such as wind and interference affect communication\nstability. This paper examines o-MRAVs in the context of robust aerial network\nplanning, comparing them with the more common under-actuated MRAVs (u-MRAVs).\nKey applications, including physical layer security, optical communications,\nand network densification, are highlighted, demonstrating the potential of\no-MRAVs to improve reliability and efficiency in dynamic communication\nscenarios.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T13:23:48Z"}
{"aid":"http://arxiv.org/abs/2504.15093v1","title":"Rethinking the Potential of Multimodality in Collaborative Problem\n  Solving Diagnosis with Large Language Models","summary":"Detecting collaborative and problem-solving behaviours from digital traces to\ninterpret students' collaborative problem solving (CPS) competency is a\nlong-term goal in the Artificial Intelligence in Education (AIEd) field.\nAlthough multimodal data and advanced models are argued to have the potential\nto detect complex CPS behaviours, empirical evidence on their value remains\nlimited with some contrasting evidence. In this study, we investigated the\npotential of multimodal data to improve model performance in diagnosing 78\nsecondary school students' CPS subskills and indicators in authentic\neducational settings. In particular, text embeddings from verbal data and\nacoustic embeddings from audio data were used in a multimodal classification\nmodel for CPS diagnosis. Both unimodal and multimodal transformer-based models\noutperformed traditional models in detecting CPS classes. Although the\ninclusion of multimodality did not improve the performance of traditional\nunimodal models, its integration into transformer-based models demonstrated\nimproved performance for diagnosing social-cognitive CPS classes compared to\nunimodal transformer-based models. Based on the results, the paper argues that\nmultimodality and the selection of a particular modelling technique should not\nbe taken for granted to achieve the best performance in the automated detection\nof every CPS subskill and indicator. Rather, their value is limited to certain\ntypes of CPS indicators, affected by the complexity of the labels, and\ndependent on the composition of indicators in the dataset. We conclude the\npaper by discussing the required nuance when considering the value of LLMs and\nmultimodality in automated CPS diagnosis, highlighting the need for human-AI\ncomplementarity, and proposing the exploration of relevant model architectures\nand techniques to improve CPS diagnosis in authentic educational contexts.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-21T13:25:55Z"}
{"aid":"http://arxiv.org/abs/2504.15104v1","title":"Search for pulsars with periods of more than two seconds at declinations\n  from +21$^o$ to +42$^o$","summary":"A search was carried out for pulsars with periods (P) from 2 to 90 s in daily\nobservations carried out over an interval of 5 years in a area measuring 6300\nsq.deg. The data was obtained on a Large Phased Array (LPA) at a frequency of\n111 MHz. The periodograms calculated using the Fast Folding Algorithm (FFA)\nwere used for the search. To increase the sensitivity, the periodograms\nobtained in different observation sessions were added together. Of the 14 known\npulsars that entered the study area, with periods of P>2 s and dispersion\nmeasures (DM) less than 200 pc/cm$^3$, 9 were detected. 2 new pulsars have been\nfound. The mean profiles of pulsars are obtained and estimates of their flux\ndensities are given. The open pulsar J1951+28, with a period of P = 7.3342 s\nand DM = 3.5 pc/cm$^3$, turned out to be one of the pulsars closest to the Sun.\nThe absence of new pulsars with periods of tens of seconds with a search\nsensitivity of 1 mJy outside the Galactic plane indicates a low probability of\nthe existence of pulsars with extremely long periods. Most likely, the recently\nfound sources of periodic radiation with periods from a minute to tens of\nminutes are white dwarfs.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-21T13:53:41Z"}
{"aid":"http://arxiv.org/abs/2504.15117v1","title":"Symplectic Geometry in Hybrid and Impulsive Optimal Control","summary":"Hybrid dynamical systems are systems which undergo both continuous and\ndiscrete transitions. The Bolza problem from optimal control theory is applied\nto these systems and a hybrid version of Pontryagin's maximum principle is\npresented. This hybrid maximum principle is presented to emphasize its\ngeometric nature which makes its study amenable to the tools of geometric\nmechanics and symplectic geometry. One explicit benefit of this geometric\napproach is that the symplectic structure (and hence the induced volume) is\npreserved. This allows for a hybrid analog of caustics and conjugate points.\nAdditionally, an introductory analysis of singular solutions (beating and Zeno)\nis discussed geometrically. This work concludes on a biological example where\nbeating can occur.","main_category":"math.OC","categories":"math.OC","published":"2025-04-21T14:13:15Z"}
{"aid":"http://arxiv.org/abs/2504.15119v1","title":"FRB cosmology with the RM-PRS Luminosity Correlation","summary":"Fast Radio Bursts (FRBs) have emerged as a powerful tool for cosmological\nstudies, particularly through the dispersion measure-redshift ($\\mathrm{DM}-z$)\nrelation. This work proposes a novel calibration method for FRBs using the\nYang-Li-Zhang (YLZ) empirical relation, which links the rotation measure (RM)\nof FRBs to the luminosity of their associated persistent radio sources (PRS).\nWe demonstrate that this approach provides independent constraints on\ncosmological parameters, bypassing limitations inherent to traditional\n$\\mathrm{DM}-z$ method. Utilizing the current sample of four YLZ-calibrated\nFRBs, we derive a Hubble constant measurement of $H_0 =\n86.18_{-14.99}^{+18.03}\\ \\mathrm{km\\ s^{-1}\\ Mpc^{-1}}$ (68\\% CL). Monte Carlo\nsimulations indicate that a future catalog of 400 FRB-PSR systems could reduce\nthe relative uncertainty of $H_0$ to 4.5\\%. Combining YLZ-calibrated FRBs with\n$\\mathrm{DM}-z$ sample reveals critical synergies: joint analysis of equalized\nsamples ($N=100$ for both methods) reduces the relative uncertainty of $H_0$ to\n2.9\\%, mainly because the incorporation of PRS observations substantially\nmitigates the degeneracy between the parameters such as IGM baryon mass\nfraction ($f_{\\rm IGM}$) and other cosmological parameters inherent to the\n$\\mathrm{DM}-z$ relation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-21T14:17:03Z"}
{"aid":"http://arxiv.org/abs/2504.15120v1","title":"Kuwain 1.5B: An Arabic SLM via Language Injection","summary":"Enhancing existing models with new knowledge is a crucial aspect of AI\ndevelopment. This paper introduces a novel method for integrating a new\nlanguage into a large language model (LLM). Our approach successfully\nincorporates a previously unseen target language into an existing LLM without\ncompromising its prior knowledge. We trained a tiny model with 1.5 billion\nparameters named Kuwain by injecting the Arabic language into a small\nopen-source model mainly trained in English. Our method demonstrates\nsignificant improvements in Arabic language performance, with an average 8%\nimprovement across various benchmarks, while retaining the model's existing\nknowledge with a minimum amount of the original model's data. This offers a\ncost-effective alternative to training a comprehensive model in both English\nand Arabic. The results highlight the potential for efficient, targeted\nlanguage model expansion without extensive retraining or resource-intensive\nprocesses.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-21T14:17:25Z"}
{"aid":"http://arxiv.org/abs/2504.15125v1","title":"Contemplative Wisdom for Superalignment","summary":"As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Rather than externally\nconstraining behavior, we advocate designing AI with intrinsic morality built\ninto its cognitive architecture and world model. Inspired by contemplative\nwisdom traditions, we show how four axiomatic principles can instil a resilient\nWise World Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark using GPT-4o, particularly when\ncombined. We offer detailed implementation strategies for state-of-the-art\nmodels, including contemplative architectures, constitutions, and reinforcement\nof chain-of-thought. For future systems, the active inference framework may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nthese insights in embodied agents. This interdisciplinary approach offers a\nself-correcting and resilient alternative to prevailing brittle control\nschemes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T14:20:49Z"}
{"aid":"http://arxiv.org/abs/2504.15128v1","title":"Efficient simulation of Clifford circuits with small Markovian errors","summary":"Classical simulation of noisy quantum circuits is essential for understanding\nquantum computing experiments. It enables scalable error characterization,\nanalysis of how noise impacts quantum algorithms, and optimized implementations\nof quantum error correction. However, most existing efficient simulation\ntechniques can only simulate the effects of stochastic (incoherent) noise. The\nlack of efficient ways to simulate coherent errors, which are common and\nsignificant in contemporary quantum computing systems, has frustrated research.\nWe remedy this gap by introducing an efficient algorithm for approximate\nsimulation of Clifford circuits with arbitrary small errors (including coherent\nerrors) that can be described by sparse $n$-qubit Lindbladians. We use this\nalgorithm to study the impact of coherent errors on syndrome extract circuits\nfor distance-3, 5, 7, 9, and 11 rotated surface codes, and on deep random\n225-qubit circuits containing over a million gates.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T14:23:56Z"}
{"aid":"http://arxiv.org/abs/2504.15131v1","title":"Beyond Binary Opinions: A Deep Reinforcement Learning-Based Approach to\n  Uncertainty-Aware Competitive Influence Maximization","summary":"The Competitive Influence Maximization (CIM) problem involves multiple\nentities competing for influence in online social networks (OSNs). While Deep\nReinforcement Learning (DRL) has shown promise, existing methods often assume\nusers' opinions are binary and ignore their behavior and prior knowledge. We\npropose DRIM, a multi-dimensional uncertainty-aware DRL-based CIM framework\nthat leverages Subjective Logic (SL) to model uncertainty in user opinions,\npreferences, and DRL decision-making. DRIM introduces an Uncertainty-based\nOpinion Model (UOM) for a more realistic representation of user uncertainty and\noptimizes seed selection for propagating true information while countering\nfalse information. In addition, it quantifies uncertainty in balancing\nexploration and exploitation. Results show that UOM significantly enhances true\ninformation spread and maintains influence against advanced false information\nstrategies. DRIM-based CIM schemes outperform state-of-the-art methods by up to\n57% and 88% in influence while being up to 48% and 77% faster. Sensitivity\nanalysis indicates that higher network observability and greater information\npropagation boost performance, while high network activity mitigates the effect\nof users' initial biases.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-21T14:26:04Z"}
{"aid":"http://arxiv.org/abs/2504.15135v1","title":"KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking","summary":"Entity linking (EL) aligns textual mentions with their corresponding entities\nin a knowledge base, facilitating various applications such as semantic search\nand question answering. Recent advances in multimodal entity linking (MEL) have\nshown that combining text and images can reduce ambiguity and improve alignment\naccuracy. However, most existing MEL methods overlook the rich structural\ninformation available in the form of knowledge-graph (KG) triples. In this\npaper, we propose KGMEL, a novel framework that leverages KG triples to enhance\nMEL. Specifically, it operates in three stages: (1) Generation: Produces\nhigh-quality triples for each mention by employing vision-language models based\non its text and images. (2) Retrieval: Learns joint mention-entity\nrepresentations, via contrastive learning, that integrate text, images, and\n(generated or KG) triples to retrieve candidate entities for each mention. (3)\nReranking: Refines the KG triples of the candidate entities and employs large\nlanguage models to identify the best-matching entity for the mention. Extensive\nexperiments on benchmark datasets demonstrate that KGMEL outperforms existing\nmethods. Our code and datasets are available at:\nhttps://github.com/juyeonnn/KGMEL.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-21T14:38:44Z"}
{"aid":"http://arxiv.org/abs/2504.15143v1","title":"Deterministic Depth-4 PIT and Normalization","summary":"In this paper, we initiate the study of deterministic PIT for\n$\\Sigma^{[k]}\\Pi\\Sigma\\Pi^{[\\delta]}$ circuits over fields of any\ncharacteristic, where $k$ and $\\delta$ are bounded. Our main result is a\ndeterministic polynomial-time black-box PIT algorithm for\n$\\Sigma^{[3]}\\Pi\\Sigma\\Pi^{[\\delta]}$ circuits, under the additional condition\nthat one of the summands at the top $\\Sigma$ gate is squarefree.\n  Our techniques are purely algebro-geometric: they do not rely on\nSylvester--Gallai-type theorems, and our PIT result holds over arbitrary\nfields.\n  The core of our proof is based on the normalization of algebraic varieties.\nSpecifically, we carry out the analysis in the integral closure of a coordinate\nring, which enjoys better algebraic properties than the original ring.","main_category":"cs.CC","categories":"cs.CC,math.AG","published":"2025-04-21T14:46:31Z"}
{"aid":"http://arxiv.org/abs/2504.15147v1","title":"The Iterative Chainlet Partitioning Algorithm for the Traveling Salesman\n  Problem with Drone and Neural Acceleration","summary":"This study introduces the Iterative Chainlet Partitioning (ICP) algorithm and\nits neural acceleration for solving the Traveling Salesman Problem with Drone\n(TSP-D). The proposed ICP algorithm decomposes a TSP-D solution into smaller\nsegments called chainlets, each optimized individually by a dynamic programming\nsubroutine. The chainlet with the highest improvement is updated and the\nprocedure is repeated until no further improvement is possible. The number of\nsubroutine calls is bounded linearly in problem size for the first iteration\nand remains constant in subsequent iterations, ensuring algorithmic\nscalability. Empirical results show that ICP outperforms existing algorithms in\nboth solution quality and computational time. Tested over 1,059 benchmark\ninstances, ICP yields an average improvement of 2.75% in solution quality over\nthe previous state-of-the-art algorithm while reducing computational time by\n79.8%. The procedure is deterministic, ensuring reliability without requiring\nmultiple runs. The subroutine is the computational bottleneck in the already\nefficient ICP algorithm. To reduce the necessity of subroutine calls, we\nintegrate a graph neural network (GNN) to predict incremental improvements. We\ndemonstrate that the resulting Neuro ICP (NICP) achieves substantial\nacceleration while maintaining solution quality. Compared to ICP, NICP reduces\nthe total computational time by 49.7%, while the objective function value\nincrease is limited to 0.12%. The framework's adaptability to various\noperational constraints makes it a valuable foundation for developing efficient\nalgorithms for truck-drone synchronized routing problems.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-21T14:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.15149v1","title":"Cosmological Constraints with Void Lensing I: the Simulation-Based\n  Inference Framework","summary":"We present a Simulation-Based Inference (SBI) framework for cosmological\nparameter estimation via void lensing analysis. Despite the absence of an\nanalytical model of void lensing, SBI can effectively learn posterior\ndistributions through forward modeling of mock data. We develop a forward\nmodeling pipeline that accounts for both cosmology and the galaxy-halo\nconnection. By training a neural density estimator on simulated data, we infer\nthe posteriors of two cosmological parameters, $\\Omega_m$ and $S_8$. Validation\ntests are conducted on posteriors derived from different cosmological\nparameters and a fiducial sample. The results demonstrate that SBI provides\nunbiased estimates of mean values and accurate uncertainties. These findings\nhighlight the potential to apply void lensing analysis to observational data\neven without an analytical void lensing model.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T14:52:56Z"}
{"aid":"http://arxiv.org/abs/2504.15155v1","title":"Dynamic 3D KAN Convolution with Adaptive Grid Optimization for\n  Hyperspectral Image Classification","summary":"Deep neural networks face several challenges in hyperspectral image\nclassification, including high-dimensional data, sparse distribution of ground\nobjects, and spectral redundancy, which often lead to classification\noverfitting and limited generalization capability. To more efficiently adapt to\nground object distributions while extracting image features without introducing\nexcessive parameters and skipping redundant information, this paper proposes\nKANet based on an improved 3D-DenseNet model, consisting of 3D KAN Conv and an\nadaptive grid update mechanism. By introducing learnable univariate B-spline\nfunctions on network edges, specifically by flattening three-dimensional\nneighborhoods into vectors and applying B-spline-parameterized nonlinear\nactivation functions to replace the fixed linear weights of traditional 3D\nconvolutional kernels, we precisely capture complex spectral-spatial nonlinear\nrelationships in hyperspectral data. Simultaneously, through a dynamic grid\nadjustment mechanism, we adaptively update the grid point positions of\nB-splines based on the statistical characteristics of input data, optimizing\nthe resolution of spline functions to match the non-uniform distribution of\nspectral features, significantly improving the model's accuracy in\nhigh-dimensional data modeling and parameter efficiency, effectively\nalleviating the curse of dimensionality. This characteristic demonstrates\nsuperior neural scaling laws compared to traditional convolutional neural\nnetworks and reduces overfitting risks in small-sample and high-noise\nscenarios. KANet enhances model representation capability through a 3D dynamic\nexpert convolution system without increasing network depth or width. The\nproposed method demonstrates superior performance on IN, UP, and KSC datasets,\noutperforming mainstream hyperspectral image classification approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T14:57:48Z"}
{"aid":"http://arxiv.org/abs/2504.15164v1","title":"Minimal effective theory for leptogenesis, dark matter, and neutrino\n  masses","summary":"We study the phenomenological consequences of choosing a minimal set of\neffective operators that allow for the simultaneous generation of the dark\nmatter relic density and the matter-antimatter asymmetry of the universe.\nNeutrino masses are obtained in a specific case of baryogenesis via\nleptogenesis. We find that only two new particles -- a heavy unstable fermion\nand a light dark matter scalar -- need to be included in addition to the\nStandard Model particle content.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T15:15:01Z"}
{"aid":"http://arxiv.org/abs/2504.15208v1","title":"Compute-Optimal LLMs Provably Generalize Better With Scale","summary":"Why do larger language models generalize better? To investigate this\nquestion, we develop generalization bounds on the pretraining objective of\nlarge language models (LLMs) in the compute-optimal regime, as described by the\nChinchilla scaling laws. We introduce a novel, fully empirical Freedman-type\nmartingale concentration inequality that tightens existing bounds by accounting\nfor the variance of the loss function. This generalization bound can be\ndecomposed into three interpretable components: the number of parameters per\ntoken, the loss variance, and the quantization error at a fixed bitrate. As\ncompute-optimal language models are scaled up, the number of parameters per\ndata point remains constant; however, both the loss variance and the\nquantization error decrease, implying that larger models should have smaller\ngeneralization gaps. We examine why larger models tend to be more quantizable\nfrom an information theoretic perspective, showing that the rate at which they\ncan integrate new information grows more slowly than their capacity on the\ncompute-optimal frontier. From these findings we produce a scaling law for the\ngeneralization gap, with bounds that become predictably stronger with scale.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T16:26:56Z"}
{"aid":"http://arxiv.org/abs/2504.15214v1","title":"Histogram-based Parameter-efficient Tuning for Passive Sonar\n  Classification","summary":"Parameter-efficient transfer learning (PETL) methods adapt large artificial\nneural networks to downstream tasks without fine-tuning the entire model.\nHowever, existing additive methods, such as adapters, sometimes struggle to\ncapture distributional shifts in intermediate feature embeddings. We propose a\nnovel histogram-based parameter-efficient tuning (HPT) technique that captures\nthe statistics of the target domain and modulates the embeddings. Experimental\nresults on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD)\ndemonstrate that HPT outperforms conventional adapters. Notably, HPT achieves\n91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields\nfeature representations closer to those of fully fine-tuned models. Overall,\nHPT balances parameter savings and performance, providing a distribution-aware\nalternative to existing adapters and shows a promising direction for scalable\ntransfer learning in resource-constrained environments. The code is publicly\navailable:\nhttps://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.","main_category":"cs.LG","categories":"cs.LG,cs.SD","published":"2025-04-21T16:36:38Z"}
{"aid":"http://arxiv.org/abs/2504.15216v1","title":"Spin dynamics and 1/3 magnetization plateau in a coupled distorted\n  diamond chain compound K2Cu3(MoO4)4","summary":"We investigate magnetic properties of the $s$ = 1/2 compound\nK$_{2}$Cu$_{3}$(MoO$_{4}$)$_{4}$ by combining magnetic susceptibility,\nmagnetization, specific heat, and electron spin resonance (ESR) with density\nfunctional calculations. Its monoclinic structure features alternating\nCu$^{2+}$ ($s$ = 1/2) monomers and edge-shared dimers linked by MoO$_{4}$\nunits, forming a distorted diamond chain along the $a$-axis. Antiferromagnetic\norder occurs at $T_{\\rm N}$ = 2.3 K, as evident from a $\\lambda$-type anomaly\nin specific heat and magnetic susceptibility derivatives. Inverse magnetic\nsusceptibility reveals coexisting ferro- and antiferromagnetic interactions.\nSpecific heat and ESR data show two characteristic temperatures: one at 20 K,\nassociated with spin-singlet formation in Cu$_{2}$O$_{9}$ dimers, and another\nat 3.68 K, indicating short-range correlations between dimers and monomers.\nMagnetization measurements reveal a metamagnetic transition at 2.6 T and a\ncritical magnetic field $\\mu_{0}H_{c}$ = 3.4 T, where a 1/3 magnetization\nplateau emerges with saturation near 0.35 $\\mu_{\\rm B}$. Low-temperature\nspecific heat and magnetization data reveal the suppression of long-range order\nat $\\mu_{0}H_{c}$, enabling the construction of a temperature-magnetic field\nphase diagram showing multiple magnetic phases near the $\\mu_{0}H_{c}$. Density\nfunctional theory confirms a distorted diamond chain with $J_{1}$ dimers and\ncompeting $J_2$, $J_4$, $J_3$, and $J_5$ interactions with monomer spins as an\neffective low-temperature spin model.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-21T16:39:41Z"}
{"aid":"http://arxiv.org/abs/2504.15217v1","title":"DRAGON: Distributional Rewards Optimize Diffusion Generative Models","summary":"We present Distributional RewArds for Generative OptimizatioN (DRAGON), a\nversatile framework for fine-tuning media generation models towards a desired\noutcome. Compared with traditional reinforcement learning with human feedback\n(RLHF) or pairwise preference approaches such as direct preference optimization\n(DPO), DRAGON is more flexible. It can optimize reward functions that evaluate\neither individual examples or distributions of them, making it compatible with\na broad spectrum of instance-wise, instance-to-distribution, and\ndistribution-to-distribution rewards. Leveraging this versatility, we construct\nnovel reward functions by selecting an encoder and a set of reference examples\nto create an exemplar distribution. When cross-modality encoders such as CLAP\nare used, the reference examples may be of a different modality (e.g., text\nversus audio). Then, DRAGON gathers online and on-policy generations, scores\nthem to construct a positive demonstration set and a negative set, and\nleverages the contrast between the two sets to maximize the reward. For\nevaluation, we fine-tune an audio-domain text-to-music diffusion model with 20\ndifferent reward functions, including a custom music aesthetics model, CLAP\nscore, Vendi diversity, and Frechet audio distance (FAD). We further compare\ninstance-wise (per-song) and full-dataset FAD settings while ablating multiple\nFAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an\n81.45% average win rate. Moreover, reward functions based on exemplar sets\nindeed enhance generations and are comparable to model-based rewards. With an\nappropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality\nwin rate without training on human preference annotations. As such, DRAGON\nexhibits a new approach to designing and optimizing reward functions for\nimproving human-perceived quality. Sound examples at\nhttps://ml-dragon.github.io/web.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-21T16:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.15219v1","title":"EvalAgent: Discovering Implicit Evaluation Criteria from the Web","summary":"Evaluation of language model outputs on structured writing tasks is typically\nconducted with a number of desirable criteria presented to human evaluators or\nlarge language models (LLMs). For instance, on a prompt like \"Help me draft an\nacademic talk on coffee intake vs research productivity\", a model response may\nbe evaluated for criteria like accuracy and coherence. However, high-quality\nresponses should do more than just satisfy basic task requirements. An\neffective response to this query should include quintessential features of an\nacademic talk, such as a compelling opening, clear research questions, and a\ntakeaway. To help identify these implicit criteria, we introduce EvalAgent, a\nnovel framework designed to automatically uncover nuanced and task-specific\ncriteria. EvalAgent first mines expert-authored online guidance. It then uses\nthis evidence to propose diverse, long-tail evaluation criteria that are\ngrounded in reliable external sources. Our experiments demonstrate that the\ngrounded criteria produced by EvalAgent are often implicit (not directly stated\nin the user's prompt), yet specific (high degree of lexical precision).\nFurther, EvalAgent criteria are often not satisfied by initial responses but\nthey are actionable, such that responses can be refined to satisfy them.\nFinally, we show that combining LLM-generated and EvalAgent criteria uncovers\nmore human-valued criteria than using LLMs alone.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T16:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.15225v1","title":"M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global\n  Scoring and Calibrated Thresholding","summary":"With the widespread availability of sensor data across industrial and\noperational systems, we frequently encounter heterogeneous time series from\nmultiple systems. Anomaly detection is crucial for such systems to facilitate\npredictive maintenance. However, most existing anomaly detection methods are\ndesigned for either univariate or single-system multivariate data, making them\ninsufficient for these complex scenarios. To address this, we introduce\nM$^2$AD, a framework for unsupervised anomaly detection in multivariate time\nseries data from multiple systems. M$^2$AD employs deep models to capture\nexpected behavior under normal conditions, using the residuals as indicators of\npotential anomalies. These residuals are then aggregated into a global anomaly\nscore through a Gaussian Mixture Model and Gamma calibration. We theoretically\ndemonstrate that this framework can effectively address heterogeneity and\ndependencies across sensors and systems. Empirically, M$^2$AD outperforms\nexisting methods in extensive evaluations by 21% on average, and its\neffectiveness is demonstrated on a large-scale real-world case study on 130\nassets in Amazon Fulfillment Centers. Our code and results are available at\nhttps://github.com/sarahmish/M2AD.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T16:57:46Z"}
{"aid":"http://arxiv.org/abs/2504.15231v1","title":"Linear Complementary Pairs of Quasi-Cyclic and Quasi-Twisted Codes","summary":"In this paper, we provide a polynomial characterization of linear\ncomplementary pairs of quasi-cyclic and quasi-twisted codes of index 2. We also\ngive several examples of linear complementary pairs of quasi-cyclic and\nquasi-twisted codes with (almost) optimal security parameters.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T17:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.15233v1","title":"A Review on Privacy in DAG-Based DLTs","summary":"Directed Acyclic Graph (DAG)-based Distributed Ledger Technologies (DLTs)\nhave emerged as a promising solution to the scalability issues inherent in\ntraditional blockchains. However, amidst the focus on scalability, the crucial\naspect of privacy within DAG-based DLTs has been largely overlooked. This paper\nseeks to address this gap by providing a comprehensive examination of privacy\nnotions and challenges within DAG-based DLTs. We delve into potential\nmethodologies to enhance privacy within these systems, while also analyzing the\nassociated hurdles and real-world implementations within state-of-the-art\nDAG-based DLTs. By exploring these methodologies, we not only illuminate the\ncurrent landscape of privacy in DAG-based DLTs but also outline future research\ndirections in this evolving field.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-21T17:08:45Z"}
{"aid":"http://arxiv.org/abs/2504.15235v1","title":"Cascade IPG Observer for Underwater Robot State Estimation","summary":"This paper presents a novel cascade nonlinear observer framework for inertial\nstate estimation. It tackles the problem of intermediate state estimation when\nexternal localization is unavailable or in the event of a sensor outage. The\nproposed observer comprises two nonlinear observers based on a recently\ndeveloped iteratively preconditioned gradient descent (IPG) algorithm. It takes\nthe inputs via an IMU preintegration model where the first observer is a\nquaternion-based IPG. The output for the first observer is the input for the\nsecond observer, estimating the velocity and, consequently, the position. The\nproposed observer is validated on a public underwater dataset and a real-world\nexperiment using our robot platform. The estimation is compared with an\nextended Kalman filter (EKF) and an invariant extended Kalman filter (InEKF).\nResults demonstrate that our method outperforms these methods regarding better\npositional accuracy and lower variance.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.15237v1","title":"Coronal Gas in Magellanic-Analog Dwarfs: Insights from the\n  \\textsc{HESTIA} Simulations","summary":"We characterize the warm circumgalactic medium (CGM) of a dwarf galaxy pair\nwith properties similar to the Magellanic Clouds in the \\textsc{Hestia}\ncosmological simulations. The system consists of a massive dwarf ($M_{\\rm halo}\n\\sim 10^{11.5} M_{\\odot}$) and a lower-mass companion ($M_{\\rm halo} \\sim\n10^{10} M_{\\odot}$), dynamically evolving in isolation before infall into a\nMilky Way-mass halo. The massive dwarf hosts a warm coronal gas envelope with a\ntemperature of $T \\sim 3 \\times 10^5$ K, consistent with expectations for\nvirialized CGM in dwarf halos. Tidal interactions produce a neutral gas stream\nthat extends over $\\sim 150$ kpc, with an \\ion{H}{1} mass of $M_{\\rm HI} \\sim\n10^8 M_{\\odot}$, similar to the Magellanic Stream. Furthermore, in the\n\\textsc{Hestia} simulation suite, we find that coronal gas is ubiquitous in all\nhalos with $M_{\\rm halo} > 10^{11} M_{\\odot}$, implying that massive dwarfs\ngenerically develop extended gaseous envelopes prior to accretion. This result\nhas significant implications for the survival of neutral tidal structures, and\nsuggests that current and future high-ion UV absorption-line observations are\nindicative of warm coronae surrounding LMC-mass dwarfs, independent of their\nenvironment.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T17:13:24Z"}
{"aid":"http://arxiv.org/abs/2504.15244v1","title":"Faster Algorithms for Agnostically Learning Disjunctions and their\n  Implications","summary":"We study the algorithmic task of learning Boolean disjunctions in the\ndistribution-free agnostic PAC model. The best known agnostic learner for the\nclass of disjunctions over $\\{0, 1\\}^n$ is the $L_1$-polynomial regression\nalgorithm, achieving complexity $2^{\\tilde{O}(n^{1/2})}$. This complexity bound\nis known to be nearly best possible within the class of Correlational\nStatistical Query (CSQ) algorithms. In this work, we develop an agnostic\nlearner for this concept class with complexity $2^{\\tilde{O}(n^{1/3})}$. Our\nalgorithm can be implemented in the Statistical Query (SQ) model, providing the\nfirst separation between the SQ and CSQ models in distribution-free agnostic\nlearning.","main_category":"cs.LG","categories":"cs.LG,cs.DS,stat.ML","published":"2025-04-21T17:16:14Z"}
{"aid":"http://arxiv.org/abs/2504.15252v1","title":"SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam","summary":"Understanding and monitoring aquatic biodiversity is critical for ecological\nhealth and conservation efforts. This paper proposes SuoiAI, an end-to-end\npipeline for building a dataset of aquatic invertebrates in Vietnam and\nemploying machine learning (ML) techniques for species classification. We\noutline the methods for data collection, annotation, and model training,\nfocusing on reducing annotation effort through semi-supervised learning and\nleveraging state-of-the-art object detection and classification models. Our\napproach aims to overcome challenges such as data scarcity, fine-grained\nclassification, and deployment in diverse environmental conditions.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.LG","published":"2025-04-21T17:33:02Z"}
{"aid":"http://arxiv.org/abs/2504.15272v1","title":"Superheavy dark matter from the natural inflation in light of the\n  highest-energy astroparticle events","summary":"Superheavy dark matter has been attractive as a candidate of particle dark\nmatter. We propose a \"natural\" particle model, in which the dark matter serves\nas the inflaton in natural inflation, while decaying to high-energy particles\nat energies of $10^{9}-10^{13} \\, \\text{GeV}$ from the prediction of the\ninflation. A scalar field responsible to dilute the dark matter abundance\nrevives the natural inflation. Since the dark matter must be a spin zero\nscalar, we study carefully the galactic dark matter 3-body decay into fermions\nand two body decays into a gluon pair, and point out relevant multi-messenger\nbounds that constrain these decay modes. Interestingly, the predicted energy\nscale may coincide with the AMATERASU event and/or the KM3NeT neutrino event,\nKM3-230213A. We also point out particle models with dark baryon to further\nalleviate $\\gamma$-ray bounds. This scenario yields several testable\npredictions for the UHECR observations, including the highest-energy neutrons\nthat are unaffected by magnetic fields, the tensor-to-scalar ratio, the running\nof spectral indices, $\\alpha_s\\gtrsim\\mathcal{O}(0.001)$, and the existence of\nlight new colored particles that could be accessible at future collider\nexperiments. Further measurements of high energy cosmic rays, including their\ncomponents and detailed coordinates may provide insight into not only the\norigin of the cosmic rays but also inflation.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE","published":"2025-04-21T17:57:50Z"}
{"aid":"http://arxiv.org/abs/2504.15273v1","title":"Efficient Testing Using Surrogate Information","summary":"In modern clinical trials, there is immense pressure to use surrogate markers\nin place of an expensive or long-term primary outcome to make more timely\ndecisions about treatment effectiveness. However, using a surrogate marker to\ntest for a treatment effect can be difficult and controversial. Existing\nmethods tend to either rely on fully parametric methods where strict\nassumptions are made about the relationship between the surrogate and the\noutcome, or assume the surrogate marker is valid for the entire study\npopulation. In this paper, we develop a fully nonparametric method for\nefficient testing using surrogate information (ETSI). Our approach is\nspecifically designed for settings where there is heterogeneity in the utility\nof the surrogate marker, i.e., the surrogate is valid for certain patient\nsubgroups and not others. ETSI enables treatment effect estimation and\nhypothesis testing via kernel-based estimation for a setting where the\nsurrogate is used in place of the primary outcome for individuals for whom the\nsurrogate is valid, and the primary outcome is purposefully only measured in\nthe remaining patients. In addition, we provide a framework for future study\ndesign with power and sample size estimates based on our proposed testing\nprocedure. We demonstrate the performance of our methods via a simulation study\nand application to two distinct HIV clinical trials.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-21T17:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.15277v1","title":"A Short History of (Orbital) Decay: Roman's Prospects for Detecting\n  Dying Planets","summary":"The Roman Space Telescope Galactic Bulge Time Domain Survey (GBTDS) is\nexpected to detect ~10^5 transiting planets. Many of these planets will have\nshort orbital periods and are thus susceptible to tidal decay. We use a catalog\nof simulated transiting planet detections to predict the yield of orbital decay\ndetections in the Roman GBTDS. Assuming a constant stellar tidal dissipation\nfactor, Q^{'}_{*}, of 10^6, we predict ~ 5 - 10 detections. We additionally\nconsider an empirical period-dependent parameterization of Q^{'}_{*} \\propto\nP^{-3} and find a substantially suppressed yield. We conclude that Roman will\nprovide constraints on the rate of planet engulfment in the Galaxy and probe\nthe physics of tidal dissipation in stars.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA,astro-ph.IM,astro-ph.SR","published":"2025-04-21T17:59:12Z"}
{"aid":"http://arxiv.org/abs/2504.15283v1","title":"Simultaneously Modelling Dusty Star Forming Galaxies and Massive\n  Quiescents: A Calibration Framework for Galaxy Formation Models","summary":"Galaxy formation models, particularly semi-analytic models (SAMs), rely on\ndifferential equations with free parameters to describe the physical mechanisms\ngoverning galaxy formation and evolution. Traditionally, most SAMs calibrate\nthese parameters manually to match observational data. However, this approach\nfails to fully explore the multidimensional parameter space, resulting in\nlimited robustness and inconsistency with some observations. In contrast, the\nL-Galaxies SAM features a unique Markov Chain Monte Carlo (MCMC) mode, enabling\nrobust model calibration. Using this functionality, we address a long-standing\ntension in galaxy formation models: simultaneously reproducing the number\ndensities of dusty star-forming galaxies (DSFGs) and high-redshift massive\nquiescent galaxies (MQs). We test nine combinations of observational\nconstraints - including stellar mass functions, quiescent fractions, neutral\nhydrogen mass functions, and DSFG number densities - across different\nredshifts. We then analyze the resulting galaxy property predictions and\ndiscuss the underlying physical mechanisms. Our results identify a model that\nreasonably matches the number density of DSFGs while remaining consistent with\nobservationally-derived lower limits on the number density of high-redshift\nMQs. This model requires high star formation efficiencies in mergers and a null\ndependency of supermassive black hole (SMBH) cold gas accretion on halo mass,\nfacilitating rapid stellar mass and SMBH growth. Additionally, our findings\nhighlight the importance of robust calibration procedures to address the\nsignificant degeneracies inherent to multidimensional galaxy formation models.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.15549v1","title":"Do It For Me vs. Do It With Me: Investigating User Perceptions of\n  Different Paradigms of Automation in Copilots for Feature-Rich Software","summary":"Large Language Model (LLM)-based in-application assistants, or copilots, can\nautomate software tasks, but users often prefer learning by doing, raising\nquestions about the optimal level of automation for an effective user\nexperience. We investigated two automation paradigms by designing and\nimplementing a fully automated copilot (AutoCopilot) and a semi-automated\ncopilot (GuidedCopilot) that automates trivial steps while offering\nstep-by-step visual guidance. In a user study (N=20) across data analysis and\nvisual design tasks, GuidedCopilot outperformed AutoCopilot in user control,\nsoftware utility, and learnability, especially for exploratory and creative\ntasks, while AutoCopilot saved time for simpler visual tasks. A follow-up\ndesign exploration (N=10) enhanced GuidedCopilot with task-and state-aware\nfeatures, including in-context preview clips and adaptive instructions. Our\nfindings highlight the critical role of user control and tailored guidance in\ndesigning the next generation of copilots that enhance productivity, support\ndiverse skill levels, and foster deeper software engagement.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.LG","published":"2025-04-22T03:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.15556v1","title":"Dynamical mean-field analysis of adaptive Langevin diffusions:\n  Propagation-of-chaos and convergence of the linear response","summary":"Motivated by an application to empirical Bayes learning in high-dimensional\nregression, we study a class of Langevin diffusions in a system with random\ndisorder, where the drift coefficient is driven by a parameter that\ncontinuously adapts to the empirical distribution of the realized process up to\nthe current time. The resulting dynamics take the form of a stochastic\ninteracting particle system having both a McKean-Vlasov type interaction and a\npairwise interaction defined by the random disorder. We prove a\npropagation-of-chaos result, showing that in the large system limit over\ndimension-independent time horizons, the empirical distribution of sample paths\nof the Langevin process converges to a deterministic limit law that is\ndescribed by dynamical mean-field theory. This law is characterized by a system\nof dynamical fixed-point equations for the limit of the drift parameter and for\nthe correlation and response kernels of the limiting dynamics. Using a\ndynamical cavity argument, we verify that these correlation and response\nkernels arise as the asymptotic limits of the averaged correlation and linear\nresponse functions of single coordinates of the system. These results enable an\nasymptotic analysis of an empirical Bayes Langevin dynamics procedure for\nlearning an unknown prior parameter in a linear regression model, which we\ndevelop in a companion paper.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-04-22T03:20:58Z"}
{"aid":"http://arxiv.org/abs/2504.15561v1","title":"SPECI: Skill Prompts based Hierarchical Continual Imitation Learning for\n  Robot Manipulation","summary":"Real-world robot manipulation in dynamic unstructured environments requires\nlifelong adaptability to evolving objects, scenes and tasks. Traditional\nimitation learning relies on static training paradigms, which are ill-suited\nfor lifelong adaptation. Although Continual Imitation Learnin (CIL) enables\nincremental task adaptation while preserving learned knowledge, current CIL\nmethods primarily overlook the intrinsic skill characteristics of robot\nmanipulation or depend on manually defined and rigid skills, leading to\nsuboptimal cross-task knowledge transfer. To address these issues, we propose\nSkill Prompts-based HiErarchical Continual Imitation Learning (SPECI), a novel\nend-to-end hierarchical CIL policy architecture for robot manipulation. The\nSPECI framework consists of a multimodal perception and fusion module for\nheterogeneous sensory information encoding, a high-level skill inference module\nfor dynamic skill extraction and selection, and a low-level action execution\nmodule for precise action generation. To enable efficient knowledge transfer on\nboth skill and task levels, SPECI performs continual implicit skill acquisition\nand reuse via an expandable skill codebook and an attention-driven skill\nselection mechanism. Furthermore, we introduce mode approximation to augment\nthe last two modules with task-specific and task-sharing parameters, thereby\nenhancing task-level knowledge transfer. Extensive experiments on diverse\nmanipulation task suites demonstrate that SPECI consistently outperforms\nstate-of-the-art CIL methods across all evaluated metrics, revealing\nexceptional bidirectional knowledge transfer and superior overall performance.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-22T03:30:38Z"}
{"aid":"http://arxiv.org/abs/2504.15566v1","title":"Minimization of Curve Length through Energy Minimization using Finite\n  Difference and Numerical Integration in Real Coordinate Space","summary":"The problem of determining the minimal length is garnering attention in\nvarious fields such as computer vision, robotics, and machine learning. One\nsolution to this problem involves linearly interpolating the solution of a\nnonlinear optimization problem that approximates the curve's energy\nminimization problem using finite differences and numerical integration. This\nmethod tends to be easier to implement compared to others. However, it was\npreviously unknown whether this approach successfully minimizes the curve's\nlength under the Riemannian metric in real coordinate spaces. In this paper, we\nprove that the length of a curve obtained by linear interpolation of the\nsolution to an optimization problem, where the energy of the curve is\napproximated using finite differences and the trapezoidal rule, converges to\nthe minimal curve length at a rate of $1/2$ in terms of the number of points\nused in the numerical integration. Similarly, we prove that when using the\nleft-point rule, the approximated curve's length likewise converges to the\nminimal curve length at a rate of $1/2$ in terms of the number of points used\nin the numerical integration.","main_category":"math.NA","categories":"math.NA,cs.NA,math.DG,math.OC","published":"2025-04-22T03:35:08Z"}
{"aid":"http://arxiv.org/abs/2504.15577v1","title":"State-Aware IoT Scheduling Using Deep Q-Networks and Edge-Based\n  Coordination","summary":"This paper addresses the challenge of energy efficiency management faced by\nintelligent IoT devices in complex application environments. A novel\noptimization method is proposed, combining Deep Q-Network (DQN) with an edge\ncollaboration mechanism. The method builds a state-action-reward interaction\nmodel and introduces edge nodes as intermediaries for state aggregation and\npolicy scheduling. This enables dynamic resource coordination and task\nallocation among multiple devices. During the modeling process, device status,\ntask load, and network resources are jointly incorporated into the state space.\nThe DQN is used to approximate and learn the optimal scheduling strategy. To\nenhance the model's ability to perceive inter-device relationships, a\ncollaborative graph structure is introduced to model the multi-device\nenvironment and assist in decision optimization. Experiments are conducted\nusing real-world IoT data collected from the FastBee platform. Several\ncomparative and validation tests are performed, including energy efficiency\ncomparisons across different scheduling strategies, robustness analysis under\nvarying task loads, and evaluation of state dimension impacts on policy\nconvergence speed. The results show that the proposed method outperforms\nexisting baseline approaches in terms of average energy consumption, processing\nlatency, and resource utilization. This confirms its effectiveness and\npracticality in intelligent IoT scenarios.","main_category":"cs.NI","categories":"cs.NI,cs.LG","published":"2025-04-22T04:24:16Z"}
{"aid":"http://arxiv.org/abs/2504.15596v1","title":"Forcibly unicyclic and bicyclic graphic sequences","summary":"A sequence $D=(d_1,d_2,\\ldots,d_n)$ of non-negative integers is called a\ngraphic sequence if there is a simple graph with vertices $v_1,v_2,\\ldots,v_n$\nsuch that the degree of $v_i$ is $d_i$ for $1\\leq i\\leq n$. Given a graph\ntheoretical property $\\mathcal{P}$, a graphic sequence $D$ is forcibly\n$\\mathcal{P}$ graphic if each graph with degree sequence $D$ has property\n$\\mathcal{P}$. A graph is acyclic if it contains no cycles. A connected acyclic\ngraph is just a tree and has $n-1$ edges. A graph of order $n$ is unicyclic\n(resp. bicyclic) if it is connected and has $n$ (resp. $n+1$) edges. Bar-Noy,\nB\\\"{o}hnlein, Peleg and Rawitz [Discrete Mathematics 346 (2023) 113460]\ncharacterized forcibly acyclic and forcibly connected acyclic graphic\nsequences. In this paper, we aim to characterize forcibly unicyclic and\nforcibly bicyclic graphic sequences.","main_category":"math.CO","categories":"math.CO","published":"2025-04-22T05:24:48Z"}
{"aid":"http://arxiv.org/abs/2504.15611v1","title":"An ACO-MPC Framework for Energy-Efficient and Collision-Free Path\n  Planning in Autonomous Maritime Navigation","summary":"Automated driving on ramps presents significant challenges due to the need to\nbalance both safety and efficiency during lane changes. This paper proposes an\nintegrated planner for automated vehicles (AVs) on ramps, utilizing an\nunsatisfactory level metric for efficiency and arrow-cluster-based sampling for\nsafety. The planner identifies optimal times for the AV to change lanes, taking\ninto account the vehicle's velocity as a key factor in efficiency.\nAdditionally, the integrated planner employs arrow-cluster-based sampling to\nevaluate collision risks and select an optimal lane-changing curve. Extensive\nsimulations were conducted in a ramp scenario to verify the planner's efficient\nand safe performance. The results demonstrate that the proposed planner can\neffectively select an appropriate lane-changing time point and a safe\nlane-changing curve for AVs, without incurring any collisions during the\nmaneuver.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-22T06:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.15615v1","title":"Dimension-Free Decision Calibration for Nonlinear Loss Functions","summary":"When model predictions inform downstream decision making, a natural question\nis under what conditions can the decision-makers simply respond to the\npredictions as if they were the true outcomes. Calibration suffices to\nguarantee that simple best-response to predictions is optimal. However,\ncalibration for high-dimensional prediction outcome spaces requires exponential\ncomputational and statistical complexity. The recent relaxation known as\ndecision calibration ensures the optimality of the simple best-response rule\nwhile requiring only polynomial sample complexity in the dimension of outcomes.\nHowever, known results on calibration and decision calibration crucially rely\non linear loss functions for establishing best-response optimality. A natural\napproach to handle nonlinear losses is to map outcomes $y$ into a feature space\n$\\phi(y)$ of dimension $m$, then approximate losses with linear functions of\n$\\phi(y)$. Unfortunately, even simple classes of nonlinear functions can demand\nexponentially large or infinite feature dimensions $m$. A key open problem is\nwhether it is possible to achieve decision calibration with sample complexity\nindependent of~$m$. We begin with a negative result: even verifying decision\ncalibration under standard deterministic best response inherently requires\nsample complexity polynomial in~$m$. Motivated by this lower bound, we\ninvestigate a smooth version of decision calibration in which decision-makers\nfollow a smooth best-response. This smooth relaxation enables dimension-free\ndecision calibration algorithms. We introduce algorithms that, given\n$\\mathrm{poly}(|A|,1/\\epsilon)$ samples and any initial predictor~$p$, can\nefficiently post-process it to satisfy decision calibration without worsening\naccuracy. Our algorithms apply broadly to function classes that can be\nwell-approximated by bounded-norm functions in (possibly infinite-dimensional)\nseparable RKHS.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-22T06:14:23Z"}
{"aid":"http://arxiv.org/abs/2504.15643v1","title":"Multimodal Perception for Goal-oriented Navigation: A Survey","summary":"Goal-oriented navigation presents a fundamental challenge for autonomous\nsystems, requiring agents to navigate complex environments to reach designated\ntargets. This survey offers a comprehensive analysis of multimodal navigation\napproaches through the unifying perspective of inference domains, exploring how\nagents perceive, reason about, and navigate environments using visual,\nlinguistic, and acoustic information. Our key contributions include organizing\nnavigation methods based on their primary environmental reasoning mechanisms\nacross inference domains; systematically analyzing how shared computational\nfoundations support seemingly disparate approaches across different navigation\ntasks; identifying recurring patterns and distinctive strengths across various\nnavigation paradigms; and examining the integration challenges and\nopportunities of multimodal perception to enhance navigation capabilities. In\naddition, we review approximately 200 relevant articles to provide an in-depth\nunderstanding of the current landscape.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T07:01:00Z"}
{"aid":"http://arxiv.org/abs/2504.15648v1","title":"A diagrammatic approach to correlation functions in superfluids","summary":"Renaud Parentani has given a vast contribution to the development of\ngravitational analogue models as tools to explore various important aspects of\ngeneral relativity and of quantum field theory in curved space-time. In these\nsystems, two-point correlation functions are of the utmost importance for the\ncharacterization of processes taking place close to the acoustic horizon. In\nthe present paper, dedicated to him, we present a study of path integral\nmethods that allow to determine two-point correlation functions by a\nperturbative expansion, in a way that -- beyond its generality -- is especially\nsuited to analyze these processes. Our results apply to non-relativistic\nsuperfluids, realizable in terrestrial experiments, as well as to relativistic\nsuperfluids, relevant for compact stellar objects.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,hep-ph","published":"2025-04-22T07:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.15653v1","title":"On a geometric comparison of representations of real and $p$-adic\n  $\\mathbf{GL}_n$","summary":"In this paper, we use geometric methods to study the relations between\nadmissible representations of $\\mathbf{GL}_n(\\mathbb{C})$ and unramified\nrepresentations of $\\mathbf{GL}_m(\\mathbb{Q}_p)$. We show that the geometric\nrelationship between Langlands parameter spaces of $\\mathbf{GL}_n(\\mathbb{C})$\nand $\\mathbf{GL}_m(\\mathbb{Q}_p)$ constructed by the first named author is\ncompatible with the functor recently defined algebraically by Chan-Wong. We\nthen show that the said relationship intertwines translation functors on\nrepresentations of $\\mathbf{GL}_n(\\mathbb{C})$ and partial\nBernstein-Zelevinskii derivatives on representations of\n$\\mathbf{GL}_m(\\mathbb{Q}_p)$, providing purely geometric counterparts to some\nresults of Chan-Wong. In the sequels, the techniques of this work will be\nextended to other classical groups and used to study their Arthur packets.","main_category":"math.RT","categories":"math.RT","published":"2025-04-22T07:21:00Z"}
{"aid":"http://arxiv.org/abs/2504.15656v1","title":"Existence and multiplicity of $L^2$-Normalized solutions for the\n  periodic Schrödinger system of Hamiltonian type","summary":"In this paper, we study the following nonlinear Schr\\\"{o}dinger system of\nHamiltonian type \\begin{equation*} \\left\\{\\begin{array}{l} -\\Delta\nu+V(x)u=\\partial_v H(x,u,v)+\\omega v, \\ x \\in \\mathbb{R}^N, \\\\ -\\Delta\nv+V(x)v=\\partial_u H(x,u,v)+\\omega u,\\ x \\in \\mathbb{R}^N, \\\\\n\\displaystyle\\int_{\\mathbb{R}^N}|z|^2dx=a^2, \\end{array}\\right. \\end{equation*}\nwhere the potential function $V(x)$ is periodic,\n$z:=(u,v):\\mathbb{R}^N\\rightarrow \\mathbb{R}\\times\\mathbb{R}$, $\\omega\\in\n\\mathbb{R}$ arises as a Lagrange multiplier, $a>0$ is a prescribed constant.\nThe main result in this paper establishes the existence and multiplicity of\n$L^2$-normalized solutions for the above nonlinear Schr\\\"{o}dinger system with\na class of non-autonomous nonlinearity $H(x,u,v)$. The proofs combine\nLyapunov-Schmidt reduction, perturbation argument and the multiplicity theorem\nof Ljusternik-Schnirelmann. In addition, we obtain bifurcation results of this\nproblem.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T07:26:52Z"}
{"aid":"http://arxiv.org/abs/2504.15668v1","title":"Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid\n  Planning Problems","summary":"Explaining unsolvability of planning problems is of significant research\ninterest in Explainable AI Planning. AI planning literature has reported\nseveral research efforts on generating explanations of solutions to planning\nproblems. However, explaining the unsolvability of planning problems remains a\nlargely open and understudied problem. A widely practiced approach to plan\ngeneration and automated problem solving, in general, is to decompose tasks\ninto sub-problems that help progressively converge towards the goal. In this\npaper, we propose to adopt the same philosophy of sub-problem identification as\na mechanism for analyzing and explaining unsolvability of planning problems in\nhybrid systems. In particular, for a given unsolvable planning problem, we\npropose to identify common waypoints, which are universal obstacles to plan\nexistence; in other words, they appear on every plan from the source to the\nplanning goal. This work envisions such waypoints as sub-problems of the\nplanning problem and the unreachability of any of these waypoints as an\nexplanation for the unsolvability of the original planning problem. We propose\na novel method of waypoint identification by casting the problem as an instance\nof the longest common subsequence problem, a widely popular problem in computer\nscience, typically considered as an illustrative example for the dynamic\nprogramming paradigm. Once the waypoints are identified, we perform symbolic\nreachability analysis on them to identify the earliest unreachable waypoint and\nreport it as the explanation of unsolvability. We present experimental results\non unsolvable planning problems in hybrid domains.","main_category":"cs.AI","categories":"cs.AI,cs.FL","published":"2025-04-22T07:45:30Z"}
{"aid":"http://arxiv.org/abs/2504.15682v1","title":"The essential norm of Toeplitz operators between Bergman spaces induced\n  by doubling weights","summary":"This paper investigates the essential norm of Toeplitz operators\n$\\mathcal{T}_\\mu$ acting from the Bergman space $A_\\omega^p$ to $A_\\omega^q$\n($1 < p \\leq q < \\infty$) on the unit ball, where $\\mu$ is a positive Borel\nmeasure and $\\omega \\in \\mathcal{D}$ (a class of doubling weights). Leveraging\nthe geometric properties of Carleson blocks and the structure of radial\ndoubling weights, we establish sharp estimates for the essential norm in terms\nof the asymptotic behavior of $\\mu$ near the boundary. As a consequence, we\nresolve the boundedness-to-compactness transition for these operators when $1 <\nq < p<\\infty$, showing that the essential norm vanishes exactly. These results\ngeneralize classical theorems for the unweighted Bergman space ($\\omega \\equiv\n1$) and provide a unified framework for studying Toeplitz operators under both\nradial and non-radial doubling weights in higher-dimensional settings.","main_category":"math.FA","categories":"math.FA","published":"2025-04-22T08:05:56Z"}
{"aid":"http://arxiv.org/abs/2504.15683v1","title":"FinTextSim: Enhancing Financial Text Analysis with BERTopic","summary":"Recent advancements in information availability and computational\ncapabilities have transformed the analysis of annual reports, integrating\ntraditional financial metrics with insights from textual data. To extract\nvaluable insights from this wealth of textual data, automated review processes,\nsuch as topic modeling, are crucial. This study examines the effectiveness of\nBERTopic, a state-of-the-art topic model relying on contextual embeddings, for\nanalyzing Item 7 and Item 7A of 10-K filings from S&P 500 companies\n(2016-2022). Moreover, we introduce FinTextSim, a finetuned\nsentence-transformer model optimized for clustering and semantic search in\nfinancial contexts. Compared to all-MiniLM-L6-v2, the most widely used\nsentence-transformer, FinTextSim increases intratopic similarity by 81% and\nreduces intertopic similarity by 100%, significantly enhancing organizational\nclarity. We assess BERTopic's performance using embeddings from both FinTextSim\nand all-MiniLM-L6-v2. Our findings reveal that BERTopic only forms clear and\ndistinct economic topic clusters when paired with FinTextSim's embeddings.\nWithout FinTextSim, BERTopic struggles with misclassification and overlapping\ntopics. Thus, FinTextSim is pivotal for advancing financial text analysis.\nFinTextSim's enhanced contextual embeddings, tailored for the financial domain,\nelevate the quality of future research and financial information. This improved\nquality of financial information will enable stakeholders to gain a competitive\nadvantage, streamlining resource allocation and decision-making processes.\nMoreover, the improved insights have the potential to leverage business\nvaluation and stock price prediction models.","main_category":"cs.CL","categories":"cs.CL,cs.LG,econ.GN,q-fin.EC,q-fin.GN","published":"2025-04-22T08:06:37Z"}
{"aid":"http://arxiv.org/abs/2504.15685v1","title":"Monte Carlo simulation of GRB data to test Lorentz-invariance violation","summary":"Lorentz-invariance violation (LV) at energy scales approaching the Planck\nregime serves as a critical probe for understanding quantum gravity\nphenomenology. Astrophysical observations of gamma-ray bursts (GRBs) present a\npromising avenue for testing LV-induced spectral lag phenomena; however,\ninterpretations are complicated by degeneracies between LV effects and\nintrinsic emission delays. This study systematically investigates three\ncompeting time delay models: Model A (LV delay combined with a constant\nintrinsic delay), Model B (energy-dependent intrinsic delay without LV), and\nModel C (LV delay combined with energy-dependent intrinsic delay). We utilize\nmock GRB datasets generated under distinct delay mechanisms and employ Bayesian\nparameter estimation on simulated observations of 10 GRBs. Our findings\ndemonstrate that Model C consistently recovers input parameters across all\ndatasets. In contrast, Models A and B struggle to reconcile data generated\nunder alternative mechanisms, particularly when confronted with high-energy TeV\nphotons from GRB 190114C and GRB 221009A. Our analysis confirms that the\nincorporation of energy-dependent intrinsic delays in Model C is essential for\nestablishing robust LV constraints, effectively resolving prior ambiguities in\nthe interpretation of multi-GeV and TeV photon emissions. The results validate\nModel C as a generalized framework for future LV searches, yielding a\nsubluminal LV scale of \\(E_{\\rm LV} \\simeq 3 \\times 10^{17}\\) GeV based on\nrealistic datasets. These findings are consistent with earlier constraints\nderived from Fermi-LAT datasets. This work underscores the necessity for joint\nmodeling of LV and astrophysical emission processes in next-generation LV\nstudies utilizing observatories such as LHAASO and CTA.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE,gr-qc","published":"2025-04-22T08:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.15694v1","title":"You Sense Only Once Beneath: Ultra-Light Real-Time Underwater Object\n  Detection","summary":"Despite the remarkable achievements in object detection, the model's accuracy\nand efficiency still require further improvement under challenging underwater\nconditions, such as low image quality and limited computational resources. To\naddress this, we propose an Ultra-Light Real-Time Underwater Object Detection\nframework, You Sense Only Once Beneath (YSOOB). Specifically, we utilize a\nMulti-Spectrum Wavelet Encoder (MSWE) to perform frequency-domain encoding on\nthe input image, minimizing the semantic loss caused by underwater optical\ncolor distortion. Furthermore, we revisit the unique characteristics of\neven-sized and transposed convolutions, allowing the model to dynamically\nselect and enhance key information during the resampling process, thereby\nimproving its generalization ability. Finally, we eliminate model redundancy\nthrough a simple yet effective channel compression and reconstructed large\nkernel convolution (RLKC) to achieve model lightweight. As a result, forms a\nhigh-performance underwater object detector YSOOB with only 1.2 million\nparameters. Extensive experimental results demonstrate that, with the fewest\nparameters, YSOOB achieves mAP50 of 83.1% and 82.9% on the URPC2020 and DUO\ndatasets, respectively, comparable to the current SOTA detectors. The inference\nspeed reaches 781.3 FPS and 57.8 FPS on the T4 GPU (TensorRT FP16) and the edge\ncomputing device Jetson Xavier NX (TensorRT FP16), surpassing YOLOv12-N by\n28.1% and 22.5%, respectively.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T08:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.15706v1","title":"Distributed Compression for Computation and Bounds on the Optimal Rate","summary":"We address the problem of distributed computation of arbitrary functions of\ntwo correlated sources $X_1$ and $X_2$, residing in two distributed source\nnodes, respectively. We exploit the structure of a computation task by coding\nsource characteristic graphs (and multiple instances using the $n$-fold OR\nproduct of this graph with itself). For regular graphs and general graphs, we\nestablish bounds on the optimal rate -- characterized by the chromatic entropy\nfor the $n$-fold graph products -- that allows a receiver for asymptotically\nlossless computation of arbitrary functions over finite fields. For the special\nclass of cycle graphs (i.e., $2$-regular graphs), we establish an exact\ncharacterization of chromatic numbers and derive bounds on the required rates.\nNext, focusing on the more general class of $d$-regular graphs, we establish\nconnections between $d$-regular graphs and expansion rates for $n$-fold graph\npowers using graph spectra. Finally, for general graphs, we leverage the\nGershgorin Circle Theorem (GCT) to provide a characterization of the spectra,\nwhich allows us to build new bounds on the optimal rate. Our codes leverage the\nspectra of the computation and provide a graph expansion-based characterization\nto efficiently/succinctly capture the computation structure, providing new\ninsights into the problem of distributed computation of arbitrary functions.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-22T08:47:40Z"}
{"aid":"http://arxiv.org/abs/2504.15710v1","title":"Prediction of CO2 reduction reaction intermediates and products on\n  transition metal-doped r-GeSe monolayers:A combined DFT and machine learning\n  approach","summary":"The electrocatalytic CO2 reduction reaction (CO2RR) is a complex\nmulti-proton-electron transfer process that generates a vast network of\nreaction intermediates. Accurate prediction of free energy changes (G) of these\nintermediates and products is essential for evaluating catalytic performance.\nWe combined density functional theory (DFT) and machine learning (ML) to screen\n25 single-atom catalysts (SACs) on defective r-GeSe monolayers for CO2\nreduction to methanol, methane, and formic acid. Among nine ML models evaluated\nwith 14 intrinsic and DFT-based features, the XGBoost performed best (R2 = 0.92\nand MAE = 0.24 eV), aligning closely with DFT calculations and identifying Ni,\nRu, and Rh@GeSe as prospective catalysts. Feature importance analysis in free\nenergy and product predictions highlighted the significance of CO2 activation\nwith O-C-O and IPC-O1 as the key attributes. Furthermore, by incorporating\nnon-DFT-based features, rapid predictions became possible, and the XGBoost\nmodel retained its predictive performance with R2 = 0.89 and MAE = 0.29 eV.\nThis accuracy was further validated using Ir@GeSe. Our work highlights\neffective SACs for CO2RR, and provides valuable insights for efficient catalyst\ndesign.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-22T08:52:18Z"}
{"aid":"http://arxiv.org/abs/2504.15719v1","title":"Implementing Rational Choice Functions with LLMs and Measuring their\n  Alignment with User Preferences","summary":"As large language models (LLMs) become integral to intelligent user\ninterfaces (IUIs), their role as decision-making agents raises critical\nconcerns about alignment. Although extensive research has addressed issues such\nas factuality, bias, and toxicity, comparatively little attention has been paid\nto measuring alignment to preferences, i.e., the relative desirability of\ndifferent alternatives, a concept used in decision making, economics, and\nsocial choice theory. However, a reliable decision-making agent makes choices\nthat align well with user preferences.\n  In this paper, we generalize existing methods that exploit LLMs for ranking\nalternative outcomes by addressing alignment with the broader and more flexible\nconcept of user preferences, which includes both strict preferences and\nindifference among alternatives. To this end, we put forward design principles\nfor using LLMs to implement rational choice functions, and provide the\nnecessary tools to measure preference satisfaction. We demonstrate the\napplicability of our approach through an empirical study in a practical\napplication of an IUI in the automotive domain.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-22T09:08:21Z"}
{"aid":"http://arxiv.org/abs/2504.15739v1","title":"Development of an Ultra-fast, Likelihood-based, Distance Inference\n  Framework for the Next Generation of Type Ia Supernova Surveys","summary":"In this work, we present EDRIS (French for Distance Estimator for Incomplete\nSupernova Surveys), a cosmological inference framework tailored to reconstruct\nunbiased cosmological distances from type Ia supernovae light-curve parameters.\nThis goal is achieved by including data truncation directly in the statistical\nmodel which takes care of the standardization of luminosity distances. It\nallows us to build a single-step distance estimate by maximizing the\ncorresponding likelihood, free from the biases the survey detection limits\nwould introduce otherwise. Moreover, we expect the current worldwide statistics\nto be multiplied by O(10) in the upcoming years. This provides a new challenge\nto handle as the cosmological analysis must stay computationally towable. We\nshow that the optimization methods used in EDRIS allow for a reasonable time\ncomplexity of O($N^2$) resulting in a very fast inference process (O(10s) for\n1500 supernovae).","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-22T09:36:07Z"}
{"aid":"http://arxiv.org/abs/2504.15741v1","title":"Stochastic Programming for Dynamic Temperature Control of Refrigerated\n  Road Transport","summary":"Temperature control in refrigerated delivery vehicles is critical for\npreserving product quality, yet existing approaches neglect critical\noperational uncertainties, such as stochastic door opening durations and\nheterogeneous initial product temperatures. We propose a framework to optimize\ncooling policies for refrigerated trucks on fixed routes by explicitly modeling\nthese uncertainties while capturing all relevant thermodynamic interactions in\nthe trailer. To this end, we integrate high-fidelity thermodynamic modeling\nwith a multistage stochastic programming formulation and solve the resulting\nproblem using stochastic dual dynamic programming. In cooperation with industry\npartners and based on real-world data, we set up computational experiments that\ndemonstrate that our stochastic policy consistently outperforms the best\ndeterministic benchmark by 35% on average while being computationally\ntractable. In a separate analysis, we show that by fixing the duration of\ntemperature violations, our policy operates with up to $40$\\% less fuel than\ndeterministic policies. Our results demonstrate that pallet-level thermal\nstatus information is the single most crucial information in the problem and\ncan be used to significantly reduce temperature violations. Knowledge of the\ntiming and length of customer stops is the second most important factor and,\ntogether with detailed modeling of thermodynamic interactions, can be used to\nfurther significantly reduce violations. Our analysis of the optimal stochastic\ncooling policy reveals that preemptive cooling before a stop is the key element\nof an optimal policy. These findings highlight the value of sophisticated\ncontrol strategies in maintaining the quality of perishable products while\nreducing the carbon footprint of the industry and improving operational\nefficiency.","main_category":"math.OC","categories":"math.OC","published":"2025-04-22T09:45:36Z"}
{"aid":"http://arxiv.org/abs/2504.15745v1","title":"Search for lepton-flavor-violating $τ^- \\to \\ell^- K_s^0$ decays at\n  Belle and Belle II","summary":"We present the results of a search for charged-lepton-flavor violating decays\n$\\tau^{-} \\rightarrow \\ell^{-}K_{S}^{0}$, where $\\ell^{-}$ is either an\nelectron or a muon. We combine $e^+e^-$ data samples recorded by the Belle II\nexperiment at the SuperKEKB collider (428 fb$^{-1}$) with samples recorded by\nthe Belle experiment at the KEKB collider (980 fb$^{-1}$) to obtain a sample of\n1.3 billion $e^+e^-\\to\\tau^+\\tau^-$ events. We observe 0 and 1 events and set\n$90\\%$ confidence level upper limits of $0.8 \\times 10^{-8}$ and $1.2 \\times\n10^{-8}$ on the branching fractions of the decay modes $\\tau^{-} \\rightarrow\ne^{-}K_{S}^{0}$ and $\\tau^{-} \\rightarrow \\mu^{-}K_{S}^{0}$, respectively.\nThese are the most stringent upper limits to date.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-22T09:46:45Z"}
{"aid":"http://arxiv.org/abs/2504.15759v1","title":"An equivalence theorem for algebraic and functorial QFT","summary":"This paper develops a novel approach to functorial quantum field theories\n(FQFTs) in the context of Lorentzian geometry. The key challenge is that\nglobally hyperbolic Lorentzian bordisms between two Cauchy surfaces cannot\nchange the topology of the Cauchy surface. This is addressed and solved by\nintroducing a more flexible concept of bordisms which provide morphisms from\ntuples of causally disjoint partial Cauchy surfaces to a later-in-time full\nCauchy surface. They assemble into a globally hyperbolic Lorentzian bordism\npseudo-operad, generalizing the geometric bordism pseudo-categories of Stolz\nand Teichner. The associated FQFTs are defined as pseudo-multifunctors into a\nsymmetric monoidal category of unital associative algebras. The main result of\nthis paper is an equivalence theorem between such globally hyperbolic\nLorentzian FQFTs and algebraic quantum field theories (AQFTs), both subject to\nthe time-slice axiom and a mild descent condition called additivity.","main_category":"math-ph","categories":"math-ph,hep-th,math.DG,math.MP,math.QA","published":"2025-04-22T10:11:48Z"}
{"aid":"http://arxiv.org/abs/2504.15763v1","title":"Modulus of continuity of Monge--Ampère potentials in big cohomology\n  classes","summary":"In this paper, we prove a uniform estimate for the modulus of continuity of\nsolutions to degenerate complex Monge--Amp\\`ere equation in big cohomology\nclasses. This improves the previous results of Di Nezza--Lu and of the first\nauthor.","main_category":"math.CV","categories":"math.CV","published":"2025-04-22T10:17:09Z"}
{"aid":"http://arxiv.org/abs/2504.15765v1","title":"Quantum Aberrations: Entangling Photons with Zernike Polynomials","summary":"In this work, we explore Zernike modes as a novel degree of freedom for\nquantum information processing. We propose procedures for generating photons in\nthese modes as well as for their manipulation, entanglement, and detection.\nEntanglement in Zernike modes is demonstrated analytically for the two-photon\nstate produced via spontaneous parametric down-conversion. This entanglement\narises from specific constraints on the mode indices of the expansion\ncoefficients of the down-converted Zernike fields.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T10:18:39Z"}
{"aid":"http://arxiv.org/abs/2504.15776v1","title":"Pose Optimization for Autonomous Driving Datasets using Neural Rendering\n  Models","summary":"Autonomous driving systems rely on accurate perception and localization of\nthe ego car to ensure safety and reliability in challenging real-world driving\nscenarios. Public datasets play a vital role in benchmarking and guiding\nadvancement in research by providing standardized resources for model\ndevelopment and evaluation. However, potential inaccuracies in sensor\ncalibration and vehicle poses within these datasets can lead to erroneous\nevaluations of downstream tasks, adversely impacting the reliability and\nperformance of the autonomous systems. To address this challenge, we propose a\nrobust optimization method based on Neural Radiance Fields (NeRF) to refine\nsensor poses and calibration parameters, enhancing the integrity of dataset\nbenchmarks. To validate improvement in accuracy of our optimized poses without\nground truth, we present a thorough evaluation process, relying on reprojection\nmetrics, Novel View Synthesis rendering quality, and geometric alignment. We\ndemonstrate that our method achieves significant improvements in sensor pose\naccuracy. By optimizing these critical parameters, our approach not only\nimproves the utility of existing datasets but also paves the way for more\nreliable autonomous driving models. To foster continued progress in this field,\nwe make the optimized sensor poses publicly available, providing a valuable\nresource for the research community.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-22T10:33:01Z"}
{"aid":"http://arxiv.org/abs/2504.15781v1","title":"Interacting Immediate Neighbour Interpolation for Geoscientific Data","summary":"A diverse range of interpolation methods, including Kriging, spline/minimum\ncurvature and radial basis function interpolation exist for interpolating\nspatially incomplete geoscientific data. Such methods use various spatial\nproperties of the observed data to infer its local and global behaviour. In\nthis study, we exploit the adaptability of locally interacting systems from\nstatistical physics and develop an interpolation framework for numerical\ngeoscientific data called Interacting Immediate Neighbour Interpolation (IINI),\nwhich solely relies on local and immediate neighbour correlations. In the IINI\nmethod, medium-to-long range correlations are constructed from the collective\nlocal interactions of grid centroids. To demonstrate the functionality and\nstrengths of IINI, we apply our methodology to the interpolation of ground\ngravity, airborne magnetic and airborne radiometric datasets. We further\ncompare the performance of IINI to conventional methods such as minimum\ncurvature surface fitting. Results show that IINI is competitive with\nconventional interpolation techniques in terms of validation accuracy, while\nbeing significantly simpler in terms of algorithmic complexity and data\npre-processing requirements. IINI demonstrates the broader applicability of\nstatistical physics concepts within the field of geostatistics, highlighting\ntheir potential to enrich and expand traditional geostatistical methods.","main_category":"stat.ME","categories":"stat.ME,physics.geo-ph","published":"2025-04-22T10:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.15784v1","title":"Automated Creativity Evaluation for Large Language Models: A\n  Reference-Based Approach","summary":"Creative writing is a key capability of Large Language Models (LLMs), with\npotential applications in literature, storytelling, and various creative\ndomains. However, evaluating the creativity of machine-generated texts remains\na significant challenge, as existing methods either rely on costly manual\nannotations or fail to align closely with human assessments. In this paper, we\npropose an effective automated evaluation method based on the Torrance Test of\nCreative Writing (TTCW), which evaluates creativity as product. Our method\nemploys a reference-based Likert-style approach, scoring generated creative\ntexts relative to high-quality reference texts across various tests.\nExperimental results demonstrate that our method significantly improves the\nalignment between LLM evaluations and human assessments, achieving a pairwise\naccuracy of 0.75 (+15\\%).","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T10:52:23Z"}
{"aid":"http://arxiv.org/abs/2504.15790v1","title":"Microstructure and Manipulation: Quantifying Pump-and-Dump Dynamics in\n  Cryptocurrency Markets","summary":"Building on our prior threshold-based analysis of six months of Poloniex\ntrading data, we have extended both the temporal span and granularity of our\nstudy by incorporating minute-level OHLCV records for 1021 tokens around each\nconfirmed pump-and-dump event. First, we algorithmically identify the\naccumulation phase, marking the initial and final insider volume spikes, and\nobserve that 70% of pre-event volume transacts within one hour of the pump\nannouncement. Second, we compute conservative lower bounds on insider profits\nunder both a single-point liquidation at 70% of peak and a tranche-based\nstrategy (selling 20% at 50%, 30% at 60%, and 50% at 80% of peak), yielding\nmedian returns above 100% and upper-quartile returns exceeding 2000%. Third, by\nunfolding the full pump structure and integrating social-media verification\n(e.g., Telegram announcements), we confirm numerous additional events that\neluded our initial model. We also categorize schemes into \"pre-accumulation\"\nversus \"on-the-spot\" archetypes-insights that sharpen detection algorithms,\ninform risk assessments, and underpin actionable strategies for real-time\nmarket-integrity enforcement.","main_category":"q-fin.TR","categories":"q-fin.TR","published":"2025-04-22T11:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.15804v1","title":"Insights from Verification: Training a Verilog Generation LLM with\n  Reinforcement Learning with Testbench Feedback","summary":"Large language models (LLMs) have shown strong performance in Verilog\ngeneration from natural language description. However, ensuring the functional\ncorrectness of the generated code remains a significant challenge. This paper\nintroduces a method that integrates verification insights from testbench into\nthe training of Verilog generation LLMs, aligning the training with the\nfundamental goal of hardware design: functional correctness. The main obstacle\nin using LLMs for Verilog code generation is the lack of sufficient functional\nverification data, particularly testbenches paired with design specifications\nand code. To address this problem, we introduce an automatic testbench\ngeneration pipeline that decomposes the process and uses feedback from the\nVerilog compiler simulator (VCS) to reduce hallucination and ensure\ncorrectness. We then use the testbench to evaluate the generated codes and\ncollect them for further training, where verification insights are introduced.\nOur method applies reinforcement learning (RL), specifically direct preference\noptimization (DPO), to align Verilog code generation with functional\ncorrectness by training preference pairs based on testbench outcomes. In\nevaluations on VerilogEval-Machine, VerilogEval-Human, RTLLM v1.1, RTLLM v2,\nand VerilogEval v2, our approach consistently outperforms state-of-the-art\nbaselines in generating functionally correct Verilog code. We open source all\ntraining code, data, and models at\nhttps://anonymous.4open.science/r/VeriPrefer-E88B.","main_category":"cs.AR","categories":"cs.AR,cs.AI","published":"2025-04-22T11:38:14Z"}
{"aid":"http://arxiv.org/abs/2504.15809v1","title":"A Line Graph-Based Framework for Identifying Optimal Routing Paths in\n  Decentralized Exchanges","summary":"Decentralized exchanges, such as those employing constant product market\nmakers (CPMMs) like Uniswap V2, play a crucial role in the blockchain ecosystem\nby enabling peer-to-peer token swaps without intermediaries. Despite the\nincreasing volume of transactions, there remains limited research on\nidentifying optimal trading paths across multiple DEXs. This paper presents a\nnovel line-graph-based algorithm (LG) designed to efficiently discover\nprofitable trading routes within DEX environments. We benchmark LG against the\nwidely adopted Depth-First Search (DFS) algorithm under a linear routing\nscenario, encompassing platforms such as Uniswap, SushiSwap, and PancakeSwap.\nExperimental results demonstrate that LG consistently identifies trading paths\nthat are as profitable as, or more profitable than, those found by DFS, while\nincurring comparable gas costs. Evaluations on Uniswap V2 token graphs across\ntwo temporal snapshots further validate LG's performance. Although LG exhibits\nexponential runtime growth with respect to graph size in empirical tests, it\nremains viable for practical, real-world use cases. Our findings underscore the\npotential of the LG algorithm for industrial adoption, offering tangible\nbenefits to traders and market participants in the DeFi space.","main_category":"q-fin.CP","categories":"q-fin.CP,cs.GT","published":"2025-04-22T11:45:49Z"}
{"aid":"http://arxiv.org/abs/2504.15810v1","title":"Multilevel lattice-based kernel approximation for elliptic PDEs with\n  random coefficients","summary":"This paper introduces a multilevel kernel-based approximation method to\nestimate efficiently solutions to elliptic partial differential equations\n(PDEs) with periodic random coefficients. Building upon the work of Kaarnioja,\nKazashi, Kuo, Nobile, Sloan (Numer. Math., 2022) on kernel interpolation with\nquasi-Monte Carlo (QMC) lattice point sets, we leverage multilevel techniques\nto enhance computational efficiency while maintaining a given level of\naccuracy. In the function space setting with product-type weight parameters,\nthe single-level approximation can achieve an accuracy of $\\varepsilon>0$ with\ncost $\\mathcal{O}(\\varepsilon^{-\\eta-\\nu-\\theta})$ for positive constants\n$\\eta, \\nu, \\theta $ depending on the rates of convergence associated with\ndimension truncation, kernel approximation, and finite element approximation,\nrespectively. Our multilevel approximation can achieve the same $\\varepsilon$\naccuracy at a reduced cost $\\mathcal{O}(\\varepsilon^{-\\eta-\\max(\\nu,\\theta)})$.\nFull regularity theory and error analysis are provided, followed by numerical\nexperiments that validate the efficacy of the proposed multilevel approximation\nin comparison to the single-level approach.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T11:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.15814v1","title":"Fast Higher-Order Interpolation and Restriction in ExaHyPE Avoiding\n  Non-physical Reflections","summary":"Wave equations help us to understand phenomena ranging from earthquakes to\ntsunamis. These phenomena materialise over very large scales. It would be\ncomputationally infeasible to track them over a regular mesh. Yet, since the\nphenomena are localised, adaptive mesh refinement (AMR) can be used to\nconstruct meshes with a higher resolution close to the regions of interest.\nExaHyPE is a software engine created to solve wave problems using AMR, and we\nuse it as baseline to construct our numerical relativity application called\nExaGRyPE. To advance the mesh in time, we have to interpolate and restrict\nalong resolution transitions in each and every time step. ExaHyPE's vanilla\ncode version uses a d-linear tensor-product approach. In benchmarks of a\nstationary black hole this performs slowly and leads to errors in conserved\nquantities near AMR boundaries. We therefore introduce a set of higher-order\ninterpolation schemes where the derivatives are calculated at each coarse grid\ncell to approximate the enclosed fine cells. The resulting methods run faster\nthan the tensor-product approach. Most importantly, when running the stationary\nblack hole simulation using the higher order methods the errors near the AMR\nboundaries are removed.","main_category":"cs.CE","categories":"cs.CE,cs.MS,gr-qc","published":"2025-04-22T11:52:58Z"}
{"aid":"http://arxiv.org/abs/2504.15824v1","title":"Characterization and ex vivo application of flexible 2D scintillating\n  coatings in ultra-high dose rate electron beams for FLASH radiotherapy","summary":"The increasing interest in FLASH-RT has lead to the conversion of linear\naccelerators to enable ultra-high dose rate (UHDR) beams for preclinical\nresearch. Dosimetry hereof remains challenging with several crucial aspects\nmissing. This work shows the challenges for real-time 2D UHDR dosimetry, and\naims to present a solution in the context of preclinical irradiations in\nnon-homogeneous UHDR electron beams. An experimental camera-scintillation sheet\ncombination, was used to investigate the spatial dose distribution of a\nconverted UHDR Varian Trilogy. The dosimetric system was characterized by\nvariation of the number of pulses and source to surface distance (SSD) and its\napplication was investigated by variation of bolus thickness and ambient light\nintensity. The challenges of prelcinical real time 2D dosimetry with\nscintillating coatings were assessed by ex vivo irradiations of a rat brain,\nmouse hindlimb and whole body mouse. Radiochromic EBT XD film was used as\npassive reference dosimeter. The coating showed a linear response with the\nnumber of pulses in the absence and presence of transparent bolus, up to 3 cm\nthick, and with the inverse squared SSD. The presence of ambient light reduces\nthe signal-background ratio. The sheet showed to have sufficient flexibility to\nbe molded on the subjects' surface, following its curvatures. Linearity with\nnumber of pulses was preserved in a preclinical setting. For small field sizes\nthe light output became too low, resulting in noisy dose maps. The system\nshowed robust within 5% for camera set up differences. Calibration of the\nsystem was complicated due to set up variations and the inhomogeneity of the\nbeam. We showed the need for 2D real-time dosimetry to determine beam\ncharacteristics in non-homogeneous UHDR beams using a preclinical setting. We\npresented one solution to meet this need with scintillating based dosimetry.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-22T12:11:50Z"}
{"aid":"http://arxiv.org/abs/2504.15835v1","title":"Text-based Animatable 3D Avatars with Morphable Model Alignment","summary":"The generation of high-quality, animatable 3D head avatars from text has\nenormous potential in content creation applications such as games, movies, and\nembodied virtual assistants. Current text-to-3D generation methods typically\ncombine parametric head models with 2D diffusion models using score\ndistillation sampling to produce 3D-consistent results. However, they struggle\nto synthesize realistic details and suffer from misalignments between the\nappearance and the driving parametric model, resulting in unnatural animation\nresults. We discovered that these limitations stem from ambiguities in the 2D\ndiffusion predictions during 3D avatar distillation, specifically: i) the\navatar's appearance and geometry is underconstrained by the text input, and ii)\nthe semantic alignment between the predictions and the parametric head model is\ninsufficient because the diffusion model alone cannot incorporate information\nfrom the parametric model. In this work, we propose a novel framework,\nAnimPortrait3D, for text-based realistic animatable 3DGS avatar generation with\nmorphable model alignment, and introduce two key strategies to address these\nchallenges. First, we tackle appearance and geometry ambiguities by utilizing\nprior information from a pretrained text-to-3D model to initialize a 3D avatar\nwith robust appearance, geometry, and rigging relationships to the morphable\nmodel. Second, we refine the initial 3D avatar for dynamic expressions using a\nControlNet that is conditioned on semantic and normal maps of the morphable\nmodel to ensure accurate alignment. As a result, our method outperforms\nexisting approaches in terms of synthesis quality, alignment, and animation\nfidelity. Our experiments show that the proposed method advances the state of\nthe art in text-based, animatable 3D head avatar generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T12:29:14Z"}
{"aid":"http://arxiv.org/abs/2504.15852v1","title":"Recovering Nesterov accelerated dynamics from Heavy Ball dynamics via\n  time rescaling","summary":"In a real Hilbert space, we consider two classical problems: the global\nminimization of a smooth and convex function $f$ (i.e., a convex optimization\nproblem) and finding the zeros of a monotone and continuous operator $V$ (i.e.,\na monotone equation). Attached to the optimization problem, first we study the\nasymptotic properties of the trajectories generated by a second-order dynamical\nsystem which features a constant viscous friction coefficient and a positive,\nmonotonically increasing function $b(\\cdot)$ multiplying $\\nabla f$. For a\ngenerated solution trajectory $y(t)$, we show small $o$ convergence rates\ndependent on $b(t)$ for $f(y(t)) - \\min f$, and the weak convergence of $y(t)$\ntowards a global minimizer of $f$. In 2015, Su, Boyd and Cand\\'es introduced a\nsecond-order system which could be seen as the continuous-time counterpart of\nNesterov's accelerated gradient. As the first key point of this paper, we show\nthat for a special choice for $b(t)$, these two seemingly unrelated dynamical\nsystems are connected: namely, they are time reparametrizations of each other.\nEvery statement regarding the continuous-time accelerated gradient system may\nbe recovered from its Heavy Ball counterpart.\n  As the second key point of this paper, we observe that this connection\nextends beyond the optimization setting. Attached to the monotone equation\ninvolving the operator $V$, we again consider a Heavy Ball-like system which\nfeatures an additional correction term which is the time derivative of the\noperator along the trajectory. We establish a time reparametrization\nequivalence with the Fast OGDA dynamics introduced by Bot, Csetnek and Nguyen\nin 2022, which can be seen as an analog of the continuous accelerated gradient\ndynamics, but for monotone operators. Again, every statement regarding the Fast\nOGDA system may be recovered from a Heavy Ball-like system.","main_category":"math.OC","categories":"math.OC","published":"2025-04-22T12:46:42Z"}
{"aid":"http://arxiv.org/abs/2504.15854v1","title":"Consistent Causal Inference of Group Effects in Non-Targeted Trials with\n  Finitely Many Effect Levels","summary":"A treatment may be appropriate for some group (the ``sick\" group) on whom it\nhas a positive effect, but it can also have a detrimental effect on subjects\nfrom another group (the ``healthy\" group). In a non-targeted trial both sick\nand healthy subjects may be treated, producing heterogeneous effects within the\ntreated group. Inferring the correct treatment effect on the sick population is\nthen difficult, because the effects on the different groups get tangled. We\npropose an efficient nonparametric approach to estimating the group effects,\ncalled {\\bf PCM} (pre-cluster and merge). We prove its asymptotic consistency\nin a general setting and show, on synthetic data, more than a 10x improvement\nin accuracy over existing state-of-the-art. Our approach applies more generally\nto consistent estimation of functions with a finite range.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-22T12:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.15859v1","title":"The 2nd MERCADO Workshop at IEEE VIS 2025: Multimodal Experiences for\n  Remote Communication Around Data Online","summary":"We propose a half-day workshop at IEEE VIS 2025 on addressing the emerging\nchallenges in data-rich multimodal remote collaboration. We focus on\nsynchronous, remote, and hybrid settings where people take part in tasks such\nas data analysis, decision-making, and presentation. With this workshop, we\ncontinue successful prior work from the first MERCADO workshop at VIS 2023 and\na 2024 Shonan Seminar that followed. Based on the findings of the earlier\nevents, we invite research and ideas related to four themes of challenges:\nTools & Technologies, Individual Differences & Interpersonal Dynamics,\nAI-assisted Collaboration, and Evaluation. With this workshop, we aim to\nbroaden the community, foster new collaborations, and develop a research agenda\nto address these challenges in future research. Our planned workshop format is\ncomprised of a keynote, short presentations, a breakout group session, and\ndiscussions organized around the identified challenges.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-22T12:54:54Z"}
{"aid":"http://arxiv.org/abs/2504.15865v1","title":"MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search","summary":"Deep learning (DL) has achieved remarkable progress in the field of medical\nimaging. However, adapting DL models to medical tasks remains a significant\nchallenge, primarily due to two key factors: (1) architecture selection, as\ndifferent tasks necessitate specialized model designs, and (2) weight\ninitialization, which directly impacts the convergence speed and final\nperformance of the models. Although transfer learning from ImageNet is a widely\nadopted strategy, its effectiveness is constrained by the substantial\ndifferences between natural and medical images. To address these challenges, we\nintroduce Medical Neural Network Search (MedNNS), the first Neural Network\nSearch framework for medical imaging applications. MedNNS jointly optimizes\narchitecture selection and weight initialization by constructing a meta-space\nthat encodes datasets and models based on how well they perform together. We\nbuild this space using a Supernetwork-based approach, expanding the model zoo\nsize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, we\nintroduce rank loss and Fr\\'echet Inception Distance (FID) loss into the\nconstruction of the space to capture inter-model and inter-dataset\nrelationships, thereby achieving more accurate alignment in the meta-space.\nExperimental results across multiple datasets demonstrate that MedNNS\nsignificantly outperforms both ImageNet pre-trained DL models and SOTA Neural\nArchitecture Search (NAS) methods, achieving an average accuracy improvement of\n1.7% across datasets while converging substantially faster. The code and the\nprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-22T13:04:40Z"}
{"aid":"http://arxiv.org/abs/2504.15868v1","title":"Geometry of regular semisimple Lusztig varieties","summary":"Lusztig varieties are subvarieties in flag manifolds $G/B$ associated to an\nelement $w$ in the Weyl group $W$ and an element $x$ in $G$, introduced in\nLusztig's papers on character sheaves. We study the geometry of these varieties\nwhen $x$ is regular semisimple.\n  In the first part, we establish that they are normal, Cohen-Macaulay, of pure\nexpected dimension and have rational singularities. We then show that the\ncohomology of ample line bundles vanishes in positive degrees, in arbitrary\ncharacteristic. This extends to nef line bundles when the base field has\ncharacteristic zero or sufficiently large characteristic. Along the way, we\nprove that Lusztig varieties are Frobenius split in positive characteristic and\nthat their open cells are affine. We also prove that the open cells in\nDeligne-Lusztig varieties are affine, settling a question that has been open\nsince the foundational paper of Deligne and Lusztig.\n  In the second part, we explore their relationship with regular semisimple\nHessenberg varieties. Both varieties admit Tymoczko's dot action of $W$ on\ntheir (intersection) cohomology. We associate to each element $w$ in $W$ a\nHessenberg space using the tangent cone of the Schubert variety associated with\n$w$, and show that the cohomology of the associated regular semisimple Lusztig\nvarieties and Hessenberg varieties is isomorphic as graded $W$-representations\nwhen they are smooth.\n  This relationship extends to the level of varieties: we construct a flat\ndegeneration of regular semisimple Lusztig varieties to regular semisimple\nHessenberg varieties. In particular, this proves a conjecture of Abreu and\nNigro on the homeomorphism types of regular semisimple Lusztig varieties in\ntype $A$, and generalizes it to arbitrary Lie types.","main_category":"math.AG","categories":"math.AG,math.CO,math.RT","published":"2025-04-22T13:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.15879v1","title":"Multivariate Poisson intensity estimation via low-rank tensor\n  decomposition","summary":"In this work, we introduce new matrix- and tensor-based methodologies for\nestimating multivariate intensity functions of spatial point processes. By\nmodeling intensity functions as infinite-rank tensors within function spaces,\nwe develop new algorithms to reveal optimal bias-variance trade-off for\ninfinite-rank tensor estimation. Our methods dramatically enhance estimation\naccuracy while simultaneously reducing computational complexity. To our\nknowledge, this work marks the first application of matrix and tensor\ntechinques to spatial point processes. Extensive numerical experiments further\ndemonstrate that our techniques consistently outperform current\nstate-of-the-art methods.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-22T13:25:17Z"}
{"aid":"http://arxiv.org/abs/2504.15880v1","title":"Cryptoanalysis of a public key exchange based on circulant matrix over\n  digital semiring","summary":"We present a cryptanalysis of a key exchange protocol based on the digital\nsemiring. For this purpose, we find the maximal solution of a linear system\nover such semiring, and use the properties of circulant matrix to demonstrate\nthat the protocol is vulnerable. Specifically, we provide an efficient attack\nthat recovers the shared secret key from publicly exchanged information for any\ninstance of the digital semiring in polynomial time.","main_category":"cs.CR","categories":"cs.CR,cs.IT,math.AC,math.IT","published":"2025-04-22T13:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.15895v1","title":"Dynamic Early Exit in Reasoning Models","summary":"Recent advances in large reasoning language models (LRLMs) rely on test-time\nscaling, which extends long chain-of-thought (CoT) generation to solve complex\ntasks. However, overthinking in long CoT not only slows down the efficiency of\nproblem solving, but also risks accuracy loss due to the extremely detailed or\nredundant reasoning steps. We propose a simple yet effective method that allows\nLLMs to self-truncate CoT sequences by early exit during generation. Instead of\nrelying on fixed heuristics, the proposed method monitors model behavior at\npotential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically\nterminates the next reasoning chain's generation when the model exhibits high\nconfidence in a trial answer. Our method requires no additional training and\ncan be seamlessly integrated into existing o1-like reasoning LLMs. Experiments\non multiple reasoning benchmarks MATH-500, AMC 2023, GPQA Diamond and AIME 2024\nshow that the proposed method is consistently effective on deepseek-series\nreasoning LLMs, reducing the length of CoT sequences by an average of 31% to\n43% while improving accuracy by 1.7% to 5.7%.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T13:36:53Z"}
{"aid":"http://arxiv.org/abs/2504.15896v1","title":"New rare meson decay constraints on a light vector in $U(1)_{B-L},\n  U(1)_R$ and the dark photon","summary":"We evaluate constraints from flavor changing rare meson decays to a light\nvector boson $X$, followed by the decay of the on-shell $X$ into the SM\nfermions. The flavor changing meson decay emitting the light $X$ is induced by\nloop processes where the up-type quarks, the $W$ boson, or charged scalar\nbosons are running inside loops. We calculate all one-loop diagrams with\nneglecting all masses of light quarks except for the top quark in a general\nanomaly free extra $U(1)$ model. Our theoretical evaluation of the branching\nratio of charged $B$ meson decay and charged kaon decay is compared to\nexperimental results, and we derive new constraints for dark photon,\n$U(1)_{B-L}$ and $U(1)_R$ models.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-22T13:39:26Z"}
{"aid":"http://arxiv.org/abs/2504.15907v1","title":"On meromorphic solutions of Fermat type delay-differential equations\n  with two exponential terms","summary":"The existence of the meromorphic solutions to Fermat type delay-differential\nequation\n  \\begin{equation}\n  f^n(z)+a(f^{(l)}(z+c))^m=p_1(z)e^{a_1z^k}+p_2(z)e^{a_2z^k}, \\nonumber\n  \\end{equation}\n  is derived by using Nevanlinna theory under certain conditions, where\n$k\\ge1$, $m,$ $n$ and $l\\ge0$ are integers, $p_i$ are nonzero entire functions\nof order less than $k$, $c$, $a$ and $a_i$ are constants, $i=1,2$. These\nresults not only improve the previous results from Zhu et al. [J. Contemp.\nMath. Anal. 59(2024), 209-219], Qi et al. [Mediterr. J. Math. 21(2024), article\nno. 122], but also completely solve two conjectures posed by Gao et al.\n[Mediterr. J. Math. 20(2023), article no. 167].Some examples are given to\nillustrate our results.","main_category":"math.CV","categories":"math.CV","published":"2025-04-22T13:52:39Z"}
{"aid":"http://arxiv.org/abs/2504.15911v1","title":"Direct and inverse problem for bi-wave equation with time-dependent\n  coefficients from partial data","summary":"In this article, we study a direct and an inverse problem for the bi-wave\noperator $(\\Box^2)$ along with second and lower order time-dependent\nperturbations. In the direct problem, we prove that the operator is well-posed,\ngiven initial and boundary data in suitable function spaces. In the inverse\nproblem, we prove uniqueness of the lower order time-dependent perturbations\nfrom the partial input-output operator. The restriction in the measurements are\nconsidered by restricting some of the Neumann data over a portion of the\nlateral boundary.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T13:56:50Z"}
{"aid":"http://arxiv.org/abs/2504.15917v1","title":"Towards Test Generation from Task Description for Mobile Testing with\n  Multi-modal Reasoning","summary":"In Android GUI testing, generating an action sequence for a task that can be\nreplayed as a test script is common. Generating sequences of actions and\nrespective test scripts from task goals described in natural language can\neliminate the need for manually writing test scripts. However, existing\napproaches based on large language models (LLM) often struggle with identifying\nthe final action, and either end prematurely or continue past the final screen.\nIn this paper, we introduce VisiDroid, a multi-modal, LLM-based, multi-agent\nframework that iteratively determines the next action and leverages visual\nimages of screens to detect the task's completeness. The multi-modal approach\nenhances our model in two significant ways. First, this approach enables it to\navoid prematurely terminating a task when textual content alone provides\nmisleading indications of task completion. Additionally, visual input helps the\ntool avoid errors when changes in the GUI do not directly affect functionality\ntoward task completion, such as adjustments to font sizes or colors. Second,\nthe multi-modal approach also ensures the tool not progress beyond the final\nscreen, which might lack explicit textual indicators of task completion but\ncould display a visual element indicating task completion, which is common in\nGUI apps. Our evaluation shows that VisiDroid achieves an accuracy of 87.3%,\noutperforming the best baseline relatively by 23.5%. We also demonstrate that\nour multi-modal framework with images and texts enables the LLM to better\ndetermine when a task is completed.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-22T14:02:57Z"}
{"aid":"http://arxiv.org/abs/2504.15937v1","title":"Intermediate modular curves with infinitely many quartic points","summary":"For every group $\\{\\pm1\\}\\subseteq \\Delta\\subseteq (\\mathbb Z/N\\mathbb\nZ)^\\times$, there exists an intermediate modular curve $X_\\Delta(N)$. In this\npaper we determine all curves $X_\\Delta(N)$ with infinitely many points of\ndegree $4$ over $\\mathbb Q$. To do that, we developed a method to compute\npossible degrees of rational morphisms from $X_\\Delta(N)$ to an elliptic curve.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T14:27:12Z"}
{"aid":"http://arxiv.org/abs/2504.15948v1","title":"Automated Vulnerability Injection in Solidity Smart Contracts: A\n  Mutation-Based Approach for Benchmark Development","summary":"The security of smart contracts is critical in blockchain systems, where even\nminor vulnerabilities can lead to substantial financial losses. Researchers\nproposed several vulnerability detection tools evaluated using existing\nbenchmarks. However, most benchmarks are outdated and focus on a narrow set of\nvulnerabilities. This work evaluates whether mutation seeding can effectively\ninject vulnerabilities into Solidity-based smart contracts and whether\nstate-of-the-art static analysis tools can detect the injected flaws. We aim to\nautomatically inject vulnerabilities into smart contracts to generate large and\nwide benchmarks. We propose MuSe, a tool to generate vulnerable smart contracts\nby leveraging pattern-based mutation operators to inject six vulnerability\ntypes into real-world smart contracts. We analyzed these vulnerable smart\ncontracts using Slither, a static analysis tool, to determine its capacity to\nidentify them and assess their validity. The results show that each\nvulnerability has a different injection rate. Not all smart contracts can\nexhibit some vulnerabilities because they lack the prerequisites for injection.\nFurthermore, static analysis tools fail to detect all vulnerabilities injected\nusing pattern-based mutations, underscoring the need for enhancements in static\nanalyzers and demonstrating that benchmarks generated by mutation seeding tools\ncan improve the evaluation of detection tools.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-22T14:46:18Z"}
{"aid":"http://arxiv.org/abs/2504.15958v1","title":"FreeGraftor: Training-Free Cross-Image Feature Grafting for\n  Subject-Driven Text-to-Image Generation","summary":"Subject-driven image generation aims to synthesize novel scenes that\nfaithfully preserve subject identity from reference images while adhering to\ntextual guidance, yet existing methods struggle with a critical trade-off\nbetween fidelity and efficiency. Tuning-based approaches rely on time-consuming\nand resource-intensive subject-specific optimization, while zero-shot methods\nfail to maintain adequate subject consistency. In this work, we propose\nFreeGraftor, a training-free framework that addresses these limitations through\ncross-image feature grafting. Specifically, FreeGraftor employs semantic\nmatching and position-constrained attention fusion to transfer visual details\nfrom reference subjects to the generated image. Additionally, our framework\nincorporates a novel noise initialization strategy to preserve geometry priors\nof reference subjects for robust feature matching. Extensive qualitative and\nquantitative experiments demonstrate that our method enables precise subject\nidentity transfer while maintaining text-aligned scene synthesis. Without\nrequiring model fine-tuning or additional training, FreeGraftor significantly\noutperforms existing zero-shot and training-free approaches in both subject\nfidelity and text alignment. Furthermore, our framework can seamlessly extend\nto multi-subject generation, making it practical for real-world deployment. Our\ncode is available at https://github.com/Nihukat/FreeGraftor.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:55:23Z"}
{"aid":"http://arxiv.org/abs/2504.15964v1","title":"Quantum machine learning advantages beyond hardness of evaluation","summary":"The most general examples of quantum learning advantages involve data labeled\nby cryptographic or intrinsically quantum functions, where classical learners\nare limited by the infeasibility of evaluating the labeling functions using\npolynomial-sized classical circuits. While broad in scope, such results reveal\nlittle about advantages arising from the learning process itself. In\ncryptographic settings, further insight is possible via random-generatability -\nthe ability to classically generate labeled data - enabling hardness proofs for\nidentification tasks, where the goal is to identify the labeling function from\na dataset, even when evaluation is classically intractable. These tasks are\nparticularly relevant in quantum contexts, including Hamiltonian learning and\nidentifying physically meaningful order parameters. However, for quantum\nfunctions, random-generatability is conjectured not to hold, leaving no known\nidentification advantages in genuinely quantum regimes.\n  In this work, we give the first proofs of quantum identification learning\nadvantages under standard complexity assumptions. We confirm that quantum-hard\nfunctions are not random-generatable unless BQP is contained in the second\nlevel of the polynomial hierarchy, ruling out cryptographic-style data\ngeneration strategies. We then introduce a new approach: we show that\nverifiable identification - solving the identification task for valid datasets\nwhile rejecting invalid ones - is classically hard for quantum labeling\nfunctions unless BQP is in the polynomial hierarchy. Finally, we show that, for\na broad class of tasks, solving the identification problem implies verifiable\nidentification in the polynomial hierarchy. This yields our main result: a\nnatural class of quantum identification tasks solvable by quantum learners but\nhard for classical learners unless BQP is in the polynomial hierarchy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T15:04:46Z"}
{"aid":"http://arxiv.org/abs/2504.15979v1","title":"Efficient Discovery of Motif Transition Process for Large-Scale Temporal\n  Graphs","summary":"Understanding the dynamic transition of motifs in temporal graphs is\nessential for revealing how graph structures evolve over time, identifying\ncritical patterns, and predicting future behaviors, yet existing methods often\nfocus on predefined motifs, limiting their ability to comprehensively capture\ntransitions and interrelationships. We propose a parallel motif transition\nprocess discovery algorithm, PTMT, a novel parallel method for discovering\nmotif transition processes in large-scale temporal graphs. PTMT integrates a\ntree-based framework with the temporal zone partitioning (TZP) strategy, which\npartitions temporal graphs by time and structure while preserving lossless\nmotif transitions and enabling massive parallelism. PTMT comprises three\nphases: growth zone parallel expansion, overlap-aware result aggregation, and\ndeterministic encoding of motif transitions, ensuring accurate tracking of\ndynamic transitions and interactions. Results on 10 real-world datasets\ndemonstrate that PTMT achieves speedups ranging from 12.0$\\times$ to\n50.3$\\times$ compared to the SOTA method.","main_category":"cs.DB","categories":"cs.DB,cs.LG","published":"2025-04-22T15:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.15988v1","title":"SN 2023vbg: A Type IIn Supernova Resembling SN 2009ip, with a\n  Long-Duration Precursor and Early-Time Bump","summary":"Type IIn supernovae (SNe) resembling SN 2009ip (09ip-like SNe) originate from\nthe interaction between circumstellar material (CSM) and the ejecta. This\nsubclass not only shares similar observational properties around the maximum,\nbut is commonly characterized by a long duration precursor before its maximum.\nInvestigating the observed properties of the precursor provides constraints on\nthe mass-loss history of the progenitor.We present observational data of SN\n2023vbg, a 09ip-like type IIn SN that displayed unique observational properties\ncompared to other 09ip-like SNe. SN 2023vbg showed a long-duration precursor at\n$M_g\\sim-14$ mag lasting for $\\sim100$ days, followed by a bright bump at\n$M_g\\sim-17$ mag at 12-25 days before the maximum. The luminosity of the\nprecursor is similar to those of other 09ip-like SNe, but the bright bump has\nnot been observed in other cases.After reaching the peak luminosity, the light\ncurve exhibited a peculiar smooth decline.While the H$\\alpha$ profile displays\ntwo velocity components ($\\sim 500$ and $3000\\ \\mathrm{km\\ s^{-1}}$), a broad\ncomponent observed in other 09ip-like SNe was not detected. We suggest that\nthese properties are explained by the difference in the CSM structure as\ncompared to other 09ip-like SNe; SN 2023vbg had an inner denser CSM component,\nas well as generally smooth CSM density distribution in a more extended scale,\nthan in the others. Such diversity of CSM likely reflects the diversity of\npre-SN outbursts, which in turn may mirror the range of evolutionary pathways\nin the final stages of the progenitors.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-22T15:44:05Z"}
{"aid":"http://arxiv.org/abs/2504.16007v1","title":"Methods for Recognizing Nested Terms","summary":"In this paper, we describe our participation in the RuTermEval competition\ndevoted to extracting nested terms. We apply the Binder model, which was\npreviously successfully applied to the recognition of nested named entities, to\nextract nested terms. We obtained the best results of term recognition in all\nthree tracks of the RuTermEval competition. In addition, we study the new task\nof recognition of nested terms from flat training data annotated with terms\nwithout nestedness. We can conclude that several approaches we proposed in this\nwork are viable enough to retrieve nested terms effectively without nested\nlabeling of them.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T16:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.16008v1","title":"An Error Mitigated Non-Orthogonal Quantum Eigensolver via Shadow\n  Tomography","summary":"We present a shadow-tomography-enhanced Non-Orthogonal Quantum Eigensolver\n(NOQE) for more efficient and accurate electronic structure calculations on\nnear-term quantum devices. By integrating shadow tomography into the NOQE, the\nmeasurement cost scales linearly rather than quadratically with the number of\nreference states, while also reducing the required qubits and circuit depth by\nhalf. This approach enables extraction of all matrix elements via randomized\nmeasurements and classical postprocessing. We analyze its sample complexity and\nshow that, for small systems, it remains constant in the high-precision regime,\nwhile for larger systems, it scales linearly with the system size. We further\napply shadow-based error mitigation to suppress noise-induced bias without\nincreasing quantum resources. Demonstrations on the hydrogen molecule in the\nstrongly correlated regime achieve chemical accuracy under realistic noise,\nshowing that our method is both resource-efficient and noise-resilient for\npractical quantum chemistry simulations in the near term.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T16:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.16009v1","title":"Upscaling the Navier-Stokes-Cahn-Hilliard model for incompressible\n  multiphase flow in inhomogeneous porous media","summary":"In this work, we present a macroscopic model for the flow of two immiscible\nand incompressible fluids in inhomogeneous porous medium. At the pore scale,\nthe flow is governed by the fully Navier-Stokes equations while the evolution\nof the phase interface is captured by the Cahn-Hilliard equation. Using the\nvolume averaging method, the upscaled equations describing the averaged\nbehavior of two fluids at the Darcy scale are obtained, with unclosed terms\nrelated to spatial deviations. Then, spatial derivations are carefully modeled\nup to some undetermined coefficients, which could be evaluated by solving\nsimplified closure problems in each representative volume element. In\nparticular, the wetting behavior is incorporated into the averaged chemical\npotential. The differences between the proposed equations and the empirical\ntwo-phase Darcy-type models are discussed. Finally, a phase-field-based lattice\nBoltzmann model for the averaged equations is presented, and numerical results\ndemonstrate the abilities of the proposed model.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,math-ph,math.MP,physics.comp-ph,physics.geo-ph","published":"2025-04-22T16:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.16013v1","title":"Thermal rectification and phonon properties in partially perforated\n  graphene","summary":"In this work, a thermal rectification ratio $\\eta$ of 18.5% was observed in\npartially perforated graphene with the use of Molecular Dynamics (MD)\nsimulations. In all cases studied here, heat preferentially flows from the\nporous to the pristine region and both $\\kappa$ and $\\eta$ increase upon\nincreasing the length of the pristine region and upon decreasing the size of\nthe pores. To interpret the results, the macroscopic \"R-Series Model\" is\napplied, attributing rectification to the different temperature dependence of\n$\\kappa$ of perforated and pristine graphene. According to the model, $\\eta$ is\nmaximized when the two regions composing the structure have matching thermal\nresistances and mismatching temperature-dependence of $\\kappa$. The model\nagrees qualitatively with the MD results, indicating that the latter is the\nprincipal rectification mechanism, but it can significantly underestimate\n$\\eta$. Phonon analysis further reveals the appearance of new 'defect' modes\nlocalized around and between pores, resulting in the emergence of a new\nprominent peak in the phonon Density of States at 520 $cm^{-1}$. The study\nconsiders key geometric factors such as the length of the pristine region, and\nthe pore size, shape, alignment, and orientation. Pore shape and alignment\nexert minimal influence on $\\eta$, although alignment greatly influences\n$\\kappa$. Eventually, arranged pores are deemed more efficient than randomly\ndistributed defects for increasing rectification.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-22T16:25:01Z"}
{"aid":"http://arxiv.org/abs/2504.16023v1","title":"PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud\n  Learning","summary":"Self-supervised representation learning for point cloud has demonstrated\neffectiveness in improving pre-trained model performance across diverse tasks.\nHowever, as pre-trained models grow in complexity, fully fine-tuning them for\ndownstream applications demands substantial computational and storage\nresources. Parameter-efficient fine-tuning (PEFT) methods offer a promising\nsolution to mitigate these resource requirements, yet most current approaches\nrely on complex adapter and prompt mechanisms that increase tunable parameters.\nIn this paper, we propose PointLoRA, a simple yet effective method that\ncombines low-rank adaptation (LoRA) with multi-scale token selection to\nefficiently fine-tune point cloud models. Our approach embeds LoRA layers\nwithin the most parameter-intensive components of point cloud transformers,\nreducing the need for tunable parameters while enhancing global feature\ncapture. Additionally, multi-scale token selection extracts critical local\ninformation to serve as prompts for downstream fine-tuning, effectively\ncomplementing the global context captured by LoRA. The experimental results\nacross various pre-trained models and three challenging public datasets\ndemonstrate that our approach achieves competitive performance with only 3.43%\nof the trainable parameters, making it highly effective for\nresource-constrained applications. Source code is available at:\nhttps://github.com/songw-zju/PointLoRA.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T16:41:21Z"}
{"aid":"http://arxiv.org/abs/2504.16025v1","title":"Modeling Tidal Disruptions with Dynamical Tides","summary":"Tidal disruption events (TDEs) occur when stars pass close enough to\nsupermassive black holes to be torn apart by tidal forces. Traditionally, these\nevents are studied with computationally intensive hydrodynamical simulations.\nIn this paper, we present a fast, physically motivated two-stage model for\nTDEs. In the first stage, we model the star's tidal deformation using linear\nstellar perturbation theory, treating the star as a collection of driven\nharmonic oscillators. When the tidal energy exceeds a fraction $\\gamma$ of the\nstar's gravitational binding energy (with $\\gamma \\sim \\mathcal{O}(1)$), we\ntransition to the second stage, where we model the disrupted material as free\nparticles. The parameter $\\gamma$ is determined with a one-time calibration to\nhydrodynamical simulations. This method enables fast computation of the energy\ndistribution $\\mathrm{d}M/\\mathrm{d}E$ and fallback rate\n$\\mathrm{d}M/\\mathrm{d}T$, while offering physical insight into the disruption\nprocess. We apply our model to MESA-generated profiles of middle-age\nmain-sequence stars. Our code is available on GitHub.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA,astro-ph.SR,gr-qc,hep-ph,hep-th","published":"2025-04-22T16:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.16029v1","title":"Bayesian Parameter Identification in the Landau-de Gennes Theory for\n  Nematic Liquid Crystals","summary":"This manuscript establishes a pathway to reconstruct material parameters from\nmeasurements within the Landau-de Gennes model for nematic liquid crystals. We\npresent a Bayesian approach to this inverse problem and analyse its properties\nusing given, simulated data for benchmark problems of a planar bistable nematic\ndevice. In particular, we discuss the accuracy of the Markov chain Monte Carlo\napproximations, confidence intervals and the limits of identifiability.","main_category":"math.NA","categories":"math.NA,cond-mat.soft,cs.NA,math.ST,stat.TH","published":"2025-04-22T16:49:43Z"}
{"aid":"http://arxiv.org/abs/2504.16034v1","title":"LHCspin: a Polarized Gas Target for LHC","summary":"The goal of the LHCspin project is to develop innovative solutions for\nmeasuring the 3D structure of nucleons in high-energy polarized fixed-target\ncollisions at LHC, exploring new processes and exploiting new probes in a\nunique, previously unexplored, kinematic regime. A precise multi-dimensional\ndescription of the hadron structure has, in fact, the potential to deepen our\nunderstanding of the strong interactions and to provide a much more precise\nframework for measuring both Standard Model and Beyond Standard Model\nobservables. This ambitious task poses its basis on the recent experience with\nthe successful installation and operation of the SMOG2 unpolarized gas target\nin front of the LHCb spectrometer. Besides allowing for interesting physics\nstudies ranging from astrophysics to heavy-ion physics, SMOG2 provides an ideal\nbenchmark for studying beam-target dynamics at the LHC and demonstrates the\nfeasibility of simultaneous operation with beam-beam collisions. With the\ninstallation of the proposed polarized target system, LHCb will become the\nfirst experiment to simultaneously collect data from unpolarized beam-beam\ncollisions at $\\sqrt{s}$=14 TeV and polarized and unpolarized beam-target\ncollisions at $\\sqrt{s_{NN}}\\sim$100 GeV. LHCspin has the potential to open new\nfrontiers in physics by exploiting the capabilities of the world's most\npowerful collider and one of the most advanced spectrometers. This document\nalso highlights the need to perform an R\\&D campaign and the commissioning of\nthe apparatus at the LHC Interaction Region 4 during the Run 4, before its\nfinal installation in LHCb. This opportunity could also allow to undertake\npreliminary physics measurements with unprecedented conditions.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-22T16:58:08Z"}
{"aid":"http://arxiv.org/abs/2504.16049v1","title":"Effect of Coriolis Force on the Shear Viscosity of Rotating Nuclear\n  Medium","summary":"Following the recent observation of non-zero spin polarization and spin\nalignment of a few hadrons, the rotational aspect of quark-gluon plasma formed\nin heavy ion collisions has attracted considerable interest. The present work\nexplores the effect of the Coriolis force, arising due to this rotation, on the\nshear viscosity of the medium. Using the relaxation time approximation within\nthe kinetic theory framework, we analyze the parallel (\\(\\eta_{||}/s\\)),\nperpendicular (\\(\\eta_\\perp/s\\)) and Hall (\\(\\eta_\\times/s\\)) components of\nshear viscosity to entropy density ratio under rotation. The estimation of\nanisotropic shear viscosity components is carried out using hadron resonance\ngas degrees of freedom below the critical (transition) temperature and massless\npartonic degrees of freedom above this temperature. Our results show that\nrotation suppresses the shear viscosity of the medium, with the degree of\nsuppression depending on the ratio between the relaxation time and the\nrotational period. In the context of realistic heavy-ion collision experiments,\nthe temperature and angular velocity both decrease with time, and one can\nestablish a connection between them through the standard approximate cooling\nlaw. For a temperature-dependent angular velocity \\(\\Omega(T)\\), we obtain a\ntraditional valley-like pattern for all components \\(\\eta_{||}/s\\),\n\\(\\eta_\\perp/s\\) and \\(\\eta_\\times/s\\) with reduced magnitudes compared to the\nvalley-like isotropic $\\eta/s$ one encounters in the absence of rotation.","main_category":"nucl-th","categories":"nucl-th,hep-th","published":"2025-04-22T17:27:10Z"}
{"aid":"http://arxiv.org/abs/2504.16059v1","title":"Sub-Horizon Amplification of Curvature Perturbations: A New Route to\n  Primordial Black Holes and Gravitational Waves","summary":"The enhanced primordial scalar power spectrum is a widely studied mechanism\nfor generating primordial gravitational waves (PGWs), also referred to as\nscalar-induced gravitational waves (SIGWs). This process also plays a pivotal\nrole in facilitating the formation of primordial black holes (PBHs).\nTraditionally, the ultra slow-roll (USR) mechanism has been the predominant\napproach used in the early universe. In this framework, the second slow-roll\nparameter $\\epsilon_2$, is typically set to $-6$ or lower for a brief period --\nmarking a significant departure from the standard slow-roll condition where\n$\\epsilon_2 \\simeq 0$. Such conditions often emerge in models with inflection\npoints or localized features, such as bumps in the potential. In this paper, we\nchallenge the conventional assumption that $\\epsilon_2 \\lesssim -6$ is a\nprerequisite for substantial amplification of the scalar power spectrum. We\ndemonstrate that any negative value of the second slow-roll parameter can\nindeed enhance the scalar power spectrum through sub-horizon growth,\nestablishing this as a necessary and sufficient condition for amplification.\nConsequently, this mechanism facilitates the generation of both PGWs and PBHs.\nTo illustrate this, we examine a standard scenario where a brief USR phase is\nembedded between two slow-roll (SR) phases. By systematically varying\n$\\epsilon_{2}$ values from $-1$ to $-10$ in the USR region, we investigate the\namplification of the power spectrum and its implications for PGWs and PBHs\nproduction, particularly in the context of ongoing and future cosmological\nmissions.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-22T17:36:01Z"}
{"aid":"http://arxiv.org/abs/2504.16062v1","title":"ForesightNav: Learning Scene Imagination for Efficient Exploration","summary":"Understanding how humans leverage prior knowledge to navigate unseen\nenvironments while making exploratory decisions is essential for developing\nautonomous robots with similar abilities. In this work, we propose\nForesightNav, a novel exploration strategy inspired by human imagination and\nreasoning. Our approach equips robotic agents with the capability to predict\ncontextual information, such as occupancy and semantic details, for unexplored\nregions. These predictions enable the robot to efficiently select meaningful\nlong-term navigation goals, significantly enhancing exploration in unseen\nenvironments. We validate our imagination-based approach using the Structured3D\ndataset, demonstrating accurate occupancy prediction and superior performance\nin anticipating unseen scene geometry. Our experiments show that the\nimagination module improves exploration efficiency in unseen environments,\nachieving a 100% completion rate for PointNav and an SPL of 67% for ObjectNav\non the Structured3D Validation split. These contributions demonstrate the power\nof imagination-driven reasoning for autonomous systems to enhance generalizable\nand efficient exploration.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-22T17:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.16068v1","title":"High-performance training and inference for deep equivariant interatomic\n  potentials","summary":"Machine learning interatomic potentials, particularly those based on deep\nequivariant neural networks, have demonstrated state-of-the-art accuracy and\ncomputational efficiency in atomistic modeling tasks like molecular dynamics\nand high-throughput screening. The size of datasets and demands of downstream\nworkflows are growing rapidly, making robust and scalable software essential.\nThis work presents a major overhaul of the NequIP framework focusing on\nmulti-node parallelism, computational performance, and extensibility. The\nredesigned framework supports distributed training on large datasets and\nremoves barriers preventing full utilization of the PyTorch 2.0 compiler at\ntrain time. We demonstrate this acceleration in a case study by training\nAllegro models on the SPICE 2 dataset of organic molecular systems. For\ninference, we introduce the first end-to-end infrastructure that uses the\nPyTorch Ahead-of-Time Inductor compiler for machine learning interatomic\npotentials. Additionally, we implement a custom kernel for the Allegro model's\nmost expensive operation, the tensor product. Together, these advancements\nspeed up molecular dynamics calculations on system sizes of practical relevance\nby up to a factor of 18.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cs.LG,physics.chem-ph","published":"2025-04-22T17:47:01Z"}
{"aid":"http://arxiv.org/abs/2504.16079v1","title":"A Distribution-Free Approach to Testing Models for Angular Power Spectra","summary":"A novel goodness-of-fit strategy is introduced for testing models for angular\npower spectra characterized by unknown parameters. Using this strategy, it is\npossible to assess the validity of such models without specifying the\ndistribution of the estimators of the angular power spectrum being used. This\nholds under general conditions, ensuring the applicability of the method across\ndiverse scenarios. Moreover, the proposed solution overcomes the need for\ncase-by-case simulations when testing different models -- leading to notable\ncomputational advantages.","main_category":"physics.data-an","categories":"physics.data-an,astro-ph.IM","published":"2025-04-22T17:57:37Z"}
{"aid":"http://arxiv.org/abs/2504.16082v1","title":"MR. Video: \"MapReduce\" is the Principle for Long Video Understanding","summary":"We propose MR. Video, an agentic long video understanding framework that\ndemonstrates the simple yet effective MapReduce principle for processing long\nvideos: (1) Map: independently and densely perceiving short video clips, and\n(2) Reduce: jointly aggregating information from all clips. Compared with\nsequence-to-sequence vision-language models (VLMs), MR. Video performs detailed\nshort video perception without being limited by context length. Compared with\nexisting video agents that typically rely on sequential key segment selection,\nthe Map operation enables simpler and more scalable sequence parallel\nperception of short video segments. Its Reduce step allows for more\ncomprehensive context aggregation and reasoning, surpassing explicit key\nsegment retrieval. This MapReduce principle is applicable to both VLMs and\nvideo agents, and we use LLM agents to validate its effectiveness.\n  In practice, MR. Video employs two MapReduce stages: (A) Captioning:\ngenerating captions for short video clips (map), then standardizing repeated\ncharacters and objects into shared names (reduce); (B) Analysis: for each user\nquestion, analyzing relevant information from individual short videos (map),\nand integrating them into a final answer (reduce). MR. Video achieves over 10%\naccuracy improvement on the challenging LVBench compared to state-of-the-art\nVLMs and video agents.\n  Code is available at: https://github.com/ziqipang/MR-Video","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T17:59:41Z"}
{"aid":"http://arxiv.org/abs/2504.16379v1","title":"SplitReason: Learning To Offload Reasoning","summary":"Reasoning in large language models (LLMs) tends to produce substantially\nlonger token generation sequences than simpler language modeling tasks. This\nextended generation length reflects the multi-step, compositional nature of\nreasoning and is often correlated with higher solution accuracy. From an\nefficiency perspective, longer token generation exacerbates the inherently\nsequential and memory-bound decoding phase of LLMs. However, not all parts of\nthis expensive reasoning process are equally difficult to generate. We leverage\nthis observation by offloading only the most challenging parts of the reasoning\nprocess to a larger, more capable model, while performing most of the\ngeneration with a smaller, more efficient model; furthermore, we teach the\nsmaller model to identify these difficult segments and independently trigger\noffloading when needed. To enable this behavior, we annotate difficult segments\nacross 18k reasoning traces from the OpenR1-Math-220k chain-of-thought (CoT)\ndataset. We then apply supervised fine-tuning (SFT) and reinforcement learning\nfine-tuning (RLFT) to a 1.5B-parameter reasoning model, training it to learn to\noffload the most challenging parts of its own reasoning process to a larger\nmodel. This approach improves AIME24 reasoning accuracy by 24% and 28.3% while\noffloading 1.35% and 5% of the generated tokens respectively. We open-source\nour SplitReason model, data, code and logs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T03:00:02Z"}
{"aid":"http://arxiv.org/abs/2504.16385v1","title":"Distributed Space Resource Logistics Architecture Optimization under\n  Economies of Scale","summary":"This paper proposes an optimization framework for distributed resource\nlogistics system design to support future multimission space exploration. The\nperformance and impact of distributed In-Situ Resource Utilization (ISRU)\nsystems in facilitating space transportation are analyzed. The proposed\nframework considers technology trade studies, deployment strategy, facility\nlocation evaluation, and resource logistics after production for distributed\nISRU systems. We develop piecewise linear sizing and cost estimation models\nbased on economies of scale that can be easily integrated into network-based\nmission planning formulations. A case study on a multi-mission cislunar\nlogistics campaign is conducted to demonstrate the value of the proposed method\nand evaluate key tradeoffs to compare the performance of distributed ISRU\nsystems with traditional concentrated ISRU. Finally, a comprehensive\nsensitivity analysis is performed to assess the proposed system under varying\nconditions, comparing concentrated and distributed ISRU systems.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-23T03:26:43Z"}
{"aid":"http://arxiv.org/abs/2504.16387v1","title":"Impact of Fuel Injection Temperature Dynamics on the Stability of Liquid\n  Oxygen-Methane Supercritical Combustion","summary":"A crucial factor in the stability of high-pressure rocket-scale combustors is\nthe temperature at which fuel is injected. This study investigates its effect\non the stability of supercritical liquid oxygen (LOx)-methane combustion and\nhighlights the impact of shear layer dynamics in cases with lower injection\ntemperatures. The stability features of a rocket-scale combustor operating with\nmultiple injector elements are investigated using a high-fidelity large eddy\nsimulation (LES) framework. The numerical framework combines a\nflamelet-generated manifold (FGM) combustion model with complex real gas\nthermodynamics in a scale-resolving simulation setup. It reproduces the\nnon-equilibrium transcritical injection and supercritical combustion\ncharacteristics of supercritical methane-oxygen flames. To ascertain the effect\nof injection temperature on flame and combustor stability, we perform several\nLES simulations at various methane injection temperatures and produce a\nstability map. Our analysis shows extremely unstable flame characteristics at\nlower fuel injection temperatures that are not seen under typical fuel\ninjection circumstances. Below a specific methane injection temperature, LES\ncaptures a high-amplitude, self-sustaining instability. It is determined that\nthe combustor becomes unstable below a specific stability boundary temperature.\nDetailed spectral and dynamic mode decomposition (DMD) analysis of the stable\nand unstable cases reveals the onset of longitudinal acoustic waves in the\ncombustor. Our thorough investigation pinpoints the instability mechanism,\nemphasizing that the leading causes of this self-sustaining instability in the\ncombustor are a reduced velocity ratio, fuel buildup, and fuel cut-off\noccurrences.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T03:30:00Z"}
{"aid":"http://arxiv.org/abs/2504.16388v1","title":"Measurement of the Temperature Dependence of the Refractive Index of\n  CdZnTe","summary":"We have been developing a CdZnTe immersion grating for a compact\nhigh-dispersion mid-infrared spectrometer (wavelength range 10--18 $\\mu$m,\nspectral resolution $R = \\lambda/\\Delta \\lambda > 25,000$, operating\ntemperature $T < 20$ K). Using an immersion grating, the spectrometer size can\nbe reduced to $1/n$ ($n$: refractive index) compared to conventional\ndiffraction gratings. CdZnTe is promising as a material for immersion gratings\nfor the wavelength range. However, the refractive index $n$ of CdZnTe has not\nbeen measured at $T < 20$ K.\n  We have been developing a system to precisely measure $n$ at cryogenic\ntemperatures ($T \\sim 10$ K) in the mid-infrared wavelength range. As the first\nresult, this paper reports the temperature dependence of $n$ of CdZnTe at the\nwavelength of 10.68 $\\mu$m. This system employs the minimum deviation method.\nThe refractive index $n$ of CdZnTe is measured at temperatures of \\( T = 12.57,\n22.47, 50.59, 70.57, \\text{ and } 298 \\, \\text{K} \\). We find that $n$ of\nCdZnTe at $\\lambda =$ 10.68 $\\mu$m is $2.6371 \\pm 0.0022$ at $12.57 \\pm 0.14$\nK, and the average temperature dependence of $n$ between 12.57 $\\pm$ 0.14 K and\n70.57 $\\pm$ 0.23 K is $\\Delta n/\\Delta T = (5.8 \\pm 0.3) \\times 10^{-5}$\nK$^{-1}$.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-23T03:30:54Z"}
{"aid":"http://arxiv.org/abs/2504.16390v1","title":"Probing Bulk Band Topology from Time Boundary Effect in Synthetic\n  Dimension","summary":"An incident wave at a temporal interface, created by an abrupt change in\nsystem parameters, generates time-refracted and time-reflected waves. We find\ntopological characteristics associated with the temporal interface that\nseparates distinct spatial topologies and report a novel bulk-boundary\ncorrespondence for the temporal interface. The vanishing of either time\nrefraction or time reflection records a topological phase transition across the\ntemporal interface, and the difference of bulk band topology predicts\nnontrivial braiding hidden in the time refraction and time reflection\ncoefficients. These findings, which are insensitive to spatial boundary\nconditions and robust against disorder, are demonstrated in a synthetic\nfrequency lattice with rich topological phases engendered by long-range\ncouplings. Our work reveals the topological aspect of temporal interface and\npaves the way for using the time boundary effect to probe topological phase\ntransitions and topological invariants.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-23T03:35:12Z"}
{"aid":"http://arxiv.org/abs/2504.16391v1","title":"Evolution of QPO during Rising Phase of Discovery Outburst of Swift\n  J1727.8-1613: Estimation of Mass from Spectro-Temporal Study","summary":"The rising phase of the 2023-24 outburst of the recently discovered bright\ntransient black hole candidate Swift J1727.8-1613 was monitored by\n\\textit{Insight}-HXMT. We study the evolution of hard ($4$-$150$ keV) and soft\n($2$-$4$ keV) band photon count rates, the hardness ratio (HR), and QPO\nfrequencies using daily observations from the HXMT/LE, ME, and HE instruments\nbetween August 25 and October 5, 2023. The QPO frequency is found to be\nstrongly correlated with the soft-band X-ray count rates, and spectral photon\nindices. In contrast, a strong anti-correlation is observed between HR and QPO\nfrequency, as well as between HR and photon index. Based on the evolution of\nthe QPO frequency, the rising phase of the outburst is subdivided into six\nparts, with parts 1-5 fitted using the propagating oscillatory shock (POS)\nsolution to understand the nature of the evolution from a physical perspective.\nThe best-fitted POS model is obtained with a black hole mass of\n$13.34\\pm0.02~M_\\odot$. An inward-propagating shock with weakening strength\n(except in part 4) is observed during the period of our study. The POS\nmodel-fitted mass of the source is further confirmed using the QPO frequency\n($\\nu$)-photon index ($\\Gamma$) scaling method. From this method, the estimated\nprobable mass of Swift J1727.8-1613 is obtained to be $13.54\\pm1.87~M_\\odot$.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T03:37:58Z"}
{"aid":"http://arxiv.org/abs/2504.16406v1","title":"Long Exposure Localization in Darkness Using Consumer Cameras","summary":"In this paper we evaluate performance of the SeqSLAM algorithm for passive\nvision-based localization in very dark environments with low-cost cameras that\nresult in massively blurred images. We evaluate the effect of motion blur from\nexposure times up to 10,000 ms from a moving car, and the performance of\nlocalization in day time from routes learned at night in two different\nenvironments. Finally we perform a statistical analysis that compares the\nbaseline performance of matching unprocessed grayscale images to using patch\nnormalization and local neighborhood normalization - the two key SeqSLAM\ncomponents. Our results and analysis show for the first time why the SeqSLAM\nalgorithm is effective, and demonstrate the potential for cheap camera-based\nlocalization systems that function despite extreme appearance change.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T04:18:57Z"}
{"aid":"http://arxiv.org/abs/2504.16407v1","title":"Public-Key Quantum Fire and Key-Fire From Classical Oracles","summary":"Quantum fire was recently formalized by Bostanci, Nehoran and Zhandry (STOC\n25). This notion considers a distribution of quantum states that can be\nefficiently cloned, but cannot be converted into a classical string.\nPreviously, work of Nehoran and Zhandry (ITCS 24) showed how to construct\nquantum fire relative to an inefficient unitary oracle. Later, the work of\nBostanci, Nehoran, Zhandry gave a candidate construction based on group action\nassumptions, and proved the correctness of their scheme; however, even in the\nclassical oracle model they only conjectured the security, and no security\nproof was given.\n  In this work, we give the first construction of public-key quantum fire\nrelative to a classical oracle, and prove its security unconditionally. This\ngives the first classical oracle seperation between the two fundamental\nprinciples of quantum mechanics that are equivalent in the\ninformation-theoretic setting: no-cloning and no-telegraphing.\n  Going further, we introduce a stronger notion called quantum key-fire where\nthe clonable fire states can be used to run a functionality (such as a signing\nor decryption key), and prove a secure construction relative to a classical\noracle. As an application of this notion, we get the first public-key\nencryption scheme whose secret key is clonable but satisfies unbounded\nleakage-resilience (Cakan, Goyal, Liu-Zhang, Ribeiro [TCC 24]), relative to a\nclassical oracle. Unbounded leakage-resilience is closely related to, and can\nbe seen as a generalization of the notion of no-telegraphing.\n  For all of our constructions, the oracles can be made efficient (i.e.\npolynomial time), assuming the existence of post-quantum one-way functions.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-23T04:19:31Z"}
{"aid":"http://arxiv.org/abs/2504.16417v1","title":"Anytime Safe Reinforcement Learning","summary":"This paper considers the problem of solving constrained\n  reinforcement learning problems with anytime guarantees, meaning\n  that the algorithmic solution returns a safe policy regardless of\n  when it is terminated. Drawing inspiration from anytime constrained\n  optimization, we introduce Reinforcement Learning-based Safe\n  Gradient Flow (RL-SGF), an on-policy algorithm which employs\n  estimates of the value functions and their respective gradients\n  associated with the objective and safety constraints for the current\n  policy, and updates the policy parameters by solving a convex\n  quadratically constrained quadratic program. We show that if the\n  estimates are computed with a sufficiently large number of episodes\n  (for which we provide an explicit bound), safe policies are updated\n  to safe policies with a probability higher than a prescribed\n  tolerance. We also show that iterates asymptotically converge to a\n  neighborhood of a KKT point, whose size can be arbitrarily reduced\n  by refining the estimates of the value function and their gradients.\n  We illustrate the performance of RL-SGF in a navigation example.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-23T04:51:31Z"}
{"aid":"http://arxiv.org/abs/2504.16419v1","title":"PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels","summary":"Graphical User Interface (GUI) datasets are crucial for various downstream\ntasks. However, GUI datasets often generate annotation information through\nautomatic labeling, which commonly results in inaccurate GUI element BBox\nannotations, including missing, duplicate, or meaningless BBoxes. These issues\ncan degrade the performance of models trained on these datasets, limiting their\neffectiveness in real-world applications. Additionally, existing GUI datasets\nonly provide BBox annotations visually, which restricts the development of\nvisually related GUI downstream tasks. To address these issues, we introduce\nPixelWeb, a large-scale GUI dataset containing over 100,000 annotated web\npages. PixelWeb is constructed using a novel automatic annotation approach that\nintegrates visual feature extraction and Document Object Model (DOM) structure\nanalysis through two core modules: channel derivation and layer analysis.\nChannel derivation ensures accurate localization of GUI elements in cases of\nocclusion and overlapping elements by extracting BGRA four-channel bitmap\nannotations. Layer analysis uses the DOM to determine the visibility and\nstacking order of elements, providing precise BBox annotations. Additionally,\nPixelWeb includes comprehensive metadata such as element images, contours, and\nmask annotations. Manual verification by three independent annotators confirms\nthe high quality and accuracy of PixelWeb annotations. Experimental results on\nGUI element detection tasks show that PixelWeb achieves performance on the\nmAP95 metric that is 3-7 times better than existing datasets. We believe that\nPixelWeb has great potential for performance improvement in downstream tasks\nsuch as GUI generation and automated user interaction.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.HC","published":"2025-04-23T05:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.16426v1","title":"Qubit Geometry through Holomorphic Quantization","summary":"We develop a wave mechanics formalism for qubit geometry using holomorphic\nfunctions and Mobius transformations, providing a geometric perspective on\nquantum computation. This framework extends the standard Hilbert space\ndescription, offering a natural interpretation of standard quantum gates on the\nRiemann sphere that is examined through their Mobius action on holomorphic\nwavefunction. These wavefunctions emerge via a quantization process, with the\nRiemann sphere serving as the classical phase space of qubit geometry. We\nquantize this space using canonical group quantization with holomorphic\npolarization, yielding holomorphic wavefunctions and spin angular momentum\noperators that recover the standard $SU(2)$ algebra with interesting geometric\nproperties. Such properties reveal how geometric transformations induce quantum\nlogic gates on the Riemann sphere, providing a novel perspective in quantum\ninformation processing. This result provides a new direction for exploring\nquantum computation through Isham's canonical group quantization and its\nholomorphic polarization method.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-23T05:24:43Z"}
{"aid":"http://arxiv.org/abs/2504.16429v1","title":"Give LLMs a Security Course: Securing Retrieval-Augmented Code\n  Generation via Knowledge Injection","summary":"Retrieval-Augmented Code Generation (RACG) leverages external knowledge to\nenhance Large Language Models (LLMs) in code synthesis, improving the\nfunctional correctness of the generated code. However, existing RACG systems\nlargely overlook security, leading to substantial risks. Especially, the\npoisoning of malicious code into knowledge bases can mislead LLMs, resulting in\nthe generation of insecure outputs, which poses a critical threat in modern\nsoftware development. To address this, we propose a security-hardening\nframework for RACG systems, CodeGuarder, that shifts the paradigm from\nretrieving only functional code examples to incorporating both functional code\nand security knowledge. Our framework constructs a security knowledge base from\nreal-world vulnerability databases, including secure code samples and root\ncause annotations. For each code generation query, a retriever decomposes the\nquery into fine-grained sub-tasks and fetches relevant security knowledge. To\nprioritize critical security guidance, we introduce a re-ranking and filtering\nmechanism by leveraging the LLMs' susceptibility to different vulnerability\ntypes. This filtered security knowledge is seamlessly integrated into the\ngeneration prompt. Our evaluation shows CodeGuarder significantly improves code\nsecurity rates across various LLMs, achieving average improvements of 20.12\\%\nin standard RACG, and 31.53\\% and 21.91\\% under two distinct poisoning\nscenarios without compromising functional correctness. Furthermore, CodeGuarder\ndemonstrates strong generalization, enhancing security even when the targeted\nlanguage's security knowledge is lacking. This work presents CodeGuarder as a\npivotal advancement towards building secure and trustworthy RACG systems.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-04-23T05:27:27Z"}
{"aid":"http://arxiv.org/abs/2504.16431v1","title":"Target Concrete Score Matching: A Holistic Framework for Discrete\n  Diffusion","summary":"Discrete diffusion is a promising framework for modeling and generating\ndiscrete data. In this work, we present Target Concrete Score Matching (TCSM),\na novel and versatile objective for training and fine-tuning discrete diffusion\nmodels. TCSM provides a general framework with broad applicability. It supports\npre-training discrete diffusion models directly from data samples, and many\nexisting discrete diffusion approaches naturally emerge as special cases of our\nmore general TCSM framework. Furthermore, the same TCSM objective extends to\npost-training of discrete diffusion models, including fine-tuning using reward\nfunctions or preference data, and distillation of knowledge from pre-trained\nautoregressive models. These new capabilities stem from the core idea of TCSM,\nestimating the concrete score of the target distribution, which resides in the\noriginal (clean) data space. This allows seamless integration with reward\nfunctions and pre-trained models, which inherently only operate in the clean\ndata space rather than the noisy intermediate spaces of diffusion processes.\nOur experiments on language modeling tasks demonstrate that TCSM matches or\nsurpasses current methods. Additionally, TCSM is versatile, applicable to both\npre-training and post-training scenarios, offering greater flexibility and\nsample efficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T05:32:58Z"}
{"aid":"http://arxiv.org/abs/2504.16446v1","title":"Mumott -- a Python package for the analysis of multi-modal tensor\n  tomography data","summary":"Small and wide angle x-ray scattering tensor tomography are powerful methods\nfor studying anisotropic nanostructures in a volume-resolved manner, and are\nbecoming increasingly available to users of synchrotron facilities. The\nanalysis of such experiments requires, however, advanced procedures and\nalgorithms, which creates a barrier for the wider adoption of these techniques.\nHere, in response to this challenge, we introduce the mumott package. It is\nwritten in Python with computationally demanding tasks handled via just-in-time\ncompilation using both CPU and GPU resources. The package is being developed\nwith a focus on usability and extensibility, while achieving a high\ncomputational efficiency. Following a short introduction to the common\nworkflow, we review key features, outline the underlying object-oriented\nframework, and demonstrate the computational performance. By developing the\nmumott package and making it generally available, we hope to lower the\nthreshold for the adoption of tensor tomography and to make these techniques\naccessible to a larger research community.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cond-mat.soft","published":"2025-04-23T06:15:11Z"}
{"aid":"http://arxiv.org/abs/2504.16469v1","title":"Closed-form analysis of Multi-RIS Reflected Signals in RIS-Aided\n  Networks Using Stochastic Geometry","summary":"Reconfigurable intelligent surfaces (RISs) enhance wireless communication by\ncreating engineered signal reflection paths in addition to direct links. This\nwork presents a stochastic geometry framework using point processes (PPs) to\nmodel multiple randomly deployed RISs conditioned on their associated base\nstation (BS) locations. By characterizing aggregated reflections from multiple\nRISs using the Laplace transform, we analytically assess the performance impact\nof RIS-reflected signals by integrating this characterization into\nwell-established stochastic geometry frameworks. Specifically, we derive\nclosed-form expressions for the Laplace transform of the reflected signal power\nin several deployment scenarios. These analytical results facilitate\nperformance evaluation of RIS-enabled enhancements. Numerical simulations\nvalidate that optimal RIS placement favors proximity to BSs or user equipment\n(UEs), and further quantify the impact of reflected interference, various\nfading assumptions, and diverse spatial deployment strategies. Importantly, our\nanalytical approach shows superior computational efficiency compared to Monte\nCarlo simulations.","main_category":"cs.PF","categories":"cs.PF,cs.IT,math.IT","published":"2025-04-23T07:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.16470v1","title":"Improved Streaming Edge Coloring","summary":"Given a graph, an edge coloring assigns colors to edges so that no pairs of\nadjacent edges share the same color. We are interested in edge coloring\nalgorithms under the W-streaming model. In this model, the algorithm does not\nhave enough memory to hold the entire graph, so the edges of the input graph\nare read from a data stream one by one in an unknown order, and the algorithm\nneeds to print a valid edge coloring in an output stream. The performance of\nthe algorithm is measured by the amount of space and the number of different\ncolors it uses.\n  This streaming edge coloring problem has been studied by several works in\nrecent years. When the input graph contains $n$ vertices and has maximum vertex\ndegree $\\Delta$, it is known that in the W-streaming model, an\n$O(\\Delta^2)$-edge coloring can be computed deterministically with\n$\\tilde{O}(n)$ space [Ansari, Saneian, and Zarrabi-Zadeh, 2022], or an\n$O(\\Delta^{1.5})$-edge coloring can be computed by a $\\tilde{O}(n)$-space\nrandomized algorithm [Behnezhad, Saneian, 2024] [Chechik, Mukhtar, Zhang,\n2024].\n  In this paper, we achieve polynomial improvement over previous results.\nSpecifically, we show how to improve the number of colors to\n$\\tilde{O}(\\Delta^{4/3+\\epsilon})$ using space $\\tilde{O}(n)$\ndeterministically, for any constant $\\epsilon > 0$. This is the first\ndeterministic result that bypasses the quadratic bound on the number of colors\nwhile using near-linear space.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T07:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.16482v1","title":"Next Generation Multi-element monolithic Germanium detectors for\n  Spectroscopy: First integration at ESRF facility","summary":"The XAFS-DET work package of the European LEAPS-INNOV project is developing a\nhigh-purity Germanium detectors for synchrotron applications requiring\nspectroscopic-grade response. The detectors integrate three key features: (1)\nnewly designed monolithic Germanium sensors optimised to mitigate\ncharge-sharing events, (2) an improved cooling and mechanical design structure\nsupported by thermal simulations, and (3) complete electronic chain featuring a\nlow-noise CMOS technology-based preamplifier. enabling high X-ray count rate\ncapability over a broad energy range (5-100 keV). This paper discusses the\nfirst integration and characterization of one of the two multi-element Ge\ndetectors at the European Synchrotron Radiation Facility (ESRF). The\nintegration phase included validating high-throughput front-End electronics,\nintegrating them with the Ge sensor, and operating them at liquid nitrogen\ntemperature, in addition to the experimental characterization, which consists\nof electronics noise study and spectroscopic performance evaluation.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-23T07:51:37Z"}
{"aid":"http://arxiv.org/abs/2504.16483v1","title":"Exploring turnover, retention and growth in an OSS Ecosystem","summary":"The Gentoo ecosystem has evolved significantly over 23 years, highlighting\nthe critical impact of developer sentiment on workforce dynamics such as\nturnover, retention, and growth. While prior research has explored sentiment at\nthe project level, sentiment-driven dynamics at the component level remain\nunderexplored, particularly in their implications for software stability.\n  This study investigates the interplay between developer sentiment and\nworkforce dynamics in Gentoo. The primary objectives are to (1) compare\nworkforce metrics (turnover, retention, and growth rates) between\nsentiment-positive (SP) and sentiment-negative (SN) components, (2) examine\ntemporal trends across three time phases, and (3) analyze the impact of these\ndynamics on software stability.\n  A mixed-method approach was employed, integrating sentiment analysis of\nmailing lists and commit histories using the SentiStrength-SE tool. Workforce\nmetrics were statistically analyzed using Pearson Correlation Matrix and\nMann-Whitney U tests. The analysis focused on the most SP and SN components in\nthe ecosystem.\n  SN components exhibited higher retention rates but slower growth and turnover\ncompared to SP components, which showed dynamic contributor behavior but\nreduced long-term stability. Temporal analysis revealed significant variations\nin workforce dynamics over three phases, with developer retention correlating\npositively with modifications in both sentiment groups.\n  Tailored strategies are necessary for managing sentiment-driven dynamics in\nOSS projects. Improving \\textit{adaptability} in SN components, and\n\\textit{continuity} in SP components, could improve project sustainability and\ninnovation. This study contributes to a nuanced understanding of sentiment's\nrole in workforce behavior and software stability within OSS ecosystems.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T07:52:12Z"}
{"aid":"http://arxiv.org/abs/2504.16484v1","title":"Experimentally Certifying Kochen-Specker Set with the Maximally Mixed\n  State","summary":"Certifying Kochen-Specker (KS) set is a task of certifying a set of\nuncharacterized projectors as desired KS set. This work demonstrates an\nimproved scheme that enables this certification using only a maximally mixed\nstate, rather than traversing over all states, making it experimental feasible.\nIn this scheme, outcomes obtained from sequential measurements are used for the\nevaluation of the worst result and its certification threshold, based on the\ncharacteristics of maximally mixed state and a semi-definite program.\nExperimentally, a group of projectors closely approximating the KS set Peres-24\nis certified in an optical system, highlighting the feasibility of this scheme\nin certifying KS set. Furthermore, a quantitative analysis is presented by\nmanually adding errors to the optical system, demonstrating a strict level of\nexperimental imperfection in achieving successful certification. These results\noffer a new perspective on characterizing measurements from quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T07:52:19Z"}
{"aid":"http://arxiv.org/abs/2504.16487v1","title":"Rethinking Generalizable Infrared Small Target Detection: A Real-scene\n  Benchmark and Cross-view Representation Learning","summary":"Infrared small target detection (ISTD) is highly sensitive to sensor type,\nobservation conditions, and the intrinsic properties of the target. These\nfactors can introduce substantial variations in the distribution of acquired\ninfrared image data, a phenomenon known as domain shift. Such distribution\ndiscrepancies significantly hinder the generalization capability of ISTD models\nacross diverse scenarios. To tackle this challenge, this paper introduces an\nISTD framework enhanced by domain adaptation. To alleviate distribution shift\nbetween datasets and achieve cross-sample alignment, we introduce Cross-view\nChannel Alignment (CCA). Additionally, we propose the Cross-view Top-K Fusion\nstrategy, which integrates target information with diverse background features,\nenhancing the model' s ability to extract critical data characteristics. To\nfurther mitigate the impact of noise on ISTD, we develop a Noise-guided\nRepresentation learning strategy. This approach enables the model to learn more\nnoise-resistant feature representations, to improve its generalization\ncapability across diverse noisy domains. Finally, we develop a dedicated\ninfrared small target dataset, RealScene-ISTD. Compared to state-of-the-art\nmethods, our approach demonstrates superior performance in terms of detection\nprobability (Pd), false alarm rate (Fa), and intersection over union (IoU). The\ncode is available at: https://github.com/luy0222/RealScene-ISTD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T07:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.16492v1","title":"Tourism diversification paths in ski mid-mountain territories: any\n  transformations?","summary":"In the context of adapting to global changes, the diversification of the\ntourist offer seems to be a solution for the mid-mountain areas, which are\nstructured around and dependent on ski tourism. However, it remains unclear how\ntourism diversification occurs, what forms it can take and what it produces at\na territorial scale. In this study, we apply a theory of regional\ndiversification to the case of tourism in order to examine tourism\ndiversification paths. We base our analysis on qualitative data collected on\ntwo French study areas: the intercommunities of the massif du Sancy and of the\nHaut-Chablais. Our results show a pattern in tourism diversification paths,\nfollowing three steps that can lead to the abandonment of the perimeter of the\nski resort. However, among the different types of tourism diversification\ntrajectories, only a saltation form of tourism diversification can lead to the\nestablishment of a larger and more diversified tourism system. Our findings\nalso show that several types of tourism diversification paths can coexist at a\nterritorial scale.","main_category":"q-fin.RM","categories":"q-fin.RM","published":"2025-04-23T08:08:47Z"}
{"aid":"http://arxiv.org/abs/2504.16502v1","title":"Helping Blind People Grasp: Enhancing a Tactile Bracelet with an\n  Automated Hand Navigation System","summary":"Grasping constitutes a critical challenge for visually impaired people. To\naddress this problem, we developed a tactile bracelet that assists in grasping\nby guiding the user's hand to a target object using vibration commands. Here we\ndemonstrate the fully automated system around the bracelet, which can\nconfidently detect and track target and distractor objects and reliably guide\nthe user's hand. We validate our approach in three tasks that resemble complex,\neveryday use cases. In a grasping task, the participants grasp varying target\nobjects on a table, guided via the automated hand navigation system. In the\nmultiple objects task, participants grasp objects from the same class,\ndemonstrating our system's ability to track one specific object without\ntargeting surrounding distractor objects. Finally, the participants grasp one\nspecific target object by avoiding an obstacle along the way in the depth\nnavigation task, showcasing the potential to utilize our system's depth\nestimations to navigate even complex scenarios. Additionally, we demonstrate\nthat the system can aid users in the real world by testing it in a less\nstructured environment with a blind participant. Overall, our results\ndemonstrate that the system, by translating the AI-processed visual inputs into\na reduced data rate of actionable signals, enables autonomous behavior in\neveryday environments, thus potentially increasing the quality of life of\nvisually impaired people.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T08:24:24Z"}
{"aid":"http://arxiv.org/abs/2504.16511v1","title":"QuaDMix: Quality-Diversity Balanced Data Selection for Efficient LLM\n  Pretraining","summary":"Quality and diversity are two critical metrics for the training data of large\nlanguage models (LLMs), positively impacting performance. Existing studies\noften optimize these metrics separately, typically by first applying quality\nfiltering and then adjusting data proportions. However, these approaches\noverlook the inherent trade-off between quality and diversity, necessitating\ntheir joint consideration. Given a fixed training quota, it is essential to\nevaluate both the quality of each data point and its complementary effect on\nthe overall dataset. In this paper, we introduce a unified data selection\nframework called QuaDMix, which automatically optimizes the data distribution\nfor LLM pretraining while balancing both quality and diversity. Specifically,\nwe first propose multiple criteria to measure data quality and employ domain\nclassification to distinguish data points, thereby measuring overall diversity.\nQuaDMix then employs a unified parameterized data sampling function that\ndetermines the sampling probability of each data point based on these quality\nand diversity related labels. To accelerate the search for the optimal\nparameters involved in the QuaDMix framework, we conduct simulated experiments\non smaller models and use LightGBM for parameters searching, inspired by the\nRegMix method. Our experiments across diverse models and datasets demonstrate\nthat QuaDMix achieves an average performance improvement of 7.2% across\nmultiple benchmarks. These results outperform the independent strategies for\nquality and diversity, highlighting the necessity and ability to balance data\nquality and diversity.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T08:36:50Z"}
{"aid":"http://arxiv.org/abs/2504.16515v1","title":"Federated Learning of Low-Rank One-Shot Image Detection Models in Edge\n  Devices with Scalable Accuracy and Compute Complexity","summary":"This paper introduces a novel federated learning framework termed LoRa-FL\ndesigned for training low-rank one-shot image detection models deployed on edge\ndevices. By incorporating low-rank adaptation techniques into one-shot\ndetection architectures, our method significantly reduces both computational\nand communication overhead while maintaining scalable accuracy. The proposed\nframework leverages federated learning to collaboratively train lightweight\nimage recognition models, enabling rapid adaptation and efficient deployment\nacross heterogeneous, resource-constrained devices. Experimental evaluations on\nthe MNIST and CIFAR10 benchmark datasets, both in an\nindependent-and-identically-distributed (IID) and non-IID setting, demonstrate\nthat our approach achieves competitive detection performance while\nsignificantly reducing communication bandwidth and compute complexity. This\nmakes it a promising solution for adaptively reducing the communication and\ncompute power overheads, while not sacrificing model accuracy.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T08:40:44Z"}
{"aid":"http://arxiv.org/abs/2504.16518v1","title":"Preconditioning Natural and Second Order Gradient Descent in Quantum\n  Optimization: A Performance Benchmark","summary":"The optimization of parametric quantum circuits is technically hindered by\nthree major obstacles: the non-convex nature of the objective function, noisy\ngradient evaluations, and the presence of barren plateaus. As a result, the\nselection of classical optimizer becomes a critical factor in assessing and\nexploiting quantum-classical applications. One promising approach to tackle\nthese challenges involves incorporating curvature information into the\nparameter update. The most prominent methods in this field are quasi-Newton and\nquantum natural gradient methods, which can facilitate faster convergence\ncompared to first-order approaches. Second order methods however exhibit a\nsignificant trade-off between computational cost and accuracy, as well as\nheightened sensitivity to noise. This study evaluates the performance of three\nfamilies of optimizers on synthetically generated MaxCut problems on a shallow\nQAOA algorithm. To address noise sensitivity and iteration cost, we demonstrate\nthat incorporating secant-penalization in the BFGS update rule (SP-BFGS) yields\nimproved outcomes for QAOA optimization problems, introducing a novel approach\nto stabilizing BFGS updates against gradient noise.","main_category":"cs.CE","categories":"cs.CE,quant-ph","published":"2025-04-23T08:44:18Z"}
{"aid":"http://arxiv.org/abs/2504.16525v1","title":"Gravitational Positivity Bounds on Higgs-Portal Dark Matter","summary":"We consider gravitational positivity bounds on the Higgs-portal scalar dark\nmatter model. Applying gravitational positivity bounds with dark matter forward\nscattering process $\\phi \\phi \\to \\phi \\phi$ to this DM model, we find that the\nnew physics, besides the Higgs-portal dark matter physics, arises at an energy\nscale lower than $10^{10}$ GeV without the dark matter self-coupling. With the\nexistence of the dark matter self-coupling, the hierarchical order of magnitude\nbetween the self-coupling $\\lambda_{\\phi}$ and the Higgs-portal coupling\n$\\lambda_{h\\phi}$ changes the game. With $\\lambda_{\\phi}/\\lambda_{h\\phi} =\n10^{12}$, the GUT scale cutoff can realize. In this case, the dark freezeout\nscenario is possible for realizing the relic density of dark matter in the\nUniverse. We find that $\\lambda_{\\phi} \\sim O(1)$, $\\lambda_{h\\phi} \\sim\n10^{-12}$, and sub-GeV dark matter is implicated for the GUT scale cutoff\npossibility with the Higgs-portal dark matter model.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T08:49:36Z"}
{"aid":"http://arxiv.org/abs/2504.16533v1","title":"SafeSpect: Safety-First Augmented Reality Heads-up Display for Drone\n  Inspections","summary":"Current tablet-based interfaces for drone operations often impose a heavy\ncognitive load on pilots and reduce situational awareness by dividing attention\nbetween the video feed and the real world. To address these challenges, we\ndesigned a heads-up augmented reality (AR) interface that overlays in-situ\ninformation to support drone pilots in safety-critical tasks. Through\nparticipatory design workshops with professional pilots, we identified key\nfeatures and developed an adaptive AR interface that dynamically switches\nbetween task and safety views to prevent information overload. We evaluated our\nprototype by creating a realistic building inspection task and comparing three\ninterfaces: a 2D tablet, a static AR, and our adaptive AR design. A user study\nwith 15 participants showed that the AR interface improved access to safety\ninformation, while the adaptive AR interface reduced cognitive load and\nenhanced situational awareness without compromising task performance. We offer\ndesign insights for developing safety-first heads-up AR interfaces.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T08:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.16549v1","title":"Exponential mixing of random interval diffeomorphisms","summary":"We consider a finite number of orientation preserving $C^2$ interval\ndiffeomorphisms and apply them randomly in such a way that the expected\nLyapunov exponents at the boundary points are positive. We prove the\nexponential mixing, with respect to the unique stationary measure supported on\nthe interior of the interval. The key step is to show the exponential\nsynchronization in average.","main_category":"math.DS","categories":"math.DS","published":"2025-04-23T09:25:49Z"}
{"aid":"http://arxiv.org/abs/2504.16551v1","title":"A new approach for the unitary Dyson Brownian motion through the theory\n  of viscosity solutions","summary":"In this paper, we study the unitary Dyson Brownian motion through a partial\ndifferential equation approach recently introduced for the real Dyson case. The\nmain difference with the real Dyson case is that the spectrum is now on the\ncircle and not on the real line, which leads to particular attention to\ncomparison principles. First we recall why the system of particles which are\nthe eigenvalues of unitary Dyson Brownian motion is well posed thanks to a\ncontainment function. Then we proved that the primitive of the limit spectral\nmeasure of the unitary Dyson Brownian motion is the unique solution to a\nviscosity equation obtained by primitive the Dyson equation on the circle.\nFinally, we study some properties of solutions of Dyson's equation on the\ncircle. We prove a L $\\infty$ regularization. We also look at the long time\nbehaviour in law of a solution through a study of the so-called free entropy of\nthe system. We conclude by discussing the uniform convergence towards the\nuniform measure on the circle of a solution of the Dyson equation.","main_category":"math.AP","categories":"math.AP,math.PR","published":"2025-04-23T09:27:42Z"}
{"aid":"http://arxiv.org/abs/2504.16558v1","title":"The TeraZ Mirage: New Physics Lost in Blind Directions","summary":"The next generation of high-luminosity electron-positron colliders, such as\nFCC-ee and CEPC operating at the $Z$ pole (TeraZ), is expected to deliver\nunprecedented precision in electroweak measurements. These precision\nobservables are typically interpreted within the Standard Model Effective Field\nTheory (SMEFT), offering a powerful tool to constrain new physics. However, the\nlarge number of independent SMEFT operators allows for the possibility of blind\ndirections, parameter combinations to which electroweak precision data are\nlargely insensitive. In this work, we demonstrate that such blind directions\nare not merely an artefact of agnostic effective field theory scans, but arise\ngenerically in realistic ultraviolet completions involving multiple heavy\nfields. We identify several concrete multi-field extensions of the Standard\nModel whose low-energy SMEFT projections align with known blind subspaces, and\nshow that these persist even after accounting for renormalisation group\nevolution and finite one-loop matching effects. Our analysis highlights that\nthe apparent sensitivity to new physics of TeraZ may be significantly\noverestimated, and that indirect searches alone are often insufficient to rule\nout broad classes of ultraviolet physics. Complementary high-energy collider\nprobes are therefore essential to fully explore the SMEFT parameter space.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T09:34:07Z"}
{"aid":"http://arxiv.org/abs/2504.16576v1","title":"MMHCL: Multi-Modal Hypergraph Contrastive Learning for Recommendation","summary":"The burgeoning presence of multimodal content-sharing platforms propels the\ndevelopment of personalized recommender systems. Previous works usually suffer\nfrom data sparsity and cold-start problems, and may fail to adequately explore\nsemantic user-product associations from multimodal data. To address these\nissues, we propose a novel Multi-Modal Hypergraph Contrastive Learning (MMHCL)\nframework for user recommendation. For a comprehensive information exploration\nfrom user-product relations, we construct two hypergraphs, i.e. a user-to-user\n(u2u) hypergraph and an item-to-item (i2i) hypergraph, to mine shared\npreferences among users and intricate multimodal semantic resemblance among\nitems, respectively. This process yields denser second-order semantics that are\nfused with first-order user-item interaction as complementary to alleviate the\ndata sparsity issue. Then, we design a contrastive feature enhancement paradigm\nby applying synergistic contrastive learning. By maximizing/minimizing the\nmutual information between second-order (e.g. shared preference pattern for\nusers) and first-order (information of selected items for users) embeddings of\nthe same/different users and items, the feature distinguishability can be\neffectively enhanced. Compared with using sparse primary user-item interaction\nonly, our MMHCL obtains denser second-order hypergraphs and excavates more\nabundant shared attributes to explore the user-product associations, which to a\ncertain extent alleviates the problems of data sparsity and cold-start.\nExtensive experiments have comprehensively demonstrated the effectiveness of\nour method. Our code is publicly available at: https://github.com/Xu107/MMHCL.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-23T09:58:54Z"}
{"aid":"http://arxiv.org/abs/2504.16582v1","title":"Nanomechanics and Pore Structure of Sodium and Potassium Geopolymer\n  Gels: Experiments, Molecular Dynamics and Coarse-Grained Simulations","summary":"The link between composition, microstructure and mechanics of NASH and KASH\ngels is elusive, even in pure metakaolin-based geopolymes. This article\nexploits molecular mechanics, coarse-grained nanomechanics and micromechanics,\nto interpret new experimental results from microscopy, porosimetry and\nnanoindentation. KASH displays a finer nanogranular structure than NASH (3 vs\n30 nm particle diameters, 5 vs 50 nm average pore diameters), higher skeletal\ndensity (2.3 vs 2.02 g/cm$^3$), nanoindentation moduli (9.21 vs 7.5 GPa) and\nhardness (0.56 vs 0.37 GPa) despite a higher total porosity (0.48-0.53 vs\n0.38). This suggests a stiffer and stronger solid skeleton for KASH, confirmed\nthrough predictive molecular dynamics simulations on recent and new models of\nNASH and KASH. The atomistic simulations inform mechanical interactions for\nnew, coarse-grained, particle-based models of NASH and KASH. The resulting\nsimulations predict the nanoindentation result that KASH is stiffer than\nequally porous NASH and the impact of formation eigenstresses on elastic\nmoduli.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T10:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.16588v1","title":"Data-Assimilated Model-Based Reinforcement Learning for Partially\n  Observed Chaotic Flows","summary":"The goal of many applications in energy and transport sectors is to control\nturbulent flows. However, because of chaotic dynamics and high dimensionality,\nthe control of turbulent flows is exceedingly difficult. Model-free\nreinforcement learning (RL) methods can discover optimal control policies by\ninteracting with the environment, but they require full state information,\nwhich is often unavailable in experimental settings. We propose a\ndata-assimilated model-based RL (DA-MBRL) framework for systems with partial\nobservability and noisy measurements. Our framework employs a control-aware\nEcho State Network for data-driven prediction of the dynamics, and integrates\ndata assimilation with an Ensemble Kalman Filter for real-time state\nestimation. An off-policy actor-critic algorithm is employed to learn optimal\ncontrol strategies from state estimates. The framework is tested on the\nKuramoto-Sivashinsky equation, demonstrating its effectiveness in stabilizing a\nspatiotemporally chaotic flow from noisy and partial measurements.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY,physics.flu-dyn","published":"2025-04-23T10:12:53Z"}
{"aid":"http://arxiv.org/abs/2504.16594v1","title":"Equivariant spaces of matrices of constant corank one","summary":"We study spaces of matrices coming from irreducible representations of\nreductive groups over an algebraically closed field of characteristic zero and\nwe completely classify those of constant corank one. In particular, we recover\nthe examples coming from symmetric forms discovered in [BFL22].","main_category":"math.AG","categories":"math.AG,math.RT","published":"2025-04-23T10:23:28Z"}
{"aid":"http://arxiv.org/abs/2504.16595v1","title":"HERB: Human-augmented Efficient Reinforcement learning for Bin-packing","summary":"Packing objects efficiently is a fundamental problem in logistics, warehouse\nautomation, and robotics. While traditional packing solutions focus on\ngeometric optimization, packing irregular, 3D objects presents significant\nchallenges due to variations in shape and stability. Reinforcement\nLearning~(RL) has gained popularity in robotic packing tasks, but training\npurely from simulation can be inefficient and computationally expensive. In\nthis work, we propose HERB, a human-augmented RL framework for packing\nirregular objects. We first leverage human demonstrations to learn the best\nsequence of objects to pack, incorporating latent factors such as space\noptimization, stability, and object relationships that are difficult to model\nexplicitly. Next, we train a placement algorithm that uses visual information\nto determine the optimal object positioning inside a packing container. Our\napproach is validated through extensive performance evaluations, analyzing both\npacking efficiency and latency. Finally, we demonstrate the real-world\nfeasibility of our method on a robotic system. Experimental results show that\nour method outperforms geometric and purely RL-based approaches by leveraging\nhuman intuition, improving both packing robustness and adaptability. This work\nhighlights the potential of combining human expertise-driven RL to tackle\ncomplex real-world packing challenges in robotic systems.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-23T10:24:36Z"}
{"aid":"http://arxiv.org/abs/2504.16601v1","title":"Comparing Large Language Models and Traditional Machine Translation\n  Tools for Translating Medical Consultation Summaries: A Pilot Study","summary":"This study evaluates how well large language models (LLMs) and traditional\nmachine translation (MT) tools translate medical consultation summaries from\nEnglish into Arabic, Chinese, and Vietnamese. It assesses both patient,\nfriendly and clinician, focused texts using standard automated metrics. Results\nshowed that traditional MT tools generally performed better, especially for\ncomplex texts, while LLMs showed promise, particularly in Vietnamese and\nChinese, when translating simpler summaries. Arabic translations improved with\ncomplexity due to the language's morphology. Overall, while LLMs offer\ncontextual flexibility, they remain inconsistent, and current evaluation\nmetrics fail to capture clinical relevance. The study highlights the need for\ndomain-specific training, improved evaluation methods, and human oversight in\nmedical translation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T10:31:33Z"}
{"aid":"http://arxiv.org/abs/2504.16607v1","title":"Path Matters: Industrial Data Meet Quantum Optimization","summary":"Real-world optimization problems must undergo a series of transformations\nbefore becoming solvable on current quantum hardware. Even for a fixed problem,\nthe number of possible transformation paths -- from industry-relevant\nformulations through binary constrained linear programs (BILPs), to quadratic\nunconstrained binary optimization (QUBO), and finally to a hardware-executable\nrepresentation -- is remarkably large. Each step introduces free parameters,\nsuch as Lagrange multipliers, encoding strategies, slack variables, rounding\nschemes or algorithmic choices -- making brute-force exploration of all paths\nintractable. In this work, we benchmark a representative subset of these\ntransformation paths using a real-world industrial production planning problem\nwith industry data: the optimization of work allocation in a press shop\nproducing vehicle parts. We focus on QUBO reformulations and algorithmic\nparameters for both quantum annealing (QA) and the Linear Ramp Quantum\nApproximate Optimization Algorithm (LR-QAOA). Our goal is to identify a reduced\nset of effective configurations applicable to similar industrial settings. Our\nresults show that QA on D-Wave hardware consistently produces near-optimal\nsolutions, whereas LR-QAOA on IBM quantum devices struggles to reach comparable\nperformance. Hence, the choice of hardware and solver strategy significantly\nimpacts performance. The problem formulation and especially the penalization\nstrategy determine the solution quality. Most importantly,\nmathematically-defined penalization strategies are equally successful as\nhand-picked penalty factors, paving the way for automated QUBO formulation.\nMoreover, we observe a strong correlation between simulated and quantum\nannealing performance metrics, offering a scalable proxy for predicting QA\nbehavior on larger problem instances.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T10:45:38Z"}
{"aid":"http://arxiv.org/abs/2504.16608v1","title":"A hybrid high-order method for the biharmonic problem","summary":"This paper proposes a new hybrid high-order discretization for the biharmonic\nproblem and the corresponding eigenvalue problem. The discrete ansatz space\nincludes degrees of freedom in $n-2$ dimensional submanifolds (e.g., nodal\nvalues in 2D and edge values in 3D), in addition to the typical degrees of\nfreedom in the mesh and on the hyperfaces in the HHO literature. This approach\nenables the characteristic commuting property of the hybrid high-order\nmethodology in any space dimension and allows for lower eigenvalue bounds of\nhigher order for the eigenvalue problem. The main results are quasi-best\napproximation estimates as well as reliable and efficient error control. The\nlatter motivates an adaptive mesh-refining algorithm that empirically recovers\noptimal convergence rates for singular solutions.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-23T10:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.16631v1","title":"Density of states and non-smooth Lyapunov exponent in the localized\n  phase","summary":"Localization of wave functions in the disordered models can be characterized\nby the Lyapunov exponent, which is zero in the extended phase and nonzero in\nthe localized phase. Previous studies have shown that this exponent is a smooth\nfunction of eigenenergy in the same phase, thus its non-smoothness can serve as\nstrong evidence to determine the phase transition from the extended phase to\nthe localized phase. However, logically, there is no fundamental reason that\nprohibits this Lyapunov exponent from being non-smooth in the localized phase.\nIn this work, we show that if the localization centers are inhomogeneous in the\nwhole chain and if the system possesses (at least) two different localization\nmodes, the Lyapunov exponent can become non-smooth in the localized phase at\nthe boundaries between the different localization modes. We demonstrate these\nresults using several slowly varying models and show that the singularities of\ndensity of states are essential to these non-smoothness, according to the\nThouless formula. These results can be generalized to higher-dimensional\nmodels, suggesting the possible delicate structures in the localized phase,\nwhich can revise our understanding of localization hence greatly advance our\ncomprehension of Anderson localization.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-23T11:44:44Z"}
{"aid":"http://arxiv.org/abs/2504.16645v1","title":"Preliminary design of a Cavity Tuner for Superconducting Radio-Frequency\n  Cavity","summary":"This paper introduces a newly designed cavity tuner for superconducting\nradio-frequency (SRF) cavity. Aiming to overcome the drawbacks of traditional\ntuning systems, like the limited tuning range of piezoelectric tuner and the\nlow-speed tuning of stepper-motor-based tuner, this novel tuner is crafted to\nimprove SRF cavity performance and stability via efficient and accurate\nfrequency tuning. The design encompasses several key elements. The cavity\nstructure includes a commonly used 1.3 GHz single-cell superconducting cavity\nand a room-temperature coaxial tuner cavity. The coupling mechanism between the\ntwo cavities, along with the coupling window design, ensures effective energy\ntransfer while minimizing losses. The mechanical tuning system, driven by\nelectromagnetic coils, enables precise adjustments, and the cooling mechanisms\nfor both cavities guarantee stable operation. Functioning by coupling an\nexternal resonant cavity to the superconducting one, this tuner can adjust\nfrequencies through mechanical or electromagnetic methods. It realizes rapid\ntuning, with a speed much faster than traditional mechanical tuner,\nhigh-precision tuning down to the sub-mHz level, and a wide tuning range\ncovering a broader frequency spectrum. Theoretical analysis and simulations\nverify that the tuner can remarkably enhance tuning speed, precision, and\nrange. It also has distinct advantages such as a simplified structure, which\nreduces manufacturing and maintenance complexity, and enhanced reliability due\nto its non-contact tuning operation. In particle accelerators, this cavity\ntuner holds great potential. It represents a significant step forward in\nsuperconducting accelerator technology, offering a novel way to optimize the\nperformance and stability of SRF cavity.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-23T12:05:34Z"}
{"aid":"http://arxiv.org/abs/2504.16652v1","title":"Non-linearity Effect Analysis of Gaussian Pulse Propagation In Optical\n  Fiber","summary":"In this research, numerical analysis of nonlinear pulse propagation is\ncarried out. This is done mainly by solving the nonlinear Schrodinger equation\nusing the split step algorithm. In a nonlinear media, dispersive effects exist\nsimultaneously with nonlinear effects. Refractive index dependence on intensity\nresults in optical Kerr effect which causes narrowing of transmitted pulses by\ninducing self-phase modulation while second order group velocity dispersion\ncauses the pulses to spread. In this project, group velocity dispersion is\ndiscussed followed by self-phase modulation. These individually detrimental\neffects are shown to combine beneficially for propagation of pulses here.\nGaussian pulse is studied and propagated by using them as input in to the\nnonlinear Schrodinger equation. The split step algorithm is described in depth.\nExplanation of each step is included along with the relevant equations defining\nthese steps.","main_category":"physics.optics","categories":"physics.optics,eess.SP","published":"2025-04-23T12:17:43Z"}
{"aid":"http://arxiv.org/abs/2504.16654v1","title":"International Comparisons: Multilateral Indices and Nonparametric\n  Welfare Bounds","summary":"Multilateral index numbers, such as those used to make international\ncomparisons of prices and income, are fundamental objects in economics.\nHowever, these numbers are often challenging to interpret in terms of economic\nwelfare as a data-dependent 'taste bias' can arise for these indices that\ndistorts measurement of price and income levels and dispersion. To study this\nproblem, I develop a means to appraise indices' economic interpretability using\nnon-parametric bounds on a true cost-of-living index. These bounds improve upon\ntheir classical counterparts, define a new class of indices, and can correct\nexisting indices for preference misspecification. In my main application I\napprise existing international comparison methods. I find that taste bias\ngenerally leads to overestimates (underestimates) of price (income) levels.\nSuperlative indices, such as the Fisher-GEKS index, lie within the permitted\nbounds more frequently than non-superlative methods, but the mean size of this\nbias is modest in all examined cases. My results can thus be interpreted as\nsupporting the economic validity of the myriad multilateral methods which are\nin practical use.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-23T12:22:12Z"}
{"aid":"http://arxiv.org/abs/2504.16658v1","title":"A Time Series Dataset of NIR Spectra and RGB and NIR-HSI Images of the\n  Barley Germination Process","summary":"We provide an open-source dataset of RGB and NIR-HSI (near-infrared\nhyperspectral imaging) images with associated segmentation masks and NIR\nspectra of 2242 individual malting barley kernels. We imaged every kernel\npre-exposure to moisture and every 24 hours after exposure to moisture for five\nconsecutive days. Every barley kernel was labeled as germinated or not\ngerminated during each image acquisition. The barley kernels were imaged with\nblack filter paper as the background, facilitating straight-forward intensity\nthreshold-based segmentation, e.g., by Otsu's method. This dataset facilitates\ntime series analysis of germination time for barley kernels using either RGB\nimage analysis, NIR spectral analysis, NIR-HSI analysis, or a combination\nhereof.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T12:25:55Z"}
{"aid":"http://arxiv.org/abs/2504.16663v1","title":"Online and feasible presentability: from trees to modal algebras","summary":"We investigate whether every computable member of a given class of structures\nadmits a fully primitive recursive (also known as punctual) or fully P-TIME\ncopy. A class with this property is referred to as punctually robust or P-TIME\nrobust, respectively. We present both positive and negative results for\nstructures corresponding to well-known representations of trees, such as binary\ntrees, ordered trees, sequential (or prefix) trees, and partially ordered\n(poset) trees. A corollary of one of our results on trees is that semilattices\nand lattices are not punctually robust. In the main result of the paper, we\ndemonstrate that, unlike Boolean algebras, modal algebras - that is, Boolean\nalgebras with modality - are not punctually robust. The question of whether\ndistributive lattices are punctually robust remains open. The paper contributes\nto a decades-old program on effective and feasible algebra, which has recently\ngained momentum due to rapid developments in punctual structure theory and its\nconnections to online presentations of structures.","main_category":"math.LO","categories":"math.LO,cs.CC","published":"2025-04-23T12:31:44Z"}
{"aid":"http://arxiv.org/abs/2504.16665v1","title":"A Diff-Attention Aware State Space Fusion Model for Remote Sensing\n  Classification","summary":"Multispectral (MS) and panchromatic (PAN) images describe the same land\nsurface, so these images not only have their own advantages, but also have a\nlot of similar information. In order to separate these similar information and\ntheir respective advantages, reduce the feature redundancy in the fusion stage.\nThis paper introduces a diff-attention aware state space fusion model\n(DAS2F-Model) for multimodal remote sensing image classification. Based on the\nselective state space model, a cross-modal diff-attention module (CMDA-Module)\nis designed to extract and separate the common features and their respective\ndominant features of MS and PAN images. Among this, space preserving visual\nmamba (SPVM) retains image spatial features and captures local features by\noptimizing visual mamba's input reasonably. Considering that features in the\nfusion stage will have large semantic differences after feature separation and\nsimple fusion operations struggle to effectively integrate these significantly\ndifferent features, an attention-aware linear fusion module (AALF-Module) is\nproposed. It performs pixel-wise linear fusion by calculating influence\ncoefficients. This mechanism can fuse features with large semantic differences\nwhile keeping the feature size unchanged. Empirical evaluations indicate that\nthe presented method achieves better results than alternative approaches. The\nrelevant code can be found at:https://github.com/AVKSKVL/DAS-F-Model","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T12:34:32Z"}
{"aid":"http://arxiv.org/abs/2504.16681v1","title":"On the origin of long-term modulation in the Sun's magnetic activity\n  cycle","summary":"One of the most striking manifestations of orderly behavior emerging out of\ncomplex interactions in any astrophysical system is the 11-year cycle of\nsunspots. However, direct sunspot observations and reconstructions of long-term\nsolar activity clearly exhibit amplitude fluctuations beyond the decadal\ntimescale -- which may be termed as supradecadal modulation. Whether this\nlong-term modulation in the Sun's magnetic activity results from nonlinear\nmechanisms or stochastic perturbations remains controversial and a matter of\nactive debate. Utilizing multi-millennial scale kinematic dynamo simulations\nbased on the Babcock-Leighton paradigm -- in the likely (near-critical) regime\nof operation of the solar dynamo -- we demonstrate that this supradecadal\nmodulation in solar activity cannot be explained by nonlinear mechanisms alone;\nstochastic forcing is essential for the manifestation of observed long-term\nfluctuations in the near-critical dynamo regime. Our findings substantiate some\nindependent observational and theoretical investigations, and provide\nadditional insights into temporal dynamics associated with a plethora of\nnatural phenomena in astronomy and planetary systems arising from weakly\nnonlinear, non-deterministic processes.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T13:01:12Z"}
{"aid":"http://arxiv.org/abs/2504.16685v1","title":"Outer regions of galaxy clusters as a new probe to test modifications to\n  gravity","summary":"We apply the caustic technique to samples of galaxy clusters stacked in\nredshift space to estimate the gravitational potential in the cluster's outer\nregion and test modifications to the standard theory of gravity. We separate\n122 galaxy clusters from the HeCS-SZ, HeCS-redMapper, and HeCS samples into\nfour samples with increasing mass; we estimate four robust, highly constraining\ncaustic profiles for these samples. The caustic masses of the four stacked\nclusters agree within $ 10\\%$ with the corresponding median values of each\ncluster sample. By adopting the NFW density profile to model the gravitational\npotential, we recover the caustic profile $\\mathcal{A}(r)$ up to radius $r_{\\rm\np} \\sim 4.0\\, {\\rm Mpc}$. This comparison is a first-order validation of the\nmass-concentration relation for galaxy clusters expected in the $\\Lambda$CDM\nmodel. We thus impose this correlation as a prior in our analysis. Based on our\nstacked clusters, we estimate the value of the filling factor, which enters the\ncaustic technique, $\\mathcal{F}_{\\beta} = 0.59\\pm 0.05$; we derive this value\nusing real data alone and find it consistent with the value usually adopted in\nthe literature. We then use the caustic profiles $\\mathcal{A}(r)$ of the\nstacked clusters to constrain the chameleon gravity model. We find that the\ncaustic profiles provide a stringent upper limit of $|f_{\\rm R0}| \\lesssim 4\n\\times 10^{-6}$ at $95\\%$ C.L. limits in the $f(\\mathcal{R})$ scenario. The\nformalism developed here shall be further refined to test modifications to\ngravity in the extended outer weak gravitational regions of galaxy clusters.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-23T13:14:47Z"}
{"aid":"http://arxiv.org/abs/2504.16706v1","title":"Sorting as Gradient Flow on the Permutohedron","summary":"We investigate how sorting algorithms efficiently overcome the exponential\nsize of the permutation space. Our main contribution is a new continuous-time\nformulation of sorting as a gradient flow on the permutohedron, yielding an\nindependent proof of the classical $\\Omega(n \\log n)$ lower bound for\ncomparison-based sorting. This formulation reveals how exponential contraction\nof disorder occurs under simple geometric dynamics. In support of this\nanalysis, we present algebraic, combinatorial, and geometric perspectives,\nincluding decision-tree arguments and linear constraints on the permutohedron.\nThe idea that efficient sorting arises from structure-guided logarithmic\nreduction offers a unifying lens for how comparisons tame exponential spaces.\nThese observations connect to broader questions in theoretical computer\nscience, such as whether the existence of structure can explain why certain\ncomputational problems permit efficient solutions.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T13:38:00Z"}
{"aid":"http://arxiv.org/abs/2504.16711v1","title":"A Unified Retrieval Framework with Document Ranking and EDU Filtering\n  for Multi-document Summarization","summary":"In the field of multi-document summarization (MDS), transformer-based models\nhave demonstrated remarkable success, yet they suffer an input length\nlimitation. Current methods apply truncation after the retrieval process to fit\nthe context length; however, they heavily depend on manually well-crafted\nqueries, which are impractical to create for each document set for MDS.\nAdditionally, these methods retrieve information at a coarse granularity,\nleading to the inclusion of irrelevant content. To address these issues, we\npropose a novel retrieval-based framework that integrates query selection and\ndocument ranking and shortening into a unified process. Our approach identifies\nthe most salient elementary discourse units (EDUs) from input documents and\nutilizes them as latent queries. These queries guide the document ranking by\ncalculating relevance scores. Instead of traditional truncation, our approach\nfilters out irrelevant EDUs to fit the context length, ensuring that only\ncritical information is preserved for summarization. We evaluate our framework\non multiple MDS datasets, demonstrating consistent improvements in ROUGE\nmetrics while confirming its scalability and flexibility across diverse model\narchitectures. Additionally, we validate its effectiveness through an in-depth\nanalysis, emphasizing its ability to dynamically select appropriate queries and\naccurately rank documents based on their relevance scores. These results\ndemonstrate that our framework effectively addresses context-length\nconstraints, establishing it as a robust and reliable solution for MDS.","main_category":"cs.LG","categories":"cs.LG,cs.IR","published":"2025-04-23T13:41:10Z"}
{"aid":"http://arxiv.org/abs/2504.16712v1","title":"Detecting Cosmological Phase Transitions with Taiji: Sensitivity\n  Analysis and Parameter Estimation","summary":"We investigate the capability of the Taiji space-based gravitational wave\nobservatory to detect stochastic gravitational wave backgrounds produced by\nfirst-order phase transitions in the early universe. Using a comprehensive\nsimulation framework that incorporates realistic instrumental noise, galactic\ndouble white dwarf confusion noise, and extragalactic compact binary\nbackgrounds, we systematically analyze Taiji's sensitivity across a range of\nsignal parameters. Our Bayesian analysis demonstrates that Taiji can robustly\ndetect and characterize phase transition signals with energy densities\nexceeding $\\Omega_{\\text{PT}} \\gtrsim 1.4 \\times 10^{-11}$ across most of its\nfrequency band, with particularly strong sensitivity around $10^{-3}$ to\n$10^{-2}$ Hz. For signals with amplitudes above $\\Omega_{\\text{PT}} \\gtrsim 1.1\n\\times 10^{-10}$, Taiji can determine the peak frequency with relative\nprecision better than $10\\%$. These detection capabilities would enable Taiji\nto probe electroweak-scale phase transitions in various beyond-Standard-Model\nscenarios, potentially revealing new physics connected to baryogenesis and dark\nmatter production. We quantify detection confidence using both Bayes factors\nand the Deviance Information Criterion, finding consistent results that\nvalidate our statistical methodology.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,astro-ph.IM","published":"2025-04-23T13:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.16714v1","title":"Room-temperature magnetoelectric coupling in strontium titanate","summary":"Magnetoelectric (ME) multiferroics enable efficient interconversion of\nelectrical and magnetic signals, offering pathways toward substantial reduction\nof power consumption in next-generation computing and information technologies.\nHowever, despite decades of research, the persistence of ME coupling at\nroom-temperature, an indispensable feature for practical applications, remains\nexceedingly rare in single-phase materials, due to symmetry constraints imposed\nby magnetic point groups and competing electronic requirements for\nferroelectricity and magnetism. Here we report the coexistence of\nferroelectricity and ferromagnetism at 780 K and a strong ME coupling with a\nconverse ME coupling coefficient up to 498 ps/m at room-temperature in\nstrontium titanate by dedicated vacancy engineering. The asymmetric\ndistribution of oxygen vacancies surrounding titanium vacancies enables atomic\ndisplacement of titanium and charge injection, providing joint origin for\nferroelectricity and ferromagnetism, as confirmed by atomic-scale structural\nanalysis and first-principles calculations. The mechanism of ME coupling is\noffered as the hopping of oxygen vacancies under electric fields, which leads\nto the rearrangement of electronic configuration. Our work opens an avenue for\ndesigning multiferroics, overcoming the long-standing scarcity of\nroom-temperature single-phase multiferroics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T13:42:37Z"}
{"aid":"http://arxiv.org/abs/2504.16718v1","title":"Simulating Quantum Circuits with Tree Tensor Networks using\n  Density-Matrix Renormalization Group Algorithm","summary":"Quantum computing offers the potential for computational abilities that can\ngo beyond classical machines. However, they are still limited by several\nchallenges such as noise, decoherence, and gate errors. As a result, efficient\nclassical simulation of quantum circuits is vital not only for validating and\nbenchmarking quantum hardware but also for gaining deeper insights into the\nbehavior of quantum algorithms. A promising framework for classical simulation\nis provided by tensor networks. Recently, the Density-Matrix Renormalization\nGroup (DMRG) algorithm was developed for simulating quantum circuits using\nmatrix product states (MPS). Although MPS is efficient for representing quantum\nstates with one-dimensional correlation structures, the fixed linear geometry\nrestricts the expressive power of the MPS. In this work, we extend the DMRG\nalgorithm for simulating quantum circuits to tree tensor networks (TTNs). To\nbenchmark the method, we simulate random and QAOA circuits with various\ntwo-qubit gate connectivities. For the random circuits, we devise tree-like\ngate layouts that are suitable for TTN and show that TTN requires less memory\nthan MPS for the simulations. For the QAOA circuits, a TTN construction that\nexploits graph structure significantly improves the simulation fidelities. Our\nfindings show that TTNs provide a promising framework for simulating quantum\ncircuits, particularly when gate connectivities exhibit clustering or a\nhierarchical structure.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T13:48:03Z"}
{"aid":"http://arxiv.org/abs/2504.16719v1","title":"Higher-order photon rings of an ultracompact object and their\n  interferometric pattern","summary":"A horizonless ultracompact object can have a stable antiphoton sphere, which\ncauses the strong deflection of photons inside the unstable photon sphere,\nleading to the formation of distinctive inner photon rings. In this work, we\npresent analytical descriptions for the shape, thickness and interference\npattern of higher-order inner photon rings. By taking the static spherically\nsymmetric Schwarzschild star with a photon sphere as an example, we find that\nits inner photon rings can be more non-circular and thicker than the outer\nones, and show that the inclusion of the inner photon rings can give rise to\nnew features in the interferometric pattern. Our formulae can also be applied\nto other ultracompact objects, providing a convenient way to study the\nobservational properties of their higher-order photon rings.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T13:49:44Z"}
{"aid":"http://arxiv.org/abs/2504.16724v1","title":"Adaptive Gradient Descent on Riemannian Manifolds with Nonnegative\n  Curvature","summary":"In this paper, we present an adaptive gradient descent method for\ngeodesically convex optimization on a Riemannian manifold with nonnegative\nsectional curvature. The method automatically adapts to the local geometry of\nthe function and does not use additional expensive computations other than\ncalculation of the derivative of the Riemannian exponential. We prove the\nconvergence of the method under the assumption of geodesic completeness. The\nperformance of the method is illustrated by experiments on the sphere, the\nmanifold of symmetric positive definite matrices equipped with the\nBures-Wasserstein metric.","main_category":"math.OC","categories":"math.OC","published":"2025-04-23T13:52:24Z"}
{"aid":"http://arxiv.org/abs/2504.16728v1","title":"IRIS: Interactive Research Ideation System for Accelerating Scientific\n  Discovery","summary":"The rapid advancement in capabilities of large language models (LLMs) raises\na pivotal question: How can LLMs accelerate scientific discovery? This work\ntackles the crucial first stage of research, generating novel hypotheses. While\nrecent work on automated hypothesis generation focuses on multi-agent\nframeworks and extending test-time compute, none of the approaches effectively\nincorporate transparency and steerability through a synergistic\nHuman-in-the-loop (HITL) approach. To address this gap, we introduce IRIS:\nInteractive Research Ideation System, an open-source platform designed for\nresearchers to leverage LLM-assisted scientific ideation. IRIS incorporates\ninnovative features to enhance ideation, including adaptive test-time compute\nexpansion via Monte Carlo Tree Search (MCTS), fine-grained feedback mechanism,\nand query-based literature synthesis. Designed to empower researchers with\ngreater control and insight throughout the ideation process. We additionally\nconduct a user study with researchers across diverse disciplines, validating\nthe effectiveness of our system in enhancing ideation. We open-source our code\nat https://github.com/Anikethh/IRIS-Interactive-Research-Ideation-System","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-23T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.16731v1","title":"300 μs optical cavity storage time and $\\mathbf{10^{-7}}$ active RAM\n  cancellation for $\\mathbf{10^{-19}}$ laser frequency stabilisation","summary":"Frequency stabilisation of lasers to optical reference cavities is an\nestablished method to achieve state-of-the-art stability. The strengths of this\nmethod are the high discriminator coefficient of optical cavities, and the\nlow-noise extraction of the stabilisation signal using modulation techniques.\nIn this Letter we report beyond state-of-the-art performance on both of these\nfundamentals, unlocking $10^{-19}$ fractional frequency laser stabilisation. We\nemploy a 68 cm long cavity to realise an optical storage time of 300\nmicroseconds, achieving ultrahigh frequency discrimination. We develop a simple\nand robust scheme to actively cancel residual amplitude modulation (RAM) at the\n$10^{-7}$ level in an annealed-proton-exchanged lithium-niobate waveguide\nelectro-optic-modulator (EOM).","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-23T14:02:41Z"}
{"aid":"http://arxiv.org/abs/2504.16760v1","title":"Lightweight Latent Verifiers for Efficient Meta-Generation Strategies","summary":"Verifiers are auxiliary models that assess the correctness of outputs\ngenerated by base large language models (LLMs). They play a crucial role in\nmany strategies for solving reasoning-intensive problems with LLMs. Typically,\nverifiers are LLMs themselves, often as large (or larger) than the base model\nthey support, making them computationally expensive. In this work, we introduce\na novel lightweight verification approach, LiLaVe, which reliably extracts\ncorrectness signals from the hidden states of the base LLM. A key advantage of\nLiLaVe is its ability to operate with only a small fraction of the\ncomputational budget required by traditional LLM-based verifiers. To\ndemonstrate its practicality, we couple LiLaVe with popular meta-generation\nstrategies, like best-of-n or self-consistency. Moreover, we design novel\nLiLaVe-based approaches, like conditional self-correction or conditional\nmajority voting, that significantly improve both accuracy and efficiency in\ngeneration tasks with smaller LLMs. Our work demonstrates the fruitfulness of\nextracting latent information from the hidden states of LLMs, and opens the\ndoor to scalable and resource-efficient solutions for reasoning-intensive\napplications.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-23T14:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.16767v1","title":"Online model learning with data-assimilated reservoir computers","summary":"We propose an online learning framework for forecasting nonlinear\nspatio-temporal signals (fields). The method integrates (i) dimensionality\nreduction, here, a simple proper orthogonal decomposition (POD) projection;\n(ii) a generalized autoregressive model to forecast reduced dynamics, here, a\nreservoir computer; (iii) online adaptation to update the reservoir computer\n(the model), here, ensemble sequential data assimilation.We demonstrate the\nframework on a wake past a cylinder governed by the Navier-Stokes equations,\nexploring the assimilation of full flow fields (projected onto POD modes) and\nsparse sensors. Three scenarios are examined: a na\\\"ive physical state\nestimation; a two-fold estimation of physical and reservoir states; and a\nthree-fold estimation that also adjusts the model parameters. The two-fold\nstrategy significantly improves ensemble convergence and reduces reconstruction\nerror compared to the na\\\"ive approach. The three-fold approach enables robust\nonline training of partially-trained reservoir computers, overcoming\nlimitations of a priori training. By unifying data-driven reduced order\nmodelling with Bayesian data assimilation, this work opens new opportunities\nfor scalable online model learning for nonlinear time series forecasting.","main_category":"cs.LG","categories":"cs.LG,physics.flu-dyn,stat.AP","published":"2025-04-23T14:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.16769v1","title":"Deep photonic reservoir computer for nonlinear equalization of 16-level\n  quadrature amplitude modulation signals","summary":"Photonic reservoir computer (PRC) is a kind of real-time and adaptive\nrecurrent neural network, where only weights in the readout layer require\ntraining. PRC is a promising tool to deal with the crucial issue of nonlinear\nequalization in optical fiber communications. Here we theoretically show a deep\nPRC for the nonlinear equalization of coherent signals with the format of 16-\nlevel quadrature amplitude modulation (16-QAM). The deep PRC consists of\ncascading injection-locked Fabry-Perot lasers with optical feedback. Both the\nin-phase component and the quadrature component of the 16-QAM signals are\nsimultaneously injected into the deep PRC in parallel, based on the wavelength\nmultiplexing of Fabry-Perot lasers. It is demonstrated that the deep PRC\nexhibits strong capability for the nonlinearity compensation of coherent\nsignals. The Q factor is improved by more than 1 dB for 16-QAM signals with\nlaunch powers above 10 dBm, associated with a bit rate of 240 Gbps and a\ntransmission distance of 50 km.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-23T14:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.16774v1","title":"Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors\n  and Cross-Model Attention Mechanism","summary":"The examination of chest X-ray images is a crucial component in detecting\nvarious thoracic illnesses. This study introduces a new image description\ngeneration model that integrates a Vision Transformer (ViT) encoder with\ncross-modal attention and a GPT-4-based transformer decoder. The ViT captures\nhigh-quality visual features from chest X-rays, which are fused with text data\nthrough cross-modal attention to improve the accuracy, context, and richness of\nimage descriptions. The GPT-4 decoder transforms these fused features into\naccurate and relevant captions. The model was tested on the National Institutes\nof Health (NIH) and Indiana University (IU) Chest X-ray datasets. On the IU\ndataset, it achieved scores of 0.854 (B-1), 0.883 (CIDEr), 0.759 (METEOR), and\n0.712 (ROUGE-L). On the NIH dataset, it achieved the best performance on all\nmetrics: BLEU 1--4 (0.825, 0.788, 0.765, 0.752), CIDEr (0.857), METEOR (0.726),\nand ROUGE-L (0.705). This framework has the potential to enhance chest X-ray\nevaluation, assisting radiologists in more precise and efficient diagnosis.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-23T14:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.16779v1","title":"Evaluating the Impact of a Yoga-Based Intervention on Software\n  Engineers' Well-Being","summary":"Software engineering tasks are high-stress and cognitively demanding.\nAdditionally, there is a latent risk of software engineers presenting burnout,\ndepression and anxiety. Established interventions in other fields centred\naround attention awareness have shown positive results in mental well-being.\n  We aim to test how effective a yoga intervention is in improving general\nwell-being in the workplace. For that, we designed, implemented and evaluated\nan eight-week yoga programme in a software development company. We used a\nmixed-methods data collection, using a survey of six psychometric scales, pre\nand post-intervention, and a weekly well-being scale during the programme. For\nmethod triangulation, we conducted a focus group with the organisers to obtain\nqualitative data. The quantitative results did not show any statistically\nsignificant improvement after the intervention. Meanwhile, the qualitative\nresults illustrated that participants felt better and liked the intervention.\n  We conclude that yoga has a positive impact, which, however, can easily get\noverlaid by contextual factors, especially with only a once-per-week\nintervention.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:54:09Z"}
{"aid":"http://arxiv.org/abs/2504.16780v1","title":"Linear Regression Using Hilbert-Space-Valued Covariates with Unknown\n  Reproducing Kernel","summary":"We present a new method of linear regression based on principal components\nusing Hilbert-space-valued covariates with unknown reproducing kernels. We\ndevelop a computationally efficient approach to estimation and derive\nasymptotic theory for the regression parameter estimates under mild\nassumptions. We demonstrate the approach in simulation studies as well as in\ndata analysis using two-dimensional brain images as predictors.","main_category":"math.ST","categories":"math.ST,stat.ME,stat.TH","published":"2025-04-23T14:55:58Z"}
{"aid":"http://arxiv.org/abs/2504.16797v1","title":"The extended adjoint state and nonlinearity in correlation-based passive\n  imaging","summary":"This articles investigates physics-based passive imaging problem, wherein one\ninfers an unknown medium using ambient noise and correlation of the noise\nsignal. We develop a general backpropagation framework via the so-called\nextended adjoint state, suitable for any linear PDE; crucially, this approach\nreduces by half the number of required PDE solves. Applications to several\ndifferent PDE models demonstrate the universality of our method. In addition,\nwe analyze the nonlinearity of the correlated model, revealing a surprising\ntangential cone condition-like structure, thereby advancing the state of the\nart towards a convergence guarantee for regularized reconstruction in passive\nimaging.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-23T15:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.16803v1","title":"Graph modification of bounded size to minor-closed classes as fast as\n  vertex deletion","summary":"A replacement action is a function $\\mathcal{L}$ that maps each graph $H$ to\na collection of graphs of size at most $|V(H)|$. Given a graph class\n$\\mathcal{H}$, we consider a general family of graph modification problems,\ncalled $\\mathcal{L}$-Replacement to $\\mathcal{H}$, where the input is a graph\n$G$ and the question is whether it is possible to replace some induced subgraph\n$H_1$ of $G$ on at most $k$ vertices by a graph $H_2$ in $\\mathcal{L}(H_1)$ so\nthat the resulting graph belongs to $\\mathcal{H}$. $\\mathcal{L}$-Replacement to\n$\\mathcal{H}$ can simulate many graph modification problems including vertex\ndeletion, edge deletion/addition/edition/contraction, vertex identification,\nsubgraph complementation, independent set deletion, (induced) matching\ndeletion/contraction, etc. We present two algorithms. The first one solves\n$\\mathcal{L}$-Replacement to $\\mathcal{H}$ in time $2^{{\\rm poly}(k)}\\cdot\n|V(G)|^2$ for every minor-closed graph class $\\mathcal{H}$, where {\\rm poly} is\na polynomial whose degree depends on $\\mathcal{H}$, under a mild technical\ncondition on $\\mathcal{L}$. This generalizes the results of Morelle, Sau,\nStamoulis, and Thilikos [ICALP 2020, ICALP 2023] for the particular case of\nVertex Deletion to $\\mathcal{H}$ within the same running time. Our second\nalgorithm is an improvement of the first one when $\\mathcal{H}$ is the class of\ngraphs embeddable in a surface of Euler genus at most $g$ and runs in time\n$2^{\\mathcal{O}(k^{9})}\\cdot |V(G)|^2$, where the $\\mathcal{O}(\\cdot)$ notation\ndepends on $g$. To the best of our knowledge, these are the first parameterized\nalgorithms with a reasonable parametric dependence for such a general family of\ngraph modification problems to minor-closed classes.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T15:21:55Z"}
{"aid":"http://arxiv.org/abs/2504.16815v1","title":"Distributed Unknown Input Observers for Discrete-Time Linear\n  Time-Invariant Systems","summary":"This paper introduces a Distributed Unknown Input Observer (D-UIO) design\nmethodology that uses a technique called node-wise detectability decomposition\nto estimate the state of a discrete-time linear time-invariant (LTI) system in\na distributed way, even when there are noisy measurements and unknown inputs.\nIn the considered scenario, sensors are associated to nodes of an underlying\ncommunication graph. Each node has a limited scope as it can only access local\nmeasurements and share data with its neighbors. The problem of designing the\nobserver gains is divided into two separate sub-problems: (i) design local\noutput injection gains to mitigate the impact of measurement noise, and (ii)\ndesign diffusive gains to compensate for the lack of information through a\nconsensus protocol. A direct and computationally efficient synthesis strategy\nis formulated by linear matrix inequalities (LMIs) and solved via semidefinite\nprogramming. Finally, two simulative scenarios are presented to illustrate the\neffectiveness of the distributed observer when two different node-wise\ndecompositions are adopted.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-23T15:33:24Z"}
{"aid":"http://arxiv.org/abs/2504.16820v1","title":"Symmetric Proofs in the Ideal Proof System","summary":"We consider the Ideal Proof System (IPS) introduced by Grochow and Pitassi\nand pose the question of which tautologies admit symmetric proofs, and of what\ncomplexity. The symmetry requirement in proofs is inspired by recent work\nestablishing lower bounds in other symmetric models of computation. We link the\nexistence of symmetric IPS proofs to the expressive power of logics such as\nfixed-point logic with counting and Choiceless Polynomial Time, specifically\nregarding the graph isomorphism problem. We identify relationships and\ntradeoffs between the symmetry of proofs and other parameters of IPS proofs\nsuch as size, degree and linearity. We study these on a number of standard\nfamilies of tautologies from proof complexity and finite model theory such as\nthe pigeonhole principle, the subset sum problem and the Cai-F\\\"urer-Immerman\ngraphs, exhibiting non-trivial upper bounds on the size of symmetric IPS\nproofs.","main_category":"cs.LO","categories":"cs.LO,cs.CC","published":"2025-04-23T15:38:05Z"}
{"aid":"http://arxiv.org/abs/2504.16835v1","title":"Robust Accelerated Dynamics for Subnetwork Bilinear Zero-Sum Games with\n  Distributed Restarting","summary":"In this paper, we investigate distributed Nash equilibrium seeking for a\nclass of two-subnetwork zero-sum games characterized by bilinear coupling. We\npresent a distributed primal-dual accelerated mirror-descent algorithm that\nguarantees convergence. However, we demonstrate that this time-varying\nalgorithm is not robust, as it fails to converge under even the slightest\ndisturbances. To address this limitation, we introduce a distributed\naccelerated algorithm that employs a coordinated restarting mechanism. We model\nthis new algorithm as a hybrid dynamical system and establish that it possesses\nstructural robustness.","main_category":"math.OC","categories":"math.OC","published":"2025-04-23T15:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.16850v1","title":"Comparative analysis of finite-size ammonia and n-heptane droplets\n  evaporation rates in weakly compressible homogeneous turbulence: an\n  interface-resolved Direct Numerical Simulation study","summary":"This study presents direct numerical simulation (DNS) of finite-size,\ninterface-resolved ammonia and n-heptane droplets evaporating in decaying\nhomogeneous isotropic turbulence. Simulations are conducted for each fuel in a\ndense spray region, where the liquid volume fraction exceeds\n$\\mathcal{O}(10^{-2})$. The focus is on investigating the complex interactions\nbetween droplets, turbulence, and phase change, with emphasis on\ndroplet-droplet interactions and their influence on the evaporation process. We\nprovide state-of-the-art insights into the evaporation characteristics of two\ndifferent fuels under turbulent conditions, aiming to provide a deeper\nunderstanding of their different evaporation rates in spray-combustion\napplications. To this end, the present study also explores how varying\nturbulence intensities affect the evaporation rates of each fuel, revealing\ndifferences in coalescence behavior and energy transfer from the liquid to the\ngaseous phase. These findings are crucial to the improvement of predictive CFD\nmodels and to the optimization of fuel injection in spray-combustion\napplications, especially under high-pressure conditions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T16:11:29Z"}
{"aid":"http://arxiv.org/abs/2504.16854v1","title":"Energetics of the nucleation and glide of disconnection modes in\n  symmetric tilt grain boundaries","summary":"GBs evolve by the nucleation and glide of disconnections, which are\ndislocations with a step character. In this work, motivated by recent success\nin predicting GB properties such as the shear coupling factor and mobility from\nthe intrinsic properties of disconnections, we develop a systematic method to\ncalculate the energy barriers for the nucleation and glide of individual\ndisconnection modes under arbitrary driving forces. This method combines tools\nfrom bicrystallography to enumerate disconnection modes and the NEB method to\ncalculate their energetics, yielding minimum energy paths and atomistic\nmechanisms for the nucleation and glide of each disconnection mode. We apply\nthe method to accurately predict shear coupling factors of [001] symmetric tilt\ngrain boundaries in Cu. Particular attention is paid to the boundaries where\nthe classical disconnection nucleation model produces incorrect nucleation\nbarriers. We demonstrate that the method can accurately compute the energy\nbarriers and predict the shear coupling factors for low temperature regime.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T16:23:04Z"}
{"aid":"http://arxiv.org/abs/2504.16856v1","title":"Emo Pillars: Knowledge Distillation to Support Fine-Grained\n  Context-Aware and Context-Less Emotion Classification","summary":"Most datasets for sentiment analysis lack context in which an opinion was\nexpressed, often crucial for emotion understanding, and are mainly limited by a\nfew emotion categories. Foundation large language models (LLMs) like GPT-4\nsuffer from over-predicting emotions and are too resource-intensive. We design\nan LLM-based data synthesis pipeline and leverage a large model, Mistral-7b,\nfor the generation of training examples for more accessible, lightweight\nBERT-type encoder models. We focus on enlarging the semantic diversity of\nexamples and propose grounding the generation into a corpus of narratives to\nproduce non-repetitive story-character-centered utterances with unique contexts\nover 28 emotion classes. By running 700K inferences in 450 GPU hours, we\ncontribute with the dataset of 100K contextual and also 300K context-less\nexamples to cover both scenarios. We use it for fine-tuning pre-trained\nencoders, which results in several Emo Pillars models. We show that Emo Pillars\nmodels are highly adaptive to new domains when tuned to specific tasks such as\nGoEmotions, ISEAR, IEMOCAP, and EmoContext, reaching the SOTA performance on\nthe first three. We also validate our dataset, conducting statistical analysis\nand human evaluation, and confirm the success of our measures in utterance\ndiversification (although less for the neutral class) and context\npersonalization, while pointing out the need for improved handling of\nout-of-taxonomy labels within the pipeline.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T16:23:17Z"}
{"aid":"http://arxiv.org/abs/2504.16873v1","title":"A LOFAR-style reconstruction of cosmic-ray air showers with SKA-Low","summary":"Cosmic-ray air shower detection with the low-frequency part of the Square\nKilometre Array (SKA) radio telescope is envisioned to yield very high\nprecision measurements of the particle composition of cosmic rays between\n$10^{16}$ and $10^{18}$ eV. This is made possible by the extreme antenna\ndensity of the core of SKA-Low, surpassing the current most dense radio air\nshower observatory LOFAR by over an order of magnitude. In order to make these\nmeasurements, the technical implementation of this observation mode and the\ndevelopment of reconstruction methods have to happen hand-in-hand. As a first\nlower limit of what is obtainable, we apply the current most precise\nreconstruction methods as used at LOFAR to a first complete simulation of air\nshower signals for the SKA-Low array. We describe this simulation setup and\ndiscuss the obtainable accuracy and resolution. A special focus is put on\neffects of the dynamic range of the system, beamforming methods to lower the\nenergy threshold, as well as the limits to the mass composition accuracy given\nby statistical and systematic uncertainties.","main_category":"astro-ph.HE","categories":"astro-ph.HE,hep-ex","published":"2025-04-23T16:47:18Z"}
{"aid":"http://arxiv.org/abs/2504.16913v1","title":"Tracing Thought: Using Chain-of-Thought Reasoning to Identify the LLM\n  Behind AI-Generated Text","summary":"In recent years, the detection of AI-generated text has become a critical\narea of research due to concerns about academic integrity, misinformation, and\nethical AI deployment. This paper presents COT Fine-tuned, a novel framework\nfor detecting AI-generated text and identifying the specific language model.\nresponsible for generating the text. We propose a dual-task approach, where\nTask A involves classifying text as AI-generated or human-written, and Task B\nidentifies the specific LLM behind the text. The key innovation of our method\nlies in the use of Chain-of-Thought reasoning, which enables the model to\ngenerate explanations for its predictions, enhancing transparency and\ninterpretability. Our experiments demonstrate that COT Fine-tuned achieves high\naccuracy in both tasks, with strong performance in LLM identification and\nhuman-AI classification. We also show that the CoT reasoning process\ncontributes significantly to the models effectiveness and interpretability.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T17:39:49Z"}
{"aid":"http://arxiv.org/abs/2504.16920v1","title":"Summary statistics of learning link changing neural representations to\n  behavior","summary":"How can we make sense of large-scale recordings of neural activity across\nlearning? Theories of neural network learning with their origins in statistical\nphysics offer a potential answer: for a given task, there are often a small set\nof summary statistics that are sufficient to predict performance as the network\nlearns. Here, we review recent advances in how summary statistics can be used\nto build theoretical understanding of neural network learning. We then argue\nfor how this perspective can inform the analysis of neural data, enabling\nbetter understanding of learning in biological and artificial neural networks.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-23T17:45:42Z"}
{"aid":"http://arxiv.org/abs/2504.16922v1","title":"Generalized Neighborhood Attention: Multi-dimensional Sparse Attention\n  at the Speed of Light","summary":"Many sparse attention mechanisms such as Neighborhood Attention have\ntypically failed to consistently deliver speedup over the self attention\nbaseline. This is largely due to the level of complexity in attention\ninfrastructure, and the rapid evolution of AI hardware architecture. At the\nsame time, many state-of-the-art foundational models, particularly in computer\nvision, are heavily bound by attention, and need reliable sparsity to escape\nthe O(n^2) complexity. In this paper, we study a class of promising sparse\nattention mechanisms that focus on locality, and aim to develop a better\nanalytical model of their performance improvements. We first introduce\nGeneralized Neighborhood Attention (GNA), which can describe sliding window,\nstrided sliding window, and blocked attention. We then consider possible design\nchoices in implementing these approaches, and create a simulator that can\nprovide much more realistic speedup upper bounds for any given setting.\nFinally, we implement GNA on top of a state-of-the-art fused multi-headed\nattention (FMHA) kernel designed for the NVIDIA Blackwell architecture in\nCUTLASS. Our implementation can fully realize the maximum speedup theoretically\npossible in many perfectly block-sparse cases, and achieves an effective\nutilization of 1.3 petaFLOPs/second in FP16. In addition, we plug various GNA\nconfigurations into off-the-shelf generative models, such as Cosmos-7B,\nHunyuanVideo, and FLUX, and show that it can deliver 28% to 46% end-to-end\nspeedup on B200 without any fine-tuning. We will open source our simulator and\nBlackwell kernels directly through the NATTEN project.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-23T17:49:53Z"}
{"aid":"http://arxiv.org/abs/2504.16923v1","title":"Meta-Learning Online Dynamics Model Adaptation in Off-Road Autonomous\n  Driving","summary":"High-speed off-road autonomous driving presents unique challenges due to\ncomplex, evolving terrain characteristics and the difficulty of accurately\nmodeling terrain-vehicle interactions. While dynamics models used in\nmodel-based control can be learned from real-world data, they often struggle to\ngeneralize to unseen terrain, making real-time adaptation essential. We propose\na novel framework that combines a Kalman filter-based online adaptation scheme\nwith meta-learned parameters to address these challenges. Offline meta-learning\noptimizes the basis functions along which adaptation occurs, as well as the\nadaptation parameters, while online adaptation dynamically adjusts the onboard\ndynamics model in real time for model-based control. We validate our approach\nthrough extensive experiments, including real-world testing on a full-scale\nautonomous off-road vehicle, demonstrating that our method outperforms baseline\napproaches in prediction accuracy, performance, and safety metrics,\nparticularly in safety-critical scenarios. Our results underscore the\neffectiveness of meta-learned dynamics model adaptation, advancing the\ndevelopment of reliable autonomous systems capable of navigating diverse and\nunseen environments. Video is available at: https://youtu.be/cCKHHrDRQEA","main_category":"cs.RO","categories":"cs.RO,cs.LG,cs.SY,eess.SY","published":"2025-04-23T17:51:36Z"}
{"aid":"http://arxiv.org/abs/2504.17583v1","title":"Shared Randomness in Locally Checkable Problems: The Role of\n  Computational Assumptions","summary":"Shared randomness is a valuable resource in distributed computing, but what\nhappens when the shared random string can affect the inputs to the system?\n  Consider the class of distributed graph problems where the correctness of\nsolutions can be checked locally, known as Locally Checkable Labelings (LCL).\nLCL problems have been extensively studied in the LOCAL model, where nodes\noperate in synchronous rounds and have access only to local information. This\nhas led to intriguing insights regarding the power of private randomness. E.g.,\nfor certain round complexity classes, derandomization does not incur an\noverhead (asymptotically).\n  This work considers a setting where the randomness is public. Recently, an\nLCL problem for which shared randomness can reduce the round complexity was\ndiscovered by Balliu et al. (2024). This result applies to inputs set\nobliviously of the shared randomness, which may not always be a plausible\nassumption.\n  We define a model where the inputs can be adversarially chosen, even based on\nthe shared randomness, which we now call preset public coins. We study LCL\nproblems in the preset public coins model, under assumptions regarding the\ncomputational power of the adversary that selects the input. We show\nconnections to hardness in the class TFNP. Our results are:\n  1. Assuming the existence of a hard-on-average problem in TFNP (which follows\nfrom fairly benign cryptographic assumptions), we show an LCL problem that, in\nthe preset public coins model, demonstrates a gap in the round complexity\nbetween polynomial-time adversaries and unbounded ones.\n  2. If there exists an LCL problem for which the error probability is\nsignificantly higher when facing unbounded adversaries, then a hard-on-average\nproblem in TFNP/poly must exist.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-24T14:13:09Z"}
{"aid":"http://arxiv.org/abs/2504.17614v1","title":"Bolt: Clothing Virtual Characters at Scale","summary":"Clothing virtual characters is a time-consuming and often manual process.\nOutfits can be composed of multiple garments, and each garment must be fitted\nto the unique shape of a character. Since characters can vary widely in size\nand shape, fitting outfits to many characters is a combinatorially large\nproblem. We present Bolt, a system designed to take outfits originally authored\non a source body and fit them to new body shapes via a three stage transfer,\ndrape, and rig process. First, our new garment transfer method transforms each\ngarment's 3D mesh positions to the new character, then optimizes the garment's\n2D sewing pattern while maintaining key features of the original seams and\nboundaries. Second, our system simulates the transferred garments to\nprogressively drape and untangle each garment in the outfit. Finally, the\ngarments are rigged to the new character. This entire process is automatic,\nmaking it feasible to clothe characters at scale with no human intervention.\nClothed characters are then ready for immediate use in applications such as\ngaming, animation, synthetic generation, and more.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-24T14:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.17622v1","title":"Likelihood-Free Variational Autoencoders","summary":"Variational Autoencoders (VAEs) typically rely on a probabilistic decoder\nwith a predefined likelihood, most commonly an isotropic Gaussian, to model the\ndata conditional on latent variables. While convenient for optimization, this\nchoice often leads to likelihood misspecification, resulting in blurry\nreconstructions and poor data fidelity, especially for high-dimensional data\nsuch as images. In this work, we propose \\textit{EnVAE}, a novel\nlikelihood-free generative framework that has a deterministic decoder and\nemploys the energy score -- a proper scoring rule -- to build the\nreconstruction loss. This enables likelihood-free inference without requiring\nexplicit parametric density functions. To address the computational\ninefficiency of the energy score, we introduce a fast variant, \\textit{FEnVAE},\nbased on the local smoothness of the decoder and the sharpness of the posterior\ndistribution of latent variables. This yields an efficient single-sample\ntraining objective that integrates seamlessly into existing VAE pipelines with\nminimal overhead. Empirical results on standard benchmarks demonstrate that\n\\textit{EnVAE} achieves superior reconstruction and generation quality compared\nto likelihood-based baselines. Our framework offers a general, scalable, and\nstatistically principled alternative for flexible and nonparametric\ndistribution learning in generative modeling.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-24T14:44:46Z"}
{"aid":"http://arxiv.org/abs/2504.17625v1","title":"Non-quadratic solutions to the Monge-Ampère equation","summary":"We construct ample smooth strictly plurisubharmonic non-quadratic solutions\nto the Monge-Amp\\`ere equation on either cylindrical type domains or the whole\ncomplex Euclidean space $\\mathbb C^2$. Among these, the entire solutions\ndefined on $\\mathbb C^2$ induce flat Kahler metrics, as expected by a question\nof Calabi. In contrast, those on cylindrical domains produce a family of\nnowhere flat Kahler metrics. Beyond these smooth solutions, we also classify\nsolutions that are radially symmetric in one variable, which exhibit various\ntypes of singularities. Finally, we explore analogous solutions to Donaldson's\nequation motivated by a result of He.","main_category":"math.CV","categories":"math.CV","published":"2025-04-24T14:48:28Z"}
{"aid":"http://arxiv.org/abs/2504.17626v1","title":"Improving Open-World Object Localization by Discovering Background","summary":"Our work addresses the problem of learning to localize objects in an\nopen-world setting, i.e., given the bounding box information of a limited\nnumber of object classes during training, the goal is to localize all objects,\nbelonging to both the training and unseen classes in an image, during\ninference. Towards this end, recent work in this area has focused on improving\nthe characterization of objects either explicitly by proposing new objective\nfunctions (localization quality) or implicitly using object-centric\nauxiliary-information, such as depth information, pixel/region affinity map\netc. In this work, we address this problem by incorporating background\ninformation to guide the learning of the notion of objectness. Specifically, we\npropose a novel framework to discover background regions in an image and train\nan object proposal network to not detect any objects in these regions. We\nformulate the background discovery task as that of identifying image regions\nthat are not discriminative, i.e., those that are redundant and constitute low\ninformation content. We conduct experiments on standard benchmarks to showcase\nthe effectiveness of our proposed approach and observe significant improvements\nover the previous state-of-the-art approaches for this task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T14:48:46Z"}
{"aid":"http://arxiv.org/abs/2504.17637v1","title":"On the negative band number","summary":"We study the negative band number of braids, knots, and links using Birman,\nKo, and Lee's left-canonical form of a braid. As applications, we characterize\nup to conjugacy strongly quasipositive braids and almost strongly quasipositive\nbraids.","main_category":"math.GT","categories":"math.GT","published":"2025-04-24T15:08:44Z"}
{"aid":"http://arxiv.org/abs/2504.17645v1","title":"A common first integral from three-body secular theory and Kepler\n  billiards","summary":"We observe that a particular first integral of the partially-averaged system\nin the secular theory of the three-body problem appears also as an important\nconserved quantity of integrable Kepler billiards. In this note we illustrate\ntheir common roots with the projective dynamics of the two-center problem. We\nthen combine these two aspects to define a class of integrable billiard systems\non surfaces of constant curvature.","main_category":"math.DS","categories":"math.DS","published":"2025-04-24T15:14:21Z"}
{"aid":"http://arxiv.org/abs/2504.17649v1","title":"On Josephy-Halley method for generalized equations","summary":"We extend the classical third-order Halley iteration to the setting of\ngeneralized equations of the form \\[ 0 \\in f(x) + F(x), \\] where \\(f\\colon\nX\\longrightarrow Y\\) is twice continuously Fr\\'echet-differentiable on Banach\nspaces and \\(F\\colon X\\tto Y\\) is a set-valued mapping with closed graph.\nBuilding on predictor-corrector framework, our scheme first solves a partially\nlinearized inclusion to produce a predictor \\(u_{k+1}\\), then incorporates\nsecond-order information in a Halley-type corrector step to obtain \\(x_{k+1}\\).\nUnder metric regularity of the linearization at a reference solution and\nH\\\"older continuity of \\(f''\\), we prove that the iterates converge locally\nwith order \\(2+p\\) (cubically when \\(p=1\\)). Moreover, by constructing a\nsuitable scalar majorant function we derive semilocal Kantorovich-type\nconditions guaranteeing well-definedness and R-cubic convergence from an\nexplicit neighbourhood of the initial guess. Numerical experiments-including\none- and two-dimensional test problems confirm the theoretical convergence\nrates and illustrate the efficiency of the Josephy-Halley method compared to\nits Josephy-Newton counterpart.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-24T15:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.17653v1","title":"Towards a comprehensive taxonomy of online abusive language informed by\n  machine leaning","summary":"The proliferation of abusive language in online communications has posed\nsignificant risks to the health and wellbeing of individuals and communities.\nThe growing concern regarding online abuse and its consequences necessitates\nmethods for identifying and mitigating harmful content and facilitating\ncontinuous monitoring, moderation, and early intervention. This paper presents\na taxonomy for distinguishing key characteristics of abusive language within\nonline text. Our approach uses a systematic method for taxonomy development,\nintegrating classification systems of 18 existing multi-label datasets to\ncapture key characteristics relevant to online abusive language classification.\nThe resulting taxonomy is hierarchical and faceted, comprising 5 categories and\n17 dimensions. It classifies various facets of online abuse, including context,\ntarget, intensity, directness, and theme of abuse. This shared understanding\ncan lead to more cohesive efforts, facilitate knowledge exchange, and\naccelerate progress in the field of online abuse detection and mitigation among\nresearchers, policy makers, online platform owners, and other stakeholders.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T15:23:47Z"}
{"aid":"http://arxiv.org/abs/2504.17656v1","title":"polyGen: A Learning Framework for Atomic-level Polymer Structure\n  Generation","summary":"Synthetic polymeric materials underpin fundamental technologies in the\nenergy, electronics, consumer goods, and medical sectors, yet their development\nstill suffers from prolonged design timelines. Although polymer informatics\ntools have supported speedup, polymer simulation protocols continue to face\nsignificant challenges: on-demand generation of realistic 3D atomic structures\nthat respect the conformational diversity of polymer structures. Generative\nalgorithms for 3D structures of inorganic crystals, bio-polymers, and small\nmolecules exist, but have not addressed synthetic polymers. In this work, we\nintroduce polyGen, the first latent diffusion model designed specifically to\ngenerate realistic polymer structures from minimal inputs such as the repeat\nunit chemistry alone, leveraging a molecular encoding that captures polymer\nconnectivity throughout the architecture. Due to a scarce dataset of only 3855\nDFT-optimized polymer structures, we augment our training with DFT-optimized\nmolecular structures, showing improvement in joint learning between similar\nchemical structures. We also establish structure matching criteria to benchmark\nour approach on this novel problem. polyGen effectively generates diverse\nconformations of both linear chains and complex branched structures, though its\nperformance decreases when handling repeat units with a high atom count. Given\nthese initial results, polyGen represents a paradigm shift in atomic-level\nstructure generation for polymer science-the first proof-of-concept for\npredicting realistic atomic-level polymer conformations while accounting for\ntheir intrinsic structural flexibility.","main_category":"cs.CE","categories":"cs.CE,cond-mat.mtrl-sci,cs.LG","published":"2025-04-24T15:26:00Z"}
{"aid":"http://arxiv.org/abs/2504.17662v1","title":"Seamless Data Migration between Database Schemas with DAMI-Framework: An\n  Empirical Study on Developer Experience","summary":"Many businesses depend on legacy systems, which often use outdated technology\nthat complicates maintenance and updates. Therefore, software modernization is\nessential, particularly data migration between different database schemas.\nEstablished methodologies, like model transformation and ETL tools, facilitate\nthis migration; they require deep knowledge of database languages and both the\nsource and target schemas. This necessity renders data migration an error-prone\nand cognitively demanding task. Our objective is to alleviate developers'\nworkloads during schema evolution through our DAMI-Framework. This framework\nincorporates a domain-specific language (DSL) and a parser to facilitate data\nmigration between database schemas. DAMI-DSL simplifies schema mapping while\nthe parser automates SQL script generation. We assess developer experience in\ndata migration by conducting an empirical evaluation with 21 developers to\nassess their experiences using our DSL versus traditional SQL. The study allows\nus to measure their perceptions of the DSL properties and user experience. The\nparticipants praised DAMI-DSL for its readability and ease of use. The findings\nindicate that our DSL reduces data migration efforts compared to SQL scripts.","main_category":"cs.SE","categories":"cs.SE,cs.DB","published":"2025-04-24T15:30:28Z"}
{"aid":"http://arxiv.org/abs/2504.17663v1","title":"The Malicious Technical Ecosystem: Exposing Limitations in Technical\n  Governance of AI-Generated Non-Consensual Intimate Images of Adults","summary":"In this paper, we adopt a survivor-centered approach to locate and dissect\nthe role of sociotechnical AI governance in preventing AI-Generated\nNon-Consensual Intimate Images (AIG-NCII) of adults, colloquially known as\n\"deep fake pornography.\" We identify a \"malicious technical ecosystem\" or\n\"MTE,\" comprising of open-source face-swapping models and nearly 200\n\"nudifying\" software programs that allow non-technical users to create AIG-NCII\nwithin minutes. Then, using the National Institute of Standards and Technology\n(NIST) AI 100-4 report as a reflection of current synthetic content governance\nmethods, we show how the current landscape of practices fails to effectively\nregulate the MTE for adult AIG-NCII, as well as flawed assumptions explaining\nthese gaps.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CY,cs.LG","published":"2025-04-24T15:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.17688v1","title":"The Hubble Image Similarity Project","summary":"We have created a large database of similarity information between\nsub-regions of Hubble Space Telescope images. These data can be used to assess\nthe accuracy of image search algorithms based on computer vision methods. The\nimages were compared by humans in a citizen science project, where they were\nasked to select similar images from a comparison sample. We utilized the Amazon\nMechanical Turk system to pay our reviewers a fair wage for their work. Nearly\n850,000 comparison measurements have been analyzed to construct a similarity\ndistance matrix between all the pairs of images. We describe the algorithm used\nto extract a robust distance matrix from the (sometimes noisy) user reviews.\nThe results are very impressive: the data capture similarity between images\nbased on morphology, texture, and other details that are sometimes difficult\neven to describe in words (e.g., dusty absorption bands with sharp edges). The\ncollective visual wisdom of our citizen scientists matches the accuracy of the\ntrained eye, with even subtle differences among images faithfully reflected in\nthe distances.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-24T15:58:00Z"}
{"aid":"http://arxiv.org/abs/2504.17704v1","title":"Safety in Large Reasoning Models: A Survey","summary":"Large Reasoning Models (LRMs) have exhibited extraordinary prowess in tasks\nlike mathematics and coding, leveraging their advanced reasoning capabilities.\nNevertheless, as these capabilities progress, significant concerns regarding\ntheir vulnerabilities and safety have arisen, which can pose challenges to\ntheir deployment and application in real-world settings. This paper presents a\ncomprehensive survey of LRMs, meticulously exploring and summarizing the newly\nemerged safety risks, attacks, and defense strategies. By organizing these\nelements into a detailed taxonomy, this work aims to offer a clear and\nstructured understanding of the current safety landscape of LRMs, facilitating\nfuture research and development to enhance the security and reliability of\nthese powerful models.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T16:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.17705v1","title":"LUIDA: Large-scale Unified Infrastructure for Digital Assessments based\n  on Commercial Metaverse Platform","summary":"Online experiments using metaverse platforms have gained significant traction\nin Human-Computer Interaction and Virtual Reality (VR) research. However,\ncurrent research workflows are highly fragmented, as researchers must use\nseparate tools for system implementation, participant recruitment, experiment\nexecution, and data collection, reducing consistency and increasing workload.\nWe present LUIDA (Large-scale Unified Infrastructure for Digital Assessments),\na metaverse-based framework that integrates these fragmented processes. LUIDA\nautomatically allocates interconnected virtual environments for parallel\nexperiment execution and provides implementation templates adaptable to various\nVR research domains, requiring minimal metaverse development expertise. Our\nevaluation included two studies using a prototype built on Cluster, the\ncommercial metaverse platform. First, VR researchers using LUIDA to develop and\nrun experiments reported high usability scores (SUS: 73.75) and moderate\nworkload (NASA-TLX: 24.11) for overall usage, with interviews confirming\nstreamlined workflows compared to traditional laboratory experiments. Second,\nwe conducted three replicated experiments with public Cluster users, each\nrecruiting approximately 200 participants within one week. These experiments\nproduced results that closely matched the original studies, validating the\nexperimental integrity of LUIDA across research domains. After technical\nrefinements, we plan to release LUIDA as an open platform, providing a\nstandardized protocol to improve research efficiency and experimental\nreproducibility in VR studies.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-24T16:11:12Z"}
{"aid":"http://arxiv.org/abs/2504.17708v1","title":"Pushing the frontiers of subexponential FPT time for Feedback Vertex Set","summary":"The paper deals with the Feedback Vertex Set problem parameterized by the\nsolution size. Given a graph $G$ and a parameter $k$, one has to decide if\nthere is a set $S$ of at most $k$ vertices such that $G-S$ is acyclic. Assuming\nthe Exponential Time Hypothesis, it is known that FVS cannot be solved in time\n$2^{o(k)}n^{\\mathcal{O}(1)}$ in general graphs. To overcome this, many recent\nresults considered FVS restricted to particular intersection graph classes and\nprovided such $2^{o(k)}n^{\\mathcal{O}(1)}$ algorithms.\n  In this paper we provide generic conditions on a graph class for the\nexistence of an algorithm solving FVS in subexponential FPT time, i.e. time\n$2^{k^\\varepsilon} \\mathop{\\rm poly}(n)$, for some $\\varepsilon<1$, where $n$\ndenotes the number of vertices of the instance and $k$ the parameter. On the\none hand this result unifies algorithms that have been proposed over the years\nfor several graph classes such as planar graphs, map graphs, unit-disk graphs,\npseudo-disk graphs, and string graphs of bounded edge-degree. On the other hand\nit extends the tractability horizon of FVS to new classes that are not amenable\nto previously used techniques, in particular intersection graphs of ``thin''\nobjects like segment graphs or more generally $s$-string graphs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T16:12:52Z"}
{"aid":"http://arxiv.org/abs/2504.17719v1","title":"Evaluating Uncertainty in Deep Gaussian Processes","summary":"Reliable uncertainty estimates are crucial in modern machine learning. Deep\nGaussian Processes (DGPs) and Deep Sigma Point Processes (DSPPs) extend GPs\nhierarchically, offering promising methods for uncertainty quantification\ngrounded in Bayesian principles. However, their empirical calibration and\nrobustness under distribution shift relative to baselines like Deep Ensembles\nremain understudied. This work evaluates these models on regression (CASP\ndataset) and classification (ESR dataset) tasks, assessing predictive\nperformance (MAE, Accu- racy), calibration using Negative Log-Likelihood (NLL)\nand Expected Calibration Error (ECE), alongside robustness under various\nsynthetic feature-level distribution shifts. Results indicate DSPPs provide\nstrong in-distribution calibration leveraging their sigma point approximations.\nHowever, compared to Deep Ensembles, which demonstrated superior robustness in\nboth per- formance and calibration under the tested shifts, the GP-based\nmethods showed vulnerabilities, exhibiting particular sensitivity in the\nobserved metrics. Our findings underscore ensembles as a robust baseline,\nsuggesting that while deep GP methods offer good in-distribution calibration,\ntheir practical robustness under distribution shift requires careful\nevaluation. To facilitate reproducibility, we make our code available at\nhttps://github.com/matthjs/xai-gp.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-24T16:31:55Z"}
{"aid":"http://arxiv.org/abs/2504.17725v1","title":"STGen: A Novel Lightweight IoT Testbed for Generating Sensor Traffic for\n  the Experimentation of IoT Protocol and its Application in Hybrid Network","summary":"A Wireless Sensor Network (WSN) is a network that does not rely on a fixed\ninfrastructure and consists of numerous sensors, such as temperature, humidity,\nGPS, and cameras, equipped with onboard processors that manage and monitor the\nenvironment in a specific area. As a result, building a real sensor network\ntestbed for verifying, validating, or experimenting with a newly designed\nprotocol presents considerable challenges in adapting a laboratory scenario due\nto the significant financial and logistical barriers, such as the need for\nspecialized hardware and large-scale deployments. Additionally, WSN suffers\nfrom severe constraints such as restricted power supply, short communication\nrange, limited bandwidth availability, and restricted memory storage.\nAddressing these challenges, this work presents a flexible testbed solution\nnamed STGen that enables researchers to experiment with IoT protocols in a\nhybrid environment that emulates WSN implementations with the physical Internet\nthrough a dedicated physical server named STGen core, which receives sensor\ntraffic and processes it for further actions. The STGen testbed is lightweight\nin memory usage and easy to deploy. Most importantly, STGen supports\nlarge-scale distributed systems, facilitates experimentation with IoT\nprotocols, and enables integration with back-end services for big data\nanalytics and statistical insights. The key feature of STGen is the integration\nof real-world IoT protocols and their applications with WSN. Its modular and\nlightweight design makes STGen efficient and enables it to outperform other\npopular testbeds, such as Gotham and GothX, reducing memory usage by 89\\%.\nWhile GothX takes approximately 26 minutes to establish a large topology with\nfour VM nodes and 498 Docker nodes, STGen requires only 1.645 seconds to\ninitialize the platform with 500 sensor nodes.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-24T16:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.17739v1","title":"Interpretable Early Detection of Parkinson's Disease through Speech\n  Analysis","summary":"Parkinson's disease is a progressive neurodegenerative disorder affecting\nmotor and non-motor functions, with speech impairments among its earliest\nsymptoms. Speech impairments offer a valuable diagnostic opportunity, with\nmachine learning advances providing promising tools for timely detection. In\nthis research, we propose a deep learning approach for early Parkinson's\ndisease detection from speech recordings, which also highlights the vocal\nsegments driving predictions to enhance interpretability. This approach seeks\nto associate predictive speech patterns with articulatory features, providing a\nbasis for interpreting underlying neuromuscular impairments. We evaluated our\napproach using the Italian Parkinson's Voice and Speech Database, containing\n831 audio recordings from 65 participants, including both healthy individuals\nand patients. Our approach showed competitive classification performance\ncompared to state-of-the-art methods, while providing enhanced interpretability\nby identifying key speech features influencing predictions.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T16:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.17746v1","title":"Flux tube clustering from magnetic coupling of adjacent type-I and -II\n  superconductors in a neutron star: persistent gravitational radiation","summary":"Adjacent type-I and -II proton superconductors in a rotation-powered pulsar\nare predicted to exist in a metastable state containing macroscopic and\nquantized flux tubes, respectively. Previous studies show that the type-I and\n-II regions are coupled magnetically, when macroscopic flux tubes divide\ndendritically into quantized flux tubes near the type-I-II interface, through a\nprocess known as flux branching. The studies assume that the\nnormal-superconducting boundary is sharp, and the quantized flux tubes do not\nrepel mutually. Here the sharp-interface approximation is refined by accounting\nfor magnetic repulsion. It is found that flux tubes in the same flux tree\ncluster with a minimum-energy separation two to seven times less than that of\nisolated flux tubes. Neutron vortices pin and cluster about flux trees. We find\nthat the maximum characteristic wave strain $h_0$ of the current quadrupole\ngravitational radiation emitted by a rectilinear array of clustered vortices\nexceeds by $(1+N_{\\rm v,t})^{1/2}$ the strain $h_0 \\sim 10^{-32}(f/30 {\\rm\nHz})^{5/2} (D/1 {\\rm kpc})^{-1}$ emitted by uniformly distributed vortices,\nwhere $N_{\\rm v,t}$ is the mean number of pinned vortices per flux tree, $f$ is\nthe star's spin frequency, and $D$ is the star's distance from Earth. The\nfactor $(1 + N_{\\rm v,t})^{1/2}$ brings $h_0$ close to the sensitivity limit of\nthe current generation of interferometric gravitational wave detectors under\ncertain circumstances, specifically when flux branching forms relatively few\n(and hence relatively large) flux trees.","main_category":"astro-ph.HE","categories":"astro-ph.HE,cond-mat.quant-gas,cond-mat.supr-con,gr-qc,nucl-th","published":"2025-04-24T17:06:50Z"}
{"aid":"http://arxiv.org/abs/2504.17755v1","title":"Measurements of inclusive and differential Higgs boson production cross\n  sections at $\\sqrt{s}$ = 13.6 TeV in the H $\\to$ $γγ$ decay\n  channel","summary":"Inclusive and differential cross sections for Higgs boson production in\nproton-proton collisions at a centre-of-mass energy of 13.6 TeV are measured\nusing data collected with the CMS detector at the LHC in 2022, corresponding to\nan integrated luminosity of 34.7 fb$^{-1}$. Events with the diphoton final\nstate are selected, and the measured inclusive fiducial cross section is\n$\\sigma_\\text{fid}$ = 74 $\\pm$ 11 (stat) $^{+5}_{-4}$ (syst) fb, in agreement\nwith the standard model prediction of 67.8 $\\pm$ 3.8 fb. Differential cross\nsections are measured as functions of several observables: the Higgs boson\ntransverse momentum and rapidity, the number of associated jets, and the\ntransverse momentum of the leading jet in the event. Within the uncertainties,\nthe differential cross sections agree with the standard model predictions.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-24T17:19:13Z"}
{"aid":"http://arxiv.org/abs/2504.17780v1","title":"Replay to Remember: Retaining Domain Knowledge in Streaming Language\n  Models","summary":"Continual learning in large language models (LLMs) typically encounters the\ncritical challenge of catastrophic forgetting, where previously acquired\nknowledge deteriorates upon exposure to new data. While techniques like replay\nbuffers and parameter-efficient tuning (e.g., Low-Rank Adaptation or LoRA) have\nbeen proposed, few studies investigate real-time domain adaptation under strict\ncomputational and data-stream constraints. In this paper, we demonstrate a\nlightweight method combining LoRA and a minimal replay mechanism in a realistic\nstreaming setting across three diverse knowledge domains: medical question\nanswering, genetics, and law. Using perplexity, semantic similarity, and\nGPT-based human-like evaluation metrics, we quantify the model's adaptation,\nforgetting, and recovery over time. Our experiments reveal that while\ncatastrophic forgetting naturally occurs, even minimal replay significantly\nstabilizes and partially restores domain-specific knowledge. This study\ncontributes practical insights for deploying adaptable LLMs in\nresource-constrained, real-world scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T17:56:22Z"}
{"aid":"http://arxiv.org/abs/2504.17785v1","title":"Silenzio: Secure Non-Interactive Outsourced MLP Training","summary":"Outsourcing the ML training to cloud providers presents a compelling\nopportunity for resource constrained clients, while it simultaneously bears\ninherent privacy risks, especially for highly sensitive training data. We\nintroduce Silenzio, the first fully non-interactive outsourcing scheme for the\ntraining of multi-layer perceptrons that achieves 128 bit security using FHE.\nUnlike traditional MPC based protocols that necessitate interactive\ncommunication between the client and server(s) or non-collusion assumptions\namong multiple servers, Silenzio enables the fire-and-forget paradigm without\nsuch assumptions. In this approach, the client encrypts the training data once,\nand the cloud server performs the training without any further interaction.\n  Silenzio operates over low bitwidth integers - never exceeding 8 bit - to\nmitigate the computational overhead of FHE. Our approach features a novel\nlow-bitwidth matrix multiplication that leverages input-dependent residue\nnumber systems and a Karatsuba-inspired multiplication routine, ensuring that\nno intermediate FHE-processed value overflows 8 bit. Starting from an\nRNS-to-MRNS conversion process, we propose an efficient block-scaling\nmechanism, which approximately shifts encrypted tensor values to the\nuser-specified most significant bits. To instantiate the backpropagation of the\nerror, Silenzio introduces a low-bitwidth and TFHE friendly gradient\ncomputation for the cross entropy loss.\n  Implemented using the state-of-the-art Concrete library, we evaluate Silenzio\non standard MLP training tasks regarding runtime as well as model performance\nand achieve similar classification accuracy as MLPs trained using standard\nPyTorch with 32 bit floating-point computations. Our open-source implementation\nrepresents a significant advancement in privacy-preserving ML, providing a new\nbaseline for secure and non-interactive outsourced MLP training.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T17:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.19949v1","title":"Capturing Aerodynamic Characteristics of ATTAS Aircraft with Evolving\n  Intelligent System","summary":"Accurate modeling of aerodynamic coefficients is crucial for understanding\nand optimizing the performance of modern aircraft systems. This paper presents\nthe novel deployment of an Evolving Type-2 Quantum Fuzzy Neural Network\n(eT2QFNN) for modeling the aerodynamic coefficients of the ATTAS aircraft to\nexpress the aerodynamic characteristics. eT2QFNN can represent the nonlinear\naircraft model by creating multiple linear submodels with its rule-based\nstructure through an incremental learning strategy rather than a traditional\nbatch learning approach. Moreover, it enhances robustness to uncertainties and\ndata noise through its quantum membership functions, as well as its automatic\nrule-learning and parameter-tuning capabilities. During the estimation of the\naerodynamic coefficients via the flight data of the ATTAS, two different\nstudies are conducted in the training phase: one with a large amount of data\nand the other with a limited amount of data. The results show that the modeling\nperformance of the eT2QFNN is superior in comparison to baseline counterparts.\nFurthermore, eT2QFNN estimated the aerodynamic model with fewer rules compared\nto Type-1 fuzzy counterparts. In addition, by applying the Delta method to the\nproposed approach, the stability and control derivatives of the aircraft are\nanalyzed. The results prove the superiority of the proposed eT2QFNN in\nrepresenting aerodynamic coefficients.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-28T16:21:20Z"}
{"aid":"http://arxiv.org/abs/2504.19951v1","title":"Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust\n  Registry-Based Approach","summary":"The rise of generative AI (GenAI) multi-agent systems (MAS) necessitates\nstandardized protocols enabling agents to discover and interact with external\ntools. However, these protocols introduce new security challenges,\nparticularly; tool squatting; the deceptive registration or representation of\ntools. This paper analyzes tool squatting threats within the context of\nemerging interoperability standards, such as Model Context Protocol (MCP) or\nseamless communication between agents protocols. It introduces a comprehensive\nTool Registry system designed to mitigate these risks. We propose a\nsecurity-focused architecture featuring admin-controlled registration,\ncentralized tool discovery, fine grained access policies enforced via dedicated\nAgent and Tool Registry services, a dynamic trust scoring mechanism based on\ntool versioning and known vulnerabilities, and just in time credential\nprovisioning. Based on its design principles, the proposed registry framework\naims to effectively prevent common tool squatting vectors while preserving the\nflexibility and power of multi-agent systems. This work addresses a critical\nsecurity gap in the rapidly evolving GenAI ecosystem and provides a foundation\nfor secure tool integration in production environments.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-28T16:22:21Z"}
{"aid":"http://arxiv.org/abs/2504.19976v1","title":"Formation of trapped surfaces for the Einstein--Maxwell--charged scalar\n  field system","summary":"In this paper, we prove a scale-critical trapped surface formation result for\nthe Einstein--Maxwell--charged scalar field (EMCSF) system, without any\nsymmetry assumptions. Specifically, we establish a scale-critical semi-global\nexistence theorem from past null infinity and show that the focusing of\ngravitational waves, the concentration of electromagnetic fields, or the\ncondensation of complex scalar fields, each individually, can lead to the\nformation of a trapped surface. In addition, we capture a nontrivial charging\nprocess along past null infinity, which introduces new difficulties due to the\nabnormal behavior of the matter fields. Nevertheless, the semi-global existence\nresult and the formation of a trapped surface remain valid.","main_category":"math.AP","categories":"math.AP,gr-qc,math.DG","published":"2025-04-28T16:49:11Z"}
{"aid":"http://arxiv.org/abs/2504.19977v1","title":"$^{208}$Pb nuclear charge radius revisited: closing the\n  fine-structure-anomaly gap","summary":"A comprehensive reevaluation of the root-mean-square nuclear charge radius is\npresented for the doubly magic $^{208}$Pb extracted from muonic spectroscopy\nmeasurements. By integrating rigorous theoretical quantum electrodynamics\ncalculations, state-of-the-art numerical methods, and a systematic reanalysis\nof the uncertainties, we reduced the long-standing muonic fine-structure\nanomaly and improved the goodness of fit by a factor of twenty. The resulting\nvalue of 5.5062(5) fm is fairly consistent with the previously reported muonic\nspectroscopy value, and three standard deviations larger than the commonly used\ncompilation data, which indicates that the current value and its uncertainty\ncould be significantly underestimated. Our study paves a new path for\nsystematic reevaluation of all rms radii based on muonic spectroscopy.","main_category":"physics.atom-ph","categories":"physics.atom-ph,nucl-th","published":"2025-04-28T16:49:59Z"}
{"aid":"http://arxiv.org/abs/2504.19982v1","title":"TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining\n  Turn-Level Precision with Dialogue-Level Comparisons","summary":"Task-oriented dialogue (TOD) systems are experiencing a revolution driven by\nLarge Language Models (LLMs), yet the evaluation methodologies for these\nsystems remain insufficient for their growing sophistication. While traditional\nautomatic metrics effectively assessed earlier modular systems, they focus\nsolely on the dialogue level and cannot detect critical intermediate errors\nthat can arise during user-agent interactions. In this paper, we introduce\nTD-EVAL (Turn and Dialogue-level Evaluation), a two-step evaluation framework\nthat unifies fine-grained turn-level analysis with holistic dialogue-level\ncomparisons. At turn level, we evaluate each response along three TOD-specific\ndimensions: conversation cohesion, backend knowledge consistency, and policy\ncompliance. Meanwhile, we design TOD Agent Arena that uses pairwise comparisons\nto provide a measure of dialogue-level quality. Through experiments on MultiWOZ\n2.4 and {\\tau}-Bench, we demonstrate that TD-EVAL effectively identifies the\nconversational errors that conventional metrics miss. Furthermore, TD-EVAL\nexhibits better alignment with human judgments than traditional and LLM-based\nmetrics. These findings demonstrate that TD-EVAL introduces a new paradigm for\nTOD system evaluation, efficiently assessing both turn and system levels with a\nplug-and-play framework for future research.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-28T16:57:17Z"}
{"aid":"http://arxiv.org/abs/2504.19992v1","title":"Towards Non-Abelian Quantum Signal Processing: Efficient Control of\n  Hybrid Continuous- and Discrete-Variable Architectures","summary":"Robust quantum control is crucial for achieving operations below the quantum\nerror correction threshold. Quantum Signal Processing (QSP) transforms a\nunitary parameterized by $\\theta$ into one governed by a polynomial function\n$f(\\theta)$, a feature that underpins key quantum algorithms. Originating from\ncomposite pulse techniques in NMR, QSP enhances robustness against systematic\ncontrol errors. We extend QSP to a new class, non-abelian QSP, which utilizes\nnon-commuting control parameters, $\\hat\\theta_1, \\hat\\theta_2, \\dots$,\nrepresenting quantum harmonic oscillator positions and momenta. We introduce a\nfundamental non-abelian composite pulse sequence, the\nGaussian-Controlled-Rotation (GCR), for entangling and disentangling a qubit\nfrom an oscillator. This sequence achieves at least a $4.5\\times$ speedup\ncompared to the state-of-the-art abelian QSP pulse BB1, while maintaining\nperformance. Though quantum fluctuations in the control parameters are\nunavoidable, the richer commutator algebra of non-abelian QSP enhances its\npower and efficiency. Non-abelian QSP represents the highest tier of QSP\nvariants tailored for hybrid oscillator-qubit architectures, unlocking new\npossibilities for such systems. We demonstrate the utility of GCR in\nhigh-fidelity preparation of continuous-variable oscillator states, including\nsqueezed, Fock, cat, and GKP states, using fully analytical schemes that match\nnumerically optimized methods in fidelity and depth while enabling mid-circuit\nerror detection. Furthermore, we propose a high-fidelity QSP-based\nend-of-the-line GKP readout and a measurement-free, error-corrected gate\nteleportation protocol for logical operations on GKP bosonic qudits, bridging\nthe gap between idealized theoretical and experimentally realistic versions of\nthe GKP code. Finally, we showcase a GCR-based phase estimation algorithm for\noscillator-based quantum computing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T17:10:27Z"}
{"aid":"http://arxiv.org/abs/2504.19998v1","title":"Homotopy theory of post-Lie algebras","summary":"In this paper, we study the homotopy theory of post-Lie algebras. Guided by\nKoszul duality theory, we consider the graded Lie algebra of coderivations of\nthe cofree conilpotent graded cocommutative cotrialgebra generated by $V$. We\nshow that in the case of $V$ being a shift of an ungraded vector space $W$,\nMaurer-Cartan elements of this graded Lie algebra are exactly post-Lie algebra\nstructures on $W$. The cohomology of a post-Lie algebra is then defined using\nMaurer-Cartan twisting. The second cohomology group of a post-Lie algebra has a\nfamiliar interpretation as equivalence classes of infinitesimal deformations.\nNext we define a post-Lie$_\\infty$ algebra structure on a graded vector space\nto be a Maurer-Cartan element of the aforementioned graded Lie algebra.\nPost-Lie$_\\infty$ algebras admit a useful characterization in terms of\n$L_\\infty$-actions (or open-closed homotopy Lie algebras). Finally, we\nintroduce the notion of homotopy Rota-Baxter operators on open-closed homotopy\nLie algebras and show that certain homotopy Rota-Baxter operators induce\npost-Lie$_\\infty$ algebras.","main_category":"math.RA","categories":"math.RA","published":"2025-04-28T17:18:50Z"}
{"aid":"http://arxiv.org/abs/2504.20001v1","title":"Engineering Minimal k-Perfect Hash Functions","summary":"Given a set S of n keys, a k-perfect hash function (kPHF) is a data structure\nthat maps the keys to the first m integers, where each output integer can be\nhit by at most k input keys. When m=n/k, the resulting function is called a\nminimal k-perfect hash function (MkPHF). Applications of kPHFs can be found in\nexternal memory data structures or to create efficient 1-perfect hash\nfunctions, which in turn have a wide range of applications from databases to\nbioinformatics. Several papers from the 1980s look at external memory data\nstructures with small internal memory indexes. However, actual k-perfect hash\nfunctions are surprisingly rare, and the area has not seen a lot of research\nrecently. At the same time, recent research in 1-perfect hashing shows that\nthere is a lack of efficient kPHFs. In this paper, we revive the area of\nk-perfect hashing, presenting four new constructions. Our implementations\nsimultaneously dominate older approaches in space consumption, construction\ntime, and query time. We see this paper as a possible starting point of an\nactive line of research, similar to the area of 1-perfect hashing.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-28T17:22:40Z"}
{"aid":"http://arxiv.org/abs/2504.20013v1","title":"LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case\n  Study on Neural News Recommendation","summary":"Online fake news moderation now faces a new challenge brought by the\nmalicious use of large language models (LLMs) in fake news production. Though\nexisting works have shown LLM-generated fake news is hard to detect from an\nindividual aspect, it remains underexplored how its large-scale release will\nimpact the news ecosystem. In this study, we develop a simulation pipeline and\na dataset with ~56k generated news of diverse types to investigate the effects\nof LLM-generated fake news within neural news recommendation systems. Our\nfindings expose a truth decay phenomenon, where real news is gradually losing\nits advantageous position in news ranking against fake news as LLM-generated\nnews is involved in news recommendation. We further provide an explanation\nabout why truth decay occurs from a familiarity perspective and show the\npositive correlation between perplexity and news ranking. Finally, we discuss\nthe threats of LLM-generated fake news and provide possible countermeasures. We\nurge stakeholders to address this emerging challenge to preserve the integrity\nof news ecosystems.","main_category":"cs.CL","categories":"cs.CL,cs.CY,cs.IR","published":"2025-04-28T17:32:38Z"}
{"aid":"http://arxiv.org/abs/2504.20030v1","title":"Allele trees for the mother-dependent neutral mutations model and their\n  scaling limits in the rare mutations regime","summary":"The mother-dependent neutral mutations model describes the evolution of a\npopulation across discrete generations, where neutral mutations occur among a\nfinite set of possible alleles. In this model, each mutant child acquires a\ntype different from that of its mother, chosen uniformly at random. In this\nwork, we define a multitype allele tree associated with this model and analyze\nits scaling limit through a Markov chain that tracks the sizes of allelic\nsubfamilies and their mutant descendants. We show that this Markov chain\nconverges to a continuous-state Markov process, whose transition probabilities\ndepend on the sizes of the initial allelic populations and those of their\nmutant offspring in the first allelic generation. As a result, the allele tree\nconverges to a multidimensional limiting object, which can be described in\nterms of the universal allele tree introduced by Bertoin (2010).","main_category":"math.PR","categories":"math.PR","published":"2025-04-28T17:54:02Z"}
{"aid":"http://arxiv.org/abs/2504.20044v1","title":"How Charged Can Neutrinos Be?","summary":"We investigate how neutrinos may acquire small electric charges within the\nStandard Model framework while preserving electromagnetic gauge invariance.\nInstead of gauging the standard hypercharge generator $Y$, a linear combination\nof $Y$ and a new generator $X$ from a gaugable global $U(1)_X$ symmetry is\nembedded, under which neutrinos transform non-trivially. We demonstrate that\nminimal scenarios based on flavor-dependent $U(1)_X$ symmetries, such as $X =\nL_\\alpha - L_\\beta$, are incompatible with current neutrino oscillation data.\nIn contrast, we have shown that only flavor-universal $U(1)_X$ symmetries-such\nas $U(1)_{B-L}$, which shifts both quark and lepton charges, and $U(1)_L$,\nwhich modifies only the lepton sector-can generate tiny neutrino charges\nconsistent with observed masses and mixing. We also discuss the necessary\nconnection between such charges and the Dirac nature of neutrinos. By analyzing\nthe phenomenological implications in detail, our findings emphasize that\nconstraints on neutrino charges should be evaluated within the specific\nframework of the $U(1)_X$ symmetry under consideration, rather than assuming a\ngeneric approach, as is often the case.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE,hep-ex,hep-th","published":"2025-04-28T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.20391v1","title":"The Mean of Multi-Object Trajectories","summary":"This paper introduces the concept of a mean for trajectories and multi-object\ntrajectories--sets or multi-sets of trajectories--along with algorithms for\ncomputing them. Specifically, we use the Fr\\'{e}chet mean, and metrics based on\nthe optimal sub-pattern assignment (OSPA) construct, to extend the notion of\naverage from vectors to trajectories and multi-object trajectories. Further, we\ndevelop efficient algorithms to compute these means using greedy search and\nGibbs sampling. Using distributed multi-object tracking as an application, we\ndemonstrate that the Fr\\'{e}chet mean approach to multi-object trajectory\nconsensus significantly outperforms state-of-the-art distributed multi-object\ntracking methods.","main_category":"eess.SP","categories":"eess.SP,cs.RO","published":"2025-04-29T03:25:39Z"}
{"aid":"http://arxiv.org/abs/2504.20396v1","title":"Generalizing the Levins metapopulation model to time varying\n  colonization and extinction rates","summary":"The metapopulation theory explores the population persistence in fragmented\nhabitats by considering a balance between the extinction of local populations\nand recolonization of empty sites. In general, the extinction and colonization\nrates have been considered as constant parameters and the novelty of this paper\nis to assume that they are subject to deterministic variations. We noticed that\nan averaging approach proposed by C. Puccia and R. Levins can be adapted to\nconstruct the upper and lower averages of the difference between the extinction\nand colonization rates, whose sign is useful to determine either the permanence\nor the extinction of the metapopulation. In fact, we use these averages to\nrevisit the classical model introduced by R. Levins. From a mathematical\nperspective, these averages can be seen as Bohl exponents whereas the\ncorresponding analysis is carried out by using tools of non autonomous\ndynamics. Last but not least, compared with the Levins model, the resulting\ndynamics of the time varying model shares the persistence/extinction scenario\nwhen the above stated upper and lower averages have the same sign but also\nraises open questions about metapopulation persistence in the case of the\naverages have different sign.","main_category":"q-bio.PE","categories":"q-bio.PE,math.DS","published":"2025-04-29T03:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.20401v1","title":"Nonlinear Computation with Linear Optics via Source-Position Encoding","summary":"Optical computing systems provide an alternate hardware model which appears\nto be aligned with the demands of neural network workloads. However, the\nchallenge of implementing energy efficient nonlinearities in optics -- a key\nrequirement for realizing neural networks -- is a conspicuous missing link. In\nthis work we introduce a novel method to achieve nonlinear computation in fully\nlinear media. Our method can operate at low power and requires only the ability\nto drive the optical system at a data-dependent spatial position. Leveraging\nthis positional encoding, we formulate a fully automated,\ntopology-optimization-based hardware design framework for extremely specialized\noptical neural networks, drawing on modern advancements in optimization and\nmachine learning. We evaluate our optical designs on machine learning\nclassification tasks: demonstrating significant improvements over linear\nmethods, and competitive performance when compared to standard artificial\nneural networks.","main_category":"physics.optics","categories":"physics.optics,cs.AR,cs.LG","published":"2025-04-29T03:55:05Z"}
{"aid":"http://arxiv.org/abs/2504.20404v1","title":"Beyond Robertson-Schrödinger: A General Uncertainty Relation Unveiling\n  Hidden Noncommutative Trade-offs","summary":"We report a universal strengthening of the Robertson-Schr\\''odinger\nuncertainty relation, revealing a previously overlooked trade-off of genuinely\nquantum origin, particularly as the state becomes more mixed. Remarkably, this\ngeneralized bound supplements the standard commutator term and the covariance\nterm with an additional positive contribution that depends on the commutator of\nobservables. The relation also rigorously proves and extends a conjectured\nuncertainty relation previously proposed in [Phys. Rev. A 110, 062215 (2024)].\nFor two-level quantum systems, the inequality becomes an exact equality for any\nstate and any pair of observables, establishing that the bound is tight in the\nstrongest possible sense.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,hep-th,math-ph,math.MP,physics.ed-ph","published":"2025-04-29T04:00:02Z"}
{"aid":"http://arxiv.org/abs/2504.20428v1","title":"Escaping Helium and a Highly Muted Spectrum Suggest a Metal-Enriched\n  Atmosphere on Sub-Neptune GJ3090b from JWST Transit Spectroscopy","summary":"Sub-Neptunes, the most common planet type, remain poorly understood. Their\natmospheres are expected to be diverse, but their compositions are challenging\nto determine, even with JWST. Here, we present the first JWST spectroscopic\nstudy of the warm sub-Neptune GJ3090b (2.13R$_\\oplus$, Teq~700 K) which orbits\nan M2V star, making it a favourable target for atmosphere characterization. We\nobserved four transits of GJ3090b; two each using JWST NIRISS/SOSS and\nNIRSpec/G395H, yielding wavelength coverage from 0.6-5.2 $\\mu$m. We detect the\nsignature of the 10833 \\r{A} metastable Helium triplet at a statistical\nsignificance of 5.5$\\sigma$ with an amplitude of 434$\\pm$79 ppm, marking the\nfirst such detection in a sub-Neptune with JWST. This amplitude is\nsignificantly smaller than predicted by solar-metallicity forward models,\nsuggesting a metal-enriched atmosphere which decreases the mass-loss rate and\nattenuates the Helium feature amplitude. Moreover, we find that stellar\ncontamination, in the form of the transit light source effect, dominates the\nNIRISS transmission spectra, with unocculted spot and faculae properties\nvarying across the two visits separated in time by approximately six months.\nFree retrieval analyses on the NIRSpec/G395H spectrum find tentative evidence\nfor highly muted features and a lack of CH4. These findings are best explained\nby a high metallicity atmosphere (>100x solar at 3$\\sigma$ confidence, for\nclouds at $\\sim \\mu$bar pressures) using chemically-consistent retrievals and\nself-consistent model grids. Further observations of GJ3090b are needed for\ntighter constraints on the atmospheric abundances, and to gain a deeper\nunderstanding of the processes that led to its potential metal enrichment.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-29T04:48:16Z"}
{"aid":"http://arxiv.org/abs/2504.20429v1","title":"Estimating the housing production function with unobserved land\n  heterogeneity","summary":"This paper develops a novel method for estimating the housing production\nfunction that addresses transmission bias caused by unobserved heterogeneity in\nland productivity. The approach builds on the nonparametric identification\nstrategy of Gandhi et al. (2020) and exploits the zero-profit condition to\nallow consistent estimation even when either capital input or housing value is\nunobserved, under the assumption that land productivity follows a Markov\nprocess. Monte Carlo simulations demonstrate that the estimator performs well\nacross a variety of production technologies.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-29T04:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.20449v1","title":"Moiré Band Engineering in Twisted Trilayer WSe2","summary":"We present a systematic theoretical study on the structural and electronic\nproperties of twisted trilayer transition metal dichalcogenide (TMD) WSe$_2$,\nwhere two independent moir\\'e patterns form between adjacent layers. Using a\ncontinuum approach, we investigate the optimized lattice structure and the\nresulting energy band structure, revealing fundamentally different electronic\nbehaviors between helical and alternating twist configurations. In helical\ntrilayers, lattice relaxation induces $\\alpha\\beta$ and $\\beta\\alpha$ domains,\nwhere the two moir\\'e patterns shift to minimize overlap, while in alternating\ntrilayers, $\\alpha\\alpha'$ domains emerge with aligned moir\\'e patterns. A key\nfeature of trilayer TMDs is the summation of moir\\'e potentials from the top\nand bottom layers onto the middle layer, effectively doubling the potential\ndepth. In helical trilayers, this mechanism generates a Kagome lattice\npotential in the $\\alpha\\beta$ domains, giving rise to flat bands\ncharacteristic of Kagome physics. In alternating trilayers, the enhanced\npotential confinement forms deep triangular quantum wells, distinct from those\nfound in bilayer systems. Furthermore, we demonstrate that a moderate\nperpendicular electric field can switch the layer polarization near the valence\nband edge, providing an additional degree of tunability. In particular, it\nenables tuning of the hybridization between orbitals on different layers,\nallowing for the engineering of diverse and controllable electronic band\nstructures. Our findings highlight the unique role of moir\\'e potential\nsummation in trilayer systems, offering a broader platform for designing\nmoir\\'e-based electronic and excitonic phenomena beyond those achievable in\nbilayer TMDs.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-29T05:47:43Z"}
{"aid":"http://arxiv.org/abs/2504.20463v1","title":"Simulation of radiation damage effect on silicon detectors using RASER","summary":"Silicon detectors play a crucial role in high energy physics experiments. In\nfuture high energy physics experiments, silicon detectors will be exposed to\nextremely high fluence environment, which can significantly affect their\nperformance. It is important to understand the electrical behavior of detectors\nafter irradiation. In this study, an irradiation simulation framework is\nconstructed in RASER to simulate leakage current and charge collection\neffciency. The defect parameters are obtained from the Hamburg penta trap model\n(HPTM). Based on this work, we predict the similar silicon inner tracker which\nunder a ten-year CEPC Higgs mode run can still maintain over 90% charge\ncollection efficiency.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-29T06:52:32Z"}
{"aid":"http://arxiv.org/abs/2504.20469v1","title":"Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large\n  Language Models","summary":"Understanding how news narratives frame entities is crucial for studying\nmedia's impact on societal perceptions of events. In this paper, we evaluate\nthe zero-shot capabilities of large language models (LLMs) in classifying\nframing roles. Through systematic experimentation, we assess the effects of\ninput context, prompting strategies, and task decomposition. Our findings show\nthat a hierarchical approach of first identifying broad roles and then\nfine-grained roles, outperforms single-step classification. We also demonstrate\nthat optimal input contexts and prompts vary across task levels, highlighting\nthe need for subtask-specific strategies. We achieve a Main Role Accuracy of\n89.4% and an Exact Match Ratio of 34.5%, demonstrating the effectiveness of our\napproach. Our findings emphasize the importance of tailored prompt design and\ninput context optimization for improving LLM performance in entity framing.","main_category":"cs.CL","categories":"cs.CL,cs.CY,I.2.7","published":"2025-04-29T07:10:53Z"}
{"aid":"http://arxiv.org/abs/2504.20486v1","title":"Criticality of charged AdS black holes with string clouds in boundary\n  conformal field theory","summary":"The aim of this letter is to study the universal thermodynamics and\ncriticality of charged AdS black holes with string clouds in the bulk and in\nthe boundary conformal field theory (CFT). For this system, we determined the\ncritical quantities and noticed that the free energy in the bulk exhibits\nswallow tail behavior. In the boundary CFT, the presence of second order phase\ntransition is observed. At constant charge, the heat capacity is finite in the\nbulk but diverges at critical points in the boundary CFT. Furthermore, we tried\nto determine the nature of interactions between black hole molecules in the\nboundary CFT and in the bulk, which is novel for charged AdS black holes with\nstring clouds.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-29T07:24:37Z"}
{"aid":"http://arxiv.org/abs/2504.20490v1","title":"Hetu v2: A General and Scalable Deep Learning System with Hierarchical\n  and Heterogeneous Single Program Multiple Data Annotations","summary":"The Single Program Multiple Data (SPMD) paradigm provides a unified\nabstraction to annotate various parallel dimensions in distributed deep\nlearning (DL) training. With SPMD, users can write training programs from the\nviewpoint of a single device, and the system will automatically deduce the\ntensor sharding and communication patterns. However, with the recent\ndevelopment in large-scale DL models, distributed training exhibits spatial and\ntemporal workload heterogeneity, arising from both device disparities (e.g.,\nmixed hardware, failures) and data variations (e.g., uneven sequence lengths).\nSuch heterogeneity violates SPMD's assumption of uniform workload partitioning,\nwhich restricts its ability to express and optimize heterogeneous parallel\nstrategies effectively.\n  To address this, we propose HSPMD within the Hetu v2 system to achieve\ngeneral and scalable DL training. HSPMD extends SPMD's annotations to support\nasymmetric sharding and composes standard communication primitives for\nhierarchical communication, all while retaining the simplicity of a\nsingle-device declarative programming model. Leveraging HSPMD, Hetu handles\nspatial heterogeneity through progressive graph specialization, enabling\ndevice-specific execution logic, and addresses temporal heterogeneity via\ndynamic graph switching. Evaluations on heterogeneous clusters, elastic\ntraining, and mixed-length data scenarios show that HSPMD matches or\noutperforms specialized systems, providing a flexible and efficient solution\nfor modern large-scale model training.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-29T07:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.20491v1","title":"Separation and Definability in Fragments of Two-Variable First-Order\n  Logic with Counting","summary":"For fragments L of first-order logic (FO) with counting quantifiers, we\nconsider the definability problem, which asks whether a given L-formula can be\nequivalently expressed by a formula in some fragment of L without counting, and\nthe more general separation problem asking whether two mutually exclusive\nL-formulas can be separated in some counting-free fragment of L. We show that\nseparation is undecidable for the two-variable fragment of FO extended with\ncounting quantifiers and for the graded modal logic with inverse, nominals and\nuniversal modality. On the other hand, if inverse or nominals are dropped,\nseparation becomes coNExpTime- or 2ExpTime-complete, depending on whether the\nuniversal modality is present. In contrast, definability can often be reduced\nin polynomial time to validity in L. We also consider uniform separation and\nshow that it often behaves similarly to definability.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-29T07:30:57Z"}
{"aid":"http://arxiv.org/abs/2504.20492v1","title":"Triadic Closure-Heterogeneity-Harmony GCN for Link Prediction","summary":"Link prediction aims to estimate the likelihood of connections between pairs\nof nodes in complex networks, which is beneficial to many applications from\nfriend recommendation to metabolic network reconstruction. Traditional\nheuristic-based methodologies in the field of complex networks typically depend\non predefined assumptions about node connectivity, limiting their\ngeneralizability across diverse networks. While recent graph neural network\n(GNN) approaches capture global structural features effectively, they often\nneglect node attributes and intrinsic structural relationships between node\npairs. To address this, we propose TriHetGCN, an extension of traditional Graph\nConvolutional Networks (GCNs) that incorporates explicit topological indicators\n-- triadic closure and degree heterogeneity. TriHetGCN consists of three\nmodules: topology feature construction, graph structural representation, and\nconnection probability prediction. The topology feature module constructs node\nfeatures using shortest path distances to anchor nodes, enhancing global\nstructure perception. The graph structural module integrates topological\nindicators into the GCN framework to model triadic closure and heterogeneity.\nThe connection probability module uses deep learning to predict links.\nEvaluated on nine real-world datasets, from traditional networks without node\nattributes to large-scale networks with rich features, TriHetGCN achieves\nstate-of-the-art performance, outperforming mainstream methods. This highlights\nits strong generalization across diverse network types, offering a promising\nframework that bridges statistical physics and graph deep learning.","main_category":"cs.SI","categories":"cs.SI,physics.data-an,physics.soc-ph","published":"2025-04-29T07:32:55Z"}
{"aid":"http://arxiv.org/abs/2504.20503v1","title":"Real-time blow-up and connection graphs of rational vector fields on the\n  Riemann sphere","summary":"Inspired by pioneering work of Ky\\^uya Masuda in the 1980s, only much more\nrecent PDE studies address global boundedness versus finite-time blow-up. The\ntwo phenomena are related by passage from real to purely imaginary time. As a\nsimple ODE example, we study scalar rational vector fields \\begin{equation*}\n\\label{*} \\dot{w}=P(w)/Q(w), \\tag{*} \\end{equation*} for complex polynomials\n$P,Q$. We impose mild generic nondegeneracy conditions, including simplicity of\npoles and hyperbolicity of zeros. Generically, the real-time dynamics become\ngradient-like Morse. Poles play the role of hyperbolic saddle points. Towards\npoles, however, solutions may blow up in finite time.\n  On the Riemann sphere $w\\in\\widehat{\\mathbb{C}}$, we classify the resulting\nglobal dynamics up to $C^0$ orbit equivalence, in real time. This relies on a\nglobal description of the connection graph of blow-up orbits, from sources\ntowards saddles/poles, in forward time. Time reversal identifies the dual graph\nof blow-down orbits. We show that the blow-up and blow-down graphs of (*)\nrealize all finite multi-graphs on $\\mathbb{S}^2$.\n  The purely polynomial case $Q=1$ realizes all planar trees, alias diagrams of\nnon-intersecting circle chords. The anti-holomorphic cousin $P=1$ realizes all\nnoncrossing trees with vertices restricted to circles. This classification\nidentifies combinatorial counts for the number of global phase portraits, which\nonly depend on the degrees of $P$ and $Q$, respectively.","main_category":"math.DS","categories":"math.DS","published":"2025-04-29T07:45:19Z"}
{"aid":"http://arxiv.org/abs/2504.20505v1","title":"MuRAL: A Multi-Resident Ambient Sensor Dataset Annotated with Natural\n  Language for Activities of Daily Living","summary":"Recent advances in Large Language Models (LLMs) have shown promising\npotential for human activity recognition (HAR) using ambient sensors,\nespecially through natural language reasoning and zero-shot learning. However,\nexisting datasets such as CASAS, ARAS, and MARBLE were not originally designed\nwith LLMs in mind and therefore lack the contextual richness, complexity, and\nannotation granularity required to fully exploit LLM capabilities. In this\npaper, we introduce MuRAL, the first Multi-Resident Ambient sensor dataset with\nnatural Language, comprising over 21 hours of multi-user sensor data collected\nfrom 21 sessions in a smart-home environment. MuRAL is annotated with\nfine-grained natural language descriptions, resident identities, and high-level\nactivity labels, all situated in dynamic, realistic multi-resident settings. We\nbenchmark MuRAL using state-of-the-art LLMs for three core tasks: subject\nassignment, action description, and activity classification. Our results\ndemonstrate that while LLMs can provide rich semantic interpretations of\nambient data, current models still face challenges in handling multi-user\nambiguity and under-specified sensor contexts. We release MuRAL to support\nfuture research on LLM-powered, explainable, and socially aware activity\nunderstanding in smart environments. For access to the dataset, please reach\nout to us via the provided contact information. A direct link for dataset\nretrieval will be made available at this location in due course.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T07:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.20506v1","title":"SPARK Hand: Scooping-Pinching Adaptive Robotic Hand with Kempe Mechanism\n  for Vertical Passive Grasp in Environmental Constraints","summary":"This paper presents the SPARK finger, an innovative passive adaptive robotic\nfinger capable of executing both parallel pinching and scooping grasps. The\nSPARK finger incorporates a multi-link mechanism with Kempe linkages to achieve\na vertical linear fingertip trajectory. Furthermore, a parallelogram linkage\nensures the fingertip maintains a fixed orientation relative to the base,\nfacilitating precise and stable manipulation. By integrating these mechanisms\nwith elastic elements, the design enables effective interaction with surfaces,\nsuch as tabletops, to handle challenging objects. The finger employs a passive\nswitching mechanism that facilitates seamless transitions between pinching and\nscooping modes, adapting automatically to various object shapes and\nenvironmental constraints without additional actuators. To demonstrate its\nversatility, the SPARK Hand, equipped with two SPARK fingers, has been\ndeveloped. This system exhibits enhanced grasping performance and stability for\nobjects of diverse sizes and shapes, particularly thin and flat objects that\nare traditionally challenging for conventional grippers. Experimental results\nvalidate the effectiveness of the SPARK design, highlighting its potential for\nrobotic manipulation in constrained and dynamic environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-29T07:47:06Z"}
{"aid":"http://arxiv.org/abs/2504.20516v1","title":"Spatial-enhanced Reflective Coded Aperture Snapshot Spectral Imaging","summary":"Coded aperture snapshot hyperspectral imaging (CASSI) system which captures\n2-D spatial information and 1-D spectral information in just one or two shots\nhas become a promising technology to capture hyperspectral image (HSI).\nHowever, previous CASSI have shortcomings such as poor spatial resolution and\nlow light efficiency that hinder their further applications. In this paper, we\npropose a spatial-enhanced reflective coded aperture snapshot spectral imaging\nsystem (SE-RCASSI). The system achieves superior spatial results and high light\nefficiency because of its specially designed structure. Then, we propose\nSpatial-enhanced Network (SEnet) which takes full use of the prior information\nof grayscale image to boost the reconstruction quality and can serve as an\nimage fusion framework to deploy different algorithms. Furthermore, we propose\nhybrid prior strategy (HPS) to effectively exploit the broad-scope prior of\ntraining set and narrow-scope prior of measurements, resulting in improved\ngeneralization and performance of the network. Finally, we fabricate the\nprototype of SE-RCASSI and conduct experiments in different environments. Both\nexperimental results and numerical simulations show the outstanding performance\nof our method.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T07:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.20517v1","title":"Boundary Control and Calderón type Inverse Problems in Non-local heat\n  equation","summary":"We examine various density results related to the solutions of the non-local\nheat equation at a specific time slice, focusing on two distinct models: one\nwith homogeneous Dirichlet boundary condition and the other with singular\nboundary data. We explore both the qualitative and quantitative aspects of the\napproximations. Additionally, we address Calder\\'on-type inverse problems for\nthese parabolic models, where we recover the potentials by analyzing the\nsolutions either on the boundary or at a particular time slice. In both the\ndensity results and the Calder\\'on type inverse problems, the Pohozaev identity\nplays a crucial role. Finally, in the last section, we apply the Pohozaev\nidentity to a specific elliptic eigenvalue problem and demonstrate that the\neigenfunctions, when divided by an appropriate power of the distance function,\ncan not vanish on any non-empty open subset of the boundary.","main_category":"math.AP","categories":"math.AP","published":"2025-04-29T07:59:11Z"}
{"aid":"http://arxiv.org/abs/2504.20542v1","title":"Digital Twin-Empowered Cooperative Autonomous Car-sharing Services:\n  Proof-of-Concept","summary":"This paper presents a digital twin-empowered real-time optimal delivery\nsystem specifically validated through a proof-of-concept (PoC) demonstration of\na real-world autonomous car-sharing service. This study integrates real-time\ndata from roadside units (RSUs) and connected and autonomous vehicles (CAVs)\nwithin a digital twin of a campus environment to address the dynamic challenges\nof urban traffic. The proposed system leverages the Age of Information (AoI)\nmetric to optimize vehicle routing by maintaining data freshness and\ndynamically adapting to real-time traffic conditions. Experimental results from\nthe PoC demonstrate a 22% improvement in delivery efficiency compared to\nconventional shortest-path methods that do not consider information freshness.\nFurthermore, digital twin-based simulation results demonstrate that this\nproposed system improves overall delivery efficiency by 12% and effectively\nreduces the peak average AoI by 23% compared to the conventional method, where\neach vehicle selects the shortest route without considering information\nfreshness. This study confirms the practical feasibility of cooperative driving\nsystems, highlighting their potential to enhance smart mobility solutions\nthrough scalable digital twin deployments in complex urban environments.","main_category":"cs.OH","categories":"cs.OH","published":"2025-04-29T08:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.20547v1","title":"Revisiting the MIMIC-IV Benchmark: Experiments Using Language Models for\n  Electronic Health Records","summary":"The lack of standardized evaluation benchmarks in the medical domain for text\ninputs can be a barrier to widely adopting and leveraging the potential of\nnatural language models for health-related downstream tasks. This paper\nrevisited an openly available MIMIC-IV benchmark for electronic health records\n(EHRs) to address this issue. First, we integrate the MIMIC-IV data within the\nHugging Face datasets library to allow an easy share and use of this\ncollection. Second, we investigate the application of templates to convert EHR\ntabular data to text. Experiments using fine-tuned and zero-shot LLMs on the\nmortality of patients task show that fine-tuned text-based models are\ncompetitive against robust tabular classifiers. In contrast, zero-shot LLMs\nstruggle to leverage EHR representations. This study underlines the potential\nof text-based approaches in the medical field and highlights areas for further\nimprovement.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T08:49:38Z"}
{"aid":"http://arxiv.org/abs/2504.20569v1","title":"VIMU: Effective Physics-based Realtime Detection and Recovery against\n  Stealthy Attacks on UAVs","summary":"Sensor attacks on robotic vehicles have become pervasive and manipulative.\nTheir latest advancements exploit sensor and detector characteristics to bypass\ndetection. Recent security efforts have leveraged the physics-based model to\ndetect or mitigate sensor attacks. However, these approaches are only resilient\nto a few sensor attacks and still need improvement in detection effectiveness.\nWe present VIMU, an efficient sensor attack detection and resilience system for\nunmanned aerial vehicles. We propose a detection algorithm, CS-EMA, that\nleverages low-pass filtering to identify stealthy gyroscope attacks while\nachieving an overall effective sensor attack detection. We develop a\nfine-grained nonlinear physical model with precise aerodynamic and propulsion\nwrench modeling. We also augment the state estimation with a FIFO buffer\nsafeguard to mitigate the impact of high-rate IMU attacks. The proposed\nphysical model and buffer safeguard provide an effective system state recovery\ntoward maintaining flight stability. We implement VIMU on PX4 autopilot. The\nevaluation results demonstrate the effectiveness of VIMU in detecting and\nmitigating various realistic sensor attacks, especially stealthy attacks.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T09:20:41Z"}
{"aid":"http://arxiv.org/abs/2504.20571v1","title":"Reinforcement Learning for Reasoning in Large Language Models with One\n  Training Example","summary":"We show that reinforcement learning with verifiable reward using one training\nexample (1-shot RLVR) is effective in incentivizing the math reasoning\ncapabilities of large language models (LLMs). Applying RLVR to the base model\nQwen2.5-Math-1.5B, we identify a single example that elevates model performance\non MATH500 from 36.0% to 73.6%, and improves the average performance across six\ncommon mathematical reasoning benchmarks from 17.6% to 35.7%. This result\nmatches the performance obtained using the 1.2k DeepScaleR subset (MATH500:\n73.6%, average: 35.9%), which includes the aforementioned example. Similar\nsubstantial improvements are observed across various models (Qwen2.5-Math-7B,\nLlama3.2-3B-Instruct, DeepSeek-R1-Distill-Qwen-1.5B), RL algorithms (GRPO and\nPPO), and different math examples (many of which yield approximately 30% or\ngreater improvement on MATH500 when employed as a single training example). In\naddition, we identify some interesting phenomena during 1-shot RLVR, including\ncross-domain generalization, increased frequency of self-reflection, and\nsustained test performance improvement even after the training accuracy has\nsaturated, a phenomenon we term post-saturation generalization. Moreover, we\nverify that the effectiveness of 1-shot RLVR primarily arises from the policy\ngradient loss, distinguishing it from the \"grokking\" phenomenon. We also show\nthe critical role of promoting exploration (e.g., by adding entropy loss with\nan appropriate coefficient) in 1-shot RLVR training. As a bonus, we observe\nthat applying entropy loss alone, without any outcome reward, significantly\nenhances Qwen2.5-Math-1.5B's performance on MATH500 by 27.4%. These findings\ncan inspire future work on RLVR data efficiency and encourage a re-examination\nof both recent progress and the underlying mechanisms in RLVR. Our code, model,\nand data are open source at https://github.com/ypwang61/One-Shot-RLVR","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-29T09:24:30Z"}
{"aid":"http://arxiv.org/abs/2504.20572v1","title":"A foundry-fabricated spin qubit unit cell with in-situ dispersive\n  readout","summary":"Spin qubits based on semiconductor quantum dots are a promising prospect for\nquantum computation because of their high coherence times and gate fidelities.\nHowever, scaling up those structures to the numbers required by fault-tolerant\nquantum computing is currently hampered by a number of issues. One of the main\nissues is the need for single-shot low-footprint qubit readout. Here, we\ndemonstrate the single-shot in situ measurement of a compact qubit unit-cell.\nThe unit cell is composed of two electron spins with a controllable exchange\ninteraction. We report initialization, single-shot readout and two-electron\nentangling gate. The unit cell was successfully operated at up to 1 K, with\nstate-of-the-art charge noise levels extracted using free induction decay. With\nits integrated readout and high stability, this foundry fabricated qubit unit\ncell demonstrates strong potential for scalable quantum computing\narchitectures.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-29T09:26:00Z"}
{"aid":"http://arxiv.org/abs/2504.20575v1","title":"Variational principles using a non-symmetric non-triangular distance","summary":"We consider Borwein-Preiss and Ekeland variational principles using distance\nfunctions that neither is symmetric nor enjoy the triangular inequality. All\nthe given results rely exclusively on the convergence and continuity behaviors\ninduced synthetically by the distance function itself without any topological\nimplications. At the end of the paper, we also present two applications; the\nCaristi fixed point theorem and an existence theorem for equilibrium problems.","main_category":"math.FA","categories":"math.FA,math.OC","published":"2025-04-29T09:28:53Z"}
{"aid":"http://arxiv.org/abs/2504.20580v1","title":"Sense-then-Charge: Wireless Power Transfer to Unresponsive Devices with\n  Unknown Location","summary":"This paper explores a multi-antenna dual-functional radio frequency (RF)\nwireless power transfer (WPT) and radar system to charge multiple unresponsive\ndevices. We formulate a beamforming problem to maximize the minimum received\npower at the devices without prior location and channel state information (CSI)\nknowledge. We propose dividing transmission blocks into sensing and charging\nphases. First, the location of the devices is estimated by sending sensing\nsignals and performing multiple signal classification and least square\nestimation on the received echo. Then, the estimations are used for CSI\nprediction and RF-WPT beamforming. Simulation results reveal that there is an\noptimal number of blocks allocated for sensing and charging depending on the\nsystem setup. Our sense-then-charge (STC) protocol can outperform CSI-free\nbenchmarks and achieve near-optimal performance with a sufficient number of\nreceive antennas and transmit power. However, STC struggles if using\ninsufficient antennas or power as device numbers grow.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T09:36:24Z"}
{"aid":"http://arxiv.org/abs/2504.20585v1","title":"Rigidity of Complete Free Boundary Minimal Hypersurfaces in Convex NNSC\n  Manifolds","summary":"We prove that in the unit ball of $\\mathbb{R}^4$, there is no complete\ntwo-sided stable free boundary immersion. The result follows from a rigidity\ntheorem of complete free boundary minimal hypersurfaces in complete 4-manifolds\nwith non-negative intermediate Ricci curvature, convex boundary and weakly\nbounded geometry. The method uses warped $\\theta$-bubble, a generalization of\ncapillary surfaces.","main_category":"math.DG","categories":"math.DG","published":"2025-04-29T09:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.20588v1","title":"Bootstrap Prediction and Confidence Bands for Frequency Response\n  Functions in Posturography","summary":"The frequency response function (FRF) is an established way to describe the\noutcome of experiments in posture control literature. The FRF is an empirical\ntransfer function between an input stimulus and the induced body segment sway\nprofile, represented as a vector of complex values associated with a vector of\nfrequencies. For this reason, testing the components of the FRF independently\nwith Bonferroni correction can result in a too-conservative approach.\nPerforming statistics on scalar values defined on the FRF, e.g., comparing the\naverages, implies an arbitrary decision by the experimenter. This work proposes\nbootstrap prediction and confidence bands as general methods to evaluate the\noutcome of posture control experiments, overcoming the foretold limitations of\npreviously used approaches.","main_category":"stat.AP","categories":"stat.AP,q-bio.NC","published":"2025-04-29T09:40:49Z"}
{"aid":"http://arxiv.org/abs/2504.20601v1","title":"How to turn a Supernova into a PeVatron","summary":"Context. It is important to determine which Galactic cosmic-ray sources can\naccelerate particles to the knee of the cosmic ray spectrum at a few PeV, and\nin particular whether supernova remnants may contribute. Current models for\nparticle acceleration in very young remnants assume the circumstellar material\nconsists of smooth, freely expanding winds. There is strong evidence that some\nsupernovae expand into much denser circumstellar material including dense\nshells ejected by eruptions shortly before explosion.\n  Aims. We investigate the effects of dense circumstellar shells on particle\nacceleration in supernova shocks during the first few years post-explosion, to\nquantify whether such interaction supernovae may act as PeVatrons.\n  Methods. We used the pion code to model the circumstellar medium around\nLuminous Blue Variables after having a brief episode with a mass-loss rate of\nup to dM/dt = 2Msol/yr. Consequently, we performed spherically symmetric 1-D\nsimulations using our time-dependent acceleration-code RATPaC in which we\nsimultaneously solve the transport equations for cosmic-rays, magnetic\nturbulence, and the hydrodynamical flow of the thermal plasma in the\ntest-particle limit.\n  Results. We find that the interaction with the circumstellar shells can\nsignificantly boost the maximum energy by enhancing particle escape during the\nonset of the shock-shell interaction followed by the reacceleration of the\nshock propagating into a medium with a pre-amplified field. Early interactions\nboost the maximum energy to a greater degree and interactions within the first\n5 months after explosion can increase Emax to more then 1 PeV.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-29T10:08:32Z"}
{"aid":"http://arxiv.org/abs/2504.20609v1","title":"WenyanGPT: A Large Language Model for Classical Chinese Tasks","summary":"Classical Chinese, as the core carrier of Chinese culture, plays a crucial\nrole in the inheritance and study of ancient literature. However, existing\nnatural language processing models primarily optimize for Modern Chinese,\nresulting in inadequate performance on Classical Chinese. This paper presents a\ncomprehensive solution for Classical Chinese language processing. By continuing\npre-training and instruction fine-tuning on the LLaMA3-8B-Chinese model, we\nconstruct a large language model, WenyanGPT, which is specifically designed for\nClassical Chinese tasks. Additionally, we develop an evaluation benchmark\ndataset, WenyanBENCH. Experimental results on WenyanBENCH demonstrate that\nWenyanGPT significantly outperforms current advanced LLMs in various Classical\nChinese tasks. We make the model's training data, instruction fine-tuning\ndata\\footnote, and evaluation benchmark dataset publicly available to promote\nfurther research and development in the field of Classical Chinese processing.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T10:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.20614v1","title":"New Zemanian Type Spaces and the Quasiasymptotics for the Fractional\n  Hankel Transform","summary":"We present an Abelian theorem for the fractional Hankel transform (FrHT) on\nthe Montel space $\\mathcal{K}_{-1/2}(\\RR_+)$, which is designed to overcome the\nlimitations of the Zemanian space $\\mathcal K^{\\mu}(\\R_+)$. The essential part\nof the paper is a new construction of the basic space\n$\\mathcal{K}_{-1/2}(\\RR_+)$, ensuring Montel space properties that guarantee\ndesirable topological features such as the equivalence of weak and strong\nconvergence. Also, we prove the continuity of the FrHT on this Montel space,\nboth in function and distribution settings. The paper concludes with a\nTauberian theorem that provides the converse implication showing that under\nappropriate growth and limit conditions the asymptotic behavior of the original\ndistribution can be deduced from that of its FrHT. For this purpose a new space\n$\\mathcal B_{-1/2}(\\RR_+)$ is construct.","main_category":"math.FA","categories":"math.FA","published":"2025-04-29T10:28:41Z"}
{"aid":"http://arxiv.org/abs/2504.20615v1","title":"Multi-Sensor Fusion for Quadruped Robot State Estimation using Invariant\n  Filtering and Smoothing","summary":"This letter introduces two multi-sensor state estimation frameworks for\nquadruped robots, built on the Invariant Extended Kalman Filter (InEKF) and\nInvariant Smoother (IS). The proposed methods, named E-InEKF and E-IS, fuse\nkinematics, IMU, LiDAR, and GPS data to mitigate position drift, particularly\nalong the z-axis, a common issue in proprioceptive-based approaches. We derived\nobservation models that satisfy group-affine properties to integrate LiDAR\nodometry and GPS into InEKF and IS. LiDAR odometry is incorporated using\nIterative Closest Point (ICP) registration on a parallel thread, preserving the\ncomputational efficiency of proprioceptive-based state estimation. We evaluate\nE-InEKF and E-IS with and without exteroceptive sensors, benchmarking them\nagainst LiDAR-based odometry methods in indoor and outdoor experiments using\nthe KAIST HOUND2 robot. Our methods achieve lower Relative Position Errors\n(RPE) and significantly reduce Absolute Trajectory Error (ATE), with\nimprovements of up to 28% indoors and 40% outdoors compared to LIO-SAM and\nFAST-LIO2. Additionally, we compare E-InEKF and E-IS in terms of computational\nefficiency and accuracy.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-29T10:29:00Z"}
{"aid":"http://arxiv.org/abs/2504.20618v1","title":"Statistical Channel Based Low-Complexity Rotation and Position\n  Optimization for 6D Movable Antennas Enabled Wireless Communication","summary":"Six-dimensional movable antenna (6DMA) is a promising technology to fully\nexploit spatial variation in wireless channels by allowing flexible adjustment\nof three-dimensional (3D) positions and rotations of antennas at the\ntransceiver. In this paper, we investigate the practical low-complexity design\nof 6DMA-enabled communication systems, including transmission protocol,\nstatistical channel information (SCI) acquisition, and joint position and\nrotation optimization of 6DMA surfaces based on the SCI of users. Specifically,\nan orthogonal matching pursuit (OMP)-based algorithm is proposed for the\nestimation of SCI of users at all possible position-rotation pairs of 6DMA\nsurfaces based on the channel measurements at a small subset of\nposition-rotation pairs. Then, the average sum logarithmic rate of all users is\nmaximized by jointly designing the positions and rotations of 6DMA surfaces\nbased on their SCI acquired. Different from prior works on 6DMA which adopt\nalternating optimization to design 6DMA positions/rotations with iterations, we\npropose a new sequential optimization approach that first determines 6DMA\nrotations and then finds their feasible positions to realize the optimized\nrotations subject to practical antenna placement constraints. Simulation\nresults show that the proposed sequential optimization significantly reduces\nthe computational complexity of conventional alternating optimization, while\nachieving comparable communication performance. It is also shown that the\nproposed SCI-based 6DMA design can effectively enhance the communication\nthroughput of wireless networks over existing fixed (position and rotation)\nantenna arrays, yet with a practically appealing low-complexity implementation.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-29T10:37:34Z"}
{"aid":"http://arxiv.org/abs/2504.20622v1","title":"The Graded Dual of a Combinatorial Hopf Algebra on Partition Diagrams","summary":"John M. Campbell constructed a combinatorial Hopf algebra (CHA) \\text{ParSym}\non partition diagrams by lifting the CHA structure of \\text{NSym} (the Hopf\nalgebra of noncommutative symmetric functions) through an analogous approach.\nIn this article, we define \\text{ParQSym}, which is the graded dual of\n\\text{ParSym}. Its CHA structure is defined in an explicit, combinatorial way,\nby analogy with that of the CHA \\text{QSym} of quasisymmetric functions. And we\ngive some subcoalgebra and Hopf subalgebras of \\text{ParQSym}, some gradings\nand filtrations of \\text{ParSym} and \\text{ParQSym}, and some bases of\n\\text{ParSym} and \\text{ParQSym} by analogy with some distinguished bases of\n\\text{NSym} and \\text{QSym}.","main_category":"math.RA","categories":"math.RA","published":"2025-04-29T10:45:30Z"}
{"aid":"http://arxiv.org/abs/2504.20624v1","title":"PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time\n  Retrieval","summary":"Social chatbots have become essential intelligent companions in daily\nscenarios ranging from emotional support to personal interaction. However,\nconventional chatbots with passive response mechanisms usually rely on users to\ninitiate or sustain dialogues by bringing up new topics, resulting in\ndiminished engagement and shortened dialogue duration. In this paper, we\npresent PaRT, a novel framework enabling context-aware proactive dialogues for\nsocial chatbots through personalized real-time retrieval and generation.\nSpecifically, PaRT first integrates user profiles and dialogue context into a\nlarge language model (LLM), which is initially prompted to refine user queries\nand recognize their underlying intents for the upcoming conversation. Guided by\nrefined intents, the LLM generates personalized dialogue topics, which then\nserve as targeted queries to retrieve relevant passages from RedNote. Finally,\nwe prompt LLMs with summarized passages to generate knowledge-grounded and\nengagement-optimized responses. Our approach has been running stably in a\nreal-world production environment for more than 30 days, achieving a 21.77\\%\nimprovement in the average duration of dialogues.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T10:51:58Z"}
{"aid":"http://arxiv.org/abs/2504.20629v1","title":"AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized\n  Speech Generation","summary":"In this paper, we address the task of multimodal-to-speech generation, which\naims to synthesize high-quality speech from multiple input modalities: text,\nvideo, and reference audio. This task has gained increasing attention due to\nits wide range of applications, such as film production, dubbing, and virtual\navatars. Despite recent progress, existing methods still suffer from\nlimitations in speech intelligibility, audio-video synchronization, speech\nnaturalness, and voice similarity to the reference speaker. To address these\nchallenges, we propose AlignDiT, a multimodal Aligned Diffusion Transformer\nthat generates accurate, synchronized, and natural-sounding speech from aligned\nmultimodal inputs. Built upon the in-context learning capability of the DiT\narchitecture, AlignDiT explores three effective strategies to align multimodal\nrepresentations. Furthermore, we introduce a novel multimodal classifier-free\nguidance mechanism that allows the model to adaptively balance information from\neach modality during speech synthesis. Extensive experiments demonstrate that\nAlignDiT significantly outperforms existing methods across multiple benchmarks\nin terms of quality, synchronization, and speaker similarity. Moreover,\nAlignDiT exhibits strong generalization capability across various multimodal\ntasks, such as video-to-speech synthesis and visual forced alignment,\nconsistently achieving state-of-the-art performance. The demo page is available\nat https://mm.kaist.ac.kr/projects/AlignDiT .","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.MM","published":"2025-04-29T10:56:24Z"}
{"aid":"http://arxiv.org/abs/2504.20650v1","title":"RuleKit 2: Faster and simpler rule learning","summary":"Rules offer an invaluable combination of predictive and descriptive\ncapabilities. Our package for rule-based data analysis, RuleKit, has proven its\neffectiveness in classification, regression, and survival problems. Here we\npresent its second version. New algorithms and optimized implementations of\nthose previously included, significantly improved the computational performance\nof our suite, reducing the analysis time of some data sets by two orders of\nmagnitude. The usability of RuleKit 2 is provided by two new components: Python\npackage and browser application with a graphical user interface. The former\ncomplies with scikit-learn, the most popular data mining library for Python,\nallowing RuleKit 2 to be straightforwardly integrated into existing data\nanalysis pipelines. RuleKit 2 is available at GitHub under GNU AGPL 3 license\n(https://github.com/adaa-polsl/RuleKit)","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T11:21:11Z"}
{"aid":"http://arxiv.org/abs/2504.20653v1","title":"ComplexVCoder: An LLM-Driven Framework for Systematic Generation of\n  Complex Verilog Code","summary":"Recent advances have demonstrated the promising capabilities of large\nlanguage models (LLMs) in generating register-transfer level (RTL) code, such\nas Verilog. However, existing LLM-based frameworks still face significant\nchallenges in accurately handling the complexity of real-world RTL designs,\nparticularly those that are large-scale and involve multi-level module\ninstantiations. To address this issue, we present ComplexVCoder, an open-source\nLLM-driven framework that enhances both the generation quality and efficiency\nof complex Verilog code. Specifically, we introduce a two-stage generation\nmechanism, which leverages an intermediate representation to enable a more\naccurate and structured transition from natural language descriptions to\nintricate Verilog designs. In addition, we introduce a rule-based alignment\nmethod and a domain-specific retrieval-augmented generation (RAG) to further\nimprove the correctness of the synthesized code by incorporating relevant\ndesign knowledge during generation. To evaluate our approach, we construct a\ncomprehensive dataset comprising 55 complex Verilog designs derived from\nreal-world implementations. We also release an open-source benchmark suite for\nsystematically assessing the quality of auto-generated RTL code together with\nthe ComplexVCoder framework. Experimental results show that ComplexVCoder\noutperforms SOTA frameworks such as CodeV and RTLCoder by 14.6% and 22.2%,\nrespectively, in terms of function correctness on complex Verilog benchmarks.\nFurthermore, ComplexVcoder achieves comparable generation performances in terms\nof functionality correctness using a lightweight 32B model (Qwen2.5), rivaling\nlarger-scale models such as GPT-3.5 and DeepSeek-V3.","main_category":"cs.SE","categories":"cs.SE,cs.SY,eess.SY","published":"2025-04-29T11:22:06Z"}
{"aid":"http://arxiv.org/abs/2504.20656v1","title":"Federated learning, ethics, and the double black box problem in medical\n  AI","summary":"Federated learning (FL) is a machine learning approach that allows multiple\ndevices or institutions to collaboratively train a model without sharing their\nlocal data with a third-party. FL is considered a promising way to address\npatient privacy concerns in medical artificial intelligence. The ethical risks\nof medical FL systems themselves, however, have thus far been underexamined.\nThis paper aims to address this gap. We argue that medical FL presents a new\nvariety of opacity -- federation opacity -- that, in turn, generates a\ndistinctive double black box problem in healthcare AI. We highlight several\ninstances in which the anticipated benefits of medical FL may be exaggerated,\nand conclude by highlighting key challenges that must be overcome to make FL\nethically feasible in medicine.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CY,cs.HC","published":"2025-04-29T11:31:48Z"}
{"aid":"http://arxiv.org/abs/2504.20657v1","title":"Image deidentification in the XNAT ecosystem: use cases and solutions","summary":"XNAT is a server-based data management platform widely used in academia for\ncurating large databases of DICOM images for research projects. We describe in\ndetail a deidentification workflow for DICOM data using facilities in XNAT,\ntogether with independent tools in the XNAT \"ecosystem\". We list different\ncontexts in which deidentification might be needed, based on our prior\nexperience. The starting point for participation in the Medical Image\nDe-Identification Benchmark (MIDI-B) challenge was a set of pre-existing local\nmethodologies, which were adapted during the validation phase of the challenge.\nOur result in the test phase was 97.91\\%, considerably lower than our peers,\ndue largely to an arcane technical incompatibility of our methodology with the\nchallenge's Synapse platform, which prevented us receiving feedback during the\nvalidation phase. Post-submission, additional discrepancy reports from the\norganisers and via the MIDI-B Continuous Benchmarking facility, enabled us to\nimprove this score significantly to 99.61\\%. An entirely rule-based approach\nwas shown to be capable of removing all name-related information in the test\ncorpus, but exhibited failures in dealing fully with address data. Initial\nexperiments using published machine-learning models to remove addresses were\npartially successful but showed the models to be \"over-aggressive\" on other\ntypes of free-text data, leading to a slight overall degradation in performance\nto 99.54\\%. Future development will therefore focus on improving\naddress-recognition capabilities, but also on better removal of identifiable\ndata burned into the image pixels. Several technical aspects relating to the\n\"answer key\" are still under discussion with the challenge organisers, but we\nestimate that our percentage of genuine deidentification failures on the MIDI-B\ntest corpus currently stands at 0.19\\%. (Abridged from original for arXiv\nsubmission)","main_category":"cs.CV","categories":"cs.CV,J.3","published":"2025-04-29T11:33:51Z"}
{"aid":"http://arxiv.org/abs/2504.20658v1","title":"TrueFake: A Real World Case Dataset of Last Generation Fake Images also\n  Shared on Social Networks","summary":"AI-generated synthetic media are increasingly used in real-world scenarios,\noften with the purpose of spreading misinformation and propaganda through\nsocial media platforms, where compression and other processing can degrade fake\ndetection cues. Currently, many forensic tools fail to account for these\nin-the-wild challenges. In this work, we introduce TrueFake, a large-scale\nbenchmarking dataset of 600,000 images including top notch generative\ntechniques and sharing via three different social networks. This dataset allows\nfor rigorous evaluation of state-of-the-art fake image detectors under very\nrealistic and challenging conditions. Through extensive experimentation, we\nanalyze how social media sharing impacts detection performance, and identify\ncurrent most effective detection and training strategies. Our findings\nhighlight the need for evaluating forensic models in conditions that mirror\nreal-world use.","main_category":"cs.MM","categories":"cs.MM,cs.AI,cs.CV","published":"2025-04-29T11:33:52Z"}
{"aid":"http://arxiv.org/abs/2504.20676v1","title":"The Limits of AI Explainability: An Algorithmic Information Theory\n  Approach","summary":"This paper establishes a theoretical foundation for understanding the\nfundamental limits of AI explainability through algorithmic information theory.\nWe formalize explainability as the approximation of complex models by simpler\nones, quantifying both approximation error and explanation complexity using\nKolmogorov complexity. Our key theoretical contributions include: (1) a\ncomplexity gap theorem proving that any explanation significantly simpler than\nthe original model must differ from it on some inputs; (2) precise bounds\nshowing that explanation complexity grows exponentially with input dimension\nbut polynomially with error tolerance for Lipschitz functions; and (3) a\ncharacterization of the gap between local and global explainability,\ndemonstrating that local explanations can be significantly simpler while\nmaintaining accuracy in relevant regions. We further establish a regulatory\nimpossibility theorem proving that no governance framework can simultaneously\npursue unrestricted AI capabilities, human-interpretable explanations, and\nnegligible error. These results highlight considerations likely to be relevant\nto the design, evaluation, and oversight of explainable AI systems.","main_category":"cs.AI","categories":"cs.AI,cs.CY,cs.IT,math.IT","published":"2025-04-29T11:58:37Z"}
{"aid":"http://arxiv.org/abs/2504.20686v1","title":"Inference of high-dimensional weak instrumental variable regression\n  models without ridge-regularization","summary":"Inference of instrumental variable regression models with many weak\ninstruments attracts many attentions recently. To extend the classical\nAnderson-Rubin test to high-dimensional setting, many procedures adopt\nridge-regularization. However, we show that it is not necessary to consider\nridge-regularization. Actually we propose a new quadratic-type test statistic\nwhich does not involve tuning parameters. Our quadratic-type test exhibits high\npower against dense alternatives. While for sparse alternatives, we derive the\nasymptotic distribution of an existing maximum-type test, enabling the use of\nless conservative critical values. To achieve strong performance across a wide\nrange of scenarios, we further introduce a combined test procedure that\nintegrates the strengths of both approaches. This combined procedure is\npowerful without requiring prior knowledge of the underlying sparsity of the\nfirst-stage model. Compared to existing methods, our proposed tests are easy to\nimplement, free of tuning parameters, and robust to arbitrarily weak\ninstruments as well as heteroskedastic errors. Simulation studies and empirical\napplications demonstrate the advantages of our methods over existing\napproaches.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-29T12:10:26Z"}
{"aid":"http://arxiv.org/abs/2504.20698v1","title":"A High-Granularity Proton CT Enhanced by Track Discrimination","summary":"Proton Computed Tomography (pCT) provides a promising solution to enhance the\naccuracy of Relative Stopping Power (RSP) required for proton therapy planning.\nThis research introduces a novel high-granularity pCT architecture that\nincorporates a silicon pixel tracking system and a calorimetric range\ntelescope, which uniquely integrates range telescope functionality with track\ndiscrimination capabilities. The Bortfeld function fitting and Convolutional\nNeural Network (CNN) classifier algorithms are developed and applied for\ndiscrimination. In simulation studies, both approaches demonstrate the\ncapability to reduce uncertainty in Water Equivalent Path Length (WEPL)\ndetermination for individual proton tracks to below 3~mm. The standard imaging\nprotocol (3.2~mGy, $4\\times10^{8}$ protons) achieves sub-millimeter spatial\nresolution ($\\sim$0.5 mm) with sub-1\\% RSP accuracy. With proton count\nrequirements reduced by track discrimination, an ultra-low-dose protocol\n(0.16~mGy, $2\\times10^{7}$~protons) is proposed with achieved sub-1\\% RSP\naccuracy and $\\sim$1.1~mm spatial resolution in simulation. This low-dose\nperformance significantly expands clinical applicability, particularly for\npediatric imaging or frequent imaging scenarios. Furthermore, the target 10 MHz\nproton detection rate suggests potential for real-time image guidance during\nradiotherapy. By circumventing the need for ultra-precise energy measurements,\nthis design minimizes hardware complexity and provides a scalable foundation\nfor future pCT systems.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.ins-det","published":"2025-04-29T12:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.20702v1","title":"Wavefront Shaping of Scattering Forces Enhances Optical Trapping of\n  Levitated Nanoparticles","summary":"Optically-levitated nanoparticles in vacuum offer a pristine platform for\nhigh-quality mechanical oscillators, enabling a wide range of precision\nmeasurements and quantum technologies. A key performance metric in such systems\nis the stiffness of the optical trap, which is typically enhanced by increasing\nlaser power-at the cost of unwanted heating, reduced coherence, and enhanced\nquantum backaction. Here, we demonstrate a fundamentally new route to\nincreasing trap stiffness: wavefront shaping of the optical field. By tailoring\nthe spatial phase profile of the trapping beam, we significantly boost the\nmechanical confinement of subwavelength particles without raising the optical\nintensity. Remarkably, this enhancement arises from a selective reduction of\nnon-conservative optical forces, while preserving the conservative restoring\nforces that define trap stiffness. As a result, mechanical nonlinearities are\nalso reduced, improving stability at low pressures. Our findings challenge the\nlong-standing assumption that diffraction-limited focusing is optimal for\ndipolar Rayleigh particles, and establish wavefront shaping as a powerful,\nreadily applicable tool to control optomechanical forces in levitation\nexperiments. This opens new avenues for minimizing backaction, reducing thermal\ndecoherence, and expanding the range of materials that can be stably levitated.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T12:33:29Z"}
{"aid":"http://arxiv.org/abs/2504.20703v1","title":"BrightCookies at SemEval-2025 Task 9: Exploring Data Augmentation for\n  Food Hazard Classification","summary":"This paper presents our system developed for the SemEval-2025 Task 9: The\nFood Hazard Detection Challenge. The shared task's objective is to evaluate\nexplainable classification systems for classifying hazards and products in two\nlevels of granularity from food recall incident reports. In this work, we\npropose text augmentation techniques as a way to improve poor performance on\nminority classes and compare their effect for each category on various\ntransformer and machine learning models. We explore three word-level data\naugmentation techniques, namely synonym replacement, random word swapping, and\ncontextual word insertion. The results show that transformer models tend to\nhave a better overall performance. None of the three augmentation techniques\nconsistently improved overall performance for classifying hazards and products.\nWe observed a statistically significant improvement (P < 0.05) in the\nfine-grained categories when using the BERT model to compare the baseline with\neach augmented model. Compared to the baseline, the contextual words insertion\naugmentation improved the accuracy of predictions for the minority hazard\nclasses by 6%. This suggests that targeted augmentation of minority classes can\nimprove the performance of transformer models.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T12:34:28Z"}
{"aid":"http://arxiv.org/abs/2504.20714v1","title":"Frequency dependence of temporal spin stiffness and short-range magnetic\n  order in the doped two-dimensional Hubbard model","summary":"We study doping and temperature dependencies of temporal and spatial spin\nstiffnesses of the Hubbard model within the mean field approach for\nincommensurate magnetic order. We show that the frequency dependence of\ntemporal spin stiffness is crucial to obtain small values of correlation\nlength, comparable to those observed in cuprates. Using the obtained spin\nstiffnesses, we obtain the temperature and doping dependence of correlation\nlength within the large-$N$ limit of the respective nonlinear sigma model. In\nagreement with the experimental data on La$_{2-x}$Sr$_x$CuO$_4$ we obtain short\nrange magnetic order with relatively small correlation length at $0.1 \\lesssim\nx\\lesssim 0.2$, and magnetically ordered ground state in the narrow doping\nregion $0.05\\lesssim x \\lesssim 0.1$. The latter state may correspond to the\nspin-frosen state, observed in the experimental data on\nLa$_{2-x}$Sr$_x$CuO$_4$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-29T12:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.20733v1","title":"Unsupervised Surrogate Anomaly Detection","summary":"In this paper, we study unsupervised anomaly detection algorithms that learn\na neural network representation, i.e. regular patterns of normal data, which\nanomalies are deviating from. Inspired by a similar concept in engineering, we\nrefer to our methodology as surrogate anomaly detection. We formalize the\nconcept of surrogate anomaly detection into a set of axioms required for\noptimal surrogate models and propose a new algorithm, named DEAN (Deep Ensemble\nANomaly detection), designed to fulfill these criteria. We evaluate DEAN on 121\nbenchmark datasets, demonstrating its competitive performance against 19\nexisting methods, as well as the scalability and reliability of our method.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-29T13:15:55Z"}
{"aid":"http://arxiv.org/abs/2504.20735v1","title":"Intelligent Task Offloading in VANETs: A Hybrid AI-Driven Approach for\n  Low-Latency and Energy Efficiency","summary":"Vehicular Ad-hoc Networks (VANETs) are integral to intelligent transportation\nsystems, enabling vehicles to offload computational tasks to nearby roadside\nunits (RSUs) and mobile edge computing (MEC) servers for real-time processing.\nHowever, the highly dynamic nature of VANETs introduces challenges, such as\nunpredictable network conditions, high latency, energy inefficiency, and task\nfailure. This research addresses these issues by proposing a hybrid AI\nframework that integrates supervised learning, reinforcement learning, and\nParticle Swarm Optimization (PSO) for intelligent task offloading and resource\nallocation. The framework leverages supervised models for predicting optimal\noffloading strategies, reinforcement learning for adaptive decision-making, and\nPSO for optimizing latency and energy consumption. Extensive simulations\ndemonstrate that the proposed framework achieves significant reductions in\nlatency and energy usage while improving task success rates and network\nthroughput. By offering an efficient, and scalable solution, this framework\nsets the foundation for enhancing real-time applications in dynamic vehicular\nenvironments.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-29T13:20:02Z"}
{"aid":"http://arxiv.org/abs/2504.20755v1","title":"Low dose gamma irradiation study of ATLAS ITk MD8 diodes","summary":"Silicon strip detectors developed for the Inner Tracker (ITk) of the ATLAS\nexperiment will operate in a harsh radiation environment of the HL-LHC\naccelerator. The ITk is thus designed to endure a total fluence of 1.6E15 1MeV\nn_eq/cm2 and a total ionizing dose (TID) of 66 Mrad in the strip detector\nregion. A radiation-hard n^+-in-p technology is implemented in the ITk strip\nsensors. To achieve the required radiation hardness, extensive irradiation\nstudies were conducted during sensor development, primarily performed up to the\nmaximal expected total fluence and TID to ensure a full functionality of the\ndetector at its end-of-life. These studies included irradiations of sensors\nwith various particle types and energies, including the Co60 gamma-rays. Our\nprevious results obtained for gamma-irradiated diodes and strip sensors\nindicate a linear increase of bulk current with TID, while the surface current\nsaturates at the lowest TID levels checked (66 Mrad), preventing a\ndetermination of the exact TID for which the observed saturation occurs. This\nwork presents the results coming from irradiations by Co60 gamma-rays to\nmultiple low TIDs, ranging from 0.5 to 100 krad. The detailed study of total,\nbulk, and surface currents of diodes explores an unknown dependence of surface\ncurrent on the TID, annealing, and temperature. Additionally, the effect of the\np-stop implant between the bias and the guard ring of measured samples is\nshown. The observations are relevant for the initial operations of the new\nATLAS tracker.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-29T13:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.20767v1","title":"did:self A registry-less DID method","summary":"We introduce did:self, a Decentralized Identifier (DID) method that does not\ndepend on any trusted registry for storing the corresponding DID documents.\nInformation for authenticating a did:self subject can be disseminated using any\nmeans and without making any security assumption about the delivery method.\ndid:self is lightweight, it allows controlled delegation, it offers increased\nsecurity and privacy, and it can be used for identifying people, content, as\nwell as IoT devices. Furthermore, DID documents in did:self can be implicit,\nallowing re-construction of DID documents based on other authentication\nmaterial, such as JSON Web Tokens and X.509 certificates.","main_category":"cs.CR","categories":"cs.CR,cs.NI","published":"2025-04-29T13:47:07Z"}
{"aid":"http://arxiv.org/abs/2504.20768v1","title":"LakeVilla: Multi-Table Transactions for Lakehouses","summary":"Data lakehouses (LHs) are at the core of current cloud analytics stacks by\nproviding elastic, relational compute on data in cloud data lakes across\nvendors. For relational semantics, they rely on open table formats (OTFs).\nUnfortunately, they have many missing features inherent to their metadata\ndesigns, like no support for multi-table transactions and recovery in case of\nan abort in concurrent, multi-query workloads. This, in turn, can lead to\nnon-repeatable reads, stale data, and high costs in productive cloud systems.\nIn this work, we introduce LakeVilla, a complementary solution that introduces\nrecovery, multi-query/table transactions, and transaction isolation to\nstate-of-the-art OTFs like Apache Iceberg and Delta Lake tables. We investigate\nits transactional guarantees and show it has minimal impact on performance (2%\nYCSB writes, 2.5% TPC-DS reads) and provides concurrency control for multiple\nreaders and writers for arbitrary long transactions in OTFs in a non-invasive\nway.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-29T13:47:53Z"}
{"aid":"http://arxiv.org/abs/2504.20774v1","title":"On the Effect of Time Preferences on the Price of Anarchy","summary":"This paper examines the impact of agents' myopic optimization on the\nefficiency of systems comprised by many selfish agents. In contrast to standard\ncongestion games where agents interact in a one-shot fashion, in our model each\nagent chooses an infinite sequence of actions and maximizes the total reward\nstream discounted over time under different ways of computing present values.\nOur model assumes that actions consume common resources that get congested, and\nthe action choice by an agent affects the completion times of actions chosen by\nother agents, which in turn affects the time rewards are accrued and their\ndiscounted value. This is a mean-field game, where an agent's reward depends on\nthe decisions of the other agents through the resulting action completion\ntimes. For this type of game we define stationary equilibria, and analyze their\nexistence and price of anarchy (PoA). Overall, we find that the PoA depends\nentirely on the type of discounting rather than its specific parameters. For\nexponential discounting, myopic behaviour leads to extreme inefficiency: the\nPoA is infinity for any value of the discount parameter. For power law\ndiscounting, such inefficiency is greatly reduced and the PoA is 2 whenever\nstationary equilibria exist. This matches the PoA when there is no discounting\nand players maximize long-run average rewards. Additionally, we observe that\nexponential discounting may introduce unstable equilibria in learning\nalgorithms, if action completion times are interdependent. In contrast, under\nno discounting all equilibria are stable.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-29T13:53:21Z"}
{"aid":"http://arxiv.org/abs/2504.20778v1","title":"A multireference picture of electronic excited states in vanadyl and\n  copper tetraphenyl porphyrin molecular qubits","summary":"The nature of electronic excited states has a deep impact on the dynamics of\nmolecular spins, but remains poorly understood and characterized. Here we carry\nout a thorough multiconfigurational investigation for two prototypical\nmolecular qubits based on vanadyl and copper tetra-phenyl porphyrins.\nState-average CASSCF and NEVPT2 calculations have been employed with four\ndifferent active spaces of growing complexity to account for the d-d, second\nd-shell, ligand-to-metal charge transfer states and $\\pi-\\pi^*$ excited states,\nrevealing an in-depth picture of low-lying excited states in agreement with\nexperimental observations. The largest active spaces attempted, (13,14) for the\nvanadyl and (17,12) for the copper compounds, reveal that the lowest-lying\nexcited states originate from $\\pi-\\pi^*$ quartet excitations. These findings\nshed light on the nature of the excited states of molecular qubits, taking an\nimportant step toward elucidating their role in molecular spin dynamics.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci","published":"2025-04-29T13:59:23Z"}
{"aid":"http://arxiv.org/abs/2504.20793v1","title":"Differential symmetry breaking operators for the pair\n  $(\\operatorname{GL}_{n+1}(\\mathbb{R}),\\operatorname{GL}_n(\\mathbb{R}))$","summary":"In this article we study differential symmetry breaking operators between\nprincipal series representations induced from minimal parabolic subgroups for\nthe pair\n$(\\operatorname{GL}_{n+1}(\\mathbb{R}),\\operatorname{GL}_n(\\mathbb{R}))$. Using\nthe source operator philosophy we construct such operators for generic\ninduction parameters of the representations and establish that this approach\nyields all possible operators in this setting. We show that these differential\noperators occur as residues of a family of symmetry breaking operators that\ndepends meromorphically on the parameters. Finally, in the $n=2$ case we\nclassify and construct all differential symmetry breaking operators for any\nparameters, including the non-generic ones.","main_category":"math.RT","categories":"math.RT,math.CA","published":"2025-04-29T14:10:04Z"}
{"aid":"http://arxiv.org/abs/2504.20802v1","title":"Contiguity relations for finite families of orthogonal polynomials in\n  the Askey scheme","summary":"This paper classifies the contiguity relations for finite families of\npolynomials within the ($q$-)Askey scheme. The necessary and sufficient\nconditions for the existence of these contiguity relations are presented first.\nThese conditions are then solved, yielding a comprehensive list of contiguity\nrelations for these various families of polynomials. Furthermore, we\ndemonstrate that all contiguity relations correspond to spectral transforms.","main_category":"math.CA","categories":"math.CA","published":"2025-04-29T14:14:50Z"}
{"aid":"http://arxiv.org/abs/2504.20804v1","title":"Region of Synchronization Estimation for Complex Networks via SOS\n  Programming","summary":"In this article, we explore the problem of the region of synchronization\n(ROS) for complex networks with nonlinear dynamics. Given a pair of state- and\ntarget- sets, our goal is to estimate the ROS such that the trajectories\noriginating within it reach the target set (i.e., synchronization manifold),\nwithout leaving the state set before the first hitting time. In order to do so,\nan exponential guidance-barrier function is proposed to construct the ROS along\nthe synchronization manifold, and the corresponding sufficient conditions for\nestimating the ROS are developed. The resulting conditions lead to a\nsum-of-squares programming problem, thereby affording a polynomial-time\nsolvability. Furthermore, when the synchronization manifold reduces to an\nequilibrium point, our method not only estimates a larger ROS compared to\nexisting results but also allows the ROS to take more general shapes. Finally,\nwe present two numerical examples to demonstrate the effectiveness of the\ntheoretical results.","main_category":"math.OC","categories":"math.OC","published":"2025-04-29T14:16:49Z"}
{"aid":"http://arxiv.org/abs/2504.20828v1","title":"Ascendra: Dynamic Request Prioritization for Efficient LLM Serving","summary":"The rapid advancement of Large Language Models (LLMs) has driven the need for\nmore efficient serving strategies. In this context, efficiency refers to the\nproportion of requests that meet their Service Level Objectives (SLOs),\nparticularly for Time To First Token (TTFT) and Time Between Tokens (TBT).\nHowever, existing systems often prioritize one metric at the cost of the other.\nWe present Ascendra, an LLM serving system designed to meet both TTFT and TBT\nSLOs simultaneously. The core insight behind Ascendra is that a request's\nurgency evolves as it approaches its deadline. To leverage this, Ascendra\npartitions GPU resources into two types of instances: low-priority and\nhigh-priority. Low-priority instances maximize throughput by processing\nrequests out of arrival order, but at the risk of request starvation. To\naddress this, Ascendra employs a performance model to predict requests at risk\nof missing their SLOs and proactively offloads them to high-priority instances.\nHigh-priority instances are optimized for low-latency execution and handle\nurgent requests nearing their deadlines. This partitioned architecture enables\nAscendra to effectively balance high throughput and low latency. Extensive\nevaluation shows that Ascendra improves system throughput by up to 1.7x\ncompared to vLLM and Sarathi-Serve while meeting both TTFT and TBT SLOs.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T14:51:26Z"}
{"aid":"http://arxiv.org/abs/2504.20832v1","title":"Approximate Quantum Fourier Transform in Logarithmic Depth on a Line","summary":"The approximate quantum Fourier transform (AQFT) on $n$ qubits can be\nimplemented in logarithmic depth using $8n$ qubits with all-to-all\nconnectivity, as shown in [Hales, PhD Thesis Berkeley, 2002]. However,\nrealizing the required all-to-all connectivity can be challenging in practice.\nIn this work, we use dynamic circuits, i.e., mid-circuit measurements and\nfeed-forward operations, to implement the AQFT in logarithmic depth using only\n$4n$ qubits arranged on a line with nearest-neighbor connectivity. Furthermore,\nfor states with a specific structure, the number of qubits can be further\nreduced to $2n$ while keeping the logarithmic depth and line connectivity. As\npart of our construction, we introduce a new implementation of an adder with\nlogarithmic depth on a line, which allows us to improve the AQFT construction\nof Hales.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T14:56:41Z"}
{"aid":"http://arxiv.org/abs/2504.20838v1","title":"Bitcoin, a DAO?","summary":"This paper investigates whether Bitcoin can be regarded as a decentralized\nautonomous organization (DAO), what insights it may offer for the broader DAO\necosystem, and how Bitcoin governance can be improved. First, a quantitative\nliterature analysis reveals that Bitcoin is increasingly overlooked in DAO\nresearch, even though early works often classified it as a DAO. Next, the paper\napplies a DAO viability framework - centering on collective intelligence,\ndigital democracy, and adaptation - to examine Bitcoin's organizational and\ngovernance mechanisms. Findings suggest that Bitcoin instantitates key DAO\nprinciples by enabling open participation, and employing decentralized\ndecision-making through Bitcoin Improvement Proposals (BIPs), miner signaling,\nand user-activated soft forks. However, this governance carries potential\nrisks, including reduced clarity on who truly 'votes' due to the concentration\nof economic power among large stakeholders. The paper concludes by highlighting\nopportunities to refine Bitcoin's deliberation process and reflecting on\nbroader implications for DAO design, such as the absence of a legal entity. In\ndoing so, it underscores Bitcoin's continued relevance as an archetype for\ndecentralized governance, offering important findings for future DAO\nimplementations.","main_category":"cs.CY","categories":"cs.CY,cs.ET","published":"2025-04-29T15:01:03Z"}
{"aid":"http://arxiv.org/abs/2504.20859v1","title":"X-Cross: Dynamic Integration of Language Models for Cross-Domain\n  Sequential Recommendation","summary":"As new products are emerging daily, recommendation systems are required to\nquickly adapt to possible new domains without needing extensive retraining.\nThis work presents ``X-Cross'' -- a novel cross-domain\nsequential-recommendation model that recommends products in new domains by\nintegrating several domain-specific language models; each model is fine-tuned\nwith low-rank adapters (LoRA). Given a recommendation prompt, operating layer\nby layer, X-Cross dynamically refines the representation of each source\nlanguage model by integrating knowledge from all other models. These refined\nrepresentations are propagated from one layer to the next, leveraging the\nactivations from each domain adapter to ensure domain-specific nuances are\npreserved while enabling adaptability across domains. Using Amazon datasets for\nsequential recommendation, X-Cross achieves performance comparable to a model\nthat is fine-tuned with LoRA, while using only 25% of the additional\nparameters. In cross-domain tasks, such as adapting from Toys domain to Tools,\nElectronics or Sports, X-Cross demonstrates robust performance, while requiring\nabout 50%-75% less fine-tuning data than LoRA to make fine-tuning effective.\nFurthermore, X-Cross achieves significant improvement in accuracy over\nalternative cross-domain baselines. Overall, X-Cross enables scalable and\nadaptive cross-domain recommendations, reducing computational overhead and\nproviding an efficient solution for data-constrained environments.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL,cs.LG","published":"2025-04-29T15:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.20899v1","title":"Timelike form factor for the anomalous process $γ^\\ast π\n  \\rightarrow ππ$","summary":"The form factor $F_\\3pi(s,t,u)$ for the anomalous process $\\gamma^\\ast \\pi\n\\rightarrow \\pi \\pi$ is calculated in the isospin limit for several values of\nthe light current-quark mass (i.e., the pion mass) using Dyson-Schwinger and\nBethe-Salpeter equations. Beyond a quark interaction kernel representing\ngluon-mediated interactions, leading beyond-rainbow-ladder effects at low\nenergies are incorporated by back-coupling pions as explicit degrees of\nfreedom. Building upon an earlier calculation of the quark-photon vertex that\ncaptures the branch cut associated with the two-pion threshold and the rho\nmeson resonance, the form factor $F_\\3pi(s,t,u)$ is determined for timelike\nMandelstam s. In particular, predictions are made for the kinematics relevant\nfor the Primakoff reaction studied with COMPASS/AMBER at CERN.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-29T16:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.20917v1","title":"Clifford algebra analogue of Cartan's theorem for symmetric pairs","summary":"We extend Kostant's results about $\\mathfrak{g}$-invariants in the Clifford\nalgebra $Cl(\\mathfrak{g})$ of a complex semisimple Lie algebra $\\mathfrak{g}$\nto the relative case of $\\mathfrak{k}$-invariants in the Clifford algebra\n$Cl(\\mathfrak{p})$, where $(\\mathfrak{g},\\mathfrak{k})$ is a classical\nsymmetric pair and $\\mathfrak{p}$ is the $(-1)$-eigenspace of the corresponding\ninvolution. In this setup we prove the Cartan theorem for Clifford algebras, a\nrelative transgression theorem, the Harish--Chandra isomorphism for\n$Cl(\\mathfrak{p})$, and a relative version of Kostant's Clifford algebra\nconjecture.","main_category":"math.RT","categories":"math.RT,math.DG","published":"2025-04-29T16:35:08Z"}
{"aid":"http://arxiv.org/abs/2504.20921v1","title":"Leveraging Generative AI Through Prompt Engineering and Rigorous\n  Validation to Create Comprehensive Synthetic Datasets for AI Training in\n  Healthcare","summary":"Access to high-quality medical data is often restricted due to privacy\nconcerns, posing significant challenges for training artificial intelligence\n(AI) algorithms within Electronic Health Record (EHR) applications. In this\nstudy, prompt engineering with the GPT-4 API was employed to generate\nhigh-quality synthetic datasets aimed at overcoming this limitation. The\ngenerated data encompassed a comprehensive array of patient admission\ninformation, including healthcare provider details, hospital departments,\nwards, bed assignments, patient demographics, emergency contacts, vital signs,\nimmunizations, allergies, medical histories, appointments, hospital visits,\nlaboratory tests, diagnoses, treatment plans, medications, clinical notes,\nvisit logs, discharge summaries, and referrals. To ensure data quality and\nintegrity, advanced validation techniques were implemented utilizing models\nsuch as BERT's Next Sentence Prediction for sentence coherence, GPT-2 for\noverall plausibility, RoBERTa for logical consistency, autoencoders for anomaly\ndetection, and conducted diversity analysis. Synthetic data that met all\nvalidation criteria were integrated into a comprehensive PostgreSQL database,\nserving as the data management system for the EHR application. This approach\ndemonstrates that leveraging generative AI models with rigorous validation can\neffectively produce high-quality synthetic medical data, facilitating the\ntraining of AI algorithms while addressing privacy concerns associated with\nreal patient data.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T16:37:34Z"}
{"aid":"http://arxiv.org/abs/2504.20922v1","title":"DYNAMAX: Dynamic computing for Transformers and Mamba based\n  architectures","summary":"Early exits (EEs) offer a promising approach to reducing computational costs\nand latency by dynamically terminating inference once a satisfactory prediction\nconfidence on a data sample is achieved. Although many works integrate EEs into\nencoder-only Transformers, their application to decoder-only architectures and,\nmore importantly, Mamba models, a novel family of state-space architectures in\nthe LLM realm, remains insufficiently explored. This work introduces DYNAMAX,\nthe first framework to exploit the unique properties of Mamba architectures for\nearly exit mechanisms. We not only integrate EEs into Mamba but also repurpose\nMamba as an efficient EE classifier for both Mamba-based and transformer-based\nLLMs, showcasing its versatility. Our experiments employ the Mistral 7B\ntransformer compared to the Codestral 7B Mamba model, using data sets such as\nTruthfulQA, CoQA, and TriviaQA to evaluate computational savings, accuracy, and\nconsistency. The results highlight the adaptability of Mamba as a powerful EE\nclassifier and its efficiency in balancing computational cost and performance\nquality across NLP tasks. By leveraging Mamba's inherent design for dynamic\nprocessing, we open pathways for scalable and efficient inference in embedded\napplications and resource-constrained environments. This study underscores the\ntransformative potential of Mamba in redefining dynamic computing paradigms for\nLLMs.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-29T16:38:15Z"}
{"aid":"http://arxiv.org/abs/2504.20930v1","title":"ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning\n  through Step-by-Step Verification","summary":"Recent advances in reasoning-enhanced large language models (LLMs) and\nmultimodal LLMs (MLLMs) have significantly improved performance in complex\ntasks, yet medical AI models often overlook the structured reasoning processes\ninherent in clinical practice. In this work, we present ChestX-Reasoner, a\nradiology diagnosis MLLM designed to leverage process supervision mined\ndirectly from clinical reports, reflecting the step-by-step reasoning followed\nby radiologists. We construct a large dataset by extracting and refining\nreasoning chains from routine radiology reports. Our two-stage training\nframework combines supervised fine-tuning and reinforcement learning guided by\nprocess rewards to better align model reasoning with clinical standards. We\nintroduce RadRBench-CXR, a comprehensive benchmark featuring 59K visual\nquestion answering samples with 301K clinically validated reasoning steps, and\npropose RadRScore, a metric evaluating reasoning factuality, completeness, and\neffectiveness. ChestX-Reasoner outperforms existing medical and general-domain\nMLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%,\nand 18% improvements in reasoning ability compared to the best medical MLLM,\nthe best general MLLM, and its base model, respectively, as well as 3.3%, 24%,\nand 27% improvements in outcome accuracy. All resources are open-sourced to\nfacilitate further research in medical reasoning MLLMs.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV","published":"2025-04-29T16:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.20932v1","title":"Improvements of Dark Experience Replay and Reservoir Sampling towards\n  Better Balance between Consolidation and Plasticity","summary":"Continual learning is the one of the most essential abilities for autonomous\nagents, which can incrementally learn daily-life skills. For this ultimate\ngoal, a simple but powerful method, dark experience replay (DER), has been\nproposed recently. DER mitigates catastrophic forgetting, in which the skills\nacquired in the past are unintentionally forgotten, by stochastically storing\nthe streaming data in a reservoir sampling (RS) buffer and by relearning them\nor retaining the past outputs for them. However, since DER considers multiple\nobjectives, it will not function properly without appropriate weighting of\nthem. In addition, the ability to retain past outputs inhibits learning if the\npast outputs are incorrect due to distribution shift or other effects. This is\ndue to a tradeoff between memory consolidation and plasticity. The tradeoff is\nhidden even in the RS buffer, which gradually stops storing new data for new\nskills in it as data is continuously passed to it. To alleviate the tradeoff\nand achieve better balance, this paper proposes improvement strategies to each\nof DER and RS. Specifically, DER is improved with automatic adaptation of\nweights, block of replaying erroneous data, and correction of past outputs. RS\nis also improved with generalization of acceptance probability, stratification\nof plural buffers, and intentional omission of unnecessary data. These\nimprovements are verified through multiple benchmarks including regression,\nclassification, and reinforcement learning problems. As a result, the proposed\nmethods achieve steady improvements in learning performance by balancing the\nmemory consolidation and plasticity.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T16:50:05Z"}
{"aid":"http://arxiv.org/abs/2504.20938v1","title":"Towards Understanding the Nature of Attention with Low-Rank Sparse\n  Decomposition","summary":"We propose Low-Rank Sparse Attention (Lorsa), a sparse replacement model of\nTransformer attention layers to disentangle original Multi Head Self Attention\n(MHSA) into individually comprehensible components. Lorsa is designed to\naddress the challenge of attention superposition to understand\nattention-mediated interaction between features in different token positions.\nWe show that Lorsa heads find cleaner and finer-grained versions of previously\ndiscovered MHSA behaviors like induction heads, successor heads and attention\nsink behavior (i.e., heavily attending to the first token). Lorsa and Sparse\nAutoencoder (SAE) are both sparse dictionary learning methods applied to\ndifferent Transformer components, and lead to consistent findings in many ways.\nFor instance, we discover a comprehensive family of arithmetic-specific Lorsa\nheads, each corresponding to an atomic operation in Llama-3.1-8B. Automated\ninterpretability analysis indicates that Lorsa achieves parity with SAE in\ninterpretability while Lorsa exhibits superior circuit discovery properties,\nespecially for features computed collectively by multiple MHSA heads. We also\nconduct extensive experiments on architectural design ablation, Lorsa scaling\nlaw and error analysis.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-29T17:03:03Z"}
{"aid":"http://arxiv.org/abs/2504.20942v1","title":"Scenario-based Compositional Verification of Autonomous Systems with\n  Neural Perception","summary":"Recent advances in deep learning have enabled the development of autonomous\nsystems that use deep neural networks for perception. Formal verification of\nthese systems is challenging due to the size and complexity of the perception\nDNNs as well as hard-to-quantify, changing environment conditions. To address\nthese challenges, we propose a probabilistic verification framework for\nautonomous systems based on the following key concepts: (1) Scenario-based\nModeling: We decompose the task (e.g., car navigation) into a composition of\nscenarios, each representing a different environment condition. (2)\nProbabilistic Abstractions: For each scenario, we build a compact abstraction\nof perception based on the DNN's performance on an offline dataset that\nrepresents the scenario's environment condition. (3) Symbolic Reasoning and\nAcceleration: The abstractions enable efficient compositional verification of\nthe autonomous system via symbolic reasoning and a novel acceleration proof\nrule that bounds the error probability of the system under arbitrary variations\nof environment conditions. We illustrate our approach on two case studies: an\nexperimental autonomous system that guides airplanes on taxiways using\nhigh-dimensional perception DNNs and a simulation model of an F1Tenth\nautonomous car using LiDAR observations.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-29T17:06:22Z"}
{"aid":"http://arxiv.org/abs/2504.20950v1","title":"Improved Bounds on the Space Complexity of Circuit Evaluation","summary":"Williams (STOC 2025) recently proved that time-$t$ multitape Turing machines\ncan be simulated using $O(\\sqrt{t \\log t})$ space using the Cook-Mertz (STOC\n2024) tree evaluation procedure. As Williams notes, applying this result to\nfast algorithms for the circuit value problem implies an $O(\\sqrt{s} \\cdot\n\\mathrm{polylog}\\; s)$ algorithm for evaluating size $s$ circuits.\n  In this work, we provide a direct reduction from circuit value to tree\nevaluation without passing through Turing machines, simultaneously improving\nthe bound to $O(\\sqrt{s \\log s})$ space and providing a proof with fewer\nabstraction layers.\n  This result can be thought of as a \"sibling\" result to Williams' for circuit\ncomplexity instead of time; in particular, using the fact that time-$t$ Turing\nmachines have size $O(t \\log t)$ circuits, we can recover a slightly weakened\nversion of Williams' result, simulating time-$t$ machines in space $O(\\sqrt{t}\n\\log t)$.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-29T17:18:52Z"}
{"aid":"http://arxiv.org/abs/2504.20958v1","title":"Soft-X-ray momentum microscopy of nonlinear magnon interactions below\n  100-nm wavelength","summary":"Magnons represent quantised collective motions of long-range ordered spins.\nFor wavelength below 100 nm, exchange interactions dominate their physics,\nwhich gives rise to a so far unexplored regime of nonlinearities and couplings\nbetween magnons and other quasiparticles. Besides their selective excitation,\nalso the detection of such short-wavelength spin waves remains a challenge of\ncurrent research and technology. Here, we probe the amplitude and wave vector\nof magnons by means of quasi-elastic resonant soft-X-ray scattering. This\nMagnon Momentum Microscopy (MMM) can access magnons directly in momentum space\nwith remarkable sensitivity and high photon efficiency up to THz frequencies\nand down to few-nanometre wavelengths. The two-dimensional information obtained\nby this light-scattering-based technique is especially valuable for studying\nthe nonlinear interactions of exchange-dominated magnons within technologically\nrelevant thin-film samples. In doing so, we uncover a rich variety of deeply\nnonlinear magnon interactions, highlighting their potential for applications in\nnovel computing schemes. With its intrinsic element-selectivity and ability to\nprobe also buried layers, soft-X-ray MMM has the potential to establish itself\nas an advanced tool for ultrabroadband studies of short-wavelength magnonics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-29T17:31:15Z"}
{"aid":"http://arxiv.org/abs/2504.20972v1","title":"SetKE: Knowledge Editing for Knowledge Elements Overlap","summary":"Large Language Models (LLMs) excel in tasks such as retrieval and question\nanswering but require updates to incorporate new knowledge and reduce\ninaccuracies and hallucinations. Traditional updating methods, like fine-tuning\nand incremental learning, face challenges such as overfitting and high\ncomputational costs. Knowledge Editing (KE) provides a promising alternative\nbut often overlooks the Knowledge Element Overlap (KEO) phenomenon, where\nmultiple triplets share common elements, leading to editing conflicts. We\nidentify the prevalence of KEO in existing KE datasets and show its significant\nimpact on current KE methods, causing performance degradation in handling such\ntriplets. To address this, we propose a new formulation, Knowledge Set Editing\n(KSE), and introduce SetKE, a method that edits sets of triplets\nsimultaneously. Experimental results demonstrate that SetKE outperforms\nexisting methods in KEO scenarios on mainstream LLMs. Additionally, we\nintroduce EditSet, a dataset containing KEO triplets, providing a comprehensive\nbenchmark.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T17:40:29Z"}
{"aid":"http://arxiv.org/abs/2504.20976v1","title":"Real-Time Wayfinding Assistant for Blind and Low-Vision Users","summary":"Navigating unfamiliar places continues to be one of the most persistent and\nessential everyday obstacles for those who are blind or have limited vision\n(BLV). Existing assistive technologies, such as GPS-based navigation systems,\nAI-powered smart glasses, and sonar-equipped canes, often face limitations in\nreal-time obstacle avoidance, precise localization, and adaptability to dynamic\nsurroundings. To investigate potential solutions, we introduced PathFinder, a\nnovel map-less navigation system that explores different models for\nunderstanding 2D images, including Vision Language Models (VLMs), Large\nLanguage Models (LLMs), and employs monocular depth estimation for free-path\ndetection. Our approach integrates a Depth-First Search (DFS) algorithm on\ndepth images to determine the longest obstacle-free path, ensuring optimal\nroute selection while maintaining computational efficiency. We conducted\ncomparative evaluations against existing AI-powered navigation methods and\nperformed a usability study with BLV participants. The results demonstrate that\nPathFinder achieves a favorable balance between accuracy, computational\nefficiency, and real-time responsiveness. Notably, it reduces mean absolute\nerror (MAE) and improves decision-making speed in outdoor navigation compared\nto AI-based alternatives. Participant feedback emphasizes the system's\nusability and effectiveness in outside situations, but also identifies issues\nin complicated indoor locations and low-light conditions. Usability testing\nrevealed that 73% of participants understood how to use the app in about a\nminute, and 80% praised its balance of accuracy, quick response, and overall\nconvenience.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-29T17:45:04Z"}
{"aid":"http://arxiv.org/abs/2504.20981v1","title":"Optical Activity of Group III-V Quantum Dots Directly Embedded in\n  Silicon","summary":"Optically active III-V group semiconductor quantum dots (QDs) are the leading\nelement of the upcoming safe quantum communication. However, the entire\nelectronic and IT infrastructure relies on silicon-based devices, with silicon\nalso providing a natural platform for photonic integration. Combining\nsemiconductor optics with silicon electronics is thus a major technological\nchallenge. This obstacle cannot be directly solved because silicon is optically\ninactive. Interfacing III-V quantum dots with silicon is thus a sought-after\nsolution. A radical approach is to embed III-V material grains directly into\nsilicon. The first realization of such technology was developed, and it gave\nInAs and core-shell InAs/GaAs QDs embedded in Si with bright and narrow\nsingle-QD emission lines. No theory has been given, though, and, as we show\nhere, it is not even obvious if and how such QDs can be optically active. We\nfirst use general arguments, also supported by atomistic calculations, that\nInAs/Si QDs cannot confine both carrier types unless the structural strain is\nmostly relaxed, meaning many defects at the interface. This explains the lack\nof light emission from those dots. Then we show that the InAs/GaAs/Si QDs can\nconfine both carrier types. Their electron states are, however, highly\ninfluenced by $k$-space valley mixing, which impacts emission spectra and\ndeteriorates optical properties. We propose to overcome this by adding an\nadditional wider-bandgap material layer.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-29T17:50:46Z"}
{"aid":"http://arxiv.org/abs/2504.20986v1","title":"Planets Across Space and Time (PAST). VI. Age Dependence of the\n  Occurrence and Architecture of Ultra-Short-Period Planet Systems","summary":"Ultra-short-period (USP) planets, with orbital periods shorter than one day,\nrepresent a unique class of exoplanets whose origin remains puzzling.\nDetermining their age distribution and temporal evolution is vital for\nuncovering their formation and evolutionary pathways. Using a sample of over\n1,000 short-period planets around Sun-like stars, we find that the host stars\nof USP planets are relatively older and have a higher prevalence in the\nGalactic thick disk compared to stars hosting other short-period planets.\nFurthermore, we find that the occurrence of USP planets increases with stellar\nage and uncover evidence indicating that USP planetary system architectures\nevolve on Gyr timescales. This includes a distinct dip-pileup in period\ndistributions around ~1 day and an expansion of orbital spacings with time. In\naddition, younger USP planet systems are observed to have fewer multiple\ntransiting planets, implying fewer nearby companions and/or larger mutual\norbital inclinations. Our findings suggest that USP planets continuously form\nthrough inward migration driven by tidal dissipation over Gyr timescales, and\nthat younger and older USP planets may have originated via different specific\ntidal migration pathways.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-29T17:56:03Z"}
{"aid":"http://arxiv.org/abs/2504.20990v1","title":"Modification of the scattering mechanisms in bilayer graphene in\n  proximity to a molecular thin film probed in the mesoscopic regime","summary":"Quantum coherent effects can be probed in multilayer graphene through\nelectronic transport measurements at low temperatures. In particular, bilayer\ngraphene is known to be susceptible to quantum interference corrections of the\nconductivity, presenting weak localization at all electronic densities, and\ndependent on different scattering mechanisms as well as on the trigonal warping\nof the electron dispersion near the K and K' valleys. Proximity effects with a\nmolecular thin film influence these scattering mechanisms, which can be\nquantified through the known theory of magnetoconductance for bilayer graphene.\nHere, we present weak localization measurements in a copper-phthalocyanine /\nbilayer graphene / h-BN heterostructure that suggest an important suppression\nof trigonal warping effects in bilayer graphene (BLG), restoring the\nmanifestation of the chirality of the charge carriers in the localization\nproperties of BLG. Additionally, we observe a charge transfer of\n3.6$\\times$10$^{12}$cm$^{-2}$ from the BLG to the molecules, as well as a very\nsmall degradation of the mobility of the BLG/h-BN heterostructure upon the\ndeposition of copper phthalocyanine (CuPc). The molecular arrangement of the\nCuPc thin film is characterized in a control sample through transmission\nelectron microscopy, that we relate to the electronic transport results.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-29T17:57:24Z"}
{"aid":"http://arxiv.org/abs/2504.20998v1","title":"YoChameleon: Personalized Vision and Language Generation","summary":"Large Multimodal Models (e.g., GPT-4, Gemini, Chameleon) have evolved into\npowerful tools with millions of users. However, they remain generic models and\nlack personalized knowledge of specific user concepts. Previous work has\nexplored personalization for text generation, yet it remains unclear how these\nmethods can be adapted to new modalities, such as image generation. In this\npaper, we introduce Yo'Chameleon, the first attempt to study personalization\nfor large multimodal models. Given 3-5 images of a particular concept,\nYo'Chameleon leverages soft-prompt tuning to embed subject-specific information\nto (i) answer questions about the subject and (ii) recreate pixel-level details\nto produce images of the subject in new contexts. Yo'Chameleon is trained with\n(i) a self-prompting optimization mechanism to balance performance across\nmultiple modalities, and (ii) a ``soft-positive\" image generation approach to\nenhance image quality in a few-shot setting.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-29T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.21267v1","title":"Searching beyond the fiducial stochastic gravitational wave background\n  in pulsar timing array data using likelihood reweighting","summary":"Since the recent announcements of evidence for a stochastic gravitational\nwave background from several pulsar timing array collaborations, much effort\nhas been devoted to explore features beyond the fiducial Hellings-Downs\nbackground including those arising in modified gravity theories and\ndeterministic gravitational wave signals. Inspired by previous studies, we\npropose a method to efficiently screen these models using likelihood\nreweighting based on the fiducial model. In order to alleviate the well-known\nunstable weight estimates in vanilla importance sampling, we implement\nreweighting for the second time making use of the kernel density estimation of\nthe previously reweighted samples. We tested this method by analyzing three\nsimulated datasets with an injected sinusoid signal applied to all pulsars. It\nis found that likelihood reweighting not only gives results compatible with\nthose from full Bayesian analyses when the signal is subdominant, but is also\nable to recover the signal posterior to a reasonable accuracy in the presence\nof a rather strong signal. Given samples from the fiducial model, this method\ncould bring an at least $\\mathcal{O}(10)$-time speedup in analyzing new models.","main_category":"gr-qc","categories":"gr-qc,astro-ph.IM","published":"2025-04-30T02:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.21278v1","title":"Robust Multi-agent Communication Based on Decentralization-Oriented\n  Adversarial Training","summary":"In typical multi-agent reinforcement learning (MARL) problems, communication\nis important for agents to share information and make the right decisions.\nHowever, due to the complexity of training multi-agent communication, existing\nmethods often fall into the dilemma of local optimization, which leads to the\nconcentration of communication in a limited number of channels and presents an\nunbalanced structure. Such unbalanced communication policy are vulnerable to\nabnormal conditions, where the damage of critical communication channels can\ntrigger the crash of the entire system. Inspired by decentralization theory in\nsociology, we propose DMAC, which enhances the robustness of multi-agent\ncommunication policies by retraining them into decentralized patterns.\nSpecifically, we train an adversary DMAC\\_Adv which can dynamically identify\nand mask the critical communication channels, and then apply the adversarial\nsamples generated by DMAC\\_Adv to the adversarial learning of the communication\npolicy to force the policy in exploring other potential communication schemes\nand transition to a decentralized structure. As a training method to improve\nrobustness, DMAC can be fused with any learnable communication policy\nalgorithm. The experimental results in two communication policies and four\nmulti-agent tasks demonstrate that DMAC achieves higher improvement on\nrobustness and performance of communication policy compared with two\nstate-of-the-art and commonly-used baselines. Also, the results demonstrate\nthat DMAC can achieve decentralized communication structure with acceptable\ncommunication cost.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-30T03:14:50Z"}
{"aid":"http://arxiv.org/abs/2504.21279v1","title":"Linear perturbations of dyonic black holes in the lowest-order $U(1)$\n  gauge-invariant scalar-vector-tensor theories","summary":"We study linear perturbations on top of the static and spherically symmetric\nbackground of dyonic black hole solutions endowed with electric and magnetic\ncharges, as well as a scalar hair, in the lowest-order $U(1)$ gauge-invariant\nscalar-vector-tensor theories. The presence of magnetic charges in the\nbackground solutions gives rise to a mixing between the odd-parity and\neven-parity sectors of perturbations, which makes it impossible to analyze each\nsector separately. Thus, we expand the action up to second order in both\nodd-parity and even-parity perturbations and derive the general conditions for\nthe absence of ghosts and Laplacian instabilities. We apply these general\nconditions to extended Einstein-Maxwell theories, which encompass a wide\nvariety of concrete models from the literature known to have dyonic black hole\nsolutions with the scalar hair, and examine their stabilities. Our general\nframework for studying stability conditions and dynamics of perturbations can\nbe applied to a wide variety of theories, including nonlinear electrodynamics\ncoupled to a scalar field, as well as to calculations of black hole quasinormal\nmodes.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-30T03:20:03Z"}
{"aid":"http://arxiv.org/abs/2504.21280v1","title":"Device-Algorithm Co-Design of Ferroelectric Compute-in-Memory In-Situ\n  Annealer for Combinatorial Optimization Problems","summary":"Combinatorial optimization problems (COPs) are crucial in many applications\nbut are computationally demanding. Traditional Ising annealers address COPs by\ndirectly converting them into Ising models (known as direct-E transformation)\nand solving them through iterative annealing. However, these approaches require\nvector-matrix-vector (VMV) multiplications with a complexity of $O(n^2)$ for\nIsing energy computation and complex exponential annealing factor calculations\nduring annealing process, thus significantly increasing hardware costs. In this\nwork, we propose a ferroelectric compute-in-memory (CiM) in-situ annealer to\novercome aforementioned challenges. The proposed device-algorithm co-design\nframework consists of (i) a novel transformation method (first to our known)\nthat converts COPs into an innovative incremental-E form, which reduces the\ncomplexity of VMV multiplication from $O(n^2)$ to $O(n)$, and approximates\nexponential annealing factor with a much simplified fractional form; (ii) a\ndouble gate ferroelectric FET (DG FeFET)-based CiM crossbar that efficiently\ncomputes the in-situ incremental-E form by leveraging the unique structure of\nDG FeFETs; (iii) %When feasible solutions are detected, a CiM annealer that\napproaches the solutions of COPs via iterative incremental-E computations\nwithin a tunable back gate-based in-situ annealing flow. Evaluation results\nshow that our proposed CiM annealer significantly reduces hardware overhead,\nreducing energy consumption by 1503/1716$\\times$ and time cost by\n8.08/8.15$\\times$ in solving 3000-node Max-Cut problems compared to two\nstate-of-the-art annealers. It also exhibits high solving efficiency, achieving\na remarkable average success rate of 98\\%, whereas other annealers show only\n50\\% given the same iteration counts.","main_category":"cs.ET","categories":"cs.ET","published":"2025-04-30T03:23:33Z"}
{"aid":"http://arxiv.org/abs/2504.21302v1","title":"CMD: Constraining Multimodal Distribution for Domain Adaptation in\n  Stereo Matching","summary":"Recently, learning-based stereo matching methods have achieved great\nimprovement in public benchmarks, where soft argmin and smooth L1 loss play a\ncore contribution to their success. However, in unsupervised domain adaptation\nscenarios, we observe that these two operations often yield multimodal\ndisparity probability distributions in target domains, resulting in degraded\ngeneralization. In this paper, we propose a novel approach, Constrain\nMulti-modal Distribution (CMD), to address this issue. Specifically, we\nintroduce \\textit{uncertainty-regularized minimization} and \\textit{anisotropic\nsoft argmin} to encourage the network to produce predominantly unimodal\ndisparity distributions in the target domain, thereby improving prediction\naccuracy. Experimentally, we apply the proposed method to multiple\nrepresentative stereo-matching networks and conduct domain adaptation from\nsynthetic data to unlabeled real-world scenes. Results consistently demonstrate\nimproved generalization in both top-performing and domain-adaptable\nstereo-matching models. The code for CMD will be available at:\n\\href{https://github.com/gallenszl/CMD}{https://github.com/gallenszl/CMD}.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-30T04:23:48Z"}
{"aid":"http://arxiv.org/abs/2504.21307v1","title":"The Dual Power of Interpretable Token Embeddings: Jailbreaking Attacks\n  and Defenses for Diffusion Model Unlearning","summary":"Despite the remarkable generalization capabilities of diffusion models,\nrecent studies have shown that these models can memorize and generate harmful\ncontent when prompted with specific text instructions. Although fine-tuning\napproaches have been developed to mitigate this issue by unlearning harmful\nconcepts, these methods can be easily circumvented through jailbreaking\nattacks. This indicates that the harmful concept has not been fully erased from\nthe model. However, existing attack methods, while effective, lack\ninterpretability regarding why unlearned models still retain the concept,\nthereby hindering the development of defense strategies. In this work, we\naddress these limitations by proposing an attack method that learns an\northogonal set of interpretable attack token embeddings. The attack token\nembeddings can be decomposed into human-interpretable textual elements,\nrevealing that unlearned models still retain the target concept through\nimplicit textual components. Furthermore, these attack token embeddings are\nrobust and transferable across text prompts, initial noises, and unlearned\nmodels. Finally, leveraging this diverse set of embeddings, we design a defense\nmethod applicable to both our proposed attack and existing attack methods.\nExperimental results demonstrate the effectiveness of both our attack and\ndefense strategies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T04:33:43Z"}
{"aid":"http://arxiv.org/abs/2504.21345v1","title":"Indecomposability of the median hypersimplex and polytopality of the\n  hemi-icosahedral Bier sphere","summary":"We prove that the median hypersimplex $\\Delta_{2k,k}$ is Minkowski\nindecomposable, i.e. it cannot be expressed as a non-trivial Minkowski sum\n$\\Delta_{2k,k} = P+Q$, where $P\\neq \\lambda\\Delta_{2k,k}\\neq Q$. We obtain as a\ncorollary that $\\Delta_{2k,k}$ represents a ray in the submodular cone (the\ndeformation cone of the permutahedron). Building on the previously developed\ngeometric methods and extensive computer search, we exhibit a twelve vertex,\n$4$-dimensional polytopal realization of the Bier sphere of the\nhemi-icosahedron, the vertex minimal triangulation of the real projective\nplane.","main_category":"math.CO","categories":"math.CO,math.MG","published":"2025-04-30T06:16:10Z"}
{"aid":"http://arxiv.org/abs/2504.21356v1","title":"Nexus-Gen: A Unified Model for Image Understanding, Generation, and\n  Editing","summary":"Unified multimodal large language models (MLLMs) aim to integrate multimodal\nunderstanding and generation abilities through a single framework. Despite\ntheir versatility, existing open-source unified models exhibit performance gaps\nagainst domain-specific architectures. To bridge this gap, we present\nNexus-Gen, a unified model that synergizes the language reasoning capabilities\nof LLMs with the image synthesis power of diffusion models. To align the\nembedding space of the LLM and diffusion model, we conduct a dual-phase\nalignment training process. (1) The autoregressive LLM learns to predict image\nembeddings conditioned on multimodal inputs, while (2) the vision decoder is\ntrained to reconstruct high-fidelity images from these embeddings. During\ntraining the LLM, we identified a critical discrepancy between the\nautoregressive paradigm's training and inference phases, where error\naccumulation in continuous embedding space severely degrades generation\nquality. To avoid this issue, we introduce a prefilled autoregression strategy\nthat prefills input sequence with position-embedded special tokens instead of\ncontinuous embeddings. Through dual-phase training, Nexus-Gen has developed the\nintegrated capability to comprehensively address the image understanding,\ngeneration and editing tasks. All models, datasets, and codes are published at\nhttps://github.com/modelscope/Nexus-Gen.git to facilitate further advancements\nacross the field.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-30T06:30:48Z"}
{"aid":"http://arxiv.org/abs/2504.21367v1","title":"Security Analysis and Implementation of Cryptocurrency Systems on\n  Blockchain 2.0","summary":"Blockchain technology has set off a wave of decentralization in the world\nsince its birth. The trust system constructed by blockchain technology based on\ncryptography algorithm and computing power provides a practical and powerful\nsolution to solve the trust problem in human society. In order to make more\nconvenient use of the characteristics of blockchain and build applications on\nit, smart contracts appear. By defining some trigger automatic execution\ncontracts, the application space of blockchain is expanded and the foundation\nfor the rapid development of blockchain is laid. This is blockchain 2.0.\nHowever, the programmability of smart contracts also introduces\nvulnerabilities. In order to cope with the insufficient security guarantee of\nhigh-value application networks running on blockchain 2.0 and smart contracts,\nthis article will be represented by Ethereum to introduce the technical details\nof understanding blockchain 2.0 and the operation principle of contract virtual\nmachines, and explain how cryptocurrencies based on blockchain 2.0 are\nconstructed and operated. The common security problems and solutions are also\ndiscussed. Based on relevant research and on-chain practice, this paper\nprovides a complete and comprehensive perspective to understanding\ncryptocurrency technology based on blockchain 2.0 and provides a reference for\nbuilding more secure cryptocurrency contracts.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-30T06:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.21377v1","title":"Physics-informed Gaussian Processes for Model Predictive Control of\n  Nonlinear Systems","summary":"Recently, a novel linear model predictive control algorithm based on a\nphysics-informed Gaussian Process has been introduced, whose realizations\nstrictly follow a system of underlying linear ordinary differential equations\nwith constant coefficients. The control task is formulated as an inference\nproblem by conditioning the Gaussian process prior on the setpoints and\nincorporating pointwise soft-constraints as further virtual setpoints. We apply\nthis method to systems of nonlinear differential equations, obtaining a local\napproximation through the linearization around an equilibrium point. In the\ncase of an asymptotically stable equilibrium point convergence is given through\nthe Bayesian inference schema of the Gaussian Process. Results for this are\ndemonstrated in a numerical example.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-30T07:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.21379v1","title":"Non-parametric multiple change-point detection","summary":"We introduce a methodology, labelled Non-Parametric Isolate-Detect (NPID),\nfor the consistent estimation of the number and locations of multiple\nchange-points in a non-parametric setting. The method can handle general\ndistributional changes and is based on an isolation technique preventing the\nconsideration of intervals that contain more than one change-point, which\nenhances the estimation accuracy. As stopping rules, we propose both\nthresholding and the optimization of an information criterion. In the scenarios\ntested, which cover a broad range of change types, NPID outperforms the state\nof the art. An R implementation is provided.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-30T07:28:05Z"}
{"aid":"http://arxiv.org/abs/2504.21402v1","title":"A product of strongly quasi-nonexpansive mappings in Hadamard spaces","summary":"In this paper, we prove that the product of strongly quasi-nonexpansive\n$\\Delta$-demiclosed mappings is also a strongly quasi-nonexpansive orbital\n$\\Delta$-demiclosed mapping in Hadamard spaces. Additionally, we establish the\n$\\Delta$-convergence theorem for approximating a common fixed point of infinite\nproducts of these mappings in Hadamard spaces. Our results have practical\napplications in convex function minimization, the minimization of the sum of\nfinitely many convex functions, and solving the convex feasibility problem for\nfinitely many sets in Hadamard spaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-30T08:03:28Z"}
{"aid":"http://arxiv.org/abs/2504.21406v1","title":"Mapping the Human Brain from the Prenatal Period to Infancy Using 3D\n  Magnetic Resonance Imaging","summary":"Human brain development is a complex and dynamic process that begins during\nthe first weeks of pregnancy and lasts until early adulthood. This chapter\nfocuses on the developmental window from prenatal period to infancy, probably\nthe most dynamic period across the entire lifespan. The availability of\nnon-invasive three-dimensional Magnetic Resonance Imaging (MRI) methodologies\nhas changed the paradigm and allows investigations of the living human brain\nstructure - e.g. micro- and macrostructural features of cortical and\nsubcortical regions and their connections, including cortical\nsulcation/gyrification, area, and thickness, as well as white matter\nmicrostructure and connectivity - beginning in utero. Because of its relative\nsafety, MRI is well-adapted to study individuals at multiple time points and to\nlongitudinally follow the changes in brain structure and function that underlie\nthe early stages of cognitive development.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-30T08:05:02Z"}
{"aid":"http://arxiv.org/abs/2504.21416v1","title":"Kolmogorov Cascade as the Governing Mechanism for Intervortex Spacing in\n  Quantum Turbulence","summary":"In this paper, we investigate inertially forced isothermal quantum turbulence\n(coflow of normal and superfluid components) at temperatures of 1.6 and 2 K.\nThe experiments are carried out in a large optical cryostat, where\nquasi-isotropic, homogeneous turbulence is generated using a double oscillating\ngrid. Turbulence intensity is tuned by varying the grid stroke and frequency.\nThe flow is probed via 2D and 3D reconstructions of quasi-isodense microsphere\ntrajectories, from which we extract the large-scale properties of the flow in\nthe fully turbulent regime for different Reynolds numbers: the turbulent\nvelocity fluctuations, the energy transfer rate, and the integral length scale.\nAdditionally, we determine the mean vortex line density $\\mathcal{L}$ via\nattenuation of a second sound standing wave across the entire measurement\nvolume. Our results confirm with an improved accuracy that the intervortex\nspacing $\\ell =1/\\sqrt{\\mathcal{L}}$ scales with the Reynolds number\n$\\text{Re}_\\kappa$ (based on the quantum of circulation $\\kappa$) as\n$\\ell\\propto \\text{Re}_\\kappa^{-3/4}$, with a well-defined numerical prefactor\nand no observed temperature dependence. This scaling recalls that of the\ndissipative length scale in classical Kolmogorov (K41) turbulence and it lead\nprevious authors to interpret $\\ell$ as an effective dissipation length scale.\nHowever, in our temperature range, this interpretation is not consistent with\nthe apparent temperature independence of the prefactor. Based on those\narguments, we propose an alternative interpretation that suggests that the\ninter-vortex distance in coflow turbulence is the consequence of the quantum\nrestricted depth of the superfluid component energy cascade.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-30T08:17:29Z"}
{"aid":"http://arxiv.org/abs/2504.21426v1","title":"Topotactical hydrogen induced single-band $d$-wave superconductivity in\n  La$_2$NiO$_4$","summary":"La$_2$NiO$_4$ is an antiferromagnetic insulator with a structural resemblance\nto its cuprate counterpart, La$_2$CuO$_4$. However, La$_2$CuO$_4$ has a\nCu$^{2+}$ or 3$d^9$ electronic configuration that needs to be hole or electron\ndoped for superconductivity, whereas La$_2$NiO$_4$ is 3$d^8$ with divalent\nNi$^{2+}$. Making a cuprate analog through conventional electron doping is\nimpractical due to the rarity of trivalent substituents for La. In this work,\nwe propose an alternative route: intercalating topotactical hydrogen which is\npossible through electric-field-controlled protonation and transforms\nLa$_2$NiO$_4$ into a 3$d_{x^2-y^2}$ single-band two-dimensional\nanti-ferromagnetic Mott insulator analogous to La$_2$CuO$_4$. This we find\nthrough density-functional theory and dynamical mean-field theory calculations.\nThe furthergoing dynamical vertex approximation predicts that H-La$_2$NiO$_4$\ncan host $d$-wave superconductivity under 15\\% hole doping with a critical\ntemperature above 20\\,K. Our findings not only suggest a new method for tuning\nthe electronic structure of layered nickelates but also provides theoretical\nevidence for a new nickelate superconductor, awaiting experimental synthesis.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-30T08:33:43Z"}
{"aid":"http://arxiv.org/abs/2504.21430v1","title":"Existence and non-existence of the CLT for a family of SDEs driven by\n  stable process","summary":"Stochastic differential equations (SDEs) without global Lipschitz drift often\ndemonstrate unusual phenomena. In this paper, we consider the following SDE on\n$\\mathbb R^d$:\n  \\begin{align*}\n  \\mathrm{d} \\mathbf{X}_t=\\mathbf{b}(\\mathbf{X}_t) \\mathrm{d} t+\n\\mathrm{d}\\mathbf{Z}_t, \\quad \\mathbf{X}_0=\\mathbf{x} \\in \\mathbb{R}^d,\n\\end{align*} where $\\mathbf{Z}_t$ is the rotationally symmetric $\\alpha$-stable\nprocess with $\\alpha \\in(1,2)$ and $\\mathbf{b}:\\mathbb{R}^d \\rightarrow\n\\mathbb{R}^d$ is a differentiable function satisfying the following condition:\nthere exist some $\\theta \\ge 0$, and $K_1 , K_2 , L>0$, so that $$\\langle\n\\mathbf{b}(\\mathbf{x})-\\mathbf{b}(\\mathbf{y}), \\mathbf{x}-\\mathbf{y}\\rangle\n\\leqslant K_1 |\\mathbf{x}-\\mathbf{y}|^2, \\ \\ \\forall \\ \\\n|\\mathbf{x}-\\mathbf{y}| \\leqslant L, $$ $$\\langle\n\\mathbf{b}(\\mathbf{x})-\\mathbf{b}(\\mathbf{y}), \\mathbf{x}-\\mathbf{y}\\rangle\n\\leqslant -K_2 |\\mathbf{x}-\\mathbf{y}|^{2+\\theta}, \\ \\ \\forall \\ \\\n|\\mathbf{x}-\\mathbf{y}| > L.$$ Under this assumption, the SDE admits a unique\ninvariant measure $\\mu$.\n  We investigate the normal central limit theorem (CLT) of the empirical\nmeasures $$ \\mathcal{E}_t^\\mathbf{x}(\\cdot)=\\frac{1}{t} \\int_0^t\n\\delta_{\\mathbf{X}_s }(\\cdot) \\mathrm{d} s, \\ \\ \\ \\ \\mathbf{X}_0=\\mathbf{x} \\in\n\\mathbb{R}^d, \\ \\ t>0, $$ where $\\delta_{\\mathbf{x}}(\\cdot)$ is the Dirac delta\nmeasure.\n  Our results reveal that, for the bounded measurable function $h$, $$\\sqrt t\n\\left(\\mathcal{E}_t^\\mathbf{x}(h)-\\mu(h)\\right)=\\frac{1}{\\sqrt t} \\int_0^t\n\\left(h\\left(\\mathbf{X}_s^\\mathbf{x}\\right)-\\mu(h)\\right) \\mathrm{d} s$$ admits\na normal CLT for $\\theta \\geqslant 0$. For the Lipschitz continuous function\n$h$, the normal CLT does not necessarily hold when $\\theta=0$, but it is\nsatisfied for $\\theta>1-\\frac{\\alpha}{2}$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T08:39:04Z"}
{"aid":"http://arxiv.org/abs/2504.21442v1","title":"Evidence for the existence of a flavor-sextet charmed meson?","summary":"Recently, the LHCb Collaboration reported a signal for a new resonance in the\n$D_s^+ \\pi^\\pm$ invariant mass distribution in the decays $B\\to \\bar{D}^{(*)}\nD_s^+ \\pi^+ \\pi^-$ (arXiv:2411.03399). This could be a direct observation of an\nSU(3) flavor-sextet charmed meson with $J^P=0^+$. Such an SU(3) multiplet, is\nbeyond the conventional quark-antiquark picture, and thus a verification of\nthis observation is important.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-30T08:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.21445v1","title":"Emerging Advances in Learned Video Compression: Models, Systems and\n  Beyond","summary":"Video compression is a fundamental topic in the visual intelligence, bridging\nvisual signal sensing/capturing and high-level visual analytics. The broad\nsuccess of artificial intelligence (AI) technology has enriched the horizon of\nvideo compression into novel paradigms by leveraging end-to-end optimized\nneural models. In this survey, we first provide a comprehensive and systematic\noverview of recent literature on end-to-end optimized learned video coding,\ncovering the spectrum of pioneering efforts in both uni-directional and\nbi-directional prediction based compression model designation. We further delve\ninto the optimization techniques employed in learned video compression (LVC),\nemphasizing their technical innovations, advantages. Some standardization\nprogress is also reported. Furthermore, we investigate the system design and\nhardware implementation challenges of the LVC inclusively. Finally, we present\nthe extensive simulation results to demonstrate the superior compression\nperformance of LVC models, addressing the question that why learned codecs and\nAI-based video technology would have with broad impact on future visual\nintelligence research.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-30T09:03:16Z"}
{"aid":"http://arxiv.org/abs/2504.21450v1","title":"Coalescing MPI communication in 6D Vlasov simulations: solving ghost\n  domains in Vlasiator","summary":"High-performance computing is used for diverse simulations, some of which\nparallelize over the Message Passing Interface (MPI) with ease, whilst others\nmay have challenges related to uniform balancing of computational load and\ncommunication between simulation domains. We introduce an alternative approach\nto solving advection equations, specifically in an application to solving the\nsix-dimensional Vlasov equation for modelling space plasmas. Communicating\nlarger ghost domains around the partition assigned to each MPI task and\ncomputing on these ghost cells allows for coalescing several discrete\ncommunication calls into one. This approach needs more overall data\ncommunication and computation, but provides interesting new avenues for the\nbalancing of computational load between MPI tasks. We discuss this trade-off,\nhow it may assist in developing other algorithmic improvements, and how the\ntransition to heterogeneous CPU-GPU architectures may impact its usefulness.","main_category":"physics.comp-ph","categories":"physics.comp-ph,physics.plasm-ph,physics.space-ph","published":"2025-04-30T09:13:44Z"}
{"aid":"http://arxiv.org/abs/2504.21452v1","title":"1-2 Conjectures for Graphs with Low Degeneracy Properties","summary":"In a recent work, Keusch proved the so-called 1-2-3 Conjecture, raised by\nKaro\\'nski, {\\L}uczak, and Thomason in 2004: for every connected graph\ndifferent from $K_2$, we can assign labels~$1,2,3$ to the edges so that no two\nadjacent vertices are incident to the same sum of labels. Despite this\nsignificant result, several problems close to the 1-2-3 Conjecture in spirit\nremain widely open. In this work, we focus on the so-called 1-2 Conjecture,\nraised by Przyby{\\l}o and Wo\\'zniak in 2010, which is a counterpart of the\n1-2-3 Conjecture where labels~$1,2$ only can be assigned, and both vertices and\nedges are labelled. We consider both the 1-2 Conjecture in its original form,\nwhere adjacent vertices must be distinguished w.r.t.~their sums of incident\nlabels, and variants for products and multisets. We prove some of these\nconjectures for graphs with bounded maximum degree (at most~$6$) and bounded\nmaximum average degree (at most~$3$), going beyond earlier results of the same\nsort.","main_category":"math.CO","categories":"math.CO","published":"2025-04-30T09:20:47Z"}
{"aid":"http://arxiv.org/abs/2504.21456v1","title":"Collisions with tidal disruption event disks: implications for\n  quasi-periodic X-ray eruptions","summary":"A popular class of models for interpreting quasi-periodic X-ray eruptions\nfrom galactic nuclei (QPEs) invoke collisions between an object on an extreme\nmass ratio inspiral (EMRI) and an accretion disk around a supermassive black\nhole. There are strong links between QPE systems and those disks which formed\nfollowing a tidal disruption event (TDE), and at least two events (AT2019qiz\nand AT2022upj) are known to have occurred following an otherwise typical TDE.\nWe show that the fact that these disks were formed following a TDE strongly\nconstrains their properties, more so than previous models have assumed. Models\nbased on steady-state AGN-like disks have mass contents which grow strongly\nwith size $M_{\\rm disk}\\propto R_{\\rm out}^{7/2}$ and do not conserve the mass\nor angular momentum of the disrupted star. A very different scaling must be\nsatisfied by a TDE disk in order to conserve the disrupted stars angular\nmomentum, $M_{\\rm disk} \\propto R_{\\rm out}^{-1/2}$. These constraints\nsubstantially change the predicted scaling relationships between QPE\nobservables (luminosity, duration, energy, temperature) and the QPE period.\nThey also allow QPE observables to be written in terms of the properties of the\ntwo stars assumed to be involved (the one tidally disrupted and the one on an\nEMRI), making plausibility tests of these models possible. We show that these\nmodifications to the disk structure imply that (i) QPEs cannot be powered by\ncollisions between an orbiting black hole and a TDE disk, (ii) QPEs also cannot\nbe powered by collisions between the surface of a stellar EMRI and a TDE disk.\nA framework in which the collisions are between a TDE disk and a star which has\npuffed up to fill its Hills sphere with a trailing debris stream (as seen in\nrecent simulations) cannot be ruled out from the data, and should be the focus\nof further study.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-30T09:23:21Z"}
{"aid":"http://arxiv.org/abs/2504.21457v1","title":"xEEGNet: Towards Explainable AI in EEG Dementia Classification","summary":"This work presents xEEGNet, a novel, compact, and explainable neural network\nfor EEG data analysis. It is fully interpretable and reduces overfitting\nthrough major parameter reduction. As an applicative use case, we focused on\nclassifying common dementia conditions, Alzheimer's and frontotemporal\ndementia, versus controls. xEEGNet is broadly applicable to other neurological\nconditions involving spectral alterations. We initially used ShallowNet, a\nsimple and popular model from the EEGNet-family. Its structure was analyzed and\ngradually modified to move from a \"black box\" to a more transparent model,\nwithout compromising performance. The learned kernels and weights were examined\nfrom a clinical standpoint to assess medical relevance. Model variants,\nincluding ShallowNet and the final xEEGNet, were evaluated using robust\nNested-Leave-N-Subjects-Out cross-validation for unbiased performance\nestimates. Variability across data splits was explained using embedded EEG\nrepresentations, grouped by class and set, with pairwise separability to\nquantify group distinction. Overfitting was assessed through\ntraining-validation loss correlation and training speed. xEEGNet uses only 168\nparameters, 200 times fewer than ShallowNet, yet retains interpretability,\nresists overfitting, achieves comparable median performance (-1.5%), and\nreduces variability across splits. This variability is explained by embedded\nEEG representations: higher accuracy correlates with greater separation between\ntest set controls and Alzheimer's cases, without significant influence from\ntraining data. xEEGNet's ability to filter specific EEG bands, learn\nband-specific topographies, and use relevant spectral features demonstrates its\ninterpretability. While large deep learning models are often prioritized for\nperformance, this study shows smaller architectures like xEEGNet can be equally\neffective in EEG pathology classification.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-30T09:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.21463v1","title":"RWKV-X: A Linear Complexity Hybrid Language Model","summary":"In this paper, we introduce \\textbf{RWKV-X}, a novel hybrid architecture that\ncombines the efficiency of RWKV for short-range modeling with a sparse\nattention mechanism designed to capture long-range context. Unlike previous\nhybrid approaches that rely on full attention layers and retain quadratic\ncomplexity, RWKV-X achieves linear-time complexity in training and\nconstant-time complexity in inference decoding. We demonstrate that RWKV-X,\nwhen continually pretrained on 64K-token sequences, achieves near-perfect\naccuracy on the 64K passkey retrieval benchmark. It consistently outperforms\nprior RWKV-7 models on long-context benchmarks, while maintaining strong\nperformance on short-context tasks. These results highlight RWKV-X as a\nscalable and efficient backbone for general-purpose language modeling, capable\nof decoding sequences up to 1 million tokens with stable speed and memory\nusage. To facilitate further research and analysis, we have made the\ncheckpoints and the associated code publicly accessible at:\nhttps://github.com/howard-hou/RWKV-X.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T09:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.21472v1","title":"Robust Orthogonal NMF with Label Propagation for Image Clustering","summary":"Non-negative matrix factorization (NMF) is a popular unsupervised learning\napproach widely used in image clustering. However, in real-world clustering\nscenarios, most existing NMF methods are highly sensitive to noise corruption\nand are unable to effectively leverage limited supervised information. To\novercome these drawbacks, we propose a unified non-convex framework with label\npropagation called robust orthogonal nonnegative matrix factorization (RONMF).\nThis method not only considers the graph Laplacian and label propagation as\nregularization terms but also introduces a more effective non-convex structure\nto measure the reconstruction error and imposes orthogonal constraints on the\nbasis matrix to reduce the noise corruption, thereby achieving higher\nrobustness. To solve RONMF, we develop an alternating direction method of\nmultipliers (ADMM)-based optimization algorithm. In particular, all subproblems\nhave closed-form solutions, which ensures its efficiency. Experimental\nevaluations on eight public image datasets demonstrate that the proposed RONMF\noutperforms state-of-the-art NMF methods across various standard metrics and\nshows excellent robustness. The code will be available at\nhttps://github.com/slinda-liu.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T09:49:55Z"}
{"aid":"http://arxiv.org/abs/2504.21476v1","title":"GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal\n  Diffusion Transformers","summary":"Garment sewing patterns are fundamental design elements that bridge the gap\nbetween design concepts and practical manufacturing. The generative modeling of\nsewing patterns is crucial for creating diversified garments. However, existing\napproaches are limited either by reliance on a single input modality or by\nsuboptimal generation efficiency. In this work, we present\n\\textbf{\\textit{GarmentDiffusion}}, a new generative model capable of producing\ncentimeter-precise, vectorized 3D sewing patterns from multimodal inputs (text,\nimage, and incomplete sewing pattern). Our method efficiently encodes 3D sewing\npattern parameters into compact edge token representations, achieving a\nsequence length that is $\\textbf{10}\\times$ shorter than that of the\nautoregressive SewingGPT in DressCode. By employing a diffusion transformer, we\nsimultaneously denoise all edge tokens along the temporal axis, while\nmaintaining a constant number of denoising steps regardless of dataset-specific\nedge and panel statistics. With all combination of designs of our model, the\nsewing pattern generation speed is accelerated by $\\textbf{100}\\times$ compared\nto SewingGPT. We achieve new state-of-the-art results on DressCodeData, as well\nas on the largest sewing pattern dataset, namely GarmentCodeData. The project\nwebsite is available at https://shenfu-research.github.io/Garment-Diffusion/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-30T09:56:59Z"}
{"aid":"http://arxiv.org/abs/2504.21494v1","title":"Towards a $\\cos(2\\varphi)$ Josephson element using aluminum junctions\n  with well-transmitted channels","summary":"We introduce a novel method for fabricating all-aluminum Josephson junctions\nwith highly transmitted conduction channels. Such properties are typically\nassociated with structures requiring intricate fabrication processes, such as\natomic contacts or hybrid junctions based on semiconducting nanowires and 2D\nmaterials. In contrast, our approach relies solely on standard nanofabrication\ntechniques. The resulting devices exhibit a key signature of high-transmission\njunctions - Multiple Andreev Reflections (MAR) - in their current-voltage\ncharacteristics. Furthermore, we propose a straightforward superconducting\ncircuit design based on these junctions, enabling the implementation of a\nparity-protected qubit.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-30T10:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.21501v1","title":"Deep Learning Optimization Using Self-Adaptive Weighted Auxiliary\n  Variables","summary":"In this paper, we develop a new optimization framework for the least squares\nlearning problem via fully connected neural networks or physics-informed neural\nnetworks. The gradient descent sometimes behaves inefficiently in deep learning\nbecause of the high non-convexity of loss functions and the vanishing gradient\nissue. Our idea is to introduce auxiliary variables to separate the layers of\nthe deep neural networks and reformulate the loss functions for ease of\noptimization. We design the self-adaptive weights to preserve the consistency\nbetween the reformulated loss and the original mean squared loss, which\nguarantees that optimizing the new loss helps optimize the original problem.\nNumerical experiments are presented to verify the consistency and show the\neffectiveness and robustness of our models over gradient descent.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-30T10:43:13Z"}
{"aid":"http://arxiv.org/abs/2504.21511v1","title":"Arbitrary precision computation of hydrodynamic stability eigenvalues","summary":"We show that by using higher order precision arithmetic, i.e., using floating\npoint types with more significant bits than standard double precision numbers,\none may accurately compute eigenvalues for non-normal matrices arising in\nhydrodynamic stability problems. The basic principle is illustrated by a\nclassical example of two $7\\times 7$ matrices for which it is well known that\neigenvalue computations fail when using standard double precision arithmetic.\nWe then present an implementation of the Chebyshev tau-QZ method allowing the\nuse of a large number of Chebyshev polynomials together with arbitrary\nprecision arithmetic. This is used to compute the behavior of the spectra for\nCouette and Poiseuille flow at high Reynolds number. An experimental\nconvergence analysis finally makes it evident that high order precision is\nrequired to obtain accurate results.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T10:59:01Z"}
{"aid":"http://arxiv.org/abs/2504.21512v1","title":"Area rule of velocity circulation in two-dimensional instability-driven\n  turbulence beyond the inertial range","summary":"Since Kolmogorov's theory, scaling properties in the inertial range have been\na key topic in turbulence research. However, the velocity statistics show\nnon-universality in three- and two-dimensional turbulence. Migdal (1995) proved\nthe velocity circulation area rule which states the probability density\nfunction (PDF) of circulation is only a function of the minimal surface area\nenclosed by the loop but not the shape of the loop, and later a bifractal\nuniversal behavior is found for circulation in three- and two-dimensional\nturbulence and quantum turbulence (Iyer et al. 2019; M\\\"uller et al. 2021; Zhu\net al. 2023). This paper finds that the velocity circulation area rule can be\ngeneralized in two-dimensional instability-driven turbulence to all scales that\nare not limited to the inertial range. However, similar to the\nthree-dimensional case, the variance of circulation is size-dependent, and\ncompared with the circulation PDFs, the variance-normalized PDFs have a\nsignificantly weaker dependence on the shape of the loop. We also discussed the\narea rule for 8-loops and double loops. We found that the normalized PDF\ndepends only on the scalar area of the 8-loop. However, the area rule for other\ncomplex loops, such as double loops, remains an open question.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-30T11:01:45Z"}
{"aid":"http://arxiv.org/abs/2504.21517v1","title":"A Bayesian approach to sharing information on sensitivity of a\n  Multi-Cancer Early Detection test across and within tumour types and stages","summary":"The Galleri (R) (GRAIL) multi-cancer early detection test measures\ncirculating tumour DNA (ctDNA) to predict the presence of more than 50\ndifferent cancers, from a blood test. If sensitivity of the test to detect\nearly-stage cancers is high, using it as part of a screening programme may lead\nto better cancer outcomes, but available evidence indicates there is\nheterogeneity in sensitivity between cancer types and stages. We describe a\nframework for sharing evidence on test sensitivity between cancer types and/or\nstages, examining whether models with different sharing assumptions are\nsupported by the evidence and considering how further data could be used to\nstrengthen inference. Bayesian hierarchical models were fitted, and the impact\nof information sharing in increasing precision of the estimates of test\nsensitivity for different cancer types and stages was examined. Assumptions on\nsharing were informed by evidence from a review of the literature on the\ndeterminants of ctDNA shedding and its detection in a blood test. Support was\nstrongest for the assumption that sensitivity can be shared only across stage 4\nfor all cancer types. There was also support for the assumption that\nsensitivities can be shared across cancer types for each stage, if cancer types\nexpected to have low sensitivity are excluded which increased precision of\nearly-stage cancer sensitivity estimates and was considered the most\nappropriate model. High heterogeneity limited improvements in precision. For\nfuture research, elicitation of expert opinion could inform more realistic\nsharing assumptions.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-30T11:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.21518v1","title":"Confidential Serverless Computing","summary":"Although serverless computing offers compelling cost and deployment\nsimplicity advantages, a significant challenge remains in securely managing\nsensitive data as it flows through the network of ephemeral function executions\nin serverless computing environments within untrusted clouds. While\nConfidential Virtual Machines (CVMs) offer a promising secure execution\nenvironment, their integration with serverless architectures currently faces\nfundamental limitations in key areas: security, performance, and resource\nefficiency.\n  We present Hacher, a confidential computing system for secure serverless\ndeployments to overcome these limitations. By employing nested confidential\nexecution and a decoupled guest OS within CVMs, Hacher runs each function in a\nminimal \"trustlet\", significantly improving security through a reduced Trusted\nComputing Base (TCB). Furthermore, by leveraging a data-centric I/O\narchitecture built upon a lightweight LibOS, Hacher optimizes network\ncommunication to address performance and resource efficiency challenges.\n  Our evaluation shows that compared to CVM-based deployments, Hacher has 4.3x\nsmaller TCB, improves end-to-end latency (15-93%), achieves higher function\ndensity (up to 907x), and reduces inter-function communication (up to 27x) and\nfunction chaining latency (16.7-30.2x); thus, Hacher offers a practical system\nfor confidential serverless computing.","main_category":"cs.CR","categories":"cs.CR,cs.OS","published":"2025-04-30T11:13:52Z"}
{"aid":"http://arxiv.org/abs/2504.21560v1","title":"Plausible Indication of Gamma-Ray Absorption by Dark Matter in NGC 1068","summary":"NGC 1068 is the brightest extragalactic source in high-energy neutrinos as\nseen by IceCube, yet the accompanying gamma-ray flux is orders of magnitude\nweaker. It has been argued that this indicates that the bulk of neutrinos and\ngamma rays are emitted in the innermost vicinity of the central supermassive\nblack hole, which is transparent to neutrinos, but opaque to gamma rays. Even\nin such extreme scenarios for the acceleration of cosmic rays, astrophysical\nmodels typically overestimate the low-energy gamma-ray flux and/or require some\nfine-tuning in the physical parameters. Here we suggest instead that the dark\nmatter surrounding the supermassive black hole may absorb the gamma rays,\ninducing the observed deficit. We show that for a dark matter-photon scattering\ncross section in the range $\\sigma_{\\rm DM-\\gamma}/m_{\\rm DM} \\simeq\n10^{-28}-10^{-30}$ cm$^2$/GeV, Fermi-LAT measurements can be well reconciled\nwith IceCube data. We also present some simple particle physics examples that\nachieve the correct spectral energy dependence while respecting complementary\nconstraints.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE","published":"2025-04-30T11:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.21568v1","title":"A Study on Group Decision Making Problem Based on Fuzzy Reasoning and\n  Bayesian Networks","summary":"Aiming at the group decision - making problem with multi - objective\nattributes, this study proposes a group decision - making system that\nintegrates fuzzy inference and Bayesian network. A fuzzy rule base is\nconstructed by combining threshold values, membership functions, expert\nexperience, and domain knowledge to address quantitative challenges such as\nscale differences and expert linguistic variables. A hierarchical Bayesian\nnetwork is designed, featuring a directed acyclic graph with nodes selected by\nexperts, and maximum likelihood estimation is used to dynamically optimize the\nconditional probability table, modeling the nonlinear correlations among\nmultidimensional indices for posterior probability aggregation. In a\ncomprehensive student evaluation case, this method is compared with the\ntraditional weighted scoring approach. The results indicate that the proposed\nmethod demonstrates effectiveness in both rule criterion construction and\nranking consistency, with a classification accuracy of 86.0% and an F1 value\nimprovement of 53.4% over the traditional method. Additionally, computational\nexperiments on real - world datasets across various group decision scenarios\nassess the method's performance and robustness, providing evidence of its\nreliability in diverse contexts.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-30T12:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.21574v1","title":"Generative AI in Financial Institution: A Global Survey of\n  Opportunities, Threats, and Regulation","summary":"Generative Artificial Intelligence (GenAI) is rapidly reshaping the global\nfinancial landscape, offering unprecedented opportunities to enhance customer\nengagement, automate complex workflows, and extract actionable insights from\nvast financial data. This survey provides an overview of GenAI adoption across\nthe financial ecosystem, examining how banks, insurers, asset managers, and\nfintech startups worldwide are integrating large language models and other\ngenerative tools into their operations. From AI-powered virtual assistants and\npersonalized financial advisory to fraud detection and compliance automation,\nGenAI is driving innovation across functions. However, this transformation\ncomes with significant cybersecurity and ethical risks. We discuss emerging\nthreats such as AI-generated phishing, deepfake-enabled fraud, and adversarial\nattacks on AI systems, as well as concerns around bias, opacity, and data\nmisuse. The evolving global regulatory landscape is explored in depth,\nincluding initiatives by major financial regulators and international efforts\nto develop risk-based AI governance. Finally, we propose best practices for\nsecure and responsible adoption - including explainability techniques,\nadversarial testing, auditability, and human oversight. Drawing from academic\nliterature, industry case studies, and policy frameworks, this chapter offers a\nperspective on how the financial sector can harness GenAI's transformative\npotential while navigating the complex risks it introduces.","main_category":"cs.CR","categories":"cs.CR,cs.CE","published":"2025-04-30T12:25:30Z"}
{"aid":"http://arxiv.org/abs/2504.21581v1","title":"Make Both Ends Meet: A Synergistic Optimization Infrared Small Target\n  Detection with Streamlined Computational Overhead","summary":"Infrared small target detection(IRSTD) is widely recognized as a challenging\ntask due to the inherent limitations of infrared imaging, including low\nsignal-to-noise ratios, lack of texture details, and complex background\ninterference. While most existing methods model IRSTD as a semantic\nsegmentation task, but they suffer from two critical drawbacks: (1)blurred\ntarget boundaries caused by long-distance imaging dispersion; and (2) excessive\ncomputational overhead due to indiscriminate feature stackin. To address these\nissues, we propose the Lightweight Efficiency Infrared Small Target Detection\n(LE-IRSTD), a lightweight and efficient framework based on YOLOv8n, with\nfollowing key innovations. Firstly, we identify that the multiple bottleneck\nstructures within the C2f component of the YOLOv8-n backbone contribute to an\nincreased computational burden. Therefore, we implement the Mobile Inverted\nBottleneck Convolution block (MBConvblock) and Bottleneck Structure block\n(BSblock) in the backbone, effectively balancing the trade-off between\ncomputational efficiency and the extraction of deep semantic information.\nSecondly, we introduce the Attention-based Variable Convolution Stem (AVCStem)\nstructure, substituting the final convolution with Variable Kernel Convolution\n(VKConv), which allows for adaptive convolutional kernels that can transform\ninto various shapes, facilitating the receptive field for the extraction of\ntargets. Finally, we employ Global Shuffle Convolution (GSConv) to shuffle the\nchannel dimension features obtained from different convolutional approaches,\nthereby enhancing the robustness and generalization capabilities of our method.\nExperimental results demonstrate that our LE-IRSTD method achieves compelling\nresults in both accuracy and lightweight performance, outperforming several\nstate-of-the-art deep learning methods.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-30T12:38:42Z"}
{"aid":"http://arxiv.org/abs/2504.21591v1","title":"Time periodic problem of compressible Euler equations with damping on\n  the whole space","summary":"In this article, time periodic problem of the compressible Euler equations\nwith damping on the whole space is studied. It is well known that in the Euler\nsystem, long-time behavior of solutions is a more delicate problem due to lack\nof the viscosity. By virtue of a damping effect, time global solutions barely\nexist. Under such circumstances, existence of a time periodic solution is\nobtained for sufficiently small time periodic external force when the space\ndimension is greater than or equal to $3$. In addition, its stability is also\nobtained. The solution is asymptotically stable under sufficiently small\ninitial perturbations and the $L^\\infty$ norm of the perturbation decays as\ntime goes to infinity. The potential theoretical estimates work well on a low\nfrequency part of solutions, while a new energy estimate with weights is\nestablished to avoid derivative loss.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T12:49:03Z"}
{"aid":"http://arxiv.org/abs/2504.21599v1","title":"Concentration of mean exit times","summary":"The mean exit time function defined on the $\\delta$-tube around any equator\n$\\mathbb{S}^{n-1} \\subseteq \\mathbb{S}^{n}$ of the sphere $\\mathbb{S}^{n}$,\n($0<\\delta<\\pi/2$), goes to infinity with the dimension, so that when we\nconsider a Brownian particle that begins its motion at one equator of the\nsphere, this particle will remain near this equator for an almost infinite\namount of time when the dimension of the sphere goes to infinity. On the other\nhand, if the Brownian particle begins its motion at the North pole, then this\nparticle will leave quickly, when the dimension of the sphere goes to infinity,\nany geodesic ball with radius $\\delta <\\pi/2$, centered at this point. Namely,\nthe mean exit time function defined on the equatorial tubes presents a kind of\n{\\em concentration} phenomenon or {\\em fat equator} effect, as it has been\ndescribed in the book \\cite{MS}.\n  Moreover, the same concentration phenomenon occurs when we consider this mean\nexit time function defined on tubes around closed and minimal hypersurfaces of\na compact Riemannian $n$-manifold $M$ with Ricci curvature bounded from below,\n${\\rm Ric}_{M}\\geq (n-1)$. Namely, a Brownian particle that begins its random\nmovement around a closed embedded minimal hypersurface of a compact\n$n$-manifold $M$ with ${\\rm Ric}_{M}\\geq (n-1)$ will wanders arbitrarily close\nto the hypersurface for a time that approaches infinity as the dimension of the\nambient manifold does so as well.","main_category":"math.DG","categories":"math.DG,math.PR","published":"2025-04-30T12:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.21607v1","title":"Optimality and stability of the radial shapes for the Sobolev trace\n  constant","summary":"In this work we establish the optimality and the stability of the ball for\nthe Sobolev trace operator $W^{1,p}(\\Omega)\\hookrightarrow L^q(\\partial\\Omega)$\namong convex sets of prescribed perimeter for any $1< p <+\\infty$ and $1\\le\nq\\le p$. More precisely, we prove that the trace constant $\\sigma_{p,q}$ is\nmaximal for the ball and the deficit is estimated from below by the Hausdorff\nasymmetry. With similar arguments, we prove the optimality and the stability of\nthe spherical shell for the Sobolev exterior trace operator\n$W^{1,p}(\\Omega_0\\setminus\\overline{\\Theta})\\hookrightarrow\nL^q(\\partial\\Omega_0)$ among open sets obtained removing from a convex set\n$\\Omega_0$ a suitably smooth open hole $\\Theta\\subset\\subset\\Omega_0$, with\n$\\Omega_0\\setminus\\overline{\\Theta}$ satisfying a volume and an outer perimeter\nconstraint.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T13:07:47Z"}
{"aid":"http://arxiv.org/abs/2504.21609v1","title":"Applying Machine Learning for characterizing social networks Agent-based\n  models","summary":"Nowadays, social media networks are increasingly significant to our lives,\nthe imperative to study social media networks becomes more and more essential.\nWith billions of users across platforms and constant updates, the complexity of\nmodeling social networks is immense. Agent-based modeling (ABM) is widely\nemployed to study social networks community, allowing us to define individual\nbehaviors and simulate system-level evolution. It can be a powerful tool to\ntest how the algorithms affect users behavior. To fully leverage agent-based\nmodels,superior data processing and storage capabilities are essential. High\nPerformance Computing (HPC) presents an optimal solution, adept at managing\ncomplex computations and analysis, particularly for voluminous or\niteration-intensive tasks. We utilize Machine Learning (ML) methods to analyze\nsocial media users due to their ability to efficiently process vast amounts of\ndata and derive insights that aid in understanding user behaviors, preferences,\nand trends. Therefore, our proposal involves ML to characterize user attributes\nand to develop a general user model for ABM simulation of in social networks on\nHPC systems.","main_category":"cs.SI","categories":"cs.SI,I.6.3","published":"2025-04-30T13:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.21611v1","title":"Prospects for new glueballs and exotics searches","summary":"Glueballs and Hybrids are solid predictions of QCD, but none have this far\nbeen identified in an undisputable way. We list several strategies, including\nthe very promising search for \"cascade\" decays of glueballs and hybrids into\neach others, and mention the yet under-exploited sources in heavy ion\ncollisions","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-30T13:09:19Z"}
{"aid":"http://arxiv.org/abs/2504.21612v1","title":"Selective Variable Convolution Meets Dynamic Content Guided Attention\n  for Infrared Small Target Detection","summary":"Infrared Small Target Detection (IRSTD) system aims to identify small targets\nin complex backgrounds. Due to the convolution operation in Convolutional\nNeural Networks (CNNs), applying traditional CNNs to IRSTD presents challenges,\nsince the feature extraction of small targets is often insufficient, resulting\nin the loss of critical features. To address these issues, we propose a dynamic\ncontent guided attention multiscale feature aggregation network (DCGANet),\nwhich adheres to the attention principle of 'coarse-to-fine' and achieves high\ndetection accuracy. First, we propose a selective variable convolution (SVC)\nmodule that integrates the benefits of standard convolution, irregular\ndeformable convolution, and multi-rate dilated convolution. This module is\ndesigned to expand the receptive field and enhance non-local features, thereby\neffectively improving the discrimination of targets from backgrounds. Second,\nthe core component of DCGANet is a two-stage content guided attention module.\nThis module employs two-stage attention mechanism to initially direct the\nnetwork's focus to salient regions within the feature maps and subsequently\ndetermine whether these regions correspond to targets or background\ninterference. By retaining the most significant responses, this mechanism\neffectively suppresses false alarms. Additionally, we propose adaptive dynamic\nfeature fusion (ADFF) module to substitute for static feature cascading. This\ndynamic feature fusion strategy enables DCGANet to adaptively integrate\ncontextual features, thereby enhancing its ability to discriminate true targets\nfrom false alarms. DCGANet has achieved new benchmarks across multiple\ndatasets.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-30T13:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.21619v1","title":"LRBO2: Improved 3D Vision Based Hand-Eye Calibration for Collaborative\n  Robot Arm","summary":"Hand-eye calibration is a common problem in the field of collaborative\nrobotics, involving the determination of the transformation matrix between the\nvisual sensor and the robot flange to enable vision-based robotic tasks.\nHowever, this process typically requires multiple movements of the robot arm\nand an external calibration object, making it both time-consuming and\ninconvenient, especially in scenarios where frequent recalibration is\nnecessary. In this work, we extend our previous method, Look at Robot Base Once\n(LRBO), which eliminates the need for external calibration objects such as a\nchessboard. We propose a generic dataset generation approach for point cloud\nregistration, focusing on aligning the robot base point cloud with the scanned\ndata. Furthermore, a more detailed simulation study is conducted involving\nseveral different collaborative robot arms, followed by real-world experiments\nin an industrial setting. Our improved method is simulated and evaluated using\na total of 14 robotic arms from 9 different brands, including KUKA, Universal\nRobots, UFACTORY, and Franka Emika, all of which are widely used in the field\nof collaborative robotics. Physical experiments demonstrate that our extended\napproach achieves performance comparable to existing commercial hand-eye\ncalibration solutions, while completing the entire calibration procedure in\njust a few seconds. In addition, we provide a user-friendly hand-eye\ncalibration solution, with the code publicly available at\ngithub.com/leihui6/LRBO2.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T13:20:57Z"}
{"aid":"http://arxiv.org/abs/2504.21625v1","title":"Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn\n  Instruction-Following Ability","summary":"The ability to follow instructions accurately is fundamental for Large\nLanguage Models (LLMs) to serve as reliable agents in real-world applications.\nWhile existing instruction-following benchmarks are either single-turn or\nintroduce new requirements in each turn without allowing self-correction,\nMeeseeks simulates realistic human-LLM interactions through an iterative\nfeedback process. This design enables models to self-correct based on specific\nrequirement failures, better reflecting real-world user-end usage patterns. The\nbenchmark implements a comprehensive evaluation system with 38 capability tags\norganized across three dimensions: Intent Recognition, Granular Content\nValidation, and Output Structure Validation. Through rigorous evaluation across\nLLMs, Meeseeks provides valuable insights into LLMs' instruction-following\ncapabilities in practical applications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T13:28:19Z"}
{"aid":"http://arxiv.org/abs/2504.21626v1","title":"Reply to comment on: Observation of the quantum equivalence principle\n  for matter-waves","summary":"We show that in contrast to a recent claim, the Quantum Galileo\nInterferometer is sensitive to a uniform gravitational field in the presence\nand even in the absence of the levitation condition.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,gr-qc,physics.atom-ph","published":"2025-04-30T13:29:18Z"}
{"aid":"http://arxiv.org/abs/2504.21629v1","title":"The Quantitative Faber-Krahn Inequality for the Combinatorial Laplacian\n  in $\\mathbb{Z}^{d}$","summary":"While the classical Faber-Krahn inequality shows that the ball uniquely\nminimizes the first Dirichlet eigenvalue of the Laplacian in the continuum,\nthis rigidity may fail in the discrete setting. We establish quantitative\nfluctuation estimates for the first Dirichlet eigenvalue of the combinatorial\nLaplacian on subsets of $\\mathbb{Z}^{d}$ when their cardinality diverges. Our\napproach is based on a controlled discrete-to-continuum extension of the\nassociated variational problem and the quantitative Faber-Krahn inequality.","main_category":"math.FA","categories":"math.FA","published":"2025-04-30T13:32:00Z"}
{"aid":"http://arxiv.org/abs/2504.21633v1","title":"Convergence rate for Nearest Neighbour matching: geometry of the domain\n  and higher-order regularity","summary":"Estimating some mathematical expectations from partially observed data and in\nparticular missing outcomes is a central problem encountered in numerous fields\nsuch as transfer learning, counterfactual analysis or causal inference.\nMatching estimators, estimators based on k-nearest neighbours, are widely used\nin this context. It is known that the variance of such estimators can converge\nto zero at a parametric rate, but their bias can have a slower rate when the\ndimension of the covariates is larger than 2. This makes analysis of this bias\nparticularly important. In this paper, we provide higher order properties of\nthe bias. In contrast to the existing literature related to this problem, we do\nnot assume that the support of the target distribution of the covariates is\nstrictly included in that of the source, and we analyse two geometric\nconditions on the support that avoid such boundary bias problems. We show that\nthese conditions are much more general than the usual convex support\nassumption, leading to an improvement of existing results. Furthermore, we show\nthat the matching estimator studied by Abadie and Imbens (2006) for the average\ntreatment effect can be asymptotically efficient when the dimension of the\ncovariates is less than 4, a result only known in dimension 1.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-30T13:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.21658v1","title":"Approximation and regularity results for the Heston model and related\n  processes","summary":"This Ph.D. thesis explores approximations and regularity for the Heston\nstochastic volatility model through three interconnected works.\n  The first work focuses on developing high-order weak approximations for the\nCox-Ingersoll-Ross (CIR) process, essential for financial modelling but\nchallenging due to the square root diffusion term preventing standard methods.\nBy employing the random grid technique (Alfonsi & Bally, 2021) built upon\nAlfonsi's (2010) second-order scheme, the work proves that weak approximations\nof any order can be achieved for smooth test functions. This holds under a\ncondition that is less restrictive than the famous Feller's one. Numerical\nresults confirm convergence for both CIR and Heston models and show significant\ncomputational time improvements.\n  The second work extends the random grid technique to the log-Heston process.\nTwo second-order schemes are introduced (one using exact volatility simulation,\nanother using Ninomiya-Victoir splitting under a the same restriction used\nabove). Convergence to any desired order is rigorously proven. Numerical\nexperiments validate the schemes' effectiveness for pricing European and Asian\noptions and suggest potential applicability to multifactor/rough Heston models.\n  The third work investigates the partial differential equation (PDE)\nassociated with the log-Heston model. It extends classical solution results and\nestablishes the existence and uniqueness of viscosity solutions without relying\non the Feller condition. Uniqueness is proven even for certain discontinuous\ninitial data, relevant for pricing instruments like digital options.\nFurthermore, the convergence of a hybrid numerical scheme to the viscosity\nsolution is shown under relaxed regularity (continuity) for the initial data.\n  An appendix includes supplementary results for the CIR process.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP,math.PR,q-fin.CP","published":"2025-04-30T14:01:01Z"}
{"aid":"http://arxiv.org/abs/2504.21681v1","title":"Investigating the Effect of Parallel Data in the Cross-Lingual Transfer\n  for Vision-Language Encoders","summary":"Most pre-trained Vision-Language (VL) models and training data for the\ndownstream tasks are only available in English. Therefore, multilingual VL\ntasks are solved using cross-lingual transfer: fine-tune a multilingual\npre-trained model or transfer the text encoder using parallel data. We study\nthe alternative approach: transferring an already trained encoder using\nparallel data. We investigate the effect of parallel data: domain and the\nnumber of languages, which were out of focus in previous work. Our results show\nthat even machine-translated task data are the best on average, caption-like\nauthentic parallel data outperformed it in some languages. Further, we show\nthat most languages benefit from multilingual training.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T14:19:15Z"}
{"aid":"http://arxiv.org/abs/2504.21695v1","title":"Self-Supervised Monocular Visual Drone Model Identification through\n  Improved Occlusion Handling","summary":"Ego-motion estimation is vital for drones when flying in GPS-denied\nenvironments. Vision-based methods struggle when flight speed increases and\nclose-by objects lead to difficult visual conditions with considerable motion\nblur and large occlusions. To tackle this, vision is typically complemented by\nstate estimation filters that combine a drone model with inertial measurements.\nHowever, these drone models are currently learned in a supervised manner with\nground-truth data from external motion capture systems, limiting scalability to\ndifferent environments and drones. In this work, we propose a self-supervised\nlearning scheme to train a neural-network-based drone model using only onboard\nmonocular video and flight controller data (IMU and motor feedback). We achieve\nthis by first training a self-supervised relative pose estimation model, which\nthen serves as a teacher for the drone model. To allow this to work at high\nspeed close to obstacles, we propose an improved occlusion handling method for\ntraining self-supervised pose estimation models. Due to this method, the root\nmean squared error of resulting odometry estimates is reduced by an average of\n15%. Moreover, the student neural drone model can be successfully obtained from\nthe onboard data. It even becomes more accurate at higher speeds compared to\nits teacher, the self-supervised vision-based model. We demonstrate the value\nof the neural drone model by integrating it into a traditional filter-based VIO\nsystem (ROVIO), resulting in superior odometry accuracy on aggressive 3D racing\ntrajectories near obstacles. Self-supervised learning of ego-motion estimation\nrepresents a significant step toward bridging the gap between flying in\ncontrolled, expensive lab environments and real-world drone applications. The\nfusion of vision and drone models will enable higher-speed flight and improve\nstate estimation, on any drone in any environment.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-30T14:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.21700v1","title":"XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs","summary":"Large Language Models are fundamental actors in the modern IT landscape\ndominated by AI solutions. However, security threats associated with them might\nprevent their reliable adoption in critical application scenarios such as\ngovernment organizations and medical institutions. For this reason, commercial\nLLMs typically undergo a sophisticated censoring mechanism to eliminate any\nharmful output they could possibly produce. In response to this, LLM\nJailbreaking is a significant threat to such protections, and many previous\napproaches have already demonstrated its effectiveness across diverse domains.\nExisting jailbreak proposals mostly adopt a generate-and-test strategy to craft\nmalicious input. To improve the comprehension of censoring mechanisms and\ndesign a targeted jailbreak attack, we propose an Explainable-AI solution that\ncomparatively analyzes the behavior of censored and uncensored models to derive\nunique exploitable alignment patterns. Then, we propose XBreaking, a novel\njailbreak attack that exploits these unique patterns to break the security\nconstraints of LLMs by targeted noise injection. Our thorough experimental\ncampaign returns important insights about the censoring mechanisms and\ndemonstrates the effectiveness and performance of our attack.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.LG","published":"2025-04-30T14:44:24Z"}
{"aid":"http://arxiv.org/abs/2504.21708v1","title":"Computing Polynomial Representation in Subrings of Multivariate\n  Polynomial Rings","summary":"Let $\\mathcal{R} = \\mathbb{K}[x_1, \\dots, x_n]$ be a multivariate polynomial\nring over a field $\\mathbb{K}$ of characteristic 0. Consider $n$ algebraically\nindependent elements $g_1, \\dots, g_n$ in $\\mathcal{R}$. Let $\\mathcal{S}$\ndenote the subring of $\\mathcal{R}$ generated by $g_1, \\dots, g_n$, and let $h$\nbe an element of $\\mathcal{S}$. Then, there exists a unique element ${f} \\in\n\\mathbb{K}[u_1, \\dots, u_n]$ such that $h = f(g_1, \\dots, g_n)$.\n  In this paper, we provide an algorithm for computing ${f}$, given $h$ and\n$g_1, \\dots, g_n$. The complexity of our algorithm is linear in the size of the\ninput, $h$ and $g_1, \\dots, g_n$, and polynomial in $n$ when the degree of $f$\nis fixed. Previous works are mostly known when $f$ is a symmetric polynomial\nand $g_1, \\dots, g_n$ are elementary symmetric, homogeneous symmetric, or power\nsymmetric polynomials.","main_category":"cs.SC","categories":"cs.SC,cs.CC,math.AG","published":"2025-04-30T14:52:31Z"}
{"aid":"http://arxiv.org/abs/2504.21709v1","title":"Discounting Approaches in Multi-Year Investment Modelling for Energy\n  Systems","summary":"This paper reviews discounting approaches for modeling multi-year energy\ninvestments, focusing on total versus annualised cost formulations. We discuss\nhow time value of money is handled, and how salvage value and milestone-year\nweighting can address mismatches between asset lifetimes and model horizons.\nThese methods are implemented in the open-source TulipaEnergyModel to support\ntransparent and tractable long-term energy system planning.","main_category":"math.OC","categories":"math.OC","published":"2025-04-30T14:52:34Z"}
{"aid":"http://arxiv.org/abs/2504.21712v1","title":"Presentations, embeddings and automorphisms of homogeneous spaces for\n  SL(2,C)","summary":"For an algebraically closed field $k$ of characteristic zero and a linear\nalgebraic $k$-group $G$, it is well known that every affine $G$-variety admits\na $G$-equivariant closed embedding into a finite-dimensional $G$-module. Such\nan embedding is a presentation of the $G$-variety, and a minimal presentation\nis one for which the dimension the $G$-module is minimal. The problem of\nfinding a minimal presentation generalizes the problem of determining whether a\ngroup action on affine space is linearizable. We give a minimal presentation\nfor each homogeneous space for $SL_2(k)$. This constitutes the paper's main\nwork. Of particular interest are the surfaces $Y=SL_2(k)/T$ and $X=SL_2(k)/N$\nwhere $T$ is the one-dimensional torus and $N$ is its normalizer. We show that\nthe minimal presentation of $X$ has dimension 5, the embedding dimension of $X$\nis 4, and there does not exist a closed $SL_2$-equivariant embedding of $X$ in\n$A_k^4$. Thus, the $SL_2$-action on $X$ is absolutely nonextendable to $A_k^4$.\nWe give two other examples of surfaces with absolutely nonextendable group\nactions. In addition, $X$ is noncancelative, that is, there exists a surface\n$Z$ such that $X\\times A_k^1\\cong_k Z\\times A_k^1$ and $X\\not\\cong_kZ$.\nFinally, we settle the long-standing open question of whether there exist\ninequivalent closed embeddings of $Y$ in $A_k^3$ by constructing inequivalent\nembeddings.","main_category":"math.AG","categories":"math.AG","published":"2025-04-30T14:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.21725v1","title":"New {\\em ab initio} constrained extended Skyrme equations of state for\n  simulations of neutron stars, supernovae and binary mergers: I. Subsaturation\n  density domain","summary":"In numerical simulations of core-collapse supernova and binary neutron stars\nmergers information about the energetics and composition of matter is\nimplemented via external tables covering the huge ranges of thermodynamic\nconditions explored during the astrophysical evolution. More than 120 general\npurpose equation of state tables have been contributed so far. Not all of them\ncomply with current constraints from theoretical and experimental nuclear\nphysics and astrophysical observations of neutron stars. Systematic\ninvestigations of the role that dense matter properties play in the evolution\nof these astrophysical phenomena require that more equation of state tables are\nprovided. We build a set of general purpose equation of state tables. At zero\ntemperature, they comply with all currently accepted constraints, including ab\ninitio chiral effective field theory calculations of pure neutron and symmetric\nnuclear matter. This set is designed to explore a wide variety of the behaviors\nof the effective masses as functions of density, which is reflected into a wide\nrange of thermal behaviors. We employ Brussels extended Skyrme interactions\ngenerated by means of Bayesian inference techniques. An extended nuclear\nstatistical equilibrium model is developed for modeling sub-saturated\ninhomogeneous nuclear matter. We study the properties of sub-saturated\ninhomogeneous nuclear matter over wide ranges of density, temperature and\nproton fraction. We analyze the mechanisms of transition to homogeneous matter\nand estimate the transition density. Our key results include the presence of a\nthink $^{14}$He layer in the inner crusts of (neo-)neutron stars, significant\nabundance of other exotic isotopes of H and He in warm and neutron rich matter\nand a detailed study of the thermodynamic stability of cold stellar matter. The\nequation of state tables will be publicly available in the Compose online\ndatabase.","main_category":"nucl-th","categories":"nucl-th,astro-ph.HE","published":"2025-04-30T15:11:02Z"}
{"aid":"http://arxiv.org/abs/2504.21738v1","title":"LangWBC: Language-directed Humanoid Whole-Body Control via End-to-end\n  Learning","summary":"General-purpose humanoid robots are expected to interact intuitively with\nhumans, enabling seamless integration into daily life. Natural language\nprovides the most accessible medium for this purpose. However, translating\nlanguage into humanoid whole-body motion remains a significant challenge,\nprimarily due to the gap between linguistic understanding and physical actions.\nIn this work, we present an end-to-end, language-directed policy for real-world\nhumanoid whole-body control. Our approach combines reinforcement learning with\npolicy distillation, allowing a single neural network to interpret language\ncommands and execute corresponding physical actions directly. To enhance motion\ndiversity and compositionality, we incorporate a Conditional Variational\nAutoencoder (CVAE) structure. The resulting policy achieves agile and versatile\nwhole-body behaviors conditioned on language inputs, with smooth transitions\nbetween various motions, enabling adaptation to linguistic variations and the\nemergence of novel motions. We validate the efficacy and generalizability of\nour method through extensive simulations and real-world experiments,\ndemonstrating robust whole-body control. Please see our website at\nLangWBC.github.io for more information.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T15:37:23Z"}
{"aid":"http://arxiv.org/abs/2504.21750v1","title":"Online Knapsack Problems with Estimates","summary":"Imagine you are a computer scientist who enjoys attending conferences or\nworkshops within the year. Sadly, your travel budget is limited, so you must\nselect a subset of events you can travel to.\n  When you are aware of all possible events and their costs at the beginning of\nthe year, you can select the subset of the possible events that maximizes your\nhappiness and is within your budget.\n  On the other hand, if you are blind about the options, you will likely have a\nhard time when trying to decide if you want to register somewhere or not, and\nwill likely regret decisions you made in the future.\n  These scenarios can be modeled by knapsack variants, either by an offline or\nan online problem. However, both scenarios are somewhat unrealistic:\n  Usually, you will not know the exact costs of each workshop at the beginning\nof the year. The online version, however, is too pessimistic, as you might\nalready know which options there are and how much they cost roughly. At some\npoint, you have to decide whether to register for some workshop, but then you\nare aware of the conference fee and the flight and hotel prices.\n  We model this problem within the setting of online knapsack problems with\nestimates: in the beginning, you receive a list of potential items with their\nestimated size as well as the accuracy of the estimates. Then, the items are\nrevealed one by one in an online fashion with their actual size, and you need\nto decide whether to take one or not. In this article, we show a best-possible\nalgorithm for each estimate accuracy $\\delta$ (i.e., when each actual item size\ncan deviate by $\\pm \\delta$ from the announced size) for both the simple\nknapsack and the simple knapsack with removability.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-30T15:42:43Z"}
{"aid":"http://arxiv.org/abs/2504.21762v1","title":"Spectra of Lorentzian quasi-Fuchsian manifolds","summary":"A three-dimensional quasi-Fuchsian Lorentzian manifold $M$ is a globally\nhyperbolic spacetime diffeomorphic to $\\Sigma\\times (-1,1)$ for a closed\norientable surface $\\Sigma$ of genus $\\geq 2$. It is the quotient\n$M=\\Gamma\\backslash \\Omega_\\Gamma$ of an open set $\\Omega_\\Gamma\\subset {\\rm\nAdS}_3$ by a discrete group $\\Gamma$ of isometries of ${\\rm AdS}_3$ which is a\nparticular example of an Anosov representation of $\\pi_1(\\Sigma)$. We first\nshow that the spacelike geodesic flow of $M$ is Axiom A, has a discrete Ruelle\nresonance spectrum with associated (co-)resonant states, and that the\nPoincar\\'e series for $\\Gamma$ extend meromorphically to $\\mathbb{C}$. This is\nthen used to prove that there is a natural notion of resolvent of the\npseudo-Riemannian Laplacian $\\Box$ of $M$, which is meromorphic on $\\mathbb{C}$\nwith poles of finite rank, defining a notion of quantum resonances and quantum\nresonant states related to the Ruelle resonances and (co-)resonant states by a\nquantum-classical correspondence. This initiates the spectral study of convex\nco-compact pseudo-Riemannian locally symmetric spaces.","main_category":"math.DG","categories":"math.DG,math.DS,math.SP","published":"2025-04-30T16:02:16Z"}
{"aid":"http://arxiv.org/abs/2504.21765v1","title":"Evaluation of In Vivo Subject-Specific Mechanical Modeling of the Optic\n  Nerve Head for Robust Assessment of Ocular Mechanics","summary":"To establish the tissue regions necessary to accurately represent the\nmechanics of the optic nerve head (ONH), imaging data of the ONH from 2 healthy\nsubjects were used to create in vivo subject-specific eye mechanical models\nconsidering distinct properties for all major ocular tissues. Tests were\nperformed to evaluate the effect of the material properties and the inclusion\nof these tissues on the mechanics of the lamina cribrosa (LC), retina, and\noptic nerve. Then, the LC mechanical response due to variations in intraocular\nand intracranial pressures was evaluated to validate the modeling approach. The\nsclera stiffness has the largest impact on the mechanics of the LC, retina, and\noptic nerve, while Bruchs membrane has a negligible effect on these tissues\nresponse. The validation tests showed increased LC strain with increased\npressure and highest strains in the inferior and temporal subregion, as seen in\nliterature studies. Consequently, accurate ONH mechanical representation can be\nobtained by only including those tissue regions identified as necessary.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.bio-ph,physics.comp-ph","published":"2025-04-30T16:05:50Z"}
{"aid":"http://arxiv.org/abs/2504.21773v1","title":"MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced\n  Knowledge Boundary Awareness","summary":"With the widespread application of large language models (LLMs), the issue of\ngenerating non-existing facts, known as hallucination, has garnered increasing\nattention. Previous research in enhancing LLM confidence estimation mainly\nfocuses on the single problem setting. However, LLM awareness of its internal\nparameterized knowledge boundary under the more challenging multi-problem\nsetting, which requires answering multiple problems accurately simultaneously,\nremains underexplored. To bridge this gap, we introduce a novel method,\nMultiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates\nthe learning of answer prediction and confidence estimation during fine-tuning\non instruction data. Extensive experiments demonstrate that our method\noutperforms baselines by up to 25% in average precision.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-30T16:17:53Z"}
{"aid":"http://arxiv.org/abs/2504.21781v1","title":"Message Optimality and Message-Time Trade-offs for APSP and Beyond","summary":"Round complexity is an extensively studied metric of distributed algorithms.\nIn contrast, our knowledge of the \\emph{message complexity} of distributed\ncomputing problems and its relationship (if any) with round complexity is still\nquite limited. To illustrate, for many fundamental distributed graph\noptimization problems such as (exact) diameter computation, All-Pairs Shortest\nPaths (APSP), Maximum Matching etc., while (near) round-optimal algorithms are\nknown, message-optimal algorithms are hitherto unknown. More importantly, the\nexisting round-optimal algorithms are not message-optimal. This raises two\nimportant questions: (1) Can we design message-optimal algorithms for these\nproblems? (2) Can we give message-time tradeoffs for these problems in case the\nmessage-optimal algorithms are not round-optimal?\n  In this work, we focus on a fundamental graph optimization problem, \\emph{All\nPairs Shortest Path (APSP)}, whose message complexity is still unresolved. We\npresent two main results in the CONGEST model: (1) We give a message-optimal\n(up to logarithmic factors) algorithm that solves weighted APSP, using\n$\\tilde{O}(n^2)$ messages. This algorithm takes $\\tilde{O}(n^2)$ rounds. (2)\nFor any $0 \\leq \\varepsilon \\le 1$, we show how to solve unweighted APSP in\n$\\tilde{O}(n^{2-\\varepsilon })$ rounds and $\\tilde{O}(n^{2+\\varepsilon })$\nmessages. At one end of this smooth trade-off, we obtain a (nearly)\nmessage-optimal algorithm using $\\tilde{O}(n^2)$ messages (for $\\varepsilon =\n0$), whereas at the other end we get a (nearly) round-optimal algorithm using\n$\\tilde{O}(n)$ rounds (for $\\varepsilon = 1$). This is the first such\nmessage-time trade-off result known.","main_category":"cs.DC","categories":"cs.DC,cs.DS","published":"2025-04-30T16:34:53Z"}
{"aid":"http://arxiv.org/abs/2504.21786v1","title":"Improved Lanczos Algorithm using Matrix Product States","summary":"We improve the Lanczos algorithm using the matrix product state\nrepresentation proposed in Phys. Rev. B 85, 205119 (2012). As an alternative to\nthe density matrix renormalization group (DMRG), the Lanczos algorithm avoids\nlocal minima and can directly find multiple low-lying eigenstates. However, its\nperformance and accuracy are affected by the truncation required to maintain\nthe efficiency of the tensor network representation. In this work, we enhance\nits convergence by restarting with multiple states. We benchmark our method on\none-dimensional instances of the Fermi-Hubbard model with 8 sites and the\nHeisenberg model with 16 sites in an external field, using numerical\nexperiments targeting the first five lowest eigenstates. Across these tests,\nour approach obtains accuracy improvements of three to seven orders of\nmagnitude. Finally, we extend the Heisenberg model simulation to a lattice with\n30 sites to highlight its scalability.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,physics.comp-ph,quant-ph","published":"2025-04-30T16:45:25Z"}
{"aid":"http://arxiv.org/abs/2504.21790v1","title":"Discrete series for the graded Hecke algebra of type $H_{4}$","summary":"This article confirms the prediction that the set of discrete series central\ncharacter for the graded (affine) Hecke algebra of type $H_4$ coincides with\nthe set of the Heckman-Opdam central characters. Combining with previous cases\nof Kazhdan-Lusztig, Kriloff, Kriloff-Ram, Opdam-Solleveld, Ciubotaru-Opdam,\nthis completes the classification of discrete series for all the graded Hecke\nalgebras of positive parameters. Main tools include construction of calibrated\nmodules and construction of certain minimally induced modules for discrete\nseries. We also study the anti-sphericiity and Ext-branching laws for some\ndiscrete series.","main_category":"math.RT","categories":"math.RT,math.NT","published":"2025-04-30T16:50:01Z"}
{"aid":"http://arxiv.org/abs/2504.21801v1","title":"DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via\n  Reinforcement Learning for Subgoal Decomposition","summary":"We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-30T16:57:48Z"}
{"aid":"http://arxiv.org/abs/2504.21804v1","title":"Indian participation in the construction of the Facility for Antiproton\n  and Ion Research (FAIR) at Darmstadt, Germany","summary":"India is a founder-member country to participate in the construction of the\ninternational multipurpose accelerator facility called the Facility for\nAntiproton and Ion Research (FAIR) at Darmstadt, Germany. Bose Institute,\nKolkata, has been designated as the Indian shareholder of the FAIR GmbH and the\nnodal Indian Institution for co-ordinating Indian participation in the FAIR\nprogramme.\n  Indian participation in FAIR is twofold. Firstly, the advancement of\nknowledge in nuclear astrophysics and reaction, high-energy nuclear physics,\natomic \\& plasma physics and application through the participation of Indian\nresearchers, engineers and students in various experiments planned at FAIR. In\naddition to this, India is also contributing high-tech accelerator equipment as\nin-kind contribution to FAIR.\n  Our active involvement include the designing, manufacturing and supply of\nin-kind accelerator items e.g. power converters, vacuum chamber, beam catchers,\nIT diagnostic cables among them and coordinating the participation of Indian\nscientists in the FAIR experiments including detector development, physics\nsimulation, experimental data analysis.\n  Indian researchers have been participating in the two major experiments at\nFAIR, i.e. Nuclear Structure, Astrophysics and Reactions (NUSTAR) and\nCompressed Baryonic Matter (CBM) and in particular Bose Institute is involved\nin the CBM experiment, to study and characterize the matter created in the\nrelativistic nucleus-nucleus collisions at high net baryon density and\nrelatively moderate temperature.\n  In this article a brief overview on the FAIR facility, the experiments at\nFAIR and Indian participation are presented.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-30T17:03:11Z"}
{"aid":"http://arxiv.org/abs/2504.21818v1","title":"Topology, Kinetics and Inheritance in Clonal Colonies of Bone Marrow\n  Stromal Cells","summary":"Bone marrow stromal cells (BMSCs), whose populations contain multipotent\nskeletal stem cells with relevant therapeutic applications, are known to\nproduce very heterogeneous colonies upon in vitro culture, a trait that may\nseverely hinder the clinical usefulness of BMSC-based therapies. Therefore,\nreaching a better insight on the nature of such heterogeneity, as well as on\nthe factors determining it, is important. Here, by using time-lapse microscopy,\nwe study the structure of N=28 human BMSC colonies from six donors, each colony\nderived from a single cell, and trace their lineage trees up to the seventh\ngeneration. We confirm the presence of very significant inter-colony and\nintra-colony heterogeneities, both in the topology of the lineages and in the\nreplicative kinetics of the colonies. We also find that topology and kinetics\nare strongly correlated, consistent with the existence of regulating factors\nlinking the sub-population of inactive cells, which uniquely determine a\nlineage's topology, and that of active cells, which are the sole responsible\nfor the proliferation rate of the colony. Finally, we submit each colony to an\nentropy-based inheritance test, which measures the degree of non-random\nclustering of inactive cells within the same branches of the lineage, and find\na clear signature of hereditary transmission of the probability of emergence of\ninactive cells in the largest majority of the experimental lineages.","main_category":"q-bio.CB","categories":"q-bio.CB,cond-mat.stat-mech,physics.bio-ph","published":"2025-04-30T17:24:21Z"}
{"aid":"http://arxiv.org/abs/2504.21826v1","title":"An Underwater, Fault-Tolerant, Laser-Aided Robotic Multi-Modal Dense\n  SLAM System for Continuous Underwater In-Situ Observation","summary":"Existing underwater SLAM systems are difficult to work effectively in\ntexture-sparse and geometrically degraded underwater environments, resulting in\nintermittent tracking and sparse mapping. Therefore, we present Water-DSLAM, a\nnovel laser-aided multi-sensor fusion system that can achieve uninterrupted,\nfault-tolerant dense SLAM capable of continuous in-situ observation in diverse\ncomplex underwater scenarios through three key innovations: Firstly, we develop\nWater-Scanner, a multi-sensor fusion robotic platform featuring a self-designed\nUnderwater Binocular Structured Light (UBSL) module that enables high-precision\n3D perception. Secondly, we propose a fault-tolerant triple-subsystem\narchitecture combining: 1) DP-INS (DVL- and Pressure-aided Inertial Navigation\nSystem): fusing inertial measurement unit, doppler velocity log, and pressure\nsensor based Error-State Kalman Filter (ESKF) to provide high-frequency\nabsolute odometry 2) Water-UBSL: a novel Iterated ESKF (IESKF)-based tight\ncoupling between UBSL and DP-INS to mitigate UBSL's degeneration issues 3)\nWater-Stereo: a fusion of DP-INS and stereo camera for accurate initialization\nand tracking. Thirdly, we introduce a multi-modal factor graph back-end that\ndynamically fuses heterogeneous sensor data. The proposed multi-sensor factor\ngraph maintenance strategy efficiently addresses issues caused by asynchronous\nsensor frequencies and partial data loss. Experimental results demonstrate\nWater-DSLAM achieves superior robustness (0.039 m trajectory RMSE and 100\\%\ncontinuity ratio during partial sensor dropout) and dense mapping (6922.4\npoints/m^3 in 750 m^3 water volume, approximately 10 times denser than existing\nmethods) in various challenging environments, including pools, dark underwater\nscenes, 16-meter-deep sinkholes, and field rivers. Our project is available at\nhttps://water-scanner.github.io/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T17:30:13Z"}
{"aid":"http://arxiv.org/abs/2504.21839v1","title":"Comment on 'Anomalies in the Electronic Stopping of Slow Antiprotons in\n  LiF', arXiv:2501.14381","summary":"This work contains detailed discussions on the contents of Phys. Rev. Lett.\n134, 076401 (2025), in the following denoted PRL134. In this comment, we\nrevisit and elaborate on the Adiabatic Ionization Model (AIM) for the energy\nloss of antiparticles in matter, with particular reference to its theoretical\nfoundation as established previously. The AIM framework plays a central role in\ndescribing the ionization dynamics in the low-velocity regime considered by the\nauthors of PRL134. Calculated AIM results for the energy loss of antiprotons in\nLiF crystals are compared to experimental data and different other models,\npointing to severe problems of the PRL134 results.\n  Beyond this specific comparative theoretical investigation, we critically\nexamine several statements and assumptions made in PRL134. Certain claims\npresented therein appear to be inconsistent with established theoretical\nprinciples or are insufficiently justified by the data and arguments provided.\nAs such, we believe that further clarification, and in some cases, a more\nrigorous justification, is necessary to substantiate those points.","main_category":"cond-mat.other","categories":"cond-mat.other,physics.atom-ph","published":"2025-04-30T17:49:37Z"}
{"aid":"http://arxiv.org/abs/2505.00248v1","title":"Revisiting the physical properties of (LaS)1+d(NbS2) misfit-layered\n  compounds","summary":"Electrical transport in polycrystalline and single-crystalline (LaS)1+d(NbS2)\nmisfit-layered compounds was measured. Polycrystalline samples were synthesized\nusing S raw materials of different purities (2N or 6N), and single-crystalline\nsamples were grown using two types of transport agents (2NH4Cl+PbCl2 or NH4Cl)\nvia the chemical vapor transport method. The temperature dependence on\nresistivity dropped at 1.3-2.0 K for some of the samples, which might be\naffected by the unknown impurity. (LaS)1+d(NbS2) misfit-layered compounds for\nthe main phase of those obtained samples exhibited no superconductivity above\n0.2 K by the resistivity measurement.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-05-01T02:01:38Z"}
{"aid":"http://arxiv.org/abs/2505.00266v1","title":"Tripartite hybrid quantum systems: Skyrmion-mediated quantum\n  interactions between single NV centers and superconducting qubits","summary":"Nitrogen-vacancy (NV) centers in diamond and superconducting qubits are two\npromising solid-state quantum systems for quantum science and technology, but\nthe realization of controlled interfaces between individual solid-state spins\nand superconducting qubits remains fundamentally challenging. Here, we propose\nand analyze a hybrid quantum system consisting of a magnetic skyrmion, an NV\ncenter, and a superconducting qubit, where the solid-state qubits are both\npositioned in proximity to the skyrmion structure in a thin magnetic disk. We\nshow that it is experimentally feasible to achieve strong magnetic (coherent or\ndissipative) coupling between the NV center and the superconducting qubit by\nusing the \\textit{quantized gyration mode of the skyrmion} as an intermediary.\nThis allows coherent information transfer and nonreciprocal responses between\nthe NV center and the superconducting qubit at the single quantum level with\nhigh controllability. The proposed platform provides a scalable pathway for\nimplementing quantum protocols that synergistically exploit the complementary\nadvantages of spin-based quantum memories, microwave-frequency superconducting\ncircuits, and topologically protected magnetic excitations.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall","published":"2025-05-01T03:24:42Z"}
{"aid":"http://arxiv.org/abs/2505.00269v1","title":"Weighted-Scenario Optimisation for the Chance Constrained Travelling\n  Thief Problem","summary":"The chance constrained travelling thief problem (chance constrained TTP) has\nbeen introduced as a stochastic variation of the classical travelling thief\nproblem (TTP) in an attempt to embody the effect of uncertainty in the problem\ndefinition. In this work, we characterise the chance constrained TTP using a\nlimited number of weighted scenarios. Each scenario represents a similar TTP\ninstance, differing slightly in the weight profile of the items and associated\nwith a certain probability of occurrence. Collectively, the weighted scenarios\nrepresent a relaxed form of a stochastic TTP instance where the objective is to\nmaximise the expected benefit while satisfying the knapsack constraint with a\nlarger probability. We incorporate a set of evolutionary algorithms and\nheuristic procedures developed for the classical TTP, and formulate adaptations\nthat apply to the weighted scenario-based representation of the problem. The\nanalysis focuses on the performance of the algorithms on different settings and\nexamines the impact of uncertainty on the quality of the solutions.","main_category":"cs.NE","categories":"cs.NE","published":"2025-05-01T03:30:21Z"}
{"aid":"http://arxiv.org/abs/2505.00287v1","title":"Avatar Communication Provides More Efficient Online Social Support Than\n  Text Communication","summary":"Online communication via avatars provides a richer online social experience\nthan text communication. This reinforces the importance of online social\nsupport. Online social support is effective for people who lack social\nresources because of the anonymity of online communities. We aimed to\nunderstand online social support via avatars and their social relationships to\nprovide better social support to avatar users. Therefore, we administered a\nquestionnaire to three avatar communication service users (Second Life, ZEPETO,\nand Pigg Party) and three text communication service users (Facebook, X, and\nInstagram) (N=8,947). There was no duplication of users for each service. By\ncomparing avatar and text communication users, we examined the amount of online\nsocial support, stability of online relationships, and the relationships\nbetween online social support and offline social resources (e.g., offline\nsocial support). We observed that avatar communication service users received\nmore online social support, had more stable relationships, and had fewer\noffline social resources than text communication service users. However, the\npositive association between online and offline social support for avatar\ncommunication users was more substantial than for text communication users.\nThese findings highlight the significance of realistic online communication\nexperiences through avatars, including nonverbal and real-time interactions\nwith co-presence. The findings also highlighted avatar communication service\nusers' problems in the physical world, such as the lack of offline social\nresources. This study suggests that enhancing online social support through\navatars can address these issues. This could help resolve social resource\nproblems, both online and offline in future metaverse societies.","main_category":"cs.SI","categories":"cs.SI","published":"2025-05-01T04:21:50Z"}
{"aid":"http://arxiv.org/abs/2505.00291v1","title":"Repetition Makes Perfect: Recurrent Sum-GNNs Match Message Passing Limit","summary":"We provide first tight bounds for the expressivity of Recurrent Graph Neural\nNetworks (recurrent GNNs) with finite-precision parameters. We prove that\nrecurrent GNNs, with sum aggregation and ReLU activation, can emulate any graph\nalgorithm that respects the natural message-passing invariance induced by the\ncolor refinement (or Weisfeiler-Leman) algorithm. While it is well known that\nthe expressive power of GNNs is limited by this invariance [Morris et al., AAAI\n2019; Xu et al., ICLR 2019], we establish that recurrent GNNs can actually\nreach this limit. This is in contrast to non-recurrent GNNs, which have the\npower of Weisfeiler-Leman only in a very weak, \"non-uniform\", sense where every\ngraph size requires a different GNN model to compute with. The emulation we\nconstruct introduces only a polynomial overhead in both time and space.\n  Furthermore, we show that by incorporating random initialization, recurrent\nGNNs can emulate all graph algorithms, implying in particular that any graph\nalgorithm with polynomial-time complexity can be emulated by a recurrent GNN\nwith random initialization, running in polynomial time.","main_category":"cs.LG","categories":"cs.LG,I.2.6","published":"2025-05-01T04:27:35Z"}
{"aid":"http://arxiv.org/abs/2505.00296v1","title":"The Complexity of Minimum-Envy House Allocation Over Graphs","summary":"In this paper, we study a generalization of the House Allocation problem. In\nour problem, agents are represented by vertices of a graph $\\GG_{\\mathcal{A}} =\n(\\AA, E_\\AA)$, and each agent $a \\in \\AA$ is associated with a set of preferred\nhouses $\\PP_a \\subseteq \\HH$, where $\\AA$ is the set of agents and $\\HH$ is the\nset of houses. A house allocation is an injective function $\\phi: \\AA\n\\rightarrow \\HH$, and an agent $a$ envies a neighbour $a' \\in N_{\\GG_\\AA}(a)$\nunder $\\phi$ if $\\phi(a) \\notin \\PP_a$ and $\\phi(a') \\in \\PP_a$. We study two\nnatural objectives: the first problem called \\ohaa, aims to compute an\nallocation that minimizes the number of envious agents; the second problem\ncalled \\ohaah aims to maximize, among all minimum-envy allocations, the number\nof agents who are assigned a house they prefer. These two objectives capture\ncomplementary notions of fairness and individual satisfaction.\n  We design polynomial time algorithms for both problems for the variant when\neach agent prefers exactly one house. On the other hand, when the list of\npreferred houses for each agent has size at most $2$ then we show that both\nproblems are \\NP-hard even when the agent graph $\\GG_\\AA$ is a complete\nbipartite graph. We also show that both problems are \\NP-hard even when the\nnumber $|\\mathcal H|$ of houses is equal to the number $|\\mathcal A|$ of\nagents. This is in contrast to the classical {\\sc House Allocation} problem,\nwhere the problem is polynomial time solvable when $|\\mathcal H| = |\\mathcal\nA|$. The two problems are also \\NP-hard when the agent graph has a small vertex\ncover. On the positive side, we design exact algorithms that exploit certain\nstructural properties of $\\GG_{\\AA}$ such as sparsity, existence of balanced\nseparators or existence of small-sized vertex covers, and perform better than\nthe naive brute-force algorithm.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-05-01T04:38:09Z"}
{"aid":"http://arxiv.org/abs/2505.00297v1","title":"A Low-Noise and High-Stability DC Source for Superconducting Quantum\n  Circuits","summary":"With the rapid scaling of superconducting quantum processors, electronic\ncontrol systems relying on commercial off-the-shelf instruments face critical\nbottlenecks in signal density, power consumption, and crosstalk mitigation.\nHere we present a custom dual-channel direct current (DC) source module\n(QPower) dedicated for large-scale superconducting quantum processors. The\nmodule delivers a voltage range of $\\pm$7 V with 200 mA maximum current per\nchannel, while achieving the following key performance benchmarks: noise\nspectral density of 20 nV/$\\sqrt{\\mathrm{Hz}}$ at 10 kHz, output ripple $<$500\n$\\mu$V$_{\\mathrm{pp}}$ within 20 MHz bandwidth, and long-term voltage drift\n$<$5 $\\mu$V$_{\\mathrm{pp}}$ over 12 hours. Integrated into the control\nelectronics of a 66-qubit quantum processor, QPower enables qubit coherence\ntimes of $T_1 = 87.6~\\mu\\mathrm{s}$ and Ramsey $T_2 = 5.1~\\mu\\mathrm{s}$, with\nqubit resonance frequency drift constrained to $\\pm$40 kHz during 12-hour\noperation. This modular design is compact in size and efficient in energy\nconsumption, providing a scalable DC source solution for intermediate-scale\nquantum processors with stringent noise and stability requirements, with\npotential extensions to other quantum hardware platforms and precision\nmeasurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T04:39:00Z"}
{"aid":"http://arxiv.org/abs/2505.00302v1","title":"Temporal Attention Evolutional Graph Convolutional Network for\n  Multivariate Time Series Forecasting","summary":"Multivariate time series forecasting enables the prediction of future states\nby leveraging historical data, thereby facilitating decision-making processes.\nEach data node in a multivariate time series encompasses a sequence of multiple\ndimensions. These nodes exhibit interdependent relationships, forming a graph\nstructure. While existing prediction methods often assume a fixed graph\nstructure, many real-world scenarios involve dynamic graph structures.\nMoreover, interactions among time series observed at different time scales vary\nsignificantly. To enhance prediction accuracy by capturing precise temporal and\nspatial features, this paper introduces the Temporal Attention Evolutional\nGraph Convolutional Network (TAEGCN). This novel method not only integrates\ncausal temporal convolution and a multi-head self-attention mechanism to learn\ntemporal features of nodes, but also construct the dynamic graph structure\nbased on these temporal features to keep the consistency of the changing in\nspatial feature with temporal series. TAEGCN adeptly captures temporal causal\nrelationships and hidden spatial dependencies within the data. Furthermore,\nTAEGCN incorporates a unified neural network that seamlessly integrates these\ncomponents to generate final predictions. Experimental results conducted on two\npublic transportation network datasets, METR-LA and PEMS-BAY, demonstrate the\nsuperior performance of the proposed model.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T04:50:00Z"}
{"aid":"http://arxiv.org/abs/2505.00306v1","title":"J-PARSE: Jacobian-based Projection Algorithm for Resolving Singularities\n  Effectively in Inverse Kinematic Control of Serial Manipulators","summary":"J-PARSE is a method for smooth first-order inverse kinematic control of a\nserial manipulator near kinematic singularities. The commanded end-effector\nvelocity is interpreted component-wise, according to the available mobility in\neach dimension of the task space. First, a substitute \"Safety\" Jacobian matrix\nis created, keeping the aspect ratio of the manipulability ellipsoid above a\nthreshold value. The desired motion is then projected onto non-singular and\nsingular directions, and the latter projection scaled down by a factor informed\nby the threshold value. A right-inverse of the non-singular Safety Jacobian is\napplied to the modified command. In the absence of joint limits and collisions,\nthis ensures smooth transition into and out of low-rank poses, guaranteeing\nasymptotic stability for target poses within the workspace, and stability for\nthose outside. Velocity control with J-PARSE is benchmarked against the\nLeast-Squares and Damped Least-Squares inversions of the Jacobian, and shows\nhigh accuracy in reaching and leaving singular target poses. By expanding the\navailable workspace of manipulators, the method finds applications in servoing,\nteleoperation, and learning.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T04:58:50Z"}
{"aid":"http://arxiv.org/abs/2505.00308v1","title":"AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented\n  Contour Quality","summary":"Purpose: This study presents a Deep Learning (DL)-based quality assessment\n(QA) approach for evaluating auto-generated contours (auto-contours) in\nradiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging\nBayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds,\nthe method enables confident QA predictions without relying on ground truth\ncontours or extensive manual labeling. Methods: We developed a BOC model to\nclassify auto-contour quality and quantify prediction uncertainty. A\ncalibration step was used to optimize uncertainty thresholds that meet clinical\naccuracy needs. The method was validated under three data scenarios: no manual\nlabels, limited labels, and extensive labels. For rectum contours in prostate\ncancer, we applied geometric surrogate labels when manual labels were absent,\ntransfer learning when limited, and direct supervision when ample labels were\navailable. Results: The BOC model delivered robust performance across all\nscenarios. Fine-tuning with just 30 manual labels and calibrating with 34\nsubjects yielded over 90% accuracy on test data. Using the calibrated\nthreshold, over 93% of the auto-contours' qualities were accurately predicted\nin over 98% of cases, reducing unnecessary manual reviews and highlighting\ncases needing correction. Conclusion: The proposed QA model enhances contouring\nefficiency in OART by reducing manual workload and enabling fast, informed\nclinical decisions. Through uncertainty quantification, it ensures safer, more\nreliable radiotherapy workflows.","main_category":"cs.CV","categories":"cs.CV,cs.AI,stat.AP","published":"2025-05-01T05:05:35Z"}
{"aid":"http://arxiv.org/abs/2505.00309v1","title":"A Survey on the Topology of Fractal Squares","summary":"We consider a special type of self-similar sets, called fractal squares, and\ngive a brief review on recent results and unsolved issues with an emphasis on\ntheir topological properties.","main_category":"math.GN","categories":"math.GN","published":"2025-05-01T05:11:12Z"}
{"aid":"http://arxiv.org/abs/2505.00327v1","title":"Aganagic's invariant is Khovanov homology","summary":"On the Coulomb branch of a quiver gauge theory, there is a family of\nfunctions parameterized by choices of points in the punctured plane. Aganagic\nhas predicted that Khovanov homology can be recovered from the braid group\naction on Fukaya-Seidel categories arising from monodromy in said space of\npotentials. These categories have since been rigorously studied, and shown to\ncontain a certain (combinatorially defined) category on which Webster had\npreviously constructed a (combinatorially defined) braid group action from\nwhich the Khovanov homology can be recovered.\n  Here we show, by a direct calculation, that the aforementioned containment\nintertwines said combinatorially defined braid group action with the braid\ngroup action arising naturally from monodromy. This provides a mathematical\nverification that Aganagic's proposal gives a symplectic construction of\nKhovanov homology -- with both gradings, and over the integers.","main_category":"math.SG","categories":"math.SG,hep-th,math.GT","published":"2025-05-01T05:55:28Z"}
{"aid":"http://arxiv.org/abs/2505.00342v1","title":"LLMPrism: Black-box Performance Diagnosis for Production LLM Training\n  Platforms","summary":"Large Language Models (LLMs) have brought about revolutionary changes in\ndiverse fields, rendering LLM training of utmost importance for modern\nenterprises. To meet this demand, multi-tenant large-scale LLM training\nplatforms have been built to offer LLM training services. Nevertheless, due to\nthe complexity and synchronous nature of LLM training process, performance\nissues occur frequently and can result in substantial resource wastage. The\nlimited visibility from the perspective of platform providers impedes existing\nprofiling methods and poses challenges to the monitoring and diagnosis of the\nperformance of LLM training jobs. For the first time, this paper proposes the\nutilization of underlying network flow data to reconstruct the training\ntimelines of jobs based on the distinct characteristics in the LLM training\nprocedure. We design LLMPrism, the first black-box performance diagnosis system\nfor LLM training platforms. By progressively recognizing LLM training jobs,\nidentifying their parallelism strategies, and reconstructing the training\ntimelines, LLMPrism achieves non-intrusive, lightweight, and continuous\nmonitoring of LLM training systems. Leveraging this monitoring capability, it\nfurther effectively diagnoses potential performance issues. Since Oct. 2024,\nLLMPrism has been deployed on our large-scale production Platform-X, in which\nthe evaluations and deployment experiences demonstrate that LLMPrism can\nachieve accurate timeline reconstruction with an error within 0.3% and\neffectively diagnose various performance issues.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-01T06:38:52Z"}
{"aid":"http://arxiv.org/abs/2505.00346v1","title":"Hilbert's Theorem 90, periodicity, and roots of Artin-Schreier\n  polynomials","summary":"Let $E/F$ be a cyclic field extension of degree $n$, and let $\\sigma$\ngenerate the group Gal$(E/F)$. If Tr${}^E_F(y)=\\sum_{i=0}^{n-1}\\sigma^i y=0$,\nthen the additive form of Hilbert's Theorem 90 asserts that $y=\\sigma x-x$ for\nsome $x\\in E$. Suppose that $E$ has characteristic $p$. We prove that $x$ gives\nrise to a periodic sequence $x_0,x_1,\\dots$ which has period $pn_p$, where\n$n_p$ is the largest $p$-power that divides $n$. As an application, we find\nclosed-form expressions for the roots of Artin-Schreier polynomials $t^p-t-y$.\nLet $y$ lie in the finite field $F_{p^n}$ of order $p^n$. The Artin-Schreier\npolynomial $t^p-t-y\\in F_{p^n}[t]$ is reducible precisely when\n$\\sum_{i=0}^{n-1}y^{p^i}=0$. In this case, $t^p-t-y=\\prod_{k=0}^{p-1}(t-x-k)$\nwhere $x=\\sum_{i=0}^{n-1}\\sum_{j=0}^{i-1}z^{p^j}y^{p^i}$ for some $z\\in\nF_{p^e}$ and $e=n_p$. The sequence\n$\\left(\\sum_{j=0}^{i-1}z^{p^j}\\right)_{i\\ge0}$ is periodic with period $pe$,\nand if $e$ is small, then we give explicit $z$.","main_category":"math.NT","categories":"math.NT,math.AC,math.GR","published":"2025-05-01T06:47:38Z"}
{"aid":"http://arxiv.org/abs/2505.00360v1","title":"Interior curvature estimate for curvature quotient equations on convex\n  hypersurfaces","summary":"We study interior curvature estimates for convex graphs which satisfy the\nquotient equation $\\frac{\\sigma_{n}}{\\sigma_{n-2}}(\\lambda)=f(X)>0$ in this\npaper.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-05-01T07:19:50Z"}
{"aid":"http://arxiv.org/abs/2505.00362v1","title":"Site-Percolation-Driven Ionic Conductivity in Random Substitutional\n  Crystal","summary":"The design of superionic conductors for all-solid-state batteries often faces\na fundamental trade-off between stability and ionic conductivity. Random\nSubstitutional Crystals (RSCs), where atomic species are randomly distributed\nthroughout a crystal lattice, present a promising route to overcome this\ncompetitive relation. Although extensive studies have focused on local ionic\nhopping, the role of mesoscale structural organization in determining\nmacroscopic conductivity remains poorly understood, limiting the rational\ndesign of optimal compositions. Here, we systematically investigate the ionic\nconductivity of NaCl-type RSCs as a function of composition using molecular\ndynamics simulations. We find that ionic conductivity increases sharply once\nthe carrier ion concentration exceeds a critical threshold, without disrupting\nthe underlying crystal structure. Strikingly, this threshold aligns with the\nsite percolation threshold predicted by percolation theory. Our findings\nestablish ion percolation as a universal design principle that reconciles the\ntrade-off between conductivity and stability, offering a simple and broadly\napplicable strategy for the development of robust, high-performance solid\nelectrolytes.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.stat-mech","published":"2025-05-01T07:22:14Z"}
{"aid":"http://arxiv.org/abs/2505.00369v1","title":"Automated segmenta-on of pediatric neuroblastoma on multi-modal MRI:\n  Results of the SPPIN challenge at MICCAI 2023","summary":"Surgery plays an important role within the treatment for neuroblastoma, a\ncommon pediatric cancer. This requires careful planning, often via magnetic\nresonance imaging (MRI)-based anatomical 3D models. However, creating these\nmodels is often time-consuming and user dependent. We organized the Surgical\nPlanning in Pediatric Neuroblastoma (SPPIN) challenge, to stimulate\ndevelopments on this topic, and set a benchmark for fully automatic\nsegmentation of neuroblastoma on multi-model MRI. The challenge started with a\ntraining phase, where teams received 78 sets of MRI scans from 34 patients,\nconsisting of both diagnostic and post-chemotherapy MRI scans. The final test\nphase, consisting of 18 MRI sets from 9 patients, determined the ranking of the\nteams. Ranking was based on the Dice similarity coefficient (Dice score), the\n95th percentile of the Hausdorff distance (HD95) and the volumetric similarity\n(VS). The SPPIN challenge was hosted at MICCAI 2023. The final leaderboard\nconsisted of 9 teams. The highest-ranking team achieved a median Dice score\n0.82, a median HD95 of 7.69 mm and a VS of 0.91, utilizing a large, pretrained\nnetwork called STU-Net. A significant difference for the segmentation results\nbetween diagnostic and post-chemotherapy MRI scans was observed (Dice = 0.89 vs\nDice = 0.59, P = 0.01) for the highest-ranking team. SPPIN is the first medical\nsegmentation challenge in extracranial pediatric oncology. The highest-ranking\nteam used a large pre-trained network, suggesting that pretraining can be of\nuse in small, heterogenous datasets. Although the results of the\nhighest-ranking team were high for most patients, segmentation especially in\nsmall, pre-treated tumors were insufficient. Therefore, more reliable\nsegmentation methods are needed to create clinically applicable models to aid\nsurgical planning in pediatric neuroblastoma.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T07:46:03Z"}
{"aid":"http://arxiv.org/abs/2505.00370v1","title":"On the Schrödingerization method for linear non-unitary dynamics with\n  optimal dependence on matrix queries","summary":"The Schr\\\"odingerization method converts linear partial and ordinary\ndifferential equations with non-unitary dynamics into systems of\nSchr\\\"odinger-type equations with unitary evolution. It does so via the\nso-called warped phase transformation that maps the original equation into a\nSchr\\\"odinger-type equation in one higher dimension\n\\cite{Schrshort,JLY22SchrLong}. We show that by employing a smooth\ninitialization of the warped phase transform \\cite{JLM24SchrBackward},\nSchr\\\"odingerization can in fact achieve optimal scaling in matrix queries.\nThis paper presents the detailed implementation of three smooth initializations\nfor the Schr\\\"odingerization method: (a) the cut-off function, (b) the\nhigher-order polynomial interpolation, and (c) the Fourier transform methods,\nthat achieve optimality for (a) and near-optimality for (b) and (c). A detailed\nanalysis of key parameters affecting time complexity is conducted.","main_category":"math.NA","categories":"math.NA,cs.NA,quant-ph","published":"2025-05-01T07:46:50Z"}
{"aid":"http://arxiv.org/abs/2505.00374v1","title":"Towards Lightweight Hyperspectral Image Super-Resolution with Depthwise\n  Separable Dilated Convolutional Network","summary":"Deep neural networks have demonstrated highly competitive performance in\nsuper-resolution (SR) for natural images by learning mappings from\nlow-resolution (LR) to high-resolution (HR) images. However, hyperspectral\nsuper-resolution remains an ill-posed problem due to the high spectral\ndimensionality of the data and the scarcity of available training samples.\nMoreover, existing methods often rely on large models with a high number of\nparameters or require the fusion with panchromatic or RGB images, both of which\nare often impractical in real-world scenarios. Inspired by the MobileNet\narchitecture, we introduce a lightweight depthwise separable dilated\nconvolutional network (DSDCN) to address the aforementioned challenges.\nSpecifically, our model leverages multiple depthwise separable convolutions,\nsimilar to the MobileNet architecture, and further incorporates a dilated\nconvolution fusion block to make the model more flexible for the extraction of\nboth spatial and spectral features. In addition, we propose a custom loss\nfunction that combines mean squared error (MSE), an L2 norm\nregularization-based constraint, and a spectral angle-based loss, ensuring the\npreservation of both spectral and spatial details. The proposed model achieves\nvery competitive performance on two publicly available hyperspectral datasets,\nmaking it well-suited for hyperspectral image super-resolution tasks. The\nsource codes are publicly available at:\n\\href{https://github.com/Usman1021/lightweight}{https://github.com/Usman1021/lightweight}.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-01T07:57:23Z"}
{"aid":"http://arxiv.org/abs/2505.00396v1","title":"Temporal coupled mode theory for high-$Q$ resonances in dielectric\n  metasurfaces","summary":"In this work, we propose a coupled mode theory for resonant response from\nquasi-guided modes in periodic dielectric metasurfaces. First, we derived a\ngeneric set of constraints imposed onto the parameters of the temporal coupled\nmode theory by energy conservation and time-reversal symmetry in an invariant\nform that allows for asymmetry between the coupling and decoupling\ncoefficients. The proposed approach is applied to the problem of Fano\nresonances induced by isolated quasi-guided modes in the regime of specular\nreflection. Our central result is a generic formula for the line-shape of the\nFano resonance in transmittance for the lossless metasurfaces in the framework\nof 2D electrodynamics. We consider all possible symmetries of the metasurface\nelementary cell and uncover the effects that the symmetry incurs on the profile\nof the Fano resonance induced by an isolated high-$Q$ mode. It is shown that\nthe proposed approach correctly describes the presence of robust reflection and\ntransmission zeros in the spectra as well as the spectral signatures of bound\nstates in the continuum. The approach is applied to uniderictionally guided\nresonant modes in metasurfaces with an asymmetric elementary cell. It is found\nthat the existence of such modes and the transmittance in their spectral\nvicinity are consistent with the theoretical predictions. Furthermore, the\ntheory predicts that a uniderictionally guided resonant mode is dual to a\ncounter-propagating mode of a peculiar type which is coupled with the outgoing\nwave on both sides of the metasurface but, nonetheless, exhibits only a\nsingle-sided coupling with incident waves.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-01T08:32:07Z"}
{"aid":"http://arxiv.org/abs/2505.00401v1","title":"Size-Dependent Tensile Behavior and Dislocation Dynamics in Cu and Ag\n  Nanowires: A Molecular Dynamics Study","summary":"By using molecular dynamics simulations, the research examine how copper and\nsilver nanowires respond to tensile loading in order to clarify their nanoscale\ndeformation mechanisms. The results demonstrate that these two metal nanowires\nfollow notably different stress - strain trends, with silver wires exhibiting\ngreater elastic stiffness and higher yield points at equivalent diameters - an\neffect likely rooted in silver's stronger atomic bonding and more stable\nmicrostructure. A pronounced size effect is observed: as the wire diameter\ndiminishes, both the yield strength and ultimate tensile strength increase\nsubstantially, a behavior driven by the higher proportion of surface atoms that\nenhance dislocation nucleation and mobility. Atomistic analyses further\nunderscore the dominant role of dislocations during plastic deformation, and in\nparticular reveal that surface - initiated dislocations in thinner wires\ncritically affect their fracture behavior.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-05-01T08:47:27Z"}
{"aid":"http://arxiv.org/abs/2505.00405v1","title":"Selling Information in Games with Externalities","summary":"A competitive market is modeled as a game of incomplete information. One\nplayer observes some payoff-relevant state and can sell (possibly noisy)\nmessages thereof to the other, whose willingness to pay is contingent on their\nown beliefs. We frame the decision of what information to sell, and at what\nprice, as a product versioning problem. The optimal menu screens buyer types to\nmaximize profit, which is the payment minus the externality induced by selling\ninformation to a competitor, that is, the cost of refining a competitor's\nbeliefs. For a class of games with binary actions and states, we derive the\nfollowing insights: (i) payments are necessary to provide incentives for\ninformation sharing amongst competing firms; (ii) the optimal menu benefits\nboth the buyer and the seller; (iii) the seller cannot steer the buyer's\nactions at the expense of social welfare; (iv) as such, as competition grows\nfiercer it can be optimal to sell no information at all.","main_category":"cs.GT","categories":"cs.GT","published":"2025-05-01T08:53:16Z"}
{"aid":"http://arxiv.org/abs/2505.00408v1","title":"Multi-dimensional optical imaging on a chip","summary":"Light inherently consists of multiple dimensions beyond intensity, including\nspectrum, polarization, etc. The coupling among these high-dimensional optical\nfeatures provides a compressive characterization of intrinsic material\nproperties. Because multiple optical dimensions are intrinsically coupled\nrather than independent, analyzing their inter-relationships and achieving\ntheir simultaneous acquisition is essential. Despite the existing optical\ntechniques to obtain different-dimensional data with cumbersome systems, joint\nacquisition of multi-dimensional optical information on a chip is still a\nserious challenge, limited by intensity-only photoelectric detection,\nsingle-dimensional optical elements, and finite bandwidth. In this work, we\nreport a multi-dimensional on-chip optical imaging (MOCI) architecture, which\nis functionally composed of three layers, including a multi-dimensional\nencoding layer to simultaneously encode different dimensions of incident light,\nan image acquisition layer to collect coupled intensity data, and a\ncomputational reconstruction layer to recover multi-dimensional images from a\nsingle frame of coupled measurement. Following the MOCI architecture, we for\nthe first time fabricated a real-time (74 FPS) on-chip\npolarization-hyperspectral imaging (PHI) sensor, with 2048$\\times$2448 pixels\nat 61 spectral channels covering the VIS-NIR range and 4 polarization states.\nWe applied the PHI sensor for simultaneously resolving hyperspectral and\npolarization information of complex scenes, and for the first time demonstrated\nnew applications including hyperspectral 3D modeling with normal and height\nmaps, and hyperspectral sensing against strong reflection and glare...","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-01T08:59:18Z"}
{"aid":"http://arxiv.org/abs/2505.00423v1","title":"Thermal evolution model from cometary nuclei to asteroids considering\n  contraction associated with ice sublimation","summary":"Comet--asteroid transition (CAT) objects are small solar system bodies in the\nprocess of evolving from cometary nuclei into asteroids, as they gradually lose\nvolatile substances due to solar heating. The volatile material is mainly water\nice, and the time required for its complete depletion is called the desiccation\ntime. Estimating the desiccation time is important for examining the formation\nand evolution of small solar system bodies. Here, we propose a new theoretical\nmodel for evaluating the desiccation time as a function of orbital elements,\nconsidering the contraction of the entire cometary nucleus due to ice\nsublimation. First, we performed numerical calculations of the thermal\nevolution of a cometary nucleus in an eccentric orbit, considering the seasonal\nvariation in the solar heating rate. Next, we derived the desiccation time\nanalytically as a function of orbital elements based on a steady-state model\nconsidering the solar heating rate averaged over the seasons. We compared the\nnumerical solutions for the desiccation time with the analytical solutions and\nclarified the conditions under which the analytical model can be applied.\nAdditionally, based on the analytical model, we derived formulae for estimating\nthe emission rates of water vapor and dust on the surface of the cometary\nnucleus, the maximum size of the emitted dust, and the dust emission velocity,\nby assuming the amount of ice remaining inside the nucleus. Using these\nanalytical solutions, we considered the internal structure and evolution\nprocess of typical CAT objects. Our analytical model was generally consistent\nwith that of the results of earlier observations of these objects. Our model\nprovides a theoretical guideline for discussing the evolution of cometary\nnuclei and the possibility of retaining internal ice in asteroids.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-05-01T09:45:32Z"}
{"aid":"http://arxiv.org/abs/2505.00426v1","title":"Leveraging Pretrained Diffusion Models for Zero-Shot Part Assembly","summary":"3D part assembly aims to understand part relationships and predict their\n6-DoF poses to construct realistic 3D shapes, addressing the growing demand for\nautonomous assembly, which is crucial for robots. Existing methods mainly\nestimate the transformation of each part by training neural networks under\nsupervision, which requires a substantial quantity of manually labeled data.\nHowever, the high cost of data collection and the immense variability of\nreal-world shapes and parts make traditional methods impractical for\nlarge-scale applications. In this paper, we propose first a zero-shot part\nassembly method that utilizes pre-trained point cloud diffusion models as\ndiscriminators in the assembly process, guiding the manipulation of parts to\nform realistic shapes. Specifically, we theoretically demonstrate that\nutilizing a diffusion model for zero-shot part assembly can be transformed into\nan Iterative Closest Point (ICP) process. Then, we propose a novel pushing-away\nstrategy to address the overlap parts, thereby further enhancing the robustness\nof the method. To verify our work, we conduct extensive experiments and\nquantitative comparisons to several strong baseline methods, demonstrating the\neffectiveness of the proposed approach, which even surpasses the supervised\nlearning method. The code has been released on\nhttps://github.com/Ruiyuan-Zhang/Zero-Shot-Assembly.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T09:54:12Z"}
{"aid":"http://arxiv.org/abs/2505.00431v1","title":"Global multiplicity results in a Moore-Nehari type problem with a\n  spectral parameter","summary":"This paper analyzes the structure of the set of positive solutions of a\nMoore-Nehari type problem, where $a\\equiv a_h$ is a piece-wise constant\nfunction defined for some $h\\in (0,1)$. In our analysis, $\\lambda$ is regarded\nas a bifurcation parameter, whereas $h$ is viewed as a deformation parameter\nbetween the autonomous case when $a=1$ and the linear case when $a=0$. In this\npaper, besides establishing some of the multiplicity results suggested by\nprevious numerical experiments (see Cubillos, L\\'opez-G\\'omez and Tellini,\n2024), we have analyzed the asymptotic behavior of the positive solutions of\nthe problem as $h\\uparrow 1$, when the shadow system of the problem is the\nlinear equation $-u''=\\pi^2 u$. This is the first paper where such a problem\nhas been addressed. Numerics is of no help in analyzing this singular\nperturbation problem because the positive solutions blow-up point-wise in\n$(0,1)$ as $h\\uparrow 1$ if $\\lambda<\\pi^2$.","main_category":"math.CA","categories":"math.CA","published":"2025-05-01T10:01:14Z"}
{"aid":"http://arxiv.org/abs/2505.00436v1","title":"Biderivations, local and 2-local derivation and automorphism of simple\n  $ω$-Lie algebras","summary":"Given a finite-dimensional complex simple $\\omega$-Lie algebras $\\mathfrak{}$\nover $\\mathbb{C}$. We prove that every local ,$2-$local derivation is a\nderivation and every local (resp. 2-local) automorphisms are automorphisms or\nan anti-automorphis (resp. automorphism). We characterize also biderivation,\n$\\frac{1}{2}$-derivation and local (2-local) $\\frac{1}{2}$-derivation of\n$\\mathfrak{g}$.","main_category":"math.RA","categories":"math.RA","published":"2025-05-01T10:23:35Z"}
{"aid":"http://arxiv.org/abs/2505.00442v1","title":"Decentralised, Self-Organising Drone Swarms using Coupled Oscillators","summary":"The problem of robotic synchronisation and coordination is a long-standing\none. Combining autonomous, computerised systems with unpredictable real-world\nconditions can have consequences ranging from poor performance to collisions\nand damage. This paper proposes using coupled oscillators to create a drone\nswarm that is decentralised and self organising. This allows for greater\nflexibility and adaptiveness than a hard-coded swarm, with more resilience and\nscalability than a centralised system. Our method allows for a variable number\nof drones to spontaneously form a swarm and react to changing swarm conditions.\nAdditionally, this method includes provisions to prevent communication\ninterference between drones, and signal processing techniques to ensure a\nsmooth and cohesive swarm.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY,nlin.AO","published":"2025-05-01T10:35:08Z"}
{"aid":"http://arxiv.org/abs/2505.00454v1","title":"Approximate calculation of functional integrals arising from the\n  operator approach","summary":"We apply the operator approach to a stochastic system belonging to a class of\ndeath-birth processes, which we introduce utilizing the master equation\napproach. By employing Doi- Peliti formalism we recast the master equation in\nthe form of a Schr\\\"odinger-like equation. Therein appearing pseudo-Hamiltonian\nis conveniently expressed in a suitable Fock space, constructed using\nbosonic-like creation and annihilation operators. The kernel of the associated\ntime evolution operator is rewritten using a functional integral, for which we\npropose an approximate method that allows its analytical treatment. The method\nis based on the expansion in eigenfunctions of the Hamiltonian generating given\nfunctional integral. In this manner, we obtain approximate values for the\nprobabilities of the system being in the first and second states for the case\nof the pure birth process.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-05-01T11:08:31Z"}
{"aid":"http://arxiv.org/abs/2505.00461v1","title":"Field-theoretic Analysis of Dynamic Isotropic Percolation: Three-loop\n  Approximation","summary":"The general epidemic process is a paradigmatic model in non-equilibrium\nstatistical physics displaying a continuous phase transition between active and\nabsorbing states.The dynamic isotropic percolation universality class captures\nits universal properties, which we aim to quantitatively study by means of the\nfield-theoretic formulation of the model augmented with a perturbative\nrenormalization group analysis. The main purpose of this work consists in\ndetermining the critical dynamic exponent $z$ to the three-loop approximation.\nThis allows us to finalize the quantitative description of the dynamic\nisotropic percolation class to this order of perturbation theory. The\ncalculations are performed within the dimensional regularization with the\nminimal subtraction scheme and actual perturbative expansions are carried out\nin a formally small parameter $\\epsilon$, where $\\epsilon = 6 - d$ is a\ndeviation from the upper critical dimension $d_c = 6$.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-05-01T11:28:53Z"}
{"aid":"http://arxiv.org/abs/2505.00462v1","title":"CORSTITCH - A free, open source software for stitching and\n  georeferencing underwater coral reef videos","summary":"CorStitch is an open-source software developed to automate the creation of\naccurate georeferenced reef mosaics from video transects obtained through\nAutomated Rapid Reef Assessment System surveys. We utilized a Fourier-based\nimage correlation algorithm to stitch sequential video frames, aligning them\nwith synchronized GNSS timestamps. The resulting compressed Keyhole Markup\nLanguage files, compatible with geographic information systems such as Google\nEarth, enable detailed spatial analysis. Validation through comparative\nanalysis of mosaics from two temporally distinct surveys of the same reef\ndemonstrated the software's consistent and reliable performance.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-01T11:29:45Z"}
{"aid":"http://arxiv.org/abs/2505.00466v1","title":"A Generalised Framework for Property-Driven Machine Learning","summary":"Neural networks have been shown to frequently fail to satisfy critical safety\nand correctness properties after training, highlighting the pressing need for\ntraining methods that incorporate such properties directly. While adversarial\ntraining can be used to improve robustness to small perturbations within\n$\\epsilon$-cubes, domains other than computer vision -- such as control systems\nand natural language processing -- may require more flexible input region\nspecifications via generalised hyper-rectangles. Meanwhile, differentiable\nlogics offer a way to encode arbitrary logical constraints as additional loss\nterms that guide the learning process towards satisfying these constraints. In\nthis paper, we investigate how these two complementary approaches can be\nunified within a single framework for property-driven machine learning. We show\nthat well-known properties from the literature are subcases of this general\napproach, and we demonstrate its practical effectiveness on a case study\ninvolving a neural network controller for a drone system. Our framework is\npublicly available at https://github.com/tflinkow/property-driven-ml.","main_category":"cs.LG","categories":"cs.LG,cs.LO","published":"2025-05-01T11:33:38Z"}
{"aid":"http://arxiv.org/abs/2505.00470v1","title":"On the Distribution of the Sample Covariance from a Matrix Normal\n  Population","summary":"This paper discusses the joint distribution of sample variances and\ncovariances, expressed in quadratic forms in a matrix population arising in\ncomparing the differences among groups under homogeneity of variance. One major\nconcern of this article is to compare $K$ different populations, by assuming\nthat the mean values of $x_{11}^{(k)}, x_{12}^{(k)}, \\dots, x_{1p}^{(k)},\nx_{21}^{(k)}, x_{22}^{(k)}, \\dots$, $x_{2p}^{(k)},\\dots,\nx_{n1}^{(k)},x_{n2}^{(k)},\\dots,$ $x_{np}^{(k)}$ in each population are\n$M^{(k)}$ ($n\\times p$), $k = 1,2,\\dots,K$ and $M$($n\\times p$) a fixed matrix,\nwith this hypothesis $$H_0: M^{(1)} = M^{(2)} = \\dots = M^{(k)} = M,$$ when the\ninter-group covariances are neglected and the intra-group covariances are\nequal. The $N$ intra-group variances and $\\frac{1}{2} N (N - 1)$ intra-group\ncovariances where $N = np$ are classified into four categories $T_{1}$,\n$T_{1\\frac{1}{2}}$, $T_{2}$ and $T_{3}$ according to the spectral forms of the\nprecision matrix. The joint distribution of the sample variances and\ncovariances is derived under these four scenarios. Besides, the moment\ngenerating function and the joint distribution of latent roots are explicitly\ncalculated. %The distribution of non-central means with known covariance is\ncalculated as an application to the one-sample analysis of variance, with its\nexact power tabulated up to order two. As an application, we consider a\nclassification problem in the discriminant analysis where the two populations\nshould have different intra-group covariances. The distribution of the ratio of\ntwo quadratic forms is considered both in the central and non-central cases,\nwith their exact power tabulated for different $n$ and $p$.","main_category":"math.ST","categories":"math.ST,stat.ME,stat.TH","published":"2025-05-01T11:49:04Z"}
{"aid":"http://arxiv.org/abs/2505.00478v1","title":"Probing ALP-portal Fermionic Dark Matter at the $e^+e^-$ Colliders","summary":"Axion-like particles (ALPs) are promising candidates for mediating\ninteractions between a dark sector and the Standard Model (SM). In this work,\nconsidering the effective interactions of ALPs with the SM gauge bosons and a\nfermion dark matter (DM), we explore the DM relic satisfied parameter space and\nassess its testability through indirect searches. The potential of probing such\nALP-portal fermionic DM at electron-positron colliders is investigated with the\nmono-photon + missing energy final states. We show that a spectacular\ndistinction between the signal and SM background is possible via missing energy\nvariable, the seed of which lies in the ALP-photon interaction, which also\ngoverns the relic density of DM. We further discuss the sensitivity of\nALP-photon coupling using the $\\chi^2$ analysis at the future electron-positron\ncollider specifications.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-01T12:11:03Z"}
{"aid":"http://arxiv.org/abs/2505.00479v1","title":"Computational Identification of Regulatory Statements in EU Legislation","summary":"Identifying regulatory statements in legislation is useful for developing\nmetrics to measure the regulatory density and strictness of legislation. A\ncomputational method is valuable for scaling the identification of such\nstatements from a growing body of EU legislation, constituting approximately\n180,000 published legal acts between 1952 and 2023. Past work on extraction of\nthese statements varies in the permissiveness of their definitions for what\nconstitutes a regulatory statement. In this work, we provide a specific\ndefinition for our purposes based on the institutional grammar tool. We develop\nand compare two contrasting approaches for automatically identifying such\nstatements in EU legislation, one based on dependency parsing, and the other on\na transformer-based machine learning model. We found both approaches performed\nsimilarly well with accuracies of 80% and 84% respectively and a K alpha of\n0.58. The high accuracies and not exceedingly high agreement suggests potential\nfor combining strengths of both approaches.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-05-01T12:11:32Z"}
{"aid":"http://arxiv.org/abs/2505.00493v1","title":"On the greatest prime factor and uniform equidistribution of quadratic\n  polynomials","summary":"We show that the greatest prime factor of $n^2+h$ is at least $n^{1.312}$\ninfinitely often. This gives an unconditional proof for the range previously\nknown under the Selberg eigenvalue conjecture. Furthermore, we get uniformity\nin $h \\leq n^{1+o(1)}$ under a natural hypothesis on real characters. The same\nuniformity is obtained for the equidistribution of the roots of quadratic\ncongruences modulo primes. We also prove a variant of the divisor problem for\n$ax^2+by^3$, which was used by the second author to give a conditional result\nabout primes of that shape.","main_category":"math.NT","categories":"math.NT","published":"2025-05-01T12:47:12Z"}
{"aid":"http://arxiv.org/abs/2505.00494v1","title":"Accelerating two-dimensional tensor network contractions using\n  QR-decompositions","summary":"Infinite projected entangled-pair states (iPEPS) provide a powerful tool for\nstudying strongly correlated systems directly in the thermodynamic limit. A\ncore component of the algorithm is the approximate contraction of the iPEPS,\nwhere the computational bottleneck typically lies in the singular value or\neigenvalue decompositions involved in the renormalization step. This is\nparticularly true on GPUs, where tensor contractions are substantially faster\nthan these decompositions. Here we propose a contraction scheme for\n$C_{4v}$-symmetric tensor networks based on combining the corner transfer\nmatrix renormalization group (CTMRG) with QR-decompositions which are\nsubstantially faster -- especially on GPUs. Our approach achieves up to two\norders of magnitude speedup compared to standard CTMRG and yields\nstate-of-the-art results for the Heisenberg and $J_1$-$J_2$ models in about one\nhour on an H100 GPU.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-05-01T12:48:26Z"}
{"aid":"http://arxiv.org/abs/2505.00502v1","title":"Towards Scalable Human-aligned Benchmark for Text-guided Image Editing","summary":"A variety of text-guided image editing models have been proposed recently.\nHowever, there is no widely-accepted standard evaluation method mainly due to\nthe subjective nature of the task, letting researchers rely on manual user\nstudy. To address this, we introduce a novel Human-Aligned benchmark for\nText-guided Image Editing (HATIE). Providing a large-scale benchmark set\ncovering a wide range of editing tasks, it allows reliable evaluation, not\nlimited to specific easy-to-evaluate cases. Also, HATIE provides a\nfully-automated and omnidirectional evaluation pipeline. Particularly, we\ncombine multiple scores measuring various aspects of editing so as to align\nwith human perception. We empirically verify that the evaluation of HATIE is\nindeed human-aligned in various aspects, and provide benchmark results on\nseveral state-of-the-art models to provide deeper insights on their\nperformance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T13:06:05Z"}
{"aid":"http://arxiv.org/abs/2505.00508v1","title":"Weak Random Feature Method for Solving Partial Differential Equations","summary":"The random feature method (RFM) has demonstrated great potential in bridging\ntraditional numerical methods and machine learning techniques for solving\npartial differential equations (PDEs). It retains the advantages of mesh-free\napproaches while achieving spectral accuracy for smooth solutions, without the\nneed for iterative procedures. However, the implementation of RFM in the\nidentification of weak solutions remains a subject of limited comprehension,\ndespite crucial role of weak solutions in addressing numerous applied problems.\nWhile the direct application of RFM to problems without strong solutions is\nfraught with potential challenges, we propose an enhancement to the original\nrandom feature method that is specifically suited for finding weak solutions\nand is termed as Weak RFM. Essentially, Weak RFM reformulates the original RFM\nby adopting the weak form of the governing equations and constructing a new\nlinear system through the use of carefully designed test functions, ensuring\nthat the resulting solution satisfies the weak form by default. To rigorously\nevaluate the performance of the proposed method, we conduct extensive\nexperiments on a variety of benchmark problems, including challenging\nthree-dimensional cases, and compare its performance with state of the art\nmachine learning-based approaches. The results demonstrate that Weak RFM\nachieves comparable or superior accuracy while significantly reducing\ncomputational time and memory consumption, highlighting its potential as a\nhighly efficient and robust tool for finding weak solutions to various PDE\nproblems.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-01T13:25:17Z"}
{"aid":"http://arxiv.org/abs/2505.00509v1","title":"Self-Ablating Transformers: More Interpretability, Less Sparsity","summary":"A growing intuition in machine learning suggests a link between sparsity and\ninterpretability. We introduce a novel self-ablation mechanism to investigate\nthis connection ante-hoc in the context of language transformers. Our approach\ndynamically enforces a k-winner-takes-all constraint, forcing the model to\ndemonstrate selective activation across neuron and attention units. Unlike\npost-hoc methods that analyze already-trained models, our approach integrates\ninterpretability directly into model training, promoting feature localization\nfrom inception. Training small models on the TinyStories dataset and employing\ninterpretability tests, we find that self-ablation leads to more localized\ncircuits, concentrated feature representations, and increased neuron\nspecialization without compromising language modelling performance.\nSurprisingly, our method also decreased overall sparsity, indicating that\nself-ablation promotes specialization rather than widespread inactivity. This\nreveals a complex interplay between sparsity and interpretability, where\ndecreased global sparsity can coexist with increased local specialization,\nleading to enhanced interpretability. To facilitate reproducibility, we make\nour code available at\nhttps://github.com/keenanpepper/self-ablating-transformers.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T13:25:37Z"}
{"aid":"http://arxiv.org/abs/2505.00510v1","title":"Ireland Topsoil Contamination Analysis: A Clustering Approach","summary":"This study investigates topsoil contamination in Ireland using geochemical\ndata from the Tellus Programme, analyzing 4,278 soil samples across 17,983\nsquare kilometer. The research employs CPF clustering with spatial constraints\nto classify samples into seven different groups, revealing distinct\ncontamination patterns.","main_category":"stat.AP","categories":"stat.AP","published":"2025-05-01T13:27:26Z"}
{"aid":"http://arxiv.org/abs/2505.00511v1","title":"Inconsistency-based Active Learning for LiDAR Object Detection","summary":"Deep learning models for object detection in autonomous driving have recently\nachieved impressive performance gains and are already being deployed in\nvehicles worldwide. However, current models require increasingly large datasets\nfor training. Acquiring and labeling such data is costly, necessitating the\ndevelopment of new strategies to optimize this process. Active learning is a\npromising approach that has been extensively researched in the image domain. In\nour work, we extend this concept to the LiDAR domain by developing several\ninconsistency-based sample selection strategies and evaluate their\neffectiveness in various settings. Our results show that using a naive\ninconsistency approach based on the number of detected boxes, we achieve the\nsame mAP as the random sampling strategy with 50% of the labeled data.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T13:29:56Z"}
{"aid":"http://arxiv.org/abs/2505.00520v1","title":"Proportionality in Practice: Quantifying Proportionality in Ordinal\n  Elections","summary":"Proportional representation plays a crucial role in electoral systems. In\nordinal elections, where voters rank candidates based on their preferences, the\nSingle Transferable Vote (STV) is the most widely used proportional voting\nmethod. STV is considered proportional because it satisfies an axiom requiring\nthat large enough solid coalitions of voters are adequately represented. Using\nreal-world data from local Scottish elections, we observe that solid coalitions\nof the required size rarely occur in practice. This observation challenges the\nimportance of proportionality axioms and raises the question of how the\nproportionality of voting methods can be assessed beyond their axiomatic\nperformance. We address these concerns by developing quantitative measures of\nproportionality. We apply these measures to evaluate the proportionality of\nvoting rules on real-world election data. Besides STV, we consider SNTV, the\nExpanding Approvals Rule, and Sequential Ranked-Choice Voting. We also study\nthe effects of ballot truncation by artificially completing truncated ballots\nand comparing the proportionality of outcomes under complete and truncated\nballots.","main_category":"cs.GT","categories":"cs.GT","published":"2025-05-01T13:41:42Z"}
{"aid":"http://arxiv.org/abs/2505.00524v1","title":"Recursive inseparability of classical theories of a binary predicate and\n  non-classical logics of a unary predicate","summary":"The paper considers algorithmic properties of classical and non-classical\nfirst-order logics and theories in bounded languages. The main idea is to prove\nthe undecidability of various fragments of classical and non-classical\nfirst-order logics and theories indirectly, by extracting it as a consequence\nof the recursive inseparability of special problems associated with them.\nFirst, we propose a domino problem, which makes it possible to catch the\nrecursive inseparability of two sets. Second, using this problem, we prove that\nthe classical first-order logic of a binary predicate and the theory of its\nfinite models where the predicate is symmetric and irreflexive are recursively\ninseparable in a language with a single binary predicate letter and three\nvariables (without constants and equality). Third, we prove, for an infinite\nclass of logics, that the monadic fragment of a modal predicate logic and the\nlogic of the class of its finite Kripke frames are recursively inseparable in\nlanguages with a single unary predicate letter and two individual variables;\nthe same result is obtained if we replace the condition of finiteness of frames\nwith the condition of finiteness of domains allowed in frames. Forth, we expand\nthe results to a wide class of superintuitionistic predicate logics. In\nparticular, it is proved that the positive fragments of the intuitionistic\npredicate logic and the logic of the class of finite intuitionistic Kripke\nframes are recursively inseparable in the language with a single unary\npredicate letter and two individual variables. The technique used and the\nresults obtained allow us to answer some additional questions about the\ndecidability of special monadic fragments of some modal and superintuitionistic\npredicate logics.","main_category":"math.LO","categories":"math.LO","published":"2025-05-01T13:46:45Z"}
{"aid":"http://arxiv.org/abs/2505.00530v1","title":"Leveraging Partial SMILES Validation Scheme for Enhanced Drug Design in\n  Reinforcement Learning Frameworks","summary":"SMILES-based molecule generation has emerged as a powerful approach in drug\ndiscovery. Deep reinforcement learning (RL) using large language model (LLM)\nhas been incorporated into the molecule generation process to achieve high\nmatching score in term of likelihood of desired molecule candidates. However, a\ncritical challenge in this approach is catastrophic forgetting during the RL\nphase, where knowledge such as molecule validity, which often exceeds 99\\%\nduring pretraining, significantly deteriorates. Current RL algorithms applied\nin drug discovery, such as REINVENT, use prior models as anchors to retian\npretraining knowledge, but these methods lack robust exploration mechanisms. To\naddress these issues, we propose Partial SMILES Validation-PPO (PSV-PPO), a\nnovel RL algorithm that incorporates real-time partial SMILES validation to\nprevent catastrophic forgetting while encouraging exploration. Unlike\ntraditional RL approaches that validate molecule structures only after\ngenerating entire sequences, PSV-PPO performs stepwise validation at each\nauto-regressive step, evaluating not only the selected token candidate but also\nall potential branches stemming from the prior partial sequence. This enables\nearly detection of invalid partial SMILES across all potential paths. As a\nresult, PSV-PPO maintains high validity rates even during aggressive\nexploration of the vast chemical space. Our experiments on the PMO and GuacaMol\nbenchmark datasets demonstrate that PSV-PPO significantly reduces the number of\ninvalid generated structures while maintaining competitive exploration and\noptimization performance. While our work primarily focuses on maintaining\nvalidity, the framework of PSV-PPO can be extended in future research to\nincorporate additional forms of valuable domain knowledge, further enhancing\nreinforcement learning applications in drug discovery.","main_category":"cs.LG","categories":"cs.LG,cs.CE,q-bio.BM","published":"2025-05-01T13:57:20Z"}
{"aid":"http://arxiv.org/abs/2505.00532v1","title":"Observation of Resonant Tunneling from Molecular Shape into Vibronic\n  Feshbach Resonances Followed by Mode-Specific Fragmentation","summary":"We present a kinematically complete study of dissociative electron attachment\n(DEA) in linear OCS molecules, focusing on how electrons resonantly attach and\ntrigger dissociation. Near the Franck-Condon regime, DEA is dominated by\nmolecular shape resonances, where transient OCS$^-$ states form with high\nvibrational amplitudes, spectroscopically evident as broad features in DEA\ncross-sections. As the electron beam energy increases from 5.5 to 6.0 eV, S$^-$\npopulation shifts from lower to higher-energy highly dense bending vibrational\nstates, reinforcing our findings on dipole-forbidden vibronic intensity\nborrowing. Our advanced potential energy curve calculations, employing the\nEquation-of-motion coupled cluster singles and doubles for electron attachment\n(EA-EOMCCSD) method, reveal that beyond the shape resonance, non-adiabatic\nresonant tunneling governs the avoided crossings, dynamically generating three\nmode-specific vibronic Feshbach resonances before complete dissociation into\nthree distinct kinetic energy bands of S$^-$. Our theoretical results probe\nmost of the experimental observations quantitatively and qualitatively. These\ninsights deepen our fundamental understanding of resonance-mediated\ndissociation in electron-molecule resonant scattering, with broader\nimplications for quantum mechanics, plasma physics, vibrational revival,\nastrochemistry, and radiation damage research.","main_category":"physics.atm-clus","categories":"physics.atm-clus,physics.chem-ph,quant-ph","published":"2025-05-01T13:58:23Z"}
{"aid":"http://arxiv.org/abs/2505.00546v1","title":"Directly Forecasting Belief for Reinforcement Learning with Delays","summary":"Reinforcement learning (RL) with delays is challenging as sensory perceptions\nlag behind the actual events: the RL agent needs to estimate the real state of\nits environment based on past observations. State-of-the-art (SOTA) methods\ntypically employ recursive, step-by-step forecasting of states. This can cause\nthe accumulation of compounding errors. To tackle this problem, our novel\nbelief estimation method, named Directly Forecasting Belief Transformer (DFBT),\ndirectly forecasts states from observations without incrementally estimating\nintermediate states step-by-step. We theoretically demonstrate that DFBT\ngreatly reduces compounding errors of existing recursively forecasting methods,\nyielding stronger performance guarantees. In experiments with D4RL offline\ndatasets, DFBT reduces compounding errors with remarkable prediction accuracy.\nDFBT's capability to forecast state sequences also facilitates multi-step\nbootstrapping, thus greatly improving learning efficiency. On the MuJoCo\nbenchmark, our DFBT-based method substantially outperforms SOTA baselines.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T14:20:48Z"}
{"aid":"http://arxiv.org/abs/2505.00556v1","title":"When is $A + x A =\\mathbb{R}$","summary":"We show that there is an additive $F_\\sigma$ subgroup $A$ of $\\mathbb{R}$ and\n$x \\in \\mathbb{R}$ such that $\\mathrm{dim_H} (A) = \\frac{1}{2}$ and $A + x A\n=\\mathbb{R}$. However, if $A \\subseteq \\mathbb{R}$ is a subring of $\\mathbb{R}$\nand there is $x \\in \\mathbb{R}$ such that $A + x A =\\mathbb{R}$, then $A\n=\\mathbb{R}$. Moreover, assuming the continuum hypothesis (CH), there is a\nsubgroup $A$ of $\\mathbb{R}$ with $\\mathrm{dim_H} (A) = 0$ such that $x \\not\\in\n\\mathbb{Q}$ if and only if $A + x A =\\mathbb{R}$ for all $x \\in \\mathbb{R}$. A\nkey ingredient in the proof of this theorem consists of some techniques in\nrecursion theory and algorithmic randomness. We believe it may lead to\napplications to other constructions of exotic sets of reals. Several other\ntheorems on measurable, and especially Borel and analytic subgroups and\nsubfields of the reals are presented. We also discuss some of these results in\nthe $p$-adics.","main_category":"math.LO","categories":"math.LO,math.CA,math.GR,math.NT","published":"2025-05-01T14:31:57Z"}
{"aid":"http://arxiv.org/abs/2505.00558v1","title":"Exponentially Consistent Low Complexity Tests for Outlier Hypothesis\n  Testing with Distribution Uncertainty","summary":"We revisit the outlier hypothesis testing (OHT) problem of Li et al. (TIT\n2024) and propose exponentially consistent tests when there is distribution\nuncertainty for both nominal samples and outliers. In original OHT, one is\ngiven a list of sequences, most of which are generated i.i.d. from a\ndistribution called the nominal distribution while the rest are generated\ni.i.d. from another distribution named the anomalous distribution. The task of\nOHT is to identify outliers when both the nominal and anomalous distributions\nare unknown. Motivated by the study for classification with distribution\nuncertainty by Hsu and Wang (ISIT 2020), we consider OHT with distribution\nuncertainty, where each nominal sample is generated from a distribution\ncentered around the unknown nominal distribution and each outlier is generated\nfrom a distribution centered around the unknown anomalous distribution. With a\nfurther step towards practical applications, in the spirit of Bu et al. (TSP\n2019), we propose low-complexity tests when the number of outliers is known and\nunknown, and show that our proposed tests are exponentially consistent.\nFurthermore, we demonstrate that there is a penalty for not knowing the number\nof outliers in the error exponent when outliers exist. Our results strengthen\nBu et al. in three aspects: i) our tests allow distribution uncertainty and\nreveal the impact of distribution uncertainty on the performance of\nlow-complexity tests; ii) when the number of outliers is known and there is no\ndistribution uncertainty, our test achieves the same asymptotic performance\nwith lower complexity; and iii) when the number of outliers is unknown, we\ncharacterize the tradeoff among the three error probabilities, while two of\nthese error probabilities were not analyzed by Bu et al. even when there is no\ndistribution uncertainty. Finally, we illustrate our theoretical results using\nnumerical examples.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-01T14:33:56Z"}
{"aid":"http://arxiv.org/abs/2505.00567v1","title":"Error Exponents for Oblivious Relaying and Connections to Source Coding\n  with a Helper","summary":"The information bottleneck channel, also known as oblivious relaying, is a\ntwo-hop channel where a transmitter sends messages to a remote receiver via an\nintermediate relay node. A codeword sent by the transmitter passes through a\ndiscrete memoryless channel to reach the relay, and then the relay processes\nthe noisy channel output and forwards it to the receiver through a noiseless\nrate-limited link. The relay is oblivious, in the sense that it has no\nknowledge of the channel codebook used in transmission. Past works on oblivious\nrelaying are focused on characterizing achievable rates. In this work, we study\nerror exponents and explore connections to loseless source coding with a\nhelper, also known as the Wyner-Ahlswede-K\\\"orner (WAK) problem. We first\nestablish an achievable error exponent for oblivious relaying under constant\ncompositions codes. A key feature of our analysis is the use of the type\ncovering lemma to design the relay's compress-forward scheme. We then show that\nemploying constant composition code ensembles does not improve the rates\nachieved with their IID counterparts. We also derive a sphere packing upper\nbound for the error exponent. In the second part of this paper, we establish a\nconnection between the information bottleneck channel and the WAK problem. We\nshow that good codes for the latter can be produced through permuting codes\ndesigned for the former. This is accomplished by revisiting Ahlswede's covering\nlemma, and extending it to achieve simultaneous covering of a type class by\nseveral distinct sets using the same sequence of permutations. We then apply\nour approach to attain the best known achievable error exponent for the WAK\nproblem, previously established by Kelly and Wagner. As a byproduct of our\nderivations, we also establish error exponents and achievable rates under\nmismatched decoding rules.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-01T14:50:51Z"}
{"aid":"http://arxiv.org/abs/2505.00580v1","title":"Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors","summary":"Foundation models have achieved tremendous success in different domains.\nHowever, their huge computation and storage complexity make these models\ndifficult to fine-tune and also less applicable in practice. Recent study shows\ntraining in Fourier domain can be an effective fine-tuning method in terms of\nboth model performance and number of training parameters. In this work, we\npropose to further reduce the complexity by the factorization through the\nproduct of interleaved circulant and diagonal matrices. In addition, we address\nthe case of non-square fine-tuning weights by partitioning the circulant matrix\ninto blocks. Our method avoids the construction of weight change matrix and\nutilizes 1D fast Fourier transform (FFT) instead of 2D FFT. Experimental\nresults show that our method achieves similar or better performance across\nvarious tasks with much less floating-point operations (FLOPs) and the number\nof trainable parameters.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T15:11:46Z"}
{"aid":"http://arxiv.org/abs/2505.00586v1","title":"ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory\n  Prediction for Automated Parking using Diffusion Models","summary":"Automated parking is a critical feature of Advanced Driver Assistance Systems\n(ADAS), where accurate trajectory prediction is essential to bridge perception\nand planning modules. Despite its significance, research in this domain remains\nrelatively limited, with most existing studies concentrating on single-modal\ntrajectory prediction of vehicles. In this work, we propose ParkDiffusion, a\nnovel approach that predicts the trajectories of both vehicles and pedestrians\nin automated parking scenarios. ParkDiffusion employs diffusion models to\ncapture the inherent uncertainty and multi-modality of future trajectories,\nincorporating several key innovations. First, we propose a dual map encoder\nthat processes soft semantic cues and hard geometric constraints using a\ntwo-step cross-attention mechanism. Second, we introduce an adaptive agent type\nembedding module, which dynamically conditions the prediction process on the\ndistinct characteristics of vehicles and pedestrians. Third, to ensure\nkinematic feasibility, our model outputs control signals that are subsequently\nused within a kinematic framework to generate physically feasible trajectories.\nWe evaluate ParkDiffusion on the Dragon Lake Parking (DLP) dataset and the\nIntersections Drone (inD) dataset. Our work establishes a new baseline for\nheterogeneous trajectory prediction in parking scenarios, outperforming\nexisting methods by a considerable margin.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-05-01T15:16:59Z"}
{"aid":"http://arxiv.org/abs/2505.00588v1","title":"Exact Many-body Quantum Dynamics in One-Dimensional Baths via\n  \"Superspins\"","summary":"Computing the exact dynamics of many-body quantum systems becomes intractable\nas system size grows. Here, we present a symmetry-based method that provides an\nexponential reduction in the complexity of a broad class of such problems\n$\\unicode{x2014}$ qubits coupled to one-dimensional electromagnetic baths. We\nidentify conditions under which partial permutational symmetry emerges and\nexploit it to group qubits into collective multi-level degrees of freedom,\nwhich we term ''superspins.'' These superspins obey a generalized angular\nmomentum algebra, reducing the relevant Hilbert space dimension from\nexponential to polynomial. Using this framework, we efficiently compute\nmany-body superradiant dynamics in large arrays of qubits coupled to waveguides\nand ring resonators, showing that $\\unicode{x2014}$ unlike in conventional\nDicke superradiance $\\unicode{x2014}$ the total spin length is not conserved.\nAt long times, dark states become populated. We identify configurations where\nthese states exhibit metrologically useful entanglement. Our approach enables\nexact treatment of complex dissipative dynamics beyond the fully symmetric\nlimit and provides a rigorous benchmark for approximate numerical methods.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T15:22:59Z"}
{"aid":"http://arxiv.org/abs/2505.00595v1","title":"All-optical radio-frequency phase detection for Rydberg atom sensors\n  using oscillatory dynamics","summary":"Rydberg atom radio frequency sensors are a unique platform for precision\nelectromagnetic field measurement, e.g. they have extraordinary carrier\nbandwidth spanning MHz-THz and can be self-calibrated. These photonic sensors\nuse lasers to prepare and read out the atomic response to a radio frequency\nelectromagnetic field. Most work on Rydberg atom sensors centers on radio\nfrequency electric field strength because the sensor functions as a square law\ndetector, unless an external radio frequency heterodyning field is used. A\nheterodyning field acts as a local oscillator and enables phase read out at the\nexpense of the radio frequency equipment necessary to generate it. In order to\novercome the disadvantages of a radio frequency local oscillator, we\ninvestigate all-optical phase-sensitive detection using a five-level\nclosed-loop excitation scheme. We show that under finite detuning of the loop\nfields, the atomic response oscillates at the frequency of the detuning. The\noscillation is transferred to a probe laser absorption signal. The phase,\nfrequency and amplitude of the radio frequency signal are imprinted on the\noscillatory dynamics and can be determined using demodulation and matched\nfilter techniques applied to the probe laser transmission signal.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-05-01T15:30:24Z"}
{"aid":"http://arxiv.org/abs/2505.00608v1","title":"Turning dispersion into signal: density-split analyses of pairwise\n  velocities","summary":"Pairwise velocities of the large-scale structure encode valuable information\nabout the growth of structure. They can be observed indirectly through\nredshift-space distortions and the kinetic Sunyaev-Zeldovich effect. Whether it\nis Gaussian or non-Gaussian, pairwise velocity has a broad distribution, but\nthe cosmologically useful information lies primarily in the mean - the\nstreaming velocities; the dispersion around the mean is often treated as a\nnuisance and marginalized over. This conventional approach reduces the\nconstraining power of our observations. Here, we show that this does not have\nto be the case, provided the physics behind the dispersion is understood. We\ndemonstrate that by splitting the halo/galaxy samples according to their\ndensity environments and measuring the streaming velocities separately, the\ntotal signal-to-noise is several times greater than in conventional global\nmeasurements of the pairwise velocity distribution (PVD). This improvement\narises because the global PVD is a composite of a series of near-Gaussian\ndistributions with different means and dispersions, each determined by its\nlocal density environment. Around underdense and overdense regions, the mean\nstreaming velocities are positive and negative, respectively. By splitting the\ndata, we avoid cancellation between these opposing velocities, effectively\nturning what would be considered dispersion in the global PVD into a signal.\nOur findings indicate substantial potential for improving the analysis of PVD\nobservations using the kinetic Sunyaev-Zeldovich effect and redshift-space\ndistortions.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-01T15:37:28Z"}
{"aid":"http://arxiv.org/abs/2505.00616v1","title":"Catastrophic Liability: Managing Systemic Risks in Frontier AI\n  Development","summary":"As artificial intelligence systems grow more capable and autonomous, frontier\nAI development poses potential systemic risks that could affect society at a\nmassive scale. Current practices at many AI labs developing these systems lack\nsufficient transparency around safety measures, testing procedures, and\ngovernance structures. This opacity makes it challenging to verify safety\nclaims or establish appropriate liability when harm occurs. Drawing on\nliability frameworks from nuclear energy, aviation software, and healthcare, we\npropose a comprehensive approach to safety documentation and accountability in\nfrontier AI development.","main_category":"cs.CY","categories":"cs.CY","published":"2025-05-01T15:47:14Z"}
{"aid":"http://arxiv.org/abs/2505.00618v1","title":"RevealNet: Distributed Traffic Correlation for Attack Attribution on\n  Programmable Networks","summary":"Network attackers have increasingly resorted to proxy chains, VPNs, and\nanonymity networks to conceal their activities. To tackle this issue, past\nresearch has explored the applicability of traffic correlation techniques to\nperform attack attribution, i.e., to identify an attacker's true network\nlocation. However, current traffic correlation approaches rely on\nwell-provisioned and centralized systems that ingest flows from multiple\nnetwork probes to compute correlation scores. Unfortunately, this makes\ncorrelation efforts scale poorly for large high-speed networks.\n  In this paper, we propose RevealNet, a decentralized framework for attack\nattribution that orchestrates a fleet of P4-programmable switches to perform\ntraffic correlation. RevealNet builds on a set of correlation primitives\ninspired by prior work on computing and comparing flow sketches -- compact\nsummaries of flows' key characteristics -- to enable efficient, distributed,\nin-network traffic correlation. Our evaluation suggests that RevealNet achieves\ncomparable accuracy to centralized attack attribution systems while\nsignificantly reducing both the computational complexity and bandwidth\noverheads imposed by correlation tasks.","main_category":"cs.CR","categories":"cs.CR,cs.NI","published":"2025-05-01T15:48:35Z"}
{"aid":"http://arxiv.org/abs/2505.00626v1","title":"The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning\n  (and How to Fix Them)","summary":"Large language models (LLMs) that integrate multiple input roles (e.g.,\nsystem instructions, user queries, external tool outputs) are increasingly\nprevalent in practice. Ensuring that the model accurately distinguishes\nmessages from each role -- a concept we call \\emph{role separation} -- is\ncrucial for consistent multi-role behavior. Although recent work often targets\nstate-of-the-art prompt injection defenses, it remains unclear whether such\nmethods truly teach LLMs to differentiate roles or merely memorize known\ntriggers. In this paper, we examine \\emph{role-separation learning}: the\nprocess of teaching LLMs to robustly distinguish system and user tokens.\nThrough a \\emph{simple, controlled experimental framework}, we find that\nfine-tuned models often rely on two proxies for role identification: (1) task\ntype exploitation, and (2) proximity to begin-of-text. Although data\naugmentation can partially mitigate these shortcuts, it generally leads to\niterative patching rather than a deeper fix. To address this, we propose\nreinforcing \\emph{invariant signals} that mark role boundaries by adjusting\ntoken-wise cues in the model's input encoding. In particular, manipulating\nposition IDs helps the model learn clearer distinctions and reduces reliance on\nsuperficial proxies. By focusing on this mechanism-centered perspective, our\nwork illuminates how LLMs can more reliably maintain consistent multi-role\nbehavior without merely memorizing known prompts or triggers.","main_category":"cs.CL","categories":"cs.CL,cs.AI,I.2","published":"2025-05-01T16:06:16Z"}
{"aid":"http://arxiv.org/abs/2505.00627v1","title":"Brain Foundation Models with Hypergraph Dynamic Adapter for Brain\n  Disease Analysis","summary":"Brain diseases, such as Alzheimer's disease and brain tumors, present\nprofound challenges due to their complexity and societal impact. Recent\nadvancements in brain foundation models have shown significant promise in\naddressing a range of brain-related tasks. However, current brain foundation\nmodels are limited by task and data homogeneity, restricted generalization\nbeyond segmentation or classification, and inefficient adaptation to diverse\nclinical tasks. In this work, we propose SAM-Brain3D, a brain-specific\nfoundation model trained on over 66,000 brain image-label pairs across 14 MRI\nsub-modalities, and Hypergraph Dynamic Adapter (HyDA), a lightweight adapter\nfor efficient and effective downstream adaptation. SAM-Brain3D captures\ndetailed brain-specific anatomical and modality priors for segmenting diverse\nbrain targets and broader downstream tasks. HyDA leverages hypergraphs to fuse\ncomplementary multi-modal data and dynamically generate patient-specific\nconvolutional kernels for multi-scale feature fusion and personalized\npatient-wise adaptation. Together, our framework excels across a broad spectrum\nof brain disease segmentation and classification tasks. Extensive experiments\ndemonstrate that our method consistently outperforms existing state-of-the-art\napproaches, offering a new paradigm for brain disease analysis through\nmulti-modal, multi-scale, and dynamic foundation modeling.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T16:06:17Z"}
{"aid":"http://arxiv.org/abs/2505.00634v1","title":"Forward kinematics of a general Stewart-Gough platform by elimination\n  templates","summary":"The paper proposes an efficient algebraic solution to the problem of forward\nkinematics for a general Stewart-Gough platform. The problem involves\ndetermining all possible postures of a mobile platform connected to a fixed\nbase by six legs, given the leg lengths and the internal geometries of the\nplatform and base. The problem is known to have 40 solutions (whether real or\ncomplex). The proposed algorithm consists of three main steps: (i) a specific\nsparse matrix of size 293x362 (the elimination template) is constructed from\nthe coefficients of the polynomial system describing the platform's kinematics;\n(ii) the PLU decomposition of this matrix is used to construct a pair of 69x69\nmatrices; (iii) all 40 solutions (including complex ones) are obtained by\ncomputing the generalized eigenvectors of this matrix pair. The proposed\nalgorithm is numerically robust, computationally efficient, and straightforward\nto implement - requiring only standard linear algebra decompositions. MATLAB,\nJulia, and Python implementations of the algorithm will be made publicly\navailable.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T16:18:07Z"}
{"aid":"http://arxiv.org/abs/2505.00635v1","title":"SOMA: a novel sampler for exchangeable variables","summary":"The problem of sampling exchangeable random variables arises in many Bayesian\ninference tasks, especially in data imputation given a privatized summary\nstatistics. These permutation-invariant joint distributions often have\ndependency structures that make sampling challenging. Component-wise sampling\nstrategies, such as Metropolis-within-Gibbs, can mix slowly because they\nconsider only comparing a proposed point with one component at a time. In this\nwork, we propose a novel Single-Offer-Multiple-Attempts (SOMA) sampler that is\ntailored to sampling permutation invariant distributions. The core intuition of\nSOMA is that a proposed point unsuitable to replace one component might still\nbe a good candidate to replace some other component in the joint distribution.\nSOMA first makes a singer offer, and then simultaneously considers attempts to\nreplace each component of the current state with the single offer, before\nmaking the final acceptance or rejection decision. We provide an acceptance\nlower bound of SOMA and, using a coupling method, derive the convergence rate\nupper bound of SOMA in the two-dimensional case. We validate theoretical\nfindings with numerical simulations, including a demonstration on\ndifferentially private Bayesian linear regression.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-01T16:20:16Z"}
{"aid":"http://arxiv.org/abs/2505.00636v1","title":"Fully passive quantum random number generation with untrusted light","summary":"Quantum random number generators (QRNGs) harness the inherent\nunpredictability of quantum mechanics to produce true randomness. Yet, in many\noptical implementations, the light source remains a potential vulnerability -\nsusceptible to deviations from ideal behavior and even adversarial\neavesdropping. Source-device-independent (SDI) protocols address this with a\npragmatic strategy, by removing trust assumptions on the source, and instead\nrely on realistic modelling and characterization of the measurement device. In\nthis work, we enhance an existing SDI-QRNG protocol by eliminating the need for\na perfectly balanced beam splitter within the trusted measurement device, which\nis an idealized assumption made for the simplification of security analysis. We\ndemonstrate that certified randomness can still be reliably extracted across a\nwide range of beam-splitting ratios, significantly improving the protocol's\npracticality and robustness. Using only off-the-shelf components, our\nimplementation achieves real-time randomness generation rates of 0.347 Gbps. We\nalso experimentally validate the protocol's resilience against adversarial\nattacks and highlight its self-testing capabilities. These advances mark a\nsignificant step toward practical, lightweight, high-performance,\nfully-passive, and composably secure QRNGs suitable for real-world deployment.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T16:21:50Z"}
{"aid":"http://arxiv.org/abs/2505.00643v1","title":"Deep Learning Assisted Outer Volume Removal for Highly-Accelerated\n  Real-Time Dynamic MRI","summary":"Real-time (RT) dynamic MRI plays a vital role in capturing rapid\nphysiological processes, offering unique insights into organ motion and\nfunction. Among these applications, RT cine MRI is particularly important for\nfunctional assessment of the heart with high temporal resolution. RT imaging\nenables free-breathing, ungated imaging of cardiac motion, making it a crucial\nalternative for patients who cannot tolerate conventional breath-hold,\nECG-gated acquisitions. However, achieving high acceleration rates in RT cine\nMRI is challenging due to aliasing artifacts from extra-cardiac tissues,\nparticularly at high undersampling factors. In this study, we propose a novel\nouter volume removal (OVR) method to address this challenge by eliminating\naliasing contributions from non-cardiac regions in a post-processing framework.\nOur approach estimates the outer volume signal for each timeframe using\ncomposite temporal images from time-interleaved undersampling patterns, which\ninherently contain pseudo-periodic ghosting artifacts. A deep learning (DL)\nmodel is trained to identify and remove these artifacts, producing a clean\nouter volume estimate that is subsequently subtracted from the corresponding\nk-space data. The final reconstruction is performed with a physics-driven DL\n(PD-DL) method trained using an OVR-specific loss function to restore high\nspatio-temporal resolution images. Experimental results show that the proposed\nmethod at high accelerations achieves image quality that is visually comparable\nto clinical baseline images, while outperforming conventional reconstruction\ntechniques, both qualitatively and quantitatively. The proposed approach\nprovides a practical and effective solution for artifact reduction in RT cine\nMRI without requiring acquisition modifications, offering a pathway to higher\nacceleration rates while preserving diagnostic quality.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV,physics.med-ph","published":"2025-05-01T16:31:52Z"}
{"aid":"http://arxiv.org/abs/2505.00655v1","title":"Why the hyperbolic polaritons are hyperbolic?","summary":"Polaritons travelling along a hyperbolic medium's surface have recently\nsparked significant interest in nanophotonics for the unprecedented\nmanipulation ability on light at the nanoscale in a planar way, promising\npotential nano-optical applications, especially in two-dimensional circuitry.\nDespite of being named hyperbolic polaritons, the hyperbolic nature has not\nbeen thoroughly revealed since an analytical description of the Iso-frequency\ncontour is still elusive. In this work, we proposed an analytical form for\ndescribing the iso-frequency contour of the hyperbolic polaritons, showcasing\ntheir strictly hyperbolic nature. Such an analytical form is obtained based on\nthe focusing behavior of the hyperbolic polaritons and verified by both the\npublished data from commonly used hyperbolic media systems of the hyperbolic\npolaritons and our own experimental characterizations on a hyperbolic\nmetamaterial film. By presenting a concise and intuitive physical image, this\nwork may provide a groundbreaking methodology in developing novel hyperbolic\npolaritons based optical devices.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-01T16:57:35Z"}
{"aid":"http://arxiv.org/abs/2505.00659v1","title":"It's All ${\\tt Ok}$: Curvature in Light of BAO from DESI DR2","summary":"Recent measurements of baryon acoustic oscillations (BAO) from the Dark\nEnergy Spectroscopic Instrument (DESI) show hints of tension with data from the\ncosmic microwave background (CMB) when interpreted within the standard model of\ncosmology. In this short note we discuss the consequences of one solution to\nthis tension, a small but negative spatial curvature with $R_k = 21 H_0^{-1}$,\nwhich DESI measures at $2\\sigma$. We describe the physical role of curvature in\ncosmological distance measures tied to recombination, i.e. the CMB and BAO, and\nthe relation to neutrino mass constraints which are relaxed to $\\sum m_\\nu <\n0.10$ eV when curvature is allowed to deviate from zero. A robust detection of\nnegative curvature would have significant implications for inflationary models:\nimproved BAO measurements, particularly from future high-redshift spectroscopic\nsurveys, will be able to distinguish curvature from other solutions to the\nDESI-CMB tension like phantom dark energy at high significance.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-01T17:01:10Z"}
{"aid":"http://arxiv.org/abs/2505.00664v1","title":"Key exchange protocol based on circulant matrix action over\n  congruence-simple semiring","summary":"We present a new key exchange protocol based on circulant matrices acting on\nmatrices over a congruence-simple semiring. We describe how to compute matrices\nwith the necessary properties for the implementation of the protocol.\nAdditionally, we provide an analysis of its computational cost and its security\nagainst known attacks.","main_category":"math.AC","categories":"math.AC,cs.CR,cs.IT,math.IT","published":"2025-05-01T17:07:11Z"}
{"aid":"http://arxiv.org/abs/2505.00665v1","title":"Auditing without Leaks Despite Curiosity","summary":"\\textit{Auditing} data accesses helps preserve privacy and ensures\naccountability by allowing one to determine who accessed (potentially\nsensitive) information. A prior formal definition of register auditability was\nbased on the values returned by read operations, \\emph{without accounting for\ncases where a reader might learn a value without explicitly reading it or gain\nknowledge of data access without being an auditor}.\n  This paper introduces a refined definition of auditability that focuses on\nwhen a read operation is \\emph{effective}, rather than relying on its\ncompletion and return of a value. Furthermore, we formally specify the\nconstraints that \\textit{prevent readers from learning values they did not\nexplicitly read or from auditing other readers' accesses.}\n  Our primary algorithmic contribution is a wait-free implementation of a\n\\emph{multi-writer, multi-reader register} that tracks effective reads while\npreventing unauthorized audits. The key challenge is ensuring that a read is\nauditable as soon as it becomes effective, which we achieve by combining value\naccess and access logging into a single atomic operation. Another challenge is\nrecording accesses without exposing them to readers, which we address using a\nsimple encryption technique (one-time pad).\n  We extend this implementation to an \\emph{auditable max register} that tracks\nthe largest value ever written. The implementation deals with the additional\nchallenge posed by the max register semantics, which allows readers to learn\nprior values without reading them.\n  The max register, in turn, serves as the foundation for implementing an\n\\emph{auditable snapshot} object and, more generally, \\emph{versioned types}.\nThese extensions maintain the strengthened notion of auditability,\nappropriately adapted from multi-writer, multi-reader registers.","main_category":"cs.DC","categories":"cs.DC,cs.CR","published":"2025-05-01T17:15:04Z"}
{"aid":"http://arxiv.org/abs/2505.00667v1","title":"A Practical Framework for Simulating Time-Resolved Spectroscopy Based on\n  a Real-time Dyson Expansion","summary":"Time-resolved spectroscopy is a powerful tool for probing electron dynamics\nin molecules and solids, revealing transient phenomena on sub-femtosecond\ntimescales. The interpretation of experimental results is often enhanced by\nparallel numerical studies, which can provide insight and validation for\nexperimental hypotheses. However, developing a theoretical framework for\nsimulating time-resolved spectra remains a significant challenge. The most\nsuitable approach involves the many-body non-equilibrium Green's function\nformalism, which accounts for crucial dynamical many-body correlations during\ntime evolution. While these dynamical correlations are essential for observing\nemergent behavior in time-resolved spectra, they also render the formalism\nprohibitively expensive for large-scale simulations. Substantial effort has\nbeen devoted to reducing this computational cost -- through approximations and\nnumerical techniques -- while preserving the key dynamical correlations. The\nultimate goal is to enable first-principles simulations of time-dependent\nsystems ranging from small molecules to large, periodic, multidimensional\nsolids. In this perspective, we outline key challenges in developing practical\nsimulations for time-resolved spectroscopy, with a particular focus on Green's\nfunction methodologies. We highlight a recent advancement toward a scalable\nframework: the real-time Dyson expansion (RT-DE). We introduce the theoretical\nfoundation of RT-DE and discuss strategies for improving scalability, which\nhave already enabled simulations of system sizes beyond the reach of previous\nfully dynamical approaches. We conclude with an outlook on future directions\nfor extending RT-DE to first-principles studies of dynamically correlated,\nnon-equilibrium systems.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-05-01T17:17:56Z"}
{"aid":"http://arxiv.org/abs/2505.00673v1","title":"Strange correlator and string order parameter for non-invertible\n  symmetry protected topological phases in 1+1d","summary":"In this paper, we construct strange correlators and string order parameters\nfor non-invertible symmetry protected topological phases (NISPTs) in 1+1d\nquantum lattice spin models. The strange correlator exhibits long-range order\nwhen evaluated between two distinct NISPTs and decays exponentially otherwise.\nWe show that strange charged operators inserted into the strange correlator are\nlinked to the interface algebra (boundary tube algebra) and are non-trivial\nwhen all its irreducible representations have dimensions greater than one. We\ndiscuss the generalization to higher dimensions. The string order parameter is\nobtained by contracting the truncated symmetry operator with charge decoration\noperators, which are determined by the NISPT action tensors. We illustrate the\nabove construction using the three NISPTs of $\\text{Rep}(D_8)$ and demonstrate\nthe extraction of categorical data via tensor networks, particularly through\nthe ZX calculus. Finally, we show that the entanglement spectrum degeneracy is\ndetermined by the irreducible representations of the interface algebra when\nassuming non-invertible symmetry on-site condition.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,hep-th,quant-ph","published":"2025-05-01T17:26:43Z"}
{"aid":"http://arxiv.org/abs/2505.00678v1","title":"Photonic Crystal Microring Resonators on a Hybrid Silicon\n  Nitride-on-Lithium Niobate Platform","summary":"Photonic-crystal resonators (PhCRs) have been widely used in nonlinear\nintegrated photonics for frequency engineering applications. A\nmicrowave-assisted frequency converter based on PhCRs highlights its precise\ncontrol of frequency (enabled by creation of a pair of supermodes by a\ncorrugated PhCR) and bidirectional frequency conversion. In this paper, we\ndemonstrate a high-quality PhCR on a hybrid silicon nitride-on-lithium\nniobate-on-insulator (SiN-on-LNOI) platform for the first time for\nvoltage-driven flexible frequency conversion using the electro-optic effect\n(0.85 pm/V). The fabricated PhCR has a large supermode splitting bandwidth =\n14.6 GHz and an intrinsic quality factor (Q) = 147,000. Using different\nperiodic corrugation amplitudes in the fabricated PhCRs enables the precise\ncontrol of mode splitting with a ratio of 93.5 MHz/nm between the mode\nsplitting bandwidth and the corrugation amplitude.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-05-01T17:36:41Z"}
{"aid":"http://arxiv.org/abs/2505.00680v1","title":"Rational points on $X_0(N)^*$ when $N$ is non-squarefree","summary":"Let $N$ be a non-squarefree integer such that the quotient $X_0(N)^*$ of the\nmodular curve $X_0(N)$ by the full group of Atkin-Lehner involutions has\npositive genus. We establish an integrality result for the $j$-invariants of\nnon-cuspidal rational points on $X_0(N)^*$, representing a significant step\ntoward resolving a key subcase of Elkies' conjecture. To this end, we prove the\nexistence of rank-zero quotients of certain modular Jacobians $J_0(pq)$.\nFurthermore, we provide a conjecturally complete classification of the rational\npoints on $X_0(N)^*$ of genus $1 \\leq g \\leq 5$. In the process we identify\nexceptional rational points on $X_0(147)^*$ and $X_0(75)^*$ which were not\nknown before.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-05-01T17:39:18Z"}
{"aid":"http://arxiv.org/abs/2505.00683v1","title":"Quantum Circuit Overhead","summary":"We introduce a measure for evaluating the efficiency of finite universal\nquantum gate sets $\\mathcal{S}$, called the Quantum Circuit Overhead (QCO), and\nthe related notion of $T$-Quantum Circuit Overhead ($T$-QCO). The overhead is\nbased on the comparison between the efficiency of $\\mathcal{S}$ versus the\noptimal efficiency among all gate sets with the same number of gates. We\ndemonstrate the usefulness of the ($T$-)QCO by extensive numerical calculations\nof its upper bounds, providing insight into the efficiency of various choices\nof single-qubit $\\mathcal{S}$, including Haar-random gate sets and the gate\nsets derived from finite subgroups, such as Clifford and Hurwitz groups. In\nparticular, our results suggest that, in terms of the upper bounds on the\n$T$-QCO, the famous T gate is a highly non-optimal choice for the completion of\nthe Clifford gate set, even among the gates of order 8. We identify the optimal\nchoices of such completions for both finite subgroups.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-05-01T17:43:33Z"}
{"aid":"http://arxiv.org/abs/2505.00692v1","title":"Multi-wavelength JWST observations of (3200) Phaethon show a dehydrated\n  object with an aqueously altered origin","summary":"We present JWST observations of the near-Earth asteroid (3200) Phaethon using\nthe Near-Infrared Camera (NIRCam), Near-Infrared Spectrograph (NIRSpec), and\nMid-Infrared Instrument (MIRI) to further investigate the composition of\nPhaethon's surface. Our NIRSpec data confirms that Phaethon's surface is\ndehydrated, showing no evidence of hydrated minerals in the 3-$\\mu$m region. We\nestimate an upper limit on the hydrogen content in phyllosilicates of 0.06 wt%.\nComparisons with laboratory spectra of carbonaceous chondrites suggest that\nPhaethon's surface composition is best matched by thermally metamorphosed\nsamples of the CM chondrite Murchison (heated to 1000$^{\\circ}$C), rather than\nCY meteorites as previous work suggested. We find no evidence of ongoing\nsurface evolution due to recent perihelion passages. A comparison of the\nmid-infrared spectra of Phaethon and Bennu shows distinct spectral differences\nthat are consistent with their different thermal histories. Our findings\nfurther refine our understanding of Phaethon's current surface composition and\nevolution and provide additional insights for the upcoming DESTINY+ mission.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-05-01T17:54:35Z"}
{"aid":"http://arxiv.org/abs/2505.07192v1","title":"Bifurcations of synchronized solutions in a continuum limit of the\n  Kuramoto model with two-mode interaction depending on two graphs","summary":"We study bifurcations of the completely synchronized state in a continuum\nlimit (CL) for the Kuramoto model (KM) of identical oscillators with two-mode\ninteraction depending on two graphs. Here one of the graphs is uniform but may\nbe deterministic dense, random dense or random sparse, and the other is a\ndeterministic finite nearest neighbor. We use the center manifold reduction\ntechnique, which is a standard one in dynamical systems, and prove that the CL\nsuffers bifurcations at which the one-parameter family of completely\nsynchronized state becomes unstable and a stable two-parameter family of\n$\\ell$-humped sinusoidal shape stationary solutions ($\\ell\\ge 2$) appears,\nwhere $n$ represents the node number. This contrasts the author's recent result\non the classical KM in which bifurcation behavior in its CL is very different\nfrom ones in the KM and difficult to explain by standard techniques in\ndynamical systems such as the center manifold reduction. Moreover, similar\nbifurcation behavior is shown to occur in the KM, based on the previous\nfundamental results. The occurrence of such bifurcations were suggested by\nnumerical simulations for the deterministic graphs in a previous study. We also\ndemonstrate our theoretical results by numerical simulations for the KM with\nthe zero natural frequency.","main_category":"math.DS","categories":"math.DS","published":"2025-05-12T02:46:22Z"}
{"aid":"http://arxiv.org/abs/2505.07202v1","title":"On the Cost and Benefits of Training Context with Utterance or Full\n  Conversation Training: A Comparative Stud","summary":"Modern TTS systems designed for conversations achieve high-quality utterances\nbut often remain inaccessible publicly. Are existing open-source architectures\ninadequate, or are current training techniques insufficient? This paper\ninvestigates prominent models and their underlying behaviors regarding\nconversational context. Using 20 GPU-hours on an NVIDIA H100, we empirically\nexamine two approaches: context-based utterance-level training versus full\nconversation training. Results demonstrate that context-based utterance\ntraining achieves superior MOS scores (4.3/5.0 vs 3.7/5.0) and reduces training\ntime by 37%, while full conversation approaches suffer from speaker similarity\nhallucination issues. These findings provide practical guidelines for\nconversational TTS development, favoring utterance-level training with\ncontextual conditioning for both resource efficiency and output quality.","main_category":"cs.CL","categories":"cs.CL,cs.SD,eess.AS","published":"2025-05-12T03:19:55Z"}
{"aid":"http://arxiv.org/abs/2505.07209v1","title":"Discovering Fine-Grained Visual-Concept Relations by Disentangled\n  Optimal Transport Concept Bottleneck Models","summary":"Concept Bottleneck Models (CBMs) try to make the decision-making process\ntransparent by exploring an intermediate concept space between the input image\nand the output prediction. Existing CBMs just learn coarse-grained relations\nbetween the whole image and the concepts, less considering local image\ninformation, leading to two main drawbacks: i) they often produce spurious\nvisual-concept relations, hence decreasing model reliability; and ii) though\nCBMs could explain the importance of every concept to the final prediction, it\nis still challenging to tell which visual region produces the prediction. To\nsolve these problems, this paper proposes a Disentangled Optimal Transport CBM\n(DOT-CBM) framework to explore fine-grained visual-concept relations between\nlocal image patches and concepts. Specifically, we model the concept prediction\nprocess as a transportation problem between the patches and concepts, thereby\nachieving explicit fine-grained feature alignment. We also incorporate\northogonal projection losses within the modality to enhance local feature\ndisentanglement. To further address the shortcut issues caused by statistical\nbiases in the data, we utilize the visual saliency map and concept label\nstatistics as transportation priors. Thus, DOT-CBM can visualize inversion\nheatmaps, provide more reliable concept predictions, and produce more accurate\nclass predictions. Comprehensive experiments demonstrate that our proposed\nDOT-CBM achieves SOTA performance on several tasks, including image\nclassification, local part detection and out-of-distribution generalization.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T03:31:57Z"}
{"aid":"http://arxiv.org/abs/2505.07210v1","title":"Generation of magnetic chiral solitons, skyrmions, and hedgehogs with\n  electric fields","summary":"Electric-field controls of Dzyaloshinskii-Moriya interactions (DMIs) have\nrecently been discussed from the microscopic viewpoint. Since the DMI plays a\ncritical role in generating topological spin textures (TSTs) such as the chiral\nsoliton, the magnetic skyrmion, and the magnetic hedgehog, electric-field\ncontrols of these TSTs have become an important issue. This paper shows that\nsuch electric-field-induced DMI indeed creates and annihilates TSTs by\nnumerically solving the Landau-Lifshitz-Gilbert (LLG) equation for many-body\nspin systems at finite temperatures. We show that when a strong electric field\nis applied in a proper way to one- or two-dimensional ferromagnets, the\nHamiltonians are changed into the well-known spin models for the chiral soliton\nor the skyrmion lattice, and the TST states emerge. We utilize a\nmachine-learning method to count the number of generated TSTs. In the\nthree-dimensional (3D) case, we demonstrate the electric-field induction of a\nmagnetic hedgehog structure as follows: Applying a strong enough electric field\nalong a proper direction to a skyrmion-string state (a triple-$\\boldsymbol{q}$\nstate) at low but finite temperatures, we find that the field-induced DMI can\ndrive a quadruple-$\\boldsymbol{q}$ state with hedgehog-antihedgehog pairs. This\nresult indicates that we have succeeded in constructing a simple 3D short-range\ninteracting spin model hosting a magnetic hedgehog structure.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,cond-mat.stat-mech","published":"2025-05-12T03:37:11Z"}
{"aid":"http://arxiv.org/abs/2505.07213v1","title":"Evolution of cooperation and competition in multilayer networks","summary":"Cooperation and competition coexist and coevolve in natural and social\nsystems. Cooperation generates resources, which in turn, drive non-cooperative\ncompetition to secure individual shares. How this complex interplay between\ncooperation and competition shapes the evolution of social dilemmas and welfare\nremains unknown. In this study, we introduce a two-layer evolutionary game\nmodel, in which one layer is a cooperative public goods game, and the other is\na competitive involution game, with cross-layer feedback linking the two. We\nfind that feedback can either promote or inhibit cooperation, depending on the\nbaseline conditions. For example, moderate resource and synergy factor values\ncan promote social welfare when feedback strength is large. This provides an\napproach to adjusting the strength and asymmetry of cross-layer feedback to\npromote cooperation and social welfare. We thus emphasize the importance of\nmanaging feedback mechanisms to balance cooperation and competition in complex\nsocial systems.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO,physics.comp-ph","published":"2025-05-12T03:46:09Z"}
{"aid":"http://arxiv.org/abs/2505.07220v1","title":"OAM spatial demultiplexing by diffraction-based noiseless mode\n  conversion with axicon","summary":"The physics of orbital angular momentum (OAM) carrying light has been\nwell-defined since the 1990s. Leveraging its physical phenomena has become a\nsignificant focus in various areas of research. For instance, OAM is applied in\nhybrid free-space optical communication channels, like wavelength division\nmultiplexing. Due to its orthogonality, OAM can be multiplexed and\ndemultiplexed, enabling the use of multiple orthogonal OAM beams to achieve\nhigh-capacity optical communication systems. In this appliance, there will be\ninstability of light because its phase distribution is quite complicated. This\nstudy focuses on spatial demultiplexing using Computer Generated Holography\n(CGH) based OAM diffraction. Earlier research on OAM diffraction primarily\ninvolved fork gratings. Spatial demultiplexing has phase distribution\ninstability and noise problems in free space optics. Axicons have been studied\nextensively in the context of perfect vortex generation. Drawing inspiration\nfrom these two areas of physics, we propose a noiseless topological charge\nconversion through axicon properties in spatial demultiplexing using CGH.\nFurthermore, we estimate the axicon optical approximate solution that is\nappropriate for research purposes.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-05-12T04:20:57Z"}
{"aid":"http://arxiv.org/abs/2505.07224v1","title":"Geometry of Almost-Conserved Quantities in Symplectic Maps. Part II:\n  Recovery of approximate invariant","summary":"Noether's theorem, which connects continuous symmetries to exact conservation\nlaws, remains one of the most fundamental principles in physics and dynamical\nsystems. In this work, we draw a conceptual parallel between two paradigms: the\nemergence of exact invariants from continuous symmetries, and the appearance of\napproximate invariants from discrete symmetries associated with reversibility\nin symplectic maps. We demonstrate that by constructing approximating functions\nthat preserve these discrete symmetries order by order, one can systematically\nuncover hidden structures, closely echoing Noether's framework. The resulting\nfunctions serve not only as diagnostic tools but also as compact\nrepresentations of near-integrable behavior.\n  The second article applies the method to global dynamics, with a focus on\nlarge-amplitude motion and chaotic systems. We demonstrate that the approximate\ninvariants, once averaged, accurately capture the structure of resonances and\nthe boundaries of stability regions. We also explore the recovery of exact\ninvariants in integrable cases, showing that the method reproduces the correct\nbehavior when such structure is present. A single unified function, derived\nfrom the map coefficients, yields phase portraits, rotation numbers, and tune\nfootprints that closely match numerical tracking across wide parameter ranges.\nComparisons with the Square Matrix method reveal that while both approaches\nsatisfy local constraints, our technique provides greater accuracy and\nrobustness in resonant and strongly nonlinear regimes. These results highlight\nthe method's practical power and broad relevance, offering a compact, analytic\nframework for organizing nonlinear dynamics in symplectic maps with direct\napplications to beam physics and beyond.","main_category":"nlin.CD","categories":"nlin.CD,nlin.PS,physics.acc-ph,physics.app-ph","published":"2025-05-12T04:37:52Z"}
{"aid":"http://arxiv.org/abs/2505.07228v1","title":"Nakai-Moishezon criteria and the toric Thomas-Yau conjecture","summary":"We consider a class of Lagrangian sections $L$ contained in certain\nCalabi-Yau Lagrangian fibrations (mirrors of toric weak Fano manifolds). We\nprove that a form of the Thomas-Yau conjecture holds in this case: $L$ is\nHamiltonian isotopic to a special Lagrangian section in this class if and only\nif a stability condition holds, in the sense of a slope inequality on objects\nin a set of exact triangles in the Fukaya-Seidel category. This agrees with\ngeneral proposals by Li. We use the SYZ transform, the toric gamma theorem, and\ntoric homological mirror symmetry in order to reduce the statement to one about\nsupercritical deformed Hermitian Yang-Mills connections, known as the\nNakai-Moishezon criterion. As an application, we prove that, on the mirror of a\ntoric weak del Pezzo surface, if $L$ defines a Bridgeland stable object in the\nFukaya-Seidel category in a natural sense, then it is Hamiltonian isotopic to a\nspecial Lagrangian section in the class. The converse also holds in the example\ngiven by the blowup of the projective plane at a point. This is consistent with\ngeneral conjectures due to Joyce. We discuss some generalisations, including a\nweaker analogue of our main result for general projective toric manifolds, and\na similar obstruction, related to Lagrangian multi-sections, in a special case.","main_category":"math.DG","categories":"math.DG,math.AG,math.SG","published":"2025-05-12T04:59:09Z"}
{"aid":"http://arxiv.org/abs/2505.07231v1","title":"Mean Field Portfolio Games with Epstein-Zin Preferences","summary":"We study mean field portfolio games under Epstein-Zin preferences, which\nnaturally encompass the classical time-additive power utility as a special\ncase. In a general non-Markovian framework, we establish a uniqueness result by\nproving a one-to-one correspondence between Nash equilibria and the solutions\nto a class of BSDEs. A key ingredient in our approach is a necessary stochastic\nmaximum principle tailored to Epstein-Zin utility and a nonlinear\ntransformation. In the deterministic setting, we further derive an explicit\nclosed-form solution for the equilibrium investment and consumption policies.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-05-12T05:06:59Z"}
{"aid":"http://arxiv.org/abs/2505.07243v1","title":"A Black-box Testing Framework for Oracle Quantum Programs","summary":"Oracle quantum programs are a fundamental class of quantum programs that\nserve as a critical bridge between quantum computing and classical computing.\nMany important quantum algorithms are built upon oracle quantum programs,\nmaking it essential to ensure their correctness during development. While\nsoftware testing is a well-established approach for improving program\nreliability, no systematic method has been developed to test oracle quantum\nprograms. This paper proposes a black-box testing framework designed for\ngeneral oracle quantum programs. We define these programs formally, establish\nthe foundational theory for their testing, and propose a detailed testing\nframework. We develop a prototype tool and conduct extensive experimental\nevaluations to evaluate the framework's effectiveness. Our results demonstrate\nthat the proposed framework significantly aids developers in testing oracle\nquantum programs, providing insights to enhance the reliability of quantum\nsoftware.","main_category":"cs.SE","categories":"cs.SE,quant-ph","published":"2025-05-12T05:31:55Z"}
{"aid":"http://arxiv.org/abs/2505.07258v1","title":"No Query, No Access","summary":"Textual adversarial attacks mislead NLP models, including Large Language\nModels (LLMs), by subtly modifying text. While effective, existing attacks\noften require knowledge of the victim model, extensive queries, or access to\ntraining data, limiting real-world feasibility. To overcome these constraints,\nwe introduce the \\textbf{Victim Data-based Adversarial Attack (VDBA)}, which\noperates using only victim texts. To prevent access to the victim model, we\ncreate a shadow dataset with publicly available pre-trained models and\nclustering methods as a foundation for developing substitute models. To address\nthe low attack success rate (ASR) due to insufficient information feedback, we\npropose the hierarchical substitution model design, generating substitute\nmodels to mitigate the failure of a single substitute model at the decision\nboundary.\n  Concurrently, we use diverse adversarial example generation, employing\nvarious attack methods to generate and select the adversarial example with\nbetter similarity and attack effectiveness. Experiments on the Emotion and SST5\ndatasets show that VDBA outperforms state-of-the-art methods, achieving an ASR\nimprovement of 52.08\\% while significantly reducing attack queries to 0. More\nimportantly, we discover that VDBA poses a significant threat to LLMs such as\nQwen2 and the GPT family, and achieves the highest ASR of 45.99% even without\naccess to the API, confirming that advanced NLP models still face serious\nsecurity risks. Our codes can be found at\nhttps://anonymous.4open.science/r/VDBA-Victim-Data-based-Adversarial-Attack-36EC/","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-12T06:19:59Z"}
{"aid":"http://arxiv.org/abs/2505.07260v1","title":"UMoE: Unifying Attention and FFN with Shared Experts","summary":"Sparse Mixture of Experts (MoE) architectures have emerged as a promising\napproach for scaling Transformer models. While initial works primarily\nincorporated MoE into feed-forward network (FFN) layers, recent studies have\nexplored extending the MoE paradigm to attention layers to enhance model\nperformance. However, existing attention-based MoE layers require specialized\nimplementations and demonstrate suboptimal performance compared to their\nFFN-based counterparts. In this paper, we aim to unify the MoE designs in\nattention and FFN layers by introducing a novel reformulation of the attention\nmechanism, revealing an underlying FFN-like structure within attention modules.\nOur proposed architecture, UMoE, achieves superior performance through\nattention-based MoE layers while enabling efficient parameter sharing between\nFFN and attention components.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-12T06:21:44Z"}
{"aid":"http://arxiv.org/abs/2505.07291v1","title":"INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized\n  Reinforcement Learning","summary":"We introduce INTELLECT-2, the first globally distributed reinforcement\nlearning (RL) training run of a 32 billion parameter language model. Unlike\ntraditional centralized training efforts, INTELLECT-2 trains a reasoning model\nusing fully asynchronous RL across a dynamic, heterogeneous swarm of\npermissionless compute contributors.\n  To enable a training run with this unique infrastructure, we built various\ncomponents from scratch: we introduce PRIME-RL, our training framework\npurpose-built for distributed asynchronous reinforcement learning, based on top\nof novel components such as TOPLOC, which verifies rollouts from untrusted\ninference workers, and SHARDCAST, which efficiently broadcasts policy weights\nfrom training nodes to inference workers.\n  Beyond infrastructure components, we propose modifications to the standard\nGRPO training recipe and data filtering techniques that were crucial to achieve\ntraining stability and ensure that our model successfully learned its training\nobjective, thus improving upon QwQ-32B, the state of the art reasoning model in\nthe 32B parameter range.\n  We open-source INTELLECT-2 along with all of our code and data, hoping to\nencourage and enable more open research in the field of decentralized training.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-05-12T07:24:33Z"}
{"aid":"http://arxiv.org/abs/2505.07303v1","title":"Online Episodic Convex Reinforcement Learning","summary":"We study online learning in episodic finite-horizon Markov decision processes\n(MDPs) with convex objective functions, known as the concave utility\nreinforcement learning (CURL) problem. This setting generalizes RL from linear\nto convex losses on the state-action distribution induced by the agent's\npolicy. The non-linearity of CURL invalidates classical Bellman equations and\nrequires new algorithmic approaches. We introduce the first algorithm achieving\nnear-optimal regret bounds for online CURL without any prior knowledge on the\ntransition function. To achieve this, we use an online mirror descent algorithm\nwith varying constraint sets and a carefully designed exploration bonus. We\nthen address for the first time a bandit version of CURL, where the only\nfeedback is the value of the objective function on the state-action\ndistribution induced by the agent's policy. We achieve a sub-linear regret\nbound for this more challenging problem by adapting techniques from bandit\nconvex optimization to the MDP setting.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-05-12T07:47:49Z"}
{"aid":"http://arxiv.org/abs/2505.07322v1","title":"RealRep: Generalized SDR-to-HDR Conversion with Style Disentangled\n  Representation Learning","summary":"High-Dynamic-Range Wide-Color-Gamut (HDR-WCG) technology is becoming\nincreasingly prevalent, intensifying the demand for converting Standard Dynamic\nRange (SDR) content to HDR. Existing methods primarily rely on fixed tone\nmapping operators, which are inadequate for handling SDR inputs with diverse\nstyles commonly found in real-world scenarios. To address this challenge, we\npropose a generalized SDR-to-HDR method that handles diverse styles in\nreal-world SDR content, termed Realistic Style Disentangled Representation\nLearning (RealRep). By disentangling luminance and chrominance, we analyze the\nintrinsic differences between contents with varying styles and propose a\ndisentangled multi-view style representation learning method. This approach\ncaptures the guidance prior of true luminance and chrominance distributions\nacross different styles, even when the SDR style distributions exhibit\nsignificant variations, thereby establishing a robust embedding space for\ninverse tone mapping. Motivated by the difficulty of directly utilizing\ndegradation representation priors, we further introduce the Degradation-Domain\nAware Controlled Mapping Network (DDACMNet), a two-stage framework that\nperforms adaptive hierarchical mapping guided by a control-aware normalization\nmechanism. DDACMNet dynamically modulates the mapping process via\ndegradation-conditioned hierarchical features, enabling robust adaptation\nacross diverse degradation domains. Extensive experiments show that RealRep\nconsistently outperforms state-of-the-art methods with superior generalization\nand perceptually faithful HDR color gamut reconstruction.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T08:08:58Z"}
{"aid":"http://arxiv.org/abs/2505.07327v1","title":"Nonrelativistic Piezomagnetic Effect in an Organic Altermagnet","summary":"We theoretically study the piezomagnetic effect on the altermagnetic state in\n$\\kappa$-type molecular conductors, focusing on its nonrelativistic mechanism.\nBy introducing shear stress as a monoclinic distortion, we evaluate variations\nin the effective tight-binding model using first-principles calculations. Using\nthe derived parameters, we investigate the Hubbard model and its effective\nHeisenberg model on the two-dimensional (distorted) $\\kappa$-type lattice\nwithin mean-field approximation. We show that the system exhibits the\npiezomagnetic effect, i.e., a net magnetization induced at finite temperatures\nin the undoped insulating state and both in the ground state and at finite\ntemperatures upon doping. In a real-space picture, this uniform magnetization\narises from the ferrimagnetic spin structure due to inequivalent spin sites\ninduced by lattice distortion. Meanwhile, in a momentum-space picture, it stems\nfrom the {\\it s}-wave spin splitting of the electron and magnon bands,\nindependent of spin-orbit coupling. We find that this nonrelativistic\npiezomagnetism remains finite, but becomes smaller in the limit of strong\ndimerization where the energy gap between the bonding and antibonding orbitals\nis infinitely large and the {\\it d}-wave altermagnetic spin splitting is\nabsent, highlighting the importance of the multi-orbital nature.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-05-12T08:13:40Z"}
{"aid":"http://arxiv.org/abs/2505.07342v1","title":"Rough Burger-like SPDEs","summary":"By applying the theory of rough paths, Martin Hairer provided a notion of\nsolution for a class of nonlinear stochastic partial differential equations\n(SPDEs) of Burgers type, driven by additive space-time white noise in one\nspatial dimension. These equations exhibit spatial roughness that is too severe\nfor classical analytical techniques to handle. Hairer developed a pathwise\nframework for solutions when the spatial regularity of the solution lies in the\nrange $(\\frac{1}{3},\\frac{1}{2}]$. In this paper, we extend Hairer's result by\nlowering the spatial regularity to the range $(\\frac{1}{4},\\frac{1}{3}]$.\nSpecifically, we establish the pathwise existence and uniqueness of mild (and,\nequivalently, weak) solutions to Burgers-type SPDEs under this lower spatial\nregularity regime.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-05-12T08:30:09Z"}
{"aid":"http://arxiv.org/abs/2505.07344v1","title":"Generative Pre-trained Autoregressive Diffusion Transformer","summary":"In this work, we present GPDiT, a Generative Pre-trained Autoregressive\nDiffusion Transformer that unifies the strengths of diffusion and\nautoregressive modeling for long-range video synthesis, within a continuous\nlatent space. Instead of predicting discrete tokens, GPDiT autoregressively\npredicts future latent frames using a diffusion loss, enabling natural modeling\nof motion dynamics and semantic consistency across frames. This continuous\nautoregressive framework not only enhances generation quality but also endows\nthe model with representation capabilities. Additionally, we introduce a\nlightweight causal attention variant and a parameter-free rotation-based\ntime-conditioning mechanism, improving both the training and inference\nefficiency. Extensive experiments demonstrate that GPDiT achieves strong\nperformance in video generation quality, video representation ability, and\nfew-shot learning tasks, highlighting its potential as an effective framework\nfor video modeling in continuous space.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-12T08:32:39Z"}
{"aid":"http://arxiv.org/abs/2505.07345v1","title":"QUPID: Quantified Understanding for Enhanced Performance, Insights, and\n  Decisions in Korean Search Engines","summary":"Large language models (LLMs) have been widely used for relevance assessment\nin information retrieval. However, our study demonstrates that combining two\ndistinct small language models (SLMs) with different architectures can\noutperform LLMs in this task. Our approach -- QUPID -- integrates a generative\nSLM with an embedding-based SLM, achieving higher relevance judgment accuracy\nwhile reducing computational costs compared to state-of-the-art LLM solutions.\nThis computational efficiency makes QUPID highly scalable for real-world search\nsystems processing millions of queries daily. In experiments across diverse\ndocument types, our method demonstrated consistent performance improvements\n(Cohen's Kappa of 0.646 versus 0.387 for leading LLMs) while offering 60x\nfaster inference times. Furthermore, when integrated into production search\npipelines, QUPID improved nDCG@5 scores by 1.9%. These findings underscore how\narchitectural diversity in model combinations can significantly enhance both\nsearch relevance and operational efficiency in information retrieval systems.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR","published":"2025-05-12T08:35:09Z"}
{"aid":"http://arxiv.org/abs/2505.07346v1","title":"Unraveling the Reaction Mechanisms in a Chemically Amplified EUV\n  Photoresist from a Combined Theoretical and Experimental Approach","summary":"Extreme ultraviolet (EUV) lithography has revolutionized high-volume\nmanufacturing of nanoscale components, enabling the production of smaller,\ndenser, and more energy efficient integrated circuit devices. Yet, the use of\nEUV light results in ionization driven chemistry within the imaging materials\nof lithography, the photoresists. The complex interplay of ionization,\ngeneration of primary and secondary electrons, and the subsequent chemical\nmechanisms leading to image formation in photoresists has been notoriously\ndifficult to study. In this work, we deploy photoemission spectroscopy with a\n92 eV EUV light source combined with first-principles simulations to unravel\nthe chemical changes occurring during exposure in a model chemically amplified\nphotoresist. The results reveal a surprising chemical reaction pathway, namely\nthe EUV-induced breakdown of the photoacid generator (PAG), which is a critical\ncomponent in the EUV mechanism. This previously unobserved reaction mechanism\nmanifests as changes in intensity of the valence band peaks of the EUV\nphotoemission spectrum, which are linked to degradation of the PAG via an\nadvanced atomistic simulation framework. Our combined experimental and\ntheoretical approach shows that EUV photoemission can simultaneously resolve\nchemical dynamics and the production of primary and secondary electrons, giving\nunique insights into the chemical transformation of photoresist materials. Our\nresults pave the way for utilizing accessible, table-top EUV spectroscopy\nsystems for observing EUV photoresist chemical dynamics, with the potential for\ntime-resolved measurements of photoemission processes in the future.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-12T08:36:16Z"}
{"aid":"http://arxiv.org/abs/2505.07354v1","title":"Time Perception in Virtual Reality: Effects of Emotional Valence and\n  Stress Level","summary":"Background & Objective: Emotional states and stress distort time perception,\nyet findings are inconsistent, particularly in immersive media. Integrating the\nAttentional Gate Model (AGM) and Internal Clock Model (ICM), we examined how\nemotional valence and stress alter perceived duration in Virtual Reality (VR).\nThis study assesses the effects of valence (calming, neutral, stressful) and\nstress (low/high) on prospective time estimation, mood, and arousal. Methods:\nFifty-four adults (18-39 years) explored three custom VR environments: (1) a\ntranquil Japanese garden, (2) an affectively neutral room, and (3) a\nthreatening underground sewer. Active navigation promoted presence; a\ndistraction task separated conditions. Valence and arousal were assessed with\nthe Visual Analog Mood Scales, stress with the Perceived Stress Scale-10\n(PSS-10), and perceived duration with a verbal estimation task. Mixed-model\nANOVAs evaluated main and interaction effects. Results: Valence reliably shaped\nperceived duration: calming VR led to overestimation, stressful VR to\nunderestimation, and neutral VR to intermediate timing. Baseline stress level,\nas measured by PSS-10, neither altered timing nor interacted with valence.\nNevertheless, the VR environments affected VAMS' mood metrics: calming\nenvironments elevated mood and reduced perceived stress, whereas stressful\nenvironments lowered mood and heightened stress. Conclusions: Findings support\nthe AGM-attentionally demanding negative environments shorten perceived\ntime-and the ICM-valence-linked arousal speeds or slows the pacemaker. Contrary\nto classical predictions, in VR, baseline stress did not distort duration,\nsuggesting valence-driven attentional allocation outweighs pre-exposure stress\nlevels. VR offers a controllable platform for dissecting time-perception\nmechanisms and advancing interventions that target emotion-related temporal\ndistortions.","main_category":"cs.HC","categories":"cs.HC","published":"2025-05-12T08:45:55Z"}
{"aid":"http://arxiv.org/abs/2505.07362v1","title":"High Performance Signal Design for ACO-OFDM Systems using Variational\n  Autoencoder","summary":"This letter proposes a design of low peak-to-average power ratio (PAPR), low\nsymbol error rate (SER), and high data rate signal for asymmetrically clipped\noptical orthogonal frequency division multiplexing (ACO-OFDM) systems. The\nproposed design leverages a variational autoencoder (VAE) incorporating gradual\nloss learning to jointly optimize the geometry and probability of the\nconstellation's symbols. This not only enhances mutual information (MI) but\nalso effectively reduces the PAPR while maintaining a low SER for reliable\ntransmission. We evaluate the performance of the proposed VAE-based design by\ncomparing the MI, SER, and PAPR against existing techniques. Simulation results\ndemonstrate that the proposed method achieves a considerably lower PAPR while\nmaintaining superior SER and MI performance for a wide range of SNRs.","main_category":"eess.SY","categories":"eess.SY,cs.SY,eess.SP","published":"2025-05-12T08:57:29Z"}
{"aid":"http://arxiv.org/abs/2505.07365v1","title":"Multi-Domain Audio Question Answering Toward Acoustic Content Reasoning\n  in The DCASE 2025 Challenge","summary":"We present Task 5 of the DCASE 2025 Challenge: an Audio Question Answering\n(AQA) benchmark spanning multiple domains of sound understanding. This task\ndefines three QA subsets (Bioacoustics, Temporal Soundscapes, and Complex QA)\nto test audio-language models on interactive question-answering over diverse\nacoustic scenes. We describe the dataset composition (from marine mammal calls\nto soundscapes and complex real-world clips), the evaluation protocol (top-1\naccuracy with answer-shuffling robustness), and baseline systems\n(Qwen2-Audio-7B, AudioFlamingo 2, Gemini-2-Flash). Preliminary results on the\ndevelopment set are compared, showing strong variation across models and\nsubsets. This challenge aims to advance the audio understanding and reasoning\ncapabilities of audio-language models toward human-level acuity, which are\ncrucial for enabling AI agents to perceive and interact about the world\neffectively.","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.CL,cs.MM,eess.AS","published":"2025-05-12T09:04:16Z"}
{"aid":"http://arxiv.org/abs/2505.07368v1","title":"Irreducible Killing and conformal Killing tensors on homogeneous plane\n  waves","summary":"This paper presents a classification of irreducible Killing and conformal\nKilling 2-tensors on homogeneous plane waves, a specific class of Lorentzian\nmetrics on four-dimensional manifolds. Using the framework of BGG operators, we\nderive explicit formulae for these tensors and identify the conditions under\nwhich they exist.","main_category":"math.DG","categories":"math.DG,math-ph,math.MP","published":"2025-05-12T09:09:23Z"}
{"aid":"http://arxiv.org/abs/2505.07371v1","title":"Single-atom imaging of ${}^{173}$Yb in optical tweezers loaded by a\n  five-beam magneto-optical trap","summary":"We report on the trapping and imaging of individual ytterbium atoms in arrays\nof optical tweezers, loaded from a magneto-optical trap (MOT) formed by only\nfive beams in an orthogonal configuration. In our five-beam MOT, operating on\nthe narrow ${}^1$S${}_0 \\rightarrow {}^3$P${}_1$ intercombination transition,\ngravity balances the radiation pressure of a single upward-directed beam. This\napproach enables efficient trapping and cooling of the most common ytterbium\nisotopes (${}^{171}$Yb, ${}^{173}$Yb and ${}^{174}$Yb) to $\\lesssim 20\\,\\mu$K\nat densities $\\sim 10^{11}$ atoms/cm$^3$ within less than one second. This\nconfiguration allows for significantly reducing the complexity of the optical\nsetup, potentially benefiting any ytterbium-atom based quantum science platform\nleveraging single-atom microscopy, from quantum processors to novel optical\nclocks. We then demonstrate the first single-atom-resolved imaging of the\nfermionic, large-spin isotope ${}^{173}$Yb ($I=5/2$), employing a two-color\nimaging scheme that does not rely on magic-wavelength trapping. We achieve a\nhigh single-atom imaging fidelity of $99.96(1)\\%$ and a large survival\nprobability of $98.5(2)\\%$, despite large differential light shifts affecting\nall nuclear spin sublevels of the excited ${}^3$P${}_1$ state involved in the\ncooling transition. The demonstrated capabilities will play a key role in\nfuture quantum simulations and computing applications with ${}^{173}$Yb arrays.","main_category":"physics.atom-ph","categories":"physics.atom-ph,cond-mat.quant-gas,quant-ph","published":"2025-05-12T09:14:02Z"}
{"aid":"http://arxiv.org/abs/2505.07379v1","title":"Measuring choriocapillaris blood flow with laser Doppler optical\n  coherence tomography","summary":"We report on using a laser Doppler processing of Fourier-domain optical\ncoherence tomography (OCT) data for the assessment of pulsatile blood flow in\nthe choriocapillaris. Signal fluctuations in B-scans recorded at 2 kHz were\nanalyzed by Fourier transform to extract blood flow information. The spectral\nbroadening of light backscattered by the choriocapillaris was used to derive a\nchoriocapillaris flow velocity index in physical units, with sufficient\ntemporal resolution to capture heartbeat-induced variations. Furthermore, the\nasymmetry in the spectral broadening enabled us to determine the axial\ndirection of blood flow with high sensitivity, allowing for the detection of\nflow orientation in retinal capillaries. This approach is promising as it can\nbe directly implemented on widely available fast-scanning Fourier-domain OCT\ninstruments.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-12T09:25:42Z"}
{"aid":"http://arxiv.org/abs/2505.07383v1","title":"Some insights into depth estimators for location and scatter in the\n  multivariate setting","summary":"The concept of statistical depth has received considerable attention as a way\nto extend the notions of the median and quantiles to other statistical models.\nThese procedures aim to formalize the idea of identifying deeply embedded fits\nto a model that are less influenced by contamination. Since contamination\nintroduces bias in estimators, it is well known in the location model that the\nmedian minimizes the worst-case performance, in terms of maximum bias, among\nall equivariant estimators. In the multivariate case, Tukey's median was a\ngroundbreaking concept for location estimation, and its counterpart for scatter\nmatrices has recently attracted considerable interest. The breakdown point and\nthe maximum asymptotic bias are key concepts used to summarize an estimator's\nbehavior under contamination. For the location and scale model, we consider two\nclosely related depth formulations, whose deepest estimators display\nsignificantly different behavior in terms of breakdown point. In the\nmultivariate setting, we analyze recently introduced concentration inequalities\nthat provide a unified framework for studying both the statistical convergence\nrate and robustness of Tukey's median and depth-based scatter matrices. We\nobserve that slight variations in these inequalities allow us to visualize the\nmaximum bias behavior of the deepest estimators. Since the maximum bias for\ndepth-based scatter matrices had not previously been derived, we explicitly\ncalculate both the breakdown point and the maximum bias curve for the deepest\nscatter matrices.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-05-12T09:29:11Z"}
{"aid":"http://arxiv.org/abs/2505.07388v1","title":"Resolution Studies for Future DIRC Detectors","summary":"The resolution of Cherenkov detectors using the DIRC method is mainly limited\nby three components: photon loss due to steep angles of incidence, dispersion\neffects, and angle straggling due to the Coulomb interaction of the charged\nparticle. This paper highlights the general limitations of any generic DIRC\ndetector, based on studies for the proposed experiments PANDA in Darmstadt and\nSCTF in Russia. These studies used theoretical calculations and simplified\nMonte-Carlo simulations to obtain an upper limit of all individual resolution\nparameters. Therefore, they can be used for feasibility studies in future\ndetector developments.","main_category":"hep-ex","categories":"hep-ex","published":"2025-05-12T09:33:25Z"}
{"aid":"http://arxiv.org/abs/2505.07393v1","title":"AI in Money Matters","summary":"In November 2022, Europe and the world by and large were stunned by the birth\nof a new large language model : ChatGPT. Ever since then, both academic and\npopulist discussions have taken place in various public spheres such as\nLinkedIn and X(formerly known as Twitter) with the view to both understand the\ntool and its benefits for the society. The views of real actors in professional\nspaces, especially in regulated industries such as finance and law have been\nlargely missing. We aim to begin to close this gap by presenting results from\nan empirical investigation conducted through interviews with professional\nactors in the Fintech industry. The paper asks the question, how and to what\nextent are large language models in general and ChatGPT in particular being\nadopted and used in the Fintech industry? The results show that while the\nfintech experts we spoke with see a potential in using large language models in\nthe future, a lot of questions marks remain concerning how they are policed and\ntherefore might be adopted in a regulated industry such as Fintech. This paper\naims to add to the existing academic discussing around large language models,\nwith a contribution to our understanding of professional viewpoints.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-05-12T09:43:51Z"}
{"aid":"http://arxiv.org/abs/2505.07394v1","title":"Correlated electronic structure of the alternating single-layer bilayer\n  nickelate La$_{5}$Ni$_{3}$O$_{11}$","summary":"The recent discovery of superconductivity under pressure in Ruddlesden-Popper\n(RP) nickelates has attracted a great deal of attention. Here, using\ndensity-functional theory plus dynamical mean-field theory, we study the\ncorrelated electronic structure of the latest superconducting member of the\nfamily: the alternating single-layer bilayer nickelate\nLa$_{5}$Ni$_{3}$O$_{11}$. Due to its alternating single-layer and bilayer\nstructural motif, this hybrid RP nickelate exhibits layer-selective physics\nwith the single-layer neighboring a Mott instability, rendering the bilayer the\ndominant contributor to its low-energy physics, both at ambient and high\npressure. The electronic structure of La$_{5}$Ni$_{3}$O$_{11}$ ultimately\nresembles that of the bilayer compound La$_{3}$Ni$_{2}$O$_{7}$, pointing to the\npresence of universal features in the family of superconducting RP nickelates.\nThus, La$_{5}$Ni$_{3}$O$_{11}$ provides a new platform to disentangle the key\ndegrees of freedom underlying superconductivity in pressurized RP nickelates,\nunderscoring the central role of the bilayer structural motif.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-05-12T09:44:53Z"}
{"aid":"http://arxiv.org/abs/2505.07395v1","title":"ReinboT: Amplifying Robot Visual-Language Manipulation with\n  Reinforcement Learning","summary":"Vision-Language-Action (VLA) models have shown great potential in general\nrobotic decision-making tasks via imitation learning. However, the variable\nquality of training data often constrains the performance of these models. On\nthe other hand, offline Reinforcement Learning (RL) excels at learning robust\npolicy models from mixed-quality data. In this paper, we introduce Reinforced\nrobot GPT (ReinboT), a novel end-to-end VLA model that integrates the RL\nprinciple of maximizing cumulative reward. ReinboT achieves a deeper\nunderstanding of the data quality distribution by predicting dense returns that\ncapture the nuances of manipulation tasks. The dense return prediction\ncapability enables the robot to generate more robust decision-making actions,\noriented towards maximizing future benefits. Extensive experiments show that\nReinboT achieves state-of-the-art performance on the CALVIN mixed-quality\ndataset and exhibits superior few-shot learning and out-of-distribution\ngeneralization capabilities in real-world tasks.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-12T09:48:03Z"}
{"aid":"http://arxiv.org/abs/2505.07407v1","title":"Scaling of wall pressure and the peak of streamwise turbulence intensity\n  in compressible wall flows","summary":"This paper develops scaling laws for wall-pressure root-mean-square (r.m.s.)\nand the peak of streamwise turbulence intensity, accounting for both\nvariable-property and intrinsic compressibility effects -- those associated\nwith changes in fluid volume due to pressure variations. To develop such\nscaling laws, we express the target quantities as an expansion series in powers\nof an appropriately defined Mach number. The leading-order term is represented\nusing the scaling relations developed for incompressible flows, but with an\neffective Reynolds number. Higher-order terms capture intrinsic compressibility\neffects and are modeled as constant coefficients, calibrated using flow cases\nspecifically designed to isolate these effects. The resulting scaling relations\nare shown to be accurate for a wide range of channel flows and boundary layers.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-05-12T09:59:43Z"}
{"aid":"http://arxiv.org/abs/2505.07426v1","title":"Thermoelectric processes of quantum normal-superconductor interfaces","summary":"Superconducting interfaces have recently been demonstrated to contain a rich\nvariety of effects that give rise to sizable thermoelectric responses and\nunexpected thermal properties, despite traditionally being considered poor\nthermoelectrics due to their intrinsic electron-hole symmetry. We review\ndifferent mechanisms driving this response in hybrid normal-superconducting\njunctions, depending on the dimensionality of the mesoscopic interface. In\naddition to discussing heat to power conversion, cooling and heat transport,\nspecial emphasis is put on physical properties of hybrid devices that can be\nrevealed by the thermoelectric effect.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con,quant-ph","published":"2025-05-12T10:30:59Z"}
{"aid":"http://arxiv.org/abs/2505.07459v1","title":"Why Uncertainty Estimation Methods Fall Short in RAG: An Axiomatic\n  Analysis","summary":"Large Language Models (LLMs) are valued for their strong performance across\nvarious tasks, but they also produce inaccurate or misleading outputs.\nUncertainty Estimation (UE) quantifies the model's confidence and helps users\nassess response reliability. However, existing UE methods have not been\nthoroughly examined in scenarios like Retrieval-Augmented Generation (RAG),\nwhere the input prompt includes non-parametric knowledge. This paper shows that\ncurrent UE methods cannot reliably assess correctness in the RAG setting. We\nfurther propose an axiomatic framework to identify deficiencies in existing\nmethods and guide the development of improved approaches. Our framework\nintroduces five constraints that an effective UE method should meet after\nincorporating retrieved documents into the LLM's prompt. Experimental results\nreveal that no existing UE method fully satisfies all the axioms, explaining\ntheir suboptimal performance in RAG. We further introduce a simple yet\neffective calibration function based on our framework, which not only satisfies\nmore axioms than baseline methods but also improves the correlation between\nuncertainty estimates and correctness.","main_category":"cs.IR","categories":"cs.IR","published":"2025-05-12T11:47:42Z"}
{"aid":"http://arxiv.org/abs/2505.07502v1","title":"Measuring Financial Resilience Using Backward Stochastic Differential\n  Equations","summary":"We propose the resilience rate as a measure of financial resilience. It\ncaptures the rate at which a dynamic risk evaluation recovers, i.e., bounces\nback, after the risk-acceptance set is breached. We develop the associated\nstochastic calculus by establishing representation theorems of a suitable\ntime-derivative of solutions to backward stochastic differential equations\n(BSDEs) with jumps, evaluated at stopping times. These results reveal that our\nresilience rate can be represented as an expectation of the generator of the\nBSDE. We also introduce resilience-acceptance sets and study their properties\nin relation to both the resilience rate and the dynamic risk measure. We\nillustrate our results in several examples.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-05-12T12:38:55Z"}
{"aid":"http://arxiv.org/abs/2505.07508v1","title":"EAGLE: Contrastive Learning for Efficient Graph Anomaly Detection","summary":"Graph anomaly detection is a popular and vital task in various real-world\nscenarios, which has been studied for several decades. Recently, many studies\nextending deep learning-based methods have shown preferable performance on\ngraph anomaly detection. However, existing methods are lack of efficiency that\nis definitely necessary for embedded devices. Towards this end, we propose an\nEfficient Anomaly detection model on heterogeneous Graphs via contrastive\nLEarning (EAGLE) by contrasting abnormal nodes with normal ones in terms of\ntheir distances to the local context. The proposed method first samples\ninstance pairs on meta path-level for contrastive learning. Then, a graph\nautoencoder-based model is applied to learn informative node embeddings in an\nunsupervised way, which will be further combined with the discriminator to\npredict the anomaly scores of nodes. Experimental results show that EAGLE\noutperforms the state-of-the-art methods on three heterogeneous network\ndatasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-12T12:45:07Z"}
{"aid":"http://arxiv.org/abs/2505.07517v1","title":"Effective Quantum Gravitational Collapse in Metric Variables: The\n  $\\barμ$ Scheme","summary":"We study, using the metric variables, how an effective theory for the\nOppenheimer-Snyder gravitational collapse can be built with the $\\bar{\\mu}$\nscheme from Loop Quantum Gravity (LQG). The collapse is analyzed for both the\nflat and spherical models. In both scenarios the effective theory make possible\nto avoid the formation of the singularity. The source of this is found in the\npresence of a negative pressure term inside the stress-energy tensor of the\ngravitational field. This pressure is analyzed and is concluded that the\neffective polymer model is the reason why the negative pressure appears. A\ncharacterization of the solutions for both models is also carried out, showing\nthat the collapse is altered and avoided in favor of a transition from a black\nhole state to a white hole one, transition that occurs when the collapse has\nreached a Planckian regime.","main_category":"gr-qc","categories":"gr-qc,hep-ph,quant-ph","published":"2025-05-12T12:56:17Z"}
{"aid":"http://arxiv.org/abs/2505.07520v1","title":"The nature of small scale EUV solar brightenings investigated as\n  impulsive heating of short loop in 1D hydrododynamics simulations","summary":"Small (400 to 4000 km) and short lived (10 to 200 km) extreme ultraviolet\n(EUV) brightenings, detected by the High Resolution Imager EUV (HRIEUV), have\nbeen found to be ubiquitous in the Quiet Sun (QS). Their contribution to\ncoronal heating as well as their physical origin are currently being\ninvestigated. We wish to determine whether models of short loops and impulsive\nheating are compatible with the results from observations. In particular, we\nused two models of loops with distinct thermal properties: cool (T below 1E5 K)\nand hot loops (T above 1E5 K). We simulated the evolution of impulsively heated\nshort loops, using the 1D hydrodynamics (HD) code HYDRAD. We computed the\nsynthetic light curves of HRIEUV, four EUV channels of the Atmospheric Imaging\nAssembly (AIA), and five emission lines measured by the SPectral Imaging of the\nCoronal Environment (SPICE). We then compared the results from the synthetic\nlight curves with observations. The aim was to reproduce the short delays\nobserved between the intensity peaks of the light curves. Cool loops subjected\nto impulsive heating are good candidates to explain the physical origin of the\nEUV brightenings. On the other hand, hot loops are not consistent with\nobservations, except when they are subjected to especially strong impulsive\nheating.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-05-12T13:01:26Z"}
{"aid":"http://arxiv.org/abs/2505.07524v1","title":"Prethermal discrete time crystals in one-dimensional classical Floquet\n  systems with nearest-neighbor interactions","summary":"Prethermal discrete time crystals (PDTCs), an emergent non-equilibrium phase\nof matter, have been studied in two- and higher-dimensional lattices with\nnearest-neighbor (NN) interactions and one-dimensional (1D) lattices with\nlong-range interactions. However, different from prethermalization that can be\nobserved in 1D Floquet classical spin systems with NN interactions, classical\nPDTCs in Floquet 1D systems with only NN interactions have not been proposed\nbefore. Here, we demonstrate the emergence of disorder-free PDTCs in 1D Floquet\nclassic spin systems with NN interactions. We show that the thermalization time\ngrows exponentially as the driving frequency increases and depends on the\nenergy density of the initial state, which are two key signatures of PDTCs. The\nrobustness of 1D classical PDTC order is verified by introducing imperfect spin\nflip operations. The emergence of 1D classical PDTCs can be explained by\nmapping the 1D classical spin chain with NN interacting to a quantum spin-half\nsystem with effective long-range interactions. Our work provides an exploration\nof quantum characteristics, when considering the classical counterparts of\nquantum phenomena, and will be helpful for further investigations of both\nclassical and quantum prethermal systems and discrete time-crystalline order.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other","published":"2025-05-12T13:08:10Z"}
{"aid":"http://arxiv.org/abs/2505.07538v1","title":"Discrete Visual Tokens of Autoregression, by Diffusion, and for\n  Reasoning","summary":"We completely discard the conventional spatial prior in image representation\nand introduce a novel discrete visual tokenizer: Self-consistency Tokenizer\n(Selftok). At its design core, we compose an autoregressive (AR) prior --\nmirroring the causal structure of language -- into visual tokens by using the\nreverse diffusion process of image generation. The AR property makes Selftok\nfundamentally distinct from traditional spatial tokens in the following two key\nways: - Selftok offers an elegant and minimalist approach to unify diffusion\nand AR for vision-language models (VLMs): By representing images with Selftok\ntokens, we can train a VLM using a purely discrete autoregressive architecture\n-- like that in LLMs -- without requiring additional modules or training\nobjectives. - We theoretically show that the AR prior satisfies the Bellman\nequation, whereas the spatial prior does not. Therefore, Selftok supports\nreinforcement learning (RL) for visual generation with effectiveness comparable\nto that achieved in LLMs. Besides the AR property, Selftok is also a SoTA\ntokenizer that achieves a favorable trade-off between high-quality\nreconstruction and compression rate. We use Selftok to build a pure AR VLM for\nboth visual comprehension and generation tasks. Impressively, without using any\ntext-image training pairs, a simple policy gradient RL working in the visual\ntokens can significantly boost the visual generation benchmark, surpassing all\nthe existing models by a large margin. Therefore, we believe that Selftok\neffectively addresses the long-standing challenge that visual tokens cannot\nsupport effective RL. When combined with the well-established strengths of RL\nin LLMs, this brings us one step closer to realizing a truly multimodal LLM.\nProject Page: https://selftok-team.github.io/report/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T13:19:08Z"}
{"aid":"http://arxiv.org/abs/2505.07563v1","title":"Pinpointing Triple Point of Noncommutative Matrix Model with Curvature","summary":"We study a Hermitian matrix model with a quartic potential, modified by a\ncurvature term $\\mathrm{tr}(R\\Phi^2)$, where $R$ is a fixed external matrix.\nMotivated by the truncated Heisenberg algebra formulation of the\nGrosse-Wulkenhaar model, this term breaks unitary invariance and gives rise to\nan effective multitrace matrix model via perturbative expansion. We analyze the\nresulting action analytically and numerically, focusing on the shift of the\ntriple point and suppression of the noncommutative stripe phase -- features\nlinked to renormalizability. Our findings, supported by Hamiltonian Monte Carlo\nsimulations, indicate that the curvature term drives the phase structure toward\nrenormalizable behavior by eliminating the stripe phase.","main_category":"hep-th","categories":"hep-th","published":"2025-05-12T13:48:25Z"}
{"aid":"http://arxiv.org/abs/2505.07574v1","title":"Security through the Eyes of AI: How Visualization is Shaping Malware\n  Detection","summary":"Malware, a persistent cybersecurity threat, increasingly targets\ninterconnected digital systems such as desktop, mobile, and IoT platforms\nthrough sophisticated attack vectors. By exploiting these vulnerabilities,\nattackers compromise the integrity and resilience of modern digital ecosystems.\nTo address this risk, security experts actively employ Machine Learning or Deep\nLearning-based strategies, integrating static, dynamic, or hybrid approaches to\ncategorize malware instances. Despite their advantages, these methods have\ninherent drawbacks and malware variants persistently evolve with increased\nsophistication, necessitating advancements in detection strategies.\nVisualization-based techniques are emerging as scalable and interpretable\nsolutions for detecting and understanding malicious behaviors across diverse\nplatforms including desktop, mobile, IoT, and distributed systems as well as\nthrough analysis of network packet capture files. In this comprehensive survey\nof more than 100 high-quality research articles, we evaluate existing\nvisualization-based approaches applied to malware detection and classification.\nAs a first contribution, we propose a new all-encompassing framework to study\nthe landscape of visualization-based malware detection techniques. Within this\nframework, we systematically analyze state-of-the-art approaches across the\ncritical stages of the malware detection pipeline. By analyzing not only the\nsingle techniques but also how they are combined to produce the final solution,\nwe shed light on the main challenges in visualization-based approaches and\nprovide insights into the advancements and potential future directions in this\ncritical field.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-12T13:53:56Z"}
{"aid":"http://arxiv.org/abs/2505.07575v1","title":"Personalized Federated Learning under Model Dissimilarity Constraints","summary":"One of the defining challenges in federated learning is that of statistical\nheterogeneity among clients. We address this problem with KARULA, a regularized\nstrategy for personalized federated learning, which constrains the pairwise\nmodel dissimilarities between clients based on the difference in their\ndistributions, as measured by a surrogate for the 1-Wasserstein distance\nadapted for the federated setting. This allows the strategy to adapt to highly\ncomplex interrelations between clients, that e.g., clustered approaches fail to\ncapture. We propose an inexact projected stochastic gradient algorithm to solve\nthe constrained problem that the strategy defines, and show theoretically that\nit converges with smooth, possibly non-convex losses to a neighborhood of a\nstationary point with rate O(1/K). We demonstrate the effectiveness of KARULA\non synthetic and real federated data sets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-12T13:54:55Z"}
{"aid":"http://arxiv.org/abs/2505.07578v1","title":"Positive normalized solutions of Schrödinger equations with Sobolev\n  critical growth in bounded domains","summary":"This paper investigates the existence of positive normalized solutions to the\nSobolev critical Schr\\\"{o}dinger equation: \\begin{equation*} \\left\\{\n\\begin{aligned} &-\\Delta u +\\lambda u =|u|^{2^*-2}u \\quad &\\mbox{in}& \\\n\\Omega,\\\\ &\\int_{\\Omega}|u|^{2}dx=c, \\quad u=0 \\quad &\\mbox{on}& \\\n\\partial\\Omega, \\end{aligned} \\right. \\end{equation*} where\n$\\Omega\\subset\\mathbb{R}^{N}$ ($N\\geq3$) is a bounded smooth domain,\n$2^*=\\frac{2N}{N-2}$, $\\lambda\\in \\mathbb{R}$ is a Lagrange multiplier, and\n$c>0$ is a prescribed constant. By introducing a novel blow-up analysis for\nSobolev subcritical approximation solutions with uniformly bounded Morse index\nand fixed mass, we establish the existence of mountain pass type positive\nnormalized solutions for\n  $N\\ge 3$. This resolves an open problem posed in [Pierotti, Verzini and Yu,\nSIAM J. Math. Anal. 2025].","main_category":"math.AP","categories":"math.AP","published":"2025-05-12T13:58:52Z"}
{"aid":"http://arxiv.org/abs/2505.07588v1","title":"Extremal Cat Herding","summary":"The game of Cat Herding is one in which cat and herder players alternate\nturns, with the evasive cat moving along non-trivial paths between vertices,\nand the herder deleting single edges from the graph. Eventually the cat cannot\nmove, and the number of edges deleted is the cat number of the graph. We\nanalyze both when the cat is captured quickly, and when the cat evades capture\nforever, or for an arbitrarily long time. We develop a reduction construction\nthat retains the cat number of the graph, and classify all (reduced) graphs\nthat have cat number 3 or less as a finite set of graphs. We expand on a\nlogical characterization of infinite Cat Herding on trees to describe all\ninfinite graphs on which the cat can evade capture forever. We also provide a\nbrief characterization of the graphs on which the cat can score arbitrarily\nhigh. We conclude by motivating a definition of cat herding ordinals for future\nresearch.","main_category":"math.CO","categories":"math.CO","published":"2025-05-12T14:15:17Z"}
{"aid":"http://arxiv.org/abs/2505.07606v1","title":"Data Ethics in the Fediverse: Analyzing the Role of Instance Policies in\n  Mastodon Research","summary":"This article addresses the disconnect between the individual policy documents\nof Mastodon instances--many of which explicitly prohibit data collection for\nresearch purposes--and the actual data handling practices observed in academic\nresearch involving Mastodon. We present a systematic analysis of 29 works that\nused Mastodon as a data source, revealing limited adherence to instance--level\npolicies despite researchers' general awareness of their existence. Our\nfindings underscore the need for broader discussion about ethical obligations\nin research on alternative, decentralized social media platforms.","main_category":"cs.SI","categories":"cs.SI","published":"2025-05-12T14:28:08Z"}
{"aid":"http://arxiv.org/abs/2505.07611v1","title":"Deep Learning Advances in Vision-Based Traffic Accident Anticipation: A\n  Comprehensive Review of Methods,Datasets,and Future Directions","summary":"Traffic accident prediction and detection are critical for enhancing road\nsafety,and vision-based traffic accident anticipation (Vision-TAA) has emerged\nas a promising approach in the era of deep learning.This paper reviews 147\nrecent studies,focusing on the application of supervised,unsupervised,and\nhybrid deep learning models for accident prediction,alongside the use of\nreal-world and synthetic datasets.Current methodologies are categorized into\nfour key approaches: image and video feature-based prediction, spatiotemporal\nfeature-based prediction, scene understanding,and multimodal data fusion.While\nthese methods demonstrate significant potential,challenges such as data\nscarcity,limited generalization to complex scenarios,and real-time performance\nconstraints remain prevalent. This review highlights opportunities for future\nresearch,including the integration of multimodal data fusion, self-supervised\nlearning,and Transformer-based architectures to enhance prediction accuracy and\nscalability.By synthesizing existing advancements and identifying critical\ngaps, this paper provides a foundational reference for developing robust and\nadaptive Vision-TAA systems,contributing to road safety and traffic management.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T14:34:22Z"}
{"aid":"http://arxiv.org/abs/2505.07614v1","title":"Trial and Trust: Addressing Byzantine Attacks with Comprehensive Defense\n  Strategy","summary":"Recent advancements in machine learning have improved performance while also\nincreasing computational demands. While federated and distributed setups\naddress these issues, their structure is vulnerable to malicious influences. In\nthis paper, we address a specific threat, Byzantine attacks, where compromised\nclients inject adversarial updates to derail global convergence. We combine the\ntrust scores concept with trial function methodology to dynamically filter\noutliers. Our methods address the critical limitations of previous approaches,\nallowing functionality even when Byzantine nodes are in the majority. Moreover,\nour algorithms adapt to widely used scaled methods like Adam and RMSProp, as\nwell as practical scenarios, including local training and partial\nparticipation. We validate the robustness of our methods by conducting\nextensive experiments on both synthetic and real ECG data collected from\nmedical institutions. Furthermore, we provide a broad theoretical analysis of\nour algorithms and their extensions to aforementioned practical setups. The\nconvergence guarantees of our methods are comparable to those of classical\nalgorithms developed without Byzantine interference.","main_category":"cs.LG","categories":"cs.LG,math.OC","published":"2025-05-12T14:36:45Z"}
{"aid":"http://arxiv.org/abs/2505.07616v1","title":"Hydrogen peroxide electrosynthesis: A comparative study employing Vulcan\n  carbon modification by different MnO2 nanostructures","summary":"The electrochemical performances of the {\\alpha}-MnO2/Vulcan XC-72 and\n{\\delta}-MnO2/Vulcan XC-72 nanostructures in hydrogen peroxide (H2O2)\nelectrosynthesis were compared herein. Both materials were synthesized by a\nsimple hydrothermal route. Their structures and morphologies were analyzed by\nSEM, HRTEM, XPS, Raman Scattering and XRD, and their ORR electrochemical\nproperties and H2O2 electrosynthesis efficacies were investigated in alkaline\nNaOH solutions applying the rotating ring-disk electrode (RRDE) technique. Gas\ndiffusion electrode (GDE) setups in acid media aiming at H2O2 formation were\nalso performed. The 3% {\\delta}-MnO2/C and 1% {\\alpha}-MnO2/C electrocatalysts\nwere more efficient and selective than pure Vulcan XC-72 through the ORR\n2-electron pathway in the RRDE essays. Concerning H2O2 electrogeneration using\nGDE, the 1% {\\alpha}-MnO2/C electrocatalyst displayed better activity, with\nperoxide accumulation of 402.6 mg/L at -1.9 V (vs Ag/AgCl) after 120 min, 48 %\nhigher than pure Vulcan XC-72 GDE. These results can be ascribed to a\nsynergistic effect between {\\alpha}-MnO2 and Vulcan XC-72, as well as oxygen\nfunctional acid species improvement, increasing electrocatalytic surface\nhydrophilicity and enhancing H2O2 electrosynthesis.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.chem-ph","published":"2025-05-12T14:40:37Z"}
{"aid":"http://arxiv.org/abs/2505.07631v1","title":"Is MixIT Really Unsuitable for Correlated Sources? Exploring MixIT for\n  Unsupervised Pre-training in Music Source Separation","summary":"In music source separation (MSS), obtaining isolated sources or stems is\nhighly costly, making pre-training on unlabeled data a promising approach.\nAlthough source-agnostic unsupervised learning like mixture-invariant training\n(MixIT) has been explored in general sound separation, they have been largely\noverlooked in MSS due to its implicit assumption of source independence. We\nhypothesize, however, that the difficulty of applying MixIT to MSS arises from\nthe ill-posed nature of MSS itself, where stem definitions are\napplication-dependent and models lack explicit knowledge of what should or\nshould not be separated, rather than from high inter-source correlation. While\nMixIT does not assume any source model and struggles with such ambiguities, our\npreliminary experiments show that it can still separate instruments to some\nextent, suggesting its potential for unsupervised pre-training. Motivated by\nthese insights, this study investigates MixIT-based pre-training for MSS. We\nfirst pre-train a model on in-the-wild, unlabeled data from the Free Music\nArchive using MixIT, and then fine-tune it on MUSDB18 with supervision. Using\nthe band-split TF-Locoformer, one of the state-of-the-art MSS models, we\ndemonstrate that MixIT-based pre-training improves the performance over\ntraining from scratch.","main_category":"eess.AS","categories":"eess.AS","published":"2025-05-12T14:58:55Z"}
{"aid":"http://arxiv.org/abs/2505.07633v1","title":"Kolmogorov scaling in bubble-induced turbulence","summary":"Experiments using 3D Lagrangian tracking are used to investigate Kolmogorov\nscaling below the bubble size in bubble-induced turbulence (BIT). Second and\nthird order structure functions reveal approximate Kolmogorov scaling for\nhomogeneous bubble swarms. A new scaling for the kinetic energy dissipation\nrate is derived and shown to be in excellent agreement with the data. Using\nthis we predict the scale separation below the bubble size as a function of the\nparameters and find that a large inertial range is not possible in BIT since\nbubbles of the required size would quickly break down.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-05-12T15:05:10Z"}
{"aid":"http://arxiv.org/abs/2505.07642v1","title":"Convergence of Time-Averaged Mean Field Gradient Descent Dynamics for\n  Continuous Multi-Player Zero-Sum Games","summary":"The approximation of mixed Nash equilibria (MNE) for zero-sum games with\nmean-field interacting players has recently raised much interest in machine\nlearning. In this paper we propose a mean-field gradient descent dynamics for\nfinding the MNE of zero-sum games involving $K$ players with $K\\geq 2$. The\nevolution of the players' strategy distributions follows coupled mean-field\ngradient descent flows with momentum, incorporating an exponentially discounted\ntime-averaging of gradients. First, in the case of a fixed entropic\nregularization, we prove an exponential convergence rate for the mean-field\ndynamics to the mixed Nash equilibrium with respect to the total variation\nmetric. This improves a previous polynomial convergence rate for a similar\ntime-averaged dynamics with different averaging factors. Moreover, unlike\nprevious two-scale approaches for finding the MNE, our approach treats all\nplayer types on the same time scale. We also show that with a suitable choice\nof decreasing temperature, a simulated annealing version of the mean-field\ndynamics converges to an MNE of the initial unregularized problem.","main_category":"math.OC","categories":"math.OC,cs.LG,math.AP,math.PR,stat.ML","published":"2025-05-12T15:12:27Z"}
{"aid":"http://arxiv.org/abs/2505.07645v1","title":"Linear growth and moduli spaces of rational curves","summary":"Working in positive characteristic, we show how one can use information about\nthe dimension of moduli spaces of rational curves on a Fano variety $X$ over\n$\\mathbb{F}_q$ to obtain strong estimates for the number of\n$\\mathbb{F}_q(t)$-points of bounded height on $X$. Building on work of\nBeheshti, Lehmann, Riedl and Tanimoto~\\cite{BeheshtiLehmannRiedlTanimoto.dP},\nwe apply our strategy to del Pezzo surfaces of degree at most 5. In addition,\nwe also treat the case of smooth cubic hypersurfaces and smooth intersections\nof two quadrics of dimension at least 3 by showing that the moduli spaces of\nrational curves of fixed degree are of the expected dimension. For large but\nfixed $q$, the bounds obtained come arbitrarily close to the linear growth\npredicted by the Batyrev--Manin conjecture.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-05-12T15:15:17Z"}
{"aid":"http://arxiv.org/abs/2505.07649v1","title":"Constructing Bayes Minimax Estimators through Integral Transformations","summary":"The problem of Bayes minimax estimation for the mean of a multivariate normal\ndistribution under quadratic loss has attracted significant attention recently.\nThese estimators have the advantageous property of being admissible, similar to\nBayes procedures, while also providing the conservative risk guarantees typical\nof frequentist methods. This paper demonstrates that Bayes minimax estimators\ncan be derived using integral transformation techniques, specifically through\nthe \\( I \\)-transform and the Laplace transform, as long as appropriate\nspherical priors are selected. Several illustrative examples are included to\nhighlight the effectiveness of the proposed approach.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-05-12T15:21:13Z"}
{"aid":"http://arxiv.org/abs/2505.07652v1","title":"ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models","summary":"Current diffusion-based text-to-video methods are limited to producing short\nvideo clips of a single shot and lack the capability to generate multi-shot\nvideos with discrete transitions where the same character performs distinct\nactivities across the same or different backgrounds. To address this limitation\nwe propose a framework that includes a dataset collection pipeline and\narchitectural extensions to video diffusion models to enable text-to-multi-shot\nvideo generation. Our approach enables generation of multi-shot videos as a\nsingle video with full attention across all frames of all shots, ensuring\ncharacter and background consistency, and allows users to control the number,\nduration, and content of shots through shot-specific conditioning. This is\nachieved by incorporating a transition token into the text-to-video model to\ncontrol at which frames a new shot begins and a local attention masking\nstrategy which controls the transition token's effect and allows shot-specific\nprompting. To obtain training data we propose a novel data collection pipeline\nto construct a multi-shot video dataset from existing single-shot video\ndatasets. Extensive experiments demonstrate that fine-tuning a pre-trained\ntext-to-video model for a few thousand iterations is enough for the model to\nsubsequently be able to generate multi-shot videos with shot-specific control,\noutperforming the baselines. You can find more details in\nhttps://shotadapter.github.io/","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T15:22:28Z"}
{"aid":"http://arxiv.org/abs/2505.07658v1","title":"Dynamical codes for hardware with noisy readouts","summary":"Dynamical stabilizer codes may offer a practical route to large-scale quantum\ncomputation. Such codes are defined by a schedule of error-detecting\nmeasurements, which allows for flexibility in their construction. In this work,\nwe ask how best to optimise the measurement schedule of dynamically condensed\ncolour codes in various limits of noise bias. We take a particular focus on the\nsetting where measurements introduce more noise than unitary and idling\noperations - a noise model relevant to some hardware proposals. For\nmeasurement-biased noise models, we improve code performance by strategically\nrepeating measurements within the schedule. For unbiased or $Z$-biased noise\nmodels, we find repeating measurements offers little improvement - somewhat\ncontrary to our expectations - and investigate why this is. To perform this\nanalysis, we generalise a metric called the teraquop footprint to the teraquop\nvolume. This is the product of the number of qubits and number of rounds of\nmeasurements required such that the probability of a spacelike or timelike\nlogical error occurring is less than $10^{-12}$. In most cases, we find\ndifferences in performance are primarily due to the number of rounds of\nmeasurements required, rather than the number of qubits - emphasising the\nimportance of using the teraquop volume in the analysis. Additionally, our\nresults provide another example of the importance of making use of correlated\nerrors when decoding, in that using belief matching rather than minimum-weight\nperfect matching can turn a worst-performing code under a given noise model\ninto a best-performing code.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-12T15:24:50Z"}
{"aid":"http://arxiv.org/abs/2505.07660v1","title":"A comparative study of Bitcoin and Ripple cryptocurrencies trading using\n  Deep Reinforcement Learning algorithms","summary":"Artificial intelligence (AI) has demonstrated remarkable success across\nvarious applications. In light of this trend, the field of automated trading\nhas developed a keen interest in leveraging AI techniques to forecast the\nfuture prices of financial assets. This interest stems from the need to address\ntrading challenges posed by the inherent volatility and dynamic nature of asset\nprices. However, crafting a flawless strategy becomes a formidable task when\ndealing with assets characterized by intricate and ever-changing price\ndynamics. To surmount these formidable challenges, this research employs an\ninnovative rule-based strategy approach to train Deep Reinforcement Learning\n(DRL). This application is carried out specifically in the context of trading\nBitcoin (BTC) and Ripple (XRP). Our proposed approach hinges on the integration\nof Deep Q-Network, Double Deep Q-Network, Dueling Deep Q-learning networks,\nalongside the Advantage Actor-Critic algorithms. Each of them aims to yield an\noptimal policy for our application. To evaluate the effectiveness of our Deep\nReinforcement Learning (DRL) approach, we rely on portfolio wealth and the\ntrade signal as performance metrics. The experimental outcomes highlight that\nDuelling and Double Deep Q-Network outperformed when using XRP with the\nincreasing of the portfolio wealth. All codes are available in this\n\\href{https://github.com/VerlonRoelMBINGUI/RL_Final_Projects_AMMI2023}{\\color{blue}Github\nlink}.","main_category":"cs.CE","categories":"cs.CE","published":"2025-05-12T15:27:36Z"}
{"aid":"http://arxiv.org/abs/2505.07663v1","title":"Rigidity and flexibility in $p$-adic symplectic geometry","summary":"Let $n\\ge 2$ be an integer and let $p$ be a prime number. We prove that the\nanalog of Gromov's non-squeezing theorem does not hold for $p$-adic embeddings:\nfor any $p$-adic absolute value $R$, the entire $p$-adic space\n$(\\mathbb{Q}_p)^{2n}$ is symplectomorphic to the $p$-adic cylinder\n$\\mathrm{Z}_p^{2n}(R)$ of radius $R$, showing a degree of flexibility which\nstands in contrast with the real case. However, some rigidity remains: we prove\nthat the $p$-adic affine analog of Gromov's result still holds. We will also\nshow that in the non-linear situation, if the $p$-adic embeddings are\nequivariant with respect to a torus action, then non-squeezing holds, which\ngeneralizes a recent result by Figalli, Palmer and the second author. This\nallows us to introduce equivariant $p$-adic analytic symplectic capacities, of\nwhich the $p$-adic equivariant Gromov width is an example.","main_category":"math.SG","categories":"math.SG,math-ph,math.MP","published":"2025-05-12T15:31:13Z"}
{"aid":"http://arxiv.org/abs/2505.07674v1","title":"Joint Graph Convolution and Sequential Modeling for Scalable Network\n  Traffic Estimation","summary":"This study focuses on the challenge of predicting network traffic within\ncomplex topological environments. It introduces a spatiotemporal modeling\napproach that integrates Graph Convolutional Networks (GCN) with Gated\nRecurrent Units (GRU). The GCN component captures spatial dependencies among\nnetwork nodes, while the GRU component models the temporal evolution of traffic\ndata. This combination allows for precise forecasting of future traffic\npatterns. The effectiveness of the proposed model is validated through\ncomprehensive experiments on the real-world Abilene network traffic dataset.\nThe model is benchmarked against several popular deep learning methods.\nFurthermore, a set of ablation experiments is conducted to examine the\ninfluence of various components on performance, including changes in the number\nof graph convolution layers, different temporal modeling strategies, and\nmethods for constructing the adjacency matrix. Results indicate that the\nproposed approach achieves superior performance across multiple metrics,\ndemonstrating robust stability and strong generalization capabilities in\ncomplex network traffic forecasting scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-12T15:38:19Z"}
{"aid":"http://arxiv.org/abs/2505.07678v1","title":"Energetic consistency and heat transport in Fourier-Galerkin truncations\n  of free slip 3D rotating convection","summary":"This paper examines the effects of energetic consistency in Fourier truncated\nmodels of the 3D Boussinesq-Coriolis (BC) equations as a case-study towards\nimproving the realism of convective processes in climate models. As a benchmark\nwe consider the Nusselt number, defined as the average vertical heat transport\nof a convective flow. A set of formulae are derived which give the ODE\nprojection of the BC model onto any finite selection of modes. It is proven\nthat projected ODE models obey energy relations consistent with the PDE if and\nonly if a mode selection Criterion regarding the vertical resolution is\nsatisfied. It is also proven that the energy relations imply the existence of a\ncompact attractor for these ODE's, which then implies bounds on the Nusselt\nnumber. By contrast, it is proven that a broad class of energetically\ninconsistent models admit solutions with unbounded, exponential growth,\nprecluding the existence of a compact attractor and giving an infinite Nusselt\nnumber. On the other hand, certain energetically inconsistent models can admit\ncompact attractors as shown via a simple model. The above formulas are\nimplemented in MATLAB, enabling a user to study any desired Fourier truncated\nmodel by selecting a desired finite set of Fourier modes. All code is made\navailable on GitHub. Several numerical studies of the Nusselt number are\nconducted to assess the convergence of the Nusselt number with respect to\nincreasing spatial resolution for consistent models and measure the distorting\neffects of inconsistency for more general solutions.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,math.DS","published":"2025-05-12T15:44:31Z"}
{"aid":"http://arxiv.org/abs/2505.07682v1","title":"Hardy-Littlewood maximal operator on spaces of exponential volume growth","summary":"We consider the Hardy-Littlewood maximal function associated with ball\naverages on spaces with exponential volume growth. We focus on discrete groups\nwith balls defined by invariant metrics associated with a variety of length\nfunctions. Under natural assumptions on the rough radial structure of the group\nin question, we establish a weak-type $\\mathcal{L}\\left(\\log\n\\mathcal{L}\\right)^{\\bf c}$ maximal inequality for the Hardy-Littlewood maximal\nfunction. We give a variety of examples where the rough radial structure\nassumptions hold, based on considerations from geometric group theory, or on\nanalytic considerations related to the regular representation of the group. We\nelucidate the connections of these assumptions to a spherical coarse median\ninequality, to almost exact polynomial-exponential growth of balls, and to the\nradial rapid decay property.\n  In particular, the weak-type maximal inequality in $\\mathcal{L}\\left(\\log\n\\mathcal{L}\\right)^{\\bf c}$ is established for any lattice in a connected\nsemisimple Lie group with finite center, with respect to the distance function\nrestricted from the Riemannian distance on symmetric space to an orbit of the\nlattice. It is also established for right-angled Artin groups, Coxeter groups\nand braid groups, for a suitable choice of word metric.\n  For non-elementary word-hyperbolic group we establish that the\nHardy-Littlewood maximal operator with respect to balls defined by a word\nlength satisfies the weak-type $(1,1)$ maximal inequality, which is the optimal\nresult.","main_category":"math.DS","categories":"math.DS","published":"2025-05-12T15:47:14Z"}
{"aid":"http://arxiv.org/abs/2505.07686v1","title":"S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models","summary":"As Test-Time Scaling emerges as an active research focus in the large\nlanguage model community, advanced post-training methods increasingly emphasize\nextending chain-of-thought (CoT) generation length, thereby enhancing reasoning\ncapabilities to approach Deepseek R1-like reasoning models. However, recent\nstudies reveal that reasoning models (even Qwen3) consistently exhibit\nexcessive thought redundancy in CoT generation. This overthinking problem stems\nfrom conventional outcome-reward reinforcement learning's systematic neglect in\nregulating intermediate reasoning steps. This paper proposes Serial-Group\nDecaying-Reward Policy Optimization (namely S-GRPO), a novel reinforcement\nlearning method that empowers models with the capability to determine the\nsufficiency of reasoning steps, subsequently triggering early exit of CoT\ngeneration. Specifically, unlike GRPO, which samples multiple possible\ncompletions (parallel group) in parallel, we select multiple temporal positions\nin the generation of one CoT to allow the model to exit thinking and instead\ngenerate answers (serial group), respectively. For the correct answers in a\nserial group, we assign rewards that decay according to positions, with lower\nrewards towards the later ones, thereby reinforcing the model's behavior to\ngenerate higher-quality answers at earlier phases with earlier exits of\nthinking. Empirical evaluations demonstrate compatibility with state-of-the-art\nreasoning models, including Qwen3 and Deepseek-distill models, achieving 35.4%\n~ 61.1\\% sequence length reduction with 0.72% ~ 6.08% accuracy improvements\nacross GSM8K, AIME 2024, AMC 2023, MATH-500, and GPQA Diamond benchmarks.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-05-12T15:50:44Z"}
{"aid":"http://arxiv.org/abs/2505.07705v1","title":"Codifying Character Logic in Role-Playing","summary":"This paper introduces Codified Profiles for role-playing, a novel approach\nthat represents character logic as structured, executable functions for\nbehavioral decision-making. Each profile defines a set of functions\nparse_by_scene(scene) that outputs a list of logic-grounded assertions\ntriggered_statements, using both explicit control structures (e.g.,\nif-then-else) and condition checks like check_condition(scene, question), where\neach question is a semantically meaningful prompt about the scene (e.g., \"Is\nthe character in danger?\") discriminated by the role-playing LLM as true,\nfalse, or unknown. This explicit representation offers three key advantages\nover traditional prompt-based profiles, which append character descriptions\ndirectly into text prompts: (1) Persistence, by enforcing complete and\nconsistent execution of character logic, rather than relying on the model's\nimplicit reasoning; (2) Updatability, through systematic inspection and\nrevision of behavioral logic, which is difficult to track or debug in\nprompt-only approaches; (3) Controllable Randomness, by supporting stochastic\nbehavior directly within the logic, enabling fine-grained variability that\nprompting alone struggles to achieve. To validate these advantages, we\nintroduce a new benchmark constructed from 83 characters and 5,141 scenes\ncurated from Fandom, using NLI-based scoring to compare character responses\nagainst ground-truth actions. Our experiments demonstrate the significant\nbenefits of codified profiles in improving persistence, updatability, and\nbehavioral diversity. Notably, by offloading a significant portion of reasoning\nto preprocessing, codified profiles enable even 1B-parameter models to perform\nhigh-quality role-playing, providing a scalable and efficient foundation for\nlocal deployment of role-play agents.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-12T16:12:42Z"}
{"aid":"http://arxiv.org/abs/2505.07710v1","title":"Hybrid Control Strategies for Safe and Adaptive Robot-Assisted Dressing","summary":"Safety, reliability, and user trust are crucial in human-robot interaction\n(HRI) where the robots must address hazards in real-time. This study presents\nhazard driven low-level control strategies implemented in robot-assisted\ndressing (RAD) scenarios where hazards like garment snags and user discomfort\nin real-time can affect task performance and user safety. The proposed control\nmechanisms include: (1) Garment Snagging Control Strategy, which detects\nexcessive forces and either seeks user intervention via a chatbot or\nautonomously adjusts its trajectory, and (2) User Discomfort/Pain Mitigation\nStrategy, which dynamically reduces velocity based on user feedback and aborts\nthe task if necessary. We used physical dressing trials in order to evaluate\nthese control strategies. Results confirm that integrating force monitoring\nwith user feedback improves safety and task continuity. The findings emphasise\nthe need for hybrid approaches that balance autonomous intervention, user\ninvolvement, and controlled task termination, supported by bi-directional\ninteraction and real-time user-driven adaptability, paving the way for more\nresponsive and personalised HRI systems.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-12T16:17:48Z"}
{"aid":"http://arxiv.org/abs/2505.07711v1","title":"Circuit Partitioning Using Large Language Models for Quantum Compilation\n  and Simulations","summary":"We are in the midst of the noisy intermediate-scale quantum (NISQ) era, where\nquantum computers are limited by noisy gates, some of which are more\nerror-prone than others and can render the final computation incomprehensible.\nQuantum circuit compilation algorithms attempt to minimize these noisy gates\nwhen mapping quantum algorithms onto quantum hardware but face computational\nchallenges that restrict their application to circuits with no more than 5-6\nqubits, necessitating the need to partition large circuits before the\napplication of noisy quantum gate minimization algorithms. The existing\ngeneration of these algorithms is heuristic in nature and does not account for\ndownstream gate minimization tasks. Large language models (LLMs) have the\npotential to change this and help improve quantum circuit partitions. This\npaper investigates the use of LLMs, such as Llama and Mistral, for partitioning\nquantum circuits by capitalizing on their abilities to understand and generate\ncode, including QASM. Specifically, we teach LLMs to partition circuits using\nthe quick partition approach of the Berkeley Quantum Synthesis Toolkit. Through\nexperimental evaluations, we show that careful fine-tuning of open source LLMs\nenables us to obtain an accuracy of 53.4% for the partition task while\nover-the-shelf LLMs are unable to correctly partition circuits, using standard\n1-shot and few-shot training approaches.","main_category":"cs.ET","categories":"cs.ET,cs.AI,quant-ph","published":"2025-05-12T16:18:48Z"}
{"aid":"http://arxiv.org/abs/2505.07712v1","title":"Possible mechanisms underlying time perception: decoupling internal and\n  external time","summary":"Alignment between subjective sense of time and chronological time can become\nskewed as a result of pharmacological interventions, neurodegenerative diseases\n(such as Parkinson's disease), or even in the moments preceding brain death.\nDespite increased understanding of mechanisms governing time perception and the\nactivity of the \"internal clock\" (such as the functionality of the dopamine\nsystem in the basal ganglia of the midbrain), there currently exist no\nmathematical models that allow investigation of changes in time perception\nthrough formalizing the decoupling of \"internal\" and \"external\" time. Here we\npropose such a model using a parametrically heterogeneous power equation, and\nuse it to investigate the critical case of indefinite increase in internal time\nfollowing cardiac arrest and preceding brain death. We identify three critical\nparameters that determine time to brain death and provide an analysis of the\nrelevant quantities. We hope that our model can lay foundation for further\nmathematical and theoretical exploration of this complex topic.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-05-12T16:18:55Z"}
{"aid":"http://arxiv.org/abs/2505.07716v1","title":"Criteria for codimension two singularities of surfacesand their\n  applications","summary":"We give simple criteria for the singularities appearing on surfaces\ncodimension less than or equal to two. As applications, we give conditions for\ncodimension two singularities that appear in ruled surfaces and center maps of\nsurfaces in the Euclidean space.","main_category":"math.DG","categories":"math.DG","published":"2025-05-12T16:21:03Z"}
{"aid":"http://arxiv.org/abs/2505.07719v1","title":"Training neural control variates using correlated configurations","summary":"Neural control variates (NCVs) have emerged as a powerful tool for variance\nreduction in Monte Carlo (MC) simulations, particularly in high-dimensional\nproblems where traditional control variates are difficult to construct\nanalytically. By training neural networks to learn auxiliary functions\ncorrelated with the target observable, NCVs can significantly reduce estimator\nvariance while preserving unbiasedness. However, a critical but often\noverlooked aspect of NCV training is the role of autocorrelated samples\ngenerated by Markov Chain Monte Carlo (MCMC). While such samples are typically\ndiscarded for error estimation due to their statistical redundancy, they may\ncontain useful information about the structure of the underlying probability\ndistribution that can benefit the training process. In this work, we\nsystematically examine the effect of using correlated configurations in\ntraining neural control variates. We demonstrate, both conceptually and\nnumerically, that training on correlated data can improve control variate\nperformance, especially in settings with limited computational resources. Our\nanalysis includes empirical results from $U(1)$ gauge theory and scalar field\ntheory, illustrating when and how autocorrelated samples enhance NCV\nconstruction. These findings provide practical guidance for the efficient use\nof MCMC data in training neural networks.","main_category":"hep-lat","categories":"hep-lat,cs.LG,nucl-th","published":"2025-05-12T16:25:00Z"}
{"aid":"http://arxiv.org/abs/2505.07720v1","title":"Interplay of localization and topology in disordered dimerized array of\n  Rydberg atoms","summary":"Rydberg tweezer arrays provide a platform for realizing spin-1/2 Hamiltonians\nwith long-range tunnelings decaying according to power-law with the distance.\nWe numerically investigate the effects of positional disorder and dimerization\non the properties of excited states in such a one-dimensional system. Our model\nallows for the continuous tuning of dimerization patterns and disorder\nstrength. We identify different distinct ergodicity-breaking regimes within the\nparameter space constrained by our geometry. Notably, one of these regimes\nexhibits a unique feature in which non-trivial symmetry-protected topological\n(SPT) properties of the ground state extend to a noticeable fraction of states\nacross the entire spectrum. This interplay between localization and SPT makes\nthe system particularly interesting, as localization should help with\nstabilization of topological excitations, while SPT states contribute to an\nadditional delocalization. Other regions of parameters correspond to more\nstandard nonergodic dynamics resembling many-body localization.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.quant-gas,quant-ph","published":"2025-05-12T16:26:44Z"}
{"aid":"http://arxiv.org/abs/2505.07726v1","title":"Mode Mismatch Mitigation in Gaussian-Modulated CV-QKD","summary":"Technical limitations in pulse shaping lead to mode mismatch, which\nsignificantly reduces the secure key rate in CV-QKD systems. To address this, a\nmachine learning approach is employed to optimize the transmitter pulse-shape,\neffectively minimizing mode mismatch and yielding substantial performance\nimprovements.","main_category":"cs.IT","categories":"cs.IT,math.IT,quant-ph","published":"2025-05-12T16:35:01Z"}
{"aid":"http://arxiv.org/abs/2505.07735v1","title":"Assessing the Chemical Intelligence of Large Language Models","summary":"Large Language Models are versatile, general-purpose tools with a wide range\nof applications. Recently, the advent of \"reasoning models\" has led to\nsubstantial improvements in their abilities in advanced problem-solving domains\nsuch as mathematics and software engineering. In this work, we assessed the\nability of reasoning models to directly perform chemistry tasks, without any\nassistance from external tools. We created a novel benchmark, called ChemIQ,\nwhich consists of 796 questions assessing core concepts in organic chemistry,\nfocused on molecular comprehension and chemical reasoning. Unlike previous\nbenchmarks, which primarily use multiple choice formats, our approach requires\nmodels to construct short-answer responses, more closely reflecting real-world\napplications. The reasoning models, exemplified by OpenAI's o3-mini, correctly\nanswered 28%-59% of questions depending on the reasoning level used, with\nhigher reasoning levels significantly increasing performance on all tasks.\nThese models substantially outperformed the non-reasoning model, GPT-4o, which\nachieved only 7% accuracy. We found that Large Language Models can now convert\nSMILES strings to IUPAC names, a task earlier models were unable to perform.\nAdditionally, we show that the latest reasoning models can elucidate structures\nfrom 1H and 13C NMR data, correctly generating SMILES strings for 74% of\nmolecules containing up to 10 heavy atoms, and in one case solving a structure\ncomprising 21 heavy atoms. For each task, we found evidence that the reasoning\nprocess mirrors that of a human chemist. Our results demonstrate that the\nlatest reasoning models have the ability to perform advanced chemical\nreasoning.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-12T16:44:38Z"}
{"aid":"http://arxiv.org/abs/2505.07739v1","title":"Torsion modules and differential operators in infinitely many variables","summary":"This paper grew out of the author's work on arXiv:2504.18460. Differential\noperators in the sense of Grothendieck acting between modules over a\ncommutative ring can be interpreted as torsion elements in the bimodule of all\noperators with respect to the diagonal ideal in the tensor square of the ring.\nVarious notions of torsion modules for an infinitely generated ideal in a\ncommutative ring lead to various notions of differential operators. We discuss\ndifferential operators of transfinite orders and differential operators having\nno global order at all, but only local orders with respect to specific elements\nof the ring. Many examples are presented. In particular, we prove that every\nordinal can be realized as the order of a differential operator acting on the\nalgebra of polynomials in infinitely many variables over a field.","main_category":"math.AC","categories":"math.AC,math.RA","published":"2025-05-12T16:49:33Z"}
{"aid":"http://arxiv.org/abs/2505.07752v1","title":"Mapping of Microstructure Transitions during Rapid Alloy Solidification\n  Using Bayesian-Guided Phase-Field Simulations","summary":"This study addresses microstructure selection mechanisms in rapid\nsolidification, specifically targeting the transition from cellular/dendritic\nto planar interface morphologies under conditions relevant to additive\nmanufacturing. We use a phase-field model that quantitatively captures solute\ntrapping, kinetic undercooling, and morphological instabilities across a broad\nrange of growth velocities ($V$) and thermal gradients ($G$), and apply it to a\nbinary Fe-Cr alloy, as a surrogate for 316L stainless steel. By combining\nhigh-fidelity phase-field simulations with a Gaussian Process-based Bayesian\nactive learning approach, we efficiently map the microstructure transitions in\nthe multi-dimensional space of composition, growth velocity, and temperature\ngradient. We compare our PF results to classical theories for rapid\nsolidification. The classical KGT model yields an accurate prediction of the\nvalue of $G$ above which the interface is planar for any growth velocity.\nMicrostructures transition from dendrites to cells as the temperature gradient\nincreases close to this value of $G$. We also identify the occurrence of\nunstable \"intermediate\" microstructures at the border between dendritic and\nplanar at low $G$, in the absence of banding instability in this Fe-Cr alloy.\nOur results highlight the capabilities of Bayesian-guided PF approaches in\nexploring complex microstructural transitions in multidimensional parameters\nspaces, thereby providing a robust computational tool for designing process\nparameters to achieve targeted microstructures and properties in rapidly\nsolidified metallic alloys.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-12T16:59:12Z"}
{"aid":"http://arxiv.org/abs/2505.07754v1","title":"Skeletonization of neuronal processes using Discrete Morse techniques\n  from computational topology","summary":"To understand biological intelligence we need to map neuronal networks in\nvertebrate brains. Mapping mesoscale neural circuitry is done using injections\nof tracers that label groups of neurons whose axons project to different brain\nregions. Since many neurons are labeled, it is difficult to follow individual\naxons. Previous approaches have instead quantified the regional projections\nusing the total label intensity within a region. However, such a quantification\nis not biologically meaningful. We propose a new approach better connected to\nthe underlying neurons by skeletonizing labeled axon fragments and then\nestimating a volumetric length density. Our approach uses a combination of deep\nnets and the Discrete Morse (DM) technique from computational topology. This\ntechnique takes into account nonlocal connectivity information and therefore\nprovides noise-robustness. We demonstrate the utility and scalability of the\napproach on whole-brain tracer injected data. We also define and illustrate an\ninformation theoretic measure that quantifies the additional information\nobtained, compared to the skeletonized tracer injection fragments, when\nindividual axon morphologies are available. Our approach is the first\napplication of the DM technique to computational neuroanatomy. It can help\nbridge between single-axon skeletons and tracer injections, two important data\ntypes in mapping neural networks in vertebrates.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.CV","published":"2025-05-12T16:59:36Z"}
{"aid":"http://arxiv.org/abs/2505.07781v1","title":"Unraveling Mn intercalation and diffusion in NbSe$_2$ bilayers through\n  DFTB simulations","summary":"Understanding transition metal atoms' intercalation and diffusion behavior in\ntwo-dimensional (2D) materials is essential for advancing their potential in\nspintronics and other emerging technologies. In this study, we used density\nfunctional tight binding (DFTB) simulations to investigate the atomic-scale\nmechanisms of manganese (Mn) intercalation into NbSe$_2$ bilayers. Our results\nshow that Mn prefers intercalated and embedded positions rather than surface\nadsorption, as cohesive energy calculations indicate enhanced stability in\nthese configurations. Nudged elastic band (NEB) calculations revealed an energy\nbarrier of 0.68 eV for the migration of Mn into the interlayer, comparable to\nother substrates, suggesting accessible diffusion pathways. Molecular dynamics\n(MD) simulations further demonstrated an intercalation concentration-dependent\nbehavior. Mn atoms initially adsorb on the surface and gradually diffuse\ninward, resulting in an effective intercalation at higher Mn densities before\nclustering effects emerge. These results provide helpful insights into the\ndiffusion pathways and stability of Mn atoms within NbSe$_2$ bilayers,\nconsistent with experimental observations and offering a deeper understanding\nof heteroatom intercalation mechanisms in transition metal dichalcogenides.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-12T17:34:56Z"}
{"aid":"http://arxiv.org/abs/2505.07786v1","title":"Nonlocal Meyers' Example","summary":"We present nonlocal variants of the famous Meyers' example of limited higher\nintegrability and differentiability. In the limit $s \\nearrow 1$ we recover the\nstandard Meyers' example. We consider the fractional Laplacian based on\ndifferences as well as the one based on fractional derivatives defined by Riesz\npotentials.","main_category":"math.AP","categories":"math.AP","published":"2025-05-12T17:39:11Z"}
{"aid":"http://arxiv.org/abs/2505.07789v1","title":"Duality theory and representations for distributive quasi relation\n  algebras and DInFL-algebras","summary":"We develop dualities for complete perfect distributive quasi relation\nalgebras and complete perfect distributive involutive FL-algebras. The duals\nare partially ordered frames with additional structure. These frames are\nanalogous to the atom structures used to study relation algebras. We also\nextend the duality from complete perfect algebras to all algebras, using\nso-called doubly-pointed frames with a Priestley topology.\n  We then turn to the representability of these algebras as lattices of binary\nrelations. Some algebras can be realised as term subreducts of representable\nrelation algebras and are hence representable. We provide a detailed account of\nknown representations for all algebras up to size six.","main_category":"cs.LO","categories":"cs.LO","published":"2025-05-12T17:42:48Z"}
{"aid":"http://arxiv.org/abs/2505.07791v1","title":"Emerging (2+1)D electrodynamics and topological instanton in\n  pseudo-Hermitian two-level systems","summary":"We reveal a hidden electrodynamical structure emerging from a general\n$2\\times2$ pseudo-Hermitian system that exhibits real spectra. Even when the\nHamiltonian does not explicitly depend on time, the Berry curvature can be\nmapped onto a $2+1$ dimensional electromagnetic field arising from an\nartificial spacetime instanton, in sharp contrast to the Hermitian systems\nwhere the Berry curvature is equivalent to the static magnetic field of a\nmagnetic monopole in three spatial dimensions. The instanton appearing as a\nspacetime singularity carries a topological charge that quantizes the jump of\nmagnetic flux of the Berry curvature at the time origin. Our findings are\ndemonstrated in a simple example related to antiferromagnetic magnons.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.other,hep-th,quant-ph","published":"2025-05-12T17:43:54Z"}
{"aid":"http://arxiv.org/abs/2505.07795v1","title":"Mixed state deep thermalization","summary":"We introduce the notion of the mixed state projected ensemble (MSPE), a\ncollection of mixed states describing a local region of a quantum many-body\nsystem, conditioned upon measurements of the complementary region which are\nincomplete. This constitutes a generalization of the pure state projected\nensemble in which measurements are assumed ideal and complete, and which has\nbeen shown to tend towards limiting pure state distributions depending only on\nsymmetries of the system, thus representing a new kind of universality in\nquantum equilibration dubbed deep thermalization. We study the MSPE generated\nby solvable (1+1)d dual-unitary quantum circuit evolution, and identify the\nlimiting mixed state distributions which emerge at late times depending on the\nsize of the incomplete measurement, which we assume to be lossy, finding that\nthey correspond to certain random density matrix ensembles known in the\nliterature. We also derive the rate of the emergence of such universality.\nFurthermore, we investigate the quantum information properties of the states\ncomposing the ensemble, specifically their capacity to teleport quantum\ninformation between the ends of the system. The teleportation fidelity is upper\nbounded by the quantum conditional entropy, which we find exhibits a sharp\ntransition from zero to maximal when the number of measurements lost matches of\nthat the number of degrees of freedom to be teleported. Our results initiate\nthe first investigation of deep thermalization for mixed state ensembles, which\nare relevant for present-day quantum simulation experiments wherein\nmeasurements are typically not perfect, and also amount to a physical and\nnatural way of sampling from hitherto abstract random density matrix ensembles.","main_category":"quant-ph","categories":"quant-ph,cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-05-12T17:45:24Z"}
{"aid":"http://arxiv.org/abs/2505.07804v1","title":"Quon Classical Simulation: Unifying Clifford, Matchgates and\n  Entanglement","summary":"We propose a unified classical simulation framework for quantum circuits,\ntermed Quon Classical Simulation (QCS), built upon the diagrammatic formalism\nof the Quon language. Central to this framework is the introduction of magic\nholes, a topological feature that captures the global source of computational\nhardness in simulating quantum systems. Unlike conventional measures, the\ncomplexity of QCS is governed by the topological entanglement entropy\nassociated with these magic holes. We show that Clifford circuits and Matchgate\ncircuits are free of magic holes and thus efficiently simulable within our\nmodel. To capture the interaction structure of magic holes, we define a\ntopological tensor network representation and develop novel skein relations and\nreduction algorithms to simplify circuit representations. This approach\nsignificantly improves the efficiency of classical simulations and provides a\nunified explanation for the tractability of various known quantum circuit\nclasses. Our work offers a new topological perspective on the classical\nsimulability of quantum systems and topological complexity.","main_category":"quant-ph","categories":"quant-ph,cs.CC,math-ph,math.MP","published":"2025-05-12T17:53:05Z"}
{"aid":"http://arxiv.org/abs/2505.07806v1","title":"The Schützenberger involution and colored lattice models","summary":"Colored lattice models can be used to describe many different types of\nspecial functions of interest in both algebraic combinatorics and\nrepresentation theory, for example Schur polynomials, nonsymmetric Macdonald\npolynomials, and characters and Whittaker functions for representations of\np-adic groups. A notable example is the metaplectic ice model of which there\nare actually two different variants: a Gamma and a Delta variant. These\nvariants differ in key aspects but surprisingly produce equal partition\nfunctions, which are weighted sums over admissible configurations, and this\nequality is called the Gamma-Delta duality. The duality was used to prove the\nanalytic continuation of certain multiple Dirichlet series and is highly\nnon-trivial, especially since the number of configurations on each side of the\nequality can differ.\n  In this paper we construct a new family of solvable, colored lattice models\nand prove that they are dual to existing lattice models in the literature,\nincluding the above metaplectic case and the lattice model for\n(non-metaplectic) Iwahori Whittaker functions together with its crystal limit\nfor Demazure atoms for Cartan type A. The equality of partition functions is\nshown using Yang-Baxter equations involving R-matrices mixing lattice model\nrows of types Gamma and Delta.\n  For the crystal Demazure lattice model we show that the duality refines to a\nweight-respecting bijection of states given by the Sch\\\"utzenberger involution\non the associated Gelfand-Tsetlin patterns or semistandard Young tableaux. We\nalso show how the individual steps exchanging two rows in the proof of the\nduality for the partition functions refines to Berenstein-Kirillov, or\nBender-Knuth involutions.","main_category":"math.CO","categories":"math.CO,math.RT","published":"2025-05-12T17:54:54Z"}
{"aid":"http://arxiv.org/abs/2505.07809v1","title":"A Comparative Analysis of Static Word Embeddings for Hungarian","summary":"This paper presents a comprehensive analysis of various static word\nembeddings for Hungarian, including traditional models such as Word2Vec,\nFastText, as well as static embeddings derived from BERT-based models using\ndifferent extraction methods. We evaluate these embeddings on both intrinsic\nand extrinsic tasks to provide a holistic view of their performance. For\nintrinsic evaluation, we employ a word analogy task, which assesses the\nembeddings ability to capture semantic and syntactic relationships. Our results\nindicate that traditional static embeddings, particularly FastText, excel in\nthis task, achieving high accuracy and mean reciprocal rank (MRR) scores. Among\nthe BERT-based models, the X2Static method for extracting static embeddings\ndemonstrates superior performance compared to decontextualized and aggregate\nmethods, approaching the effectiveness of traditional static embeddings. For\nextrinsic evaluation, we utilize a bidirectional LSTM model to perform Named\nEntity Recognition (NER) and Part-of-Speech (POS) tagging tasks. The results\nreveal that embeddings derived from dynamic models, especially those extracted\nusing the X2Static method, outperform purely static embeddings. Notably, ELMo\nembeddings achieve the highest accuracy in both NER and POS tagging tasks,\nunderscoring the benefits of contextualized representations even when used in a\nstatic form. Our findings highlight the continued relevance of static word\nembeddings in NLP applications and the potential of advanced extraction methods\nto enhance the utility of BERT-based models. This piece of research contributes\nto the understanding of embedding performance in the Hungarian language and\nprovides valuable insights for future developments in the field. The training\nscripts, evaluation codes, restricted vocabulary, and extracted embeddings will\nbe made publicly available to support further research and reproducibility.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-12T17:57:11Z"}
{"aid":"http://arxiv.org/abs/2505.07817v1","title":"Pixel Motion as Universal Representation for Robot Control","summary":"We present LangToMo, a vision-language-action framework structured as a\ndual-system architecture that uses pixel motion forecasts as intermediate\nrepresentations. Our high-level System 2, an image diffusion model, generates\ntext-conditioned pixel motion sequences from a single frame to guide robot\ncontrol. Pixel motion-a universal, interpretable, and motion-centric\nrepresentation-can be extracted from videos in a self-supervised manner,\nenabling diffusion model training on web-scale video-caption data. Treating\ngenerated pixel motion as learned universal representations, our low level\nSystem 1 module translates these into robot actions via motion-to-action\nmapping functions, which can be either hand-crafted or learned with minimal\nsupervision. System 2 operates as a high-level policy applied at sparse\ntemporal intervals, while System 1 acts as a low-level policy at dense temporal\nintervals. This hierarchical decoupling enables flexible, scalable, and\ngeneralizable robot control under both unsupervised and supervised settings,\nbridging the gap between language, motion, and action. Checkout\nhttps://kahnchana.github.io/LangToMo for visualizations.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-05-12T17:59:32Z"}
{"aid":"http://arxiv.org/abs/2505.07818v1","title":"DanceGRPO: Unleashing GRPO on Visual Generation","summary":"Recent breakthroughs in generative models-particularly diffusion models and\nrectified flows-have revolutionized visual content creation, yet aligning model\noutputs with human preferences remains a critical challenge. Existing\nreinforcement learning (RL)-based methods for visual generation face critical\nlimitations: incompatibility with modern Ordinary Differential Equations\n(ODEs)-based sampling paradigms, instability in large-scale training, and lack\nof validation for video generation. This paper introduces DanceGRPO, the first\nunified framework to adapt Group Relative Policy Optimization (GRPO) to visual\ngeneration paradigms, unleashing one unified RL algorithm across two generative\nparadigms (diffusion models and rectified flows), three tasks (text-to-image,\ntext-to-video, image-to-video), four foundation models (Stable Diffusion,\nHunyuanVideo, FLUX, SkyReel-I2V), and five reward models (image/video\naesthetics, text-image alignment, video motion quality, and binary reward). To\nour knowledge, DanceGRPO is the first RL-based unified framework capable of\nseamless adaptation across diverse generative paradigms, tasks, foundational\nmodels, and reward models. DanceGRPO demonstrates consistent and substantial\nimprovements, which outperform baselines by up to 181% on benchmarks such as\nHPS-v2.1, CLIP Score, VideoAlign, and GenEval. Notably, DanceGRPO not only can\nstabilize policy optimization for complex video generation, but also enables\ngenerative policy to better capture denoising trajectories for Best-of-N\ninference scaling and learn from sparse binary feedback. Our results establish\nDanceGRPO as a robust and versatile solution for scaling Reinforcement Learning\nfrom Human Feedback (RLHF) tasks in visual generation, offering new insights\ninto harmonizing reinforcement learning and visual synthesis. The code will be\nreleased.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T17:59:34Z"}
{"aid":"http://arxiv.org/abs/2505.08192v1","title":"Saturation of the Cramér-Rao Bound for the Atomic Resonance Frequency\n  with Phased Array of Hyperbolic Secant Pulses","summary":"Precise estimation of the atomic resonance frequency is fundamental for the\ncharacterization and control of quantum systems. The resonance experiment is a\nstandard method for this measurement, wherein the drive field frequency is\nswept to invert the system population. We analyze the classical and quantum\nFisher information for the resonance experiment driven by hyperbolic secant\nshaped $\\pi$-pulses; setting a fundamental limit on the precision obtainable\nusing the resonance method. We show that measurements using sequences of pulses\nwith alternating phases globally saturates the quantum Cram\\'er-Rao bound,\nachieving the theoretical limit of precision for atomic resonance frequency\nestimation.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T03:02:01Z"}
{"aid":"http://arxiv.org/abs/2505.08216v1","title":"Rethink Repeatable Measures of Robot Performance with Statistical Query","summary":"For a general standardized testing algorithm designed to evaluate a specific\naspect of a robot's performance, several key expectations are commonly imposed.\nBeyond accuracy (i.e., closeness to a typically unknown ground-truth reference)\nand efficiency (i.e., feasibility within acceptable testing costs and equipment\nconstraints), one particularly important attribute is repeatability.\nRepeatability refers to the ability to consistently obtain the same testing\noutcome when similar testing algorithms are executed on the same subject robot\nby different stakeholders, across different times or locations. However,\nachieving repeatable testing has become increasingly challenging as the\ncomponents involved grow more complex, intelligent, diverse, and, most\nimportantly, stochastic. While related efforts have addressed repeatability at\nethical, hardware, and procedural levels, this study focuses specifically on\nrepeatable testing at the algorithmic level. Specifically, we target the\nwell-adopted class of testing algorithms in standardized evaluation:\nstatistical query (SQ) algorithms (i.e., algorithms that estimate the expected\nvalue of a bounded function over a distribution using sampled data). We propose\na lightweight, parameterized, and adaptive modification applicable to any SQ\nroutine, whether based on Monte Carlo sampling, importance sampling, or\nadaptive importance sampling, that makes it provably repeatable, with\nguaranteed bounds on both accuracy and efficiency. We demonstrate the\neffectiveness of the proposed approach across three representative scenarios:\n(i) established and widely adopted standardized testing of manipulators, (ii)\nemerging intelligent testing algorithms for operational risk assessment in\nautomated vehicles, and (iii) developing use cases involving command tracking\nperformance evaluation of humanoid robots in locomotion tasks.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-05-13T04:14:48Z"}
{"aid":"http://arxiv.org/abs/2505.08224v1","title":"A conditional match rate anomaly and ranking pressure in residency\n  matching programs","summary":"In the medical residency matching markets of the U.S. and Japan, we observe\nthat an applicant's probability of matching with their first-listed program is\ndisproportionately higher than that of matching with their second-listed\nprogram, given that they were rejected by the first. In contrast, the\nconditional probabilities of matching with lower-ranked programs are markedly\nlower and remain relatively stable. Furthermore, several experts have noted\nthat participating programs sometimes exert pressure on applicants to\nmanipulate the order of their rank-order lists.\n  In this study, we show that this pressure can account for the observed\nprobability pattern, considering the verifiability of being ranked first on the\nlist. Using empirical data, we identify the prevalence of ranking pressure and\nquantify its impact on rank-order list changes and welfare under a simplified\nacceptance and pressure process. Additionally, we explore the implementation of\na random permutation of the submitted rank-order list as a measure to\ncounteract list reordering due to pressure. Our analysis shows that the\nbenefits of this intervention outweigh the associated efficiency losses.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-05-13T04:57:11Z"}
{"aid":"http://arxiv.org/abs/2505.08242v1","title":"Congenital Heart Disease recognition using Deep Learning/Transformer\n  models","summary":"Congenital Heart Disease (CHD) remains a leading cause of infant morbidity\nand mortality, yet non-invasive screening methods often yield false negatives.\nDeep learning models, with their ability to automatically extract features, can\nassist doctors in detecting CHD more effectively. In this work, we investigate\nthe use of dual-modality (sound and image) deep learning methods for CHD\ndiagnosis. We achieve 73.9% accuracy on the ZCHSound dataset and 80.72%\naccuracy on the DICOM Chest X-ray dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T05:34:06Z"}
{"aid":"http://arxiv.org/abs/2505.08243v1","title":"Training Strategies for Efficient Embodied Reasoning","summary":"Robot chain-of-thought reasoning (CoT) -- wherein a model predicts helpful\nintermediate representations before choosing actions -- provides an effective\nmethod for improving the generalization and performance of robot policies,\nespecially vision-language-action models (VLAs). While such approaches have\nbeen shown to improve performance and generalization, they suffer from core\nlimitations, like needing specialized robot reasoning data and slow inference\nspeeds. To design new robot reasoning approaches that address these issues, a\nmore complete characterization of why reasoning helps policy performance is\ncritical. We hypothesize several mechanisms by which robot reasoning improves\npolicies -- (1) better representation learning, (2) improved learning\ncurricularization, and (3) increased expressivity -- then devise simple\nvariants of robot CoT reasoning to isolate and test each one. We find that\nlearning to generate reasonings does lead to better VLA representations, while\nattending to the reasonings aids in actually leveraging these features for\nimproved action prediction. Our results provide us with a better understanding\nof why CoT reasoning helps VLAs, which we use to introduce two simple and\nlightweight alternative recipes for robot reasoning. Our proposed approaches\nachieve significant performance gains over non-reasoning policies,\nstate-of-the-art results on the LIBERO-90 benchmark, and a 3x inference speedup\ncompared to standard robot reasoning.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-13T05:35:00Z"}
{"aid":"http://arxiv.org/abs/2505.08249v1","title":"Modelling of time-dependent electrostatic effects and AFM-based surface\n  conductivity characterization","summary":"Atomic Force Microscopy (AFM) combined with electrical modes provides a\npowerful contactless approach to characterize material electrical properties at\nthe nanoscale. However, conventional electrostatic models often overlook\ndynamic charge effects, which are particularly relevant for 2D materials\ndeposited on insulating substrates. In this work, we introduce a theoretical\nframework that extends traditional electrostatic models by incorporating charge\ndynamics, analyzing two key cases: quasi-ideal conductors and quasi-ideal\ninsulators. Our model establishes a characteristic timescale, $\\tau$, which\ngoverns charge redistribution and measurement reliability. Experimental\nvalidation using Graphene Oxide, Reduced Graphene Oxide, and lightly reduced GO\ndemonstrates strong dependence of frequency shift on surface conductivity,\nconfirming our predictions. Temperature-dependent measurements further reveal\nconductivity variations consistent with disordered electronic materials. These\nfindings provide critical insight into the impact of finite surface\nconductivity on AFM-based techniques and establish a novel method for\nevaluating charge dynamics in individual flakes of 2D materials and propose an\nalternative, contactless method for estimating surface conductivity.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,physics.app-ph","published":"2025-05-13T05:57:24Z"}
{"aid":"http://arxiv.org/abs/2505.08263v1","title":"LLM-Based Detection of Tangled Code Changes for Higher-Quality\n  Method-Level Bug Datasets","summary":"Tangled code changes-commits that conflate unrelated modifications such as\nbug fixes, refactorings, and enhancements-introduce significant noise into bug\ndatasets and adversely affect the performance of bug prediction models.\nAddressing this issue at a fine-grained, method-level granularity remains\nunderexplored. This is critical to address, as recent bug prediction models,\ndriven by practitioner demand, are increasingly focusing on finer granularity\nrather than traditional class- or file-level predictions. This study\ninvestigates the utility of Large Language Models (LLMs) for detecting tangled\ncode changes by leveraging both commit messages and method-level code diffs. We\nformulate the problem as a binary classification task and evaluate multiple\nprompting strategies, including zero-shot, few-shot, and chain-of-thought\nprompting, using state-of-the-art proprietary LLMs such as GPT-4o and\nGemini-2.0-Flash.\n  Our results demonstrate that combining commit messages with code diffs\nsignificantly enhances model performance, with the combined few-shot and\nchain-of-thought prompting achieving an F1-score of 0.88. Additionally, we\nexplore embedding-based machine learning models trained on LLM-generated\nembeddings, where a multi-layer perceptron classifier achieves superior\nperformance (F1-score: 0.906, MCC: 0.807). These findings are encouraging for\nthe research community, as method-level bug prediction remains an open research\nproblem, largely due to the lack of noise-free bug datasets. This research not\nonly contributes a novel method-level perspective to the untangling problem but\nalso highlights practical avenues for enhancing automated software quality\nassessment tools.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-13T06:26:13Z"}
{"aid":"http://arxiv.org/abs/2505.08273v1","title":"IrrMap: A Large-Scale Comprehensive Dataset for Irrigation Method\n  Mapping","summary":"We introduce IrrMap, the first large-scale dataset (1.1 million patches) for\nirrigation method mapping across regions. IrrMap consists of multi-resolution\nsatellite imagery from LandSat and Sentinel, along with key auxiliary data such\nas crop type, land use, and vegetation indices. The dataset spans 1,687,899\nfarms and 14,117,330 acres across multiple western U.S. states from 2013 to\n2023, providing a rich and diverse foundation for irrigation analysis and\nensuring geospatial alignment and quality control. The dataset is ML-ready,\nwith standardized 224x224 GeoTIFF patches, the multiple input modalities,\ncarefully chosen train-test-split data, and accompanying dataloaders for\nseamless deep learning model training andbenchmarking in irrigation mapping.\nThe dataset is also accompanied by a complete pipeline for dataset generation,\nenabling researchers to extend IrrMap to new regions for irrigation data\ncollection or adapt it with minimal effort for other similar applications in\nagricultural and geospatial analysis. We also analyze the irrigation method\ndistribution across crop groups, spatial irrigation patterns (using Shannon\ndiversity indices), and irrigated area variations for both LandSat and\nSentinel, providing insights into regional and resolution-based differences. To\npromote further exploration, we openly release IrrMap, along with the derived\ndatasets, benchmark models, and pipeline code, through a GitHub repository:\nhttps://github.com/Nibir088/IrrMap and Data repository:\nhttps://huggingface.co/Nibir/IrrMap, providing comprehensive documentation and\nimplementation details.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T06:36:41Z"}
{"aid":"http://arxiv.org/abs/2505.08277v1","title":"Iteratively reweighted kernel machines efficiently learn sparse\n  functions","summary":"The impressive practical performance of neural networks is often attributed\nto their ability to learn low-dimensional data representations and hierarchical\nstructure directly from data. In this work, we argue that these two phenomena\nare not unique to neural networks, and can be elicited from classical kernel\nmethods. Namely, we show that the derivative of the kernel predictor can detect\nthe influential coordinates with low sample complexity. Moreover, by\niteratively using the derivatives to reweight the data and retrain kernel\nmachines, one is able to efficiently learn hierarchical polynomials with finite\nleap complexity. Numerical experiments illustrate the developed theory.","main_category":"stat.ML","categories":"stat.ML,cs.LG,math.OC,math.ST,stat.TH","published":"2025-05-13T06:41:39Z"}
{"aid":"http://arxiv.org/abs/2505.08278v1","title":"Investigating self-supervised features for expressive, multilingual\n  voice conversion","summary":"Voice conversion (VC) systems are widely used for several applications, from\nspeaker anonymisation to personalised speech synthesis. Supervised approaches\nlearn a mapping between different speakers using parallel data, which is\nexpensive to produce. Unsupervised approaches are typically trained to\nreconstruct the input signal, which is composed of the content and the speaker\ninformation. Disentangling these components is a challenge and often leads to\nspeaker leakage or prosodic information removal. In this paper, we explore\nvoice conversion by leveraging the potential of self-supervised learning (SSL).\nA combination of the latent representations of SSL models, concatenated with\nspeaker embeddings, is fed to a vocoder which is trained to reconstruct the\ninput. Zero-shot voice conversion results show that this approach allows to\nkeep the prosody and content of the source speaker while matching the speaker\nsimilarity of a VC system based on phonetic posteriorgrams (PPGs).","main_category":"eess.AS","categories":"eess.AS","published":"2025-05-13T06:44:03Z"}
{"aid":"http://arxiv.org/abs/2505.08280v1","title":"Extremising eigenvalues of the GJMS operators in a fixed conformal class","summary":"Let $(M,g)$ be a closed Riemannian manifold of dimension $n\\geq 3$. If $s$ is\na positive integer satisfying $2s<n$, we let $P_g^s$ be the GJMS operator of\norder $2s$ in $M$. We investigate in this paper the extremal values taken by\nfixed eigenvalues of $P_h^s$ as $h$ runs though the whole conformal class\n$[g]$. Due to the conformal covariance of $P_g^s$ we need only consider two\nvariational problems: maximising negative eigenvalues of $P_h^s$ and minimising\npositive eigenvalues of $P_h^s$ when $h \\in [g]$. These extremal values are\nconformal invariants of $(M,g)$ and optimisers for these problems, when they\nexist, are known to not be smooth metrics in general. To overcome this we\ndefine and investigate eigenvalues for singular conformal metrics, that we call\n\\emph{generalised eigenvalues}. We develop a new variational framework for\nrenormalised eigenvalues of any index over the set of admissible (singular)\nconformal factors: we obtain semi-continuity results and Euler-Lagrange\nequations for local extremals. Using this framework we prove, under mild\nassumptions on $(M,g)$ and $s$, several new (non)-existence results for\nextremals of renormalised eigenvalues over $[g]$. These include, among other\nresults, a maximisation result for negative eigenvalues, the minimisation of\nthe principal eigenvalue of $P_g^s$ and the analysis of several invariants of\nthe round sphere $(\\mathbb{S}^n, g_0)$. We also establish a strong connection\nbetween the existence of optimisers and (nodal) solutions of prescribed\n$Q$-curvature equations. Our analysis covers the case of any order $s \\ge 1$\nand allows $P_g^s$ to have kernel. When $s=1$ and $P_g^1$ is the conformal\nLaplacian, this problem was previously investigated when $k=1, 2$. Our work\nstrongly generalises previous results to eigenvalues of any index.","main_category":"math.DG","categories":"math.DG,math.AP,math.SP","published":"2025-05-13T06:50:50Z"}
{"aid":"http://arxiv.org/abs/2505.08298v1","title":"On Analysis of Superimposed Pilot in Multi-User Massive MIMO with\n  Massive Connectivity","summary":"The simultaneous transmission of numerous users presents substantial\nchallenges due to the inherent trade-off between channel estimation and\ninformation transmission in multi-user multiple-input multiple-output (MIMO)\nsystem. In this paper, we explore the use of the superimposed pilot (SP) scheme\nto tackle the large transmitting users, where the number of users may exceed\nthe coherent time. SP scheme incorporates both transmitted data and noise in\nthe channel estimation process, which is significant different from the\ncounterpart of RP scheme. We provide an in-depth analysis of the interaction\nbetween interference caused by channel estimation errors and noise. We then\nderive the explicit expression for the scaling law of the mutual information\nlower bound (MILB) in relation to the number of users and the levels of\ntransmitted power. Besides, the optimal power allocation between pilots and\ndata transmission is also derived analytically. The analytical results\ndemonstrate that the SP scheme significantly improves performance compared to\ntraditional RP scheme in our consider case. Numerical results are also\npresented to validate our theoretical derivations.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-13T07:22:38Z"}
{"aid":"http://arxiv.org/abs/2505.08299v1","title":"Efficient Unstructured Pruning of Mamba State-Space Models for\n  Resource-Constrained Environments","summary":"State-space models (SSMs), particularly the Mamba architecture, have emerged\nas powerful alternatives to Transformers for sequence modeling, offering\nlinear-time complexity and competitive performance across diverse tasks.\nHowever, their large parameter counts pose significant challenges for\ndeployment in resource-constrained environments. We propose a novel\nunstructured pruning framework tailored for Mamba models that achieves up to\n70\\% parameter reduction while retaining over 95\\% of the original performance.\nOur approach integrates three key innovations: (1) a gradient-aware magnitude\npruning technique that combines weight magnitude and gradient information to\nidentify less critical parameters, (2) an iterative pruning schedule that\ngradually increases sparsity to maintain model stability, and (3) a global\npruning strategy that optimizes parameter allocation across the entire model.\nThrough extensive experiments on WikiText-103, Long Range Arena, and ETT\ntime-series benchmarks, we demonstrate significant efficiency gains with\nminimal performance degradation. Our analysis of pruning effects on Mamba's\ncomponents reveals critical insights into the architecture's redundancy and\nrobustness, enabling practical deployment in resource-constrained settings\nwhile broadening Mamba's applicability.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-05-13T07:23:08Z"}
{"aid":"http://arxiv.org/abs/2505.08307v1","title":"Against Radical Relationalism: in Defense of the Ordinal Structure of\n  Time","summary":"Some authors in the quantum gravity community endorse, explicitly or\nimplicitly, a radical relationalist view of time which states that the ordinal\nstructure of time is not needed even in our classical theories, especially in\ngeneral relativity. In this article I analyze this position and the arguments\nsupporting it, and I argue that there are some serious concerns with some of\nthe radical relationalists' arguments which make it an unattractive position.\nIn this sense, I conclude that the chrono-ordinal structures of our theories\nplay important theoretical and explanatory roles and that they can be taken to\nbe part of the empirical content of our theories.","main_category":"physics.hist-ph","categories":"physics.hist-ph,gr-qc","published":"2025-05-13T07:33:37Z"}
{"aid":"http://arxiv.org/abs/2505.08314v1","title":"SemCSINet: A Semantic-Aware CSI Feedback Network in Massive MIMO Systems","summary":"Massive multiple-input multiple-output (MIMO) technology is a key enabler of\nmodern wireless communication systems, which demand accurate downlink channel\nstate information (CSI) for optimal performance. Although deep learning (DL)\nhas shown great potential in improving CSI feedback, most existing approaches\nfail to exploit the semantic relationship between CSI and other related channel\nmetrics. In this paper, we propose SemCSINet, a semantic-aware\nTransformer-based framework that incorporates Channel Quality Indicator (CQI)\ninto the CSI feedback process. By embedding CQI information and leveraging a\njoint coding-modulation (JCM) scheme, SemCSINet enables efficient,\ndigital-friendly CSI feedback under noisy feedback channels. Experimental\nresults on DeepMIMO datasets show that SemCSINet significantly outperforms\nconventional methods, particularly in scenarios with low signal-to-noise ratio\n(SNR) and low compression ratios (CRs), highlighting the effectiveness of\nsemantic embedding in enhancing CSI reconstruction accuracy and system\nrobustness.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-13T07:43:12Z"}
{"aid":"http://arxiv.org/abs/2505.08316v1","title":"Improving Unsupervised Task-driven Models of Ventral Visual Stream via\n  Relative Position Predictivity","summary":"Based on the concept that ventral visual stream (VVS) mainly functions for\nobject recognition, current unsupervised task-driven methods model VVS by\ncontrastive learning, and have achieved good brain similarity. However, we\nbelieve functions of VVS extend beyond just object recognition. In this paper,\nwe introduce an additional function involving VVS, named relative position (RP)\nprediction. We first theoretically explain contrastive learning may be unable\nto yield the model capability of RP prediction. Motivated by this, we\nsubsequently integrate RP learning with contrastive learning, and propose a new\nunsupervised task-driven method to model VVS, which is more inline with\nbiological reality. We conduct extensive experiments, demonstrating that: (i)\nour method significantly improves downstream performance of object recognition\nwhile enhancing RP predictivity; (ii) RP predictivity generally improves the\nmodel brain similarity. Our results provide strong evidence for the involvement\nof VVS in location perception (especially RP prediction) from a computational\nperspective.","main_category":"cs.CE","categories":"cs.CE,cs.CV","published":"2025-05-13T07:45:21Z"}
{"aid":"http://arxiv.org/abs/2505.08324v1","title":"An incremental algorithm for non-convex AI-enhanced medical image\n  processing","summary":"Solving non-convex regularized inverse problems is challenging due to their\ncomplex optimization landscapes and multiple local minima. However, these\nmodels remain widely studied as they often yield high-quality, task-oriented\nsolutions, particularly in medical imaging, where the goal is to enhance\nclinically relevant features rather than merely minimizing global error. We\npropose incDG, a hybrid framework that integrates deep learning with\nincremental model-based optimization to efficiently approximate the\n$\\ell_0$-optimal solution of imaging inverse problems. Built on the Deep Guess\nstrategy, incDG exploits a deep neural network to generate effective\ninitializations for a non-convex variational solver, which refines the\nreconstruction through regularized incremental iterations. This design combines\nthe efficiency of Artificial Intelligence (AI) tools with the theoretical\nguarantees of model-based optimization, ensuring robustness and stability. We\nvalidate incDG on TpV-regularized optimization tasks, demonstrating its\neffectiveness in medical image deblurring and tomographic reconstruction across\ndiverse datasets, including synthetic images, brain CT slices, and\nchest-abdomen scans. Results show that incDG outperforms both conventional\niterative solvers and deep learning-based methods, achieving superior accuracy\nand stability. Moreover, we confirm that training incDG without ground truth\ndoes not significantly degrade performance, making it a practical and powerful\ntool for solving non-convex inverse problems in imaging and beyond.","main_category":"cs.CV","categories":"cs.CV,cs.NA,math.NA","published":"2025-05-13T08:03:14Z"}
{"aid":"http://arxiv.org/abs/2505.08326v1","title":"Coding Theorem for Generalized Reed-Solomon Codes","summary":"In this paper, we prove that the sub-field images of generalized Reed-Solomon\n(RS) codes can achieve the symmetric capacity of p-ary memoryless channels.\nUnlike the totally random linear code ensemble, as a class of maximum distance\nseparable (MDS) codes, the generalized RS code ensemble lacks the pair-wise\nindependence among codewords and has non-identical distributions of nonzero\ncodewords. To prove the coding theorem for the p-ary images of generalized RS\ncodes, we analyze the exponential upper bound on the error probability of the\ngeneralized RS code in terms of its spectrum using random coding techniques. In\nthe finite-length region, we present an ML decoding algorithm for the\ngeneralized RS codes over the binary erasure channels (BECs). In particular,\nthe algebraic structure of the generalized RS codes allows us to implement the\nparallel Lagrange interpolation to derive an ordered systematic matrix.\nSubsequently, we can reconstruct the ML codeword through a change of basis,\naccelerating the conventional Gaussian elimination (GE), as validated in the\nsimulation results. Additionally, we apply this decoding technique to the\nLC-OSD algorithm over the additive white Gaussian noise (AWGN) channels with\nbinary phase shift keying (BPSK) modulation and three-level pulse amplitude\nmodulation (3PAM). Simulation results show that, in the high-rate region,\ngeneralized RS codes defined over fields of characteristic three with 3-PAM\nperform better than those defined over fields of characteristic two with BPSK.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-13T08:05:41Z"}
{"aid":"http://arxiv.org/abs/2505.08327v1","title":"Low-Complexity Inference in Continual Learning via Compressed Knowledge\n  Transfer","summary":"Continual learning (CL) aims to train models that can learn a sequence of\ntasks without forgetting previously acquired knowledge. A core challenge in CL\nis balancing stability -- preserving performance on old tasks -- and plasticity\n-- adapting to new ones. Recently, large pre-trained models have been widely\nadopted in CL for their ability to support both, offering strong generalization\nfor new tasks and resilience against forgetting. However, their high\ncomputational cost at inference time limits their practicality in real-world\napplications, especially those requiring low latency or energy efficiency. To\naddress this issue, we explore model compression techniques, including pruning\nand knowledge distillation (KD), and propose two efficient frameworks tailored\nfor class-incremental learning (CIL), a challenging CL setting where task\nidentities are unavailable during inference. The pruning-based framework\nincludes pre- and post-pruning strategies that apply compression at different\ntraining stages. The KD-based framework adopts a teacher-student architecture,\nwhere a large pre-trained teacher transfers downstream-relevant knowledge to a\ncompact student. Extensive experiments on multiple CIL benchmarks demonstrate\nthat the proposed frameworks achieve a better trade-off between accuracy and\ninference complexity, consistently outperforming strong baselines. We further\nanalyze the trade-offs between the two frameworks in terms of accuracy and\nefficiency, offering insights into their use across different scenarios.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-13T08:07:40Z"}
{"aid":"http://arxiv.org/abs/2505.08332v1","title":"Improving the detection significance of gravitational wave transient\n  searches with CNN models","summary":"Gravitational wave (GW) transient searches rely on signal-noise\ndiscriminators to distinguish astrophysical signals from noise artefacts. These\ndiscriminators are typically tuned towards expected signal morphologies, which\nmay limit their effectiveness as detector sensitivity improves and more complex\nsignals, such as from core collapse supernovae or compact binary mergers\nfeaturing precession, higher-order harmonics, or eccentricity, become\ndetectable. In this work, we use a Convolutional Neural Network-based approach\nto classify noise transients from astrophysical transients, aiming to enhance\nthe sensitivity of existing searches. We evaluate our method on two matched\nfilter based searches, PyCBC-IMBH and PyCBC-HM tuned for Intermediate Mass\nBlack Hole (IMBH) binary systems. Our approach improves the sensitive\nvolume-time reach of these searches by approximately 30% at a false alarm rate\nof once per 100 years. Finally, we apply our method to the first four chunks of\nthe first half of the third observation run and demonstrate a marked\nimprovement in significance. In particular, we significantly improve the first\nIMBH binary GW event GW190521 with an IFAR exceeding 42000 years.","main_category":"gr-qc","categories":"gr-qc,astro-ph.IM","published":"2025-05-13T08:18:43Z"}
{"aid":"http://arxiv.org/abs/2505.08339v1","title":"Unified approach to classical equations of inverse problem theory","summary":"The boundary control (BC-) method is an approach to inverse problems based\nupon their deep relations to control and system theory. We show that the\nclassical integral equations of inverse problem theory (Gelfand-Levitan, Krein\nand Marchenko equations) can be derived in the framework of the BC-method in a\nunified way. Namely, to solve each of these equations is in fact to solve a\nrelevant boundary control problem, whereas its solution is determined by the\ninverse data.","main_category":"math.AP","categories":"math.AP,math.SP","published":"2025-05-13T08:31:50Z"}
{"aid":"http://arxiv.org/abs/2505.08343v1","title":"An Identifiable Cost-Aware Causal Decision-Making Framework Using\n  Counterfactual Reasoning","summary":"Decision making under abnormal conditions is a critical process that involves\nevaluating the current state and determining the optimal action to restore the\nsystem to a normal state at an acceptable cost. However, in such scenarios,\nexisting decision-making frameworks highly rely on reinforcement learning or\nroot cause analysis, resulting in them frequently neglecting the cost of the\nactions or failing to incorporate causal mechanisms adequately. By relaxing the\nexisting causal decision framework to solve the necessary cause, we propose a\nminimum-cost causal decision (MiCCD) framework via counterfactual reasoning to\naddress the above challenges. Emphasis is placed on making counterfactual\nreasoning processes identifiable in the presence of a large amount of mixed\nanomaly data, as well as finding the optimal intervention state in a continuous\ndecision space. Specifically, it formulates a surrogate model based on causal\ngraphs, using abnormal pattern clustering labels as supervisory signals. This\nenables the approximation of the structural causal model among the variables\nand lays a foundation for identifiable counterfactual reasoning. With the\ncausal structure approximated, we then established an optimization model based\non counterfactual estimation. The Sequential Least Squares Programming (SLSQP)\nalgorithm is further employed to optimize intervention strategies while taking\ncosts into account. Experimental evaluations on both synthetic and real-world\ndatasets reveal that MiCCD outperforms conventional methods across multiple\nmetrics, including F1-score, cost efficiency, and ranking quality(nDCG@k\nvalues), thus validating its efficacy and broad applicability.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-13T08:41:45Z"}
{"aid":"http://arxiv.org/abs/2505.08350v1","title":"STORYANCHORS: Generating Consistent Multi-Scene Story Frames for\n  Long-Form Narratives","summary":"This paper introduces StoryAnchors, a unified framework for generating\nhigh-quality, multi-scene story frames with strong temporal consistency. The\nframework employs a bidirectional story generator that integrates both past and\nfuture contexts to ensure temporal consistency, character continuity, and\nsmooth scene transitions throughout the narrative. Specific conditions are\nintroduced to distinguish story frame generation from standard video synthesis,\nfacilitating greater scene diversity and enhancing narrative richness. To\nfurther improve generation quality, StoryAnchors integrates Multi-Event Story\nFrame Labeling and Progressive Story Frame Training, enabling the model to\ncapture both overarching narrative flow and event-level dynamics. This approach\nsupports the creation of editable and expandable story frames, allowing for\nmanual modifications and the generation of longer, more complex sequences.\nExtensive experiments show that StoryAnchors outperforms existing open-source\nmodels in key areas such as consistency, narrative coherence, and scene\ndiversity. Its performance in narrative consistency and story richness is also\non par with GPT-4o. Ultimately, StoryAnchors pushes the boundaries of\nstory-driven frame generation, offering a scalable, flexible, and highly\neditable foundation for future research.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-13T08:48:10Z"}
{"aid":"http://arxiv.org/abs/2505.08357v1","title":"Hamiltonian replica exchange augmented with diffusion-based generative\n  models and importance sampling to assess biomolecular conformational basins\n  and barriers","summary":"Enhanced sampling techniques are essential for exploring biomolecular\nconformational dynamics that occur on timescales inaccessible to conventional\nmolecular dynamics (MD) simulations. This study introduces a framework that\ncombines Hamiltonian replica exchange (REST2) with denoising diffusion\nprobabilistic models (DDPMs) and importance sampling to enhance the mapping of\nconformational free-energy landscapes. Building on previous applications of\nDDPMs to temperature replica exchange (TREM), we propose two key improvements.\nFirst, we adapt the method to REST2 by treating potential energy as a\nfluctuating variable. This adaptation allows for more efficient sampling in\nlarge biomolecular systems. Second, to further improve resolution in\nhigh-barrier regions, we develop an iterative scheme combining replica\nexchange, DDPM, and importance sampling along known collective variables.\nBenchmarking on the mini-protein CLN025 demonstrates that DDPM-refined REST2\nachieves comparable accuracy to TREM while requiring fewer replicas.\nApplication to the enzyme PTP1B reveals a loop transition pathway consistent\nwith prior complex biased simulations, showcasing the approach's ability to\nuncover high-barrier transitions with minimal computational overhead with\nrespect to conventional replica exchange approaches. Overall, this hybrid\nstrategy enables more efficient exploration of free-energy landscapes,\nexpanding the utility of generative models in enhanced sampling simulations.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,physics.bio-ph,physics.chem-ph,physics.data-an","published":"2025-05-13T09:02:28Z"}
{"aid":"http://arxiv.org/abs/2505.08360v1","title":"A Comparison Between Human and Generative AI Decision-Making Attributes\n  in Complex Health Services","summary":"A comparison between human and Generative AI decision-making attributes in\ncomplex health services is a knowledge gap in the literature, at present.\nHumans may possess unique attributes beneficial to decision-making in complex\nhealth services such as health policy and health regulation, but are also\nsusceptible to decision-making flaws. The objective is to explore whether\nhumans have unique, and/or helpful attributes that contribute to optimal\ndecision-making in complex health services. This comparison may also shed light\non whether humans are likely to compete, cooperate, or converge with Generative\nAI. The comparison is based on two published reviews: a scoping review of human\nattributes [1] and a rapid review of Generative AI attributes [2]. The analysis\ncategorizes attributes by uniqueness and impact. The results are presented in\ntabular form, comparing the sets and subsets of human and Generative AI\nattributes. Humans and Generative AI decision-making attributes have\ncomplementary strengths. Cooperation between these two entities seems more\nlikely than pure competition. To maintain meaningful decision-making roles,\nhumans could develop their unique attributes, with decision-making systems\nintegrating both human and Generative AI contributions. These entities may also\nconverge, in future.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-05-13T09:08:18Z"}
{"aid":"http://arxiv.org/abs/2505.08361v1","title":"Modeling Unseen Environments with Language-guided Composable Causal\n  Components in Reinforcement Learning","summary":"Generalization in reinforcement learning (RL) remains a significant\nchallenge, especially when agents encounter novel environments with unseen\ndynamics. Drawing inspiration from human compositional reasoning -- where known\ncomponents are reconfigured to handle new situations -- we introduce World\nModeling with Compositional Causal Components (WM3C). This novel framework\nenhances RL generalization by learning and leveraging compositional causal\ncomponents. Unlike previous approaches focusing on invariant representation\nlearning or meta-learning, WM3C identifies and utilizes causal dynamics among\ncomposable elements, facilitating robust adaptation to new tasks. Our approach\nintegrates language as a compositional modality to decompose the latent space\ninto meaningful components and provides theoretical guarantees for their unique\nidentification under mild assumptions. Our practical implementation uses a\nmasked autoencoder with mutual information constraints and adaptive sparsity\nregularization to capture high-level semantic information and effectively\ndisentangle transition dynamics. Experiments on numerical simulations and\nreal-world robotic manipulation tasks demonstrate that WM3C significantly\noutperforms existing methods in identifying latent processes, improving policy\nlearning, and generalizing to unseen tasks.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-13T09:08:28Z"}
{"aid":"http://arxiv.org/abs/2505.08369v1","title":"On the first quantization and quantum diversity of photons","summary":"Quantum theory of photons based on the first quantization technique, similar\nto that used by Schroedinger in the formulation of quantum mechanics, is\nconsidered. First, scalar quantum mechanics of photons operating with the\nphoton wave functions is discussed. Using the first quantization, the wave\nequation, the Schroedinger-like equations, and the Dirac equation for photons\nare derived. Then, vector quantum mechanics of photons is introduced, which\ndefines the electromagnetic vector fields. Using the first quantization, the\nMaxwell equations for photons in magneto-dielectric medium are obtained. Since\nthe photon electric and magnetic fields satisfy the Maxwell equations, all what\nis known about the classical optical fields can be directly transferred to\nphotons demonstrating their quantum diversity. Relationships between the scalar\nand vector quantum mechanics of photons and between the Dirac and Maxwell\nequations are analyzed. To describe the propagation of photons in dispersive\nmedia novel equations are introduced.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-05-13T09:13:47Z"}
{"aid":"http://arxiv.org/abs/2505.08371v1","title":"Density Ratio-based Causal Discovery from Bivariate Continuous-Discrete\n  Data","summary":"This paper proposes a causal discovery method for mixed bivariate data\nconsisting of one continuous and one discrete variable. Existing\nconstraint-based approaches are ineffective in the bivariate setting, as they\nrely on conditional independence tests that are not suited to bivariate data.\nScore-based methods either impose strong distributional assumptions or face\nchallenges in fairly comparing causal directions between variables of different\ntypes, due to differences in their information content. We introduce a novel\napproach that determines causal direction by analyzing the monotonicity of the\nconditional density ratio of the continuous variable, conditioned on different\nvalues of the discrete variable. Our theoretical analysis shows that the\nconditional density ratio exhibits monotonicity when the continuous variable\ncauses the discrete variable, but not in the reverse direction. This property\nprovides a principled basis for comparing causal directions between variables\nof different types, free from strong distributional assumptions and bias\narising from differences in their information content. We demonstrate its\neffectiveness through experiments on both synthetic and real-world datasets,\nshowing superior accuracy compared to existing methods.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-05-13T09:18:41Z"}
{"aid":"http://arxiv.org/abs/2505.08379v1","title":"Influence of density-dependent bag function $B(n)$ on strange stars for\n  non-zero strange quark mass ($m_s\\neq0$) in $f(R,T)$ gravity consistent with\n  observational validation","summary":"In this work a new class of solution of Einstein field equation for isotropic\nstrange star using Mak and Harko density profile in the context of MIT bag\nmodel equation of state considering finite value of strange quark mass ($m_s$)\nis presented using the framework of modified gravity $f(R,T)=R+2\\zeta T$,\nwhere, $\\zeta$ is the coupling parameter. To incorporate quark core hypothesis\nwith a physically viable stellar framework a baryon number density ($n$)\ndependent bag constant $B(n)$ has been analysed, using exponential type\nparametrisation. The energy per baryon ($E_B$) has been investigated to\nrestrict $B(n)$ within stable window, specifically satisfying the condition\n$E_B\\leq 930.4~MeV$, which corresponds to the binding energy of\n$\\isotope[56]{Fe}$. Also it has been noted that $n$ has a maximum value of\n$0.36~fm^{-3}$ irrespective of $m_s$. As with decreasing $n$, $E_B$ rises,\nthere is a lower limit of $n$ which depends on $m_s$. It has been observed that\nall the essential characteristics are satisfactorily fulfilled within the\nstellar interior for the selected set of parameter space. Maximum mass and\nradius in this model is found by numerically solving the TOV equations which\ngives a mass of about $2.02~M_{\\odot}$ with a radius of $11.44~km$. The\nproposed model has been shown to comply with the required energy conditions and\nsatisfies the criterion for dynamical stability, thereby confirming its\nphysical plausibility as a physically consistent stellar model within the\nparameter space used.","main_category":"gr-qc","categories":"gr-qc","published":"2025-05-13T09:23:13Z"}
{"aid":"http://arxiv.org/abs/2505.08386v1","title":"An effcient variational quantum Korkin-Zolotarev algorithm for solving\n  shortest vector problems","summary":"Noisy intermediate-scale quantum cryptanalysis focuses on the capability of\nnear-term quantum devices to solve the mathematical problems underlying\ncryptography, and serves as a cornerstone for the design of post-quantum\ncryptographic algorithms. For the shortest vector problem (SVP), which is one\nof the computationally hard problems in lattice-based cryptography, existing\nnear-term quantum cryptanalysis algorithms map the problem onto a\nfully-connected quantum Ising Hamiltonian, and obtain the solution by\noptimizing for the first excited state. However, as the quantum system scales\nwith the problem size, determining the first excited state becomes intractable\ndue to the exponentially increased complexity for large-scale SVP instances. In\nthis paper, we propose a variational quantum Korkin-Zolotarev (VQKZ) algorithm,\nwhich significantly reduces the qubit requirement for solving the SVP.\nSpecifically, by transforming the original SVP into a series of subproblems on\nprojected sublattices, the proposed VQKZ algorithm enables near-term quantum\ndevices to solve SVP instances with lattice dimensions 61.39% larger than those\nsolvable by previous methods. Furthermore, numerical simulations demonstrate\nthat the proposed VQKZ algorithm can significantly outperform existing methods\nin terms of the length of solution vectors.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T09:32:21Z"}
{"aid":"http://arxiv.org/abs/2505.08397v1","title":"Metal-Insulator Transition described by Natural Orbital Functional\n  Theory","summary":"The metal-insulator transition (MIT) is a fundamental phenomenon in condensed\nmatter physics and a hallmark of strong electronic correlations. Hydrogen-based\nsystems offer a simple yet powerful model for investigating the MIT, as their\ninsulating behavior arises purely from electron-electron interactions. In this\nwork, we study finite hydrogen clusters with cubic geometries using Natural\nOrbital Functional Theory (NOFT), a method capable of accurately describing\ncorrelated systems beyond mean-field approaches. We focus on two key signatures\nof the MIT: the fundamental energy gap and the harmonic average of the atomic\none-particle reduced density matrix. Our results show that NOFT captures the\ntransition from insulating to metallic behavior as the interatomic distance\ndecreases. By extrapolating the energy gap to the thermodynamic limit, we\nestimate a critical distance rc ~ 1.2 Ang, in excellent agreement with quantum\nMonte Carlo benchmarks. These findings demonstrate the reliability of NOFT for\ndescribing strong correlation effects in large-scale models.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci,physics.chem-ph,quant-ph","published":"2025-05-13T09:52:18Z"}
{"aid":"http://arxiv.org/abs/2505.08401v1","title":"The modular automorphisms of quotient modular curves","summary":"We obtain the modular automorphism group of any quotient modular curve of\nlevel $N$, with $4,9\\nmid N$. In particular, we obtain some non-expected\nautomorphisms of order 3 that appear for the quotient modular curves when the\nAtkin-Lehner involution $w_{25}$ belongs to the quotient modular group, such\nautomorphisms are not necessarily defined over $\\mathbb{Q}$. As a consequence\nof the results, we obtain the full automorphism group of the quotient modular\ncurve $X_0^*(N^2)$, for sufficiently large $N$.","main_category":"math.NT","categories":"math.NT","published":"2025-05-13T09:56:14Z"}
{"aid":"http://arxiv.org/abs/2505.08410v1","title":"Understanding molecular ratios in the carbon and oxygen poor outer Milky\n  Way with interpretable machine learning","summary":"Context. The outer Milky Way has a lower metallicity than our solar\nneighbourhood, but still many molecules are detected in the region. Molecular\nline ratios can serve as probes to better understand the chemistry and physics\nin these regions. Aims. We use interpretable machine learning to study 9\ndifferent molecular ratios, helping us understand the forward connection\nbetween the physics of these environments and the carbon and oxygen\nchemistries. Methods. Using a large grid of astrochemical models generated\nusing UCLCHEM, we study the properties of molecular clouds of low oxygen and\ncarbon initial abundance. We first try to understand the line ratios using a\nclassical analysis. We then move on to using interpretable machine learning,\nnamely Shapley Additive Explanations (SHAP), to understand the higher order\ndependencies of the ratios over the entire parameter grid. Lastly we use the\nUniform Manifold Approximation and Projection technique (UMAP) as a reduction\nmethod to create intuitive groupings of models. Results. We find that the\nparameter space is well covered by the line ratios, allowing us to investigate\nall input parameters. SHAP analysis shows that the temperature and density are\nthe most important features, but the carbon and oxygen abundances are important\nin parts of the parameter space. Lastly, we find that we can group different\ntypes of ratios using UMAP. Conclusions. We show the chosen ratios are mostly\nsensitive to changes in the carbon initial abundance, together with the\ntemperature and density. Especially the CN/HCN and HNC/HCN ratio are shown to\nbe sensitive to the initial carbon abundance, making them excellent probes for\nthis parameter. Out of the ratios, only CS/SO shows a sensitivity to the oxygen\nabundance.","main_category":"astro-ph.GA","categories":"astro-ph.GA,cs.LG","published":"2025-05-13T10:08:37Z"}
{"aid":"http://arxiv.org/abs/2505.08426v1","title":"DHECA-SuperGaze: Dual Head-Eye Cross-Attention and Super-Resolution for\n  Unconstrained Gaze Estimation","summary":"Unconstrained gaze estimation is the process of determining where a subject\nis directing their visual attention in uncontrolled environments. Gaze\nestimation systems are important for a myriad of tasks such as driver\ndistraction monitoring, exam proctoring, accessibility features in modern\nsoftware, etc. However, these systems face challenges in real-world scenarios,\npartially due to the low resolution of in-the-wild images and partially due to\ninsufficient modeling of head-eye interactions in current state-of-the-art\n(SOTA) methods. This paper introduces DHECA-SuperGaze, a deep learning-based\nmethod that advances gaze prediction through super-resolution (SR) and a dual\nhead-eye cross-attention (DHECA) module. Our dual-branch convolutional backbone\nprocesses eye and multiscale SR head images, while the proposed DHECA module\nenables bidirectional feature refinement between the extracted visual features\nthrough cross-attention mechanisms. Furthermore, we identified critical\nannotation errors in one of the most diverse and widely used gaze estimation\ndatasets, Gaze360, and rectified the mislabeled data. Performance evaluation on\nGaze360 and GFIE datasets demonstrates superior within-dataset performance of\nthe proposed method, reducing angular error (AE) by 0.48{\\deg} (Gaze360) and\n2.95{\\deg} (GFIE) in static configurations, and 0.59{\\deg} (Gaze360) and\n3.00{\\deg} (GFIE) in temporal settings compared to prior SOTA methods.\nCross-dataset testing shows improvements in AE of more than 1.53{\\deg}\n(Gaze360) and 3.99{\\deg} (GFIE) in both static and temporal settings,\nvalidating the robust generalization properties of our approach.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T10:45:08Z"}
{"aid":"http://arxiv.org/abs/2505.08437v1","title":"TT-DF: A Large-Scale Diffusion-Based Dataset and Benchmark for Human\n  Body Forgery Detection","summary":"The emergence and popularity of facial deepfake methods spur the vigorous\ndevelopment of deepfake datasets and facial forgery detection, which to some\nextent alleviates the security concerns about facial-related artificial\nintelligence technologies. However, when it comes to human body forgery, there\nhas been a persistent lack of datasets and detection methods, due to the later\ninception and complexity of human body generation methods. To mitigate this\nissue, we introduce TikTok-DeepFake (TT-DF), a novel large-scale\ndiffusion-based dataset containing 6,120 forged videos with 1,378,857 synthetic\nframes, specifically tailored for body forgery detection. TT-DF offers a wide\nvariety of forgery methods, involving multiple advanced human image animation\nmodels utilized for manipulation, two generative configurations based on the\ndisentanglement of identity and pose information, as well as different\ncompressed versions. The aim is to simulate any potential unseen forged data in\nthe wild as comprehensively as possible, and we also furnish a benchmark on\nTT-DF. Additionally, we propose an adapted body forgery detection model,\nTemporal Optical Flow Network (TOF-Net), which exploits the spatiotemporal\ninconsistencies and optical flow distribution differences between natural data\nand forged data. Our experiments demonstrate that TOF-Net achieves favorable\nperformance on TT-DF, outperforming current state-of-the-art extendable facial\nforgery detection models. For our TT-DF dataset, please refer to\nhttps://github.com/HashTAG00002/TT-DF.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T11:01:25Z"}
{"aid":"http://arxiv.org/abs/2505.08438v1","title":"A Survey of 3D Reconstruction with Event Cameras: From Event-based\n  Geometry to Neural 3D Rendering","summary":"Event cameras have emerged as promising sensors for 3D reconstruction due to\ntheir ability to capture per-pixel brightness changes asynchronously. Unlike\nconventional frame-based cameras, they produce sparse and temporally rich data\nstreams, which enable more accurate 3D reconstruction and open up the\npossibility of performing reconstruction in extreme environments such as\nhigh-speed motion, low light, or high dynamic range scenes. In this survey, we\nprovide the first comprehensive review focused exclusively on 3D reconstruction\nusing event cameras. The survey categorises existing works into three major\ntypes based on input modality - stereo, monocular, and multimodal systems, and\nfurther classifies them by reconstruction approach, including geometry-based,\ndeep learning-based, and recent neural rendering techniques such as Neural\nRadiance Fields and 3D Gaussian Splatting. Methods with a similar research\nfocus were organised chronologically into the most subdivided groups. We also\nsummarise public datasets relevant to event-based 3D reconstruction. Finally,\nwe highlight current research limitations in data availability, evaluation,\nrepresentation, and dynamic scene handling, and outline promising future\nresearch directions. This survey aims to serve as a comprehensive reference and\na roadmap for future developments in event-driven 3D reconstruction.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-13T11:04:04Z"}
{"aid":"http://arxiv.org/abs/2505.08444v1","title":"Symbolically-Guided Visual Plan Inference from Uncurated Video Data","summary":"Visual planning, by offering a sequence of intermediate visual subgoals to a\ngoal-conditioned low-level policy, achieves promising performance on\nlong-horizon manipulation tasks. To obtain the subgoals, existing methods\ntypically resort to video generation models but suffer from model hallucination\nand computational cost. We present Vis2Plan, an efficient, explainable and\nwhite-box visual planning framework powered by symbolic guidance. From raw,\nunlabeled play data, Vis2Plan harnesses vision foundation models to\nautomatically extract a compact set of task symbols, which allows building a\nhigh-level symbolic transition graph for multi-goal, multi-stage planning. At\ntest time, given a desired task goal, our planner conducts planning at the\nsymbolic level and assembles a sequence of physically consistent intermediate\nsub-goal images grounded by the underlying symbolic representation. Our\nVis2Plan outperforms strong diffusion video generation-based visual planners by\ndelivering 53\\% higher aggregate success rate in real robot settings while\ngenerating visual plans 35$\\times$ faster. The results indicate that Vis2Plan\nis able to generate physically consistent image goals while offering fully\ninspectable reasoning steps.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-13T11:13:00Z"}
{"aid":"http://arxiv.org/abs/2505.08447v1","title":"A Practical Approach to Generating First-Order Rician Channel Statistics\n  in a RC plus CATR Chamber at mmWave","summary":"This paper explores a novel hybrid configuration integrating a Reverberation\nChamber (RC) with a Compact Antenna Test Range (CATR) to achieve a controllable\nRician K-factor. The focus is testing directive antennas in the lower FR2\nfrequency bands (24.25-29.5 GHz) for 5G and beyond wireless applications. The\nstudy meticulously evaluates 39 unique configurations, using a stationary horn\nantenna for consistent reference K-factor characterization, and considers\nvariables like absorbers and CATR polarization. Results demonstrate that the\nK-factor can be effectively adjusted within the hybrid setup, maintaining\nsubstantial margins above the noise level across all configurations. Sample\nindependence is confirmed for at least 600 samples in all cases. The Bootstrap\nAnderson-Darling goodness-of-fit test verifies that the data align with Rician\nor Rayleigh distributions. Analysis of total received power, stirred and\nunstirred power and frequency-dependent modeling reveals that power variables\nare inversely related to frequency, while the K-factor remains\nfrequency-independent. The hybrid RC-CATR system achieves a wide range of\nfrequency-averaged K-factors from -9.2 dB to 40.8 dB, with an average\ngranularity of 1.3 dB. Notably, configurations using co-polarized CATR signals\nyield large K-factors, reduced system losses, and improved frequency stability,\nunderscoring the system's efficacy for millimeter-wave over-the-air testing.\nThis research offers a cost-efficient and repeatable method for generating\ncomplex Rician fading channels at mmWave frequencies, crucial for the effective\nOTA testing of advanced wireless devices.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-13T11:20:14Z"}
{"aid":"http://arxiv.org/abs/2505.08449v1","title":"Nonnegative solutions to nonlocal parabolic equations","summary":"We aim to study nonnegative, global solutions to a general class of nonlocal\nparabolic equations with bounded measurable coefficients. First, we prove a\nWidder-type theorem. Such a result has previously been studied only for certain\ntranslation invariant operators, and new ideas are needed in our general\nsetting. Second, we establish sharp two-sided bounds for the fundamental\nsolution via purely variational techniques, entirely bypassing tools from\nsemigroup theory, Dirichlet forms, and stochastic analysis. Third, we derive\nsharp Harnack-type estimates that are novel even for the fractional heat\nequation.","main_category":"math.AP","categories":"math.AP,math.PR","published":"2025-05-13T11:24:09Z"}
{"aid":"http://arxiv.org/abs/2505.08450v1","title":"IterKey: Iterative Keyword Generation with LLMs for Enhanced Retrieval\n  Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) has emerged as a way to complement the\nin-context knowledge of Large Language Models (LLMs) by integrating external\ndocuments. However, real-world applications demand not only accuracy but also\ninterpretability. While dense retrieval methods provide high accuracy, they\nlack interpretability; conversely, sparse retrieval methods offer transparency\nbut often fail to capture the full intent of queries due to their reliance on\nkeyword matching. To address these issues, we introduce IterKey, an LLM-driven\niterative keyword generation framework that enhances RAG via sparse retrieval.\nIterKey consists of three LLM-driven stages: generating keywords for retrieval,\ngenerating answers based on retrieved documents, and validating the answers. If\nvalidation fails, the process iteratively repeats with refined keywords. Across\nfour QA tasks, experimental results show that IterKey achieves 5% to 20%\naccuracy improvements over BM25-based RAG and simple baselines. Its performance\nis comparable to dense retrieval-based RAG and prior iterative query refinement\nmethods using dense models. In summary, IterKey is a novel BM25-based approach\nleveraging LLMs to iteratively refine RAG, effectively balancing accuracy with\ninterpretability.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-13T11:25:15Z"}
{"aid":"http://arxiv.org/abs/2505.08455v1","title":"VCRBench: Exploring Long-form Causal Reasoning Capabilities of Large\n  Video Language Models","summary":"Despite recent advances in video understanding, the capabilities of Large\nVideo Language Models (LVLMs) to perform video-based causal reasoning remains\nunderexplored, largely due to the absence of relevant and dedicated benchmarks\nfor evaluating causal reasoning in visually grounded and goal-driven settings.\nTo fill this gap, we introduce a novel benchmark named Video-based long-form\nCausal Reasoning (VCRBench). We create VCRBench using procedural videos of\nsimple everyday activities, where the steps are deliberately shuffled with each\nclip capturing a key causal event, to test whether LVLMs can identify, reason\nabout, and correctly sequence the events needed to accomplish a specific goal.\nMoreover, the benchmark is carefully designed to prevent LVLMs from exploiting\nlinguistic shortcuts, as seen in multiple-choice or binary QA formats, while\nalso avoiding the challenges associated with evaluating open-ended QA. Our\nevaluation of state-of-the-art LVLMs on VCRBench suggests that these models\nstruggle with video-based long-form causal reasoning, primarily due to their\ndifficulty in modeling long-range causal dependencies directly from visual\nobservations. As a simple step toward enabling such capabilities, we propose\nRecognition-Reasoning Decomposition (RRD), a modular approach that breaks\nvideo-based causal reasoning into two sub-tasks of video recognition and causal\nreasoning. Our experiments on VCRBench show that RRD significantly boosts\naccuracy on VCRBench, with gains of up to 25.2%. Finally, our thorough analysis\nreveals interesting insights, for instance, that LVLMs primarily rely on\nlanguage knowledge for complex video-based long-form causal reasoning tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T11:35:58Z"}
{"aid":"http://arxiv.org/abs/2505.08459v1","title":"Strategy-Augmented Planning for Large Language Models via Opponent\n  Exploitation","summary":"Efficiently modeling and exploiting opponents is a long-standing challenge in\nadversarial domains. Large Language Models (LLMs) trained on extensive textual\ndata have recently demonstrated outstanding performance in general tasks,\nintroducing new research directions for opponent modeling. Some studies\nprimarily focus on directly using LLMs to generate decisions based on the\nelaborate prompt context that incorporates opponent descriptions, while these\napproaches are limited to scenarios where LLMs possess adequate domain\nexpertise. To address that, we introduce a two-stage Strategy-Augmented\nPlanning (SAP) framework that significantly enhances the opponent exploitation\ncapabilities of LLM-based agents by utilizing a critical component, the\nStrategy Evaluation Network (SEN). Specifically, in the offline stage, we\nconstruct an explicit strategy space and subsequently collect strategy-outcome\npair data for training the SEN network. During the online phase, SAP\ndynamically recognizes the opponent's strategies and greedily exploits them by\nsearching best response strategy on the well-trained SEN, finally translating\nstrategy to a course of actions by carefully designed prompts. Experimental\nresults show that SAP exhibits robust generalization capabilities, allowing it\nto perform effectively not only against previously encountered opponent\nstrategies but also against novel, unseen strategies. In the MicroRTS\nenvironment, SAP achieves a 85.35\\% performance improvement over baseline\nmethods and matches the competitiveness of reinforcement learning approaches\nagainst state-of-the-art (SOTA) rule-based AI.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-13T11:41:10Z"}
{"aid":"http://arxiv.org/abs/2505.08460v1","title":"Landau levels in a time-dependent magnetic field: the Madelung fluid\n  perspective","summary":"We propose to revisit a fundamental quantum problem, namely the evolution of\nan electron's wave function under a time-dependent magnetic field, with the\ndual perspective of the Madelung fluid. First we present an analysis of the\nproblem in a quantum mechanistic fashion, based on a perturbation theory of the\nLandau levels, and next address the same problem with the Madelung equations.\nWe show that the latter formulation does not only provide an intuitive\nderivation of the solution, but it also allows us to understand the diabatic\ncharacter of quantum evolution in terms of mechanical energy transfers. The\nsloshing oscillations of the wave function can be then interpreted as the\nconsequence of deviations from the balance between the magnetic force and the\ngradient of the Bohm potential in the Landau levels. This study shows that the\nMadelung fluid approach reveals analogies between a priori unrelated concepts\nfrom quantum mechanics and geophysical fluid dynamics.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T11:41:24Z"}
{"aid":"http://arxiv.org/abs/2505.08477v1","title":"Emerging axion detection in artificial magnetoelectric materials","summary":"The origin of dark matter is a fundamental problem in physics. Axions are\nconsidered a key component of dark matter, characterized by very weak\nChern-Simons couplings to electromagnetism, gravity, and fermions. We propose a\nnovel symmetry-breaking detection mechanism in magnetoelectric materials,\nallowing for a linear axionic coupling between magnetism and ferroelectric\npolarization. We focus on strain gradient Sr2IrO4, where the breaking of\nspace-inversion symmetry results in an emergent polar phase and out-of-plane\nmagnetic moment, exhibiting a flexomagnetoelectric effect. In this material,\nthe linear P||M enables direct coupling between the external axion field and\nthe intrinsic axion-like field within the material. This mechanism amplifies\nthe weak electromagnetic signals induced by axions, paving the way for\npioneering axion detection. These signals can be detected by monitoring changes\nin macroscopic physical quantities, such as the magnetoelectric and magnetic\nresponses. In contrast to conventional detection techniques, this mechanism\nsignificantly enhances the sensitivity of the axion-electron and axion-photon\ncoupling, providing a novel platform for axion detection and advancing the\nstudy of dark matter through the magnetoelectric effect.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-13T12:04:30Z"}
{"aid":"http://arxiv.org/abs/2505.08490v1","title":"Dynamic interfacial effects in ultrathin ferromagnetic bilayers","summary":"We investigate the magnetization dynamics of an ultrathin Co (1.5 nm) /Py\n(1.5 nm) bilayer system from femtosecond (fs) to nanosecond (ns) timescales.\nMagnetization dynamics in the fs timescales is characterized as a highly\nnon-equilibrium regime due to an ultrafast reduction of magnetization by laser\nexcitation. On the other hand, the dynamics in the ns timescales is\ncharacterized as a close-to-equilibrium regime involving the excitation of\ncoherent magnons. We demonstrate that the interfacial interaction between the\nCo and Py layers in these two non-equilibrium regimes across the timescales is\ndynamic and simultaneously influences the magnetization loss in the fs\ntimescales and the magnon dynamics in the ns timescales. On ultrafast (fs)\ntimescales, comparison between time-resolved magneto-optical Kerr effect\n(TR-MOKE) measurements and temperature-based {\\mu}T model simulations reveals\nthat the bilayer exhibits demagnetization dynamics intermediate between those\nof its individual layers. When driven far from equilibrium by ultrashort laser\npulse excitation, the magnetization dynamics of the individual Co and Py layers\nappear to remain decoupled and evolve independently in the initial stages of\nthe ultrafast response. On the other hand, in the ns regime, the two individual\nlayers of the bilayer precess together at the same frequency in a coupled\nmanner as one effective single layer. Furthermore, by correlating the ultrafast\ndemagnetization to precessional damping we attempt to bridge the two\nnon-equilibrium regimes across fs to ns timescales. These results improve our\nunderstanding of magnetization dynamics across timescales in ultrathin\nexchanged-coupled ferromagnetic bilayers and provide valuable insights for the\ndesign of high-frequency and energy efficient spintronic device concepts.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-05-13T12:21:58Z"}
{"aid":"http://arxiv.org/abs/2505.08493v1","title":"BizChat: Scaffolding AI-Powered Business Planning for Small Business\n  Owners Across Digital Skill Levels","summary":"Generative AI can help small business owners automate tasks, increase\nefficiency, and improve their bottom line. However, despite the seemingly\nintuitive design of systems like ChatGPT, significant barriers remain for those\nless comfortable with technology. To address these disparities, prior work\nhighlights accessory skills -- beyond prompt engineering -- users must master\nto successfully adopt generative AI including keyboard shortcuts, editing\nskills, file conversions, and browser literacy. Building on a design workshop\nseries and 15 interviews with small businesses, we introduce BizChat, a large\nlanguage model (LLM)-powered web application that helps business owners across\ndigital skills levels write their business plan -- an essential but often\nneglected document. To do so, BizChat's interface embodies three design\nconsiderations inspired by learning sciences: ensuring accessibility to users\nwith less digital skills while maintaining extensibility to power users\n(\"low-floor-high-ceiling\"), providing in situ micro-learning to support\nentrepreneurial education (\"just-in-time learning\"), and framing interaction\naround business activities (\"contextualized technology introduction\"). We\nconclude with plans for a future BizChat deployment.","main_category":"cs.HC","categories":"cs.HC,H.5.2","published":"2025-05-13T12:23:11Z"}
{"aid":"http://arxiv.org/abs/2505.08512v1","title":"Experimental investigation of a novel liquid metal plasma facing\n  component with pre-filled microstructures","summary":"Regarding the plasma facing components (PFCs) in nuclear fusion, liquid metal\nPFCs with stable free surface flow on PFC surface are considered a promising\nalternative. However, due to the poor wettability of liquid metal on most solid\nsubstrates and the complex magnetohydrodynamic (MHD), the realization of stable\nfree surface flow on PFCs surface is challenging. In the present study, using\nthe 3D printed methods, we developed a novel liquid metal PFC surface with\nMIcrostructures pre-FIlled by Liquid Metal (MIFILM) to realize a stable free\nliquid metal surface flow. The experimental results demonstrated that due to\nthe existence of MIFILM, the apparent contact angle (ACA) of liquid metal\nchanges from 140$^{\\circ}$ to approximately 20$^{\\circ}$, indicating a\ntransition from hydrophobic to hydrophilic. When the liquid metal flows on the\nMIFILM substrate, it is found that the liquid metal can completely spread on\nthe surface with a stable and orderly free surface, even at a low flow rate.\nMoreover, the liquid metal could exhibit sustained spreading properties on the\nMIFILM substrate under a strong transverse magnetic field (up to 1.6 T).\nResults indicate that the magnetic field induces limited MHD drag but also\naccelerates the flow via two-dimensional effects. When the Stuart number $N<1$,\nthe flow accelerates and the film thickness decreases. For $N>1$, both flow\nvelocity and film thickness gradually stabilize. Therefore, the present novel\nMIFILM can offer a good choice for liquid metal PFC substrates in nuclear\nfusion.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-05-13T12:44:04Z"}
{"aid":"http://arxiv.org/abs/2505.08516v1","title":"Learning Advanced Self-Attention for Linear Transformers in the Singular\n  Value Domain","summary":"Transformers have demonstrated remarkable performance across diverse domains.\nThe key component of Transformers is self-attention, which learns the\nrelationship between any two tokens in the input sequence. Recent studies have\nrevealed that the self-attention can be understood as a normalized adjacency\nmatrix of a graph. Notably, from the perspective of graph signal processing\n(GSP), the self-attention can be equivalently defined as a simple graph filter,\napplying GSP using the value vector as the signal. However, the self-attention\nis a graph filter defined with only the first order of the polynomial matrix,\nand acts as a low-pass filter preventing the effective leverage of various\nfrequency information. Consequently, existing self-attention mechanisms are\ndesigned in a rather simplified manner. Therefore, we propose a novel method,\ncalled \\underline{\\textbf{A}}ttentive \\underline{\\textbf{G}}raph\n\\underline{\\textbf{F}}ilter (AGF), interpreting the self-attention as learning\nthe graph filter in the singular value domain from the perspective of graph\nsignal processing for directed graphs with the linear complexity w.r.t. the\ninput length $n$, i.e., $\\mathcal{O}(nd^2)$. In our experiments, we demonstrate\nthat AGF achieves state-of-the-art performance on various tasks, including Long\nRange Arena benchmark and time series classification.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-13T12:48:04Z"}
{"aid":"http://arxiv.org/abs/2505.08518v1","title":"SPP-SBL: Space-Power Prior Sparse Bayesian Learning for Block Sparse\n  Recovery","summary":"The recovery of block-sparse signals with unknown structural patterns remains\na fundamental challenge in structured sparse signal reconstruction. By\nproposing a variance transformation framework, this paper unifies existing\npattern-based block sparse Bayesian learning methods, and introduces a novel\nspace power prior based on undirected graph models to adaptively capture the\nunknown patterns of block-sparse signals. By combining the EM algorithm with\nhigh-order equation root-solving, we develop a new structured sparse Bayesian\nlearning method, SPP-SBL, which effectively addresses the open problem of space\ncoupling parameter estimation in pattern-based methods. We further demonstrate\nthat learning the relative values of space coupling parameters is key to\ncapturing unknown block-sparse patterns and improving recovery accuracy.\nExperiments validate that SPP-SBL successfully recovers various challenging\nstructured sparse signals (e.g., chain-structured signals and multi-pattern\nsparse signals) and real-world multi-modal structured sparse signals (images,\naudio), showing significant advantages in recovery accuracy across multiple\nmetrics.","main_category":"math.OC","categories":"math.OC,cs.LG","published":"2025-05-13T12:49:25Z"}
{"aid":"http://arxiv.org/abs/2505.08520v1","title":"Towards Resilient SDA: Graph Theory and Cooperative Control in\n  Distributed Network Architectures","summary":"Space Domain Awareness (SDA) involves the detection, tracking, and\ncharacterization of space objects through the fusion of data across the space\nenvironment. As SDA advances beyond localized or operator-specific\ncapabilities, there is a growing reliance on in-domain space assets for\nreal-time, distributed sensing and decision-making. This paper investigates the\npotential of on-orbit collaboration by enabling data sharing among\nheterogeneous satellites as actuators within a single orbital regime. Using\ngraph-theoretic constructs, we define regions of spatial responsibility via\nVoronoi tessellations and model communication pathways between actuators using\nDelaunay triangulation. We apply this framework independently to Low Earth\nOrbit (LEO), Medium Earth Orbit (MEO), Highly Elliptical Orbit (HEO), and\nGeostationary Orbit (GEO), and analyze each to quantify structural properties\nrelevant to efficient communication, cooperative control, and synchronization\nfor SDA operations with the growth in deployments of space assets.","main_category":"math.CO","categories":"math.CO","published":"2025-05-13T12:51:06Z"}
{"aid":"http://arxiv.org/abs/2505.08536v1","title":"Short Wins Long: Short Codes with Language Model Semantic Correction\n  Outperform Long Codes","summary":"This paper presents a novel semantic-enhanced decoding scheme for\ntransmitting natural language sentences with multiple short block codes over\nnoisy wireless channels. After ASCII source coding, the natural language\nsentence message is divided into segments, where each is encoded with short\nblock channel codes independently before transmission. At the receiver, each\nshort block of codewords is decoded in parallel, followed by a semantic error\ncorrection (SEC) model to reconstruct corrupted segments semantically. We\ndesign and train the SEC model based on Bidirectional and Auto-Regressive\nTransformers (BART). Simulations demonstrate that the proposed scheme can\nsignificantly outperform encoding the sentence with one conventional long LDPC\ncode, in terms of block error rate (BLER), semantic metrics, and decoding\nlatency. Finally, we proposed a semantic hybrid automatic repeat request (HARQ)\nscheme to further enhance the error performance, which selectively requests\nretransmission depends on semantic uncertainty.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-13T13:07:01Z"}
{"aid":"http://arxiv.org/abs/2505.08551v1","title":"Untouchable sets of size $2q \\pm 1$ in $PG(2,q)$","summary":"An untouchable set in a projective plane is a set of points such that no line\nof the plane meets the set in exactly one point. Recently, H\\'eger and Nagy\n(Avoiding Secants of Given Size in Finite Projective Planes, J. Combin. Des.\n33:83--93, 2024.) provided a generalization of untouchable sets to $k$-avoiding\nsets, and addressed the issue of the spectrum of sizes that such sets can\nattain in finite planes. Specific to the untouchable set case, the authors\nstate as an open question the existence of untouchable sets of size $2q-1$ and\n$2q+1$. We answer this question in the affirmative for Desarguesian planes of\neven order, and provide a construction of untouchable sets of size $2q+1$ in\n$PG(2,q)$ for $q \\equiv 3\\pmod{4}$.","main_category":"math.CO","categories":"math.CO","published":"2025-05-13T13:22:07Z"}
{"aid":"http://arxiv.org/abs/2505.08554v1","title":"On the solutions of a double-phase Dirichlet problem involving the\n  1-Laplacian","summary":"In this paper we study a double-phase problem involving the 1-Laplacian with\nnon-homogeneous Dirichlet boundary conditions and show the existence and\nuniqueness of a solution in a suitable weak sense. We also provide a\nvariational characterization of this solution via the corresponding\nminimization problem.","main_category":"math.AP","categories":"math.AP","published":"2025-05-13T13:27:20Z"}
{"aid":"http://arxiv.org/abs/2505.08555v1","title":"Simulation and measurement of Black Body Radiation background in a\n  Transition Edge Sensor","summary":"The Any Light Particle Search II (ALPS II) experiment at DESY, Hamburg, is a\nLight-Shining-through-a-Wall (LSW) experiment aiming to probe the existence of\naxions and axion-like particles (ALPs), which are candidates for dark matter.\nData collection in ALPS II is underway utilizing a heterodyne-based detection\nscheme. A complementary run for confirmation or as an alternative method is\nplanned using single photon detection, requiring a sensor capable of measuring\nlow-energy photons ($1064\\,\\mathrm{nm}$, $1.165\\,\\mathrm{eV}$) with high\nefficiency (higher than $50\\,\\%$) and a low background rate (below\n$7.7\\cdot10^{-6}\\,\\mathrm{cps}$). To meet these requirements, we are\ninvestigating a tungsten Transition Edge Sensor (TES) provided by NIST, which\noperates in its superconducting transition region at millikelvin temperatures.\nThis sensor exploits the drastic change in resistance caused by the absorption\nof a single photon. We find that the background observed in the setup with a\nfiber-coupled TES is consistent with Black Body Radiation (BBR) as the primary\nbackground contributor. A framework was developed to simulate BBR propagation\nto the TES under realistic conditions. The framework not only allows the\nexploration of background reduction strategies, such as improving the TES\nenergy resolution, but also reproduces, within uncertainties, the spectral\ndistribution of the observed background. These simulations have been validated\nwith experimental data, in agreement with the modeled background distribution,\nand show that the improved energy resolution reduces the background rate in the\n$1064\\,\\mathrm{nm}$ signal region by one order of magnitude, to approximately\n$10^{-4}\\,\\mathrm{cps}$. However, this rate must be reduced further to meet the\nALPS II requirements.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-05-13T13:28:05Z"}
{"aid":"http://arxiv.org/abs/2505.08579v1","title":"Assembly of High-Performance van der Waals Devices Using Commercial\n  Polyvinyl Chloride Films","summary":"Control over the position, orientation, and stacking order of two-dimensional\n(2D) materials within van der Waals heterostructures is crucial for\napplications in electronics, spintronics, optics, and sensing. The most popular\nstrategy for assembling 2D materials uses purpose-built stamps with working\nsurfaces made from one of several different polymers. However, these stamps\ntypically require tedious preparation steps and suffer from poor durability,\ncontamination, and limited applicability to specific 2D materials or surfaces.\nHere, we demonstrate significant improvements upon current 2D flake transfer\nand assembly practices by using mechanically durable stamps made from polyvinyl\nchloride (PVC) thin films. These stamps are simpler to prepare compared with\nexisting methods and can withstand multiple transfer cycles, enabling greater\nreusability. We use two commercially available PVC films with distinct pick-up\nand release temperatures. Together, these films also enable polymer-to-polymer\nflake transfers and stack-and-flip fabrication of inverted heterostructures in\none seamless process. Systematic comparisons of cleaning processes confirm the\nremoval of PVC-derived residue from the assembled structures to create\natomically clean interfaces. We demonstrate the utility and versatility of\nthese polymer films and transfer process by fabricating graphene/hexagonal\nboron nitride heterostructure devices with high-performance electrical\ncharacteristics. Further, we demonstrate the ability to pick up and to deposit\nbulk aluminum gallium arsenide nanostructured films, enabling the creation of\nheterogeneously integrated devices. This technique increases fabrication rates,\nimproves device quality, and enables more complex structures, thereby\nfacilitating nanomaterial assembly in a broad range of applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-13T13:54:41Z"}
{"aid":"http://arxiv.org/abs/2505.08581v1","title":"ReSurgSAM2: Referring Segment Anything in Surgical Video via Credible\n  Long-term Tracking","summary":"Surgical scene segmentation is critical in computer-assisted surgery and is\nvital for enhancing surgical quality and patient outcomes. Recently, referring\nsurgical segmentation is emerging, given its advantage of providing surgeons\nwith an interactive experience to segment the target object. However, existing\nmethods are limited by low efficiency and short-term tracking, hindering their\napplicability in complex real-world surgical scenarios. In this paper, we\nintroduce ReSurgSAM2, a two-stage surgical referring segmentation framework\nthat leverages Segment Anything Model 2 to perform text-referred target\ndetection, followed by tracking with reliable initial frame identification and\ndiversity-driven long-term memory. For the detection stage, we propose a\ncross-modal spatial-temporal Mamba to generate precise detection and\nsegmentation results. Based on these results, our credible initial frame\nselection strategy identifies the reliable frame for the subsequent tracking.\nUpon selecting the initial frame, our method transitions to the tracking stage,\nwhere it incorporates a diversity-driven memory mechanism that maintains a\ncredible and diverse memory bank, ensuring consistent long-term tracking.\nExtensive experiments demonstrate that ReSurgSAM2 achieves substantial\nimprovements in accuracy and efficiency compared to existing methods, operating\nin real-time at 61.2 FPS. Our code and datasets will be available at\nhttps://github.com/jinlab-imvr/ReSurgSAM2.","main_category":"cs.CV","categories":"cs.CV,eess.IV,q-bio.TO","published":"2025-05-13T13:56:10Z"}
{"aid":"http://arxiv.org/abs/2505.08583v1","title":"Strain Induced Robust Skyrmion lattice at Room Temperature in van der\n  Waals Ferromagnet","summary":"Manipulating topological magnetic orders of two-dimensional (2D) magnets by\nstrain, once achieved, offers enormous potential for future low-power flexible\nspintronic applications. In this work, by placing Fe3GaTe2 (FGaT), a\nroom-temperature 2D ferromagnet, on flexible substrate, we demonstrate a\nfield-free and robust formation of skyrmion lattice induced by strain. By\napplying a minimal strain of ~0.80% to pre-annealed FGaT flakes, the Magnetic\nForce Microscopy (MFM) tip directly triggers the transition from maze-like\ndomains to an ordered skyrmion lattice while scanning the sample surface. The\nskyrmion lattice is rather stable against extensive cyclic mechanical testing\n(stretching, bending, and twisting over 2000 cycles each). It also exhibited\nstability across a wide range of magnetic fields (~2.9 kOe) and temperatures (~\n323 K), as well as long-term retention stability, highlighting its robustness\nand field free stabilization. The strain effect reduces the lattice symmetry\nand enhances the Dzyaloshinskii-Moriya interaction (DMI) of FGaT, thus\nstabilizing the skyrmion lattice. Our findings highlight the potential of FGaT\nfor integrating magnetic skyrmions into future low-power-consumption flexible\nspintronics devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-13T13:56:36Z"}
{"aid":"http://arxiv.org/abs/2505.08599v1","title":"MINIMALIST: switched-capacitor circuits for efficient in-memory\n  computation of gated recurrent units","summary":"Recurrent neural networks (RNNs) have been a long-standing candidate for\nprocessing of temporal sequence data, especially in memory-constrained systems\nthat one may find in embedded edge computing environments. Recent advances in\ntraining paradigms have now inspired new generations of efficient RNNs. We\nintroduce a streamlined and hardware-compatible architecture based on minimal\ngated recurrent units (GRUs), and an accompanying efficient mixed-signal\nhardware implementation of the model. The proposed design leverages\nswitched-capacitor circuits not only for in-memory computation (IMC), but also\nfor the gated state updates. The mixed-signal cores rely solely on commodity\ncircuits consisting of metal capacitors, transmission gates, and a clocked\ncomparator, thus greatly facilitating scaling and transfer to other technology\nnodes.\n  We benchmark the performance of our architecture on time series data,\nintroducing all constraints required for a direct mapping to the hardware\nsystem. The direct compatibility is verified in mixed-signal simulations,\nreproducing data recorded from the software-only network model.","main_category":"cs.AR","categories":"cs.AR,cs.AI,cs.LG,eess.SP","published":"2025-05-13T14:13:41Z"}
{"aid":"http://arxiv.org/abs/2505.08600v1","title":"Automatic Task Detection and Heterogeneous LLM Speculative Decoding","summary":"Speculative decoding, which combines a draft model with a target model, has\nemerged as an effective approach to accelerate large language model (LLM)\ninference. However, existing methods often face a trade-off between the\nacceptance rate and decoding speed in downstream tasks due to the limited\ncapacity of the draft model, making it difficult to ensure efficiency across\ndiverse tasks. To address this problem, we propose a speculative decoding\nalgorithm tailored for downstream task optimization. It includes an automatic\ntask partitioning and assigning method, which automatically categorizes\ndownstream tasks into different sub-tasks and assigns them to a set of\nheterogeneous draft models. Each draft model is aligned with the target model\nusing task-specific data, thereby enhancing the consistency of inference\nresults. In addition, our proposed method incorporates an online lightweight\nprompt classifier to dynamically route prompts to the appropriate draft model.\nExperimental results demonstrate that the proposed method improves draft\naccuracy by 6% to 50% over vanilla speculative decoding, while achieving a\nspeedup of 1.10x to 2.64x in LLM inference.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-05-13T14:16:12Z"}
{"aid":"http://arxiv.org/abs/2505.08606v1","title":"High-contrast interaction between remote superconducting qubits mediated\n  by multimode cable coupling","summary":"Superconducting quantum processors offer a promising path towards practical\nquantum computing. However, building a fault-tolerant quantum computer with\nmillions of superconducting qubits is hindered by wiring density, packaging\nconstraints and fabrication yield. Interconnecting medium-scale processors via\nlow-loss superconducting links provides a promising alternative. Yet, achieving\nhigh-fidelity two-qubit gates across such channels remains difficult. Here, we\nshow that a multimode coaxial cable can mediate high-contrast interaction\nbetween spatially separated super-conducting qubits. Leveraging interference\nbetween cable modes, we can implement high-fidelity controlled-Z and ZZ-free\niSWAP gates by simply modulating qubit frequencies. Numerical simulations under\nrealistic coherence and coupling parameters predict fidelities above 99% for\nboth gate schemes. Our approach provides a versatile building block for modular\nsuperconducting architectures and facilitates distributed quantum error\ncorrection and large-scale fault-tolerant quantum computing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T14:23:04Z"}
{"aid":"http://arxiv.org/abs/2505.08610v1","title":"neuralGAM: An R Package for Fitting Generalized Additive Neural Networks","summary":"Nowadays, Neural Networks are considered one of the most effective methods\nfor various tasks such as anomaly detection, computer-aided disease detection,\nor natural language processing. However, these networks suffer from the\n``black-box'' problem which makes it difficult to understand how they make\ndecisions. In order to solve this issue, an R package called neuralGAM is\nintroduced. This package implements a Neural Network topology based on\nGeneralized Additive Models, allowing to fit an independent Neural Network to\nestimate the contribution of each feature to the output variable, yielding a\nhighly accurate and interpretable Deep Learning model. The neuralGAM package\nprovides a flexible framework for training Generalized Additive Neural\nNetworks, which does not impose any restrictions on the Neural Network\narchitecture. We illustrate the use of the neuralGAM package in both synthetic\nand real data examples.","main_category":"stat.ML","categories":"stat.ML,cs.LG,stat.CO,stat.ME","published":"2025-05-13T14:30:01Z"}
{"aid":"http://arxiv.org/abs/2505.08618v1","title":"Symmetry Transmutation and Anomaly Matching","summary":"We explore a situation where a global symmetry of the ultraviolet (UV) theory\ndoes not act faithfully on the local infrared (IR) degrees of freedom, but\ninstead acts effectively as a higher-form symmetry. We refer to this phenomenon\nas symmetry transmutation, where the UV symmetry is \"transmuted\" into a\nhigher-form symmetry in the IR. Notably, unlike emergent (accidental)\nsymmetries, which are approximate, these symmetries are exact. We illustrate\nthe ubiquity of this phenomenon in various continuum and lattice systems and\nprovide examples where the 't Hooft anomalies of the UV symmetry are matched by\nthose of the new higher-form symmetry in the IR. We also show that in certain\nphases and for certain energies, the UV baryon-number symmetry of one-flavor\nQCD is transmuted into a discrete one-form global symmetry. Finally, we compare\nour symmetry transmutation to the well-known phenomenon of symmetry\nfractionalization.","main_category":"hep-th","categories":"hep-th,cond-mat.str-el","published":"2025-05-13T14:38:02Z"}
{"aid":"http://arxiv.org/abs/2505.08624v1","title":"Nonprojective crepant resolutions of quiver varieties","summary":"In this paper, we construct a large class of examples of proper,\nnonprojective crepant resolutions of singularities for Nakajima quiver\nvarieties. These include four and six dimensional examples and examples with\n$Q$ containing only three vertices. There are two main techniques: by taking a\nlocally projective resolution of a projective partial resolution as in our\nprevious work arXiv:2311.07539, and more generally by taking quotients of open\nsubsets of representation space which are not stable loci, related to\nArzhantsev--Derental--Hausen--Laface's construction in the setting of Cox\nrings. By the latter method we exhibit a proper crepant resolution that does\nnot factor through a projective partial resolution. Most of our quiver settings\ninvolve one-dimensional vector spaces, hence the resolutions are toric\nhyperk\\\"ahler, which were studied from a different point of view in Arbo and\nProudfoot arXiv:1511.09138.\n  This builds on the classification of projective crepant resolutions of a\nlarge class of quiver varieties in arXiv:2212.09623 and the classification of\nproper crepant resolutions for the hyperpolygon quiver varieties in\narXiv:2406.04117.","main_category":"math.AG","categories":"math.AG,math.RT,math.SG","published":"2025-05-13T14:45:02Z"}
{"aid":"http://arxiv.org/abs/2505.08626v1","title":"Cracking the relation between mass and 1P-star fraction of globular\n  clusters: III. Initial distributions of in-situ and ex-situ clusters","summary":"Galactic globular clusters consist of two main stellar populations, the\npristine (1P) and polluted (2P) stars. The fraction of 1P stars in clusters,\n$F_{1P}$, is a decreasing function of the cluster present-day mass, $m_{prst}$.\nThe information about cluster formation it contains has yet to be unlocked.\nPaper I demonstrated that the observed distribution $(m_{prst},F_{1P})$ of\nGalactic globular clusters can result from a pristine-star fraction that is\ninversely proportional to their birth mass, $m_{ecl}$. This relation was then\ncalibrated with a fixed stellar mass threshold for 2P-star formation, $m_{th}$,\ni.e., $F_{1P}=m_{th}/m_{ecl}$. We now estimate the masses $m_{init}$ of\nGalactic globular clusters as they start their long-term gas-free evolution in\nthe Galaxy and we map their behavior in the $(m_{init},F_{1P})$ space. Several\ndissolution time-scales are tested (with and without primordial mass\nsegregation), each yielding its own initial cluster distribution\n$(m_{init},F_{1P})$. The $(m_{init},F_{1P})$ distributions are mapped according\nto cluster origin, with the emphasis on the Disk, Low-Energy and Gaia-Enceladus\ncluster groups of Massari et al. (2019). All three initial distributions\n$(m_{init},F_{1P})$ are more compact than their present-day counterparts since\ndynamical evolution scatters clusters in the $F_{1P}$ versus cluster-mass\nspace. The Disk initial distribution is the tightest one and potential reasons\nfor this are discussed. Its power-law representation allows us to generalize\nthe initial mass threshold of Paper I and prompts us to represent the cluster\n$({\\rm mass},F_{1P})$ distribution in a log-log space. No evidence is found\nsuggesting that, initially, the pristine-star fraction of globular clusters\ndepends on their metallicity on top of their mass.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-13T14:45:51Z"}
{"aid":"http://arxiv.org/abs/2505.08629v1","title":"Chilean Avian flu and its marine impacts: an online Statistical Process\n  Control task","summary":"The rapid spread of the HPAI H5N1 virus, responsible for the Avian Flu, is\ncausing a great catastrophe on the South American Pacific coast (especially in\nthe south of Peru and north of Chile). Although very little attention has been\ndelivered to this pandemic, it presents a tremendous lethal rate, though the\nnumber of infected humans is relatively low. Towards monitoring and statistical\ncontrol, this work shows the Chilean national statistics from the year 2023,\nand presents the developed online tool for supporting the government's\ndecision-making. Additionally, a Bayesian hierarchical spatiotemporal model was\nused to model the joint analysis of the weekly registered animal including\nspatial covariates as well as specific and shared spatial effects that take\ninto account the potential autocorrelation between the HPAI H5N1 virus per\nRegion. Our findings allow us to identify the hot-spot areas with high amounts\nof dead bodies (mostly pinnipeds and penguins) and their evolution over time.","main_category":"stat.AP","categories":"stat.AP","published":"2025-05-13T14:49:10Z"}
{"aid":"http://arxiv.org/abs/2505.08642v1","title":"Robust Beamforming Design for STAR-RIS Aided RSMA Network with Hardware\n  Impairments","summary":"In this article, we investigate the robust beamforming design for a\nsimultaneous transmitting and reflecting reconfigurable intelligent surface\n(STAR-RIS) aided downlink rate-splitting multiple access (RSMA) communication\nsystem, where both transceivers and STAR-RIS suffer from the impact of hardware\nimpairments (HWI). A base station (BS) is deployed to transmit messages\nconcurrently to multiple users, utilizing a STAR-RIS to improve communication\nquality and expand user coverage. We aim to maximize the achievable sum rate of\nthe users while ensuring the constraints of transmit power, STAR-RIS\ncoefficients, and the actual rate of the common stream for all users. To solve\nthis challenging high-coupling and non-convexity problem, we adopt a fractional\nprogramming (FP)-based alternating optimization (AO) approach, where each\nsub-problem is addressed via semidefinite relaxation (SDR) and successive\nconvex approximation (SCA) methods. Numerical results demonstrate that the\nproposed scheme outperforms other multiple access schemes and conventional\npassive RIS in terms of the achievable sum rate. Additionally, considering the\nHWI of the transceiver and STAR-RIS makes our algorithm more robust than when\nsuch considerations are not included.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-13T14:58:55Z"}
{"aid":"http://arxiv.org/abs/2505.08646v1","title":"Modular Federated Learning: A Meta-Framework Perspective","summary":"Federated Learning (FL) enables distributed machine learning training while\npreserving privacy, representing a paradigm shift for data-sensitive and\ndecentralized environments. Despite its rapid advancements, FL remains a\ncomplex and multifaceted field, requiring a structured understanding of its\nmethodologies, challenges, and applications. In this survey, we introduce a\nmeta-framework perspective, conceptualising FL as a composition of modular\ncomponents that systematically address core aspects such as communication,\noptimisation, security, and privacy. We provide a historical contextualisation\nof FL, tracing its evolution from distributed optimisation to modern\ndistributed learning paradigms. Additionally, we propose a novel taxonomy\ndistinguishing Aggregation from Alignment, introducing the concept of alignment\nas a fundamental operator alongside aggregation. To bridge theory with\npractice, we explore available FL frameworks in Python, facilitating real-world\nimplementation. Finally, we systematise key challenges across FL sub-fields,\nproviding insights into open research questions throughout the meta-framework\nmodules. By structuring FL within a meta-framework of modular components and\nemphasising the dual role of Aggregation and Alignment, this survey provides a\nholistic and adaptable foundation for understanding and advancing FL research\nand deployment.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-13T15:04:55Z"}
{"aid":"http://arxiv.org/abs/2505.08647v1","title":"Comments on the de Sitter Double Cone","summary":"We study the double cone geometry proposed by Saad, Shenker, and Stanford in\nde Sitter space. We demonstrate that with the inclusion of static patch\nobservers, the double cone leads to a linear ramp consistent with random matrix\nbehavior. This ramp arises from the relative time shift between two clocks\nlocated in opposite static patches.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-05-13T15:06:01Z"}
{"aid":"http://arxiv.org/abs/2505.08649v1","title":"Constraints on light scalars in the Aligned-two-Higgs-doublet model","summary":"In this work, we explore the viability of light-scalar scenarios within the\n$\\mathcal{CP}$-conserving, flavour-aligned two-Higgs-doublet model (A2HDM),\nwhere at least one additional neutral or charged scalar is assumed to be\nlighter than the 125 GeV Higgs boson. The A2HDM naturally avoids\nflavour-changing neutral currents via Yukawa alignment, providing a more\nflexible framework than conventional $Z_2$-symmetric models. Employing the\n$\\texttt{HEPfit}$ package within a Bayesian statistical approach, we perform\nglobal fits across all distinct light-scalar configurations, incorporating\ntheoretical requirements and experimental constraints from electroweak\nprecision observables, flavour data, Higgs measurements, and direct searches at\nthe LEP and the LHC.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-05-13T15:10:20Z"}
{"aid":"http://arxiv.org/abs/2505.08657v1","title":"A Comparative Study of Human Activity Recognition: Motion, Tactile, and\n  multi-modal Approaches","summary":"Human activity recognition (HAR) is essential for effective Human-Robot\nCollaboration (HRC), enabling robots to interpret and respond to human actions.\nThis study evaluates the ability of a vision-based tactile sensor to classify\n15 activities, comparing its performance to an IMU-based data glove.\nAdditionally, we propose a multi-modal framework combining tactile and motion\ndata to leverage their complementary strengths. We examined three approaches:\nmotion-based classification (MBC) using IMU data, tactile-based classification\n(TBC) with single or dual video streams, and multi-modal classification (MMC)\nintegrating both. Offline validation on segmented datasets assessed each\nconfiguration's accuracy under controlled conditions, while online validation\non continuous action sequences tested online performance. Results showed the\nmulti-modal approach consistently outperformed single-modality methods,\nhighlighting the potential of integrating tactile and motion sensing to enhance\nHAR systems for collaborative robotics.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-05-13T15:20:21Z"}
{"aid":"http://arxiv.org/abs/2505.08667v1","title":"$\\mathcal{P}$, $\\mathcal{T}$-violating axion mediated interactions in\n  RaOH molecule","summary":"If axion simultaneously has the scalar couplings to the nucleons and\npseudo-scalar couplings to the electrons, they may mediate a $\\mathcal{P}$,\n$\\mathcal{T}$ violating interaction between the electronic shell and nuclei in\nthe molecules. The polyatomic molecule RaOH, which is considered as a promising\nplatform for the $\\mathcal{P}$, $\\mathcal{T}$ violation searches, is studied\nfor its sensitivity to such interactions. Due to the long-range nature (on\nmolecular scales) of the axion-mediated interaction, it is interesting whether\nthe enhancement parameter would be sensitive to the vibration of the molecule.\nOur results imply that the impact of the vibrations on the axion-mediated\nelectron-nucleon interaction in the molecule is similar to the impact on the\nshort-range electron-nucleon scalar-pseudoscalar interaction studied earlier.","main_category":"hep-ph","categories":"hep-ph,physics.atom-ph,quant-ph","published":"2025-05-13T15:29:39Z"}
{"aid":"http://arxiv.org/abs/2505.08690v1","title":"Adaptive Schema-aware Event Extraction with Retrieval-Augmented\n  Generation","summary":"Event extraction (EE) is a fundamental task in natural language processing\n(NLP) that involves identifying and extracting event information from\nunstructured text. Effective EE in real-world scenarios requires two key steps:\nselecting appropriate schemas from hundreds of candidates and executing the\nextraction process. Existing research exhibits two critical gaps: (1) the rigid\nschema fixation in existing pipeline systems, and (2) the absence of benchmarks\nfor evaluating joint schema matching and extraction. Although large language\nmodels (LLMs) offer potential solutions, their schema hallucination tendencies\nand context window limitations pose challenges for practical deployment. In\nresponse, we propose Adaptive Schema-aware Event Extraction (ASEE), a novel\nparadigm combining schema paraphrasing with schema retrieval-augmented\ngeneration. ASEE adeptly retrieves paraphrased schemas and accurately generates\ntargeted structures. To facilitate rigorous evaluation, we construct the\nMulti-Dimensional Schema-aware Event Extraction (MD-SEE) benchmark, which\nsystematically consolidates 12 datasets across diverse domains, complexity\nlevels, and language settings. Extensive evaluations on MD-SEE show that our\nproposed ASEE demonstrates strong adaptability across various scenarios,\nsignificantly improving the accuracy of event extraction.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-05-13T15:47:54Z"}
{"aid":"http://arxiv.org/abs/2505.08696v1","title":"Quantum confinement theory of ultra-thin films: electronic, thermal and\n  superconducting properties","summary":"The miniaturization of electronic devices has led to the prominence, in\ntechnological applications, of ultra-thin films with a thickness ranging from a\nfew tens of nanometers to just about 1-2 nanometers. While these materials are\nstill effectively 3D in many respects, traditional theories as well as ab\ninitio methods struggle to describe their properties as measured in\nexperiments. In particular, standard approaches to quantum confinement rely on\nhard-wall boundary conditions, which neglect the unavoidable, ubiquitous,\natomic-scale irregularities of the interface. Recently, a unified theoretical\napproach to quantum confinement has been proposed which is able to effectively\ntake the real nature of the interface into account, and can efficiently be\nimplemented in synergy with microscopic theories. Its predictions for the\nelectronic properties such as electrical conductivity of semiconductor thin\nfilms or critical temperature of superconducting thin films, have been\nsuccessfully verified in comparison with experimental data. The same\nconfinement principles lead to new laws for the phonon density of states and\nfor the heat capacity of thin films, again in agreement with the available\nexperimental data.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.mtrl-sci,quant-ph","published":"2025-05-13T15:56:20Z"}
{"aid":"http://arxiv.org/abs/2505.08706v1","title":"Big Data and the Computational Social Science of Entrepreneurship and\n  Innovation","summary":"As large-scale social data explode and machine-learning methods evolve,\nscholars of entrepreneurship and innovation face new research opportunities but\nalso unique challenges. This chapter discusses the difficulties of leveraging\nlarge-scale data to identify technological and commercial novelty, document new\nventure origins, and forecast competition between new technologies and\ncommercial forms. It suggests how scholars can take advantage of new text,\nnetwork, image, audio, and video data in two distinct ways that advance\ninnovation and entrepreneurship research. First, machine-learning models,\ncombined with large-scale data, enable the construction of precision\nmeasurements that function as system-level observatories of innovation and\nentrepreneurship across human societies. Second, new artificial intelligence\nmodels fueled by big data generate 'digital doubles' of technology and\nbusiness, forming laboratories for virtual experimentation about innovation and\nentrepreneurship processes and policies. The chapter argues for the advancement\nof theory development and testing in entrepreneurship and innovation by\ncoupling big data with big models.","main_category":"econ.GN","categories":"econ.GN,cs.AI,cs.CY,cs.SI,q-fin.EC,stat.AP","published":"2025-05-13T16:13:18Z"}
{"aid":"http://arxiv.org/abs/2505.08720v1","title":"Hyperreflexivity of von Neumann algebras and similarity of finitely\n  generated $C^*$-algebras","summary":"Let $\\cl A$ be a $C^*$-algebra. We say that $\\cl A$ satisfies the SP if every\nbounded homomorphism $\\cl A\\to B(K)$, with $K$ a Hilbert space, is similar to a\n$*$-homomorphism. We introduce the following hypotheses:\n  EPH.1 For every hyperreflexive von Neumann algebra $\\cl A$ acting on the\nHilbert space $H$ and every projection $Q\\in B(H)$ the algebra $\\cl A\\vee\n\\{Q\\}^{''}$ is hyperreflexive.\n  EPH.2 For every completely hyperreflexive von Neumann algebra $\\cl A$ acting\non the Hilbert space $H$ and every projection $Q\\in B(H)$ the algebra $\\cl\nA\\wedge \\{Q\\}'$ is completely\n  hyperreflexive.\n  EPH.3 For every $Q_1, Q_2,...,Q_n, n\\in \\bb N$ projections the algebra\n$$\\{Q_1\\otimes I _{\\ell^2(I)} \\}'\\wedge ...\\wedge\\{Q_n\\otimes I\n_{\\ell^2(I)}\\}'$$ is hyperreflexive for all cardinals $I.$\n  We prove that EPH.1 implies EPH.2, EPH.2 implies EPH.3 and that EPH.3 is\nequivalent to the statement that every finitely generated $C^*$-algebra\nsatisfies the SP.","main_category":"math.OA","categories":"math.OA","published":"2025-05-13T16:29:57Z"}
{"aid":"http://arxiv.org/abs/2505.08723v1","title":"TiMo: Spatiotemporal Foundation Model for Satellite Image Time Series","summary":"Satellite image time series (SITS) provide continuous observations of the\nEarth's surface, making them essential for applications such as environmental\nmanagement and disaster assessment. However, existing spatiotemporal foundation\nmodels rely on plain vision transformers, which encode entire temporal\nsequences without explicitly capturing multiscale spatiotemporal relationships\nbetween land objects. This limitation hinders their effectiveness in downstream\ntasks. To overcome this challenge, we propose TiMo, a novel hierarchical vision\ntransformer foundation model tailored for SITS analysis. At its core, we\nintroduce a spatiotemporal gyroscope attention mechanism that dynamically\ncaptures evolving multiscale patterns across both time and space. For\npre-training, we curate MillionST, a large-scale dataset of one million images\nfrom 100,000 geographic locations, each captured across 10 temporal phases over\nfive years, encompassing diverse geospatial changes and seasonal variations.\nLeveraging this dataset, we adapt masked image modeling to pre-train TiMo,\nenabling it to effectively learn and encode generalizable spatiotemporal\nrepresentations.Extensive experiments across multiple spatiotemporal\ntasks-including deforestation monitoring, land cover segmentation, crop type\nclassification, and flood detection-demonstrate TiMo's superiority over\nstate-of-the-art methods. Code, model, and dataset will be released at\nhttps://github.com/MiliLab/TiMo.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T16:35:11Z"}
{"aid":"http://arxiv.org/abs/2505.08731v1","title":"On jump minimizing liftings for $\\mathbb S^1$-valued maps and\n  connections with Ambrosio-Tortorelli-type $Γ$-limits","summary":"This paper is concerned with the $\\Gamma$-limits of Ambrosio-Tortorelli-type\nfunctionals, for maps $u$ defined on an open bounded set $\\Omega\\subset\\mathbb\nR^n$ and taking values in the unit circle $\\mathbb S^1\\subset\\mathbb R^2$.\nDepending on the domain of the functional, two different $\\Gamma$-limits are\npossible, one of which is nonlocal, and related to the notion of jump\nminimizing lifting, i.e., a lifting of a map $u$ whose measure of the jump set\nis minimal. The latter requires ad hoc compactness results for sequences of\nliftings which, besides being interesting by themselves, also allow to deduce\nexistence of a jump minimizing lifting.","main_category":"math.AP","categories":"math.AP","published":"2025-05-13T16:41:08Z"}
{"aid":"http://arxiv.org/abs/2505.08732v1","title":"The structure and migration of twin boundaries in tetragonal $β$-Sn:\n  an application of machine learning based interatomic potentials","summary":"Although atomistic simulations have contributed significantly to our\nunderstanding of twin boundary structure and migration in metals and alloys\nwith hexagonal close packed (HCP) crystal structures, few direct atomistic\nstudies of twinning have been conducted for other types of low symmetry\nmaterials, in large part due to a lack of reliable interatomic potentials. In\nthis work, we examine twin boundary structure and migration in a tetragonal\nmaterial, $\\beta$-Sn, comparing high resolution Transmission Electron\nMicroscopy (TEM) images of deformation twins in $\\beta$-Sn to the results of\ndirect atomistic simulations using multiple interatomic potentials. ML-based\npotentials developed in this work are found to give results consistent with our\nexperimental data, revealing faceted twin boundary structures formed by the\nnucleation and motion of twinning disconnections. We use bicrystallographic\nmethods in combination with atomistic simulations to analyze the structure,\nenergy and shear coupled migration of observed twin facets in $\\beta$-Sn. In\nanalogy to Prismatic-Basal (PB/BP) interfaces in HCP metals, we discover low\nenergy asymmetric Prismatic-A-plane (PA/AP) interfaces important to twin growth\nin $\\beta$-Sn. A Moment Tensor Potential (MTP) and Rapid Artificial Neural\nNetwork (RANN) interatomic potential suitable for studying twinning and phase\ntransformations in Sn are made publicly available as part of this work.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-13T16:45:32Z"}
{"aid":"http://arxiv.org/abs/2505.08744v1","title":"DeepMath-Creative: A Benchmark for Evaluating Mathematical Creativity of\n  Large Language Models","summary":"To advance the mathematical proficiency of large language models (LLMs), the\nDeepMath team has launched an open-source initiative aimed at developing an\nopen mathematical LLM and systematically evaluating its mathematical\ncreativity. This paper represents the initial contribution of this initiative.\nWhile recent developments in mathematical LLMs have predominantly emphasized\nreasoning skills, as evidenced by benchmarks on elementary to\nundergraduate-level mathematical tasks, the creative capabilities of these\nmodels have received comparatively little attention, and evaluation datasets\nremain scarce. To address this gap, we propose an evaluation criteria for\nmathematical creativity and introduce DeepMath-Creative, a novel, high-quality\nbenchmark comprising constructive problems across algebra, geometry, analysis,\nand other domains. We conduct a systematic evaluation of mainstream LLMs'\ncreative problem-solving abilities using this dataset. Experimental results\nshow that even under lenient scoring criteria -- emphasizing core solution\ncomponents and disregarding minor inaccuracies, such as small logical gaps,\nincomplete justifications, or redundant explanations -- the best-performing\nmodel, O3 Mini, achieves merely 70% accuracy, primarily on basic\nundergraduate-level constructive tasks. Performance declines sharply on more\ncomplex problems, with models failing to provide substantive strategies for\nopen problems. These findings suggest that, although current LLMs display a\ndegree of constructive proficiency on familiar and lower-difficulty problems,\nsuch performance is likely attributable to the recombination of memorized\npatterns rather than authentic creative insight or novel synthesis.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-13T16:58:05Z"}
{"aid":"http://arxiv.org/abs/2505.08745v1","title":"Estimating the mass of the thin shell of gravastars in generalised\n  cylindrically symmetric space-time within the framework of Rastall theory of\n  gravity","summary":"This study investigates the gravastars in the framemwork of Rastall theory of\ngravity in generalised cylindrically symmetric space-time. Following the\nMazur-Mottola hypothesis (P. O. Mazur and E. Mottola, Universe {\\bf 9}, 88\n(2023)), gravastars are classified as one of the most unique and exotic kind of\ncompact objects, presenting themselves as a plausible alternative to black\nholes. In this study, we build upon the Mazur-Mottola framework of\nGravitational Bose-Einstein Condensate (GBEC) stars by generalising it to a\ncylindrically symmetric spacetime within the framework of Rastall gravity to\npresent a novel approach for estimating the mass limit of the thin shell of\nisotropic gravastars. We have ensured singularity-free solutions for the\ninterior de-Sitter core, non-vanishing solutions for the thin shell and flat\nvacuum solution of the exterior region, within this parameter space. Under the\nframework of Rastall gravity and cylindrically symmetric spacetime, the Lanczos\nequations at the hypersurface junction $(r=R)$ undergo significant\nmodifications, leading to a revised form of the Darmois-Israel junction\nconditions. These modified junction conditions are utilised to investigate the\ninfluence of the Rastall parameter $(\\xi)$ on the mass of the thin shell and\nkey characteristics of gravastars, including the shell's proper length, energy,\nand entropy. Additionally, we propose a novel method for estimating the mass of\nthe thin shell using the concept of surface redshift $(Z_{s})$. By adhering to\nthe Buchdahl upper limit, $Z_{s}<2$ for isotropic configuration, we have\ndetermined the mass bounds of the thin shell for various characteristic radii\nand values of the Rastall parameter $(\\xi)$.","main_category":"gr-qc","categories":"gr-qc","published":"2025-05-13T16:59:00Z"}
{"aid":"http://arxiv.org/abs/2505.08761v1","title":"The CMB cold spot under the lens II: Lensing on polarization and cosmic\n  textures footprints","summary":"We present a quadratic lensing estimator that incorporates off-diagonal\ncorrelations in both temperature and polarization CMB maps, and is capable of\nmeasuring localized lensing profiles with $<10''$ average deflection angle at\nthe $\\sim3\\sigma$ level in upcoming Simons observatory (SO) data. The proposed\npipeline is agnostic to the underlying mass profile and can probe the subtle\nsignatures of voids, clusters, and topological defects. As a case study and\ntest scenario we focus on a collapsing cosmic texture, a topological defect\nthat has been proposed to explain the CMB Cold Spot. With the forthcoming SO\ndata, we forecast a $2.8\\sigma$ detection if the texture amplitude reaches the\ncurrent Planck 2018 $2\\sigma$ limit, and a $1.8\\sigma$ measurement for the\nbest-fit value, which is remarkable given the expected typical lensing angle of\n$<6''$. As the next-generation CMB surveys will reach $\\ell>3000$ for\npolarization, we demonstrate that its inclusion is significant, boosting the\nestimator's signal-to-noise ratio by $\\sim50\\%$, and making it a powerful tool,\nallowing us to recover faint lensing footprints that were previously\ninaccessible.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-13T17:28:26Z"}
