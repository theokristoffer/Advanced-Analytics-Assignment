{"aid":"http://arxiv.org/abs/2504.09881v1","title":"Focus on Local: Finding Reliable Discriminative Regions for Visual Place\n  Recognition","summary":"Visual Place Recognition (VPR) is aimed at predicting the location of a query\nimage by referencing a database of geotagged images. For VPR task, often fewer\ndiscriminative local regions in an image produce important effects while\nmundane background regions do not contribute or even cause perceptual aliasing\nbecause of easy overlap. However, existing methods lack precisely modeling and\nfull exploitation of these discriminative regions. In this paper, we propose\nthe Focus on Local (FoL) approach to stimulate the performance of image\nretrieval and re-ranking in VPR simultaneously by mining and exploiting\nreliable discriminative local regions in images and introducing\npseudo-correlation supervision. First, we design two losses,\nExtraction-Aggregation Spatial Alignment Loss (SAL) and Foreground-Background\nContrast Enhancement Loss (CEL), to explicitly model reliable discriminative\nlocal regions and use them to guide the generation of global representations\nand efficient re-ranking. Second, we introduce a weakly-supervised local\nfeature training strategy based on pseudo-correspondences obtained from\naggregating global features to alleviate the lack of local correspondences\nground truth for the VPR task. Third, we suggest an efficient re-ranking\npipeline that is efficiently and precisely based on discriminative region\nguidance. Finally, experimental results show that our FoL achieves the\nstate-of-the-art on multiple VPR benchmarks in both image retrieval and\nre-ranking stages and also significantly outperforms existing two-stage VPR\nmethods in terms of computational efficiency. Code and models are available at\nhttps://github.com/chenshunpeng/FoL","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T05:04:51Z"}
{"aid":"http://arxiv.org/abs/2504.09884v1","title":"Markov Clustering based Fully Automated Nonblocking Hierarchical\n  Supervisory Control of Large-Scale Discrete-Event Systems","summary":"In this paper we revisit the abstraction-based approach to synthesize a\nhierarchy of decentralized supervisors and coordinators for nonblocking control\nof large-scale discrete-event systems (DES), and augment it with a new\nclustering method for automatic and flexible grouping of relevant components\nduring the hierarchical synthesis process. This method is known as Markov\nclustering, which not only automatically performs grouping but also allows\nflexible tuning the sizes of the resulting clusters using a single parameter.\nCompared to the existing abstraction-based approach that lacks effective\ngrouping method for general cases, our proposed approach based on Markov\nclustering provides a fully automated and effective hierarchical synthesis\nprocedure applicable to general large-scale DES. Moreover, it is proved that\nthe resulting hierarchy of supervisors and coordinators collectively achieves\nglobal nonblocking (and maximally permissive) controlled behavior under the\nsame conditions as those in the existing abstraction-based approach. Finally, a\nbenchmark case study is conducted to empirically demonstrate the effectiveness\nof our approach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T05:16:30Z"}
{"aid":"http://arxiv.org/abs/2504.09891v1","title":"NR-SSOR right preconditioned RRGMRES for arbitrary singular systems and\n  least squares problems","summary":"GMRES is known to determine a least squares solution of $ A x = b $ where $ A\n\\in R^{n \\times n} $ without breakdown for arbitrary $ b \\in R^n $, and initial\niterate $ x_0 \\in R^n $ if and only if $ A $ is range-symmetric, i.e. $ R(A^T)\n= R(A) $, where $ A $ may be singular and $ b $ may not be in the range space $\nR(A) $ of $ A $.\n  In this paper, we propose applying the Range Restricted GMRES (RRGMRES) to $\nA C A^T z = b $, where $ C \\in R^{n \\times n} $ is symmetric positive definite.\nThis determines a least squares solution $ x = C A^T z $ of $ A x = b $ without\nbreakdown for arbitrary (singular) matrix $ A \\in R^{n \\times n} $ and $ b, x_0\n\\in R^n $, and is much more stable and accurate compared to GMRES, RRGMRES and\nMINRES-QLP applied to $ A x = b $ for inconsistent problems when $ b \\notin\nR(A) $. In particular, we propose applying the NR-SSOR as the inner iteration\nright preconditioner, which also works efficiently for least squares problems $\n\\min_{x \\in R^n} \\| b - A x\\|_2 $ for $ A \\in R^{m \\times n} $ and arbitrary $\nb \\in R^m $.\n  Numerical experiments demonstrate the validity of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T05:34:02Z"}
{"aid":"http://arxiv.org/abs/2504.09902v1","title":"Quantum Image Visualizer: Visual Debugging of Quantum Image Processing\n  Circuits","summary":"Quantum computing is an emerging field that utilizes the unique principles of\nquantum mechanics to offer significant advantages in algorithm execution over\nclassical approaches. This potential is particularly promising in the domain of\nquantum image processing, which aims to manipulate all pixels simultaneously.\nHowever, the process of designing and verifying these algorithms remains a\ncomplex and error-prone task. To address this challenge, new methods are needed\nto support effective debugging of quantum circuits. The Quantum Image\nVisualizer is an interactive visual analysis tool that allows for the\nexamination of quantum images and their transformation throughout quantum\ncircuits. The framework incorporates two overview visualizations that trace\nimage evolution across a sequence of gates based on the most probable outcomes.\nInteractive exploration allows users to focus on relevant gates, and select\npixels of interest. Upon selection, detailed visualizations enable in-depth\ninspection of individual pixels and their probability distributions, revealing\nhow specific gates influence the likelihood of pixel color values and the\nmagnitude of these changes. An evaluation of the Quantum Image Visualizer was\nconducted through in-depth interviews with eight domain experts. The findings\ndemonstrate the effectiveness and practical value of our approach in supporting\nvisual debugging of quantum image processing circuits.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T05:50:41Z"}
{"aid":"http://arxiv.org/abs/2504.09909v1","title":"Quantum Natural Language Processing: A Comprehensive Review of Models,\n  Methods, and Applications","summary":"In recent developments, deep learning methodologies applied to Natural\nLanguage Processing (NLP) have revealed a paradox: They improve performance but\ndemand considerable data and resources for their training. Alternatively,\nquantum computing exploits the principles of quantum mechanics to overcome the\ncomputational limitations of current methodologies, thereby establishing an\nemerging field known as quantum natural language processing (QNLP). This domain\nholds the potential to attain a quantum advantage in the processing of\nlinguistic structures, surpassing classical models in both efficiency and\naccuracy. In this paper, it is proposed to categorise QNLP models based on\nquantum computing principles, architecture, and computational approaches. This\npaper attempts to provide a survey on how quantum meets language by mapping\nstate-of-the-art in this area, embracing quantum encoding techniques for\nclassical data, QNLP models for prevalent NLP tasks, and quantum optimisation\ntechniques for hyper parameter tuning. The landscape of quantum computing\napproaches applied to various NLP tasks is summarised by showcasing the\nspecific QNLP methods used, and the popularity of these methods is indicated by\ntheir count. From the findings, it is observed that QNLP approaches are still\nlimited to small data sets, with only a few models explored extensively, and\nthere is increasing interest in the application of quantum computing to natural\nlanguage processing tasks.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T06:09:26Z"}
{"aid":"http://arxiv.org/abs/2504.09912v1","title":"Parameter Convergence Detector Based on VAMP Deep Unfolding: A Novel\n  Radar Constant False Alarm Rate Detection Algorithm","summary":"The sub-Nyquist radar framework exploits the sparsity of signals, which\neffectively alleviates the pressure on system storage and transmission\nbandwidth. Compressed sensing (CS) algorithms, such as the VAMP algorithm, are\nused for sparse signal processing in the sub-Nyquist radar framework. By\ncombining deep unfolding techniques with VAMP, faster convergence and higher\naccuracy than traditional CS algorithms are achieved. However, deep unfolding\ndisrupts the parameter constrains in traditional VAMP algorithm, leading to the\ndistribution of non-sparse noisy estimation in VAMP deep unfolding unknown, and\nits distribution parameter unable to be obtained directly using method of\ntraditional VAMP, which prevents the application of VAMP deep unfolding in\nradar constant false alarm rate (CFAR) detection. To address this problem, we\nexplore the distribution of the non-sparse noisy estimation and propose a\nparameter convergence detector (PCD) to achieve CFAR detection based on VAMP\ndeep unfolding. Compared to the state-of-the-art methods, PCD leverages not\nonly the sparse solution, but also the non-sparse noisy estimation, which is\nused to iteratively estimate the distribution parameter and served as the test\nstatistic in detection process. In this way, the proposed algorithm takes\nadvantage of both the enhanced sparse recovery accuracy from deep unfolding and\nthe distribution property of VAMP, thereby achieving superior CFAR detection\nperformance. Additionally, the PCD requires no information about the power of\nAWGN in the environment, which is more suitable for practical application. The\nconvergence performance and effectiveness of the proposed PCD are analyzed\nbased on the Banach Fixed-Point Theorem. Numerical simulations and practical\ndata experiments demonstrate that PCD can achieve better false alarm control\nand target detection performance.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T06:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.09920v1","title":"Strain Engineering of Magnetoresistance and Magnetic Anisotropy in CrSBr","summary":"Tailoring magnetoresistance and magnetic anisotropy in van der Waals magnetic\nmaterials is essential for advancing their integration into technological\napplications. In this regard, strain engineering has emerged as a powerful and\nversatile strategy to control magnetism at the two-dimensional (2D) limit.\nHere, we demonstrate that compressive biaxial strain significantly enhances the\nmagnetoresistance and magnetic anisotropy of few-layer CrSBr flakes. Strain is\nefficiently transferred to the flakes from the thermal compression of a\npolymeric substrate upon cooling, as confirmed by temperature-dependent Raman\nspectroscopy. This strain induces a remarkable increase in the\nmagnetoresistance ratio and in the saturation fields required to align the\nmagnetization of CrSBr along each of its three crystalographic directions,\nreaching a twofold enhancement along the magnetic easy axis. This enhancement\nis accompanied by a subtle reduction of the N\\'eel temperature by ~10K. Our\nexperimental results are fully supported by first-principles calculations,\nwhich link the observed effects to a strain-driven modification in interlayer\nexchange coupling and magnetic anisotropy energy. These findings establish\nstrain engineering as a key tool for fine-tuning magnetotransport properties in\n2D magnetic semiconductors, paving the way for implementation in spintronics\nand information storage devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.app-ph","published":"2025-04-14T06:27:26Z"}
{"aid":"http://arxiv.org/abs/2504.09937v1","title":"Probing Temperature at Nanoscale through Thermal Vibration\n  Characterization using Scanning Precession Electron Diffraction","summary":"Accurate, non-contact temperature measurement with high spatial resolution is\nessential for understanding thermal behavior in integrated nanoscale devices\nand heterogeneous interfaces. However, existing techniques are often limited by\nthe need for physical contact or insufficient spatial resolution for the\nmeasurement of local temperature and mapping its distribution. Here, we\nshowcase the direct temperature measurement of graphene with nanometer spatial\nresolution in transmission electron microscopy. In experiments, combining a\nscanning nanobeam with precession electron diffraction offers the collection of\nkinemetic diffraction from a local area at the nanometer scale. In analysis, we\nuse a pre-calculated, sample-specific structure-factor-based correction method\nto enable the linear fitting of the diffraction intensities, allowing the\ndetermination of the Debye-Waller factor as a function of temperature at the\nprecision of 10-4{\\AA}2/{\\deg}C. With the high spatial resolution and\nmeasurement precision, the temperature and thermal vibration mapping further\nreveal the influence of graphene lattice parameters and thickness on the\nDebye-Waller factor, providing valuable insights into the vibrational\nproperties impacted by temperature, lattice structure, and graphene layer\nthickness.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T06:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.09947v1","title":"Predicting Children's Travel Modes for School Journeys in Switzerland: A\n  Machine Learning Approach Using National Census Data","summary":"Children's travel behavior plays a critical role in shaping long-term\nmobility habits and public health outcomes. Despite growing global interest,\nlittle is known about the factors influencing travel mode choice of children\nfor school journeys in Switzerland. This study addresses this gap by applying a\nrandom forest classifier - a machine learning algorithm - to data from the\nSwiss Mobility and Transport Microcensus, in order to identify key predictors\nof children's travel mode choice for school journeys. Distance consistently\nemerges as the most important predictor across all models, for instance when\ndistinguishing between active vs. non-active travel or car vs. non-car usage.\nThe models show relatively high performance, with overall classification\naccuracy of 87.27% (active vs. non-active) and 78.97% (car vs. non-car),\nrespectively. The study offers empirically grounded insights that can support\nschool mobility policies and demonstrates the potential of machine learning in\nuncovering behavioral patterns in complex transport datasets.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-14T07:18:23Z"}
{"aid":"http://arxiv.org/abs/2504.09954v1","title":"Romanoff's theorem and sums of two squares","summary":"Let $A=\\{a_{n}\\}_{n=1}^{\\infty}$ and $B=\\{b_{n}\\}_{n=1}^{\\infty}$ be two\nsequences of positive integers. Under some restrictions on $A$ and $B$, we\nobtain a lower bound for a number of integers $n$ not exceeding $x$ that can be\nexpressed as a sum $n = a_i + b_j$. In particular, we obtain the result in the\ncase when $A$ is the set of numbers representable as the sum of two squares.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T07:33:30Z"}
{"aid":"http://arxiv.org/abs/2504.09963v1","title":"Towards Unbiased Federated Graph Learning: Label and Topology\n  Perspectives","summary":"Federated Graph Learning (FGL) enables privacy-preserving, distributed\ntraining of graph neural networks without sharing raw data. Among its\napproaches, subgraph-FL has become the dominant paradigm, with most work\nfocused on improving overall node classification accuracy. However, these\nmethods often overlook fairness due to the complexity of node features, labels,\nand graph structures. In particular, they perform poorly on nodes with\ndisadvantaged properties, such as being in the minority class within subgraphs\nor having heterophilous connections (neighbors with dissimilar labels or\nmisleading features). This reveals a critical issue: high accuracy can mask\ndegraded performance on structurally or semantically marginalized nodes. To\naddress this, we advocate for two fairness goals: (1) improving representation\nof minority class nodes for class-wise fairness and (2) mitigating topological\nbias from heterophilous connections for topology-aware fairness. We propose\nFairFGL, a novel framework that enhances fairness through fine-grained graph\nmining and collaborative learning. On the client side, the History-Preserving\nModule prevents overfitting to dominant local classes, while the Majority\nAlignment Module refines representations of heterophilous majority-class nodes.\nThe Gradient Modification Module transfers minority-class knowledge from\nstructurally favorable clients to improve fairness. On the server side, FairFGL\nuploads only the most influenced subset of parameters to reduce communication\ncosts and better reflect local distributions. A cluster-based aggregation\nstrategy reconciles conflicting updates and curbs global majority dominance .\nExtensive evaluations on eight benchmarks show FairFGL significantly improves\nminority-group performance , achieving up to a 22.62 percent Macro-F1 gain\nwhile enhancing convergence over state-of-the-art baselines.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DB,cs.SI","published":"2025-04-14T08:00:20Z"}
{"aid":"http://arxiv.org/abs/2504.09966v1","title":"SemiETS: Integrating Spatial and Content Consistencies for\n  Semi-Supervised End-to-end Text Spotting","summary":"Most previous scene text spotting methods rely on high-quality manual\nannotations to achieve promising performance. To reduce their expensive costs,\nwe study semi-supervised text spotting (SSTS) to exploit useful information\nfrom unlabeled images. However, directly applying existing semi-supervised\nmethods of general scenes to SSTS will face new challenges: 1) inconsistent\npseudo labels between detection and recognition tasks, and 2) sub-optimal\nsupervisions caused by inconsistency between teacher/student. Thus, we propose\na new Semi-supervised framework for End-to-end Text Spotting, namely SemiETS\nthat leverages the complementarity of text detection and recognition.\nSpecifically, it gradually generates reliable hierarchical pseudo labels for\neach task, thereby reducing noisy labels. Meanwhile, it extracts important\ninformation in locations and transcriptions from bidirectional flows to improve\nconsistency. Extensive experiments on three datasets under various settings\ndemonstrate the effectiveness of SemiETS on arbitrary-shaped text. For example,\nit outperforms previous state-of-the-art SSL methods by a large margin on\nend-to-end spotting (+8.7%, +5.6%, and +2.6% H-mean under 0.5%, 1%, and 2%\nlabeled data settings on Total-Text, respectively). More importantly, it still\nimproves upon a strongly supervised text spotter trained with plenty of labeled\ndata by 2.0%. Compelling domain adaptation ability shows practical potential.\nMoreover, our method demonstrates consistent improvement on different text\nspotters.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.09972v1","title":"Measurement of the helicity-dependent response in quasi-elastic proton\n  knockout from $^{40}{\\rm Ca}$","summary":"The role of the electron-helicity-dependent cross-section term and the\nstructure function $f^{\\prime}_{01}$ in the quasi-elastic $A(\\vec{e},\ne^{\\prime}p)$ process was studied. The $f^{\\prime}_{01}$ was measured for\nproton knockout from the $1\\mathrm{d}_{3/2}$ shell in $^{40}\\mathrm{Ca}$ via\nthe $^{40}{\\rm Ca}(\\vec{e},e' p)^{39}{\\rm K}_{\\rm g.s.}$ reaction, leaving the\nresidual nucleus in a well-defined state. It requires a longitudinally\npolarized electron beam and out-of-plane proton detection. This structure\nfunction vanishes in the absence of final-state interactions (FSI) involving\nthe ejected proton. Presented are the dependencies of $f^{\\prime}_{01}$ on the\nmissing momentum (closely related to the initial proton's Fermi momentum) and\nthe angle between the knocked-out proton and the virtual photon momenta. The\nrole of the spin-orbit interaction in FSI through the $\\vec{L}\\cdot \\vec{S}$\nterm in a nuclear optical potential is discussed.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-14T08:23:53Z"}
{"aid":"http://arxiv.org/abs/2504.10028v1","title":"Sequence models for by-trial decoding of cognitive strategies from\n  neural data","summary":"Understanding the sequence of cognitive operations that underlie\ndecision-making is a fundamental challenge in cognitive neuroscience.\nTraditional approaches often rely on group-level statistics, which obscure\ntrial-by-trial variations in cognitive strategies. In this study, we introduce\na novel machine learning method that combines Hidden Multivariate Pattern\nanalysis with a Structured State Space Sequence model to decode cognitive\nstrategies from electroencephalography data at the trial level. We apply this\nmethod to a decision-making task, where participants were instructed to\nprioritize either speed or accuracy in their responses. Our results reveal an\nadditional cognitive operation, labeled Confirmation, which seems to occur\npredominantly in the accuracy condition but also frequently in the speed\ncondition. The modeled probability that this operation occurs is associated\nwith higher probability of responding correctly as well as changes of mind, as\nindexed by electromyography data. By successfully modeling cognitive operations\nat the trial level, we provide empirical evidence for dynamic variability in\ndecision strategies, challenging the assumption of homogeneous cognitive\nprocesses within experimental conditions. Our approach shows the potential of\nsequence modeling in cognitive neuroscience to capture trial-level variability\nthat is obscured by aggregate analyses. The introduced method offers a new way\nto detect and understand cognitive strategies in a data-driven manner, with\nimplications for both theoretical research and practical applications in many\nfields.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.AI","published":"2025-04-14T09:33:02Z"}
{"aid":"http://arxiv.org/abs/2504.10031v1","title":"Using Reinforcement Learning to Integrate Subjective Wellbeing into\n  Climate Adaptation Decision Making","summary":"Subjective wellbeing is a fundamental aspect of human life, influencing life\nexpectancy and economic productivity, among others. Mobility plays a critical\nrole in maintaining wellbeing, yet the increasing frequency and intensity of\nboth nuisance and high-impact floods due to climate change are expected to\nsignificantly disrupt access to activities and destinations, thereby affecting\noverall wellbeing. Addressing climate adaptation presents a complex challenge\nfor policymakers, who must select and implement policies from a broad set of\noptions with varying effects while managing resource constraints and uncertain\nclimate projections. In this work, we propose a multi-modular framework that\nuses reinforcement learning as a decision-support tool for climate adaptation\nin Copenhagen, Denmark. Our framework integrates four interconnected\ncomponents: long-term rainfall projections, flood modeling, transport\naccessibility, and wellbeing modeling. This approach enables decision-makers to\nidentify spatial and temporal policy interventions that help sustain or enhance\nsubjective wellbeing over time. By modeling climate adaptation as an open-ended\nsystem, our framework provides a structured framework for exploring and\nevaluating adaptation policy pathways. In doing so, it supports policymakers to\nmake informed decisions that maximize wellbeing in the long run.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T09:34:12Z"}
{"aid":"http://arxiv.org/abs/2504.10035v1","title":"TT3D: Table Tennis 3D Reconstruction","summary":"Sports analysis requires processing large amounts of data, which is\ntime-consuming and costly. Advancements in neural networks have significantly\nalleviated this burden, enabling highly accurate ball tracking in sports\nbroadcasts. However, relying solely on 2D ball tracking is limiting, as it\ndepends on the camera's viewpoint and falls short of supporting comprehensive\ngame analysis. To address this limitation, we propose a novel approach for\nreconstructing precise 3D ball trajectories from online table tennis match\nrecordings. Our method leverages the underlying physics of the ball's motion to\nidentify the bounce state that minimizes the reprojection error of the ball's\nflying trajectory, hence ensuring an accurate and reliable 3D reconstruction. A\nkey advantage of our approach is its ability to infer ball spin without relying\non human pose estimation or racket tracking, which are often unreliable or\nunavailable in broadcast footage. We developed an automated camera calibration\nmethod capable of reliably tracking camera movements. Additionally, we adapted\nan existing 3D pose estimation model, which lacks depth motion capture, to\naccurately track player movements. Together, these contributions enable the\nfull 3D reconstruction of a table tennis rally.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:37:47Z"}
{"aid":"http://arxiv.org/abs/2504.10046v1","title":"CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code\n  Generation","summary":"Large language models (LLMs) have shown promising performance in automated\ncode generation, especially excelling in simple tasks such as generating\nstandalone codes. Different from simple tasks, real-world code generation\nusually depends on specific programming environment (e.g., code repositories).\nIt contains complex dependencies and domain knowledge, which is needed for LLMs\nwhen generating target code snippets. In this paper, we propose CodeRAG, a\nretrieval-augmented code generation (RAG) framework to comprehensively retrieve\nsupportive codes for real-world code generation. Beginning with the\nrequirement, CodeRAG first constructs a requirement graph for the current\nrepository, and retrieves sub- and similar- requirement nodes of the target\nrequirement on the graph. Meanwhile, it models the repository into a DS-code\ngraph. CodeRAG then maps these relevant requirement nodes into their\ncorresponding code nodes, and treats these code nodes as archors for LLM\nreasoning on DS-code graph. Finally, CodeRAG introduces a code-oriented agentic\nreasoning process, seamlessly allowing LLMs to reason and comprehensively\nretrieve for supportive codes which LLMs' need for generating correct programs.\nExperiments show that CodeRAG achieves significant improvements (i.e.,\nincreasing 40.90 and 37.79 Pass@1 on GPT-4o and Gemini-Pro on DevEval) compared\nto no RAG scenarios. Further tests on reasoning LLMs (i.e., QwQ-32B) confirm\nCodeRAG's adaptability and efficacy across various types of LLMs. In addition,\nCodeRAG outperforms commercial programming products such as Copilit and Cursor.\nWe further investigate the performance of our framework on different dependency\ntypes, and observe that CodeRAG is superior in generating examples where target\ncodes invoke predefined cross-file code snippets. These results demonstrate\nCodeRAG's potential in solving real-world repo-level coding challenges.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T09:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.10047v1","title":"Vibrational structure and symmetry in $^{110-116}$Cd","summary":"We show that a vibrational interpretation and good U(5) symmetry are\nmaintained for the majority of low-lying normal states in\n$^{110,112,114,116}$Cd isotopes, consistent with the empirical data. The\nobserved deviations from this paradigm are properly treated by an interacting\nboson model Hamiltonian which breaks the U(5) symmetry in selected non-yrast\nstates, while securing a weak mixing with coexisting SO(6)-like intruder\nstates. The results demonstrate the relevance of the U(5) partial dynamical\nsymmetry notion to this series of isotopes.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-14T09:53:30Z"}
{"aid":"http://arxiv.org/abs/2504.10048v1","title":"Multi-Object Grounding via Hierarchical Contrastive Siamese Transformers","summary":"Multi-object grounding in 3D scenes involves localizing multiple objects\nbased on natural language input. While previous work has primarily focused on\nsingle-object grounding, real-world scenarios often demand the localization of\nseveral objects. To tackle this challenge, we propose Hierarchical Contrastive\nSiamese Transformers (H-COST), which employs a Hierarchical Processing strategy\nto progressively refine object localization, enhancing the understanding of\ncomplex language instructions. Additionally, we introduce a Contrastive Siamese\nTransformer framework, where two networks with the identical structure are\nused: one auxiliary network processes robust object relations from ground-truth\nlabels to guide and enhance the second network, the reference network, which\noperates on segmented point-cloud data. This contrastive mechanism strengthens\nthe model' s semantic understanding and significantly enhances its ability to\nprocess complex point-cloud data. Our approach outperforms previous\nstate-of-the-art methods by 9.5% on challenging multi-object grounding\nbenchmarks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.10049v1","title":"Summarization of Multimodal Presentations with Vision-Language Models:\n  Study of the Effect of Modalities and Structure","summary":"Vision-Language Models (VLMs) can process visual and textual information in\nmultiple formats: texts, images, interleaved texts and images, or even\nhour-long videos. In this work, we conduct fine-grained quantitative and\nqualitative analyses of automatic summarization of multimodal presentations\nusing VLMs with various representations as input. From these experiments, we\nsuggest cost-effective strategies for generating summaries from text-heavy\nmultimodal documents under different input-length budgets using VLMs. We show\nthat slides extracted from the video stream can be beneficially used as input\nagainst the raw video, and that a structured representation from interleaved\nslides and transcript provides the best performance. Finally, we reflect and\ncomment on the nature of cross-modal interactions in multimodal presentations\nand share suggestions to improve the capabilities of VLMs to understand\ndocuments of this nature.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-14T09:55:01Z"}
{"aid":"http://arxiv.org/abs/2504.10066v1","title":"A Framework for Adaptive Load Redistribution in Human-Exoskeleton-Cobot\n  Systems","summary":"Wearable devices like exoskeletons are designed to reduce excessive loads on\nspecific joints of the body. Specifically, single- or two-degrees-of-freedom\n(DOF) upper-body industrial exoskeletons typically focus on compensating for\nthe strain on the elbow and shoulder joints. However, during daily activities,\nthere is no assurance that external loads are correctly aligned with the\nsupported joints. Optimizing work processes to ensure that external loads are\nprimarily (to the extent that they can be compensated by the exoskeleton)\ndirected onto the supported joints can significantly enhance the overall\nusability of these devices and the ergonomics of their users. Collaborative\nrobots (cobots) can play a role in this optimization, complementing the\ncollaborative aspects of human work. In this study, we propose an adaptive and\ncoordinated control system for the human-cobot-exoskeleton interaction. This\nsystem adjusts the task coordinates to maximize the utilization of the\nsupported joints. When the torque limits of the exoskeleton are exceeded, the\nframework continuously adapts the task frame, redistributing excessive loads to\nnon-supported body joints to prevent overloading the supported ones. We\nvalidated our approach in an equivalent industrial painting task involving a\nsingle-DOF elbow exoskeleton, a cobot, and four subjects, each tested in four\ndifferent initial arm configurations with five distinct optimisation weight\nmatrices and two different payloads.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T10:09:00Z"}
{"aid":"http://arxiv.org/abs/2504.10067v1","title":"Undermining Federated Learning Accuracy in EdgeIoT via Variational Graph\n  Auto-Encoders","summary":"EdgeIoT represents an approach that brings together mobile edge computing\nwith Internet of Things (IoT) devices, allowing for data processing close to\nthe data source. Sending source data to a server is bandwidth-intensive and may\ncompromise privacy. Instead, federated learning allows each device to upload a\nshared machine-learning model update with locally processed data. However, this\ntechnique, which depends on aggregating model updates from various IoT devices,\nis vulnerable to attacks from malicious entities that may inject harmful data\ninto the learning process. This paper introduces a new attack method targeting\nfederated learning in EdgeIoT, known as data-independent model manipulation\nattack. This attack does not rely on training data from the IoT devices but\ninstead uses an adversarial variational graph auto-encoder (AV-GAE) to create\nmalicious model updates by analyzing benign model updates intercepted during\ncommunication. AV-GAE identifies and exploits structural relationships between\nbenign models and their training data features. By manipulating these\nstructural correlations, the attack maximizes the training loss of the\nfederated learning system, compromising its overall effectiveness.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T10:09:38Z"}
{"aid":"http://arxiv.org/abs/2504.10073v1","title":"Quantum-Classical Comparison of B-cell Epitope Prediction Using QSVM and\n  VQC","summary":"Support Vector Machine (SVM) is a classical and widely applied supervised\nmachine learning algorithm for binary classification. Utilizing the kernel\ntrick enables embedding data into higher-dimensional feature spaces to address\nnon-linear classification tasks effectively.\n  This study investigates the classical SVM and its quantum counterpart, the\nQuantum Support Vector Machine (QSVM), which leverages quantum feature maps to\nembed data into high-dimensional Hilbert spaces. Additionally, we explore the\nVariational Quantum Classifier (VQC), a fully quantum model based on\nparameterized quantum circuits.\n  We apply these quantum and classical models to the task of B-cell epitope\nprediction, a critical problem in immunoinformatics relevant to vaccine design.\nUsing curated data from the Immune Epitope Database (IEDB), we examine\nclassification performance under varying feature dimensionality and sample\nsizes. Dimensionality reduction is performed using Principal Component Analysis\n(PCA), and experiments include both QSVM and VQC under multiple training\nconditions.\n  Our findings show that VQC generally performs better on larger,\nhigh-dimensional datasets, while QSVM maintains more stable accuracy on small,\nnoise-free datasets. This study also highlights the resource trade-offs between\nthe two models: QSVM demands extensive kernel evaluations, while VQC benefits\nfrom shallow circuits and sample-wise training, making it suitable for\nnear-term quantum hardware. These results contribute to understanding how\ndifferent quantum machine learning models perform under practical constraints\nin biomedical sequence classification.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T10:19:33Z"}
{"aid":"http://arxiv.org/abs/2504.10075v1","title":"Long-range magnetic interactions in Nd$_2$PdSi$_3$ and the formation of\n  skyrmion phases in centrosymmetric metals","summary":"We present an extensive X-ray and neutron scattering study of the structure\nand magnetic excitations of Nd$_2$PdSi$_3$, a sister compound of Gd$_2$PdSi$_3$\nwhich was recently found to host a skyrmion lattice phase despite its\ncentrosymmetric crystal structure. Dispersive magnetic excitations were\nmeasured throughout the Brillouin zone and modelled using mean-field\nrandom-phase approximation to determine the magnetic interactions between Nd\nions. Our analysis reveals that the magnetic interactions in this system extend\nover large distances and are significantly affected by a crystallographic\nsuperstructure formed by ordering of the Pd and Si atoms. The results suggest\nthat the mechanism for the skyrmion phase formation in this family of\nmaterials, e.g. Gd$_2$PdSi$_3$ is through the long-range RKKY interactions\nrather than short-range triangular-lattice frustration.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.other","published":"2025-04-14T10:20:39Z"}
{"aid":"http://arxiv.org/abs/2504.10086v1","title":"Bagci-Hoggan Complete and Orthonormal Sets of ETOs. Results for He-like\n  atoms","summary":"The Hartree-Fock-Rothaan equations are solved for He-like ions using the\niterative self-consistent method. Bagci-Hoggan complete and orthonormal sets of\nexponential-type orbitals are employed as the basis. These orbitals satisfy the\northonormality relationship for quantum numbers with fractional order. They are\nsolution of Schrodinger-like differential equation derived by the author. In a\nrecent study conducted for the calculation of the hydrogen atom energy levels,\nit has been demonstrated that the fractional formalism of the principal and the\nangular momentum quantum numbers converges to the 1s level of the ground state\nenergy of hydrogen atom, obtained from the solution of the standard Schrodinger\nequation. This study examines the effect of fractional values of the quantum\nnumbers for two-electron systems, where electron correlation effects exist.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-14T10:42:04Z"}
{"aid":"http://arxiv.org/abs/2504.10087v1","title":"Joint Localization and Synchronization in Downlink Distributed MIMO","summary":"We investigate joint localization and synchronization in the downlink of a\ndistributed multiple-input-multiple-output (D-MIMO) system, aiming to estimate\nthe position and phase offset of a single-antenna user equipment (UE) using\ndownlink transmissions of multiple phase-synchronized, multi-antenna access\npoints (APs). We propose two transmission protocols: sequential (P1) and\nsimultaneous (P2) AP transmissions, together with the ML estimators that either\nleverage (coherent estimator) or disregard phase information (non-coherent\nestimator). Simulation results reveal that downlink D-MIMO holds significant\npotential for high-accuracy localization while showing that P2 provides\nsuperior localization performance and reduced transmission latency.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T10:47:05Z"}
{"aid":"http://arxiv.org/abs/2504.10099v1","title":"Regularization of Functional Determinants of Radial Operators via Heat\n  Kernel Coefficients","summary":"We propose an efficient regularization method for functional determinants of\nradial operators using heat kernel coefficients. Our key finding is a\nsystematic way to identify heat kernel coefficients in the angular momentum\nspace. We explicitly obtain the formulas up to sixth order in the heat kernel\nexpansion, which suffice to regularize functional determinants in up to 13\ndimensions. We find that the heat kernel coefficients accurately approximate\nthe large angular momentum dependence of functional determinants, and make\nnumerical computations more efficient. In the limit of a large angular\nmomentum, our formulas reduce to the WKB formulas in previous studies, but\nextended to higher orders. All the results are available in both the zeta\nfunction regularization and the dimensional regularization.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-14T11:06:21Z"}
{"aid":"http://arxiv.org/abs/2504.10103v1","title":"Numerical approach for solving problems arising from polynomial analysis","summary":"This paper deals with the use of numerical methods based on random root\nsampling techniques to solve some theoretical problems arising in the analysis\nof polynomials. These methods are proved to be practical and give solutions\nwhere traditional methods might fall short.","main_category":"math.NA","categories":"math.NA,cs.NA,math.CA","published":"2025-04-14T11:13:11Z"}
{"aid":"http://arxiv.org/abs/2504.10106v1","title":"SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene\n  Understanding","summary":"Sports video analysis is a key domain in computer vision, enabling detailed\nspatial understanding through multi-view correspondences. In this work, we\nintroduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets\ndesigned for 3D scene understanding in soccer broadcast analysis. These\ndatasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera\ncalibration and multi-view synchronization, enabling 3D object localization\nthrough triangulation. We propose a monocular 3D ball localization task built\nupon the triangulation of ground-truth 2D ball annotations, along with several\ncalibration and reprojection metrics to assess annotation quality on demand.\nAdditionally, we present a single-image 3D ball localization method as a\nbaseline, leveraging camera calibration and ball size priors to estimate the\nball's position from a monocular viewpoint. To further refine 2D annotations,\nwe introduce a bounding box optimization technique that ensures alignment with\nthe 3D scene representation. Our proposed datasets establish new benchmarks for\n3D soccer scene understanding, enhancing both spatial and temporal analysis in\nsports analytics. Finally, we provide code to facilitate access to our\nannotations and the generation pipelines for the datasets.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T11:15:13Z"}
{"aid":"http://arxiv.org/abs/2504.10108v1","title":"A Photometric Comparison of B and Be stars using Gaia DR3","summary":"Previous studies have observed significant photometric differences between\nnon-emission B-type and classical Be stars, however the precise mechanism\nresponsible for these differences is unclear. This study combines the Bright\nStar Catalogue with Tycho and Gaia photometry to create a homogeneous sample of\n1015 of the closest and brightest B and Be-type field stars with 90 per cent of\nobjects at distances < 500pc. Due to their proximity, the extinction towards\nthese objects is very low, ensuring we minimise any obfuscation in the\nreddening correction and final photometry. We present our findings in both\nTycho and Gaia photometry through colour magnitude diagrams and present\nintrinsic colours and absolute magnitudes for each spectral type. We find Be\nstars are on average ~0.5 magnitudes brighter in both Gaia $G$ and Tycho V$_T$\ncompared to non-emission B stars of the same spectral type. Additionally, we\nfind tentative evidence that Be stars are redder in Gaia B$_P$$-$R$_P$,\nparticularly for the earlier types, but have similar Tycho B$_T$$-$V$_T$\ncolours. We test the effects of gravitational darkening due to rapid rotation\nand binarity on the photometry of our sample and find both to be insufficient\nto explain the observed photometric differences between B and Be stars. We\nconclude that the most likely mechanism responsible for the observed\nphotometric differences is the combined effect of the circumstellar disc and\nstellar evolution up the Main Sequence, with the disc dominating early-types\nand evolution dominating late type stars.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-14T11:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.10109v1","title":"Lightweight Trustworthy Distributed Clustering","summary":"Ensuring data trustworthiness within individual edge nodes while facilitating\ncollaborative data processing poses a critical challenge in edge computing\nsystems (ECS), particularly in resource-constrained scenarios such as\nautonomous systems sensor networks, industrial IoT, and smart cities. This\npaper presents a lightweight, fully distributed k-means clustering algorithm\nspecifically adapted for edge environments, leveraging a distributed averaging\napproach with additive secret sharing, a secure multiparty computation\ntechnique, during the cluster center update phase to ensure the accuracy and\ntrustworthiness of data across nodes.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-04-14T11:16:07Z"}
{"aid":"http://arxiv.org/abs/2504.10115v1","title":"Heat Kernel methods in the first-order formalism","summary":"In this paper, we extend the heat kernel methods to the first-order formalism\nof gravity, specifically, in the language of differential forms. This allows us\nto compute the effective dynamics of 4D gravity when the tetrad degrees of\nfreedom are integrated out. We show that the resulting effective field theory\nis the Lorentz gauge theory.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-14T11:25:40Z"}
{"aid":"http://arxiv.org/abs/2504.10125v1","title":"An initial-boundary corrected splitting method for diffusion-reaction\n  problems","summary":"Strang splitting is a widely used second-order method for solving\ndiffusion-reaction problems. However, its convergence order is often reduced to\norder $1$ for Dirichlet boundary conditions and to order $1.5$ for Neumann and\nRobin boundary conditions, leading to lower accuracy and reduced efficiency. In\nthis paper, we propose a new splitting approach, called an initial-boundary\ncorrected splitting, which avoids order reduction while improving computational\nefficiency for a wider range of applications. In contrast to the corrections\nproposed in the literature, it does not require the computation of correction\nterms that depend on the boundary conditions and boundary data. Through\nrigorous analytical convergence analysis and numerical experiments, we\ndemonstrate the improved accuracy and performance of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T11:32:33Z"}
{"aid":"http://arxiv.org/abs/2504.10135v1","title":"Exploiting Structure in MIMO Scaled Graph Analysis","summary":"Scaled graphs offer a graphical tool for analysis of nonlinear feedback\nsystems. Although recently substantial progress has been made in scaled graph\nanalysis, at present their use in multivariable feedback systems is limited by\nconservatism. In this paper, we aim to reduce this conservatism by introducing\nmultipliers and exploit system structure in the analysis with scaled graphs. In\nparticular, we use weighted inner products to arrive at a weighted scaled graph\nand combine this with a commutation property to formulate a stability result\nfor multivariable feedback systems. We present a method for computing the\nweighted scaled graph of Lur'e systems based on solving sets of linear matrix\ninequalities, and demonstrate a significant reduction in conservatism through\nan example.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T11:46:22Z"}
{"aid":"http://arxiv.org/abs/2504.10136v1","title":"Uncertainty Propagation in the Fast Fourier Transform","summary":"We address the problem of uncertainty propagation in the discrete Fourier\ntransform by modeling the fast Fourier transform as a factor graph. Building on\nthis representation, we propose an efficient framework for approximate Bayesian\ninference using belief propagation (BP) and expectation propagation, extending\nits applicability beyond Gaussian assumptions. By leveraging an appropriate BP\nmessage representation and a suitable schedule, our method achieves stable\nconvergence with accurate mean and variance estimates. Numerical experiments in\nrepresentative scenarios from communications demonstrate the practical\npotential of the proposed framework for uncertainty-aware inference in\nprobabilistic systems operating across both time and frequency domain.","main_category":"cs.LG","categories":"cs.LG,eess.SP","published":"2025-04-14T11:47:42Z"}
{"aid":"http://arxiv.org/abs/2504.10138v1","title":"$k$-Fibonacci numbers that are palindromic concatenations of two\n  distinct Repdigits","summary":"Let $k\\ge 2$ and $\\{F_n^{(k)}\\}_{n\\geq 2-k}$ be the sequence of\n$k$--generalized Fibonacci numbers whose first $k$ terms are $0,\\ldots,0,0,1$\nand each term afterwards is the sum of the preceding $k$ terms. In this paper,\nwe determine all $k$-Fibonacci numbers that are palindromic concatenations of\ntwo distinct repdigits.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T11:52:33Z"}
{"aid":"http://arxiv.org/abs/2504.10141v1","title":"The Impact of Model Zoo Size and Composition on Weight Space Learning","summary":"Re-using trained neural network models is a common strategy to reduce\ntraining cost and transfer knowledge. Weight space learning - using the weights\nof trained models as data modality - is a promising new field to re-use\npopulations of pre-trained models for future tasks. Approaches in this field\nhave demonstrated high performance both on model analysis and weight generation\ntasks. However, until now their learning setup requires homogeneous model zoos\nwhere all models share the same exact architecture, limiting their capability\nto generalize beyond the population of models they saw during training. In this\nwork, we remove this constraint and propose a modification to a common weight\nspace learning method to accommodate training on heterogeneous populations of\nmodels. We further investigate the resulting impact of model diversity on\ngenerating unseen neural network model weights for zero-shot knowledge\ntransfer. Our extensive experimental evaluation shows that including models\nwith varying underlying image datasets has a high impact on performance and\ngeneralization, for both in- and out-of-distribution settings. Code is\navailable on github.com/HSG-AIML/MultiZoo-SANE.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T11:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.10150v1","title":"HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation\n  with User History Encoding and Compression","summary":"While large language models (LLMs) have proven effective in leveraging\ntextual data for recommendations, their application to multimodal\nrecommendation tasks remains relatively underexplored. Although LLMs can\nprocess multimodal information through projection functions that map visual\nfeatures into their semantic space, recommendation tasks often require\nrepresenting users' history interactions through lengthy prompts combining text\nand visual elements, which not only hampers training and inference efficiency\nbut also makes it difficult for the model to accurately capture user\npreferences from complex and extended prompts, leading to reduced\nrecommendation performance. To address this challenge, we introduce HistLLM, an\ninnovative multimodal recommendation framework that integrates textual and\nvisual features through a User History Encoding Module (UHEM), compressing\nmultimodal user history interactions into a single token representation,\neffectively facilitating LLMs in processing user preferences. Extensive\nexperiments demonstrate the effectiveness and efficiency of our proposed\nmechanism.","main_category":"cs.IR","categories":"cs.IR,cs.MM","published":"2025-04-14T12:01:11Z"}
{"aid":"http://arxiv.org/abs/2504.10156v1","title":"The missing elements in the telegraph equations","summary":"The conventional modeling of transmission lines relies on the classical\ntelegraph equations, originally formulated over 150 years ago. These equations\nare typically derived by representing the line as an assembly of infinitesimal\ninductive, capacitive, and resistive elements. However, this formulation is\nfundamentally flawed, as a transmission line cannot be accurately described\nthrough a discretized model of infinitesimal lumped components. Instead, a more\nrigorous approach should derive the governing equations directly from Maxwells\nequations in conjunction with Ohms law. This paper presents such a derivation\nand introduces a corrected formulation, herein referred to as the Trump\nEquations.","main_category":"physics.gen-ph","categories":"physics.gen-ph","published":"2025-04-14T12:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.10160v1","title":"MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like\n  Reinforcement Learning","summary":"Large-scale reinforcement learning (RL) methods have proven highly effective\nin enhancing the reasoning abilities of large language models (LLMs),\nparticularly for tasks with verifiable solutions such as mathematics and\ncoding. However, applying this idea to machine translation (MT), where outputs\nare flexibly formatted and difficult to automatically evaluate with explicit\nrules, remains underexplored. In this work, we introduce MT-R1-Zero, the first\nopen-source adaptation of the R1-Zero RL framework for MT without supervised\nfine-tuning or cold-start. We propose a rule-metric mixed reward mechanism to\nguide LLMs towards improved translation quality via emergent reasoning. On the\nWMT 24 English-Chinese benchmark, our MT-R1-Zero-3B-Mix achieves competitive\nperformance, surpassing TowerInstruct-7B-v0.2 by an average of 1.26 points.\nMeanwhile, our MT-R1-Zero-7B-Mix attains a high average score of 62.25 across\nall metrics, placing it on par with advanced proprietary models such as GPT-4o\nand Claude-3.5-Sonnet, while the MT-R1-Zero-7B-Sem variant achieves\nstate-of-the-art scores on semantic metrics. Moreover, our work exhibits strong\ngeneralization capabilities on out-of-distribution MT tasks, robustly\nsupporting multilingual and low-resource settings. Extensive analysis of model\nbehavior across different initializations and reward metrics offers pioneering\ninsight into the critical role of reward design, LLM adaptability, training\ndynamics, and emergent reasoning patterns within the R1-Zero paradigm for MT.\nOur code is available at https://github.com/fzp0424/MT-R1-Zero.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T12:14:18Z"}
{"aid":"http://arxiv.org/abs/2504.10171v1","title":"Kullback-Leibler excess risk bounds for exponential weighted aggregation\n  in Generalized linear models","summary":"Aggregation methods have emerged as a powerful and flexible framework in\nstatistical learning, providing unified solutions across diverse problems such\nas regression, classification, and density estimation. In the context of\ngeneralized linear models (GLMs), where responses follow exponential family\ndistributions, aggregation offers an attractive alternative to classical\nparametric modeling. This paper investigates the problem of sparse aggregation\nin GLMs, aiming to approximate the true parameter vector by a sparse linear\ncombination of predictors. We prove that an exponential weighted aggregation\nscheme yields a sharp oracle inequality for the Kullback-Leibler risk with\nleading constant equal to one, while also attaining the minimax-optimal rate of\naggregation. These results are further enhanced by establishing\nhigh-probability bounds on the excess risk.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-04-14T12:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.10177v1","title":"Lagrangian averaging of singular stochastic actions for fluid dynamics","summary":"We construct sub-grid scale models of incompressible fluids by considering\nexpectations of semi-martingale Lagrangian particle trajectories. Our\nconstruction is based on the Lagrangian decomposition of flow maps into mean\nand fluctuation parts, and it is separated into the following steps. First,\nthrough Magnus expansion, the fluid velocity field is expressed in terms of\nfluctuation vector fields whose dynamics are assumed to be stochastic. Second,\nwe use Malliavin calculus to give a regularised interpretation of the product\nof white noise when inserting the stochastic velocity field into the Lagrangian\nfor Euler's fluid. Lastly, we consider closures of the mean velocity by making\nstochastic analogues of Talyor's frozen-in turbulence hypothesis to derive a\nversion of the anisotropic Lagrangian averaged Euler equation.","main_category":"math-ph","categories":"math-ph,math.MP,physics.flu-dyn","published":"2025-04-14T12:29:06Z"}
{"aid":"http://arxiv.org/abs/2504.10182v1","title":"Explicit cluster multiplication formulas for the quantum cluster algebra\n  of type $A_2^{(1)}$","summary":"Let $Q$ be an affine quiver of type $A_2^{(1)}$. We explicitly construct the\ncluster multiplication formulas for the quantum cluster algebra of $Q$ with\nprincipal coefficients. As applications, we obtain: (1)\\ an exact expression\nfor every quantum cluster variable as a polynomial in terms of the quantum\ncluster variables in clusters which are one-step mutations from the initial\ncluster; (2)\\ an explicit bar-invariant positive $\\mathbb{ZP}$-basis.","main_category":"math.QA","categories":"math.QA,math.RT","published":"2025-04-14T12:35:08Z"}
{"aid":"http://arxiv.org/abs/2504.10185v1","title":"LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in\n  Current Benchmarks","summary":"Large language model unlearning has become a critical challenge in ensuring\nsafety and controlled model behavior by removing undesired data-model\ninfluences from the pretrained model while preserving general utility.\nSignificant recent efforts have been dedicated to developing LLM unlearning\nbenchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine\nUnlearning Six-way Evaluation), facilitating standardized unlearning\nperformance assessment and method comparison. Despite their usefulness, we\nuncover for the first time a novel coreset effect within these benchmarks.\nSpecifically, we find that LLM unlearning achieved with the original (full)\nforget set can be effectively maintained using a significantly smaller subset\n(functioning as a \"coreset\"), e.g., as little as 5% of the forget set, even\nwhen selected at random. This suggests that LLM unlearning in these benchmarks\ncan be performed surprisingly easily, even in an extremely low-data regime. We\ndemonstrate that this coreset effect remains strong, regardless of the LLM\nunlearning method used, such as NPO (Negative Preference Optimization) and RMU\n(Representation Misdirection Unlearning), the popular ones in these benchmarks.\nThe surprisingly strong coreset effect is also robust across various data\nselection methods, ranging from random selection to more sophisticated\nheuristic approaches. We explain the coreset effect in LLM unlearning through a\nkeyword-based perspective, showing that keywords extracted from the forget set\nalone contribute significantly to unlearning effectiveness and indicating that\ncurrent unlearning is driven by a compact set of high-impact tokens rather than\nthe entire dataset. We further justify the faithfulness of coreset-unlearned\nmodels along additional dimensions, such as mode connectivity and robustness to\njailbreaking attacks. Codes are available at\nhttps://github.com/OPTML-Group/MU-Coreset.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T12:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.10212v1","title":"WG-IDENT: Weak Group Identification of PDEs with Varying Coefficients","summary":"Partial Differential Equations (PDEs) identification is a data-driven method\nfor mathematical modeling, and has received a lot of attentions recently. The\nstability and precision in identifying PDE from heavily noisy spatiotemporal\ndata present significant difficulties. This problem becomes even more complex\nwhen the coefficients of the PDEs are subject to spatial variation. In this\npaper, we propose a Weak formulation of Group-sparsity-based framework for\nIDENTifying PDEs with varying coefficients, called WG-IDENT, to tackle this\nchallenge. Our approach utilizes the weak formulation of PDEs to reduce the\nimpact of noise. We represent test functions and unknown PDE coefficients using\nB-splines, where the knot vectors of test functions are optimally selected\nbased on spectral analysis of the noisy data. To facilitate feature selection,\nwe propose to integrate group sparse regression with a newly designed group\nfeature trimming technique, called GF-trim, to eliminate unimportant features.\nExtensive and comparative ablation studies are conducted to validate our\nproposed method. The proposed method not only demonstrates greater robustness\nto high noise levels compared to state-of-the-art algorithms but also achieves\nsuperior performance while exhibiting reduced sensitivity to hyperparameter\nselection.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T13:26:56Z"}
{"aid":"http://arxiv.org/abs/2504.10217v1","title":"Dissimilar magnetically driven accretion on the components of V4046\n  Sagittarii","summary":"Accretion of pre-main sequence stars (PMS) is a key process in stellar\nformation, governing mass assembly, influencing angular momentum conservation\nand stellar internal structure, and shaping disc evolution, which serves as the\nbirthplace of exoplanets. Classical T Tauri stars (cTTSs), low-mass PMS stars\nactively accreting from a disc, hold a well-described magnetospheric accretion\nmodel. Their strong, inclined dipole magnetic fields truncate the disc at a few\nstellar radii, channelling material along magnetic field lines to fall onto the\nstellar surface near the dipole pole. However, this paradigm assumes the\npresence of a single star, and a complete description of the accretion process\nin multiple systems remains to be achieved. Building on our previous work on DQ\nTau and AK Sco, we aim to describe the accretion processes in cTTS binaries,\naccounting for the influence of stellar magnetic fields. Specifically, we\nsought to explore how the magnetospheric accretion model of cTTSs can be\napplied to V4046 Sgr, a spectroscopic binary composed of equal-mass and coeval\ncTTSs in a circular orbit with synchronous rotation, surrounded by a\ncircumbinary disc. We analysed a time series of ESPaDOnS spectra covering\nseveral orbital cycles. A variability analysis was performed on the radial\nvelocities and on the Balmer, He I D3, and Ca II emission lines, which are\nassociated with the accretion process. We identified the secondary as the\nsystem's main accretor, operating in an unstable regime. Additionally, we\ndetected an accretion funnel flow connecting the dipole pole of the primary\nstar with a nearby bulk of gas. We concluded that the two components exhibit\ndissimilar accretion patterns. The primary operates in an \"ordered chaotic\"\nregime, where accretion funnel flows and accretion tongues coexist. Conversely,\nthe secondary appears to be in a chaotic regime, with accretion tongues\ndominating.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-14T13:33:44Z"}
{"aid":"http://arxiv.org/abs/2504.10218v1","title":"A Novel Quantum Fourier Ordinary Differential Equation Solver for\n  Solving Linear and Nonlinear Partial Differential Equations","summary":"In this work, a novel quantum Fourier ordinary differential equation (ODE)\nsolver is proposed to solve both linear and nonlinear partial differential\nequations (PDEs). Traditional quantum ODE solvers transform a PDE into an ODE\nsystem via spatial discretization and then integrate it, thereby converting the\ntask of solving the PDE into computing the integral for the driving function\n$f(x)$. These solvers rely on the quantum amplitude estimation algorithm, which\nrequires the driving function $f(x)$ to be within the range of [0, 1] and\nnecessitates the construction of a quantum circuit for the oracle R that\nencodes $f(x)$. This construction can be highly complex, even for simple\nfunctions like $f(x) = x$. An important exception arises for the specific case\nof $f(x) = sin^2(mx+c)$, which can be encoded more efficiently using a set of\n$Ry$ rotation gates. To address these challenges, we expand the driving\nfunction $f(x)$ as a Fourier series and propose the Quantum Fourier ODE Solver.\nThis approach not only simplifies the construction of the oracle R but also\nremoves the restriction that $f(x)$ must lie within [0,1]. The proposed method\nwas evaluated by solving several representative linear and nonlinear PDEs,\nincluding the Navier-Stokes (N-S) equations. The results show that the quantum\nFourier ODE solver produces results that closely match both analytical and\nreference solutions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T13:36:46Z"}
{"aid":"http://arxiv.org/abs/2504.10241v1","title":"Cross-correlations between X-ray clusters and the general galaxy\n  population","summary":"This study presents highly precise measurements of the cross-correlation\nbetween volume-limited galaxy samples from the DESI legacy survey catalogue and\nX-ray selected galaxy clusters from eROSITA, allowing for detailed analysis\nacross redshift and color. Two key findings emerge. First, the cluster-galaxy\ncross-correlation, when split into quiescent and star-forming galaxies,\ncontains significant information about the infall, feedback, and quenching\nprocesses of blue cloud galaxies in massive environments. These results align\nwell with existing galaxy evolution models for higher stellar masses\n($\\log_{10}(M^*[M_\\odot]) > 10.75$), though the red fraction may be slightly\nunderestimated in the intermediate mass range ($10.25 <\n\\log_{10}(M^*[M_\\odot])< 10.75$). Second, the integral of the cross-correlation\nwithin 500 kpc enables a model-independent measurement of the red sequence and\nits scatter in clusters, providing a robust alternative to existing\nred-sequence calibration methods without requiring spectroscopic redshifts or\nclassifications of galaxies. Similar analyses on upcoming photometric surveys\nas Euclid and LSST together with spectroscopic samples like 4MOST and DESI\nshould lead to a significant increase in the signal-to-noise ratio and in\nparticular at small separations.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-14T14:03:56Z"}
{"aid":"http://arxiv.org/abs/2504.10242v1","title":"CAT: A Conditional Adaptation Tailor for Efficient and Effective\n  Instance-Specific Pansharpening on Real-World Data","summary":"Pansharpening is a crucial remote sensing technique that fuses low-resolution\nmultispectral (LRMS) images with high-resolution panchromatic (PAN) images to\ngenerate high-resolution multispectral (HRMS) imagery. Although deep learning\ntechniques have significantly advanced pansharpening, many existing methods\nsuffer from limited cross-sensor generalization and high computational\noverhead, restricting their real-time applications. To address these\nchallenges, we propose an efficient framework that quickly adapts to a specific\ninput instance, completing both training and inference in a short time. Our\nframework splits the input image into multiple patches, selects a subset for\nunsupervised CAT training, and then performs inference on all patches,\nstitching them into the final output. The CAT module, integrated between the\nfeature extraction and channel transformation stages of a pre-trained network,\ntailors the fused features and fixes the parameters for efficient inference,\ngenerating improved results. Our approach offers two key advantages: (1)\n$\\textit{Improved Generalization Ability}$: by mitigating cross-sensor\ndegradation, our model--although pre-trained on a specific dataset--achieves\nsuperior performance on datasets captured by other sensors; (2)\n$\\textit{Enhanced Computational Efficiency}$: the CAT-enhanced network can\nswiftly adapt to the test sample using the single LRMS-PAN pair input, without\nrequiring extensive large-scale data retraining. Experiments on the real-world\ndata from WorldView-3 and WorldView-2 datasets demonstrate that our method\nachieves state-of-the-art performance on cross-sensor real-world data, while\nachieving both training and inference of $512\\times512$ image within\n$\\textit{0.4 seconds}$ and $4000\\times4000$ image within $\\textit{3 seconds}$\nat the fastest setting on a commonly used RTX 3090 GPU.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T14:04:55Z"}
{"aid":"http://arxiv.org/abs/2504.10268v1","title":"Theoretical Model of Microparticle-Assisted Super-Resolution Microscopy","summary":"This work presents the development of a three-dimensional model of\nsuper-resolution imaging, which may help resolve the longstanding debate about\nthe nature of this phenomenon and the methods used to describe it. We discuss\nthe approaches that enable an efficient and accurate theoretical description. A\ncomparison between theoretical predictions and experimental results is\npresented for both conventional and confocal microscopy.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T14:33:51Z"}
{"aid":"http://arxiv.org/abs/2504.10271v1","title":"Change Your Perspective, Widen Your Worldview! Societally Beneficial\n  Perceptual Filter Bubbles in Personalized Reality","summary":"Extended Reality (XR) technologies enable the personalized mediation of an\nindividual's perceivable reality across modalities, thereby creating a\nPersonalized Reality (PR). While this may lead to individually beneficial\neffects in the form of more efficient, more fun, and safer experiences, it may\nalso lead to perceptual filter bubbles since individuals are exposed\npredominantly or exclusively to content that is congruent with their existing\nbeliefs and opinions. This undermining of a shared basis for interaction and\ndiscussion through constrained perceptual worldviews may impact society through\nincreased polarization and other well-documented negative effects of filter\nbubbles. In this paper, we argue that this issue can be mitigated by increasing\nindividuals' awareness of their current perspective and providing avenues for\ndevelopment, including through support for engineered serendipity and fostering\nof self-actualization that already show promise for traditional recommender\nsystems. We discuss how these methods may be transferred to XR to yield\nvaluable tools to give people transparency and agency over their perceptual\nworldviews in a responsible manner.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T14:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10282v1","title":"Optimal Execution in Intraday Energy Markets under Hawkes Processes with\n  Transient Impact","summary":"This paper investigates optimal execution strategies in intraday energy\nmarkets through a mutually exciting Hawkes process model. Calibrated to data\nfrom the German intraday electricity market, the model effectively captures key\nempirical features, including intra-session volatility, distinct intraday\nmarket activity patterns, and the Samuelson effect as gate closure approaches.\nBy integrating a transient price impact model with a bivariate Hawkes process\nto model the market order flow, we derive an optimal trading trajectory for\nenergy companies managing large volumes, accounting for the specific trading\npatterns in these markets. A back-testing analysis compares the proposed\nstrategy against standard benchmarks such as Time-Weighted Average Price (TWAP)\nand Volume-Weighted Average Price (VWAP), demonstrating substantial cost\nreductions across various hourly trading products in intraday energy markets.","main_category":"q-fin.TR","categories":"q-fin.TR","published":"2025-04-14T14:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.10310v1","title":"Existence of Nonequilibrium Glasses in the Degenerate Stealthy\n  Hyperuniform Ground-State Manifold","summary":"Stealthy interactions are an emerging class of nontrivial, bounded\nlong-ranged oscillatory pair potentials with classical ground states that can\nbe disordered, hyperuniform, and infinitely degenerate. Their hybrid\ncrystal-liquid nature endows them with novel physical properties with\nadvantages over their crystalline counterparts. Here, we show the existence of\nnonequilibrium hard-sphere glasses within this unusual ground-state manifold as\nthe stealthiness parameter $\\chi$ tends to zero that are remarkably\nconfigurationally extremely close to hyperuniform 3D maximally random jammed\n(MRJ) sphere packings. The latter are prototypical glasses since they are\nmaximally disordered, perfectly rigid, and perfectly nonergodic. Our\noptimization procedure, which leverages the maximum cardinality of the infinite\nground-state set, not only guarantees that our packings are hyperuniform with\nthe same structure-factor scaling exponent as the MRJ state, but they share\nother salient structural attributes, including a packing fraction of $0.638$, a\nmean contact number per particle of 6, gap exponent of $0.44(1)$, and pair\ncorrelation functions $g_2(r)$ and structures factors $S(k)$ that are virtually\nidentical to one another for all $r$ and $k$, respectively. Moreover, we\ndemonstrate that stealthy hyperuniform packings can be created within the\ndisordered regime ($0 < \\chi <1/2$) with heretofore unattained maximal packing\nfractions. As $\\chi$ increases from zero, they always form interparticle\ncontacts, albeit with sparser contact networks as $\\chi$ increases from zero,\nresulting in linear polymer-like chains of contacting particles with\nincreasingly shorter chain lengths. The capacity to generate ultradense\nstealthy hyperuniform packings for all $\\chi$ opens up new materials\napplications in optics and acoustics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-14T15:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.10313v1","title":"An Empirical Evaluation of White-box and Black-box Test Case\n  Prioritization Techniques in CPSs Modeled in Simulink","summary":"MATLAB/Simulink is the leading tool for simulating complex Cyber-Physical\nSystems (CPSs). The simulation models of complex CPSs are typically compute\nintensive, and the execution of test cases is long. Furthermore, the execution\nof test cases is typically triggered several times at different ``in-the-Loop''\ntest levels (i.e., Model, Software and Hardware-in-the-Loop). Therefore, test\noptimization techniques, such as test case prioritization, are paramount when\ntesting these systems. In this paper, we present the largest empirical study on\ntest case prioritization techniques for Simulink models by comparing the\nperformance of white-box and black-box test case prioritization techniques. We\nassess traditional test case prioritization techniques, and we also propose new\napproaches for use in the context of Simulink models. We empirically compared\n11 test case prioritization techniques using six Simulink models of different\nsizes and complexities. When comparing white-box against black-box test case\nprioritization techniques, we found that in general, white-box techniques were\nslightly better than black-box ones. In the context of white-box test case\nprioritization, the total greedy approach performed better than the additional\ngreedy techniques in larger models. As for the test case prioritization time,\nblack-box techniques were faster, although total greedy techniques were fast\nenough to be used in practice.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T15:22:12Z"}
{"aid":"http://arxiv.org/abs/2504.10314v1","title":"Universal Algebra and Effectful Computation","summary":"Abstract clones serve as an algebraic presentation of the syntax of a simple\ntype theory. From the perspective of universal algebra, they define algebraic\ntheories like those of groups, monoids and rings. This link allows one to study\nthe language of simple type theory from the viewpoint of universal algebra.\n  Programming languages, however, are much more complicated than simple type\ntheory. Many useful features like reading, writing, and exception handling\ninvolve interacting with the environment; these are called side-effects.\nAlgebraic presentations for languages with the appropriate syntax for handling\neffects are given by premulticategories and effectful multicategories. We study\nthese structures with the aim of defining a suitable notion of an algebra.\n  To achieve this goal, we proceed in two steps. First, we define a tensor on\n$[\\to,\\category{Set}]$, and show that this tensor along with the cartesian\nproduct gives the category a duoidal structure. Secondly, we introduce the\nnovel notion of a multicategory enriched in a duoidal category which generalize\nthe traditional notion of a multicategory. Further, we prove that an effectful\nmulticategory is the same as a multicategory enriched in the duoidal category\n$[\\to,\\category{Set}]$. This result places multicategories and effectful\nmulticategories on a similar footing, and provides a mechanism for transporting\nconcepts from the theory of multicategories (which model pure computation) to\nthe theory of effectful multicategories (which model effectful computation). As\nan example of this, we generalize the definition of a 2-morphism for\nmulticategories to the duoidally enriched case. Our equivalence result then\ngives a natural definition of a 2-morphism for effectful multicategories, which\nwe then use to define the notion of an algebra.","main_category":"cs.PL","categories":"cs.PL,math.CT","published":"2025-04-14T15:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.10319v1","title":"Modular invariant gluon-graviton scattering in AdS at one loop","summary":"We consider mixed gluon-graviton scattering in Type IIB string theory on\nAdS$_5\\times S^5/\\mathbb{Z}_2$ in the presence of D7 branes, which is dual to a\nmixed correlator of the $SO(8)$ and $SU(2)_L$ flavor multiplets of a certain 4d\n$\\mathcal{N}=2$ $USp(2N)$ gauge theory with complexified coupling $\\tau$. We\ncompute this holographic correlator in the large $N$ and finite $\\tau$\nexpansion using constraints from derivatives of the mass deformed sphere free\nenergy, which we compute using supersymmetric localization at large $N$ and\nfinite $\\tau$ in terms of modular invariant non-holomorphic Eisenstein series.\nIn particular, we combine this constraint with the known flat space limit to\nfix the $R^2F^2$ higher derivative correction to the correlator in terms of the\nweight one non-holomorphic Eisenstein series, and also to fix the logarithmic\nthreshold. We also compute the one-loop correction to the correlator, and match\nit to the expected flat space limit result.","main_category":"hep-th","categories":"hep-th","published":"2025-04-14T15:27:59Z"}
{"aid":"http://arxiv.org/abs/2504.10331v1","title":"LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian\n  Splatting for Novel View Synthesis","summary":"Novel view synthesis (NVS) in low-light scenes remains a significant\nchallenge due to degraded inputs characterized by severe noise, low dynamic\nrange (LDR) and unreliable initialization. While recent NeRF-based approaches\nhave shown promising results, most suffer from high computational costs, and\nsome rely on carefully captured or pre-processed data--such as RAW sensor\ninputs or multi-exposure sequences--which severely limits their practicality.\nIn contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering with\ncompetitive visual fidelity; however, existing 3DGS-based methods struggle with\nlow-light sRGB inputs, resulting in unstable Gaussian initialization and\nineffective noise suppression. To address these challenges, we propose\nLL-Gaussian, a novel framework for 3D reconstruction and enhancement from\nlow-light sRGB images, enabling pseudo normal-light novel view synthesis. Our\nmethod introduces three key innovations: 1) an end-to-end Low-Light Gaussian\nInitialization Module (LLGIM) that leverages dense priors from learning-based\nMVS approach to generate high-quality initial point clouds; 2) a dual-branch\nGaussian decomposition model that disentangles intrinsic scene properties\n(reflectance and illumination) from transient interference, enabling stable and\ninterpretable optimization; 3) an unsupervised optimization strategy guided by\nboth physical constrains and diffusion prior to jointly steer decomposition and\nenhancement. Additionally, we contribute a challenging dataset collected in\nextreme low-light environments and demonstrate the effectiveness of\nLL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussian\nachieves up to 2,000 times faster inference and reduces training time to just\n2%, while delivering superior reconstruction and rendering quality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T15:39:31Z"}
{"aid":"http://arxiv.org/abs/2504.10338v1","title":"Classifying Copy Number Variations Using State Space Modeling of\n  Targeted Sequencing Data: A Case Study in Thalassemia","summary":"Thalassemia, a blood disorder and one of the most prevalent hereditary\ngenetic disorders worldwide, is often caused by copy number variations (CNVs)\nin the hemoglobin genes. This disorder has incredible diversity, with a large\nnumber of distinct profiles corresponding to alterations of different regions\nin the genes. Correctly classifying an individual's profile is critical as it\nimpacts treatment, prognosis, and genetic counseling. However, genetic\nclassification is challenging due to the large number of profiles worldwide,\nand often requires a large number of sequential tests. Targeted next generation\nsequencing (NGS), which characterizes segments of an individual's genome, has\nthe potential to dramatically reduce the cost of testing and increase accuracy.\nIn this work, we introduce a probabilistic state space model for profiling\nthalassemia from targeted NGS data, which naturally characterize the spatial\nordering of the genes along the chromosome. We then use decision theory to\nchoose the best profile among the different options. Due to our use of Bayesian\nmethodology, we are also able to detect low-quality samples to be excluded from\nconsideration, an important component of clinical screening. We evaluate our\nmodel on a dataset of 57 individuals, including both controls and cases with a\nvariety of thalassemia profiles. Our model has a sensitivity of 0.99 and\nspecificity of 0.93 for thalassemia detection, and accuracy of 91.5\\% for\ncharacterizing subtypes. Furthermore, the specificity and accuracy rise to\n$0.96$ and 93.9\\% when low-quality samples are excluded using our automated\nquality control method. This approach outperforms alternative methods,\nparticularly in specificity, and is broadly applicable to other disorders.","main_category":"q-bio.GN","categories":"q-bio.GN","published":"2025-04-14T15:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.10357v1","title":"The Communication and Computation Trade-off in Wireless Semantic\n  Communications","summary":"Semantic communications have emerged as a crucial research direction for\nfuture wireless communication networks. However, as wireless systems become\nincreasingly complex, the demands for computation and communication resources\nin semantic communications continue to grow rapidly. This paper investigates\nthe trade-off between computation and communication in wireless semantic\ncommunications, taking into consideration transmission task delay and\nperformance constraints within the semantic communication framework. We propose\na novel tradeoff metric to analyze the balance between computation and\ncommunication in semantic transmissions and employ the deep reinforcement\nlearning (DRL) algorithm to minimize this metric, thereby reducing the cost\nassociated with balancing computation and communication. Through simulations,\nwe analyze the tradeoff between computation and communication and demonstrate\nthe effectiveness of optimizing this trade-off metric.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T16:06:20Z"}
{"aid":"http://arxiv.org/abs/2504.10366v1","title":"Analogical models to introduce high school students to modern physics:\n  an inquiry-based activity on Rutherford's gold foil experiment","summary":"This paper presents the design, implementation, and evaluation of a didactic\nproposal on Rutherford's gold foil experiment, tailored for high schools.\nGrounded in constructivist pedagogy, the activity introduces key concepts of\nmodern physics-often absent from standard curricula-through a hands on,\ninquiry-based approach. By employing analogical reasoning and black box\nmodeling, students engage in experimental investigation and collaborative\nproblem-solving to explore atomic structure. The activity was implemented as a\ncase study with a class of first-year students (aged 14-15) from a applied\nscience-focused secondary school in Italy. Data collection combined qualitative\nobservations, structured discussions, and digital feedback tools to assess\nconceptual learning and student engagement. Findings indicate that\nwell-designed, student-centered interventions can meaningfully support the\ndevelopment of abstract scientific understanding, while fostering critical\nthinking and collaborative skills.","main_category":"physics.ed-ph","categories":"physics.ed-ph,nucl-ex,physics.app-ph,physics.hist-ph,physics.soc-ph","published":"2025-04-14T16:12:23Z"}
{"aid":"http://arxiv.org/abs/2504.10371v1","title":"Brain-Machine Interfaces & Information Retrieval Challenges and\n  Opportunities","summary":"The fundamental goal of Information Retrieval (IR) systems lies in their\ncapacity to effectively satisfy human information needs - a challenge that\nencompasses not just the technical delivery of information, but the nuanced\nunderstanding of human cognition during information seeking. Contemporary IR\nplatforms rely primarily on observable interaction signals, creating a\nfundamental gap between system capabilities and users' cognitive processes.\nBrain-Machine Interface (BMI) technologies now offer unprecedented potential to\nbridge this gap through direct measurement of previously inaccessible aspects\nof information-seeking behaviour. This perspective paper offers a broad\nexamination of the IR landscape, providing a comprehensive analysis of how BMI\ntechnology could transform IR systems, drawing from advances at the\nintersection of both neuroscience and IR research. We present our analysis\nthrough three identified fundamental vertices: (1) understanding the neural\ncorrelates of core IR concepts to advance theoretical models of search\nbehaviour, (2) enhancing existing IR systems through contextual integration of\nneurophysiological signals, and (3) developing proactive IR capabilities\nthrough direct neurophysiological measurement. For each vertex, we identify\nspecific research opportunities and propose concrete directions for developing\nBMI-enhanced IR systems. We conclude by examining critical technical and\nethical challenges in implementing these advances, providing a structured\nroadmap for future research at the intersection of neuroscience and IR.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T16:18:30Z"}
{"aid":"http://arxiv.org/abs/2504.10386v1","title":"Universal fault-tolerant logic with heterogeneous holographic codes","summary":"The study of holographic bulk-boundary dualities has led to the construction\nof novel quantum error correcting codes. Although these codes have shed new\nlight on conceptual aspects of these dualities, they have widely been believed\nto lack a crucial feature of practical quantum error correction: The ability to\nsupport universal fault-tolerant quantum logic. In this work, we introduce a\nnew class of holographic codes that realize this feature. These heterogeneous\nholographic codes are constructed by combining two seed codes in a tensor\nnetwork on an alternating hyperbolic tiling. We show how this construction\ngeneralizes previous strategies for fault tolerance in tree-type concatenated\ncodes, allowing one to implement non-Clifford gates fault-tolerantly on the\nholographic boundary. We also demonstrate that these codes allow for high\nerasure thresholds under a suitable heterogeneous combination of specific seed\ncodes. Compared to previous concatenated codes, heterogeneous holographic codes\nachieve large overhead savings in physical qubits, e.g., a $21.8\\%$ reduction\nfor a two-layer Steane/quantum Reed-Muller combination. Unlike standard\nconcatenated codes, we establish that the new codes can encode more than a\nsingle logical qubit per code block by applying ``black hole'' deformations\nwith tunable rate and distance, while possessing fully addressable, universal\nfault-tolerant gate sets. Therefore, our work strengthens the case for the\nutility of holographic quantum codes for practical quantum computing.","main_category":"quant-ph","categories":"quant-ph,hep-th","published":"2025-04-14T16:28:33Z"}
{"aid":"http://arxiv.org/abs/2504.10396v1","title":"Biquandles, quivers and virtual bridge indices","summary":"We investigate connections between biquandle colorings, quiver enhancements,\nand several notions of the bridge numbers $b_i(K)$ for virtual links, where\n$i=1,2$. We show that for any positive integers $m \\leq n$, there exists a\nvirtual link $K$ with $b_1(K) = m$ and $b_2(K) = n$, thereby answering a\nquestion posed by Nakanishi and Satoh. In some sense, this gap between the two\nformulations measures how far the knot is from being classical. We also use\nthese bridge number analyses to systematically construct families of links in\nwhich quiver invariants can distinguish between links that share the same\nbiquandle counting invariant.","main_category":"math.GT","categories":"math.GT","published":"2025-04-14T16:44:30Z"}
{"aid":"http://arxiv.org/abs/2504.10397v1","title":"Can LLMs Assist Expert Elicitation for Probabilistic Causal Modeling?","summary":"Objective: This study investigates the potential of Large Language Models\n(LLMs) as an alternative to human expert elicitation for extracting structured\ncausal knowledge and facilitating causal modeling in biometric and healthcare\napplications.\n  Material and Methods: LLM-generated causal structures, specifically Bayesian\nnetworks (BNs), were benchmarked against traditional statistical methods (e.g.,\nBayesian Information Criterion) using healthcare datasets. Validation\ntechniques included structural equation modeling (SEM) to verifying\nrelationships, and measures such as entropy, predictive accuracy, and\nrobustness to compare network structures.\n  Results and Discussion: LLM-generated BNs demonstrated lower entropy than\nexpert-elicited and statistically generated BNs, suggesting higher confidence\nand precision in predictions. However, limitations such as contextual\nconstraints, hallucinated dependencies, and potential biases inherited from\ntraining data require further investigation.\n  Conclusion: LLMs represent a novel frontier in expert elicitation for\nprobabilistic causal modeling, promising to improve transparency and reduce\nuncertainty in the decision-making using such models.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-14T16:45:52Z"}
{"aid":"http://arxiv.org/abs/2504.10400v1","title":"Towards Low-Latency Event-based Obstacle Avoidance on a FPGA-Drone","summary":"This work quantitatively evaluates the performance of event-based vision\nsystems (EVS) against conventional RGB-based models for action prediction in\ncollision avoidance on an FPGA accelerator. Our experiments demonstrate that\nthe EVS model achieves a significantly higher effective frame rate (1 kHz) and\nlower temporal (-20 ms) and spatial prediction errors (-20 mm) compared to the\nRGB-based model, particularly when tested on out-of-distribution data. The EVS\nmodel also exhibits superior robustness in selecting optimal evasion maneuvers.\nIn particular, in distinguishing between movement and stationary states, it\nachieves a 59 percentage point advantage in precision (78% vs. 19%) and a\nsubstantially higher F1 score (0.73 vs. 0.06), highlighting the susceptibility\nof the RGB model to overfitting. Further analysis in different combinations of\nspatial classes confirms the consistent performance of the EVS model in both\ntest data sets. Finally, we evaluated the system end-to-end and achieved a\nlatency of approximately 2.14 ms, with event aggregation (1 ms) and inference\non the processing unit (0.94 ms) accounting for the largest components. These\nresults underscore the advantages of event-based vision for real-time collision\navoidance and demonstrate its potential for deployment in resource-constrained\nenvironments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:51:10Z"}
{"aid":"http://arxiv.org/abs/2504.10420v1","title":"Role of Coulomb-nuclear breakup of 6,7Li projectiles with heavy deformed\n  232Th target","summary":"The significance of both Coulomb and nuclear couplings and their interference\neffects in the breakup processes of 6,7Li with a non-spherical nucleus 232Th\nhas been evaluated. The continuum discretized coupled channel(CDCC)\ncalculations are carried out in a nonstandard way, using short-range imaginary\npotentials for the fragment-target interaction at energies close to the Coulomb\nbarrier. The present calculations employing short-range imaginary potentials\nexhibit better agreement with the experimental elastic scattering angular\ndistributions than those using standard systematic value (0.78xWSPP ) used to\ndescribe elastic scattering. Including the excitation of the 232Th inelastic\nshows significant coupling effects on the elastic scattering below the barrier\nenergies compared to higher incident energies. Subsequently, the CDCC framework\nwas used to analyze the nuclear, Coulomb, and total breakup predictions\nseparately. The breakup cross sections for the 6Li+232Th system are greater\nthan those for the 7Li+232Th system across various energies. The present study\npredicts destructive Coulomb-nuclear interference in the breakup processes\ninvolving both 6Li and 7Li projectile nuclei with the deformed 232Th target.\nAdditionally, the breakup reaction cross-sections are compared with\nexperimentally measured fusion cross-sections near the barrier energies for\nboth 6,7Li+232Th systems.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-14T17:07:28Z"}
{"aid":"http://arxiv.org/abs/2504.10421v1","title":"Can We Edit LLMs for Long-Tail Biomedical Knowledge?","summary":"Knowledge editing has emerged as an effective approach for updating large\nlanguage models (LLMs) by modifying their internal knowledge. However, their\napplication to the biomedical domain faces unique challenges due to the\nlong-tailed distribution of biomedical knowledge, where rare and infrequent\ninformation is prevalent. In this paper, we conduct the first comprehensive\nstudy to investigate the effectiveness of knowledge editing methods for editing\nlong-tail biomedical knowledge. Our results indicate that, while existing\nediting methods can enhance LLMs' performance on long-tail biomedical\nknowledge, their performance on long-tail knowledge remains inferior to that on\nhigh-frequency popular knowledge, even after editing. Our further analysis\nreveals that long-tail biomedical knowledge contains a significant amount of\none-to-many knowledge, where one subject and relation link to multiple objects.\nThis high prevalence of one-to-many knowledge limits the effectiveness of\nknowledge editing in improving LLMs' understanding of long-tail biomedical\nknowledge, highlighting the need for tailored strategies to bridge this\nperformance gap.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T17:08:20Z"}
{"aid":"http://arxiv.org/abs/2504.10438v1","title":"Streaming Democratized: Ease Across the Latency Spectrum with Delayed\n  View Semantics and Snowflake Dynamic Tables","summary":"Streaming data pipelines remain challenging and expensive to build and\nmaintain, despite significant advancements in stronger consistency, event time\nsemantics, and SQL support over the last decade. Persistent obstacles continue\nto hinder usability, such as the need for manual incrementalization, semantic\ndiscrepancies across SQL implementations, and the lack of enterprise-grade\noperational features. While the rise of incremental view maintenance (IVM) as a\nway to integrate streaming with databases has been a huge step forward,\ntransaction isolation in the presence of IVM remains underspecified, leaving\nthe maintenance of application-level invariants as a painful exercise for the\nuser. Meanwhile, most streaming systems optimize for latencies of 100 ms to 3\nsec, whereas many practical use cases are well-served by latencies ranging from\nseconds to tens of minutes.\n  We present delayed view semantics (DVS), a conceptual foundation that bridges\nthe semantic gap between streaming and databases, and introduce Dynamic Tables,\nSnowflake's declarative streaming transformation primitive designed to\ndemocratize analytical stream processing. DVS formalizes the intuition that\nstream processing is primarily a technique to eagerly compute derived results\nasynchronously, while also addressing the need to reason about the resulting\nsystem end to end. Dynamic Tables then offer two key advantages: ease of use\nthrough DVS, enterprise-grade features, and simplicity; as well as scalable\ncost efficiency via IVM with an architecture designed for diverse latency\nrequirements.\n  We first develop extensions to transaction isolation that permit the\npreservation of invariants in streaming applications. We then detail the\nimplementation challenges of Dynamic Tables and our experience operating it at\nscale. Finally, we share insights into user adoption and discuss our vision for\nthe future of stream processing.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-14T17:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.10451v1","title":"Minimizing Functions of Age of Incorrect Information for Remote\n  Estimation","summary":"The age of incorrect information (AoII) process which keeps track of the time\nsince the source and monitor processes are in sync, has been extensively used\nin remote estimation problems. In this paper, we consider a push-based remote\nestimation system with a discrete-time Markov chain (DTMC) information source\ntransmitting status update packets towards the monitor once the AoII process\nexceeds a certain estimation-based threshold. In this paper, the time average\nof an arbitrary function of AoII is taken as the AoII cost, as opposed to using\nthe average AoII as the mismatch metric, whereas this function is also allowed\nto depend on the estimation value. In this very general setting, our goal is to\nminimize a weighted sum of AoII and transmission costs. For this purpose, we\nformulate a discrete-time semi-Markov decision process (SMDP) regarding the\nmulti-threshold status update policy. We propose a novel tool in discrete-time\ncalled 'dual-regime absorbing Markov chain' (DR-AMC) and its corresponding\nabsorption time distribution named as 'dual-regime phase-type' (DR-PH)\ndistribution, to obtain the characterizing parameters of the SMDP, which allows\nus to obtain the distribution of the AoII process for a given policy, and hence\nthe average of any function of AoII. The proposed method is validated with\nnumerical results by which we compare our proposed method against other\npolicies obtained by exhaustive-search, and also various benchmark policies.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T17:39:06Z"}
{"aid":"http://arxiv.org/abs/2504.10458v1","title":"GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI\n  Agents","summary":"Existing efforts in building Graphical User Interface (GUI) agents largely\nrely on the training paradigm of supervised fine-tuning on Large\nVision-Language Models (LVLMs). However, this approach not only demands\nextensive amounts of training data but also struggles to effectively understand\nGUI screenshots and generalize to unseen interfaces. The issue significantly\nlimits its application in real-world scenarios, especially for high-level\ntasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models\n(e.g., DeepSeek-R1), which efficiently enhances the problem-solving\ncapabilities of large language models in real-world settings, we propose \\name,\nthe first reinforcement learning framework designed to enhance the GUI\ncapabilities of LVLMs in high-level real-world task scenarios, through unified\naction space rule modeling. By leveraging a small amount of carefully curated\nhigh-quality data across multiple platforms (including Windows, Linux, MacOS,\nAndroid, and Web) and employing policy optimization algorithms such as Group\nRelative Policy Optimization (GRPO) to update the model, \\name achieves\nsuperior performance using only 0.02\\% of the data (3K vs. 13M) compared to\nprevious state-of-the-art methods like OS-Atlas across eight benchmarks\nspanning three different platforms (mobile, desktop, and web). These results\ndemonstrate the immense potential of reinforcement learning based on unified\naction space rule modeling in improving the execution capabilities of LVLMs for\nreal-world GUI agent tasks.","main_category":"cs.CV","categories":"cs.CV,cs.CL,cs.HC","published":"2025-04-14T17:45:54Z"}
{"aid":"http://arxiv.org/abs/2504.10466v1","title":"Art3D: Training-Free 3D Generation from Flat-Colored Illustration","summary":"Large-scale pre-trained image-to-3D generative models have exhibited\nremarkable capabilities in diverse shape generations. However, most of them\nstruggle to synthesize plausible 3D assets when the reference image is\nflat-colored like hand drawings due to the lack of 3D illusion, which are often\nthe most user-friendly input modalities in art content creation. To this end,\nwe propose Art3D, a training-free method that can lift flat-colored 2D designs\ninto 3D. By leveraging structural and semantic features with pre- trained 2D\nimage generation models and a VLM-based realism evaluation, Art3D successfully\nenhances the three-dimensional illusion in reference images, thus simplifying\nthe process of generating 3D from 2D, and proves adaptable to a wide range of\npainting styles. To benchmark the generalization performance of existing\nimage-to-3D models on flat-colored images without 3D feeling, we collect a new\ndataset, Flat-2D, with over 100 samples. Experimental results demonstrate the\nperformance and robustness of Art3D, exhibiting superior generalizable capacity\nand promising practical applicability. Our source code and dataset will be\npublicly available on our project page: https://joy-jy11.github.io/ .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:53:10Z"}
{"aid":"http://arxiv.org/abs/2504.10468v1","title":"Quantum Barcodes: Persistent Homology for Quantum Phase Transitions","summary":"We introduce \"quantum barcodes,\" a theoretical framework that applies\npersistent homology to classify topological phases in quantum many-body\nsystems. By mapping quantum states to classical data points through strategic\nobservable measurements, we create a \"quantum state cloud\" analyzable via\npersistent homology techniques. Our framework establishes that quantum systems\nin the same topological phase exhibit consistent barcode representations with\nshared persistent homology groups over characteristic intervals. We prove that\nquantum phase transitions manifest as significant changes in these persistent\nhomology features, detectable through discontinuities in the persistent Dirac\noperator spectrum. Using the SSH model as a demonstrative example, we show how\nour approach successfully identifies the topological phase transition and\ndistinguishes between trivial and topological phases. While primarily developed\nfor symmetry-protected topological phases, our framework provides a\nmathematical connection between persistent homology and quantum topology,\noffering new methods for phase classification that complement traditional\ninvariant-based approaches.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.AT,math.MP","published":"2025-04-14T17:53:21Z"}
{"aid":"http://arxiv.org/abs/2504.10472v1","title":"False and genuine decoherence in the early universe: a local observer\n  and time-averaged observables","summary":"We study quantum decoherence of curvature perturbations at superhorizon\nscales caused by the gravitational nonlinearities. We show that cubic\ngravitational couplings, constrained by the spatial diffeomorphism invariance,\nlead to infrared (IR) and ultraviolet (UV) divergences in the decoherence rate\nat one loop. These divergences arise from fluctuations of deep IR modes which\nlook like a background mode for a local observer and violent zero-point\nfluctuations in the deep UV, respectively. We argue that these divergences are\nunobservable, as they vanish when considering proper observables. We consider\ncorrelators defined using the geodesic distance for IR divergences and\ntime-averaged correlators for UV divergences. To account for these observer's\nperspectives, we propose to consider an effective quantum state, defined in\nterms of actual observables, as a more appropriate probe of the quantum\ncoherence of the system measured by an observer. We then evaluate the finite\ndecoherence rate induced by superhorizon environment during inflation and at\nlate universe.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc,hep-ph","published":"2025-04-14T17:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.10485v1","title":"Decoupled Diffusion Sparks Adaptive Scene Generation","summary":"Controllable scene generation could reduce the cost of diverse data\ncollection substantially for autonomous driving. Prior works formulate the\ntraffic layout generation as predictive progress, either by denoising entire\nsequences at once or by iteratively predicting the next frame. However, full\nsequence denoising hinders online reaction, while the latter's short-sighted\nnext-frame prediction lacks precise goal-state guidance. Further, the learned\nmodel struggles to generate complex or challenging scenarios due to a large\nnumber of safe and ordinal driving behaviors from open datasets. To overcome\nthese, we introduce Nexus, a decoupled scene generation framework that improves\nreactivity and goal conditioning by simulating both ordinal and challenging\nscenarios from fine-grained tokens with independent noise states. At the core\nof the decoupled pipeline is the integration of a partial noise-masking\ntraining strategy and a noise-aware schedule that ensures timely environmental\nupdates throughout the denoising process. To complement challenging scenario\ngeneration, we collect a dataset consisting of complex corner cases. It covers\n540 hours of simulated data, including high-risk interactions such as cut-in,\nsudden braking, and collision. Nexus achieves superior generation realism while\npreserving reactivity and goal orientation, with a 40% reduction in\ndisplacement error. We further demonstrate that Nexus improves closed-loop\nplanning by 20% through data augmentation and showcase its capability in\nsafety-critical data generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.10826v1","title":"SteerMusic: Enhanced Musical Consistency for Zero-shot Text-Guided and\n  Personalized Music Editing","summary":"Music editing is an important step in music production, which has broad\napplications, including game development and film production. Most existing\nzero-shot text-guided methods rely on pretrained diffusion models by involving\nforward-backward diffusion processes for editing. However, these methods often\nstruggle to maintain the music content consistency. Additionally, text\ninstructions alone usually fail to accurately describe the desired music. In\nthis paper, we propose two music editing methods that enhance the consistency\nbetween the original and edited music by leveraging score distillation. The\nfirst method, SteerMusic, is a coarse-grained zero-shot editing approach using\ndelta denoising score. The second method, SteerMusic+, enables fine-grained\npersonalized music editing by manipulating a concept token that represents a\nuser-defined musical style. SteerMusic+ allows for the editing of music into\nany user-defined musical styles that cannot be achieved by the text\ninstructions alone. Experimental results show that our methods outperform\nexisting approaches in preserving both music content consistency and editing\nfidelity. User studies further validate that our methods achieve superior music\nediting quality. Audio examples are available on https://steermusic.pages.dev/.","main_category":"cs.SD","categories":"cs.SD,cs.MM,eess.AS","published":"2025-04-15T03:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.10830v1","title":"Radiation Footprint Control in Cell-Free Cooperative ISAC: Optimal Joint\n  BS Activation and Beamforming Coordination","summary":"Coordinated beamforming across distributed base stations (BSs) in cell-free\narchitectures can efficiently support integrated sensing and communication\n(ISAC) users by improving resource sharing and reducing conflicts in the\nspatial domain. However, coordinating numerous BSs within the ISAC network\nposes risks of generating substantial interference for other networks sharing\nthe spectrum, while also increasing operational costs from power consumption\nand signaling overhead. Therefore, in this paper, we propose an\ninterference-suppressed and cost-optimized cell-free ISAC network by\nopportunistically and cooperatively orchestrating distributed radio resources\nto address competing sensing and communication (S\\&C) demands. Specifically, we\nconceive a radiation footprint control mechanism that autonomously suppresses\ninterference across the entire signal propagation space to safeguard other\nnetworks without exchanging signaling. Then, we propose joint BS activation and\nbeamforming coordination to dynamically activate appropriate BSs and\norchestrate their spatial beams for service provisioning. Building upon this\nframework, we formulate a cost-efficient utility maximization problem that\nconsiders individual S\\&C demands and location-dependent radiation footprint\nconstraints. Since this results in a non-convex optimization problem, we\ndevelop a monotonic optimization embedded branch-and-bound (MO-BRB) algorithm\nto find the optimal solution. Additionally, we apply a low-complexity iterative\nmethod to obtain near-optimal solutions. Finally, simulation results validate\nthe effectiveness of the proposed algorithms.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-15T03:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.10837v1","title":"Elastocaloric signature of the excitonic instability in Ta$_2$NiSe$_5$","summary":"On cooling through a temperature $T_S$ of around 324 K, Ta$_2$NiSe$_5$\nundergoes a transition from a semimetallic state to one with a gapped\nelectronic spectrum which is suspected to be an excitonic insulator. However,\nat this transition the structure also changes, from orthorhombic to monoclinic,\nleaving open the question of whether it is driven primarily by excitonic\nordering or by a lattice instability. A lattice instability of this symmetry\nwould correspond to softening of a B$_{2g}$ optical or acoustic phonon mode.\nHere, we report that elastocaloric measurements of Ta$_2$NiSe$_5$ with induced\nB$_{2g}$ strain reveal a thermodynamic susceptibility described by a\nCurie-Weiss law with a Curie temperature $T^*$ of 298 K. The fact that $T^*$ is\nclose to $T_S$ rules out the possibility that the B$_{2g}$ acoustic mode is\nresponsible for the transition. Since prior Raman measurements have shown\nminimal softening of the B$_{2g}$ optical mode as well, our finding strengthens\nthe case that the transition is largely excitonic in nature. Our work\nunderscores the potential of using strain as a tool for separating electronic\nand lattice contributions in phase transitions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T03:38:21Z"}
{"aid":"http://arxiv.org/abs/2504.10841v1","title":"Some four-dimensional orthogonal invariants","summary":"Let $p$ be an odd prime and $\\mathbb{F}_p$ be the prime field of order $p$.\nConsider a $2$-dimensional orthogonal group $G$ over $\\mathbb{F}_p$ acting on\nthe standard representation $V$ and the dual space $V^*$. We compute the\ninvariant ring $\\mathbb{F}_p[V\\oplus V^*]^G$ via explicitly exhibiting a\nminimal generating set. Our method finds an application of $s$-invariants\nappeared in covariant theory of finite groups.","main_category":"math.AC","categories":"math.AC","published":"2025-04-15T03:59:00Z"}
{"aid":"http://arxiv.org/abs/2504.10861v1","title":"Ai2 Scholar QA: Organized Literature Synthesis with Attribution","summary":"Retrieval-augmented generation is increasingly effective in answering\nscientific questions from literature, but many state-of-the-art systems are\nexpensive and closed-source. We introduce Ai2 Scholar QA, a free online\nscientific question answering application. To facilitate research, we make our\nentire pipeline public: as a customizable open-source Python package and\ninteractive web app, along with paper indexes accessible through public APIs\nand downloadable datasets. We describe our system in detail and present\nexperiments analyzing its key design decisions. In an evaluation on a recent\nscientific QA benchmark, we find that Ai2 Scholar QA outperforms competing\nsystems.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T04:48:18Z"}
{"aid":"http://arxiv.org/abs/2504.10871v1","title":"DAAF:Degradation-Aware Adaptive Fusion Framework for Robust Infrared and\n  Visible Images Fusion","summary":"Existing infrared and visible image fusion(IVIF) algorithms often prioritize\nhigh-quality images, neglecting image degradation such as low light and noise,\nwhich limits the practical potential. This paper propose Degradation-Aware\nAdaptive image Fusion (DAAF), which achieves unified modeling of adaptive\ndegradation optimization and image fusion. Specifically, DAAF comprises an\nauxiliary Adaptive Degradation Optimization Network (ADON) and a Feature\nInteractive Local-Global Fusion (FILGF) Network. Firstly, ADON includes\ninfrared and visible-light branches. Within the infrared branch,\nfrequency-domain feature decomposition and extraction are employed to isolate\nGaussian and stripe noise. In the visible-light branch, Retinex decomposition\nis applied to extract illumination and reflectance components, enabling\ncomplementary enhancement of detail and illumination distribution.\nSubsequently, FILGF performs interactive multi-scale local-global feature\nfusion. Local feature fusion consists of intra-inter model feature complement,\nwhile global feature fusion is achieved through a interactive cross-model\nattention. Extensive experiments have shown that DAAF outperforms current IVIF\nalgorithms in normal and complex degradation scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T05:02:49Z"}
{"aid":"http://arxiv.org/abs/2504.10875v1","title":"Emergence of Creativity and Individuality in Music: Insights from\n  Brain's Statistical Learning and its Embodied Mechanisms","summary":"Music is a universal feature of human culture, linked to embodied cognitive\nfunctions that drive learning, action, and the emergence of creativity and\nindividuality. Evidence highlights the critical role of statistical learning an\nimplicit cognitive process of the brain in musical creativity and\nindividuality. Despite its significance, the precise neural and computational\nmechanisms underpinning these dynamic and embodied cognitive processes re-main\npoorly understood. This paper discusses how individuality and creativity emerge\nwithin the framework of the brain's statistical learning, drawing on a series\nof neural and computational studies. This work offers perspectives on the\nmechanisms driving the heterogeneous nature of statistical learning abilities\nand embodied mechanisms and provides a framework to explain the paradoxical\nphenomenon where individuals with specific cognitive traits that limit certain\nperceptual abilities excel in creative domains.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-15T05:09:07Z"}
{"aid":"http://arxiv.org/abs/2504.10877v1","title":"Weather-Aware Object Detection Transformer for Domain Adaptation","summary":"RT-DETRs have shown strong performance across various computer vision tasks\nbut are known to degrade under challenging weather conditions such as fog. In\nthis work, we investigate three novel approaches to enhance RT-DETR robustness\nin foggy environments: (1) Domain Adaptation via Perceptual Loss, which\ndistills domain-invariant features from a teacher network to a student using\nperceptual supervision; (2) Weather Adaptive Attention, which augments the\nattention mechanism with fog-sensitive scaling by introducing an auxiliary\nfoggy image stream; and (3) Weather Fusion Encoder, which integrates a\ndual-stream encoder architecture that fuses clear and foggy image features via\nmulti-head self and cross-attention. Despite the architectural innovations,\nnone of the proposed methods consistently outperform the baseline RT-DETR. We\nanalyze the limitations and potential causes, offering insights for future\nresearch in weather-aware object detection.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T05:11:18Z"}
{"aid":"http://arxiv.org/abs/2504.10892v1","title":"Multiple points of view: The simultaneous crossing number for knots with\n  doubly transvergent diagrams","summary":"The simultaneous crossing number is a new knot invariant which is defined for\nstrongly invertible knots having diagrams with two orthogonal transvergent axes\nof strong inversions. Because the composition of the two inversions gives a\ncyclic period of order 2 with an axis orthogonal to the two axes of strong\ninversion, knot diagrams with this property have three characteristic\northogonal directions. We define the simultaneous crossing number,\n$\\operatorname{sim}(K)$, as the minimum of the sum of the numbers of crossings\nof projections in the 3 directions, where the minimum is taken over all\nembeddings of $K$ satisfying the symmetry condition. Dividing the simultaneous\ncrossing number by the usual crossing number, $\\operatorname{cr}(K)$, of a knot\ngives a number $\\ge 3$, because each of the 3 diagrams is a knot diagram of the\nknot in question. We show that $\\liminf_{\\operatorname{cr}(K) \\to \\infty}\n\\operatorname{sim}(K)/\\operatorname{cr}(K) \\le 8$, when the minimum over all\nknots and the limit over increasing crossing numbers is considered.","main_category":"math.GT","categories":"math.GT","published":"2025-04-15T06:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.10900v1","title":"Bridging Distribution Gaps in Time Series Foundation Model Pretraining\n  with Prototype-Guided Normalization","summary":"Foundation models have achieved remarkable success across diverse\nmachine-learning domains through large-scale pretraining on large, diverse\ndatasets. However, pretraining on such datasets introduces significant\nchallenges due to substantial mismatches in data distributions, a problem\nparticularly pronounced with time series data. In this paper, we tackle this\nissue by proposing a domain-aware adaptive normalization strategy within the\nTransformer architecture. Specifically, we replace the traditional LayerNorm\nwith a prototype-guided dynamic normalization mechanism (ProtoNorm), where\nlearned prototypes encapsulate distinct data distributions, and\nsample-to-prototype affinity determines the appropriate normalization layer.\nThis mechanism effectively captures the heterogeneity of time series\ncharacteristics, aligning pretrained representations with downstream tasks.\nThrough comprehensive empirical evaluation, we demonstrate that our method\nsignificantly outperforms conventional pretraining techniques across both\nclassification and forecasting tasks, while effectively mitigating the adverse\neffects of distribution shifts during pretraining. Incorporating ProtoNorm is\nas simple as replacing a single line of code. Extensive experiments on diverse\nreal-world time series benchmarks validate the robustness and generalizability\nof our approach, advancing the development of more versatile time series\nfoundation models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T06:23:00Z"}
{"aid":"http://arxiv.org/abs/2504.10904v1","title":"A Pseudorandom Generator for Functions of Low-Degree Polynomial\n  Threshold Functions","summary":"Developing explicit pseudorandom generators (PRGs) for prominent categories\nof Boolean functions is a key focus in computational complexity theory. In this\npaper, we investigate the PRGs against the functions of degree-$d$ polynomial\nthreshold functions (PTFs) over Gaussian space. Our main result is an explicit\nconstruction of PRG with seed length $\\mathrm{poly}(k,d,1/\\epsilon)\\cdot\\log n$\nthat can fool any function of $k$ degree-$d$ PTFs with probability at least\n$1-\\varepsilon$. More specifically, we show that the summation of $L$\nindependent $R$-moment-matching Gaussian vectors $\\epsilon$-fools functions of\n$k$ degree-$d$ PTFs, where $L=\\mathrm{poly}( k, d, \\frac{1}{\\epsilon})$ and $R\n= O({\\log \\frac{kd}{\\epsilon}})$. The PRG is then obtained by applying an\nappropriate discretization to Gaussian vectors with bounded independence.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-15T06:28:56Z"}
{"aid":"http://arxiv.org/abs/2504.10912v1","title":"Superconducting quantum oscillations and anomalous negative\n  magnetoresistance in a honeycomb nanopatterned oxide interface superconductor","summary":"The extremely low superfluid density and unprecedented tunability of oxide\ninterface superconductors provide an ideal platform for studying fluctuations\nin two-dimensional superconductors. In this work, we have fabricated a\nLaAlO3/KTaO3 interface superconductor patterned with a nanohoneycomb array of\ninsulating islands. Little-Parks-like magnetoresistance oscillations have been\nobserved, which are dictated by the superconducting flux quantum h/2e.\nMoreover, an anomalous negative magnetoresistance (ANMR) appears under a weak\nmagnetic field, suggesting magnetic-field-enhanced superconductivity. By\nexamining their dependences on temperature, measurement current, and electrical\ngating, we conclude that both phenomena are associated with superconducting\norder parameter: The h/2e oscillations provide direct evidence of Cooper pair\ntransport; the ANMR is interpreted as a consequence of multiple connected\nnarrow superconducting paths with strong fluctuations.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-15T06:49:00Z"}
{"aid":"http://arxiv.org/abs/2504.10937v1","title":"Finding Locally Densest Subgraphs: Convex Programming with Edge and\n  Triangle Density","summary":"Finding the densest subgraph (DS) from a graph is a fundamental problem in\ngraph databases. The DS obtained, which reveals closely related entities, has\nbeen found to be useful in various application domains such as e-commerce,\nsocial science, and biology. However, in a big graph that contains billions of\nedges, it is desirable to find more than one subgraph cluster that is not\nnecessarily the densest, yet they reveal closely related vertices. In this\npaper, we study the locally densest subgraph (LDS), a recently proposed variant\nof DS. An LDS is a subgraph which is the densest among the ``local neighbors''.\nGiven a graph $G$, a number of LDSs can be returned, which reflect different\ndense regions of $G$ and thus give more information than DS. The existing LDS\nsolution suffers from low efficiency. We thus develop a\nconvex-programming-based solution that enables powerful pruning. We also extend\nour algorithm to triangle-based density to solve LTDS problem. Based on current\nalgorithms, we propose a unified framework for the LDS and LTDS problems.\nExtensive experiments on thirteen real large graph datasets show that our\nproposed algorithm is up to four orders of magnitude faster than the\nstate-of-the-art.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T07:32:35Z"}
{"aid":"http://arxiv.org/abs/2504.10952v1","title":"A Signal Matrix-Based Local Flaw Detection Framework for Steel Wire\n  Ropes Using Convolutional Neural Networks","summary":"Steel wire ropes (SWRs) are critical load-bearing components in industrial\napplications, yet their structural integrity is often compromised by local\nflaws (LFs). Magnetic Flux Leakage (MFL) is a widely used non-destructive\ntesting method that detects defects by measuring perturbations in magnetic\nfields. Traditional MFL detection methods suffer from critical limitations:\none-dimensional approaches fail to capture spatial relationships across sensor\nchannels, while multi-dimensional image-based techniques introduce\ninterpolation artifacts and computational inefficiencies. This paper proposes a\nnovel detection framework based on signal matrices, directly processing raw\nmulti-channel MFL signals using a specialized Convolutional Neural Network for\nsignal matrix as input (SM-CNN). The architecture incorporates stripe pooling\nto preserve channel-wise features and symmetric padding to improve boundary\ndefect detection. Our model achieves state-of-the-art performance with 98.74%\naccuracy and 97.85% recall. Additionally, it demonstrates exceptional\ncomputational efficiency, processing at 87.72 frames per second (FPS) with a\nlow inference latency of 2.6ms and preprocessing time of 8.8ms. With only 1.48\nmillion parameters, this lightweight design supports real-time processing,\nestablishing a new benchmark for SWR inspection in industrial settings.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T07:59:04Z"}
{"aid":"http://arxiv.org/abs/2504.10961v1","title":"Evaluating Trust in AI, Human, and Co-produced Feedback Among\n  Undergraduate Students","summary":"As generative AI transforms educational feedback practices, understanding\nstudents' perceptions of different feedback providers becomes crucial for\neffective implementation. This study addresses a critical gap by comparing\nundergraduate students' trust in AI-generated, human-created, and human-AI\nco-produced feedback, informing how institutions can adapt feedback practices\nin this new era. Through a within-subject experiment with 91 participants, we\ninvestigated factors predicting students' ability to distinguish between\nfeedback types, perception of feedback quality, and potential biases to AI\ninvolvement. Findings revealed that students generally preferred AI and\nco-produced feedback over human feedback in terms of perceived usefulness and\nobjectivity. Only AI feedback suffered a decline in perceived genuineness when\nfeedback sources were revealed, while co-produced feedback maintained its\npositive perception. Educational AI experience improved students' ability to\nidentify AI feedback and increased their trust in all feedback types, while\ngeneral AI experience decreased perceived usefulness and credibility. Male\nstudents consistently rated all feedback types as less valuable than their\nfemale and non-binary counterparts. These insights inform evidence-based\nguidelines for integrating AI into higher education feedback systems while\naddressing trust concerns and fostering AI literacy among students.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-04-15T08:06:36Z"}
{"aid":"http://arxiv.org/abs/2504.10973v1","title":"Early Detection of Cognitive Impairment in Elderly using a Passive\n  FPVS-EEG BCI and Machine Learning -- Extended Version","summary":"Early dementia diagnosis requires biomarkers sensitive to both structural and\nfunctional brain changes. While structural neuroimaging biomarkers have\nprogressed significantly, objective functional biomarkers of early cognitive\ndecline remain a critical unmet need. Current cognitive assessments often rely\non behavioral responses, making them susceptible to factors like effort,\npractice effects, and educational background, thereby hindering early and\naccurate detection. This work introduces a novel approach, leveraging a\nlightweight convolutional neural network (CNN) to infer cognitive impairment\nlevels directly from electroencephalography (EEG) data. Critically, this method\nemploys a passive fast periodic visual stimulation (FPVS) paradigm, eliminating\nthe need for explicit behavioral responses or task comprehension from the\nparticipant. This passive approach provides an objective measure of working\nmemory function, independent of confounding factors inherent in active\ncognitive tasks, and offers a promising new avenue for early and unbiased\ndetection of cognitive decline.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.HC,cs.LG,J.3","published":"2025-04-15T08:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.10987v1","title":"Leveraging Vertical Public-Private Split for Improved Synthetic Data\n  Generation","summary":"Differentially Private Synthetic Data Generation (DP-SDG) is a key enabler of\nprivate and secure tabular-data sharing, producing artificial data that carries\nthrough the underlying statistical properties of the input data. This typically\ninvolves adding carefully calibrated statistical noise to guarantee individual\nprivacy, at the cost of synthetic data quality. Recent literature has explored\nscenarios where a small amount of public data is used to help enhance the\nquality of synthetic data. These methods study a horizontal public-private\npartitioning which assumes access to a small number of public rows that can be\nused for model initialization, providing a small utility gain. However,\nrealistic datasets often naturally consist of public and private attributes,\nmaking a vertical public-private partitioning relevant for practical synthetic\ndata deployments. We propose a novel framework that adapts horizontal\npublic-assisted methods into the vertical setting. We compare this framework\nagainst our alternative approach that uses conditional generation, highlighting\ninitial limitations of public-data assisted methods and proposing future\nresearch directions to address these challenges.","main_category":"cs.LG","categories":"cs.LG,cs.CR","published":"2025-04-15T08:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.10994v1","title":"Near-room-temperature zero-dimensional polariton lasers with sub-10 GHz\n  linewidths","summary":"Narrow and brilliant spectral lines are essential assets for high-resolution\nspectroscopy as well as for precision sensing and optomechanics. In\nsemiconductor structures and, in particular, in the well-established (Al,Ga)As\nmaterial system, strong emission lines with nanosecond coherence times can be\nprovided by the opto-electronic resonances of microcavity exciton-polariton\ncondensates. The temporal coherence of these resonances, however, normally\nrapidly deteriorates as the temperature increases beyond a few tens of kelvins\ndue to exciton dissociation. Here, we demonstrate that the temperature\nstability of polariton condensates in (Al,Ga)As can be significantly improved\nby confinement within micrometer-sized intracavity traps. We show that trapped\ncondensates can survive up to ~200 K while maintaining a light-matter character\nwith decoherence rates below 10 GHz (i.e., $< 40 {\\mu}$eV linewidths). These\nlinewidths are by an order of magnitude smaller than those so far reported for\nother solid-state systems at these temperatures. Confinement thus provides a\npathway towards room-temperature polariton condensation using the\nwell-established (Al,Ga)As material system with prospects for application in\nscalable on-chip photonic devices for optical processing, sensing, and\ncomputing.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cond-mat.quant-gas,physics.optics","published":"2025-04-15T09:11:45Z"}
{"aid":"http://arxiv.org/abs/2504.11004v1","title":"Dynamic Compressing Prompts for Efficient Inference of Large Language\n  Models","summary":"Large Language Models (LLMs) have shown outstanding performance across a\nvariety of tasks, partly due to advanced prompting techniques. However, these\ntechniques often require lengthy prompts, which increase computational costs\nand can hinder performance because of the limited context windows of LLMs.\nWhile prompt compression is a straightforward solution, existing methods\nconfront the challenges of retaining essential information, adapting to context\nchanges, and remaining effective across different tasks. To tackle these\nissues, we propose a task-agnostic method called Dynamic Compressing Prompts\n(LLM-DCP). Our method reduces the number of prompt tokens while aiming to\npreserve the performance as much as possible. We model prompt compression as a\nMarkov Decision Process (MDP), enabling the DCP-Agent to sequentially remove\nredundant tokens by adapting to dynamic contexts and retaining crucial content.\nWe develop a reward function for training the DCP-Agent that balances the\ncompression rate, the quality of the LLM output, and the retention of key\ninformation. This allows for prompt token reduction without needing an external\nblack-box LLM. Inspired by the progressive difficulty adjustment in curriculum\nlearning, we introduce a Hierarchical Prompt Compression (HPC) training\nstrategy that gradually increases the compression difficulty, enabling the\nDCP-Agent to learn an effective compression method that maintains information\nintegrity. Experiments demonstrate that our method outperforms state-of-the-art\ntechniques, especially at higher compression rates. The code for our approach\nwill be available at https://github.com/Fhujinwu/DCP.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T09:20:45Z"}
{"aid":"http://arxiv.org/abs/2504.11026v1","title":"A PyTorch-Compatible Spike Encoding Framework for Energy-Efficient\n  Neuromorphic Applications","summary":"Spiking Neural Networks (SNNs) offer promising energy efficiency advantages,\nparticularly when processing sparse spike trains. However, their\nincompatibility with traditional datasets, which consist of batches of input\nvectors rather than spike trains, necessitates the development of efficient\nencoding methods. This paper introduces a novel, open-source PyTorch-compatible\nPython framework for spike encoding, designed for neuromorphic applications in\nmachine learning and reinforcement learning. The framework supports a range of\nencoding algorithms, including Leaky Integrate-and-Fire (LIF), Step Forward\n(SF), Pulse Width Modulation (PWM), and Ben's Spiker Algorithm (BSA), as well\nas specialized encoding strategies covering population coding and reinforcement\nlearning scenarios. Furthermore, we investigate the performance trade-offs of\neach method on embedded hardware using C/C++ implementations, considering\nenergy consumption, computation time, spike sparsity, and reconstruction\naccuracy. Our findings indicate that SF typically achieves the lowest\nreconstruction error and offers the highest energy efficiency and fastest\nencoding speed, achieving the second-best spike sparsity. At the same time,\nother methods demonstrate particular strengths depending on the signal\ncharacteristics. This framework and the accompanying empirical analysis provide\nvaluable resources for selecting optimal encoding strategies for\nenergy-efficient SNN applications.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T09:50:03Z"}
{"aid":"http://arxiv.org/abs/2504.11050v1","title":"Leveraging LLMs and attention-mechanism for automatic annotation of\n  historical maps","summary":"Historical maps are essential resources that provide insights into the\ngeographical landscapes of the past. They serve as valuable tools for\nresearchers across disciplines such as history, geography, and urban studies,\nfacilitating the reconstruction of historical environments and the analysis of\nspatial transformations over time. However, when constrained to analogue or\nscanned formats, their interpretation is limited to humans and therefore not\nscalable. Recent advancements in machine learning, particularly in computer\nvision and large language models (LLMs), have opened new avenues for automating\nthe recognition and classification of features and objects in historical maps.\nIn this paper, we propose a novel distillation method that leverages LLMs and\nattention mechanisms for the automatic annotation of historical maps. LLMs are\nemployed to generate coarse classification labels for low-resolution historical\nimage patches, while attention mechanisms are utilized to refine these labels\nto higher resolutions. Experimental results demonstrate that the refined labels\nachieve a high recall of more than 90%. Additionally, the intersection over\nunion (IoU) scores--84.2% for Wood and 72.0% for Settlement--along with\nprecision scores of 87.1% and 79.5%, respectively, indicate that most labels\nare well-aligned with ground-truth annotations. Notably, these results were\nachieved without the use of fine-grained manual labels during training,\nunderscoring the potential of our approach for efficient and scalable\nhistorical map analysis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T10:34:23Z"}
{"aid":"http://arxiv.org/abs/2504.11055v1","title":"Crane: Context-Guided Prompt Learning and Attention Refinement for\n  Zero-Shot Anomaly Detections","summary":"Anomaly Detection (AD) involves identifying deviations from normal data\ndistributions and is critical in fields such as medical diagnostics and\nindustrial defect detection. Traditional AD methods typically require the\navailability of normal training samples; however, this assumption is not always\nfeasible, as collecting such data can be impractical. Additionally, these\nmethods often struggle to generalize across different domains. Recent\nadvancements, such as AnomalyCLIP and AdaCLIP, utilize the zero-shot\ngeneralization capabilities of CLIP but still face a performance gap between\nimage-level and pixel-level anomaly detection. To address this gap, we propose\na novel approach that conditions the prompts of the text encoder based on image\ncontext extracted from the vision encoder. Also, to capture fine-grained\nvariations more effectively, we have modified the CLIP vision encoder and\naltered the extraction of dense features. These changes ensure that the\nfeatures retain richer spatial and structural information for both normal and\nanomalous prompts. Our method achieves state-of-the-art performance, improving\nperformance by 2% to 29% across different metrics on 14 datasets. This\ndemonstrates its effectiveness in both image-level and pixel-level anomaly\ndetection.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T10:42:25Z"}
{"aid":"http://arxiv.org/abs/2504.11057v1","title":"Electrically tunable nonrigid moire exciton polariton supersolids at\n  room temperature","summary":"A supersolid is a macroscopic quantum state which sustains superfluid and\ncrystallizing structure together after breaking the U(1) symmetry and\ntranslational symmetry. On the other hand, a moire pattern can form by\nsuperimposing two periodic structures along a particular direction. Up to now,\nsupersolids and moire states are disconnected from each other. In this work we\nshow that exciton polariton supersolids can form moire states in a double\ndegenerate parametric scattering process which creates two constituted\nsupersolids with different periods in a liquid crystal microcavity. In\naddition, we demonstrate the nonrigidity of the moire exciton polariton\nsupersolids by electrically tuning the wavevector and period of one supersolid\ncomponent with another one being fixed. Our work finds a simple way to link\nmoire states and supersolids, which offers to study nontrivial physics emerging\nfrom the combination of moire lattices and supersolids which can be\nelectrically tuned at room temperature.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T10:44:29Z"}
{"aid":"http://arxiv.org/abs/2504.11058v1","title":"Modeling zero-inflated precipitation extremes","summary":"Accurate modeling of daily rainfall, encompassing both dry and wet days as\nwell as extreme precipitation events, is critical for robust hydrological and\nclimatological analyses. This study proposes a zero-inflated extended\ngeneralized Pareto distribution model that unifies the modeling of dry days,\nlow, moderate, and extreme rainfall within a single framework. Unlike\ntraditional approaches that rely on prespecified threshold selection to\nidentify extremes, our proposed model captures tail behavior intrinsically\nthrough a tail index that aligns with the generalized Pareto distribution. The\nmodel also accommodates covariate effects via generalized additive modeling,\nallowing for the representation of complex climatic variability. The current\nimplementation is limited to a univariate setting, modeling daily rainfall\nindependently of covariates. Model estimation is carried out using both maximum\nlikelihood and Bayesian approaches. Simulation studies and empirical\napplications demonstrate the model flexibility in capturing zero inflation and\nheavy-tailed behavior characteristics of daily rainfall distributions.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-15T10:45:09Z"}
{"aid":"http://arxiv.org/abs/2504.11075v1","title":"Emergence of Goal-Directed Behaviors via Active Inference with\n  Self-Prior","summary":"Infants often exhibit goal-directed behaviors, such as reaching for a sensory\nstimulus, even when no external reward criterion is provided. These\nintrinsically motivated behaviors facilitate spontaneous exploration and\nlearning of the body and environment during early developmental stages.\nAlthough computational modeling can offer insight into the mechanisms\nunderlying such behaviors, many existing studies on intrinsic motivation focus\nprimarily on how exploration contributes to acquiring external rewards. In this\npaper, we propose a novel density model for an agent's own multimodal sensory\nexperiences, called the \"self-prior,\" and investigate whether it can\nautonomously induce goal-directed behavior. Integrated within an active\ninference framework based on the free energy principle, the self-prior\ngenerates behavioral references purely from an intrinsic process that minimizes\nmismatches between average past sensory experiences and current observations.\nThis mechanism is also analogous to the acquisition and utilization of a body\nschema through continuous interaction with the environment. We examine this\napproach in a simulated environment and confirm that the agent spontaneously\nreaches toward a tactile stimulus. Our study implements intrinsically motivated\nbehavior shaped by the agent's own sensory experiences, demonstrating the\nspontaneous emergence of intentional behavior during early development.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-15T11:16:27Z"}
{"aid":"http://arxiv.org/abs/2504.11077v1","title":"Lorentzian homogeneous Ricci-flat metrics on almost abelian Lie groups","summary":"We study Lorentzian homogeneous metrics on almost abelian Lie groups of\ndimensions larger than three. An almost abelian Lie group is a Lie group whose\nLie algebra has a codimension one abelian ideal. Ricci-flat and non-flat\nconditions on the Lie algebra are derived. In particular, we generalize the\nfour-dimensional Petrov solution to arbitrarily higher dimensions.","main_category":"math.DG","categories":"math.DG,gr-qc,hep-th","published":"2025-04-15T11:21:39Z"}
{"aid":"http://arxiv.org/abs/2504.11103v1","title":"FCC feasibility studies: Impact of tracker- and calorimeter-detector\n  performance on jet flavor identification and Higgs physics analyses","summary":"The extensive and ambitious physics program planned at the Future Circular\nCollider for electrons and positrons (FCC-ee) imposes strict constraints on\ndetector performance. This work investigates how different detector properties\nimpact jet flavor identification and their subsequent effects on high-profile\nphysics analyses. Using Higgs boson coupling measurements and searches for\ninvisible Higgs decays as benchmarks, we systematically evaluate the\nsensitivity of these analyses to tracker and calorimeter detector\nconfigurations. We examine variations in single-point resolution, material\nbudget, silicon layer placement, and particle identification capabilities,\nquantifying their effects on flavor-tagging performance. Additionally, we\npresent the first comprehensive study of Higgs-to-invisible decay detection\nusing full detector simulation, providing important insights for optimizing\nfuture detector designs at lepton colliders.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-15T11:51:47Z"}
{"aid":"http://arxiv.org/abs/2504.11104v1","title":"Using LLMs as prompt modifier to avoid biases in AI image generators","summary":"This study examines how Large Language Models (LLMs) can reduce biases in\ntext-to-image generation systems by modifying user prompts. We define bias as a\nmodel's unfair deviation from population statistics given neutral prompts. Our\nexperiments with Stable Diffusion XL, 3.5 and Flux demonstrate that\nLLM-modified prompts significantly increase image diversity and reduce bias\nwithout the need to change the image generators themselves. While occasionally\nproducing results that diverge from original user intent for elaborate prompts,\nthis approach generally provides more varied interpretations of underspecified\nrequests rather than superficial variations. The method works particularly well\nfor less advanced image generators, though limitations persist for certain\ncontexts like disability representation. All prompts and generated images are\navailable at https://iisys-hof.github.io/llm-prompt-img-gen/","main_category":"cs.CL","categories":"cs.CL,cs.CV,cs.CY","published":"2025-04-15T11:52:20Z"}
{"aid":"http://arxiv.org/abs/2504.11109v1","title":"Fine-Tuning Large Language Models on Quantum Optimization Problems for\n  Circuit Generation","summary":"Large language models (LLM) have achieved remarkable outcomes in addressing\ncomplex problems, including math, coding, and analyzing large amounts of\nscientific reports. Yet few works have explored the potential of LLM in quantum\ncomputing. The most challenging problem is how to leverage LLMs to\nautomatically generate quantum circuits at a large scale. In this paper, we\naddress such a challenge by fine-tuning LLMs and injecting the domain-specific\nknowledge of quantum computing. In particular, we investigate the mechanisms to\ngenerate training data sets and construct the end-to-end pipeline to fine-tune\npre-trained LLMs that produce parameterized quantum circuits for optimization\nproblems. We have prepared 14,000 quantum circuits covering a substantial part\nof the quantum optimization landscape: 12 optimization problem instances and\ntheir optimized QAOA, VQE, and adaptive VQE circuits. The fine-tuned LLMs can\nconstruct syntactically correct parametrized quantum circuits in the most\nrecent OpenQASM 3.0. We have evaluated the quality of the parameters by\ncomparing them to the optimized expectation values and distributions. Our\nevaluation shows that the fine-tuned LLM outperforms state-of-the-art models\nand that the parameters are better than random. The LLM-generated parametrized\ncircuits and initial parameters can be used as a starting point for further\noptimization, \\emph{e.g.,} templates in quantum machine learning and the\nbenchmark for compilers and hardware.","main_category":"quant-ph","categories":"quant-ph,cs.AI","published":"2025-04-15T11:56:54Z"}
{"aid":"http://arxiv.org/abs/2504.11113v1","title":"Generation of Relativistic Structured Spin-Polarized Lepton Beams","summary":"Relativistic structured spin-polarized (SSP) particle beams, characterized by\npolarization structures, are of critical importance in a wide range of\napplications, such as material properties investigation, imaging, and\ninformation storage. However, generation of relativistic SSP beams faces\nsignificant challenges. Here, we put forward a novel method for generating\nrelativistic SSP lepton beams via employing a moderate-intensity terahertz\n(THz) wave. Building upon our foundational work on velocity-matched spin\nrotation in dielectric-lined waveguides [Phys. Rev. Lett. 134, 075001 (2025)],\nwe present the first demonstration of spin-polarization mode matching - a novel\nmechanism that establishes a direct relation between waveguide modes and beam\npolarization states. This breakthrough enables precise spatial control over\nspin structures at relativistic energies, generating customizable\nspin-polarization configurations such as spider-like, azimuthal, and helical\nstructures, etc. Such SSP beams have the potential to generate high-energy\nstructured photon beams and open a new avenue for research on relativistic\nstructured particle beams, especially in nuclear physics, high-energy physics,\nmaterials science and atomic physics.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T12:01:45Z"}
{"aid":"http://arxiv.org/abs/2504.11114v1","title":"Continuous Aperture Array (CAPA)-Based Secure Wireless Communications","summary":"A continuous aperture array (CAPA)-based secure communication system is\ninvestigated, where a base station equipped with a CAPA transmits signals to a\nlegitimate user under the existence of an eavesdropper. For improving the\nsecrecy performance, the artificial noise (AN) is employed at the BS for the\njamming purpose. We aim at maximizing the secrecy rate by jointly optimizing\nthe information-bearing and AN source current patterns, subject to the maximum\ntransmit power constraint. To solve the resultant non-convex integral-based\nfunctional programming problem, a channel subspace-based approach is first\nproposed via exploiting the result that the optimal current patterns always lie\nwithin the subspace spanned by all users' channel responses. Then, the\nintractable CAPA continuous source current pattern design problem with an\ninfinite number of optimization variables is equivalently transformed into the\nchannel-subspace weighting factor optimization problem with a finite number of\noptimization variables. A penalty-based successive convex approximation method\nis developed for iteratively optimizing the finite-size weighting vectors. To\nfurther reduce the computational complexity, we propose a two-stage source\ncurrent patterns design scheme. Specifically, the information-bearing and AN\npatterns are first designed using the maximal ration transmission and\nzero-forcing transmission, respectively. Then, the remaining power allocation\nis addressed via the one-dimensional search method. Numerical results unveil\nthat 1) the CAPA brings in significant secrecy rate gain compared to the\nconventional discrete multiple-input multiple-output; 2) the proposed channel\nsubspace-based algorithm outperforms the conventional Fourier-based approach,\nwhile sustaining much lower computational complexity; and 3) the two-stage\nZF-MRT approach has negligible performance loss for the large transmit power\nregime.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T12:02:03Z"}
{"aid":"http://arxiv.org/abs/2504.11139v1","title":"Non-stabilizerness in open XXZ spin chains: Universal scaling and\n  dynamics","summary":"Magic, or non-stabilizerness, is a crucial quantum resource, yet its dynamics\nin open quantum systems remain largely unexplored. We investigate magic in the\nopen XXZ spin chain under either boundary gain and loss, or bulk dephasing\nusing the stabilizer R\\'enyi entropy $M_2$. To enable scalable simulations of\nlarge systems, we develop a novel, highly efficient algorithm for computing\n$M_2$ within the matrix product states formalism while maintaining constant\nbond dimension--an advancement over existing methods. For boundary driving, we\nuncover universal scaling laws, $M_2(t) \\sim t^{1/z}$, linked to the dynamical\nexponent $z$ for several distinct universality classes. We also disentangle\nclassical and quantum contributions to magic by introducing a mean-field\napproximation for magic, thus emphasizing the prominent role of quantum\ncritical fluctuations in non-stabilizerness. For bulk dephasing, dissipation\ncan transiently enhance magic before suppressing it, and drive it to a\nnontrivial steady-state value. These findings position magic as a powerful\ndiagnostic tool for probing universality and dynamics in open quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-04-15T12:41:52Z"}
{"aid":"http://arxiv.org/abs/2504.11143v1","title":"Taming Consistency Distillation for Accelerated Human Image Animation","summary":"Recent advancements in human image animation have been propelled by video\ndiffusion models, yet their reliance on numerous iterative denoising steps\nresults in high inference costs and slow speeds. An intuitive solution involves\nadopting consistency models, which serve as an effective acceleration paradigm\nthrough consistency distillation. However, simply employing this strategy in\nhuman image animation often leads to quality decline, including visual\nblurring, motion degradation, and facial distortion, particularly in dynamic\nregions. In this paper, we propose the DanceLCM approach complemented by\nseveral enhancements to improve visual quality and motion continuity at\nlow-step regime: (1) segmented consistency distillation with an auxiliary\nlight-weight head to incorporate supervision from real video latents,\nmitigating cumulative errors resulting from single full-trajectory generation;\n(2) a motion-focused loss to centre on motion regions, and explicit injection\nof facial fidelity features to improve face authenticity. Extensive qualitative\nand quantitative experiments demonstrate that DanceLCM achieves results\ncomparable to state-of-the-art video diffusion models with a mere 2-4 inference\nsteps, significantly reducing the inference burden without compromising video\nquality. The code and models will be made publicly available.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T12:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.11157v1","title":"Similarity Constrained CC2 for Efficient Coupled Cluster Nonadiabatic\n  Dynamics","summary":"Despite their high accuracy, standard coupled cluster models cannot be used\nfor nonadiabatic molecular dynamics simulations because they yield unphysical\ncomplex excitation energies at conical intersections between same-symmetry\nexcited states. On the other hand, similarity constrained coupled cluster\ntheory has enabled the application of coupled cluster theory in such dynamics\nsimulations. Here, we present a similarity constrained perturbative doubles\n(SCC2) model with same-symmetry excited-state conical intersections that\nexhibit correct topography, topology, and real excitation energies. This is\nachieved while retaining the favorable computational scaling of the standard\nCC2 model. We illustrate the model for conical intersections in hypofluorous\nacid and thymine, and compare its performance with other methods. The results\ndemonstrate that conical intersections between excited states can be described\ncorrectly and efficiently at the SCC2 level. We therefore expect that the SCC2\nmodel will enable coupled cluster nonadiabatic dynamics simulations for large\nmolecular systems.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-15T13:04:06Z"}
{"aid":"http://arxiv.org/abs/2504.11168v1","title":"Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails","summary":"Large Language Models (LLMs) guardrail systems are designed to protect\nagainst prompt injection and jailbreak attacks. However, they remain vulnerable\nto evasion techniques. We demonstrate two approaches for bypassing LLM prompt\ninjection and jailbreak detection systems via traditional character injection\nmethods and algorithmic Adversarial Machine Learning (AML) evasion techniques.\nThrough testing against six prominent protection systems, including Microsoft's\nAzure Prompt Shield and Meta's Prompt Guard, we show that both methods can be\nused to evade detection while maintaining adversarial utility achieving in some\ninstances up to 100% evasion success. Furthermore, we demonstrate that\nadversaries can enhance Attack Success Rates (ASR) against black-box targets by\nleveraging word importance ranking computed by offline white-box models. Our\nfindings reveal vulnerabilities within current LLM protection mechanisms and\nhighlight the need for more robust guardrail systems.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.LG,I.2.7","published":"2025-04-15T13:16:02Z"}
{"aid":"http://arxiv.org/abs/2504.11174v1","title":"Algorithmic thresholds in combinatorial optimization depend on the time\n  scaling","summary":"In the last decades, many efforts have focused on analyzing typical-case\nhardness in optimization and inference problems. Some recent work has pointed\nout that polynomial algorithms exist, running with a time that grows more than\nlinearly with the system size, which can do better than linear algorithms,\nfinding solutions to random problems in a wider range of parameters. However, a\ntheory for polynomial and superlinear algorithms is in general lacking. In this\npaper, we examine the performance of the Simulated Annealing algorithm, a\nstandard, versatile, and robust choice for solving optimization and inference\nproblems, in the prototypical random $K$-Sat problem. For the first time, we\nshow that the algorithmic thresholds depend on the time scaling of the\nalgorithm with the size of the system. Indeed, one can identify not just one,\nbut different thresholds for linear, quadratic, cubic regimes (and so on). This\nobservation opens new directions in studying the typical case hardness in\noptimization problems.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-15T13:27:57Z"}
{"aid":"http://arxiv.org/abs/2504.11184v1","title":"A simple, robust and cost-effective method to achieve dispersion\n  matching in swept source OCT","summary":"Optical path length and dispersion matching in both measurement and reference\narms of an OCT system is critical for achieving bandwidth-limited axial\nresolution. To minimize or eliminate dispersion mismatch, most, if not all,\nfiber-based OCT realisations employ a reference arm configuration that is as\nclosely identical to the measurement arm as possible. This typically includes a\ncollimator, dispersion compensating material (or sometimes a set of lenses), as\nwell as a mirror (or retro-reflector) mounted on a translation stage. However,\nthis solution makes the total instrument cost higher and the setup bulkier than\nnecessary and it also renders the reference arm mechanically unstable. Here, a\nsimple yet robust, low-cost reference arm setup is presented and its ability to\ncompensate for measurement arm dispersion is demonstrated. We use a single-mode\nfiber cleaved and polished perpendicular to the fiber axis to construct the\nreference arm. The length and material of the fibre is determined by\nconsidering the optical path length and dispersion of the measurement arm.\nExperimental images demonstrate the operation of the novel reference arm in our\nSwept-source Optical Coherence Tomography.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T13:40:50Z"}
{"aid":"http://arxiv.org/abs/2504.11186v1","title":"Benchmarking Next-Generation Reasoning-Focused Large Language Models in\n  Ophthalmology: A Head-to-Head Evaluation on 5,888 Items","summary":"Recent advances in reasoning-focused large language models (LLMs) mark a\nshift from general LLMs toward models designed for complex decision-making, a\ncrucial aspect in medicine. However, their performance in specialized domains\nlike ophthalmology remains underexplored. This study comprehensively evaluated\nand compared the accuracy and reasoning capabilities of four newly developed\nreasoning-focused LLMs, namely DeepSeek-R1, OpenAI o1, o3-mini, and Gemini 2.0\nFlash-Thinking. Each model was assessed using 5,888 multiple-choice\nophthalmology exam questions from the MedMCQA dataset in zero-shot setting.\nQuantitative evaluation included accuracy, Macro-F1, and five text-generation\nmetrics (ROUGE-L, METEOR, BERTScore, BARTScore, and AlignScore), computed\nagainst ground-truth reasonings. Average inference time was recorded for a\nsubset of 100 randomly selected questions. Additionally, two board-certified\nophthalmologists qualitatively assessed clarity, completeness, and reasoning\nstructure of responses to differential diagnosis questions.O1 (0.902) and\nDeepSeek-R1 (0.888) achieved the highest accuracy, with o1 also leading in\nMacro-F1 (0.900). The performance of models across the text-generation metrics\nvaried: O3-mini excelled in ROUGE-L (0.151), o1 in METEOR (0.232), DeepSeek-R1\nand o3-mini tied for BERTScore (0.673), DeepSeek-R1 (-4.105) and Gemini 2.0\nFlash-Thinking (-4.127) performed best in BARTScore, while o3-mini (0.181) and\no1 (0.176) led AlignScore. Inference time across the models varied, with\nDeepSeek-R1 being slowest (40.4 seconds) and Gemini 2.0 Flash-Thinking fastest\n(6.7 seconds). Qualitative evaluation revealed that DeepSeek-R1 and Gemini 2.0\nFlash-Thinking tended to provide detailed and comprehensive intermediate\nreasoning, whereas o1 and o3-mini displayed concise and summarized\njustifications.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T13:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.11191v1","title":"Magnetic Field Conforming Formulations for Foil Windings","summary":"We extend the foil winding homogenization method to magnetic field conforming\nformulations. We first propose a full magnetic field foil winding formulation\nby analogy with magnetic flux density conforming formulations. We then\nintroduce the magnetic scalar potential in non-conducting regions to improve\nthe efficiency of the model. This leads to a significant reduction in the\nnumber of degrees of freedom, particularly in 3-D applications. The proposed\nmodels are verified on two frequency-domain benchmark problems: a 2-D\naxisymmetric problem and a 3-D problem. They reproduce results obtained with\nmagnetic flux density conforming formulations and with resolved conductor\nmodels that explicitly discretize all turns. Moreover, the models are applied\nin the transient simulation of a high-temperature superconducting coil. In all\ninvestigated configurations, the proposed models provide reliable results while\nconsiderably reducing the size of the numerical problem to be solved.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-15T13:48:18Z"}
{"aid":"http://arxiv.org/abs/2504.11193v1","title":"Time-Resolved Stokes Analysis of Single Photon Emitters in Hexagonal\n  Boron Nitride","summary":"Solid-state quantum emitters play a vital role in advancing quantum\ntechnologies, particularly in quantum computation and communication, where\nsingle-photon polarization acts as a fundamental information carrier. Precise\npolarization characterization is essential for understanding the mechanisms\nunderlying polarization dynamics, which is critical for developing quantum\nemitters with minimized polarization-related errors. In this study, we employ\nthe Rotating Quarter-Wave Plate (RQWP) method to comprehensively characterize\nthe polarization state of quantum emitters in hexagonal boron nitride (hBN). By\nexamining both time-averaged and dynamic polarization features, we demonstrate\nthe time-resolved evolution of Stokes parameters from a solid-state\nsingle-photon emitter using the RQWP technique. This approach provides more\ncomplete polarization information than conventional micro-photoluminescence\nmethods, without requiring modifications to the experimental setup. Our results\nuncover intricate polarization dynamics in hBN emitters, offering insights that\nwere previously inaccessible. The techniques presented here can be broadly\napplied to polarization analysis of solid-state quantum emitters across various\nmaterial platforms.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mes-hall,quant-ph","published":"2025-04-15T13:49:14Z"}
{"aid":"http://arxiv.org/abs/2504.11197v1","title":"Efficient Distributed Retrieval-Augmented Generation for Enhancing\n  Language Model Performance","summary":"Small language models (SLMs) support efficient deployments on\nresource-constrained edge devices, but their limited capacity compromises\ninference performance. Retrieval-augmented generation (RAG) is a promising\nsolution to enhance model performance by integrating external databases,\nwithout requiring intensive on-device model retraining. However, large-scale\npublic databases and user-specific private contextual documents are typically\nlocated on the cloud and the device separately, while existing RAG\nimplementations are primarily centralized. To bridge this gap, we propose\nDRAGON, a distributed RAG framework to enhance on-device SLMs through both\ngeneral and personal knowledge without the risk of leaking document privacy.\nSpecifically, DRAGON decomposes multi-document RAG into multiple parallel token\ngeneration processes performed independently and locally on the cloud and the\ndevice, and employs a newly designed Speculative Aggregation, a dual-side\nspeculative algorithm to avoid frequent output synchronization between the\ncloud and device. A new scheduling algorithm is further introduced to identify\nthe optimal aggregation side based on real-time network conditions. Evaluations\non real-world hardware testbed demonstrate a significant performance\nimprovement of DRAGON-up to 1.9x greater gains over standalone SLM compared to\nthe centralized RAG, substantial reduction in per-token latency, and negligible\nTime to First Token (TTFT) overhead.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DC,cs.IR","published":"2025-04-15T13:53:08Z"}
{"aid":"http://arxiv.org/abs/2504.11209v1","title":"The CMS Barrel Timing Layer: test beam confirmation of module timing\n  performance","summary":"First of its kind, the barrel section of the MIP Timing Detector is a large\narea timing detector based on LYSO:Ce crystals and SiPMs which are required to\noperate in an unprecedentedly harsh radiation environment (up to an integrated\nfluence of $2\\times10^{14}$ 1 MeV $n_{eq}/cm^2$). It is designed as a key\nelement of the upgrade of the existing CMS detector to provide a time\nresolution for minimum ionizing particles in the range between 30-60 ps\nthroughout the entire operation at the High Luminosity LHC. A thorough\noptimization of its components has led to the final detector module layout\nwhich exploits 25 $\\rm \\mu m$ cell size SiPMs and 3.75 mm thick crystals. This\ndesign achieved the target performance in a series of test beam campaigns. In\nthis paper we present test beam results which demonstrate the desired\nperformance of detector modules in terms of radiation tolerance, time\nresolution and response uniformity.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-15T14:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.11223v1","title":"The Simplicial Loop Space of a Simplicial Complex","summary":"Given a simplicial complex $X$, we construct a simplicial complex $\\Omega X$\nthat may be regarded as a combinatorial version of the based loop space of a\ntopological space. Our construction explicitly describes the simplices of\n$\\Omega X$ directly in terms of the simplices of $X$. Working at a purely\ncombinatorial level, we show two main results that confirm the (combinatorial)\nalgebraic topology of our $\\Omega X$ behaves like that of the topological based\nloop space. Whereas our $\\Omega X$ is generally a disconnected simplical\ncomplex, each component of $\\Omega X$ has the same edge group, up to\nisomorphism. We show an isomorphism between the edge group of $\\Omega X$ and\nthe combinatorial second homotopy group of $X$ as it has been defined in\nseparate work (arxiv:2503.23651). Finally, we enter the topological setting\nand, relying on prior work of Stone, show a homotopy equivalence between the\nspatial realization of our $\\Omega X$ and the based loop space of the spatial\nrealization of $X$.","main_category":"math.AT","categories":"math.AT","published":"2025-04-15T14:25:01Z"}
{"aid":"http://arxiv.org/abs/2504.11225v1","title":"Directed First-Order Logic","summary":"We present a first-order logic equipped with an \"asymmetric\" directed notion\nof equality, which can be thought of as transitions/rewrites between terms,\nallowing for types to be interpreted as preorders. We then provide a universal\nproperty to such \"directed equalities\" by describing introduction and\nelimination rules that allows them to be contracted only with certain syntactic\nrestrictions, based on polarity, which do not allow for symmetry to be derived.\nWe give a characterization of such directed equality as a relative left\nadjoint, generalizing the idea by Lawvere of equality as left adjoint. The\nlogic is equipped with a precise syntactic system of polarities, inspired by\ndinaturality, that keeps track of the occurrence of variables\n(positive/negative/both). The semantics of this logic and its system of\nvariances is then captured categorically using the notion of directed doctrine,\nwhich we prove sound and complete with respect to the syntax.","main_category":"cs.LO","categories":"cs.LO,math.CT","published":"2025-04-15T14:28:05Z"}
{"aid":"http://arxiv.org/abs/2504.11233v1","title":"AutoRAN: Automated and Zero-Touch Open RAN Systems","summary":"[...] This paper presents AutoRAN, an automated, intent-driven framework for\nzero-touch provisioning of open, programmable cellular networks. Leveraging\ncloud-native principles, AutoRAN employs virtualization, declarative\ninfrastructure-as-code templates, and disaggregated micro-services to abstract\nphysical resources and protocol stacks. Its orchestration engine integrates\nLanguage Models (LLMs) to translate high-level intents into machine-readable\nconfigurations, enabling closed-loop control via telemetry-driven\nobservability. Implemented on a multi-architecture OpenShift cluster with\nheterogeneous compute (x86/ARM CPUs, NVIDIA GPUs) and multi-vendor Radio Access\nNetwork (RAN) hardware (Foxconn, NI), AutoRAN automates deployment of\nO-RAN-compliant stacks-including OpenAirInterface, NVIDIA ARC RAN, Open5GS\ncore, and O-RAN Software Community (OSC) RIC components-using CI/CD pipelines.\nExperimental results demonstrate that AutoRAN is capable of deploying an\nend-to-end Private 5G network in less than 60 seconds with 1.6 Gbps throughput,\nvalidating its ability to streamline configuration, accelerate testing, and\nreduce manual intervention with similar performance than non cloud-based\nimplementations. With its novel LLM-assisted intent translation mechanism, and\nperformance-optimized automation workflow for multi-vendor environments,\nAutoRAN has the potential of advancing the robustness of next-generation\ncellular supply chains through reproducible, intent-based provisioning across\npublic and private deployments.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-15T14:36:08Z"}
{"aid":"http://arxiv.org/abs/2504.11245v1","title":"Influence Maximization in Temporal Social Networks with a Cold-Start\n  Problem: A Supervised Approach","summary":"Influence Maximization (IM) in temporal graphs focuses on identifying\ninfluential \"seeds\" that are pivotal for maximizing network expansion. We\nadvocate defining these seeds through Influence Propagation Paths (IPPs), which\nis essential for scaling up the network. Our focus lies in efficiently labeling\nIPPs and accurately predicting these seeds, while addressing the\noften-overlooked cold-start issue prevalent in temporal networks. Our strategy\nintroduces a motif-based labeling method and a tensorized Temporal Graph\nNetwork (TGN) tailored for multi-relational temporal graphs, bolstering\nprediction accuracy and computational efficiency. Moreover, we augment\ncold-start nodes with new neighbors from historical data sharing similar IPPs.\nThe recommendation system within an online team-based gaming environment\npresents subtle impact on the social network, forming multi-relational (i.e.,\nweak and strong) temporal graphs for our empirical IM study. We conduct offline\nexperiments to assess prediction accuracy and model training efficiency,\ncomplemented by online A/B testing to validate practical network growth and the\neffectiveness in addressing the cold-start issue.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-04-15T14:44:30Z"}
{"aid":"http://arxiv.org/abs/2504.11246v1","title":"Respiratory Inhaler Sound Event Classification Using Self-Supervised\n  Learning","summary":"Asthma is a chronic respiratory condition that affects millions of people\nworldwide. While this condition can be managed by administering controller\nmedications through handheld inhalers, clinical studies have shown low\nadherence to the correct inhaler usage technique. Consequently, many patients\nmay not receive the full benefit of their medication. Automated classification\nof inhaler sounds has recently been studied to assess medication adherence.\nHowever, the existing classification models were typically trained using data\nfrom specific inhaler types, and their ability to generalize to sounds from\ndifferent inhalers remains unexplored. In this study, we adapted the wav2vec\n2.0 self-supervised learning model for inhaler sound classification by\npre-training and fine-tuning this model on inhaler sounds. The proposed model\nshows a balanced accuracy of 98% on a dataset collected using a dry powder\ninhaler and smartwatch device. The results also demonstrate that re-finetuning\nthis model on minimal data from a target inhaler is a promising approach to\nadapting a generic inhaler sound classification model to a different inhaler\ndevice and audio capture hardware. This is the first study in the field to\ndemonstrate the potential of smartwatches as assistive technologies for the\npersonalized monitoring of inhaler adherence using machine learning models.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.LG","published":"2025-04-15T14:44:47Z"}
{"aid":"http://arxiv.org/abs/2504.11275v1","title":"Relic gravitational waves from primordial gravitational collapses","summary":"A large primordial density perturbation of the Hubble scale will\ngravitationally collapse, generating an outgoing sound shell whether or not a\nprimordial black hole (PBH) is formed. In this Letter, we report a new source\nof the stochastic gravitational wave background induced by the collision of\nsound shells in the early Universe. The peak frequency and amplitude in the GW\nspectrum depend on the Hubble horizon and the abundance of sound shells.\nAbundant density perturbations would lead to GW backgrounds potentially\ndetectable for future pulsar timing arrays and ground-based/space-borne\ndetectors. For those perturbations that collapse into PBHs, future null\ndetection of the corresponding high-frequency GW background could put new\nobservational constraints on those PBHs that have already evaporated.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph","published":"2025-04-15T15:15:15Z"}
{"aid":"http://arxiv.org/abs/2504.11285v1","title":"Balancing hydrogen delivery in national energy systems: impact of the\n  temporal flexibility of hydrogen delivery on export prices","summary":"Hydrogen is expected to play a key role in the energy transition. Analyses\nexploring the price of hydrogen usually calculate average or marginal\nproduction costs regardless of the time of delivery. A key factor that affects\nthe price of hydrogen is the balancing costs, which we define as the expense of\nensuring a steady schedule of hydrogen delivery. We explore the effect of\ndelivering hydrogen to the export ports at different schedules, ranging from\nfully flexible to moderately stable with a daily and weekly buffer, to fully\nstable. We quantify the rise in hydrogen price with strict balancing constraint\nin three countries: Brazil, Morocco and Turkey, and three export volumes: 10,\n50 and 200 TWh. The price difference between the flexible and stable schedules\nwas found to reach a maximum of 36% in Brazil, 47% in Morocco and 18% in Turkey\nacross the different export volumes.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T15:25:59Z"}
{"aid":"http://arxiv.org/abs/2504.11293v1","title":"Remote electric-field control of antiferromagnetic magnon-polaritons","summary":"The control of hybrid light-matter states, specifically magnon-polaritons\nthat emerge from the strong coupling between magnons and cavity photons,\nremains a key challenge in developing reconfigurable quantum and classical\ndevices. Here, we showcase the ability to remotely control antiferromagnetic\nmagnon-polaritons at room temperature using electric field by integrating a\nhighly birefringent liquid crystal layer into a terahertz Fabry-P\\'erot cavity\ncontaining an antiferromagnetic crystal. Positioned several millimeters from\nthe magnetic material, the liquid crystal allows for adjusting the cavity's\nphotonic environment through electric field. This adjustment, in turn,\ninfluences the coupling strength of a particular cavity mode to the magnon\nresonance, thereby controlling the extent of magnon dressing by cavity photons.\nOur approach facilitates dynamic and reversible tuning of magnon-photon\nhybridization without the need for direct electrical contact or alterations to\nthe magnetic medium. These findings create the conditions for\nvoltage-programmable terahertz magnonic devices and new possibilities for\nnoninvasive control strategies in spin-based information processing\ntechnologies.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-04-15T15:32:31Z"}
{"aid":"http://arxiv.org/abs/2504.11297v1","title":"Current response to axial gauge fields in noncentrosymmetric magnetic\n  Weyl semimetals","summary":"We investigate the electric current response to axial gauge fields in\nnoncentrosymmetric magnetic Weyl semimetals. The absence of both time-reversal\nand inversion symmetries allows for new types of responses. We systematically\ncalculate the transverse, longitudinal, and Hall responses to axial gauge\npotentials with both linear and quadratic dispersion relations. The transverse\nand Hall responses are of comparable magnitude, while the longitudinal response\nis much smaller. Notably, with increasing frequency, the transverse and Hall\nresponse functions manifest a peak whose height is determined by the properties\nof Weyl fermions and is independent of the axial gauge potential. The main\nfeatures of the response functions survive in the presence of disorders. As\napplications of our results, we propose a Hall type magnetopiezoelectric\neffect, where a transverse sound wave can induce an electric current whose\ndirection is perpendicular to the directions of sound propagation and\npolarization. Our results also provide a mechanism to excite magnons using\nelectric fields and could be useful for magnon spintronics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T15:36:52Z"}
{"aid":"http://arxiv.org/abs/2504.11302v1","title":"Limits of Discrete Energy of Families of Increasing Sets","summary":"The Hausdorff dimension of a set can be detected using the Riesz energy.\nHere, we consider situations where a sequence of points, $\\{x_n\\}$, ``fills\nin'' a set $E \\subset \\mathbb{R}^d$ in an appropriate sense and investigate the\ndegree to which the discrete analog to the Riesz energy of these sets can be\nused to bound the Hausdorff dimension of $E$. We also discuss applications to\ndata science and Erd\\H{o}s/Falconer type problems.","main_category":"math.CA","categories":"math.CA,cs.LG,math.MG","published":"2025-04-15T15:45:14Z"}
{"aid":"http://arxiv.org/abs/2504.11312v1","title":"Boundedness and compactness of Bergman projection commutators in\n  two-weight setting","summary":"The goal of this paper is to study the boundedness and compactness of the\nBergman projection commutators in two weighted settings via the weighted BMO\nand VMO spaces, respectively. The novelty of our work lies in the distinct\ntreatment of the symbol b in the commutator, depending on whether it is\nanalytic or not, which turns out to be quite different. In particular, we show\nthat an additional weight condition due to Aleman, Pott, and Reguera is\nnecessary to study the commutators when b is not analytic, while it can be\nrelaxed when b is analytic. In the analytic setting, we completely characterize\nboundedness and compactness, while in the non-analytic setting, we provide a\nsufficient condition which generalizes the Euclidean case and is also necessary\nin many cases of interest. Our work initiates a study of the commutators acting\non complex function spaces with different symbols.","main_category":"math.CA","categories":"math.CA,math.CV","published":"2025-04-15T15:52:36Z"}
{"aid":"http://arxiv.org/abs/2504.11316v1","title":"Role of Matter Inhomogeneity on Fast Flavor Conversion of Supernova\n  Neutrinos","summary":"We investigated the impact of a spatially varying matter potential $\\lambda$,\ncoming from neutrino-electron forward scattering, on the emergence of fast\nneutrino flavor conversion (FFC) triggered by the presence of zero crossings in\nthe angular distribution of the neutrino electron lepton number (ELN). We find\nthat FFC can be significantly affected as the spatial variation rate of\n$\\lambda$ increases, and strong spatial variations can completely stabilize\ninitially unstable systems. Using stability analysis based solely on initial\nconditions, we identified for the first time a critical variation rate above\nwhich no FFC occurs even if the flavor instability exists. By analyzing several\nrepresentative matter profiles based on an 18 $M_{\\odot}$ SN model, we show\nthat spatially inhomogeneous $\\lambda$ can suppress the occurrence of FFC\nassociated with shallow ELN zero crossings in most of the SN's radial region,\nespecially during the accretion phase. Our finding highlights the need to\nconsider the impact of matter inhomogeneity in the development of improved SN\nmodels that aim to include the effect of neutrino flavor conversions.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.CO,astro-ph.SR,hep-ph,nucl-th","published":"2025-04-15T15:56:26Z"}
{"aid":"http://arxiv.org/abs/2504.11328v1","title":"Extended source fringe flats for the JWST MIRI Medium Resolution\n  Spectrometer","summary":"The detectors of the JWST Mid-Infrared Instrument (MIRI) Medium Resolution\nSpectrometer (MRS) form low-finesse resonating cavities that cause periodic\ncount rate modulations (fringes) with peak amplitudes of up to 15% for sources\nexternal to MIRI. To detect weak features on a strong continuum and reliably\nmeasure line fluxes and line-flux ratios, fringe correction is crucial. This\npaper describes the first of two steps implemented in the JWST Science\nCalibration Pipeline, which is the division by a static fringe flat that\nremoves the bulk of the fringes for extended sources. Fringe flats were derived\nby fitting a numerical model to observations of spatially extended sources. The\nmodel includes fringes that originate from two resonating cavities in the\ndetector substrate (a third fringe component that originates from the dichroic\nfilters is not included). The model, numerical implementation, and resulting\nfringe flats are described, and the efficiency of the calibration was evaluated\nfor sources of various spatial extents on the detector. Flight fringe flats are\nobtained from observations of the planetary nebula NGC 7027. The two fringe\ncomponents are well recovered and fitted by the model. The derived parameters\nare used to build a fringe flat for each MRS spectral band, except for 1A and\n1B due to the low signal-to-noise ratio of NGC 7027 in these bands. When\napplied to extended sources, fringe amplitudes are reduced to the sub-percent\nlevel on individual spaxels. For point sources, they are reduced to amplitudes\nof 1 to 5% considering individual spaxels and a single dither position, and\ndecrease to the 1 to 2% level after two-dimensional residual fringe correction.\nThe fringe flats derived from this work are the reference files currently in\nuse by the JWST Science Calibration Pipeline. They provide an efficient\ncalibration for extended sources, and are less efficient for point sources.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-15T16:02:59Z"}
{"aid":"http://arxiv.org/abs/2504.11339v1","title":"Optimal and Scalable Augmented Lagrangian preconditioners for Fictitious\n  Domain problems","summary":"We present optimal and scalable preconditioning techniques to solve linear\nsystems of equations with a block two-by-two and three-by-three structure\narising from fictitious domain problems and from finite element discretizations\nof immersed boundary methods. In particular, we propose two augmented\nLagrangian-based preconditioners to accelerate the convergence of iterative\nsolvers for these two classes of linear. We consider two relevant examples to\nillustrate the performance of these preconditioners when used in conjunction\nwith flexible GMRES: the Poisson and the Stokes fictitious domain problems. A\nspectral analysis is established for both exact and inexact versions of these\npreconditioners. We show the effectiveness of the proposed approach and the\nrobustness of our preconditioning strategy through extensive numerical tests in\nboth two and three dimensions.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T16:12:51Z"}
{"aid":"http://arxiv.org/abs/2504.11356v1","title":"Dimension preserving set-valued approximation and decomposition via\n  metric sum","summary":"In the literature, the Minkowski-sum and the metric-sum of compact sets are\nhighlighted. While the first is associative, the latter is not. But the major\ndrawback of the Minkowski combination is that, by increasing the number of\nsummands, this leads to convexification. The present article is uncovered in\ntwo folds: The initial segment presents a novel approach to approximate a\ncontinuous set-valued function with compact images via a fractal approach using\nthe metric linear combination of sets. The other segment contains the dimension\nanalysis of the distance set of graph of set-valued function and solving the\ncelebrated distance set conjecture. In the end, a decomposition of any\ncontinuous convex compact set-valued function is exhibited that preserves the\nHausdorff dimension, so this will serve as a method for dealing with\ncomplicated set-valued functions.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T16:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.11371v1","title":"Taxonomy of Prediction","summary":"A prediction makes a claim about a system's future given knowledge of its\npast. A retrodiction makes a claim about its past given knowledge of its\nfuture. We introduce the ambidextrous hidden Markov chain that does both\noptimally -- the bidirectional machine whose state structure makes explicit all\nstatistical correlations in a stochastic process. We introduce an informational\ntaxonomy to profile these correlations via a suite of multivariate information\nmeasures. While prior results laid out the different kinds of information\ncontained in isolated measurements, in addition to being limited to single\nmeasurements the associated informations were challenging to calculate\nexplicitly. Overcoming these via bidirectional machine states, we expand that\nanalysis to information embedded across sequential measurements. The result\nhighlights fourteen new interpretable and calculable information measures that\nfully characterize a process' informational structure. Additionally, we\nintroduce a labeling and indexing scheme that systematizes\ninformation-theoretic analyses of highly complex multivariate systems.\nOperationalizing this, we provide algorithms to directly calculate all of these\nquantities in closed form for finitely-modeled processes.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cs.IT,math.IT,nlin.AO","published":"2025-04-15T16:36:20Z"}
{"aid":"http://arxiv.org/abs/2504.11373v1","title":"Cancer-Myth: Evaluating AI Chatbot on Patient Questions with False\n  Presuppositions","summary":"Cancer patients are increasingly turning to large language models (LLMs) as a\nnew form of internet search for medical information, making it critical to\nassess how well these models handle complex, personalized questions. However,\ncurrent medical benchmarks focus on medical exams or consumer-searched\nquestions and do not evaluate LLMs on real patient questions with detailed\nclinical contexts. In this paper, we first evaluate LLMs on cancer-related\nquestions drawn from real patients, reviewed by three hematology oncology\nphysicians. While responses are generally accurate, with GPT-4-Turbo scoring\n4.13 out of 5, the models frequently fail to recognize or address false\npresuppositions in the questions-posing risks to safe medical decision-making.\nTo study this limitation systematically, we introduce Cancer-Myth, an\nexpert-verified adversarial dataset of 585 cancer-related questions with false\npresuppositions. On this benchmark, no frontier LLM -- including GPT-4o,\nGemini-1.Pro, and Claude-3.5-Sonnet -- corrects these false presuppositions\nmore than 30% of the time. Even advanced medical agentic methods do not prevent\nLLMs from ignoring false presuppositions. These findings expose a critical gap\nin the clinical reliability of LLMs and underscore the need for more robust\nsafeguards in medical AI systems.","main_category":"cs.CL","categories":"cs.CL,cs.CY","published":"2025-04-15T16:37:32Z"}
{"aid":"http://arxiv.org/abs/2504.11375v1","title":"Ring Artifacts Correction Based on Global-Local Features Interaction\n  Guidance in the Projection Domain","summary":"Ring artifacts are common artifacts in CT imaging, typically caused by\ninconsistent responses of detector units to X-rays, resulting in stripe\nartifacts in the projection data. Under circular scanning mode, such artifacts\nmanifest as concentric rings radiating from the center of rotation, severely\ndegrading image quality. In the Radon transform domain, even if the object's\ndensity function is piecewise discontinuous in certain regions, the projection\nimages remain nearly continuous in the angular direction, making the ideal\nprojections exhibit a smooth global low-frequency characteristic. In practical\nscanning, the local disturbances of the same detector unit at different\nscanning angles lead to a prominent high-frequency locality of stripe\nartifacts. Existing studies generally model ring artifacts disturbances as\nfixed additive errors, which overlooks the dynamic variation of detector\nresponses during practical scanning. However, the degree of detector response\ninconsistency is a function of the projection values, as revealed in our\nexperiments, thereby requiring consideration of the interaction between global\nand local features in the process of stripe artifacts extraction and\ncorrection. Therefore, we propose a CT ring artifacts correction method based\non global and local features in the projection domain. We employ the VSS block\nand Dense block to respectively correct the low-frequency sub-band, which\ncapture the global correlations of the projection, and the high-frequency\nsub-band, which contain local stripe artifacts after wavelet decomposition.\nSpecifically, the accuracy of artifacts correction is enhanced by the\ninteraction guidance between global and local features. Extensive experiments\ndemonstrate that our method achieves superior performance in both quantitative\nmetrics and visual quality, verifying its robustness and practical\napplicability.","main_category":"eess.IV","categories":"eess.IV,I.4.5","published":"2025-04-15T16:42:23Z"}
{"aid":"http://arxiv.org/abs/2504.11393v1","title":"DataDecide: How to Predict Best Pretraining Data with Small Experiments","summary":"Because large language models are expensive to pretrain on different\ndatasets, using smaller-scale experiments to decide on data is crucial for\nreducing costs. Which benchmarks and methods of making decisions from observed\nperformance at small scale most accurately predict the datasets that yield the\nbest large models? To empower open exploration of this question, we release\nmodels, data, and evaluations in DataDecide -- the most extensive open suite of\nmodels over differences in data and scale. We conduct controlled pretraining\nexperiments across 25 corpora with differing sources, deduplication, and\nfiltering up to 100B tokens, model sizes up to 1B parameters, and 3 random\nseeds. We find that the ranking of models at a single, small size (e.g., 150M\nparameters) is a strong baseline for predicting best models at our larger\ntarget scale (1B) (~80% of com parisons correct). No scaling law methods among\n8 baselines exceed the compute-decision frontier of single-scale predictions,\nbut DataDecide can measure improvement in future scaling laws. We also identify\nthat using continuous likelihood metrics as proxies in small experiments makes\nbenchmarks including MMLU, ARC, HellaSwag, MBPP, and HumanEval >80% predictable\nat the target 1B scale with just 0.01% of the compute.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-15T17:02:15Z"}
{"aid":"http://arxiv.org/abs/2504.11396v1","title":"Property Inheritance for Subtensors in Tensor Train Decompositions","summary":"Tensor dimensionality reduction is one of the fundamental tools for modern\ndata science. To address the high computational overhead, fiber-wise sampled\nsubtensors that preserve the original tensor rank are often used in designing\nefficient and scalable tensor dimensionality reduction. However, the theory of\nproperty inheritance for subtensors is still underdevelopment, that is, how the\nessential properties of the original tensor will be passed to its subtensors.\nThis paper theoretically studies the property inheritance of the two key tensor\nproperties, namely incoherence and condition number, under the tensor train\nsetting. We also show how tensor train rank is preserved through fiber-wise\nsampling. The key parameters introduced in theorems are numerically evaluated\nunder various settings. The results show that the properties of interest can be\nwell preserved to the subtensors formed via fiber-wise sampling. Overall, this\npaper provides several handy analytic tools for developing efficient tensor\nanalysis","main_category":"cs.IT","categories":"cs.IT,math.IT,stat.ML","published":"2025-04-15T17:10:38Z"}
{"aid":"http://arxiv.org/abs/2504.11398v1","title":"Breaking a Long-Standing Barrier: 2-$\\varepsilon$ Approximation for\n  Steiner Forest","summary":"The Steiner Forest problem, also known as the Generalized Steiner Tree\nproblem, is a fundamental optimization problem on edge-weighted graphs where,\ngiven a set of vertex pairs, the goal is to select a minimum-cost subgraph such\nthat each pair is connected. This problem generalizes the Steiner Tree problem,\nfirst introduced in 1811, for which the best known approximation factor is 1.39\n[Byrka, Grandoni, Rothvo{\\ss}, and Sanit\\`a, 2010] (Best Paper award, STOC\n2010).\n  The celebrated work of [Agrawal, Klein, and Ravi, 1989] (30-Year Test-of-Time\naward, STOC 2023), along with refinements by [Goemans and Williamson, 1992]\n(SICOMP'95), established a 2-approximation for Steiner Forest over 35 years\nago. Jain's (FOCS'98) pioneering iterative rounding techniques later extended\nthese results to higher connectivity settings. Despite the long-standing\nimportance of this problem, breaking the approximation factor of 2 has remained\na major challenge, raising suspicions that achieving a better factor -- similar\nto Vertex Cover -- might indeed be hard. Notably, fundamental works, including\nthose by Gupta and Kumar (STOC'15) and Gro{\\ss} et al. (ITCS'18), introduced\n96- and 69-approximation algorithms, possibly with the hope of paving the way\nfor a breakthrough in achieving a constant-factor approximation below 2 for the\nSteiner Forest problem.\n  In this paper, we break the approximation barrier of 2 by designing a novel\ndeterministic algorithm that achieves a $2 - 10^{-11}$ approximation for this\nfundamental problem. As a key component of our approach, we also introduce a\nnovel dual-based local search algorithm for the Steiner Tree problem with an\napproximation guarantee of $1.943$, which is of independent interest.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-15T17:13:48Z"}
{"aid":"http://arxiv.org/abs/2504.11405v1","title":"Size-Frequency Distribution of Terrestrial Leftover Planetesimals and\n  S-complex Implanted Asteroids","summary":"The isotopic composition of meteorites linked to S-complex asteroids has been\nused to suggest that these asteroids originated in the terrestrial planet's\nregion, i.e., within 1.5 au, and later got implanted into the main asteroid\nbelt (MAB). Dynamical models of planet formation support this view. Yet, it\nremains to be demonstrated whether the currently observed size-frequency\ndistribution (SFD) of S-complex bodies in the MAB can be reproduced via this\nimplantation process. Here we studied the evolution of the SFD of planetesimals\nduring the accretion of terrestrial planets with the code LIPAD\nself-consistently accounting for growth and fragmentation of planetesimals. In\nour simulations we vary the initial surface density of planetesimals, the\ngaseous disk lifetime, and the power slope of the initial planetesimals' SFD.\nWe compared the final SFDs of leftover planetesimals in the terrestrial planet\nregion with the SFD of observed S-complex MAB objects (D $>$ 100km). We found\nthat the SFDs of our planetesimal populations and that of S-complex MAB objects\nshow very similar cumulative power index (i.e., q $\\approx$ 3.15 in\nN($>$D)$~\\propto$ D$^{-q}$) for slopes in the diameter range 100 km $<$ D $<$\n400 km by the end of our simulations. Our results support the hypothesis of\nS-complex MAB implantation from the terrestrial planet forming region, assuming\nimplantation is size-independent, and implies that implantation efficiency is\nsmaller than $\\mathcal{O}$(10$^{\\rm -2}$--10$^{\\rm -4}$) to avoid\nover-implantation of (4) Vesta-sized objects or larger.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T17:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.11406v1","title":"Multi-level Cellular Automata for FLIM networks","summary":"The necessity of abundant annotated data and complex network architectures\npresents a significant challenge in deep-learning Salient Object Detection\n(deep SOD) and across the broader deep-learning landscape. This challenge is\nparticularly acute in medical applications in developing countries with limited\ncomputational resources. Combining modern and classical techniques offers a\npath to maintaining competitive performance while enabling practical\napplications. Feature Learning from Image Markers (FLIM) methodology empowers\nexperts to design convolutional encoders through user-drawn markers, with\nfilters learned directly from these annotations. Recent findings demonstrate\nthat coupling a FLIM encoder with an adaptive decoder creates a flyweight\nnetwork suitable for SOD, requiring significantly fewer parameters than\nlightweight models and eliminating the need for backpropagation. Cellular\nAutomata (CA) methods have proven successful in data-scarce scenarios but\nrequire proper initialization -- typically through user input, priors, or\nrandomness. We propose a practical intersection of these approaches: using FLIM\nnetworks to initialize CA states with expert knowledge without requiring user\ninteraction for each image. By decoding features from each level of a FLIM\nnetwork, we can initialize multiple CAs simultaneously, creating a multi-level\nframework. Our method leverages the hierarchical knowledge encoded across\ndifferent network layers, merging multiple saliency maps into a high-quality\nfinal output that functions as a CA ensemble. Benchmarks across two challenging\nmedical datasets demonstrate the competitiveness of our multi-level CA approach\ncompared to established models in the deep SOD literature.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T17:22:24Z"}
{"aid":"http://arxiv.org/abs/2504.11440v1","title":"Greedy Restart Schedules: A Baseline for Dynamic Algorithm Selection on\n  Numerical Black-box Optimization Problems","summary":"In many optimization domains, there are multiple different solvers that\ncontribute to the overall state-of-the-art, each performing better on some, and\nworse on other types of problem instances. Meta-algorithmic approaches, such as\ninstance-based algorithm selection, configuration and scheduling, aim to close\nthis gap by extracting the most performance possible from a set of\n(configurable) optimizers. In this context, the best performing individual\nalgorithms are often hand-crafted hybrid heuristics which perform many restarts\nof fast local optimization approaches. However, data-driven techniques to\ncreate optimized restart schedules have not yet been extensively studied.\n  Here, we present a simple scheduling approach that iteratively selects the\nalgorithm performing best on the distribution of unsolved training problems at\ntime of selection, resulting in a problem-independent solver schedule. We\ndemonstrate our approach using well-known optimizers from numerical black-box\noptimization on the BBOB testbed, bridging much of the gap between single and\nvirtual best solver from the original portfolio across various evaluation\nprotocols. Our greedy restart schedule presents a powerful baseline for more\ncomplex dynamic algorithm selection models.","main_category":"math.OC","categories":"math.OC,cs.AI","published":"2025-04-15T17:54:21Z"}
{"aid":"http://arxiv.org/abs/2504.11441v1","title":"TADACap: Time-series Adaptive Domain-Aware Captioning","summary":"While image captioning has gained significant attention, the potential of\ncaptioning time-series images, prevalent in areas like finance and healthcare,\nremains largely untapped. Existing time-series captioning methods typically\noffer generic, domain-agnostic descriptions of time-series shapes and struggle\nto adapt to new domains without substantial retraining. To address these\nlimitations, we introduce TADACap, a retrieval-based framework to generate\ndomain-aware captions for time-series images, capable of adapting to new\ndomains without retraining. Building on TADACap, we propose a novel retrieval\nstrategy that retrieves diverse image-caption pairs from a target domain\ndatabase, namely TADACap-diverse. We benchmarked TADACap-diverse against\nstate-of-the-art methods and ablation variants. TADACap-diverse demonstrates\ncomparable semantic accuracy while requiring significantly less annotation\neffort.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-15T17:54:59Z"}
{"aid":"http://arxiv.org/abs/2504.11450v1","title":"Optimal Hardness of Online Algorithms for Large Independent Sets","summary":"We study the algorithmic problem of finding a large independent set in an\nErd\\\"{o}s-R\\'{e}nyi random graph $\\mathbb{G}(n,p)$. For constant $p$ and\n$b=1/(1-p)$, the largest independent set has size $2\\log_b n$, while a simple\ngreedy algorithm revealing vertices sequentially and making decisions based\nonly on previously seen vertices finds an independent set of size $\\log_b n$.\nIn his seminal 1976 paper, Karp challenged to either improve this guarantee or\nestablish its hardness. Decades later, this problem remains open, one of the\nmost prominent algorithmic problems in the theory of random graphs.\n  In this paper, we establish that a broad class of online algorithms fails to\nfind an independent set of size $(1+\\epsilon)\\log_b n$ any constant\n$\\epsilon>0$ w.h.p. This class includes Karp's algorithm as a special case, and\nextends it by allowing the algorithm to query exceptional edges not yet 'seen'\nby the algorithm. Our lower bound holds for all $p\\in [d/n,1-n^{-1/d}]$, where\n$d$ is a large constant. In the dense regime (constant $p$), we further prove\nthat our result is asymptotically tight with respect to the number of\nexceptional edges queried, by designing an online algorithm which beats the\nhalf-optimality threshold when the number of exceptional edges slightly exceeds\nour bound.\n  Our result provides evidence for the algorithmic hardness of Karp's problem\nby supporting the conjectured optimality of the aforementioned greedy algorithm\nand establishing it within the class of online algorithms. Our proof relies on\na refined analysis of the geometric structure of tuples of large independent\nsets, establishing a variant of the Overlap Gap Property (OGP) commonly used as\na barrier for classes of algorithms. While OGP has predominantly served as a\nbarrier to stable algorithms, online algorithms are not stable and our\napplication of OGP-based techniques to online setting is novel.","main_category":"cs.DS","categories":"cs.DS,cs.CC,cs.DM,math.CO,math.PR","published":"2025-04-15T17:58:08Z"}
{"aid":"http://arxiv.org/abs/2504.11453v1","title":"A Clean Slate for Offline Reinforcement Learning","summary":"Progress in offline reinforcement learning (RL) has been impeded by ambiguous\nproblem definitions and entangled algorithmic designs, resulting in\ninconsistent implementations, insufficient ablations, and unfair evaluations.\nAlthough offline RL explicitly avoids environment interaction, prior methods\nfrequently employ extensive, undocumented online evaluation for hyperparameter\ntuning, complicating method comparisons. Moreover, existing reference\nimplementations differ significantly in boilerplate code, obscuring their core\nalgorithmic contributions. We address these challenges by first introducing a\nrigorous taxonomy and a transparent evaluation protocol that explicitly\nquantifies online tuning budgets. To resolve opaque algorithmic design, we\nprovide clean, minimalistic, single-file implementations of various model-free\nand model-based offline RL methods, significantly enhancing clarity and\nachieving substantial speed-ups. Leveraging these streamlined implementations,\nwe propose Unifloral, a unified algorithm that encapsulates diverse prior\napproaches within a single, comprehensive hyperparameter space, enabling\nalgorithm development in a shared hyperparameter space. Using Unifloral with\nour rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR\n(model-free) and MoBRAC (model-based) - which substantially outperform\nestablished baselines. Our implementation is publicly available at\nhttps://github.com/EmptyJackson/unifloral.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.RO","published":"2025-04-15T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2504.11454v1","title":"Elucidating the Design Space of Multimodal Protein Language Models","summary":"Multimodal protein language models (PLMs) integrate sequence and token-based\nstructural information, serving as a powerful foundation for protein modeling,\ngeneration, and design. However, the reliance on tokenizing 3D structures into\ndiscrete tokens causes substantial loss of fidelity about fine-grained\nstructural details and correlations. In this paper, we systematically elucidate\nthe design space of multimodal PLMs to overcome their limitations. We identify\ntokenization loss and inaccurate structure token predictions by the PLMs as\nmajor bottlenecks. To address these, our proposed design space covers improved\ngenerative modeling, structure-aware architectures and representation learning,\nand data exploration. Our advancements approach finer-grained supervision,\ndemonstrating that token-based multimodal PLMs can achieve robust structural\nmodeling. The effective design methods dramatically improve the structure\ngeneration diversity, and notably, folding abilities of our 650M model by\nreducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B\nbaselines and on par with the specialized folding models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.QM","published":"2025-04-15T17:59:43Z"}
{"aid":"http://arxiv.org/abs/2504.12610v1","title":"Machine Learning Methods for Gene Regulatory Network Inference","summary":"Gene Regulatory Networks (GRNs) are intricate biological systems that control\ngene expression and regulation in response to environmental and developmental\ncues. Advances in computational biology, coupled with high throughput\nsequencing technologies, have significantly improved the accuracy of GRN\ninference and modeling. Modern approaches increasingly leverage artificial\nintelligence (AI), particularly machine learning techniques including\nsupervised, unsupervised, semi-supervised, and contrastive learning to analyze\nlarge scale omics data and uncover regulatory gene interactions. To support\nboth the application of GRN inference in studying gene regulation and the\ndevelopment of novel machine learning methods, we present a comprehensive\nreview of machine learning based GRN inference methodologies, along with the\ndatasets and evaluation metrics commonly used. Special emphasis is placed on\nthe emerging role of cutting edge deep learning techniques in enhancing\ninference performance. The potential future directions for improving GRN\ninference are also discussed.","main_category":"cs.LG","categories":"cs.LG,q-bio.MN","published":"2025-04-17T03:19:49Z"}
{"aid":"http://arxiv.org/abs/2504.12620v1","title":"Fractional balanced chromatic number of signed subcubic graphs","summary":"A signed graph is a pair $(G,\\sigma)$, where $G$ is a graph and $\\sigma:\nE(G)\\rightarrow \\{-, +\\}$, called signature, is an assignment of signs to the\nedges. Given a signed graph $(G,\\sigma)$ with no negative loops, a balanced\n$(p,q)$-coloring of $(G,\\sigma)$ is an assignment $f$ of $q$ colors to each\nvertex from a pool of $p$ colors such that each color class induces a balanced\nsubgraph, i.e., no negative cycles. Let $(K_4,-)$ be the signed graph on $K_4$\nwith all edges being negative. In this work, we show that every signed (simple)\nsubcubic graph admits a balanced $(5,3)$-coloring except for $(K_4,-)$ and\nsigned graphs switching equivalent to it. For this particular signed graph the\nbest balanced colorings are $(2p,p)$-colorings.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T03:51:29Z"}
{"aid":"http://arxiv.org/abs/2504.12625v1","title":"Spectral Algorithms under Covariate Shift","summary":"Spectral algorithms leverage spectral regularization techniques to analyze\nand process data, providing a flexible framework for addressing supervised\nlearning problems. To deepen our understanding of their performance in\nreal-world scenarios where the distributions of training and test data may\ndiffer, we conduct a rigorous investigation into the convergence behavior of\nspectral algorithms under distribution shifts, specifically within the\nframework of reproducing kernel Hilbert spaces. Our study focuses on the case\nof covariate shift. In this scenario, the marginal distributions of the input\ndata differ between the training and test datasets, while the conditional\ndistribution of the output given the input remains unchanged. Under this\nsetting, we analyze the generalization error of spectral algorithms and show\nthat they achieve minimax optimality when the density ratios between the\ntraining and test distributions are uniformly bounded. However, we also\nidentify a critical limitation: when the density ratios are unbounded, the\nspectral algorithms may become suboptimal. To address this limitation, we\npropose a weighted spectral algorithm that incorporates density ratio\ninformation into the learning process. Our theoretical analysis shows that this\nweighted approach achieves optimal capacity-independent convergence rates.\nFurthermore, by introducing a weight clipping technique, we demonstrate that\nthe convergence rates of the weighted spectral algorithm can approach the\noptimal capacity-dependent convergence rates arbitrarily closely. This\nimprovement resolves the suboptimality issue in unbounded density ratio\nscenarios and advances the state-of-the-art by refining existing theoretical\nresults.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-17T04:02:06Z"}
{"aid":"http://arxiv.org/abs/2504.12631v1","title":"Geometry-preserving Numerical Scheme for Riemannian Stochastic\n  Differential Equations","summary":"Stochastic differential equations (SDEs) on Riemannian manifolds have\nnumerous applications in system identification and control. However,\ngeometry-preserving numerical methods for simulating Riemannian SDEs remain\nrelatively underdeveloped. In this paper, we propose the Exponential\nEuler-Maruyama (Exp-EM) scheme for approximating solutions of SDEs on\nRiemannian manifolds. The Exp-EM scheme is both geometry-preserving and\ncomputationally tractable. We establish a strong convergence rate of\n$\\mathcal{O}(\\delta^{\\frac{1 - \\epsilon}{2}})$ for the Exp-EM scheme, which\nextends previous results obtained for specific manifolds to a more general\nsetting. Numerical simulations are provided to illustrate our theoretical\nfindings.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-17T04:14:00Z"}
{"aid":"http://arxiv.org/abs/2504.12633v1","title":"Towards Characterizing Subjectivity of Individuals through Modeling\n  Value Conflicts and Trade-offs","summary":"Large Language Models (LLMs) not only have solved complex reasoning problems\nbut also exhibit remarkable performance in tasks that require subjective\ndecision making. Existing studies suggest that LLM generations can be\nsubjectively grounded to some extent, yet exploring whether LLMs can account\nfor individual-level subjectivity has not been sufficiently studied. In this\npaper, we characterize subjectivity of individuals on social media and infer\ntheir moral judgments using LLMs. We propose a framework, SOLAR (Subjective\nGround with Value Abstraction), that observes value conflicts and trade-offs in\nthe user-generated texts to better represent subjective ground of individuals.\nEmpirical results show that our framework improves overall inference results as\nwell as performance on controversial situations. Additionally, we qualitatively\nshow that SOLAR provides explanations about individuals' value preferences,\nwhich can further account for their judgments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T04:20:05Z"}
{"aid":"http://arxiv.org/abs/2504.12640v1","title":"On Invariant Conjugate Symmetric Statistical Structures on the Space of\n  Zero-Mean Multivariate Normal Distributions","summary":"By the results of Furuhata--Inoguchi--Kobayashi [Inf. Geom. (2021)] and\nKobayashi--Ohno [Osaka Math. J. (2025)], the Amari--Chentsov\n$\\alpha$-connections on the space $\\mathcal{N}$ of all $n$-variate normal\ndistributions are uniquely characterized by the invariance under the transitive\naction of the affine transformation group among all conjugate symmetric\nstatistical connections with respect to the Fisher metric. In this paper, we\ninvestigate the Amari--Chentsov $\\alpha$-connections on the submanifold\n$\\mathcal{N}_0$ consisting of zero-mean $n$-variate normal distributions. It is\nknown that $\\mathcal{N}_0$ admits a natural transitive action of the general\nlinear group $GL(n,\\mathbb{R})$. We establish a one-to-one correspondence\nbetween the set of $GL(n,\\mathbb{R})$-invariant conjugate symmetric statistical\nconnections on $\\mathcal{N}_0$ with respect to the Fisher metric and the space\nof homogeneous cubic real symmetric polynomials in $n$ variables. As a\nconsequence, if $n \\geq 2$, we show that the Amari--Chentsov\n$\\alpha$-connections on $\\mathcal{N}_0$ are not uniquely characterized by the\ninvariance under the $GL(n,\\mathbb{R})$-action among all conjugate symmetric\nstatistical connections with respect to the Fisher metric. Furthermore, we show\nthat any invariant statistical structure on a Riemannian symmetric space is\nnecessarily conjugate symmetric.","main_category":"math.DG","categories":"math.DG,math.PR","published":"2025-04-17T04:50:35Z"}
{"aid":"http://arxiv.org/abs/2504.12641v1","title":"Hodge Dual Gauge Symmetry in Minimal Einstein-Aether Theory","summary":"Einstein-aether gravity is a theory that breaks the local Lorentz symmetry by\nintroducing a preferred direction via a vector field, which is considered to\nplay the role of an aether. The theory is identified by four coupling constants\nbetween the aether and gravity. Minimal Einstein-aether is the special case in\nwhich only one of the couplings is non-zero. We show that the aether vector\nfield in its minimal version is Hodge dual to a gauge field. The gauge symmetry\nin the dual description has been known for decades and has been used to\nimplement a cosmological constant into the Lagrangian. As a result, solutions\nto the well-established gauge theory can be transferred into the minimal\nEinstein-aether theory straightforwardly. On the other hand, some of the\nproposed solutions to the minimal Einstein-aether theory could be discarded as\npure gauges of the vanishing aether. We prove as a theorem that this holds true\nfor all divergence-less aether fields.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T04:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.12644v1","title":"Quantum Computing Supported Adversarial Attack-Resilient Autonomous\n  Vehicle Perception Module for Traffic Sign Classification","summary":"Deep learning (DL)-based image classification models are essential for\nautonomous vehicle (AV) perception modules since incorrect categorization might\nhave severe repercussions. Adversarial attacks are widely studied cyberattacks\nthat can lead DL models to predict inaccurate output, such as incorrectly\nclassified traffic signs by the perception module of an autonomous vehicle. In\nthis study, we create and compare hybrid classical-quantum deep learning\n(HCQ-DL) models with classical deep learning (C-DL) models to demonstrate\nrobustness against adversarial attacks for perception modules. Before feeding\nthem into the quantum system, we used transfer learning models, alexnet and\nvgg-16, as feature extractors. We tested over 1000 quantum circuits in our\nHCQ-DL models for projected gradient descent (PGD), fast gradient sign attack\n(FGSA), and gradient attack (GA), which are three well-known untargeted\nadversarial approaches. We evaluated the performance of all models during\nadversarial attacks and no-attack scenarios. Our HCQ-DL models maintain\naccuracy above 95\\% during a no-attack scenario and above 91\\% for GA and FGSA\nattacks, which is higher than C-DL models. During the PGD attack, our\nalexnet-based HCQ-DL model maintained an accuracy of 85\\% compared to C-DL\nmodels that achieved accuracies below 21\\%. Our results highlight that the\nHCQ-DL models provide improved accuracy for traffic sign classification under\nadversarial settings compared to their classical counterparts.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR,cs.CV,cs.ET","published":"2025-04-17T05:08:08Z"}
{"aid":"http://arxiv.org/abs/2504.12645v1","title":"High-Time-Cadence Spectroscopy and Photometry of Stellar Flares on\n  M-dwarf YZ Canis Minoris with Seimei Telescope and TESS. II. Statistical\n  Properties of Blue/Red Asymmetries in the H$α$ Line","summary":"M-dwarfs frequently produce flares, and their associated coronal mass\nejections (CMEs) may threaten the habitability of close-in exoplanets. M-dwarf\nflares sometimes show prominence eruption signatures, observed as blue/red\nasymmetries in the H$\\alpha$ line. In Paper I, we reported four candidates of\nprominence eruptions, which shows large diversity in their durations and\nvelocities. In this study, we statistically investigate how blue/red\nasymmetries are related with their flare and starspot properties, using the\ndataset from 27 H$\\alpha$ flares in Paper I and previously reported 8 H$\\alpha$\nflares on an M-dwarf YZ Canis Minoris. We found that these asymmetry events\ntend to show larger H$\\alpha$ flare energies compared to non-asymmetry events.\nIn particular, 5 out of 6 blue asymmetry events are not associated with\nwhite-light flares, whereas all 7 red asymmetry events are associated with\nwhite-light flares. Furthermore, their starspot distributions estimated from\nthe TESS light curve show that all prominence eruption candidates occurred when\nstarspots were located on the stellar disk center as well as on the stellar\nlimb. These results suggest that flares with lower heating rates may have a\nhigher association rate with prominence eruptions and/or the possibility that\nprominence eruptions are more detectable on the limb than on the disk center on\nM-dwarfs. These results provide significant insights into CMEs that can affect\nthe habitable world around M-dwarfs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-17T05:10:20Z"}
{"aid":"http://arxiv.org/abs/2504.12649v1","title":"Extensions of locally matricial and locally semisimple algebras","summary":"Two extension problems are solved. First, the class of locally matricial\nalgebras over an arbitrary field is closed under extensions. Second, the class\nof locally finite dimensional semisimple algebras over a fixed field is closed\nunder extensions if and only if the base field is perfect. Regardless of the\nbase field, extensions of the latter type are always locally unit-regular.","main_category":"math.RA","categories":"math.RA","published":"2025-04-17T05:21:10Z"}
{"aid":"http://arxiv.org/abs/2504.12653v1","title":"Current-driven dynamics of antiferromagnetic domain-wall skyrmions","summary":"Domain-wall skyrmions are magnetic solitons embedded in a domain wall that\nare topologically equivalent to skyrmions. Here, we theoretically study\nantiferromagnetic domain-wall skyrmions and their current-driven motion within\nthe Landau-Lifshitz-Gilbert phenomenology, and verify our findings with\nmicromagnetic simulations. While the skyrmion Hall effect is expected to be\nsuppressed in the current-induced motion of antiferromagnetic domain-wall\nskyrmions, we observe a finite Hall angle, which originates from the\nanisotropic spin configuration of domain-wall skyrmions. The skyrmion Hall\neffect is, however, conditionally suppressed and the motion aligns with the\ncurrent applied in certain directions, which can be interpreted as principal\naxes of a domain-wall skyrmion that is easily identified from the symmetry of\nthe spin configuration. Our work on antiferromagnetic domain-wall skyrmions\nshows that the dynamics of spin textures endowed with multiple soliton\ncharacteristics can be unconventional, which is envisaged to enrich the field\nof topological solitons.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T05:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.12667v1","title":"Two Tasks, One Goal: Uniting Motion and Planning for Excellent End To\n  End Autonomous Driving Performance","summary":"End-to-end autonomous driving has made impressive progress in recent years.\nFormer end-to-end autonomous driving approaches often decouple planning and\nmotion tasks, treating them as separate modules. This separation overlooks the\npotential benefits that planning can gain from learning out-of-distribution\ndata encountered in motion tasks. However, unifying these tasks poses\nsignificant challenges, such as constructing shared contextual representations\nand handling the unobservability of other vehicles' states. To address these\nchallenges, we propose TTOG, a novel two-stage trajectory generation framework.\nIn the first stage, a diverse set of trajectory candidates is generated, while\nthe second stage focuses on refining these candidates through vehicle state\ninformation. To mitigate the issue of unavailable surrounding vehicle states,\nTTOG employs a self-vehicle data-trained state estimator, subsequently extended\nto other vehicles. Furthermore, we introduce ECSA (equivariant context-sharing\nscene adapter) to enhance the generalization of scene representations across\ndifferent agents. Experimental results demonstrate that TTOG achieves\nstate-of-the-art performance across both planning and motion tasks. Notably, on\nthe challenging open-loop nuScenes dataset, TTOG reduces the L2 distance by\n36.06\\%. Furthermore, on the closed-loop Bench2Drive dataset, our approach\nachieves a 22\\% improvement in the driving score (DS), significantly\noutperforming existing baselines.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T05:52:35Z"}
{"aid":"http://arxiv.org/abs/2504.12677v1","title":"Excitation transfer and many-body dark states in WQED","summary":"In one-dimensional waveguide quantum electrodynamics systems, quantum\nemitters interact through infinite-range, dispersive, and dissipative\ndipole-dipole interactions mediated by guided photonic modes. These\ninteractions give rise to long-range periodic behavior and rich many-body\nphysics absent in free space. In this work, we construct a set of symmetrized\nM-excitation dark states and derive analytic expressions for their\ntime-evolution projections. This framework captures the essential dynamics of\nexcitation transport and storage while significantly reducing computational\ncomplexity compared to full quantum simulations. Our analysis reveals a\nfundamental bound on energy redistribution governed by the structure of dark\nstates and collective dissipation, and discovers that optimal excitation\ntransfer between emitter ensembles converges toward an initial pumped fraction\nof $N_\\text{p}/N \\approx 0.55$ for large system sizes. We further examine the\nrobustness of this mechanism under realistic imperfections, including\npositional disorder, nonradiative decay, and dephasing. These results highlight\nthe role of many-body dark states in enabling efficient and controllable energy\ntransfer, offering new insights into dissipative many-body dynamics in\nintegrated quantum platforms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T06:07:22Z"}
{"aid":"http://arxiv.org/abs/2504.12678v1","title":"A Genetic Approach to Gradient-Free Kinodynamic Planning in Uneven\n  Terrains","summary":"This paper proposes a genetic algorithm-based kinodynamic planning algorithm\n(GAKD) for car-like vehicles navigating uneven terrains modeled as triangular\nmeshes. The algorithm's distinct feature is trajectory optimization over a\nfixed-length receding horizon using a genetic algorithm with heuristic-based\nmutation, ensuring the vehicle's controls remain within its valid operational\nrange. By addressing challenges posed by uneven terrain meshes, such as\nchanging face normals, GAKD offers a practical solution for path planning in\ncomplex environments. Comparative evaluations against Model Predictive Path\nIntegral (MPPI) and log-MPPI methods show that GAKD achieves up to 20 percent\nimprovement in traversability cost while maintaining comparable path length.\nThese results demonstrate GAKD's potential in improving vehicle navigation on\nchallenging terrains.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T06:11:31Z"}
{"aid":"http://arxiv.org/abs/2504.12683v1","title":"Cluster weighted models with multivariate skewed distributions for\n  functional data","summary":"We propose a clustering method, funWeightClustSkew, based on mixtures of\nfunctional linear regression models and three skewed multivariate\ndistributions: the variance-gamma distribution, the skew-t distribution, and\nthe normal-inverse Gaussian distribution. Our approach follows the framework of\nthe functional high dimensional data clustering (funHDDC) method, and we extend\nto functional data the cluster weighted models based on skewed distributions\nused for finite dimensional multivariate data. We consider several parsimonious\nmodels, and to estimate the parameters we construct an expectation maximization\n(EM) algorithm. We illustrate the performance of funWeightClustSkew for\nsimulated data and for the Air Quality dataset.","main_category":"stat.ME","categories":"stat.ME,cs.LG,stat.ML","published":"2025-04-17T06:17:06Z"}
{"aid":"http://arxiv.org/abs/2504.12689v1","title":"HSS-IAD: A Heterogeneous Same-Sort Industrial Anomaly Detection Dataset","summary":"Multi-class Unsupervised Anomaly Detection algorithms (MUAD) are receiving\nincreasing attention due to their relatively low deployment costs and improved\ntraining efficiency. However, the real-world effectiveness of MUAD methods is\nquestioned due to limitations in current Industrial Anomaly Detection (IAD)\ndatasets. These datasets contain numerous classes that are unlikely to be\nproduced by the same factory and fail to cover multiple structures or\nappearances. Additionally, the defects do not reflect real-world\ncharacteristics. Therefore, we introduce the Heterogeneous Same-Sort Industrial\nAnomaly Detection (HSS-IAD) dataset, which contains 8,580 images of\nmetallic-like industrial parts and precise anomaly annotations. These parts\nexhibit variations in structure and appearance, with subtle defects that\nclosely resemble the base materials. We also provide foreground images for\nsynthetic anomaly generation. Finally, we evaluate popular IAD methods on this\ndataset under multi-class and class-separated settings, demonstrating its\npotential to bridge the gap between existing datasets and real factory\nconditions. The dataset is available at\nhttps://github.com/Qiqigeww/HSS-IAD-Dataset.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:31:26Z"}
{"aid":"http://arxiv.org/abs/2504.12691v1","title":"Why and How LLMs Hallucinate: Connecting the Dots with Subsequence\n  Associations","summary":"Large language models (LLMs) frequently generate hallucinations-content that\ndeviates from factual accuracy or provided context-posing challenges for\ndiagnosis due to the complex interplay of underlying causes. This paper\nintroduces a subsequence association framework to systematically trace and\nunderstand hallucinations. Our key insight is that hallucinations arise when\ndominant hallucinatory associations outweigh faithful ones. Through theoretical\nand empirical analyses, we demonstrate that decoder-only transformers\neffectively function as subsequence embedding models, with linear layers\nencoding input-output associations. We propose a tracing algorithm that\nidentifies causal subsequences by analyzing hallucination probabilities across\nrandomized input contexts. Experiments show our method outperforms standard\nattribution techniques in identifying hallucination causes and aligns with\nevidence from the model's training corpus. This work provides a unified\nperspective on hallucinations and a robust framework for their tracing and\nanalysis.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T06:34:45Z"}
{"aid":"http://arxiv.org/abs/2504.12707v1","title":"On what finitely generated (left-orderable) simple groups can know about\n  their subgroups","summary":"In this paper, we survey some of the recent advances on embeddings into\nfinitely generated (left-orderable) simple group such that the overgroup\npreserves algorithmic, geometric, or algebraic information about the embedded\ngroup. We discuss some new consequences and also extend some of those embedding\ntheorems to countable classes of finitely generated groups.","main_category":"math.GR","categories":"math.GR","published":"2025-04-17T07:25:31Z"}
{"aid":"http://arxiv.org/abs/2504.12713v1","title":"Efficient Primal-dual Forward-backward Splitting Method for\n  Wasserstein-like Gradient Flows with General Nonlinear Mobilities","summary":"We construct an efficient primal-dual forward-backward (PDFB) splitting\nmethod for computing a class of minimizing movement schemes with nonlinear\nmobility transport distances, and apply it to computing Wasserstein-like\ngradient flows. This approach introduces a novel saddle point formulation for\nthe minimizing movement schemes, leveraging a support function form from the\nBenamou-Brenier dynamical formulation of optimal transport. The resulting\nframework allows for flexible computation of Wasserstein-like gradient flows by\nsolving the corresponding saddle point problem at the fully discrete level, and\ncan be easily extended to handle general nonlinear mobilities. We also provide\na detailed convergence analysis of the PDFB splitting method, along with\npractical remarks on its implementation and application. The effectiveness of\nthe method is demonstrated through several challenging numerical examples.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-17T07:37:08Z"}
{"aid":"http://arxiv.org/abs/2504.12715v1","title":"Hierarchical Vector Quantized Graph Autoencoder with Annealing-Based\n  Code Selection","summary":"Graph self-supervised learning has gained significant attention recently.\nHowever, many existing approaches heavily depend on perturbations, and\ninappropriate perturbations may corrupt the graph's inherent information. The\nVector Quantized Variational Autoencoder (VQ-VAE) is a powerful autoencoder\nextensively used in fields such as computer vision; however, its application to\ngraph data remains underexplored. In this paper, we provide an empirical\nanalysis of vector quantization in the context of graph autoencoders,\ndemonstrating its significant enhancement of the model's capacity to capture\ngraph topology. Furthermore, we identify two key challenges associated with\nvector quantization when applying in graph data: codebook underutilization and\ncodebook space sparsity. For the first challenge, we propose an annealing-based\nencoding strategy that promotes broad code utilization in the early stages of\ntraining, gradually shifting focus toward the most effective codes as training\nprogresses. For the second challenge, we introduce a hierarchical two-layer\ncodebook that captures relationships between embeddings through clustering. The\nsecond layer codebook links similar codes, encouraging the model to learn\ncloser embeddings for nodes with similar features and structural topology in\nthe graph. Our proposed model outperforms 16 representative baseline methods in\nself-supervised link prediction and node classification tasks across multiple\ndatasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T07:43:52Z"}
{"aid":"http://arxiv.org/abs/2504.12718v1","title":"TUMLS: Trustful Fully Unsupervised Multi-Level Segmentation for Whole\n  Slide Images of Histology","summary":"Digital pathology, augmented by artificial intelligence (AI), holds\nsignificant promise for improving the workflow of pathologists. However,\nchallenges such as the labor-intensive annotation of whole slide images (WSIs),\nhigh computational demands, and trust concerns arising from the absence of\nuncertainty estimation in predictions hinder the practical application of\ncurrent AI methodologies in histopathology. To address these issues, we present\na novel trustful fully unsupervised multi-level segmentation methodology\n(TUMLS) for WSIs. TUMLS adopts an autoencoder (AE) as a feature extractor to\nidentify the different tissue types within low-resolution training data. It\nselects representative patches from each identified group based on an\nuncertainty measure and then does unsupervised nuclei segmentation in their\nrespective higher-resolution space without using any ML algorithms. Crucially,\nthis solution integrates seamlessly into clinicians workflows, transforming the\nexamination of a whole WSI into a review of concise, interpretable cross-level\ninsights. This integration significantly enhances and accelerates the workflow\nwhile ensuring transparency. We evaluated our approach using the UPENN-GBM\ndataset, where the AE achieved a mean squared error (MSE) of 0.0016.\nAdditionally, nucleus segmentation is assessed on the MoNuSeg dataset,\noutperforming all unsupervised approaches with an F1 score of 77.46% and a\nJaccard score of 63.35%. These results demonstrate the efficacy of TUMLS in\nadvancing the field of digital pathology.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-17T07:48:05Z"}
{"aid":"http://arxiv.org/abs/2504.12721v1","title":"TimeCapsule: Solving the Jigsaw Puzzle of Long-Term Time Series\n  Forecasting with Compressed Predictive Representations","summary":"Recent deep learning models for Long-term Time Series Forecasting (LTSF)\noften emphasize complex, handcrafted designs, while simpler architectures like\nlinear models or MLPs have often outperformed these intricate solutions. In\nthis paper, we revisit and organize the core ideas behind several key\ntechniques, such as redundancy reduction and multi-scale modeling, which are\nfrequently employed in advanced LTSF models. Our goal is to streamline these\nideas for more efficient deep learning utilization. To this end, we introduce\nTimeCapsule, a model built around the principle of high-dimensional information\ncompression that unifies these techniques in a generalized yet simplified\nframework. Specifically, we model time series as a 3D tensor, incorporating\ntemporal, variate, and level dimensions, and leverage mode production to\ncapture multi-mode dependencies while achieving dimensionality compression. We\npropose an internal forecast within the compressed representation domain,\nsupported by the Joint-Embedding Predictive Architecture (JEPA), to monitor the\nlearning of predictive representations. Extensive experiments on challenging\nbenchmarks demonstrate the versatility of our method, showing that TimeCapsule\ncan achieve state-of-the-art performance.","main_category":"cs.LG","categories":"cs.LG,cs.AI,eess.SP","published":"2025-04-17T07:54:26Z"}
{"aid":"http://arxiv.org/abs/2504.12733v1","title":"Adversary-Augmented Simulation for Fairness Evaluation and Defense in\n  Hyperledger Fabric","summary":"This paper presents an adversary model and a simulation framework\nspecifically tailored for analyzing attacks on distributed systems composed of\nmultiple distributed protocols, with a focus on assessing the security of\nblockchain networks. Our model classifies and constrains adversarial actions\nbased on the assumptions of the target protocols, defined by failure models,\ncommunication models, and the fault tolerance thresholds of Byzantine Fault\nTolerant (BFT) protocols. The goal is to study not only the intended effects of\nadversarial strategies but also their unintended side effects on critical\nsystem properties. We apply this framework to analyze fairness properties in a\nHyperledger Fabric (HF) blockchain network. Our focus is on novel fairness\nattacks that involve coordinated adversarial actions across various HF\nservices. Simulations show that even a constrained adversary can violate\nfairness with respect to specific clients (client fairness) and impact related\nguarantees (order fairness), which relate the reception order of transactions\nto their final order in the blockchain. This paper significantly extends our\nprevious work by introducing and evaluating a mitigation mechanism specifically\ndesigned to counter transaction reordering attacks. We implement and integrate\nthis defense into our simulation environment, demonstrating its effectiveness\nunder diverse conditions.","main_category":"cs.CR","categories":"cs.CR,cs.DC,cs.MA","published":"2025-04-17T08:17:27Z"}
{"aid":"http://arxiv.org/abs/2504.12740v1","title":"GPMFS: Global Foundation and Personalized Optimization for Multi-Label\n  Feature Selection","summary":"As artificial intelligence methods are increasingly applied to complex task\nscenarios, high dimensional multi-label learning has emerged as a prominent\nresearch focus. At present, the curse of dimensionality remains one of the\nmajor bottlenecks in high-dimensional multi-label learning, which can be\neffectively addressed through multi-label feature selection methods. However,\nexisting multi-label feature selection methods mostly focus on identifying\nglobal features shared across all labels, which overlooks personalized\ncharacteristics and specific requirements of individual labels. This\nglobal-only perspective may limit the ability to capture label-specific\ndiscriminative information, thereby affecting overall performance. In this\npaper, we propose a novel method called GPMFS (Global Foundation and\nPersonalized Optimization for Multi-Label Feature Selection). GPMFS firstly\nidentifies global features by exploiting label correlations, then adaptively\nsupplements each label with a personalized subset of discriminative features\nusing a threshold-controlled strategy. Experiments on multiple real-world\ndatasets demonstrate that GPMFS achieves superior performance while maintaining\nstrong interpretability and robustness. Furthermore, GPMFS provides insights\ninto the label-specific strength across different multi-label datasets, thereby\ndemonstrating the necessity and potential applicability of personalized feature\nselection approaches.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-17T08:29:14Z"}
{"aid":"http://arxiv.org/abs/2504.12753v1","title":"Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges\n  Domain Generalized Semantic Segmentation","summary":"Vision Foundation Models (VFMs) have delivered remarkable performance in\nDomain Generalized Semantic Segmentation (DGSS). However, recent methods often\noverlook the fact that visual cues are susceptible, whereas the underlying\ngeometry remains stable, rendering depth information more robust. In this\npaper, we investigate the potential of integrating depth information with\nfeatures from VFMs, to improve the geometric consistency within an image and\nboost the generalization performance of VFMs. We propose a novel fine-tuning\nDGSS framework, named DepthForge, which integrates the visual cues from frozen\nDINOv2 or EVA02 and depth cues from frozen Depth Anything V2. In each layer of\nthe VFMs, we incorporate depth-aware learnable tokens to continuously decouple\ndomain-invariant visual and spatial information, thereby enhancing depth\nawareness and attention of the VFMs. Finally, we develop a depth refinement\ndecoder and integrate it into the model architecture to adaptively refine\nmulti-layer VFM features and depth-aware learnable tokens. Extensive\nexperiments are conducted based on various DGSS settings and five different\ndatsets as unseen target domains. The qualitative and quantitative results\ndemonstrate that our method significantly outperforms alternative approaches\nwith stronger performance, steadier visual-spatial attention, and superior\ngeneralization ability. In particular, DepthForge exhibits outstanding\nperformance under extreme conditions (e.g., night and snow). Code is available\nat https://github.com/anonymouse-xzrptkvyqc/DepthForge.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:45:33Z"}
{"aid":"http://arxiv.org/abs/2504.12758v1","title":"Universal Approximation with XL MIMO Systems: OTA Classification via\n  Trainable Analog Combining","summary":"In this paper, we demonstrate that an eXtremely Large (XL) Multiple-Input\nMultiple-Output (MIMO) wireless system with appropriate analog combining\ncomponents exhibits the properties of a universal function approximator,\nsimilar to a feedforward neural network. By treating the XL MIMO channel\ncoefficients as the random nodes of a hidden layer, and the receiver's analog\ncombiner as a trainable output layer, we cast the end-to-end system to the\nExtreme Learning Machine (ELM) framework, leading to a novel formulation for\nOver-The-Air (OTA) edge inference without requiring traditional digital\nprocessing nor pre-processing at the transmitter. Through theoretical analysis\nand numerical evaluation, we showcase that XL-MIMO-ELM enables\nnear-instantaneous training and efficient classification, suggesting the\nparadigm shift of beyond massive MIMO systems as neural networks alongside\ntheir profound communications role. Compared to deep learning approaches and\nconventional ELMs, the proposed framework achieves on par performance with\norders of magnitude lower complexity, making it highly attractive for ultra low\npower wireless devices.","main_category":"eess.SP","categories":"eess.SP,cs.LG","published":"2025-04-17T08:53:30Z"}
{"aid":"http://arxiv.org/abs/2504.12759v1","title":"Perturbed Proximal Gradient ADMM for Nonconvex Composite Optimization","summary":"This paper proposes a Perturbed Proximal Gradient ADMM (PPG-ADMM) framework\nfor solving general nonconvex composite optimization problems, where the\nobjective function consists of a smooth nonconvex term and a nonsmooth weakly\nconvex term for both primal variables.\n  Unlike existing ADMM-based methods which necessitate the function associated\nwith the last updated primal variable to be smooth, the proposed PPG-ADMM\nremoves this restriction by introducing a perturbation mechanism, which also\nhelps reduce oscillations in the primal-dual updates, thereby improving\nconvergence stability.\n  By employing a linearization technique for the smooth term and the proximal\noperator for the nonsmooth and weakly convex term, the subproblems have\nclosed-form solutions, significantly reducing computational complexity. The\nconvergence is established through a technically constructed Lyapunov function,\nwhich guarantees sufficient descent and has a well-defined lower bound.\n  With properly chosen parameters, PPG-ADMM converges to an\n$\\epsilon$-approximate stationary point at a sublinear convergence rate of\n$\\mathcal{O}(1/\\sqrt{K})$.\n  Furthermore, by appropriately tuning the perturbation parameter $\\beta$, it\nachieves an $\\epsilon$-stationary point, providing stronger optimality\nguarantees. We further apply PPG-ADMM to two practical distributed nonconvex\ncomposite optimization problems, i.e., the distributed partial consensus\nproblem and the resource allocation problem. The algorithm operates in a fully\ndecentralized manner without a central coordinating node. Finally, numerical\nexperiments validate the effectiveness of PPG-ADMM, demonstrating its improved\nconvergence performance.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T08:55:42Z"}
{"aid":"http://arxiv.org/abs/2504.12765v1","title":"Distributed Intelligent Sensing and Communications for 6G: Architecture\n  and Use Cases","summary":"The Distributed Intelligent Sensing and Communication (DISAC) framework\nredefines Integrated Sensing and Communication (ISAC) for 6G by leveraging\ndistributed architectures to enhance scalability, adaptability, and resource\nefficiency. This paper presents key architectural enablers, including advanced\ndata representation, seamless target handover, support for heterogeneous\ndevices, and semantic integration. Two use cases illustrate the transformative\npotential of DISAC: smart factory shop floors and Vulnerable Road User (VRU)\nprotection at smart intersections. These scenarios demonstrate significant\nimprovements in precision, safety, and operational efficiency compared to\ntraditional ISAC systems. The preliminary DISAC architecture incorporates\nintelligent data processing, distributed coordination, and emerging\ntechnologies such as Reconfigurable Intelligent Surfaces (RIS) to meet 6G's\nstringent requirements. By addressing critical challenges in sensing accuracy,\nlatency, and real-time decision-making, DISAC positions itself as a cornerstone\nfor next-generation wireless networks, advancing innovation in dynamic and\ncomplex environments.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T09:02:36Z"}
{"aid":"http://arxiv.org/abs/2504.12766v1","title":"Falcon: Advancing Asynchronous BFT Consensus for Lower Latency and\n  Enhanced Throughput","summary":"Asynchronous Byzantine Fault Tolerant (BFT) consensus protocols have garnered\nsignificant attention with the rise of blockchain technology. A typical\nasynchronous protocol is designed by executing sequential instances of the\nAsynchronous Common Sub-seQuence (ACSQ). The ACSQ protocol consists of two\nprimary components: the Asynchronous Common Subset (ACS) protocol and a block\nsorting mechanism, with the ACS protocol comprising two stages: broadcast and\nagreement. However, current protocols encounter three critical issues: high\nlatency arising from the execution of the agreement stage, latency instability\ndue to the integral-sorting mechanism, and reduced throughput caused by block\ndiscarding. To address these issues,we propose Falcon, an asynchronous BFT\nprotocol that achieves low latency and enhanced throughput. Falcon introduces a\nnovel broadcast protocol, Graded Broadcast (GBC), which enables a block to be\nincluded in the ACS set directly, bypassing the agreement stage and thereby\nreducing latency. To ensure safety, Falcon incorporates a new binary agreement\nprotocol called Asymmetrical Asynchronous Binary Agreement (AABA), designed to\ncomplement GBC. Additionally, Falcon employs a partial-sorting mechanism,\nallowing continuous rather than simultaneous block committing, enhancing\nlatency stability. Finally, we incorporate an agreement trigger that, before\nits activation, enables nodes to wait for more blocks to be delivered and\ncommitted, thereby boosting throughput. We conduct a series of experiments to\nevaluate Falcon, demonstrating its superior performance.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-17T09:03:55Z"}
{"aid":"http://arxiv.org/abs/2504.12770v1","title":"Comparative Analysis of POX and RYU SDN Controllers in Scalable Networks","summary":"This paper explores the Quality of Service (QoS) performance of two widely\nused Software-Defined Networking (SDN) controllers, POX and Ryu, using Mininet\nfor network simulation. SDN, a transformative approach to network architecture,\nseparates the control and data planes, enabling centralized management,\nimproved agility, and cost-effective solutions. The study evaluates key QoS\nparameters, including throughput, delay, and jitter, to understand the\ncapabilities and limitations of the POX and Ryu controllers in handling traffic\nunder diverse network topologies. The research employs a systematic methodology\ninvolving the design of custom network topologies, implementation of OpenFlow\nrules, and analysis of controller behavior under simulated conditions. Results\nreveal that while POX offers simplicity and ease of use, making it suitable for\nsmaller-scale applications and experimentation, Ryu provides superior\nscalability and adaptability for more complex network environments. The\nfindings highlight the strengths and challenges of each controller, providing\nvaluable insights for organizations seeking to optimize SDN deployment. This\nstudy contributes to the growing body of knowledge on SDN technologies and\ntheir role in building scalable, efficient, and resilient network\ninfrastructures.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-17T09:09:56Z"}
{"aid":"http://arxiv.org/abs/2504.12782v1","title":"Set You Straight: Auto-Steering Denoising Trajectories to Sidestep\n  Unwanted Concepts","summary":"Ensuring the ethical deployment of text-to-image models requires effective\ntechniques to prevent the generation of harmful or inappropriate content. While\nconcept erasure methods offer a promising solution, existing finetuning-based\napproaches suffer from notable limitations. Anchor-free methods risk disrupting\nsampling trajectories, leading to visual artifacts, while anchor-based methods\nrely on the heuristic selection of anchor concepts. To overcome these\nshortcomings, we introduce a finetuning framework, dubbed ANT, which\nAutomatically guides deNoising Trajectories to avoid unwanted concepts. ANT is\nbuilt on a key insight: reversing the condition direction of classifier-free\nguidance during mid-to-late denoising stages enables precise content\nmodification without sacrificing early-stage structural integrity. This\ninspires a trajectory-aware objective that preserves the integrity of the\nearly-stage score function field, which steers samples toward the natural image\nmanifold, without relying on heuristic anchor concept selection. For\nsingle-concept erasure, we propose an augmentation-enhanced weight saliency map\nto precisely identify the critical parameters that most significantly\ncontribute to the unwanted concept, enabling more thorough and efficient\nerasure. For multi-concept erasure, our objective function offers a versatile\nplug-and-play solution that significantly boosts performance. Extensive\nexperiments demonstrate that ANT achieves state-of-the-art results in both\nsingle and multi-concept erasure, delivering high-quality, safe outputs without\ncompromising the generative fidelity. Code is available at\nhttps://github.com/lileyang1210/ANT","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR,cs.LG","published":"2025-04-17T09:29:30Z"}
{"aid":"http://arxiv.org/abs/2504.12788v1","title":"ARAP-GS: Drag-driven As-Rigid-As-Possible 3D Gaussian Splatting Editing\n  with Diffusion Prior","summary":"Drag-driven editing has become popular among designers for its ability to\nmodify complex geometric structures through simple and intuitive manipulation,\nallowing users to adjust and reshape content with minimal technical skill. This\ndrag operation has been incorporated into numerous methods to facilitate the\nediting of 2D images and 3D meshes in design. However, few studies have\nexplored drag-driven editing for the widely-used 3D Gaussian Splatting (3DGS)\nrepresentation, as deforming 3DGS while preserving shape coherence and visual\ncontinuity remains challenging. In this paper, we introduce ARAP-GS, a\ndrag-driven 3DGS editing framework based on As-Rigid-As-Possible (ARAP)\ndeformation. Unlike previous 3DGS editing methods, we are the first to apply\nARAP deformation directly to 3D Gaussians, enabling flexible, drag-driven\ngeometric transformations. To preserve scene appearance after deformation, we\nincorporate an advanced diffusion prior for image super-resolution within our\niterative optimization process. This approach enhances visual quality while\nmaintaining multi-view consistency in the edited results. Experiments show that\nARAP-GS outperforms current methods across diverse 3D scenes, demonstrating its\neffectiveness and superiority for drag-driven 3DGS editing. Additionally, our\nmethod is highly efficient, requiring only 10 to 20 minutes to edit a scene on\na single RTX 3090 GPU.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T09:37:11Z"}
{"aid":"http://arxiv.org/abs/2504.12790v1","title":"Empirically Evaluating the Use of Bytecode for Diversity-Based Test Case\n  Prioritisation","summary":"Regression testing assures software correctness after changes but is\nresource-intensive. Test Case Prioritisation (TCP) mitigates this by ordering\ntests to maximise early fault detection. Diversity-based TCP prioritises\ndissimilar tests, assuming they exercise different system parts and uncover\nmore faults. Traditional static diversity-based TCP approaches (i.e., methods\nthat utilise the dissimilarity of tests), like the state-of-the-art FAST\napproach, rely on textual diversity from test source code, which is effective\nbut inefficient due to its relative verbosity and redundancies affecting\nsimilarity calculations. This paper is the first to study bytecode as the basis\nof diversity in TCP, leveraging its compactness for improved efficiency and\naccuracy. An empirical study on seven Defects4J projects shows that bytecode\ndiversity improves fault detection by 2.3-7.8% over text-based TCP. It is also\n2-3 orders of magnitude faster in one TCP approach and 2.5-6 times faster in\nFAST-based TCP. Filtering specific bytecode instructions improves efficiency up\nto fourfold while maintaining effectiveness, making bytecode diversity a\nsuperior static approach.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T09:40:49Z"}
{"aid":"http://arxiv.org/abs/2504.12808v1","title":"Coupling a vertex algebra to a large center","summary":"Suppose a Lie group $G$ acts on a vertex algebra $V$. In this article we\nconstruct a vertex algebra $\\tilde{V}$, which is an extension of $V$ by a big\ncentral vertex subalgebra identified with the algebra of functionals on the\nspace of regular $\\mathfrak{g}$-connections $(d+A)$.\n  The category of representations of $\\tilde{V}$ fibres over the set of\nconnections, and the fibres should be viewed as $(d+A)$-twisted modules of $V$,\ngeneralizing the familiar notion of $g$-twisted modules. In fact, another\napplication of our result is that it proposes an explicit definition of\n$(d+A)$-twisted modules of $V$ in terms of a twisted commutator formula, and we\nfeel that this subject should be pursued further.\n  Vertex algebras with big centers appear in practice as critical level or\nlarge level limits of vertex algebras. I particular we have in mind limits of\nthe generalized quantum Langlands kernel, in which case $G$ is the Langland\ndual and $V$ is conjecturally the Feigin-Tipunin vertex algebra and the\nextension $\\tilde{V}$ is conjecturally related to the Kac-DeConcini-Procesi\nquantum group with big center. With the current article, we can give a uniform\nand independent construction of these limits.","main_category":"math.QA","categories":"math.QA,hep-th","published":"2025-04-17T10:14:12Z"}
{"aid":"http://arxiv.org/abs/2504.12812v1","title":"SoK: Security of EMV Contactless Payment Systems","summary":"The widespread adoption of EMV (Europay, Mastercard, and Visa) contactless\npayment systems has greatly improved convenience for both users and merchants.\nHowever, this growth has also exposed significant security challenges. This SoK\nprovides a comprehensive analysis of security vulnerabilities in EMV\ncontactless payments, particularly within the open-loop systems used by Visa\nand Mastercard. We categorize attacks into seven attack vectors across three\nkey areas: application selection, cardholder authentication, and transaction\nauthorization. We replicate the attacks on Visa and Mastercard protocols using\nour experimental platform to determine their practical feasibility and offer\ninsights into the current security landscape of contactless payments. Our study\nalso includes a detailed evaluation of the underlying protocols, along with a\ncomparative analysis of Visa and Mastercard, highlighting vulnerabilities and\nrecommending countermeasures.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-17T10:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.12814v1","title":"Integral control of the proximal gradient method for unbiased sparse\n  optimization","summary":"Proximal gradient methods are popular in sparse optimization as they are\nstraightforward to implement. Nevertheless, they achieve biased solutions,\nrequiring many iterations to converge. This work addresses these issues through\na suitable feedback control of the algorithm's hyperparameter. Specifically, by\ndesigning an integral control that does not substantially impact the\ncomputational complexity, we can reach an unbiased solution in a reasonable\nnumber of iterations. In the paper, we develop and analyze the convergence of\nthe proposed approach for strongly-convex problems. Moreover, numerical\nsimulations validate and extend the theoretical results to the non-strongly\nconvex framework.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-17T10:17:32Z"}
{"aid":"http://arxiv.org/abs/2504.12820v1","title":"Skewness as a Probe of Gravity: Real and Redshift Space Counts-In-Cells","summary":"We study the counts-in-cells reduced skewness $s_3$ for dark matter, halo,\nand galaxy distributions in both real and redshift space, using the ELEPHANT\n($\\textit{Extended LEnsing PHysics with ANalytical ray Tracing}$) suite of\n$N$-body simulations. We compare General Relativity (GR) with two extended (EG)\ngravity models: $f(R)$ gravity with chameleon screening and the normal-branch\nDvali-Gabadadze-Porrati (nDGP) model with Vainshtein screening. We quantify the\nsuppression of $s_3$ by redshift-space distortions (RSD), finding that while\nsmall-scale skewness is strongly reduced, the $F5$ model retains a $\\sim 4\\%$\ndeviation from GR in galaxy samples, corresponding to a $2\\sigma$ significance.\nWe show that the ratio $s_3^{\\mathrm{RSD}}/s_3^{\\mathrm{real}}$ is\napproximately independent of the gravity model across tracers and redshifts.\nOur results demonstrate that real-space predictions can help reliably infer\nredshift-space skewness in both GR and extended gravity, providing a new tool\nfor testing gravity with current and forthcoming galaxy redshift surveys.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-17T10:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.12821v1","title":"Revisiting the Haken Lighthouse Model","summary":"Simple spiking neural network models, such as those built from interacting\nintegrate-and-fire (IF) units, exhibit rich emergent behaviours but remain\nnotoriously difficult to analyse, particularly in terms of their\npattern-forming properties. In contrast, rate-based models and coupled phase\noscillators offer greater mathematical tractability but fail to capture the\nfull dynamical complexity of spiking networks. To bridge these modelling\nparadigms, Hermann Haken -- the pioneer of Synergetics -- introduced the\nLighthouse model, a framework that provides insights into synchronisation,\ntravelling waves, and pattern formation in neural systems.\n  In this work, we revisit the Lighthouse model and develop new mathematical\nresults that deepen our understanding of self-organisation in spiking neural\nnetworks. Specifically, we derive the linear stability conditions for\nphase-locked spiking states in Lighthouse networks structured on graphs with\nrealistic synaptic interactions ($\\alpha$-function synapses) and axonal\nconduction delays. Extending the analysis on graphs to a spatially continuous\n(non-local) setting, we develop a variant of Turing instability analysis to\nexplore emergent spiking patterns. Finally, we show how localised spiking bump\nsolutions -- which are difficult to mathematically analyse in IF networks --\nare far more tractable in the Lighthouse model and analyse their linear\nstability to wandering states.\n  These results reaffirm the Lighthouse model as a valuable tool for studying\nstructured neural interactions and self-organisation, further advancing the\nsynergetic perspective on spiking neural dynamics.","main_category":"math.DS","categories":"math.DS","published":"2025-04-17T10:26:06Z"}
{"aid":"http://arxiv.org/abs/2504.12824v1","title":"Mixed Structural Choice Operator: Enhancing Technology Mapping with\n  Heterogeneous Representations","summary":"The independence of logic optimization and technology mapping poses a\nsignificant challenge in achieving high-quality synthesis results. Recent\nstudies have improved optimization outcomes through collaborative optimization\nof multiple logic representations and have improved structural bias through\nstructural choices. However, these methods still rely on technology-independent\noptimization and fail to truly resolve structural bias issues. This paper\nproposes a scalable and efficient framework based on Mixed Structural Choices\n(MCH). This is a novel heterogeneous mapping method that combines multiple\nlogic representations with technology-aware optimization. MCH flexibly\nintegrates different logic representations and stores candidates for various\noptimization strategies. By comprehensively evaluating the technology costs of\nthese candidates, it enhances technology mapping and addresses structural bias\nissues in logic synthesis. Notably, the MCH-based lookup table (LUT) mapping\nalgorithm set new records in the EPFL Best Results Challenge by combining the\nstructural strengths of both And-Inverter Graph (AIG) and XOR-Majority Graph\n(XMG) logic representations. Additionally, MCH-based ASIC technology mapping\nachieves a 3.73% area and 8.94% delay reduction (balanced), 20.35% delay\nreduction (delay-oriented), and 21.02% area reduction (area-oriented),\noutperforming traditional structural choice methods. Furthermore, MCH-based\nlogic optimization utilizes diverse structures to surpass local optima and\nachieve better results.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-17T10:34:52Z"}
{"aid":"http://arxiv.org/abs/2504.12827v1","title":"Direct Sum of Lower Semi-Frames in Hilbert Spaces","summary":"In this paper, structural properties of lower semi-frames in separable\nHilbert spaces are explored with a focus on transformations under linear\noperators (may be unbounded). Also, the direct sum of lower semi-frames,\nproviding necessary and sufficient conditions for the preservation of lower\nsemi-frame structure, is examined.","main_category":"math.FA","categories":"math.FA","published":"2025-04-17T10:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.12833v1","title":"Image-Editing Specialists: An RLAIF Approach for Diffusion Models","summary":"We present a novel approach to training specialized instruction-based\nimage-editing diffusion models, addressing key challenges in structural\npreservation with input images and semantic alignment with user prompts. We\nintroduce an online reinforcement learning framework that aligns the diffusion\nmodel with human preferences without relying on extensive human annotations or\ncurating a large dataset. Our method significantly improves the realism and\nalignment with instructions in two ways. First, the proposed models achieve\nprecise and structurally coherent modifications in complex scenes while\nmaintaining high fidelity in instruction-irrelevant areas. Second, they capture\nfine nuances in the desired edit by leveraging a visual prompt, enabling\ndetailed control over visual edits without lengthy textual prompts. This\napproach simplifies users' efforts to achieve highly specific edits, requiring\nonly 5 reference images depicting a certain concept for training. Experimental\nresults demonstrate that our models can perform intricate edits in complex\nscenes, after just 10 training steps. Finally, we showcase the versatility of\nour method by applying it to robotics, where enhancing the visual realism of\nsimulated environments through targeted sim-to-real image edits improves their\nutility as proxies for real-world settings.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-17T10:46:39Z"}
{"aid":"http://arxiv.org/abs/2504.12848v1","title":"Scattering of a Dirac particle by a Berry phase domain wall","summary":"Massless Dirac particles are characterized by an effective\npseudospin-momentum locking, which is the origin of the peculiar scattering\nproperties of Dirac particles through potential barriers. This\npseudospin-momentum locking also governs the quantum geometric properties (such\nas the Berry phase and Berry curvature) of Dirac particles. In the present\nwork, we demonstrate that a domain wall separating two regions with distinct\nquantum geometric properties can serve as an alternative to potential barriers.\nSpecifically, using the three-band $\\alpha-T_3$ model of two-dimensional Dirac\nparticles, we show that a Berry phase domain wall results in partial reflection\nand transmission of the Dirac particles, despite the fact that the incident and\nrefracted momenta are identical.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T11:08:30Z"}
{"aid":"http://arxiv.org/abs/2504.12865v1","title":"DashChat: Interactive Authoring of Industrial Dashboard Design\n  Prototypes through Conversation with LLM-Powered Agents","summary":"Industrial dashboards, commonly deployed by organizations such as enterprises\nand governments, are increasingly crucial in data communication and\ndecision-making support across various domains. Designing an industrial\ndashboard prototype is particularly challenging due to its visual complexity,\nwhich can include data visualization, layout configuration, embellishments, and\nanimations. Additionally, in real-world industrial settings, designers often\nencounter numerous constraints. For instance, when companies negotiate\ncollaborations with clients and determine design plans, they typically need to\ndemo design prototypes and iterate on them based on mock data quickly. Such a\ntask is very common and crucial during the ideation stage, as it not only helps\nsave developmental costs but also avoids data-related issues such as lengthy\ndata handover periods. However, existing authoring tools of dashboards are\nmostly not tailored to such prototyping needs, and motivated by these gaps, we\npropose DashChat, an interactive system that leverages large language models\n(LLMs) to generate industrial dashboard design prototypes from natural\nlanguage. We collaborated closely with designers from the industry and derived\nthe requirements based on their practical experience. First, by analyzing 114\nhigh-quality industrial dashboards, we summarized their common design patterns\nand inject the identified ones into LLMs as reference. Next, we built a\nmulti-agent pipeline powered by LLMs to understand textual requirements from\nusers and generate practical, aesthetic prototypes. Besides, functionally\ndistinct, parallel-operating agents are created to enable efficient generation.\nThen, we developed a user-friendly interface that supports text-based\ninteraction for generating and modifying prototypes. Two user studies\ndemonstrated that our system is both effective and efficient in supporting\ndesign prototyping.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-17T11:46:17Z"}
{"aid":"http://arxiv.org/abs/2504.12866v1","title":"Intersections of random chords of a circle","summary":"Where are the intersection points of diagonals of a regular $n$-gon located?\nWhat is the distribution of the intersection point of two random chords of a\ncircle? We investigate these and related new questions in geometric\nprobability, extend a largely forgotten result of Karamata, and elucidate its\nconnection to the Bertrand paradox.","main_category":"math.MG","categories":"math.MG,math.PR","published":"2025-04-17T11:49:28Z"}
{"aid":"http://arxiv.org/abs/2504.12873v1","title":"On a category of extensions whose endomorphism rings have at most four\n  maximal ideals","summary":"We describe the endomorphism ring of a short exact sequences $0 \\to A_R \\to\nB_R \\to C_R \\to 0$ with $A_R$ and $C_R$ uniserial modules and the behavior of\nthese short exact sequences as far as their direct sums are concerned.","main_category":"math.RA","categories":"math.RA","published":"2025-04-17T12:02:19Z"}
{"aid":"http://arxiv.org/abs/2504.12885v1","title":"Optimizing Movable Antennas in Wideband Multi-User MIMO With Hardware\n  Impairments","summary":"Movable antennas represent an emerging field in telecommunication research\nand a potential approach to achieving higher data rates in multiple-input\nmultiple-output (MIMO) communications when the total number of antennas is\nlimited. Most solutions and analyses to date have been limited to\n\\emph{narrowband} setups. This work complements the prior studies by\nquantifying the benefit of using movable antennas in \\emph{wideband} MIMO\ncommunication systems. First, we derive a novel uplink wideband system model\nthat also accounts for distortion from transceiver hardware impairments. We\nthen formulate and solve an optimization task to maximize the average sum rate\nby adjusting the antenna positions using particle swarm optimization. Finally,\nthe performance with movable antennas is compared with fixed uniform arrays and\nthe derived theoretical upper bound. The numerical study concludes that the\ndata rate improvement from movable antennas over other arrays heavily depends\non the level of hardware impairments, the richness of the multi-path\nenvironments, and the number of subcarriers. The present study provides vital\ninsights into the most suitable use cases for movable antennas in future\nwideband systems.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-17T12:20:46Z"}
{"aid":"http://arxiv.org/abs/2504.12886v1","title":"The multiplication probability of a finite ring","summary":"We study the probability that the product of two randomly chosen elements in\na finite ring $R$ is equal to some fixed element $x \\in R$. We calculate this\nprobability for semisimple rings and some special classes of local rings, and\nfind the bounds for this probability for an arbitrary finite ring.","main_category":"math.RA","categories":"math.RA","published":"2025-04-17T12:21:08Z"}
{"aid":"http://arxiv.org/abs/2504.12907v1","title":"De-jittering Ariel: an optimized algorithm","summary":"The European Space Agency's Ariel mission, scheduled for launch in 2029, aims\nto conduct the first large-scale survey of atmospheric spectra of transiting\nexoplanets. Ariel achieves the high photometric stability on transit timescales\nrequired to detect the spectroscopic signatures of chemical elements with a\npayload design optimized for transit photometry that either eliminates known\nsystematics or allows for their removal during data processing without\nsignificantly degrading or biasing the detection. Jitter in the spacecraft's\nline of sight is a source of disturbance when measuring the spectra of\nexoplanet atmospheres. We describe an improved algorithm for de-jittering Ariel\nobservations simulated in the time domain. We opt for an approach based on the\nspatial information on the Point Spread Function (PSF) distortion from jitter\nto detrend the optical signals. The jitter model is based on representative\nsimulations from Airbus Defence and Space, the prime contractor for the Ariel\nservice module. We investigate the precision and biases of the retrieved\natmospheric spectra from the jitter-detrended observations. At long\nwavelengths, the photometric stability of the Ariel spectrometer is already\ndominated by photon noise. Our algorithm effectively de-jitters both\nphotometric and spectroscopic data, ensuring that the performance remains\nphoton noise-limited across the entire Ariel spectrum, fully compliant with\nmission requirements. This work contributes to the development of the data\nreduction pipeline for Ariel, aligning with its scientific goals, and may also\nbenefit other astronomical telescopes and instrumentation.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-17T12:55:46Z"}
{"aid":"http://arxiv.org/abs/2504.12916v1","title":"Exact Learning Dynamics of In-Context Learning in Linear Transformers\n  and Its Application to Non-Linear Transformers","summary":"Transformer models exhibit remarkable in-context learning (ICL), adapting to\nnovel tasks from examples within their context, yet the underlying mechanisms\nremain largely mysterious. Here, we provide an exact analytical\ncharacterization of ICL emergence by deriving the closed-form stochastic\ngradient descent (SGD) dynamics for a simplified linear transformer performing\nregression tasks. Our analysis reveals key properties: (1) a natural separation\nof timescales directly governed by the input data's covariance structure,\nleading to staged learning; (2) an exact description of how ICL develops,\nincluding fixed points corresponding to learned algorithms and conservation\nlaws constraining the dynamics; and (3) surprisingly nonlinear learning\nbehavior despite the model's linearity. We hypothesize this phenomenology\nextends to non-linear models. To test this, we introduce theory-inspired\nmacroscopic measures (spectral rank dynamics, subspace stability) and use them\nto provide mechanistic explanations for (1) the sudden emergence of ICL in\nattention-only networks and (2) delayed generalization (grokking) in modular\narithmetic models. Our work offers an exact dynamical model for ICL and\ntheoretically grounded tools for analyzing complex transformer training.","main_category":"cs.LG","categories":"cs.LG,cond-mat.dis-nn","published":"2025-04-17T13:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.12925v1","title":"Physical limits on information metrics and quantum gravity as gravitized\n  quantum theory","summary":"There is a long history in both general relativity and quantum mechanics of\nremoving fixed background structures, thereby making observed objects and\nmeasurement processes dynamical. We continue this evolution by combining\ncentral insights from both theories to argue that physical limits on\ninformation collection resulting from quantum gravity coupled with general\ncovariance preclude the fixed information geometry still assumed in both\ninformation theory and quantum mechanics. As a consequence there must be a\ngravitized, generally covariant extension of both theories. We also propose a\nnovel experimental test involving intrinsic triple and higher order quantum\ninterferences that would provide evidence for dynamical information metrics and\na dynamical Born rule.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-17T13:17:42Z"}
{"aid":"http://arxiv.org/abs/2504.12928v1","title":"Eigenvalue distribution in gaps of the essential spectrum of the\n  Bochner-Schrödinger operator","summary":"The Bochner-Schr\\\"odinger operator $H_{p}=\\frac 1p\\Delta^{L^p}+V$ on high\ntensor powers $L^p$ of a Hermitian line bundle $L$ on a Riemannian manifold $X$\nof bounded geometry is studied under the assumption of non-degeneracy of the\ncurvature form of $L$. For large $p$, the spectrum of $H_p$ asymptotically\ncoincides with the union of all local Landau levels of the operator at the\npoints of $X$. Moreover, if the union of the local Landau levels over the\ncomplement of a compact subset of $X$ has a gap, then the spectrum of $H_{p}$\nin the gap is discrete. The main result of the paper is the trace asymptotics\nformula associated with these eigenvalues. As a consequence, we get a Weyl type\nasymptotic formula for the eigenvalue counting function.","main_category":"math.SP","categories":"math.SP,math-ph,math.DG,math.MP","published":"2025-04-17T13:26:05Z"}
{"aid":"http://arxiv.org/abs/2504.12929v1","title":"Switching of an antiferromagnet controlled by spin canting in a\n  laser-induced hidden phase","summary":"During laser-induced phase transitions, fast transformations of electronic,\natomic, and spin configurations often involve emergence of hidden and\nmetastable phases. Being inaccessible under any other stimuli, such phases are\nindispensable for unveiling mechanisms and controlling the transitions. We\nexperimentally explore spin kinetics during ultrafast first-order 90$^{\\circ}$\nspin-reorientation (SR) transition in a canted antiferromagnet Fe$_3$BO$_6$,\nand reveal that the transition is controlled by the canting between the\nmagnetic sublattices. Laser-induced perturbation of the Dzyaloshinskii-Moriya\ninteraction results in a change of the intersublattice canting within first\npicoseconds, bringing Fe$_3$BO$_6$ to a hidden phase. Once this phase emerges,\nlaser-induced heating activates precessional 90$^\\circ$ spin switching.\nCombination of the spin canting and heating controls the final spin\nconfiguration comprising coexisting initial and switched phases. Extended phase\ncoexistence range is in a striking contrast to the narrow SR transition in\nFe$_3$BO$_6$ induced by conventional heating.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-17T13:27:46Z"}
{"aid":"http://arxiv.org/abs/2504.12933v1","title":"Spatio-temporal pattern formation under varying functional response\n  parametrizations","summary":"Enhancement of the predictive power and robustness of nonlinear population\ndynamics models allows ecologists to make more reliable forecasts about\nspecies' long term survival. However, the limited availability of detailed\necological data, especially for complex ecological interactions creates\nuncertainty in model predictions, often requiring adjustments to the\nmathematical formulation of these interactions. Modifying the mathematical\nrepresentation of components responsible for complex behaviors, such as\npredation, can further contribute to this uncertainty, a phenomenon known as\nstructural sensitivity. Structural sensitivity has been explored primarily in\nnon-spatial systems governed by ordinary differential equations (ODEs), and in\na limited number of simple, spatially extended systems modeled by\nnonhomogeneous parabolic partial differential equations (PDEs), where\nself-diffusion alone cannot produce spatial patterns. In this study, we broaden\nthe scope of structural sensitivity analysis to include spatio-temporal\necological systems in which spatial patterns can emerge due to diffusive\ninstability. Through a combination of analytical techniques and supporting\nnumerical simulations, we show that pattern formation can be highly sensitive\nto how the system and its associated ecological interactions are mathematically\nparameterized. In fact, some patterns observed in one version of the model may\ncompletely disappear in another with a different parameterization, even though\nthe underlying properties remain unchanged.","main_category":"nlin.PS","categories":"nlin.PS,math.DS","published":"2025-04-17T13:28:08Z"}
{"aid":"http://arxiv.org/abs/2504.12934v1","title":"Quantifying walkable accessibility to urban services: An application to\n  Florence, Italy","summary":"The concept of quality of life in urban settings is increasingly associated\nto the accessibility of amenities within a short walking distance for\nresidents. However, this narrative still requires thorough empirical\ninvestigation to evaluate the practical implications, benefits, and challenges.\nIn this work, we propose a novel methodology for evaluating urban accessibility\nto services, with an application to the city of Florence, Italy. Our approach\ninvolves identifying the accessibility of essential services from residential\nbuildings within a 10-minute walking distance, employing a rigorous spatial\nanalysis process and open-source geospatial data. As a second contribution, we\nextend the concept of 10-minute accessibility within a network theory framework\nand apply a clustering algorithm to identify urban communities based on shared\naccess to essential services. Finally, we explore the dimension of functional\nredundancy. Our proposed metrics represent a step forward towards an accurate\nassessment of the adherence to the 10-minute city model and offer a valuable\ntool for place-based policies aimed at addressing spatial disparities in urban\ndevelopment.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-17T13:28:21Z"}
{"aid":"http://arxiv.org/abs/2504.12937v1","title":"Palatini Linear Attractors Are Back in ACTion","summary":"Recent results from the Atacama Cosmology Telescope (ACT) indicate a scalar\nspectral index $n_s \\simeq 0.9743$, in excellent agreement with the prediction\nof linear inflation. However, the corresponding tensor-to-scalar ratio $r\n\\simeq 0.0667$ is in tension with current observational bounds. In this work,\nwe investigate how this tension can be alleviated in the Palatini formulation\nof gravity. We consider two classes of models based on simple monomial\npotentials: (i) models with a non-minimal coupling between the inflaton and\ngravity, and (ii) models including an $\\alpha R^2$ term. In the first case, we\nfind that a quadratic potential with a linear non-minimal coupling leads to the\nlinear inflation attractor, with $r$ suppressed as $\\xi$ increases. In the\nsecond case, we show that a linear potential can yield values of $r$ consistent\nwith observations for sufficiently large $\\alpha$. Our results demonstrate that\nsimple monomial models can remain compatible with current observational\nconstraints when embedded in the Palatini framework.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph","published":"2025-04-17T13:35:17Z"}
{"aid":"http://arxiv.org/abs/2504.12940v1","title":"A study of Andromeda to improve our knowledge on the evolution and dust\n  production by AGB stars","summary":"We study the AGB population of the galaxy M31, based on available HST and\nSpitzer data,\n  to characterize the individual sources in terms of mass, metallicity and\nformation epoch\n  of the progenitors. Particular attention is dedicated to the derivation of\nthe dust\n  production rate of the stars, in the attempt of determining the global\ncurrent dust production\n  rate of the galaxy, divided between the silicates and the carbonaceous dust\ncontributions.\n  We use results from stellar evolution modelling complemented by the\ndescription of the\n  dust formation process in the wind, to be used in a population synthesis\napproach, based on\n  the star formation history and age-metallicity relationship obtained in\nprevious investigations.\n  The comparison between the results from synthetic modelling and the data\navailable are used\n  for the characterization of AGB stars in M31.\n  We find that the bulk of the AGB population of M31 is composed by low-mass\nstars of\n  different metallicity formed between 6 Gyr and 14 Gyr ago, with an\nadditional, significant\n  contribution from the progeny of 1.7-2.5Msun stars formed during the\nsecondary peak\n  in the star formation, which occurred between 1 and 2 Gyr ago. The dust\nproduction rate of the\n  galaxy is mostly provided by carbon stars, whose contribution is of the order\nof\n  4x10^{-4} Msun/yr, completed by silicates production from massive AGB stars,\n  occurring at a rate of 6x10^{-5} Msun/yr. The implications of the present\n  results on the reliability of AGB modelling are also commented.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-17T13:38:03Z"}
{"aid":"http://arxiv.org/abs/2504.12942v1","title":"Dressed Interference in Giant Superatoms: Entanglement Generation and\n  Transfer","summary":"We introduce the concept of giant superatoms (GSAs), where two or more\ninteracting atoms are nonlocally coupled to a waveguide through one of them,\nand explore their unconventional quantum dynamics. For braided GSAs, this setup\nenables decoherence-free transfer and swapping of their internal entangled\nstates. For separate GSAs, engineering coupling phases leads to state-dependent\nchiral emission, which enables selective, directional quantum information\ntransfer. This mechanism further facilitates remote generation of W-class\nentangled states. Our results thereby open exciting possibilities for quantum\nnetworks and quantum information processing.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T13:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.12943v1","title":"Customizing Emotional Support: How Do Individuals Construct and Interact\n  With LLM-Powered Chatbots","summary":"Personalized support is essential to fulfill individuals' emotional needs and\nsustain their mental well-being. Large language models (LLMs), with great\ncustomization flexibility, hold promises to enable individuals to create their\nown emotional support agents. In this work, we developed ChatLab, where users\ncould construct LLM-powered chatbots with additional interaction features\nincluding voices and avatars. Using a Research through Design approach, we\nconducted a week-long field study followed by interviews and design activities\n(N = 22), which uncovered how participants created diverse chatbot personas for\nemotional reliance, confronting stressors, connecting to intellectual\ndiscourse, reflecting mirrored selves, etc. We found that participants actively\nenriched the personas they constructed, shaping the dynamics between themselves\nand the chatbot to foster open and honest conversations. They also suggested\nother customizable features, such as integrating online activities and\nadjustable memory settings. Based on these findings, we discuss opportunities\nfor enhancing personalized emotional support through emerging AI technologies.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-17T13:43:13Z"}
{"aid":"http://arxiv.org/abs/2504.12944v1","title":"A Bi-Objective MDP Design approach to redundancy allocation with dynamic\n  maintenance for a parallel system","summary":"The reliability of a system can be improved by the addition of redundant\nelements, giving rise to the well-known redundancy allocation problem (RAP),\nwhich can be seen as a design problem. We propose a novel extension to the RAP\ncalled the Bi-Objective Integrated Design and Dynamic Maintenance Problem\n(BO-IDDMP) which allows for future dynamic maintenance decisions to be\nincorporated. This leads to a problem with first-stage redundancy design\ndecisions and a second-stage sequential decision problem. To the best of our\nknowledge, this is the first use of a continuous-time Markov Decision Process\nDesign framework to formulate a problem with non-trivial dynamics, as well as\nits first use alongside bi-objective optimization. A general heuristic\noptimization methodology for two-stage bi-objective programmes is developed,\nwhich is then applied to the BO-IDDMP. The efficiency and accuracy of our\nmethodology are demonstrated against an exact optimization formulation. The\nheuristic is shown to be orders of magnitude faster, and in only 2 out of 42\ncases fails to find one of the Pareto-optimal solutions found by the exact\nmethod. The inclusion of dynamic maintenance policies is shown to yield\nstronger and better-populated Pareto fronts, allowing more flexibility for the\ndecision-maker. The impacts of varying parameters unique to our problem are\nalso investigated.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T13:45:14Z"}
{"aid":"http://arxiv.org/abs/2504.12952v1","title":"Safe Physics-Informed Machine Learning for Dynamics and Control","summary":"This tutorial paper focuses on safe physics-informed machine learning in the\ncontext of dynamics and control, providing a comprehensive overview of how to\nintegrate physical models and safety guarantees. As machine learning techniques\nenhance the modeling and control of complex dynamical systems, ensuring safety\nand stability remains a critical challenge, especially in safety-critical\napplications like autonomous vehicles, robotics, medical decision-making, and\nenergy systems. We explore various approaches for embedding and ensuring safety\nconstraints, such as structural priors, Lyapunov functions, Control Barrier\nFunctions, predictive control, projections, and robust optimization techniques,\nensuring that the learned models respect stability and safety criteria.\nAdditionally, we delve into methods for uncertainty quantification and safety\nverification, including reachability analysis and neural network verification\ntools, which help validate that control policies remain within safe operating\nbounds even in uncertain environments. The paper includes illustrative examples\ndemonstrating the implementation aspects of safe learning frameworks that\ncombine the strengths of data-driven approaches with the rigor of physical\nprinciples, offering a path toward the safe control of complex dynamical\nsystems.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-17T13:52:55Z"}
{"aid":"http://arxiv.org/abs/2504.12955v1","title":"Systemic risk mitigation in supply chains through network rewiring","summary":"The networked nature of supply chains makes them susceptible to systemic\nrisk, where local firm failures can propagate through firm interdependencies\nthat can lead to cascading supply chain disruptions. The systemic risk of\nsupply chains can be quantified and is closely related to the topology and\ndynamics of supply chain networks (SCN). How different network properties\ncontribute to this risk remains unclear. Here, we ask whether systemic risk can\nbe significantly reduced by strategically rewiring supplier-customer links. In\ndoing so, we understand the role of specific endogenously emerged network\nstructures and to what extent the observed systemic risk is a result of\nfundamental properties of the dynamical system. We minimize systemic risk\nthrough rewiring by employing a method from statistical physics that respects\nfirm-level constraints to production. Analyzing six specific subnetworks of the\nnational SCNs of Ecuador and Hungary, we demonstrate that systemic risk can be\nconsiderably mitigated by 16-50% without reducing the production output of\nfirms. A comparison of network properties before and after rewiring reveals\nthat this risk reduction is achieved by changing the connectivity in\nnon-trivial ways. These results suggest that actual SCN topologies carry\nunnecessarily high levels of systemic risk. We discuss the possibility of\ndevising policies to reduce systemic risk through minimal, targeted\ninterventions in supply chain networks through market-based incentives.","main_category":"econ.GN","categories":"econ.GN,physics.soc-ph,q-fin.EC","published":"2025-04-17T13:59:01Z"}
{"aid":"http://arxiv.org/abs/2504.12961v1","title":"QLLM: Do We Really Need a Mixing Network for Credit Assignment in\n  Multi-Agent Reinforcement Learning?","summary":"Credit assignment has remained a fundamental challenge in multi-agent\nreinforcement learning (MARL). Previous studies have primarily addressed this\nissue through value decomposition methods under the centralized training with\ndecentralized execution paradigm, where neural networks are utilized to\napproximate the nonlinear relationship between individual Q-values and the\nglobal Q-value. Although these approaches have achieved considerable success in\nvarious benchmark tasks, they still suffer from several limitations, including\nimprecise attribution of contributions, limited interpretability, and poor\nscalability in high-dimensional state spaces. To address these challenges, we\npropose a novel algorithm, \\textbf{QLLM}, which facilitates the automatic\nconstruction of credit assignment functions using large language models (LLMs).\nSpecifically, the concept of \\textbf{TFCAF} is introduced, wherein the credit\nallocation process is represented as a direct and expressive nonlinear\nfunctional formulation. A custom-designed \\textit{coder-evaluator} framework is\nfurther employed to guide the generation, verification, and refinement of\nexecutable code by LLMs, significantly mitigating issues such as hallucination\nand shallow reasoning during inference. Extensive experiments conducted on\nseveral standard MARL benchmarks demonstrate that the proposed method\nconsistently outperforms existing state-of-the-art baselines. Moreover, QLLM\nexhibits strong generalization capability and maintains compatibility with a\nwide range of MARL algorithms that utilize mixing networks, positioning it as a\npromising and versatile solution for complex multi-agent scenarios.","main_category":"cs.MA","categories":"cs.MA,cs.AI","published":"2025-04-17T14:07:11Z"}
{"aid":"http://arxiv.org/abs/2504.12970v1","title":"MathPhys-Guided Coarse-to-Fine Anomaly Synthesis with SQE-Driven\n  Bi-Level Optimization for Anomaly Detection","summary":"Anomaly detection is a crucial task in computer vision, yet collecting\nreal-world defect images is inherently difficult due to the rarity and\nunpredictability of anomalies. Consequently, researchers have turned to\nsynthetic methods for training data augmentation. However, existing synthetic\nstrategies (e.g., naive cut-and-paste or inpainting) overlook the underlying\nphysical causes of defects, leading to inconsistent, low-fidelity anomalies\nthat hamper model generalization to real-world complexities. In this thesis, we\nintroduced a novel pipeline that generates synthetic anomalies through\nMath-Physics model guidance, refines them via a Coarse-to-Fine approach and\nemploys a bi-level optimization strategy with a Synthesis Quality\nEstimator(SQE). By incorporating physical modeling of cracks, corrosion, and\ndeformation, our method produces realistic defect masks, which are subsequently\nenhanced in two phases. The first stage (npcF) enforces a PDE-based consistency\nto achieve a globally coherent anomaly structure, while the second stage\n(npcF++) further improves local fidelity using wavelet transforms and boundary\nsynergy blocks. Additionally, we leverage SQE-driven weighting, ensuring that\nhigh-quality synthetic samples receive greater emphasis during training. To\nvalidate our approach, we conducted comprehensive experiments on three widely\nadopted industrial anomaly detection benchmarks: MVTec AD, VisA, and BTAD.\nAcross these datasets, the proposed pipeline achieves state-of-the-art (SOTA)\nresults in both image-AUROC and pixel-AUROC, confirming the effectiveness of\nour MaPhC2F and BiSQAD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T14:22:27Z"}
{"aid":"http://arxiv.org/abs/2504.12987v1","title":"Global regularity for the Dirichlet problem of Monge-Ampère equation\n  in convex polytopes","summary":"We study the Dirichlet problem for Monge-Amp\\`ere equation in bounded convex\npolytopes. We give sharp conditions for the existence of global $C^2$ and\n$C^{2,\\alpha}$ convex solutions provided that a global $C^2$, convex\nsubsolution exists.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T14:50:08Z"}
{"aid":"http://arxiv.org/abs/2504.12995v1","title":"Time-Varying Spectrum of the Random String","summary":"We consider the response of a finite string to white noise and obtain the\nexact time-dependent spectrum. The complete exact solution is obtained, that\nis, both the transient and steady-state solution. To define the time-varying\nspectrum we ensemble average the Wigner distribution. We obtain the exact\nsolution by transforming the differential equation for the string into the\nphase space differential equation of time and frequency and solve it directly.\nWe also obtain the exact solution by an impulse response method which gives a\ndifferent form of the solution. Also, we obtain the time-dependent variance of\nthe process at each position. Limiting cases for small and large times are\nobtained. As a special case we obtain the results of van Lear Jr. and Uhlenbeck\nand Lyon. A numerical example is given and the results plotted.","main_category":"physics.class-ph","categories":"physics.class-ph,math-ph,math.MP","published":"2025-04-17T15:04:00Z"}
{"aid":"http://arxiv.org/abs/2504.13000v1","title":"Tree-Line graphs and their quantum walks","summary":"For a simple graph $\\Gamma$, a (bipartite)tree-line graph and a tree-graph of\n$\\Gamma$ can be defined. With a (bipartite)tree-line graph constructed by the\nfunction $(b)\\ell$, we study the continuous quantum walk on $(b)\\ell ^n\n\\Gamma$. An equitable partition of a bipartite tree-line graph is obtained by\nits corresponding derived tree graph. This paper also examines quantum walks on\nderived graphs, whose vertices represent their basis state.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T15:10:49Z"}
{"aid":"http://arxiv.org/abs/2504.13001v1","title":"Nonlinear wave dynamics on a chip","summary":"Shallow water waves are a striking example of nonlinear hydrodynamics, giving\nrise to phenomena such as tsunamis and undular waves. These dynamics are\ntypically studied in hundreds-of-meter-long wave flumes. Here, we demonstrate a\nchip-scale, quantum-enabled wave flume. The wave flume exploits nanometer-thick\nsuperfluid helium films and optomechanical interactions to achieve\nnonlinearities surpassing those of extreme terrestrial flows. Measurements\nreveal wave steepening, shock fronts, and soliton fission -- nonlinear\nbehaviors long predicted in superfluid helium but never previously directly\nobserved. Our approach enables lithography-defined wave flume geometries,\noptomechanical control of hydrodynamic properties, and orders of magnitude\nfaster measurements than terrestrial flumes. Together, this opens a new\nfrontier in hydrodynamics, combining quantum fluids and nanophotonics to\nexplore complex wave dynamics at microscale.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.optics,quant-ph","published":"2025-04-17T15:11:21Z"}
{"aid":"http://arxiv.org/abs/2504.13006v1","title":"Mathematical programs with complementarity constraints and application\n  to hyperparameter tuning for nonlinear support vector machines","summary":"We consider the Mathematical Program with Complementarity Constraints (MPCC).\nOne of the main challenges in solving this problem is the systematic failure of\nstandard Constraint Qualifications (CQs). Carefully accounting for the\ncombinatorial nature of the complementarity constraints, tractable versions of\nthe Mangasarian Fromovitz Constraint Qualification (MFCQ) have been designed\nand widely studied in the literature. This paper looks closely at two such\nMPCC-MFCQs and their influence on MPCC algorithms. As a key contribution, we\nprove the convergence of the sequential penalisation and Scholtes relaxation\nalgorithms under a relaxed MPCC-MFCQ that is much weaker than the CQs currently\nused in the literature. We then form the problem of tuning hyperparameters of a\nnonlinear Support Vector Machine (SVM), a fundamental machine learning problem\nfor classification, as a MPCC. For this application, we establish that the\naforementioned relaxed MPCC-MFCQ holds under a very mild assumption. Moreover,\nwe program robust implementations and comprehensive numerical experimentation\non real-world data sets, where we show that the sequential penalisation method\napplied to the MPCC formulation for tuning SVM hyperparameters can outperform\nboth the Scholtes relaxation technique and the state-of-the-art derivative-free\nmethods from the machine learning literature.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T15:15:34Z"}
{"aid":"http://arxiv.org/abs/2504.13009v1","title":"Sequential ejections of plasma blobs due to unbraiding of tangled loops\n  in the solar atmosphere","summary":"Nanoflares, which are consequences of braids in tangled magnetic fields, are\nan important candidate to heat the solar corona to million degrees. However,\ntheir observational evidence is sparse and many of their observational\ncharacteristics are yet to be discovered. With the high-resolution observations\ntaken by the Extreme Ultraviolet Imager onboard the Solar Orbiter, here we\nstudy a series of ejections of plasma blobs resulted from a braided magnetic\nloops in the upper transition region and reveal some critical characteristics\nof such processes. The cores of these ejections have a size of about 700\\,km, a\nduration less than 1 minute and a speed of about 90\\,\\kms. An important\ncharacteristic is that these plasma blobs are apparently constrained by the\npost-reconnection magnetic loops, along which they show an extension of up to\nabout 2\\,000\\,km. The propagation of unbraiding nodes along the main axis of\nthe tangled loops has a speed of about 45\\,\\kms. The separation angles between\nthe post-reconnection loops and the main axis of the tangled loops are about\n30\\degree. The observations from the Atmospheric Imaging Assembly reveal that\nthe braiding loops are upper transition region structures. Based on these\nobservations, the typical magnetic free energy producing a blob is estimated to\nbe about $3.4\\times10^{23}$\\,erg, well in the nano-flare regime, while the\nkinematic energy of a blob is about $2.3\\times10^{23}$\\,erg, suggesting that a\nmajority of magnetic free energy in a magnetic braid is likely transferred into\nkinematic energy.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-17T15:16:17Z"}
{"aid":"http://arxiv.org/abs/2504.13018v1","title":"High Dimensional Sparse Canonical Correlation Analysis for Elliptical\n  Symmetric Distributions","summary":"This paper proposes a robust high-dimensional sparse canonical correlation\nanalysis (CCA) method for investigating linear relationships between two\nhigh-dimensional random vectors, focusing on elliptical symmetric\ndistributions. Traditional CCA methods, based on sample covariance matrices,\nstruggle in high-dimensional settings, particularly when data exhibit\nheavy-tailed distributions. To address this, we introduce the spatial-sign\ncovariance matrix as a robust estimator, combined with a sparsity-inducing\npenalty to efficiently estimate canonical correlations. Theoretical analysis\nshows that our method is consistent and robust under mild conditions,\nconverging at an optimal rate even in the presence of heavy tails. Simulation\nstudies demonstrate that our approach outperforms existing sparse CCA methods,\nparticularly under heavy-tailed distributions. A real-world application further\nconfirms the method's robustness and efficiency in practice. Our work provides\na novel solution for high-dimensional canonical correlation analysis, offering\nsignificant advantages over traditional methods in terms of both stability and\nperformance.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T15:25:51Z"}
{"aid":"http://arxiv.org/abs/2504.13020v1","title":"Euclid preparation. Estimating galaxy physical properties using CatBoost\n  chained regressors with attention","summary":"Euclid will image ~14000 deg^2 of the extragalactic sky at visible and NIR\nwavelengths, providing a dataset of unprecedented size and richness that will\nfacilitate a multitude of studies into the evolution of galaxies. In the vast\nmajority of cases the main source of information will come from broad-band\nimages and data products thereof. Therefore, there is a pressing need to\nidentify or develop scalable yet reliable methodologies to estimate the\nredshift and physical properties of galaxies using broad-band photometry from\nEuclid, optionally including ground-based optical photometry also. To address\nthis need, we present a novel method to estimate the redshift, stellar mass,\nstar-formation rate, specific star-formation rate, E(B-V), and age of galaxies,\nusing mock Euclid and ground-based photometry. The main novelty of our\nproperty-estimation pipeline is its use of the CatBoost implementation of\ngradient-boosted regression-trees, together with chained regression and an\nintelligent, automatic optimization of the training data. The pipeline also\nincludes a computationally-efficient method to estimate prediction\nuncertainties, and, in the absence of ground-truth labels, provides accurate\npredictions for metrics of model performance up to z~2. We apply our pipeline\nto several datasets consisting of mock Euclid broad-band photometry and mock\nground-based ugriz photometry, to evaluate the performance of our methodology\nfor estimating the redshift and physical properties of galaxies detected in the\nEuclid Wide Survey. The quality of our photometric redshift and physical\nproperty estimates are highly competitive overall, validating our modeling\napproach. We find that the inclusion of ground-based optical photometry\nsignificantly improves the quality of the property estimation, highlighting the\nimportance of combining Euclid data with ancillary ground-based optical data.\n(Abridged)","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.IM","published":"2025-04-17T15:28:36Z"}
{"aid":"http://arxiv.org/abs/2504.13021v1","title":"Pose and Facial Expression Transfer by using StyleGAN","summary":"We propose a method to transfer pose and expression between face images.\nGiven a source and target face portrait, the model produces an output image in\nwhich the pose and expression of the source face image are transferred onto the\ntarget identity. The architecture consists of two encoders and a mapping\nnetwork that projects the two inputs into the latent space of StyleGAN2, which\nfinally generates the output. The training is self-supervised from video\nsequences of many individuals. Manual labeling is not required. Our model\nenables the synthesis of random identities with controllable pose and\nexpression. Close-to-real-time performance is achieved.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T15:29:41Z"}
{"aid":"http://arxiv.org/abs/2504.13027v1","title":"Competing Bosonic Reactions: Insight from Exactly Solvable\n  Time-Dependent Models","summary":"We discuss the progress on exactly solvable multistate Landau-Zener models\nfrom a perspective of their application to competing reactions of particle\ncreation from a false vacuum. Such models generally predict that, even with\nidentical initial conditions, and for nearly the same other particle\nparameters, a quantum coherent evolution results in a final particle\ndistribution with significant asymmetry. We use an exact solution of the driven\nbosonic Tavis-Cummings model for two reaction pathways in order to quantify\nthis effect, reveal a corresponding phase transition, and identify its\nuniversality class.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,gr-qc,hep-th","published":"2025-04-17T15:38:04Z"}
{"aid":"http://arxiv.org/abs/2504.13033v1","title":"Practical Application of the Quantum Carleman Lattice Boltzmann Method\n  in Industrial CFD Simulations","summary":"Computational Fluid Dynamics simulations are crucial in industrial\napplications but require extensive computational resources, particularly for\nextreme turbulent regimes. While classical digital approaches remain the\nstandard, quantum computing promises a breakthrough by enabling a more\nefficient encoding of large-scale simulations with a limited number of qubits.\n  This work presents a practical numerical assessment of a hybrid\nquantum-classical approach to CFD based on the Lattice Boltzmann Method (LBM).\nThe inherently non-linear LBM equations are linearized via a Carleman expansion\nand solved using the quantum Harrow Hassidim Lloyd algorithm (HHL). We evaluate\nthis method on three benchmark cases featuring different boundary conditions,\nperiodic, bounceback, and moving wall, using statevector emulation on\nhigh-performance computing resources.\n  Our results confirm the validity of the approach, achieving median error\nfidelities on the order of $10^{-3}$ and success probabilities sufficient for\npractical quantum state sampling. Notably, the spectral properties of small\nlattice systems closely approximate those of larger ones, suggesting a pathway\nto mitigate one of HHL's bottlenecks: eigenvalue pre-evaluation.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph,physics.flu-dyn","published":"2025-04-17T15:41:48Z"}
{"aid":"http://arxiv.org/abs/2504.13035v1","title":"Prototypes are Balanced Units for Efficient and Effective Partially\n  Relevant Video Retrieval","summary":"In a retrieval system, simultaneously achieving search accuracy and\nefficiency is inherently challenging. This challenge is particularly pronounced\nin partially relevant video retrieval (PRVR), where incorporating more diverse\ncontext representations at varying temporal scales for each video enhances\naccuracy but increases computational and memory costs. To address this\ndichotomy, we propose a prototypical PRVR framework that encodes diverse\ncontexts within a video into a fixed number of prototypes. We then introduce\nseveral strategies to enhance text association and video understanding within\nthe prototypes, along with an orthogonal objective to ensure that the\nprototypes capture a diverse range of content. To keep the prototypes\nsearchable via text queries while accurately encoding video contexts, we\nimplement cross- and uni-modal reconstruction tasks. The cross-modal\nreconstruction task aligns the prototypes with textual features within a shared\nspace, while the uni-modal reconstruction task preserves all video contexts\nduring encoding. Additionally, we employ a video mixing technique to provide\nweak guidance to further align prototypes and associated textual\nrepresentations. Extensive evaluations on TVR, ActivityNet-Captions, and\nQVHighlights validate the effectiveness of our approach without sacrificing\nefficiency.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T15:43:29Z"}
{"aid":"http://arxiv.org/abs/2504.13045v1","title":"Expert Kernel Generation Network Driven by Contextual Mapping for\n  Hyperspectral Image Classification","summary":"Deep neural networks face several challenges in hyperspectral image\nclassification, including high-dimensional data, sparse distribution of ground\nobjects, and spectral redundancy, which often lead to classification\noverfitting and limited generalization capability. To more efficiently adapt to\nground object distributions while extracting image features without introducing\nexcessive parameters and skipping redundant information, this paper proposes\nEKGNet based on an improved 3D-DenseNet model, consisting of a context-aware\nmapping network and a dynamic kernel generation module. The context-aware\nmapping module translates global contextual information of hyperspectral inputs\ninto instructions for combining base convolutional kernels, while the dynamic\nkernels are composed of K groups of base convolutions, analogous to K different\ntypes of experts specializing in fundamental patterns across various\ndimensions. The mapping module and dynamic kernel generation mechanism form a\ntightly coupled system - the former generates meaningful combination weights\nbased on inputs, while the latter constructs an adaptive expert convolution\nsystem using these weights. This dynamic approach enables the model to focus\nmore flexibly on key spatial structures when processing different regions,\nrather than relying on the fixed receptive field of a single static\nconvolutional kernel. EKGNet enhances model representation capability through a\n3D dynamic expert convolution system without increasing network depth or width.\nThe proposed method demonstrates superior performance on IN, UP, and KSC\ndatasets, outperforming mainstream hyperspectral image classification\napproaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T16:00:06Z"}
{"aid":"http://arxiv.org/abs/2504.13049v1","title":"Multi-modal single-cell foundation models via dynamic token adaptation","summary":"Recent advances in applying deep learning in genomics include DNA-language\nand single-cell foundation models. However, these models take only one data\ntype as input. We introduce dynamic token adaptation and demonstrate how it\ncombines these models to predict gene regulation at the single-cell level in\ndifferent genetic contexts. Although the method is generalisable, we focus on\nan illustrative example by training an adapter from DNA-sequence embeddings to\na single-cell foundation model's token embedding space. As a qualitative\nevaluation, we assess the impact of DNA sequence changes on the model's learned\ngene regulatory networks by mutating the transcriptional start site of the\ntranscription factor GATA4 in silico, observing predicted expression changes in\nits target genes in fetal cardiomyocytes.","main_category":"q-bio.GN","categories":"q-bio.GN","published":"2025-04-17T16:05:59Z"}
{"aid":"http://arxiv.org/abs/2504.13060v1","title":"Imaging for All-Day Wearable Smart Glasses","summary":"In recent years smart glasses technology has rapidly advanced, opening up\nentirely new areas for mobile computing. We expect future smart glasses will\nneed to be all-day wearable, adopting a small form factor to meet the\nrequirements of volume, weight, fashionability and social acceptability, which\nputs significant constraints on the space of possible solutions. Additional\nchallenges arise due to the fact that smart glasses are worn in arbitrary\nenvironments while their wearer moves and performs everyday activities. In this\npaper, we systematically analyze the space of imaging from smart glasses and\nderive several fundamental limits that govern this imaging domain. We discuss\nthe impact of these limits on achievable image quality and camera module size\n-- comparing in particular to related devices such as mobile phones. We then\npropose a novel distributed imaging approach that allows to minimize the size\nof the individual camera modules when compared to a standard monolithic camera\ndesign. Finally, we demonstrate the properties of this novel approach in a\nseries of experiments using synthetic data as well as images captured with two\ndifferent prototype implementations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T16:14:34Z"}
{"aid":"http://arxiv.org/abs/2504.13061v1","title":"ArtistAuditor: Auditing Artist Style Pirate in Text-to-Image Generation\n  Models","summary":"Text-to-image models based on diffusion processes, such as DALL-E, Stable\nDiffusion, and Midjourney, are capable of transforming texts into detailed\nimages and have widespread applications in art and design. As such, amateur\nusers can easily imitate professional-level paintings by collecting an artist's\nwork and fine-tuning the model, leading to concerns about artworks' copyright\ninfringement. To tackle these issues, previous studies either add visually\nimperceptible perturbation to the artwork to change its underlying styles\n(perturbation-based methods) or embed post-training detectable watermarks in\nthe artwork (watermark-based methods). However, when the artwork or the model\nhas been published online, i.e., modification to the original artwork or model\nretraining is not feasible, these strategies might not be viable.\n  To this end, we propose a novel method for data-use auditing in the\ntext-to-image generation model. The general idea of ArtistAuditor is to\nidentify if a suspicious model has been finetuned using the artworks of\nspecific artists by analyzing the features related to the style. Concretely,\nArtistAuditor employs a style extractor to obtain the multi-granularity style\nrepresentations and treats artworks as samplings of an artist's style. Then,\nArtistAuditor queries a trained discriminator to gain the auditing decisions.\nThe experimental results on six combinations of models and datasets show that\nArtistAuditor can achieve high AUC values (> 0.937). By studying\nArtistAuditor's transferability and core modules, we provide valuable insights\ninto the practical implementation. Finally, we demonstrate the effectiveness of\nArtistAuditor in real-world cases by an online platform Scenario. ArtistAuditor\nis open-sourced at https://github.com/Jozenn/ArtistAuditor.","main_category":"cs.CV","categories":"cs.CV,cs.CR,cs.LG","published":"2025-04-17T16:15:38Z"}
{"aid":"http://arxiv.org/abs/2504.13073v1","title":"Topological defect engineering enables size and shape control in\n  self-assembly","summary":"The self-assembly of complex structures from engineered subunits is a major\ngoal of nanotechnology, but controlling their size becomes increasingly\ndifficult in larger assemblies. Existing strategies present significant\nchallenges, among which are the use of multiple subunit types or the precise\ncontrol of their shape and mechanics. Here we introduce an alternative approach\nbased on identical subunits whose interactions promote crystals, but also favor\ncrystalline defects. We theoretically show that topological restrictions on the\nscope of these defects in large assemblies imply that the assembly size is\ncontrolled by the magnitude of the defect-inducing interaction. Using DNA\norigami, we experimentally demonstrate both size and shape control in\ntwo-dimensional disk- and fiber-like assemblies. Our basic concept of defect\nengineering could be generalized well beyond these simple examples, and thus\nprovide a broadly applicable scheme to control self-assembly.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-17T16:35:44Z"}
{"aid":"http://arxiv.org/abs/2504.13096v1","title":"Tight and overtwisted contact structures","summary":"The tight versus overtwisted dichotomy has been an essential organizing\nprinciple and driving force in 3-dimensional contact geometry since its\ninception around 1990. In this article, we will discuss the genesis of this\ndichotomy in Eliashberg's seminal work and his influential contributions to the\ntheory.","main_category":"math.SG","categories":"math.SG,math.GT","published":"2025-04-17T17:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.13113v1","title":"Quorum: Zero-Training Unsupervised Anomaly Detection using Quantum\n  Autoencoders","summary":"Detecting mission-critical anomalous events and data is a crucial challenge\nacross various industries, including finance, healthcare, and energy. Quantum\ncomputing has recently emerged as a powerful tool for tackling several machine\nlearning tasks, but training quantum machine learning models remains\nchallenging, particularly due to the difficulty of gradient calculation. The\nchallenge is even greater for anomaly detection, where unsupervised learning\nmethods are essential to ensure practical applicability. To address these\nissues, we propose Quorum, the first quantum anomaly detection framework\ndesigned for unsupervised learning that operates without requiring any\ntraining.","main_category":"cs.LG","categories":"cs.LG,cs.ET","published":"2025-04-17T17:27:39Z"}
{"aid":"http://arxiv.org/abs/2504.13125v1","title":"LLMs Meet Finance: Fine-Tuning Foundation Models for the Open FinLLM\n  Leaderboard","summary":"This paper investigates the application of large language models (LLMs) to\nfinancial tasks. We fine-tuned foundation models using the Open FinLLM\nLeaderboard as a benchmark. Building on Qwen2.5 and Deepseek-R1, we employed\ntechniques including supervised fine-tuning (SFT), direct preference\noptimization (DPO), and reinforcement learning (RL) to enhance their financial\ncapabilities. The fine-tuned models demonstrated substantial performance gains\nacross a wide range of financial tasks. Moreover, we measured the data scaling\nlaw in the financial domain. Our work demonstrates the potential of large\nlanguage models (LLMs) in financial applications.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-17T17:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.13127v1","title":"Force and Speed in a Soft Stewart Platform","summary":"Many soft robots struggle to produce dynamic motions with fast, large\ndisplacements. We develop a parallel 6 degree-of-freedom (DoF) Stewart-Gough\nmechanism using Handed Shearing Auxetic (HSA) actuators. By using soft\nactuators, we are able to use one third as many mechatronic components as a\nrigid Stewart platform, while retaining a working payload of 2kg and an\nopen-loop bandwidth greater than 16Hx. We show that the platform is capable of\nboth precise tracing and dynamic disturbance rejection when controlling a ball\nand sliding puck using a Proportional Integral Derivative (PID) controller. We\ndevelop a machine-learning-based kinematics model and demonstrate a functional\nworkspace of roughly 10cm in each translation direction and 28 degrees in each\norientation. This 6DoF device has many of the characteristics associated with\nrigid components - power, speed, and total workspace - while capturing the\nadvantages of soft mechanisms.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T17:43:33Z"}
{"aid":"http://arxiv.org/abs/2504.13129v1","title":"Science-T2I: Addressing Scientific Illusions in Image Synthesis","summary":"We present a novel approach to integrating scientific knowledge into\ngenerative models, enhancing their realism and consistency in image synthesis.\nFirst, we introduce Science-T2I, an expert-annotated adversarial dataset\ncomprising adversarial 20k image pairs with 9k prompts, covering wide distinct\nscientific knowledge categories. Leveraging Science-T2I, we present SciScore,\nan end-to-end reward model that refines the assessment of generated images\nbased on scientific knowledge, which is achieved by augmenting both the\nscientific comprehension and visual capabilities of pre-trained CLIP model.\nAdditionally, based on SciScore, we propose a two-stage training framework,\ncomprising a supervised fine-tuning phase and a masked online fine-tuning\nphase, to incorporate scientific knowledge into existing generative models.\nThrough comprehensive experiments, we demonstrate the effectiveness of our\nframework in establishing new standards for evaluating the scientific realism\nof generated content. Specifically, SciScore attains performance comparable to\nhuman-level, demonstrating a 5% improvement similar to evaluations conducted by\nexperienced human evaluators. Furthermore, by applying our proposed fine-tuning\nmethod to FLUX, we achieve a performance enhancement exceeding 50% on SciScore.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-17T17:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.13132v1","title":"Cosmological Parameters Estimate from Persistent Radio Sources of Fast\n  Radio Bursts","summary":"We introduce a novel method to constrain the Hubble constant ($H_0$) by\ncombining fast radio bursts (FRBs) and their persistent radio sources (PRSs)\nthrough the observationally validated Yang relation, $ L_{\\nu} \\propto |\n\\mathrm{RM} | $, which links PRS luminosity to the rotation measure (RM) of the\nassociated FRB. Using a mock sample of PRSs, we demonstrate that the Yang\nrelation can help to unravel the degeneracies among $H_0$, baryon density\nparameter $\\Omega_b$, and baryon fraction in the intergalactic medium\n$f_{\\mathrm{IGM}}$ in the traditional approach of using dispersion measure only\nto perform cosmological analyses. Our method employs a two-stage Markov Chain\nMonte Carlo (MCMC) analysis to constrain $H_0$. Using the available data of six\nobserved PRS systems, we obtain a preliminary constraint of $H_0 = 75 \\pm\n30~\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$. We briefly discuss possible refinements of\nthe method by reducing residual degeneracies and systematic uncertainties using\nfuture data and physical modeling. Our results indicate that the Yang relation\ncan potentially become a new probe for performing FRB cosmology.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.HE","published":"2025-04-17T17:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.13145v1","title":"Exploring Expert Failures Improves LLM Agent Tuning","summary":"Large Language Models (LLMs) have shown tremendous potential as agents,\nexcelling at tasks that require multiple rounds of reasoning and interactions.\nRejection Sampling Fine-Tuning (RFT) has emerged as an effective method for\nfinetuning LLMs as agents: it first imitates expert-generated successful\ntrajectories and further improves agentic skills through iterative fine-tuning\non successful, self-generated trajectories. However, since the expert (e.g.,\nGPT-4) succeeds primarily on simpler subtasks and RFT inherently favors simpler\nscenarios, many complex subtasks remain unsolved and persistently\nout-of-distribution (OOD). Upon investigating these challenging subtasks, we\ndiscovered that previously failed expert trajectories can often provide\nvaluable guidance, e.g., plans and key actions, that can significantly improve\nagent exploration efficiency and acquisition of critical skills. Motivated by\nthese observations, we propose Exploring Expert Failures (EEF), which\nidentifies beneficial actions from failed expert trajectories and integrates\nthem into the training dataset. Potentially harmful actions are meticulously\nexcluded to prevent contamination of the model learning process. By leveraging\nthe beneficial actions in expert failures, EEF successfully solves some\npreviously unsolvable subtasks and improves agent tuning performance.\nRemarkably, our approach achieved a 62\\% win rate in WebShop, outperforming RFT\n(53. 6\\%) and GPT-4 (35. 6\\%), and to the best of our knowledge, setting a new\nstate-of-the-art as the first method to surpass a score of 0.81 in WebShop and\nexceed 81 in SciWorld.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-17T17:53:54Z"}
{"aid":"http://arxiv.org/abs/2504.13164v1","title":"Minute-long quantum coherence enabled by electrical depletion of\n  magnetic noise","summary":"Integrating solid-state spin defects into classical electronic devices can\nenable new opportunities for quantum information processing that benefit from\nexisting semiconductor technology. We show, through bias control of an\nisotopically purified silicon carbide (SiC) p-i-n diode, the depletion of not\nonly electrical noise sources but also magnetic noise sources, resulting in\nrecord coherences for SiC electron spin qubits. We also uncover complementary\nimprovements to the relaxation times of nuclear spin registers controllable by\nthe defect, and measure diode-enhanced coherences. These improvements lead to\nrecord-long nuclear spin Hahn-echo times on the scale of minutes. These results\ndemonstrate the power of materials control and electronic device integration to\ncreate highly coherent solid-state quantum network nodes and processors.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci","published":"2025-04-17T17:58:52Z"}
{"aid":"http://arxiv.org/abs/2504.13177v1","title":"Single-Shot Shape and Reflectance with Spatial Polarization Multiplexing","summary":"We propose spatial polarization multiplexing (SPM) for reconstructing object\nshape and reflectance from a single polarimetric image and demonstrate its\napplication to dynamic surface recovery. Although single-pattern structured\nlight enables single-shot shape reconstruction, the reflectance is challenging\nto recover due to the lack of angular sampling of incident light and the\nentanglement of the projected pattern and the surface color texture. We design\na spatially multiplexed pattern of polarization that can be robustly and\nuniquely decoded for shape reconstruction by quantizing the AoLP values. At the\nsame time, our spatial-multiplexing enables single-shot ellipsometry of linear\npolarization by projecting differently polarized light within a local region,\nwhich separates the specular and diffuse reflections for BRDF estimation. We\nachieve this spatial polarization multiplexing with a constrained de Bruijn\nsequence. Unlike single-pattern structured light with intensity and color, our\npolarization pattern is invisible to the naked eye and retains the natural\nsurface appearance which is essential for accurate appearance modeling and also\ninteraction with people. We experimentally validate our method on real data.\nThe results show that our method can recover the shape, the Mueller matrix, and\nthe BRDF from a single-shot polarimetric image. We also demonstrate the\napplication of our method to dynamic surfaces.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.13178v1","title":"Aligning Constraint Generation with Design Intent in Parametric CAD","summary":"We adapt alignment techniques from reasoning LLMs to the task of generating\nengineering sketch constraints found in computer-aided design (CAD) models.\nEngineering sketches consist of geometric primitives (e.g. points, lines)\nconnected by constraints (e.g. perpendicular, tangent) that define the\nrelationships between them. For a design to be easily editable, the constraints\nmust effectively capture design intent, ensuring the geometry updates\npredictably when parameters change. Although current approaches can generate\nCAD designs, an open challenge remains to align model outputs with design\nintent, we label this problem `design alignment'. A critical first step towards\naligning generative CAD models is to generate constraints which fully-constrain\nall geometric primitives, without over-constraining or distorting sketch\ngeometry. Using alignment techniques to train an existing constraint generation\nmodel with feedback from a constraint solver, we are able to fully-constrain\n93% of sketches compared to 34% when using a na\\\"ive supervised fine-tuning\n(SFT) baseline and only 8.9% without alignment. Our approach can be applied to\nany existing constraint generation model and sets the stage for further\nresearch bridging alignment strategies between the language and design domains.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T17:59:54Z"}
{"aid":"http://arxiv.org/abs/2504.14849v1","title":"Language Models for Materials Discovery and Sustainability: Progress,\n  Challenges, and Opportunities","summary":"Significant advancements have been made in one of the most critical branches\nof artificial intelligence: natural language processing (NLP). These\nadvancements are exemplified by the remarkable success of OpenAI's GPT-3.5/4\nand the recent release of GPT-4.5, which have sparked a global surge of\ninterest akin to an NLP gold rush. In this article, we offer our perspective on\nthe development and application of NLP and large language models (LLMs) in\nmaterials science. We begin by presenting an overview of recent advancements in\nNLP within the broader scientific landscape, with a particular focus on their\nrelevance to materials science. Next, we examine how NLP can facilitate the\nunderstanding and design of novel materials and its potential integration with\nother methodologies. To highlight key challenges and opportunities, we delve\ninto three specific topics: (i) the limitations of LLMs and their implications\nfor materials science applications, (ii) the creation of a fully automated\nmaterials discovery pipeline, and (iii) the potential of GPT-like tools to\nsynthesize existing knowledge and aid in the design of sustainable materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T04:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.14851v1","title":"Highly Stable Silicon Anodes Enabled by Sub-10 nm Pores and Particles","summary":"Silicon anodes offer high energy densities for next-generation lithium-ion\nbatteries; however, their application is limited by severe volume expansion\nduring cycling. Making silicon porous or nanostructured mitigates this\nexpansion but often increases lithium inventory losses due to the inherent high\nsurface area of nanomaterials. This study introduces a simple bottom-up process\nthat overcomes this limitation. The approach relies on small silicon particles\n(<10 nm) produced using an efficient low-temperature plasma approach. These\nsmall building blocks are assembled into micron-scale superstructures\ncharacterized by uniformly dispersed sub-10 nm pores. This structure addresses\nboth volume expansion and lithium-inventory issues while achieving tap\ndensities exceeding those of commercial graphite (~1.2 g/cm3), all while\nmaintaining good processability. The resulting silicon-dominant anodes achieve\nremarkable stability in full pouch cells with NMC811 and LFP cathodes,\nretaining ~80% capacity for more than 400 cycles without pre-lithiation,\ngraphite blending, or pre-cycling.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T04:21:42Z"}
{"aid":"http://arxiv.org/abs/2504.14872v1","title":"Efficient Function Orchestration for Large Language Models","summary":"Function calling is a fundamental capability of today's large language\nmodels, but sequential function calling posed efficiency problems. Recent\nstudies have proposed to request function calls with parallelism support in\norder to alleviate this issue. However, they either delegate the concurrent\nfunction calls to users for execution which are conversely executed\nsequentially, or overlook the relations among various function calls, rending\nlimited efficiency. This paper introduces LLMOrch, an advanced framework for\nautomated, parallel function calling in large language models. The key\nprinciple behind LLMOrch is to identify an available processor to execute a\nfunction call while preventing any single processor from becoming overburdened.\nTo this end, LLMOrch models the data relations (i.e., def-use) among different\nfunction calls and coordinates their executions by their control relations\n(i.e., mutual-exclusion) as well as the working status of the underlying\nprocessors. When comparing with state-of-the-art techniques, LLMOrch\ndemonstrated comparable efficiency improvements in orchestrating I/O-intensive\nfunctions, while significantly outperforming (2$\\times$) them with\ncompute-intensive functions. LLMOrch's performance even showed a linear\ncorrelation to the number of allocated processors. We believe that these\nresults highlight the potential of LLMOrch as an efficient solution for\nparallel function orchestration in the context of large language models.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-21T05:57:34Z"}
{"aid":"http://arxiv.org/abs/2504.14878v1","title":"Free Energy Distribution and Relaxation Dynamics Near the First-Order\n  Transition Line","summary":"Using the three-dimensional kinetic Ising model with Metropolis algorithm, we\ncalculate the free energy in the whole phase boundary, particularly near the\nfirst phase transition line (1st-PTL).The results show that along the 1st-PTL,\nas the temperature decreases, the energy barrier between the two coexisting\nphases diverges. This results in more difficulty to reach the equilibrium,\ni.e., ultra-slow relaxation, which has been recently demonstrated. Meanwhile,\nwe exam the randomness of the equilibrium time. It is found that near the\n1st-PTL the equilibrium time is self-diverging, in contrast to the\nnon-self-averaging near the critical point.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-21T06:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.14886v1","title":"Zero Day Malware Detection with Alpha: Fast DBI with Transformer Models\n  for Real World Application","summary":"The effectiveness of an AI model in accurately classifying novel malware\nhinges on the quality of the features it is trained on, which in turn depends\non the effectiveness of the analysis tool used. Peekaboo, a Dynamic Binary\nInstrumentation (DBI) tool, defeats malware evasion techniques to capture\nauthentic behavior at the Assembly (ASM) instruction level. This behavior\nexhibits patterns consistent with Zipf's law, a distribution commonly seen in\nnatural languages, making Transformer models particularly effective for binary\nclassification tasks. We introduce Alpha, a framework for zero day malware\ndetection that leverages Transformer models and ASM language. Alpha is trained\non malware and benign software data collected through Peekaboo, enabling it to\nidentify entirely new samples with exceptional accuracy. Alpha eliminates any\ncommon functions from the test samples that are in the training dataset. This\nforces the model to rely on contextual patterns and novel ASM instruction\ncombinations to detect malicious behavior, rather than memorizing familiar\nfeatures. By combining the strengths of DBI, ASM analysis, and Transformer\narchitectures, Alpha offers a powerful approach to proactively addressing the\nevolving threat of malware. Alpha demonstrates perfect accuracy for Ransomware,\nWorms and APTs with flawless classification for both malicious and benign\nsamples. The results highlight the model's exceptional performance in detecting\ntruly new malware samples.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-21T06:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.14889v1","title":"Latent Bayesian Optimization via Autoregressive Normalizing Flows","summary":"Bayesian Optimization (BO) has been recognized for its effectiveness in\noptimizing expensive and complex objective functions. Recent advancements in\nLatent Bayesian Optimization (LBO) have shown promise by integrating generative\nmodels such as variational autoencoders (VAEs) to manage the complexity of\nhigh-dimensional and structured data spaces. However, existing LBO approaches\noften suffer from the value discrepancy problem, which arises from the\nreconstruction gap between input and latent spaces. This value discrepancy\nproblem propagates errors throughout the optimization process, leading to\nsuboptimal outcomes. To address this issue, we propose a Normalizing Flow-based\nBayesian Optimization (NF-BO), which utilizes normalizing flow as a generative\nmodel to establish one-to-one encoding function from the input space to the\nlatent space, along with its left-inverse decoding function, eliminating the\nreconstruction gap. Specifically, we introduce SeqFlow, an autoregressive\nnormalizing flow for sequence data. In addition, we develop a new candidate\nsampling strategy that dynamically adjusts the exploration probability for each\ntoken based on its importance. Through extensive experiments, our NF-BO method\ndemonstrates superior performance in molecule generation tasks, significantly\noutperforming both traditional and recent LBO approaches.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T06:36:09Z"}
{"aid":"http://arxiv.org/abs/2504.14891v1","title":"Retrieval Augmented Generation Evaluation in the Era of Large Language\n  Models: A Comprehensive Survey","summary":"Recent advancements in Retrieval-Augmented Generation (RAG) have\nrevolutionized natural language processing by integrating Large Language Models\n(LLMs) with external information retrieval, enabling accurate, up-to-date, and\nverifiable text generation across diverse applications. However, evaluating RAG\nsystems presents unique challenges due to their hybrid architecture that\ncombines retrieval and generation components, as well as their dependence on\ndynamic knowledge sources in the LLM era. In response, this paper provides a\ncomprehensive survey of RAG evaluation methods and frameworks, systematically\nreviewing traditional and emerging evaluation approaches, for system\nperformance, factual accuracy, safety, and computational efficiency in the LLM\nera. We also compile and categorize the RAG-specific datasets and evaluation\nframeworks, conducting a meta-analysis of evaluation practices in high-impact\nRAG research. To the best of our knowledge, this work represents the most\ncomprehensive survey for RAG evaluation, bridging traditional and LLM-driven\nmethods, and serves as a critical resource for advancing RAG development.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T06:39:47Z"}
{"aid":"http://arxiv.org/abs/2504.14909v1","title":"A Novel FFA-Based Storage Ring Design with an Internal Target for\n  Heavy-Ion Beams Undergoing Stochastic Charge State Conversions","summary":"A heavy-ion storage ring with an energy recovery internal target(ERIT) is\nsuitable for rare production reactions. The most onerous obstacle to the stable\noperation of this ring is a phenomenon of stochastic charge state\nconversions(SCSC) of the ions in the beam caused by the collision with the\ntarget. This phenomenon causes a rapid increase in the beam emittance. To solve\nthis problem, we have developed a method to match the closed orbits and beta\nfunctions of the beams in different charge states at the production target\nlocation in the scaling FFA ring. In this paper, we show through 6D beam\ntracking simulations that the FFA ring with modulated $k$ suppresses the\nemittance growth even in the presence of SCSC, and it can accumulate the beam\nover 600 turns effectively.","main_category":"physics.acc-ph","categories":"physics.acc-ph,nucl-ex","published":"2025-04-21T07:27:27Z"}
{"aid":"http://arxiv.org/abs/2504.14916v1","title":"Sombor Spectrum of Super Graphs defined on groups","summary":"Given a simple graph $A$ on a group $G$ and an equivalence relation $B$ on\n$G$, the $B$ super $A$ graph is defined as a simple graph, whose vertex set is\n$G$ and two vertices $g$, $h$ are adjacent if either they are in the same\nequivalence class or there exist $g^{\\prime} \\in[g]$ and $h^{\\prime} \\in[h]$\nsuch that $g^{\\prime}$ and $h^{\\prime}$ are adjacent in $A$. In the literature,\nthe $B$ super $A$ graphs have been investigated by considering $A$ to be either\npower graph, enhanced power graph, or commuting graph and $B$ to be an\nequality, order or conjugacy relation. In this paper, we investigate the Sombor\nspectrums of these $B$ super $A$ graphs for certain non-abelian groups, viz.\nthe dihedral group, generalized quaternion group and the semidihedral group,\nrespectively.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-21T07:34:07Z"}
{"aid":"http://arxiv.org/abs/2504.14922v1","title":"Emulating multi-channel scattering based on the eigenvector continuation\n  in the discrete basis formalism","summary":"We construct an emulator for a multi-channel scattering problem based on the\neigenvector continuation. To this end, we employ the Kohn variational principle\nformulated in the discrete basis formalism. We apply this to one-dimensional\nscattering problems with a Gaussian barrier. Both for a single-channel and\ntwo-channel problems, we demonstrate that the penetration probability as well\nas the wave functions are well reproduced by the emulator. In particular, the\nenergy dependence of the penetrability in a wider range of energy from well\nbelow the barrier to well above the barrier is successfully reproduced.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-21T07:41:59Z"}
{"aid":"http://arxiv.org/abs/2504.14925v1","title":"Metamorphic quantum dot arrays in twisted trilayer hexagonal boron\n  nitride","summary":"A large set of controlled quantum states with tunable spacing and\ninteractions is crucial in understanding and engineering novel quantum\nmaterials for quantum information processing. Such achievements have been\nmostly confined to atomic physics, exemplified by ordered arrays of neutral\natoms or trapped ions. In solid-state systems, well-ordered quantum dots (QDs),\nin particular, also have significant potential for these applications. However,\ntheir precise large-scale fabrication and on-demand reconfigurations remain\nimportant challenges. Here, we predict that twisted trilayer hexagonal boron\nnitride hosts well-defined QD arrays with spatial precision and symmetry\ncontrol as well as exceptional dynamic repositioning. These arrays emerge\nnaturally at ultrasmall twist angles, forming diverse domain configurations\nincluding triangular, kagome and hexagram arrangements. The quantum states\nwithin each dot exhibit high fidelity to quantum harmonic oscillator\nwavefunctions, realizing uniform dot states as long as the moire-of-moire\nlattice is well ordered. Uniquely, we demonstrate that these arrays can be\ndynamically reconfigured via external electric fields coupled to local electric\npolarizations, allowing continuous tuning between regimes of strong coupling\nand complete isolation, and offering a pathway to long-ranged quantum\ninformation shuttling. This tunability and uniformity distinguish our platform\nfrom conventional implementations and suggest substantial potential for quantum\napplications, from array-based single-photon sources to scalable quantum\nprocessors, establishing twisted van der Waals systems as a promising platform\nfor programmable quantum architectures with spatial and energetic control.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-21T07:47:17Z"}
{"aid":"http://arxiv.org/abs/2504.14928v1","title":"EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent\n  Dialogue Framework","summary":"Large language models (LLMs) increasingly serve as educational tools, yet\nevaluating their teaching capabilities remains challenging due to the\nresource-intensive, context-dependent, and methodologically complex nature of\nteacher-student interactions. We introduce EducationQ, a multi-agent dialogue\nframework that efficiently assesses teaching capabilities through simulated\ndynamic educational scenarios, featuring specialized agents for teaching,\nlearning, and evaluation. Testing 14 LLMs across major AI Organizations\n(OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13\ndisciplines and 10 difficulty levels reveals that teaching effectiveness does\nnot correlate linearly with model scale or general reasoning capabilities -\nwith some smaller open-source models outperforming larger commercial\ncounterparts in teaching contexts. This finding highlights a critical gap in\ncurrent evaluations that prioritize knowledge recall over interactive pedagogy.\nOur mixed-methods evaluation, combining quantitative metrics with qualitative\nanalysis and expert case studies, identifies distinct pedagogical strengths\nemployed by top-performing models (e.g., sophisticated questioning strategies,\nadaptive feedback mechanisms). Human expert evaluations show 78% agreement with\nour automated qualitative analysis of effective teaching behaviors, validating\nour methodology. EducationQ demonstrates that LLMs-as-teachers require\nspecialized optimization beyond simple scaling, suggesting next-generation\neducational AI prioritize targeted enhancement of specific pedagogical\neffectiveness.","main_category":"cs.AI","categories":"cs.AI,cs.CE,cs.CL,cs.CY,cs.HC","published":"2025-04-21T07:48:20Z"}
{"aid":"http://arxiv.org/abs/2504.14934v1","title":"On negative eigenvalues of 1D Schrödinger operators with\n  $δ'$-like potentials","summary":"We study the asymptotic behavior of the discrete spectrum of one-dimensional\nSchr\\\"odinger operators with $\\delta'$-like potentials, which are used to\nconstruct exactly solvable models for localized dipoles in quantum mechanics.\nAlthough these operators converge in the norm resolvent topology to a limiting\noperator that is bounded from below, we prove that they can possess a finite\nbut arbitrarily large number of discrete eigenvalues that diverge to negative\ninfinity as the regularization parameter tends to zero. This phenomenon\nillustrates a spectral instability of Schr\\\"odinger operators with these\nsingular potentials.","main_category":"math.SP","categories":"math.SP,math-ph,math.MP","published":"2025-04-21T07:54:05Z"}
{"aid":"http://arxiv.org/abs/2504.14937v1","title":"Causal DAG Summarization (Full Version)","summary":"Causal inference aids researchers in discovering cause-and-effect\nrelationships, leading to scientific insights. Accurate causal estimation\nrequires identifying confounding variables to avoid false discoveries. Pearl's\ncausal model uses causal DAGs to identify confounding variables, but incorrect\nDAGs can lead to unreliable causal conclusions. However, for high dimensional\ndata, the causal DAGs are often complex beyond human verifiability. Graph\nsummarization is a logical next step, but current methods for general-purpose\ngraph summarization are inadequate for causal DAG summarization. This paper\naddresses these challenges by proposing a causal graph summarization objective\nthat balances graph simplification for better understanding while retaining\nessential causal information for reliable inference. We develop an efficient\ngreedy algorithm and show that summary causal DAGs can be directly used for\ninference and are more robust to misspecification of assumptions, enhancing\nrobustness for causal inference. Experimenting with six real-life datasets, we\ncompared our algorithm to three existing solutions, showing its effectiveness\nin handling high-dimensional data and its ability to generate summary DAGs that\nensure both reliable causal inference and robustness against misspecifications.","main_category":"cs.LG","categories":"cs.LG,cs.DB,stat.ME","published":"2025-04-21T08:01:32Z"}
{"aid":"http://arxiv.org/abs/2504.14942v1","title":"On Hamiltonicity and Perfect Codes in Non-Cyclic Graphs of Finite Groups","summary":"Let \\( G \\) be a finite non-cyclic group. Define \\( \\mathrm{Cyc}(G) \\) as the\nset of all elements \\( a \\in G \\) such that for any $b\\in G$, the subgroup \\(\n\\langle a, b \\rangle \\) is cyclic. The \\emph{non-cyclic graph} $\\Gamma(G)$ of\n\\( G \\) is a simple undirected graph with vertex set \\( G \\setminus\n\\mathrm{Cyc}(G) \\), where two distinct vertices \\( x \\) and \\( y \\) are\nadjacent if the subgroup \\( \\langle x, y \\rangle \\) is not cyclic. An\nindependent subset $C$ of the vertex set of a graph $\\Gamma$ is called a\nperfect code of $\\Gamma$ if every vertex of $V(\\Gamma)\\setminus C$ is adjacent\nto exactly one vertex in $C$. A subset \\( T \\) of the vertex set a graph \\(\n\\Gamma \\) is said to be a \\emph{total perfect code} if every vertex of \\(\n\\Gamma \\) is adjacent to exactly one vertex in \\( T \\). In this paper, we prove\nthat the graph $\\Gamma(G)$ is Hamiltonian for any finite non-cyclic nilpotent\ngroup $G$. Also, we characterize all finite groups such that their non-cyclic\ngraphs admit a perfect code. Finally, we prove that for a non-cyclic nilpotent\ngroup $G$, the non-cyclic graph $\\Gamma(G)$ does not admit total perfect code.","main_category":"math.CO","categories":"math.CO","published":"2025-04-21T08:05:24Z"}
{"aid":"http://arxiv.org/abs/2504.14943v1","title":"Cloud-cloud collision and star formation in G013.313+0.193","summary":"We study the G013.313+0.193 G013.313 region, a complex environment\ncharacterized by molecular cloud interactions indicative of cloud-cloud\ncollision (CCC). Observations of the NH3(1,1) and (2,2) inversion transitions\nwere obtained using the Nanshan 26 m radio telescope, while HCO+ (1-0), 12CO,\n13CO, and C18O(1-0) transitions from the Purple Mountain Observatory Delingha\n14 m telescope. Archival data are also included. We identified key\nobservational signatures of CCC, including complementary spatial distributions,\nU-shaped structures, bridge features, and V-shaped velocity distributions. The\nposition-velocity diagrams (P-V) reveal clear indications of gas interaction\nbetween two velocity components, suggesting an ongoing collision at an\nestimated angle of approximately 45 degree to the line of sight. The estimated\ncollision timescale is 0.35-1.03 Myr, aligned with the inferred ages of young\nstellar objects (YSOs) in the region, supporting the hypothesis of\ncollision-induced star formation. Hub-filament system (HFS) are identified in\nthe compressed gas region, where filaments converge toward a dense hub,\nsuggesting the CCC as a potential driver of HFS formation and massive star\nformation. The high column density suggests favorable conditions for the\nformation of massive stars. Although alternative kinematic drivers such as\nlongitudinal collapse and shear motion are considered, CCC remains the most\nplausible explanation for the observed features. Our findings contribute to our\nunderstanding of the mechanisms of cloud dynamics and massive star formation in\nturbulent molecular environments.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR,A.0","published":"2025-04-21T08:06:55Z"}
{"aid":"http://arxiv.org/abs/2504.14961v1","title":"Mitigating error cancellation in density functional approximations via\n  machine learning correction","summary":"The integration of machine learning (ML) with density functional theory has\nemerged as a promising strategy to enhance the accuracy of density functional\nmethods. While practical implementations of density functional approximations\n(DFAs) often exploit error cancellation between chemical species to achieve\nhigh accuracy in thermochemical and kinetic energy predictions, this approach\nis inherently system-dependent, which severely limits the transferability of\nDFAs. To address this challenge, we develop a novel ML-based correction to the\nwidely used B3LYP functional, directly targeting its deviations from the exact\nexchange-correlation functional. By utilizing highly accurate absolute energies\nas exclusive reference data, our approach eliminates the reliance on error\ncancellation. To optimize the ML model, we attribute errors to real-space\npointwise contributions and design a double-cycle protocol that incorporates\nself-consistent-field calculations into the training workflow. Numerical tests\ndemonstrate that the ML model, trained solely on absolute energies, improves\nthe accuracy of calculated relative energies, demonstrating that robust DFAs\ncan be constructed without resorting to error cancellation. Comprehensive\nbenchmarks further show that our ML-corrected B3LYP functional significantly\noutperforms the original B3LYP across diverse thermochemical and kinetic energy\ncalculations, offering a versatile and superior alternative for practical\napplications.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-21T08:40:22Z"}
{"aid":"http://arxiv.org/abs/2504.14968v1","title":"Intervals without primes near an iterated linear recurrence sequence","summary":"Let $M$ be a fixed positive integer. Let $(R_{j}(n))_{n\\ge 1}$ be a linear\nrecurrence sequence for every $j=0,1,\\ldots, M$, and we set $f(n)=(R_0\\circ\n\\cdots \\circ R_M)(n)$, where $(S\\circ T)(n)= S(T(n))$. In this paper, we obtain\nsufficient conditions on $(R_{0}(n))_{n\\ge 1},\\ldots, (R_{M}(n))_{n\\ge 1}$ so\nthat the intervals $(|f(n)|-c\\log n, |f(n)|+c\\log n)$ do not contain any prime\nnumbers for infinitely many integers $n\\ge 1$, where $c$ is an explicit\npositive constant depending only on the orders of $R_0,\\ldots, R_M$. As a\ncorollary, we show that if for each $j=1,2,\\ldots, M$, the sequence\n$(R_j(n))_{n\\ge 1}$ is positive, strictly increasing, and the constant term of\nits characteristic polynomial is $\\pm 1$, then for every Pisot or Salem number\n$\\alpha$, the numbers $\\lfloor \\alpha^{(R_1\\circ \\cdots \\circ R_M)(n)} \\rfloor\n$ are composite for infinitely many integers $n\\ge 1$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-21T08:55:16Z"}
{"aid":"http://arxiv.org/abs/2504.14972v1","title":"Effect of presence of rigid impurities in a system of annihilating\n  domain walls with dynamic bias","summary":"The dynamics of interacting domain walls, regarded as a system of particles\nwhich are biased to move towards their nearest neighbours and annihilate when\nthey meet, have been studied in the recent past. We study the effect of the\npresence of a fraction $r$ of quenched impurities (which act as rigid walkers)\non the dynamics. Here, in case two domain walls or one impurity and one domain\nwall happen to be on the same site, both get simultaneously annihilated. It is\nfound that for any non-zero value of $r$, the dynamical behaviour changes as\nthe surviving fraction of particles $\\rho(t)$ attains a constant value.\n$\\rho(t)t^\\alpha $ shows a universal behaviour when plotted against $r^\\beta t$\nwith $\\alpha, \\beta$ values depending on whether the particles are rigid or\nnonrigid. Also, the values differ for the biased and unbiased cases. The time\nscale associated with the particle decay obtained in several ways shows that it\nvaries with $r$ in a power law manner with a universal exponent.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-21T08:59:34Z"}
{"aid":"http://arxiv.org/abs/2504.14981v1","title":"On feature representations for marmoset vocal communication analysis","summary":"The acoustic analysis of marmoset (Callithrix jacchus) vocalizations is often\nused to understand the evolutionary origins of human language. Currently, the\nanalysis is largely carried out in a manual or semi-manual manner. Thus, there\nis a need to develop automatic call analysis methods. In that direction,\nresearch has been limited to the development of analysis methods with small\namounts of data or for specific scenarios. Furthermore, there is lack of prior\nknowledge about what type of information is relevant for different call\nanalysis tasks. To address these issues, as a first step, this paper explores\ndifferent feature representation methods, namely, HCTSA-based hand-crafted\nfeatures Catch22, pre-trained self supervised learning (SSL) based features\nextracted from neural networks trained on human speech and end-to-end acoustic\nmodeling for call-type classification, caller identification and caller sex\nidentification. Through an investigation on three different marmoset call\ndatasets, we demonstrate that SSL-based feature representations and end-to-end\nacoustic modeling tend to lead to better systems than Catch22 features for\ncall-type and caller classification. Furthermore, we also highlight the impact\nof signal bandwidth on the obtained task performances.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-21T09:15:45Z"}
{"aid":"http://arxiv.org/abs/2504.14987v1","title":"A general approach to distributed operator splitting","summary":"Splitting methods have emerged as powerful tools to address complex problems\nby decomposing them into smaller solvable components. In this work, we develop\na general approach of forward-backward splitting methods for solving monotone\ninclusion problems involving both set-valued and single-valued operators, where\nthe latter may lack cocoercivity. Our proposed approach, based on some\ncoefficient matrices, not only encompasses several important existing\nalgorithms but also extends to new ones, offering greater flexibility for\ndifferent applications. Moreover, by appropriately selecting the coefficient\nmatrices, the resulting algorithms can be implemented in a distributed and\ndecentralized manner.","main_category":"math.OC","categories":"math.OC","published":"2025-04-21T09:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.14997v1","title":"Gravitational form factors of the pion in the self-consistent\n  light-front quark model","summary":"We present a self-consistent light-front quark model (LFQM) analysis of the\npion's gravitational form factors (GFFs), incorporating the Bakamjian-Thomas\n(BT) construction consistently throughout the framework. By uniformly applying\nthe BT formalism to both hadronic matrix elements and their associated Lorentz\nstructures, we achieve a current-component-independent extraction of the pion\nGFFs $A_\\pi(t)$ and $D_\\pi(t)$, thereby eliminating the light-front zero-mode\nambiguities that typically hinder conventional LFQM approaches. By tuning the\nmodel parameters, we identify an optimal set that successfully reproduces the\ndecay constant and electromagnetic form factor of the pion, while yielding a\n$D$-term value $D_\\pi(0) \\approx -1$, consistent with predictions from chiral\nperturbation theory. The $D$-term emerges as a sensitive probe of the pion's\ninternal dynamics, governing its mechanical radius -- the largest among the\ncharge, mass, and mechanical radii. We further examine the pion's spatial\nstructure via its associated two-dimensional light-front densities, including\nthe momentum density, transverse pressure, and shear stress, all of which\nsatisfy the required normalization and von Laue stability conditions. Our\nresults reveal a detailed mechanical landscape: a centrally peaked momentum\ndensity that decreases monotonically; a repulsive pressure near the center (up\nto $x_\\perp = 0.33$~fm) that transitions to attraction in the outer region; and\na shear stress profile peaking at an intermediate distance ($x_\\perp \\approx\n0.2$~fm).","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T09:53:57Z"}
{"aid":"http://arxiv.org/abs/2504.15001v1","title":"Weakly Approximating Knapsack in Subquadratic Time","summary":"We consider the classic Knapsack problem. Let $t$ and $\\mathrm{OPT}$ be the\ncapacity and the optimal value, respectively. If one seeks a solution with\ntotal profit at least $\\mathrm{OPT}/(1 + \\varepsilon)$ and total weight at most\n$t$, then Knapsack can be solved in $\\tilde{O}(n + (\\frac{1}{\\varepsilon})^2)$\ntime [Chen, Lian, Mao, and Zhang '24][Mao '24]. This running time is the best\npossible (up to a logarithmic factor), assuming that $(\\min,+)$-convolution\ncannot be solved in truly subquadratic time [K\\\"unnemann, Paturi, and Schneider\n'17][Cygan, Mucha, W\\k{e}grzycki, and W{\\l}odarczyk '19]. The same upper and\nlower bounds hold if one seeks a solution with total profit at least\n$\\mathrm{OPT}$ and total weight at most $(1 + \\varepsilon)t$. Therefore, it is\nnatural to ask the following question.\n  If one seeks a solution with total profit at least\n$\\mathrm{OPT}/(1+\\varepsilon)$ and total weight at most $(1 + \\varepsilon)t$,\ncan Knsapck be solved in $\\tilde{O}(n + (\\frac{1}{\\varepsilon})^{2-\\delta})$\ntime for some constant $\\delta > 0$?\n  We answer this open question affirmatively by proposing an $\\tilde{O}(n +\n(\\frac{1}{\\varepsilon})^{7/4})$-time algorithm.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-21T10:00:13Z"}
{"aid":"http://arxiv.org/abs/2504.15012v1","title":"Frequency Comb-based Wavelength Division Multiplexing and Detection\n  without Wavelength Demultiplexers","summary":"We demonstrate a wavelength division multiplexing (WDM) concept using\ndemultiplexer-free frequency combs at both transmitter and receiver in a\n4-wavelength 200-GHz-grid WDM system with flexible symbol rates, aiming to\navoid the power-hungry wavelength control on demultiplexers.","main_category":"physics.optics","categories":"physics.optics,eess.SP","published":"2025-04-21T10:30:53Z"}
{"aid":"http://arxiv.org/abs/2504.15016v1","title":"Probing high-order deformation effects in neutron-deficient nuclei\n  $^{246,248}$No with improved potential-energy-surface calculations","summary":"The high-order deformation effects in even-even $^{246,248}$No are\ninvestigated by means of pairing self-consistent Woods-Saxon-Strutinsky\ncalculations using the potential-energy-surface (PES) approach in an extended\ndeformation space $(\\beta_2, \\beta_3,\\beta_4,\\beta_5,\\beta_6,\\beta_7,\n\\beta_8)$. Based on the calculated two-dimensional-projected energy maps and\ndifferent potential-energy curves, we find that the highly even-order\ndeformations have an important impact on both the fission trajectory and energy\nminima, while the odd-order deformations, accompanying the even-order ones,\nprimarily affect the fission path beyond the second barrier. Relative to the\nlight actinide nuclei, nuclear ground state changes to the superdeformed\nconfiguration but the normally-deformed minimum, as the low-energy shape\nisomer, may still be primarily responsible for enhancing nuclear stability and\nensuring experimental accessibility in $^{246,248}$No. Our present\ninvestigation indicates the nonnegligible impact of high-order deformation\neffects along the fission valley and will be helpful for deepening the\nunderstandings of different deformation effects and deformation couplings in\nnuclei, especially in this neutron-deficient heavy-mass region.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-21T10:49:33Z"}
{"aid":"http://arxiv.org/abs/2504.15026v1","title":"Gaussian Shading++: Rethinking the Realistic Deployment Challenge of\n  Performance-Lossless Image Watermark for Diffusion Models","summary":"Ethical concerns surrounding copyright protection and inappropriate content\ngeneration pose challenges for the practical implementation of diffusion\nmodels. One effective solution involves watermarking the generated images.\nExisting methods primarily focus on ensuring that watermark embedding does not\ndegrade the model performance. However, they often overlook critical challenges\nin real-world deployment scenarios, such as the complexity of watermark key\nmanagement, user-defined generation parameters, and the difficulty of\nverification by arbitrary third parties. To address this issue, we propose\nGaussian Shading++, a diffusion model watermarking method tailored for\nreal-world deployment. We propose a double-channel design that leverages\npseudorandom error-correcting codes to encode the random seed required for\nwatermark pseudorandomization, achieving performance-lossless watermarking\nunder a fixed watermark key and overcoming key management challenges.\nAdditionally, we model the distortions introduced during generation and\ninversion as an additive white Gaussian noise channel and employ a novel soft\ndecision decoding strategy during extraction, ensuring strong robustness even\nwhen generation parameters vary. To enable third-party verification, we\nincorporate public key signatures, which provide a certain level of resistance\nagainst forgery attacks even when model inversion capabilities are fully\ndisclosed. Extensive experiments demonstrate that Gaussian Shading++ not only\nmaintains performance losslessness but also outperforms existing methods in\nterms of robustness, making it a more practical solution for real-world\ndeployment.","main_category":"cs.CV","categories":"cs.CV,cs.CR","published":"2025-04-21T11:18:16Z"}
{"aid":"http://arxiv.org/abs/2504.15041v1","title":"Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong\n  Person Re-identification","summary":"Lifelong Person Re-identification (LReID) suffers from a key challenge in\npreserving old knowledge while adapting to new information. The existing\nsolutions include rehearsal-based and rehearsal-free methods to address this\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\ncontinuously accumulating forgetting during the distillation process.\nRehearsal-free methods insufficiently learn the distribution of each domain,\nleading to forgetfulness over time. To solve these issues, we propose a novel\nDistribution-aware Forgetting Compensation (DAFC) model that explores\ncross-domain shared representation learning and domain-specific distribution\nintegration without using old exemplars or knowledge distillation. We propose a\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\nprompt elements and guide the prompt model to learn fine-grained\nrepresentations for each instance. This can enhance the differentiation of\nidentity information and establish the foundation for domain distribution\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\nto capture each domain-specific distribution by a dedicated expert network and\nadaptively consolidate them into a shared region in high-dimensional space. In\nthis manner, DAI can consolidate and enhance cross-domain shared representation\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\ndiscrimination and cross-domain consistency alignment strategies to facilitate\nmodel adaptive learning of new knowledge from the current domain and promote\nknowledge consolidation learning between acquired domain-specific\ndistributions, respectively. Experimental results show that our DAFC outperform\nstate-of-the-art methods by at least 9.8\\%/6.6\\% and 6.4\\%/6.2\\% of average\nmAP/R@1 on two training orders.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T11:53:43Z"}
{"aid":"http://arxiv.org/abs/2504.15055v1","title":"Failure of the comformal-map method for relativistic quantum billiards","summary":"We demonstrate that the conformal-map method introduced by Robnik in 1984 for\nnonrelativistic quantum billiards is not applicable for the quantization of\nrelativistic neutrino billiards (NBs) consisting of a massless non-interacting\nspin-1/2 particle confined to a two-dimensional domain. To be precise, we\ndemonstrate in this work, that this method does not provide solutions of the\nassociated Weyl (Dirac) equation, nor does it fulfill the boundary conditions\nimposed on the spinor eigenfunctions to ensure confinement of the particle to\nthe domain of the billiard. We review in detail the wave equation, boundary\nconditions and quantization of NBs and derivation of relevant equations, to\nmake the proof comprehensible for the general reader. Our results are\ncorroborated with numerical results for non-relativistic and relativistic\nquantum billiards whose shapes depend on a parameter, which allows the study of\nthe properties of their eigenstates as the classical dynamics experiences a\ntransition from regular to chaotic dynamics.","main_category":"nlin.CD","categories":"nlin.CD,quant-ph","published":"2025-04-21T12:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.15072v1","title":"Rhythm of Opinion: A Hawkes-Graph Framework for Dynamic Propagation\n  Analysis","summary":"The rapid development of social media has significantly reshaped the dynamics\nof public opinion, resulting in complex interactions that traditional models\nfail to effectively capture. To address this challenge, we propose an\ninnovative approach that integrates multi-dimensional Hawkes processes with\nGraph Neural Network, modeling opinion propagation dynamics among nodes in a\nsocial network while considering the intricate hierarchical relationships\nbetween comments. The extended multi-dimensional Hawkes process captures the\nhierarchical structure, multi-dimensional interactions, and mutual influences\nacross different topics, forming a complex propagation network. Moreover,\nrecognizing the lack of high-quality datasets capable of comprehensively\ncapturing the evolution of public opinion dynamics, we introduce a new dataset,\nVISTA. It includes 159 trending topics, corresponding to 47,207 posts, 327,015\nsecond-level comments, and 29,578 third-level comments, covering diverse\ndomains such as politics, entertainment, sports, health, and medicine. The\ndataset is annotated with detailed sentiment labels across 11 categories and\nclearly defined hierarchical relationships. When combined with our method, it\noffers strong interpretability by linking sentiment propagation to the comment\nhierarchy and temporal evolution. Our approach provides a robust baseline for\nfuture research.","main_category":"cs.SI","categories":"cs.SI,cs.CL","published":"2025-04-21T13:02:30Z"}
{"aid":"http://arxiv.org/abs/2504.15085v1","title":"Hierarchical Attention Fusion of Visual and Textual Representations for\n  Cross-Domain Sequential Recommendation","summary":"Cross-Domain Sequential Recommendation (CDSR) predicts user behavior by\nleveraging historical interactions across multiple domains, focusing on\nmodeling cross-domain preferences through intra- and inter-sequence item\nrelationships. Inspired by human cognitive processes, we propose Hierarchical\nAttention Fusion of Visual and Textual Representations (HAF-VT), a novel\napproach integrating visual and textual data to enhance cognitive modeling.\nUsing the frozen CLIP model, we generate image and text embeddings, enriching\nitem representations with multimodal data. A hierarchical attention mechanism\njointly learns single-domain and cross-domain preferences, mimicking human\ninformation integration. Evaluated on four e-commerce datasets, HAF-VT\noutperforms existing methods in capturing cross-domain user interests, bridging\ncognitive principles with computational models and highlighting the role of\nmultimodal data in sequential decision-making.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T13:18:54Z"}
{"aid":"http://arxiv.org/abs/2504.15094v1","title":"10$^4$-fold amplification of a tiny magnetic field to megagauss scale in\n  femtosecond, ultraintense laser-solid interaction","summary":"Generating a powerful and quasistatic magnetic field within the confines of a\ntabletop laboratory experiment has proven to be a persistent challenge. The\ncreation of magnetized high-energy-density plasma through such experiments\npresents significant opportunities for exploring several terrestrial as well as\nastrophysical phenomena, apart from controlling relativistic electron\ntransport, directly relevant for fusion schemes. Here we demonstrate that the\nmodest magnetic field (10$^{-3}$ megagauss ) in a common, readily available\nNeodymium magnet is amplified to 10's of megagauss levels lasting a few\npicoseconds, when excited by an ultraintense, femtosecond laser pulse. The\nexperimental findings are strongly supported by particle-in-cell simulations,\nwhich not only validate the observations but also unveil a potential dynamo\nmechanism responsible for the enhancement and amplification of the axial\nmagnetic field. These outcomes are of utmost importance in comprehending the\nintricacies of relativistic electron transport and the realm of magnetized\nlaboratory astrophysics.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-21T13:28:45Z"}
{"aid":"http://arxiv.org/abs/2504.15096v1","title":"Bisections of graphs under degree constraints","summary":"In this paper, we investigate the problem of finding {\\it bisections} (i.e.,\nbalanced bipartitions) in graphs. We prove the following two results for {\\it\nall} graphs $G$: (1). $G$ has a bisection where each vertex $v$ has at least\n$(1/4 - o(1))d_G(v)$ neighbors in its own part; (2). $G$ also has a bisection\nwhere each vertex $v$ has at least $(1/4 - o(1))d_G(v)$ neighbors in the\nopposite part. These results are asymptotically optimal up to a factor of\n$1/2$, aligning with what is expected from random constructions, and provide\nthe first systematic understanding of bisections in general graphs under degree\nconstraints. As a consequence, we establish for the first time the existence of\na function $f(k)$ such that for any $k\\geq 1$, every graph with minimum degree\nat least $f(k)$ admits a bisection where every vertex has at least $k$\nneighbors in its own part, as well as a bisection where every vertex has at\nleast $k$ neighbors in the opposite part.\n  Using a more general setting, we further show that for any $\\varepsilon > 0$,\nthere exist $c_\\varepsilon, c'_\\varepsilon > 0$ such that any graph $G$ with\nminimum degree at least $c_\\varepsilon k$ (respectively, $c'_\\varepsilon k$)\nadmits a bisection satisfying: every vertex has at least $k$ neighbors in its\nown part (respectively, in the opposite part), and at least $(1 -\n\\varepsilon)|V(G)|$ vertices have at least $k$ neighbors in the opposite part\n(respectively, in their own part). These results extend and strengthen\nclassical graph partitioning theorems of Erd\\H{o}s, Thomassen, and\nK\\\"{u}hn-Osthus, while additionally satisfying the bisection requirement.","main_category":"math.CO","categories":"math.CO","published":"2025-04-21T13:31:27Z"}
{"aid":"http://arxiv.org/abs/2504.15103v1","title":"Muon Imaging of Hydrotreatment Towers","summary":"This study presents the design and simulation-based validation of a muon\nimaging system tailored for potential applications in industrial hydrotreatment\ntowers. The system is built around a two-panel plastic scintillator hodoscope,\nequipped with silicon photomultipliers and read-out via a CAEN FERS-A5202\nacquisition system. The detector was calibrated using a stepwise ``staircase''\nmethod and characterized under open-sky and controlled conditions. We conducted\nmuon flux attenuation measurements to validate its response using variable lead\nshielding. We found agreement with simulations generated using the MEIGA\nframework and realistic cosmic ray spectra from the ARTI simulation chain. With\nthe detector response validated, we modelled muon transmission through a\nrealistic 3D representation of a hydrotreatment tower, incorporating internal\nvariations in catalyst bed density. By reconstructing angular muon fluxes and\ncomputing relative attenuation maps, we demonstrated the system's capability to\ndetect internal density contrasts. Simulation results indicate that 20~hours of\nexposure to vertical muon flux is sufficient to retrieve structural\ninformation. In comparison, inclined configurations (30$^\\circ$ and 60$^\\circ$\nfrom vertical) require extended exposure times--up to 8~days--yet remain\nfeasible within industrial monitoring schedules. These findings highlight the\nfeasibility of muography as a non-invasive diagnostic tool for complex\nindustrial infrastructure. The proposed system shows strong potential for\nreal-time monitoring of catalyst bed integrity and long-term structural\nanalysis in high-pressure chemical reactors.","main_category":"physics.ins-det","categories":"physics.ins-det,physics.app-ph","published":"2025-04-21T13:53:17Z"}
{"aid":"http://arxiv.org/abs/2504.15108v1","title":"Unwarping Screen Content Images via Structure-texture Enhancement\n  Network and Transformation Self-estimation","summary":"While existing implicit neural network-based image unwarping methods perform\nwell on natural images, they struggle to handle screen content images (SCIs),\nwhich often contain large geometric distortions, text, symbols, and sharp\nedges. To address this, we propose a structure-texture enhancement network\n(STEN) with transformation self-estimation for SCI warping. STEN integrates a\nB-spline implicit neural representation module and a transformation error\nestimation and self-correction algorithm. It comprises two branches: the\nstructure estimation branch (SEB), which enhances local aggregation and global\ndependency modeling, and the texture estimation branch (TEB), which improves\ntexture detail synthesis using B-spline implicit neural representation.\nAdditionally, the transformation self-estimation module autonomously estimates\nthe transformation error and corrects the coordinate transformation matrix,\neffectively handling real-world image distortions. Extensive experiments on\npublic SCI datasets demonstrate that our approach significantly outperforms\nstate-of-the-art methods. Comparisons on well-known natural image datasets also\nshow the potential of our approach for natural image distortion.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T13:59:44Z"}
{"aid":"http://arxiv.org/abs/2504.15138v1","title":"Automatic Generation of Aerobatic Flight in Complex Environments via\n  Diffusion Models","summary":"Performing striking aerobatic flight in complex environments demands manual\ndesigns of key maneuvers in advance, which is intricate and time-consuming as\nthe horizon of the trajectory performed becomes long. This paper presents a\nnovel framework that leverages diffusion models to automate and scale up\naerobatic trajectory generation. Our key innovation is the decomposition of\ncomplex maneuvers into aerobatic primitives, which are short frame sequences\nthat act as building blocks, featuring critical aerobatic behaviors for\ntractable trajectory synthesis. The model learns aerobatic primitives using\nhistorical trajectory observations as dynamic priors to ensure motion\ncontinuity, with additional conditional inputs (target waypoints and optional\naction constraints) integrated to enable user-editable trajectory generation.\nDuring model inference, classifier guidance is incorporated with batch sampling\nto achieve obstacle avoidance. Additionally, the generated outcomes are refined\nthrough post-processing with spatial-temporal trajectory optimization to ensure\ndynamical feasibility. Extensive simulations and real-world experiments have\nvalidated the key component designs of our method, demonstrating its\nfeasibility for deploying on real drones to achieve long-horizon aerobatic\nflight.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T14:40:55Z"}
{"aid":"http://arxiv.org/abs/2504.15163v1","title":"Survey of Loss Augmented Knowledge Tracing","summary":"The training of artificial neural networks is heavily dependent on the\ncareful selection of an appropriate loss function. While commonly used loss\nfunctions, such as cross-entropy and mean squared error (MSE), generally\nsuffice for a broad range of tasks, challenges often emerge due to limitations\nin data quality or inefficiencies within the learning process. In such\ncircumstances, the integration of supplementary terms into the loss function\ncan serve to address these challenges, enhancing both model performance and\nrobustness. Two prominent techniques, loss regularization and contrastive\nlearning, have been identified as effective strategies for augmenting the\ncapacity of loss functions in artificial neural networks.\n  Knowledge tracing is a compelling area of research that leverages predictive\nartificial intelligence to facilitate the automation of personalized and\nefficient educational experiences for students. In this paper, we provide a\ncomprehensive review of the deep learning-based knowledge tracing (DKT)\nalgorithms trained using advanced loss functions and discuss their improvements\nover prior techniques. We discuss contrastive knowledge tracing algorithms,\nsuch as Bi-CLKT, CL4KT, SP-CLKT, CoSKT, and prediction-consistent DKT,\nproviding performance benchmarks and insights into real-world deployment\nchallenges. The survey concludes with future research directions, including\nhybrid loss strategies and context-aware modeling.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T15:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.15165v1","title":"An Efficient Aerial Image Detection with Variable Receptive Fields","summary":"Aerial object detection using unmanned aerial vehicles (UAVs) faces critical\nchallenges including sub-10px targets, dense occlusions, and stringent\ncomputational constraints. Existing detectors struggle to balance accuracy and\nefficiency due to rigid receptive fields and redundant architectures. To\naddress these limitations, we propose Variable Receptive Field DETR (VRF-DETR),\na transformer-based detector incorporating three key components: 1) Multi-Scale\nContext Fusion (MSCF) module that dynamically recalibrates features through\nadaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution\n(GConv) layer enabling parameter-efficient local-context modeling via depthwise\nseparable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF)\nBottleneck that hierarchically disentangles occluded objects through cascaded\nglobal-local interactions. Experiments on VisDrone2019 demonstrate VRF-DETR\nachieves 51.4\\% mAP\\textsubscript{50} and 31.8\\% mAP\\textsubscript{50:95} with\nonly 13.5M parameters. This work establishes a new efficiency-accuracy Pareto\nfrontier for UAV-based detection tasks.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T15:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.15166v1","title":"Simulating biochemical reactions: The Linear Noise Approximation can\n  capture non-linear dynamics","summary":"There is a plethora of highly stochastic non-linear dynamical systems in\nfields such as molecular biology, chemistry, epidemiology, and ecology. Yet,\nnone of the currently available stochastic models are both accurate and\ncomputationally efficient for long-term predictions of large systems. The\nLinear Noise Approximation (LNA) model for biochemical reaction networks is\nanalytically tractable, which makes it computationally efficient for\nsimulation, analysis, and inference. However, it is only accurate for linear\nsystems and short-time transitions. Other methods can achieve greater accuracy\nacross a wider range of systems, including non-linear ones, but lack analytical\ntractability. This paper seeks to challenge the prevailing view by\ndemonstrating that the Linear Noise Approximation can indeed capture non-linear\ndynamics after certain modifications. We introduce a new framework that\nutilises centre manifold theory allowing us to identify simple interventions to\nthe LNA that do not significantly compromise its computational efficiency. We\ndevelop specific algorithms for systems that exhibit oscillations or\nbi-stability and demonstrate their accuracy and computational efficiency across\nmultiple examples.","main_category":"q-bio.QM","categories":"q-bio.QM,math.PR,physics.chem-ph,q-bio.MN","published":"2025-04-21T15:16:30Z"}
{"aid":"http://arxiv.org/abs/2504.15176v1","title":"DSPO: Direct Semantic Preference Optimization for Real-World Image\n  Super-Resolution","summary":"Recent advances in diffusion models have improved Real-World Image\nSuper-Resolution (Real-ISR), but existing methods lack human feedback\nintegration, risking misalignment with human preference and may leading to\nartifacts, hallucinations and harmful content generation. To this end, we are\nthe first to introduce human preference alignment into Real-ISR, a technique\nthat has been successfully applied in Large Language Models and Text-to-Image\ntasks to effectively enhance the alignment of generated outputs with human\npreferences. Specifically, we introduce Direct Preference Optimization (DPO)\ninto Real-ISR to achieve alignment, where DPO serves as a general alignment\ntechnique that directly learns from the human preference dataset. Nevertheless,\nunlike high-level tasks, the pixel-level reconstruction objectives of Real-ISR\nare difficult to reconcile with the image-level preferences of DPO, which can\nlead to the DPO being overly sensitive to local anomalies, leading to reduced\ngeneration quality. To resolve this dichotomy, we propose Direct Semantic\nPreference Optimization (DSPO) to align instance-level human preferences by\nincorporating semantic guidance, which is through two strategies: (a) semantic\ninstance alignment strategy, implementing instance-level alignment to ensure\nfine-grained perceptual consistency, and (b) user description feedback\nstrategy, mitigating hallucinations through semantic textual feedback on\ninstance-level images. As a plug-and-play solution, DSPO proves highly\neffective in both one-step and multi-step SR frameworks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T15:35:48Z"}
{"aid":"http://arxiv.org/abs/2504.15183v1","title":"Multiple Quantum Many-Body Clustering Probed by Dynamical Decoupling","summary":"The manipulation of quantum information in large systems requires precise\ncontrol of quantum systems that are out-of-equilibrium. As the size of the\nsystem increases, its fragility in response to external perturbations and\nintrinsic decoherence processes also increases. The degradation of the system\nresponse makes accurate measurements a challenging and time-consuming task.\nHowever, quantum information lifetime enhancement can be achieved by dynamical\ndecoupling techniques (DD), where an external drive with a frequency much\nhigher than the system's internal evolution renders signal acquisition with\ndecay times greater than 1000-fold. In this study, we demonstrate that the\nsystem response during a prethermal period, subject to Floquet control, can be\nutilized to probe the multiple quantum evolution of dense and highly connected\nspin systems. This approach exhibits an enhanced sensitivity at a reduced\nexperimental time. The enhanced signal-to-noise ratio achieved enabled the use\nof numerical inversion strategies to model the evolution of the excited\nmultiple quantum coherences, which describe the number of correlated spins\nwithin a cluster. We observed for the first time, to the best of our knowledge,\nthat the increase in the number of correlated spins with multiple quantum\nevolution is accompanied by an increase in the distribution of spin cluster\nsizes, which follows a quadratic law.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T15:46:05Z"}
{"aid":"http://arxiv.org/abs/2504.15184v1","title":"Wave Arithmetic: A Smooth Integral Representation of Number Theory","summary":"We introduce Wave Arithmetic, a smooth analytical framework in which natural,\ninteger, and rational numbers are represented not as discrete entities, but as\nintegrals of smooth, compactly supported or periodic kernel functions. In this\nformulation, each number arises as the accumulated amplitude of a structured\nwaveform -- an interference pattern encoded by carefully designed kernels.\nArithmetic operations such as addition, multiplication, and exponentiation are\nrealized as geometric and tensorial constructions over multidimensional\nintegration domains. Rational numbers emerge through amplitude scaling, and\nnegative values through sign inversion, preserving all classical arithmetic\nidentities within a continuous and differentiable structure. This\nrepresentation embeds number theory into the realm of smooth analysis, enabling\nnew interpretations of primality, factorization, and divisibility as geometric\nand spectral phenomena. Beyond technical formulation, Wave Arithmetic proposes\na paradigm shift: numbers as the collapsed states of harmonic processes --\nanalytic resonances rather than atomic symbols.","main_category":"math.LO","categories":"math.LO,math.NT,F.4.1","published":"2025-04-21T15:46:44Z"}
{"aid":"http://arxiv.org/abs/2504.15186v1","title":"Sum of Independent XGamma Distributions","summary":"The XGamma distribution is a generated distribution from a mixture of\nExponential and Gamma distributions. It is found that in many cases the XGamma\nhas more flexibility than the Exponential distribution. In this paper we\nconsider the sum of independent XGamma distributions with different parameters.\nWe showed that the probability density function of this distribution is a sum\nof the probability density function of the Erlang distributions. As a\nconsequence, we find exact closed expressions of the other related statistical\nfunctions. Next, we examine the estimation of the parameters by maximum\nlikelihood estimators. We observe in an applications a real data set which\nshows that this model provides better fit to the data as compared to the sum of\nthe Exponential distributions, the Hypoexponential models.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-04-21T15:55:29Z"}
{"aid":"http://arxiv.org/abs/2504.15189v1","title":"LACE: Controlled Image Prompting and Iterative Refinement with GenAI for\n  Professional Visual Art Creators","summary":"We present LACE, a hybrid Human-AI co-creative system integrated into Adobe\nPhotoshop supporting turn-taking and parallel interaction modes for iterative\nimage generation. Through a study with 21 participants across representational,\nabstract, and design tasks, we found turn-taking preferred in early stages for\nidea generation, and parallel modes suited for detailed refinement. While this\nshorter workshop paper provides key insights and highlights, the comprehensive\nfindings and detailed analysis are presented in a longer version available\nseparately on arXiv.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-21T15:57:33Z"}
{"aid":"http://arxiv.org/abs/2504.15194v1","title":"Quantum phase discrimination with applications to quantum search on\n  graphs","summary":"We study the phase discrimination problem, in which we want to decide whether\nthe eigenphase $\\theta\\in(-\\pi,\\pi]$ of a given eigenstate $|\\psi\\rangle$ with\neigenvalue $e^{i\\theta}$ is zero or not, using applications of the unitary $U$\nprovided as a black box oracle.We propose a quantum algorithm named {\\it\nquantum phase discrimination(QPD)} for this task, with optimal query complexity\n$\\Theta(\\frac{1}{\\lambda}\\log\\frac{1}{\\delta})$ to the oracle $U$, where\n$\\lambda$ is the gap between zero and non-zero eigenphases and $\\delta$ the\nallowed one-sided error. The quantum circuit is simple, consisting of only one\nancillary qubit and a sequence of controlled-$U$ interleaved with single qubit\n$Y$ rotations, whose angles are given by a simple analytical formula. Quantum\nphase discrimination could become a fundamental subroutine in other quantum\nalgorithms, as we present two applications to quantum search on graphs:\n  i) Spatial search on graphs. Inspired by the structure of QPD, we propose a\nnew quantum walk model, and based on them we tackle the spatial search problem,\nobtaining a novel quantum search algorithm. For any graph with any number of\nmarked vertices, the quantum algorithm that can find a marked vertex with\nprobability $\\Omega(1)$ in total evolution time $ O(\\frac{1}{\\lambda\n\\sqrt{\\varepsilon}})$ and query complexity $ O(\\frac{1}{\\sqrt{\\varepsilon}})$,\nwhere $\\lambda$ is the gap between the zero and non-zero eigenvalues of the\ngraph Laplacian and $\\varepsilon$ is a lower bound on the proportion of marked\nvertices.\n  ii) Path-finding on graphs.} By using QPD, we reduce the query complexity of\na path-finding algorithm proposed by Li and Zur [arxiv: 2311.07372] from\n$\\tilde{O}(n^{11})$ to $\\tilde{O}(n^8)$, in a welded-tree circuit graph with\n$\\Theta(n2^n)$ vertices.\n  Besides these two applications, we argue that more quantum algorithms might\nbenefit from QPD.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T16:06:43Z"}
{"aid":"http://arxiv.org/abs/2504.15198v1","title":"Scalable Discrete Event Simulation Tool for Large-Scale Cyber-Physical\n  Energy Systems: Advancing System Efficiency and Scalability","summary":"Modern power systems face growing risks from cyber-physical attacks,\nnecessitating enhanced resilience due to their societal function as critical\ninfrastructures. The challenge is that defense of large-scale\nsystems-of-systems requires scalability in their threat and risk assessment\nenvironment for cyber physical analysis including cyber-informed transmission\nplanning, decision-making, and intrusion response. Hence, we present a scalable\ndiscrete event simulation tool for analysis of energy systems, called DESTinE.\nThe tool is tailored for largescale cyber-physical systems, with a focus on\npower systems. It supports faster-than-real-time traffic generation and models\npacket flow and congestion under both normal and adversarial conditions. Using\nthree well-established power system synthetic cases with 500, 2000, and 10,000\nbuses, we overlay a constructed cyber network employing star and radial\ntopologies. Experiments are conducted to identify critical nodes within a\ncommunication network in response to a disturbance. The findings are\nincorporated into a constrained optimization problem to assess the impact of\nthe disturbance on a specific node and its cascading effects on the overall\nnetwork. Based on the solution of the optimization problem, a new hybrid\nnetwork topology is also derived, combining the strengths of star and radial\nstructures to improve network resilience. Furthermore, DESTinE is integrated\nwith a virtual server and a hardware-in-the-loop (HIL) system using Raspberry\nPi 5.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-21T16:14:45Z"}
{"aid":"http://arxiv.org/abs/2504.15203v1","title":"Fine features of entanglement dynamics in quenches across the Ising\n  quantum critical point","summary":"The task of exploring and understanding important aspects of\nfar-from-equilibrium dynamics of closed and generic quantum many-body systems\nhas received a thrust of attention in recent years, driven partly by remarkable\nadvances in ultracold experimental technologies. In this work, for the\nparadigmatic Ising spin chain with transverse and longitudinal fields, we\npresent numerical observations of several \"fine-grained\" features of\nfar-from-equilibrium dynamics, induced by quantum quenches across the Ising\ncritical point, from a quantum informational point of view that have hitherto\nescaped notice. Rather featureless dynamics is seen for ferromagnetic to\nparamagnetic quenches, but paramagnetic to ferromagnetic quenches exhibit rich\nbehaviour, including a series of sudden deaths and revivals of entanglement\nbetween two spins in the system's bulk, periodic but short-lived occurrences of\napproximately $1-$uniform states, non-analytic cusps in single-copy\nentanglement entropy for sufficiently big subsystems, insufficient mixedness\nand a series of scrambling-$\\textit{un}$scrambling of local information between\nneighboring spins. Moreover, essentially indistinguishable dynamics is seen at\nvery early times between the integrable limit (zero longitudinal field) and\nnon-integrable cases, with the former eventually showing signatures of better\nmixing and faster approach to equilibration than the latter. These features are\nexpected to hold for quench dynamics across Ising quantum critical points in\nmore complicated systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-21T16:19:17Z"}
{"aid":"http://arxiv.org/abs/2504.15205v1","title":"Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus\n  LLM Judges","summary":"Retrieval-augmented generation (RAG) enables large language models (LLMs) to\ngenerate answers with citations from source documents containing \"ground\ntruth\", thereby reducing system hallucinations. A crucial factor in RAG\nevaluation is \"support\", whether the information in the cited documents\nsupports the answer. To this end, we conducted a large-scale comparative study\nof 45 participant submissions on 36 topics to the TREC 2024 RAG Track,\ncomparing an automatic LLM judge (GPT-4o) against human judges for support\nassessment. We considered two conditions: (1) fully manual assessments from\nscratch and (2) manual assessments with post-editing of LLM predictions. Our\nresults indicate that for 56% of the manual from-scratch assessments, human and\nGPT-4o predictions match perfectly (on a three-level scale), increasing to 72%\nin the manual with post-editing condition. Furthermore, by carefully analyzing\nthe disagreements in an unbiased study, we found that an independent human\njudge correlates better with GPT-4o than a human judge, suggesting that LLM\njudges can be a reliable alternative for support assessment. To conclude, we\nprovide a qualitative analysis of human and GPT-4o errors to help guide future\niterations of support assessment.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR","published":"2025-04-21T16:20:43Z"}
{"aid":"http://arxiv.org/abs/2504.15207v1","title":"Parametric Gromov width of Liouville domains","summary":"The classical Gromov width measures the largest symplectic ball embeddable\ninto a symplectic manifold; inspired by the symplectic camel problem, we\ngeneralize this to ask how large a symplectic ball can be embedded as a family\nover a parameter space $N$. Given a smooth map $f: N \\to \\Omega$, where\n$\\Omega$ is a symplectic manifold, we define the parametric Gromov width\n$\\mathrm{Gr}(f,\\Omega)$ as the supremum of capacities $a$ for which there\nexists $F: N \\times B(a) \\to \\Omega$ with $F(\\eta, 0) = f(\\eta)$ and which\nrestricts to a symplectic embedding on each ball $\\{ \\eta \\} \\times B(a)$,\nwhere $B(a) \\subset \\mathbb{C}^n$ is the closed ball of capacity $a$. For\nLiouville domains $\\Omega$, we establish upper bounds on\n$\\mathrm{Gr}(f,\\Omega)$ using the Floer cohomology persistence module\nassociated to $\\Omega$. Specializing to fiberwise starshaped domains in the\ncotangent bundle $T^*M$, we derive computable bounds via filtered string\ntopology. Specific examples of $\\Omega$ -- including disk cotangent bundles of\nthin ellipsoids, open books, and tori -- demonstrate our bounds, and reveal\nconstraints on parameterized symplectic embeddings beyond the classical Gromov\nwidth.","main_category":"math.SG","categories":"math.SG","published":"2025-04-21T16:26:10Z"}
{"aid":"http://arxiv.org/abs/2504.15223v1","title":"A Deep Learning Framework for Sequence Mining with Bidirectional LSTM\n  and Multi-Scale Attention","summary":"This paper addresses the challenges of mining latent patterns and modeling\ncontextual dependencies in complex sequence data. A sequence pattern mining\nalgorithm is proposed by integrating Bidirectional Long Short-Term Memory\n(BiLSTM) with a multi-scale attention mechanism. The BiLSTM captures both\nforward and backward dependencies in sequences, enhancing the model's ability\nto perceive global contextual structures. At the same time, the multi-scale\nattention module assigns adaptive weights to key feature regions under\ndifferent window sizes. This improves the model's responsiveness to both local\nand global important information. Extensive experiments are conducted on a\npublicly available multivariate time series dataset. The proposed model is\ncompared with several mainstream sequence modeling methods. Results show that\nit outperforms existing models in terms of accuracy, precision, and recall.\nThis confirms the effectiveness and robustness of the proposed architecture in\ncomplex pattern recognition tasks. Further ablation studies and sensitivity\nanalyses are carried out to investigate the effects of attention scale and\ninput sequence length on model performance. These results provide empirical\nsupport for structural optimization of the model.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T16:53:02Z"}
{"aid":"http://arxiv.org/abs/2504.15227v1","title":"The preparation and properties of polycrystalline Bi$_2$O$_2$Se --\n  pitfalls and difficulties with reproducibility and charge transport limiting\n  parameters","summary":"Thermoelectric materials allow the direct conversion of waste heat into\nelectricity, and novel materials are being investigated for this purpose.\nRecently, doped Bi$_2$O$_2$Se has shown high application potential. In this\nstudy, we discuss causes for large variation in reported transport properties\nof pure Bi$_2$O$_2$Se and present a preparation method that improves the\nreproducibility of undoped polycrystalline samples and improves their stability\nunder thermal cycling. Key steps of this method include calcination of the\nBi$_2$O$_3$ precursor, purification of the synthesized material in a\ntemperature gradient, use of a coarse particle fraction and compaction of the\npowders in a Si3N4 die instead of a graphite die. The resulting polycrystalline\nmaterial exhibits improved reproducibility and enhanced resistance to thermal\ncycling. It has room temperature electrical conductivity {\\sigma}RT ~ 500 S.m-1\nand Seebeck coefficient S ~ -300 $\\mu$V.K$^{-1}$. These properties make it\nsuitable as a reference material for future doping studies. The presented\nsynthesis approach may provide a more reliable platform for investigating the\nintrinsic behavior and doping response of Bi$_2$O$_2$Se in thermoelectric\napplications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T16:58:05Z"}
{"aid":"http://arxiv.org/abs/2504.15239v1","title":"Toeplitz operators on large vector-valued Fock spaces","summary":"We characterize boundedness and compactness of Toeplitz operators on large\nvector-valued Fock spaces with Dall'Ara's weights [Adv.\\ Math., 285 (2015)\n1706--1740] in terms of generalized Berezin transforms, averaging functions,\nand Carleson measures. To determine Schatten class Toeplitz operators, we\nintroduce the operator-valued Berezin transform and averaging functions.","main_category":"math.FA","categories":"math.FA","published":"2025-04-21T17:13:50Z"}
{"aid":"http://arxiv.org/abs/2504.15247v1","title":"Lance: Efficient Random Access in Columnar Storage through Adaptive\n  Structural Encodings","summary":"The growing interest in artificial intelligence has created workloads that\nrequire both sequential and random access. At the same time, NVMe-backed\nstorage solutions have emerged, providing caching capability for large columnar\ndatasets in cloud storage. Current columnar storage libraries fall short of\neffectively utilizing an NVMe device's capabilities, especially when it comes\nto random access. Historically, this has been assumed an implicit weakness in\ncolumnar storage formats, but this has not been sufficiently explored. In this\npaper, we examine the effectiveness of popular columnar formats such as Apache\nArrow, Apache Parquet, and Lance in both random access and full scan tasks\nagainst NVMe storage.\n  We argue that effective encoding of a column's structure, such as the\nrepetition and validity information, is the key to unlocking the disk's\nperformance. We show that Parquet, when configured correctly, can achieve over\n60x better random access performance than default settings. We also show that\nthis high random access performance requires making minor trade-offs in scan\nperformance and RAM utilization. We then describe the Lance structural encoding\nscheme, which alternates between two different structural encodings based on\ndata width, and achieves better random access performance without making\ntrade-offs in scan performance or RAM utilization.","main_category":"cs.DB","categories":"cs.DB,H.3.2","published":"2025-04-21T17:22:18Z"}
{"aid":"http://arxiv.org/abs/2504.15248v1","title":"Searching for Compact Obscured Nuclei in Compton Thick AGN","summary":"Compact Obscured Nuclei (CONs) are heavily obscured infrared cores that have\nbeen found in local (ultra)luminous infrared galaxies (U/LIRGs). They show\nbright emission from vibrationally excited rotational transitions of HCN, known\nas HCN-vib, and are thought to harbor Compton Thick (CT, $N_{\\text{H}} \\geq\n10^{24}$ cm$^{-2}$) active galactic nuclei (AGN) or extreme compact starbursts.\nWe explore the potential evolutionary link between CONs and CT AGN by searching\nfor CONs in hard X-ray-confirmed CT AGN from the Great Observatories All-sky\nLIRG Survey (GOALS). Here, we present new Atacama Large\nMillimeter/submillimeter Array Band 6 observations that targeted HCN-vib\nemission in four hard X-ray-confirmed CT AGN. We analyze these objects together\nwith literature HCN-vib measurements of five additional hard X-ray-confirmed CT\nAGN from the GOALS sample. We do not detect any CONs in this combined sample of\nnine CT AGN. We then explore a proposed evolutionary sequence in which CONs\nevolve into X-ray-detectable CT AGN once outflows and feedback reduce the\ncolumn densities of the enshrouding gas. We find, however, no evidence of\nwell-developed dense molecular outflows in the observed CT AGN. While this\ncould suggest that CT AGN are not universally linked to CONs, it could also be\nexplained by a short duty cycle for molecular outflows.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T17:25:43Z"}
{"aid":"http://arxiv.org/abs/2504.15258v1","title":"Broadband Fourier transform spectroscopy of quantum emitters\n  photoluminescence with sub-nanosecond temporal resolution","summary":"The spectral characterization of quantum emitter luminescence over broad\nwavelength ranges and fast timescales is important for applications ranging\nfrom biophysics to quantum technologies. Here we present the application of\ntime-domain Fourier transform spectroscopy, based on a compact and stable\nbirefringent interferometer coupled to low-dark-count superconducting\nsingle-photon detectors, to the study of quantum emitters. We experimentally\ndemonstrate that the system enables spectroscopy of quantum emitters over a\nbroad wavelength interval from the near-infrared to the telecom range, where\ngrating-based spectrometers coupled to InGaAs cameras are typically noisy and\ninefficient. We further show that the high temporal resolution of single-photon\ndetectors, which can be on the order of tens of picoseconds, enables the\nmonitoring of spin-dependent spectral changes on sub-nanosecond timescales.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,physics.chem-ph,physics.optics","published":"2025-04-21T17:38:20Z"}
{"aid":"http://arxiv.org/abs/2504.15260v1","title":"Joint Knowledge and Power Management for Secure Semantic Communication\n  Networks","summary":"Recently, semantic communication (SemCom) has shown its great superiorities\nin resource savings and information exchanges. However, while its unique\nbackground knowledge guarantees accurate semantic reasoning and recovery,\nsemantic information security-related concerns are introduced at the same time.\nSince the potential eavesdroppers may have the same background knowledge to\naccurately decrypt the private semantic information transmitted between legal\nSemCom users, this makes the knowledge management in SemCom networks rather\nchallenging in joint consideration with the power control. To this end, this\npaper focuses on jointly addressing three core issues of power allocation,\nknowledge base caching (KBC), and device-to-device (D2D) user pairing (DUP) in\nsecure SemCom networks. We first develop a novel performance metric, namely\nsemantic secrecy throughput (SST), to quantify the information security level\nthat can be achieved at each pair of D2D SemCom users. Next, an SST\nmaximization problem is formulated subject to secure SemCom-related delay and\nreliability constraints. Afterward, we propose a security-aware resource\nmanagement solution using the Lagrange primal-dual method and a two-stage\nmethod. Simulation results demonstrate our proposed solution nearly doubles the\nSST performance and realizes less than half of the queuing delay performance\ncompared to different benchmarks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-21T17:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.15265v1","title":"Realization of maximally-entangling two-qutrit gates using the\n  Cross-Resonance scheme","summary":"Three-level systems have natural advantages over their two-level counterparts\nin quantum information and computation. Although generally used for qubits, the\nexisting superconducting transmon architecture can naturally be extended to\nthree levels, which allows the exploration of the entire qutrit Hilbert space.\nRealizing a maximally entangling two-qutrit gate is necessary for universal\nquantum computation using three-level systems. Our work extends the\nstate-of-the-art approach by providing a theoretical framework for realizing a\nhigh-fidelity two-qutrit generalized CR gate using the cross-resonance\nframework. Using our framework, we experimentally demonstrate two-qutrit\ngeneralized controlled-$\\sqrt{X}$ gates through simulations on QISKIT dynamics,\nwhich in turn allow us to obtain a maximum extracted concurrence of\n$97.2\\pm0.1\\%$, thereby demonstrating that entanglement has been achieved on\nall three levels. Using the above gates, we also prepare a two-qutrit Bell\nstate with a fidelity of $96.9\\pm 0.1\\%$.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T17:47:16Z"}
{"aid":"http://arxiv.org/abs/2504.15268v1","title":"Beating the Correlation Breakdown: Robust Inference, Flexible Scenarios,\n  and Stress Testing for Financial Portfolios","summary":"We live in a multivariate world, and effective modeling of financial\nportfolios, including their construction, allocation, forecasting, and risk\nanalysis, simply is not possible without explicitly modeling the dependence\nstructure of their assets. Dependence structure can drive portfolio results\nmore than many other parameters in investment and risk models, sometimes even\nmore than their combined effects, but the literature provides relatively little\nto define the finite-sample distributions of dependence measures in useable and\nuseful ways under challenging, real-world financial data conditions. Yet this\nis exactly what is needed to make valid inferences about their estimates, and\nto use these inferences for a myriad of essential purposes, such as hypothesis\ntesting, dynamic monitoring, realistic and granular scenario and reverse\nscenario analyses, and mitigating the effects of correlation breakdowns during\nmarket upheavals (which is when we need valid inferences the most). This work\ndevelops a new and straightforward method, Nonparametric Angles-based\nCorrelation (NAbC), for defining the finite-sample distributions of any\ndependence measure whose matrix of pairwise associations is positive definite\n(e.g. Pearsons, Kendalls Tau, Spearmans Rho, Chatterjees, Lancasters, Szekelys,\nand their many variants). The solution remains valid under marginal asset\ndistributions characterized by notably different and varying degrees of serial\ncorrelation, non-stationarity, heavy-tailedness, and asymmetry. Notably, NAbCs\np-values and confidence intervals remain analytically consistent at both the\nmatrix level and the pairwise cell level. Finally, NAbC maintains validity even\nwhen selected cells in the matrix are frozen for a given scenario or stress\ntest, that is, unaffected by the scenario, thus enabling flexible, granular,\nand realistic scenarios.","main_category":"q-fin.RM","categories":"q-fin.RM,q-fin.PM,q-fin.ST,stat.AP,G.3","published":"2025-04-21T17:52:36Z"}
{"aid":"http://arxiv.org/abs/2504.15270v1","title":"An LMM for Efficient Video Understanding via Reinforced Compression of\n  Video Cubes","summary":"Large Multimodal Models (LMMs) uniformly perceive video frames, creating\ncomputational inefficiency for videos with inherently varying temporal\ninformation density. This paper present \\textbf{Quicksviewer}, an LMM with new\nperceiving paradigm that partitions a video of nonuniform density into varying\ncubes using Gumbel Softmax, followed by a unified resampling for each cube to\nachieve efficient video understanding. This simple and intuitive approach\ndynamically compress video online based on its temporal density, significantly\nreducing spatiotemporal redundancy (overall 45$\\times$ compression rate), while\nenabling efficient training with large receptive field. We train the model from\na language backbone through three progressive stages, each incorporating\nlengthy videos on average of 420s/1fps thanks to the perceiving efficiency.\nWith only 0.8M total video-text samples for training, our model outperforms the\ndirect baseline employing a fixed partitioning strategy by a maximum of 8.72 in\naccuracy, demonstrating the effectiveness in performance. On Video-MME,\nQuicksviewer achieves SOTA under modest sequence lengths using just up to 5\\%\nof tokens per frame required by baselines. With this paradigm, scaling up the\nnumber of input frames reveals a clear power law of the model capabilities. It\nis also empirically verified that the segments generated by the cubing network\ncan help for analyzing continuous events in videos.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-21T17:57:21Z"}
{"aid":"http://arxiv.org/abs/2504.15558v1","title":"Dynamical mean-field analysis of adaptive Langevin diffusions:\n  Replica-symmetric fixed point and empirical Bayes","summary":"In many applications of statistical estimation via sampling, one may wish to\nsample from a high-dimensional target distribution that is adaptively evolving\nto the samples already seen. We study an example of such dynamics, given by a\nLangevin diffusion for posterior sampling in a Bayesian linear regression model\nwith i.i.d. regression design, whose prior continuously adapts to the Langevin\ntrajectory via a maximum marginal-likelihood scheme. Results of dynamical\nmean-field theory (DMFT) developed in our companion paper establish a precise\nhigh-dimensional asymptotic limit for the joint evolution of the prior\nparameter and law of the Langevin sample. In this work, we carry out an\nanalysis of the equations that describe this DMFT limit, under conditions of\napproximate time-translation-invariance which include, in particular, settings\nwhere the posterior law satisfies a log-Sobolev inequality. In such settings,\nwe show that this adaptive Langevin trajectory converges on a\ndimension-independent time horizon to an equilibrium state that is\ncharacterized by a system of scalar fixed-point equations, and the associated\nprior parameter converges to a critical point of a replica-symmetric limit for\nthe model free energy. As a by-product of our analyses, we obtain a new\ndynamical proof that this replica-symmetric limit for the free energy is exact,\nin models having a possibly misspecified prior and where a log-Sobolev\ninequality holds for the posterior law.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-22T03:24:09Z"}
{"aid":"http://arxiv.org/abs/2504.15564v1","title":"A Large-scale Class-level Benchmark Dataset for Code Generation with\n  LLMs","summary":"Recent advancements in large language models (LLMs) have demonstrated\npromising capabilities in code generation tasks. However, most existing\nbenchmarks focus on isolated functions and fail to capture the complexity of\nreal-world, class-level software structures. To address this gap, we introduce\na large-scale, Python class-level dataset curated from $13{,}174$ real-world\nopen-source projects. The dataset contains over 842,000 class skeletons, each\nincluding class and method signatures, along with associated docstrings when\navailable. We preserve structural and contextual dependencies critical to\nrealistic software development scenarios and enrich the dataset with static\ncode metrics to support downstream analysis. To evaluate the usefulness of this\ndataset, we use extracted class skeletons as prompts for GPT-4 to generate full\nclass implementations. Results show that the LLM-generated classes exhibit\nstrong lexical and structural similarity to human-written counterparts, with\naverage ROUGE@L, BLEU, and TSED scores of 0.80, 0.59, and 0.73, respectively.\nThese findings confirm that well-structured prompts derived from real-world\nclass skeletons significantly enhance LLM performance in class-level code\ngeneration. This dataset offers a valuable resource for benchmarking, training,\nand improving LLMs in realistic software engineering contexts.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.LG","published":"2025-04-22T03:33:57Z"}
{"aid":"http://arxiv.org/abs/2504.15571v1","title":"High-sensitivity and high-resolution collaborative determination of\n  birefringence coefficient using weak measurement","summary":"We present a high-sensitivity and high-resolution birefringence coefficient\ndetermination system for nm-level membrane films based on weak measurement,\naddressing the sensitivity-resolution trade-off. A tunable bandwidth light\nsource is exploited to achieve complementary momentum (P-pointer) and intensity\n(I-pointer) measurements,enabling calibration-free operation across various\nbandwidths, and to realize high-precision phase difference monitoring of the\nmeasured membranes.This method maps the birefringence effect to a weak-value\namplified signal of spectral shift and light intensity. The optimal resolution,\nachieved at a spectral width of 6 nm, is $1.5 \\times 10^{-8}$ RIU, while the\noptimal sensitivity is achieved when the light source is a narrow-linewidth\ncoherent laser, reaching 4710 mV/RIU. The linear range of the system covers a\nbroad birefringence coefficient range for crystals,from $10^{-6}$ to 0.1.\nFurthermore, the auxiliary optical path eliminates substrate interference,\nachieving a detection limit of the birefringence coefficient as low as\n$10^{-8}$ RIU.This approach, characterized high precision, high sensitivity,\nand strong robustness, provides an effective solution for the detection of\noptical nano-thin membrane parameters.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-22T03:56:40Z"}
{"aid":"http://arxiv.org/abs/2504.15573v1","title":"Instruction-Tuning Data Synthesis from Scratch via Web Reconstruction","summary":"The improvement of LLMs' instruction-following capabilities depends\ncritically on the availability of high-quality instruction-response pairs.\nWhile existing automatic data synthetic methods alleviate the burden of manual\ncuration, they often rely heavily on either the quality of seed data or strong\nassumptions about the structure and content of web documents. To tackle these\nchallenges, we propose Web Reconstruction (WebR), a fully automated framework\nfor synthesizing high-quality instruction-tuning (IT) data directly from raw\nweb documents with minimal assumptions. Leveraging the inherent diversity of\nraw web content, we conceptualize web reconstruction as an instruction-tuning\ndata synthesis task via a novel dual-perspective paradigm--Web as Instruction\nand Web as Response--where each web document is designated as either an\ninstruction or a response to trigger the reconstruction process. Comprehensive\nexperiments show that datasets generated by WebR outperform state-of-the-art\nbaselines by up to 16.65% across four instruction-following benchmarks.\nNotably, WebR demonstrates superior compatibility, data efficiency, and\nscalability, enabling enhanced domain adaptation with minimal effort. The data\nand code are publicly available at https://github.com/YJiangcm/WebR.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T04:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.15581v1","title":"Central limit theorems and moderate deviations for additive functionals\n  of SSEP on regular trees","summary":"In this paper, we are concerned with the symmetric simple exclusion process\n(SSEP) on the regular tree $\\mathcal{T}_d$. A central limit theorem and a\nmoderate deviation principle of the additive functional of the process are\nproved, which include the CLT and the MDP of the occupation time as special\ncases. A graphical representation of the SSEP plays the key role in proofs of\nthe main results, by which we can extend the martingale decomposition formula\nintroduced in Kipnis (1987) for the occupation time to the case of general\nadditive functionals.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T04:40:28Z"}
{"aid":"http://arxiv.org/abs/2504.15593v1","title":"Inverse Drexhage effect in Epsilon-Near-Zero Substrates","summary":"The Drexhage effect, caused by interference between a dipole and its image\nformed in a substrate, modifies the local density of optical states of quantum\nemitters which can either enhance or suppress their spontaneous emission rate\ndepending on the dipole orientation and distance from the substrate. Here, we\nshow that for an epsilon-near-zero (ENZ) substrate, the observed orientation\nand distance dependence of the spontaneous emission rate is reversed compared\nto metals. This inverse Drexhage effect is studied for ideal ENZ and real ENZ\nsubstrates compared with ideal and real metallic substrates. ENZ metamaterials\nconsisting of a subwavelength metal-dielectric stack are shown to exhibit the\nconventional Drexhage effects due to the large optical losses associated with\nthese materials. Our results could find applications in quantum sensing,\nquantum information, and energy-efficient optoelectronic devices.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-22T05:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.15594v1","title":"Analytical Softmax Temperature Setting from Feature Dimensions for\n  Model- and Domain-Robust Classification","summary":"In deep learning-based classification tasks, the softmax function's\ntemperature parameter $T$ critically influences the output distribution and\noverall performance. This study presents a novel theoretical insight that the\noptimal temperature $T^*$ is uniquely determined by the dimensionality of the\nfeature representations, thereby enabling training-free determination of $T^*$.\nDespite this theoretical grounding, empirical evidence reveals that $T^*$\nfluctuates under practical conditions owing to variations in models, datasets,\nand other confounding factors. To address these influences, we propose and\noptimize a set of temperature determination coefficients that specify how $T^*$\nshould be adjusted based on the theoretical relationship to feature\ndimensionality. Additionally, we insert a batch normalization layer immediately\nbefore the output layer, effectively stabilizing the feature space. Building on\nthese coefficients and a suite of large-scale experiments, we develop an\nempirical formula to estimate $T^*$ without additional training while also\nintroducing a corrective scheme to refine $T^*$ based on the number of classes\nand task complexity. Our findings confirm that the derived temperature not only\naligns with the proposed theoretical perspective but also generalizes\neffectively across diverse tasks, consistently enhancing classification\nperformance and offering a practical, training-free solution for determining\n$T^*$.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-22T05:14:38Z"}
{"aid":"http://arxiv.org/abs/2504.15597v1","title":"Linear independence for $A_1^{(1)}$ by using $C_{2}^{(1)}$","summary":"In the previous paper the authors proved linear independence of the\ncombinatorial spanning set for standard $C_\\ell^{(1)}$-module $L(k\\Lambda_0)$\nby establishing a connection with the combinatorial basis of\nFeigin-Stoyanovsky's type subspace $W(k\\Lambda_0)$ of $C_{2\\ell}^{(1)}$-module\n$L(k\\Lambda_0)$. In this note we extend this argument for $C_{1}^{(1)}\\cong\nA_{1}^{(1)}$ to all standard $A_{1}^{(1)}$-modules $L(\\Lambda)$. In the proof\nwe use a coefficient of an intertwining operator of the type\n$\\binom{L(\\Lambda_2)}{L(\\Lambda_1)\\ L(\\Lambda_1)}$ for standard\n$C_{2}^{(1)}$-modules.","main_category":"math.QA","categories":"math.QA","published":"2025-04-22T05:28:04Z"}
{"aid":"http://arxiv.org/abs/2504.15613v1","title":"Learning Dynamic Graphs via Tensorized and Lightweight Graph\n  Convolutional Networks","summary":"A dynamic graph (DG) is frequently encountered in numerous real-world\nscenarios. Consequently, A dynamic graph convolutional network (DGCN) has been\nsuccessfully applied to perform precise representation learning on a DG.\nHowever, conventional DGCNs typically consist of a static GCN coupled with a\nsequence neural network (SNN) to model spatial and temporal patterns\nseparately. This decoupled modeling mechanism inherently disrupts the intricate\nspatio-temporal dependencies. To address the issue, this study proposes a novel\nTensorized Lightweight Graph Convolutional Network (TLGCN) for accurate dynamic\ngraph learning. It mainly contains the following two key concepts: a) designing\na novel spatio-temporal information propagation method for joint propagation of\nspatio-temporal information based on the tensor M-product framework; b)\nproposing a tensorized lightweight graph convolutional network based on the\nabove method, which significantly reduces the memory occupation of the model by\nomitting complex feature transformation and nonlinear activation. Numerical\nexperiments on four real-world datasets demonstrate that the proposed TLGCN\noutperforms the state-of-the-art models in the weight estimation task on DGs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-22T06:13:32Z"}
{"aid":"http://arxiv.org/abs/2504.15625v1","title":"Comprehensive List Generation for Multi-Generator Reranking","summary":"Reranking models solve the final recommendation lists that best fulfill\nusers' demands. While existing solutions focus on finding parametric models\nthat approximate optimal policies, recent approaches find that it is better to\ngenerate multiple lists to compete for a ``pass'' ticket from an evaluator,\nwhere the evaluator serves as the supervisor who accurately estimates the\nperformance of the candidate lists. In this work, we show that we can achieve a\nmore efficient and effective list proposal with a multi-generator framework and\nprovide empirical evidence on two public datasets and online A/B tests. More\nimportantly, we verify that the effectiveness of a generator is closely related\nto how much it complements the views of other generators with sufficiently\ndifferent rerankings, which derives the metric of list comprehensiveness. With\nthis intuition, we design an automatic complementary generator-finding\nframework that learns a policy that simultaneously aligns the users'\npreferences and maximizes the list comprehensiveness metric. The experimental\nresults indicate that the proposed framework can further improve the\nmulti-generator reranking performance.","main_category":"cs.IR","categories":"cs.IR,H.3.3","published":"2025-04-22T06:34:57Z"}
{"aid":"http://arxiv.org/abs/2504.15637v1","title":"DR.FIX: Automatically Fixing Data Races at Industry Scale","summary":"Data races are a prevalent class of concurrency bugs in shared-memory\nparallel programs, posing significant challenges to software reliability and\nreproducibility. While there is an extensive body of research on detecting data\nraces and a wealth of practical detection tools across various programming\nlanguages, considerably less effort has been directed toward automatically\nfixing data races at an industrial scale. In large codebases, data races are\ncontinuously introduced and exhibit myriad patterns, making automated fixing\nparticularly challenging.\n  In this paper, we tackle the problem of automatically fixing data races at an\nindustrial scale. We present Dr.Fix, a tool that combines large language models\n(LLMs) with program analysis to generate fixes for data races in real-world\nsettings, effectively addressing a broad spectrum of racy patterns in complex\ncode contexts. Implemented for Go--the programming language widely used in\nmodern microservice architectures where concurrency is pervasive and data races\nare common--Dr.Fix seamlessly integrates into existing development workflows.\nWe detail the design of Dr.Fix and examine how individual design choices\ninfluence the quality of the fixes produced. Over the past 18 months, Dr.Fix\nhas been integrated into developer workflows at Uber demonstrating its\npractical utility. During this period, Dr.Fix produced patches for 224 (55%)\nfrom a corpus of 404 data races spanning various categories; 193 of these\npatches (86%) were accepted by more than a hundred developers via code reviews\nand integrated into the codebase.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.LG,cs.PL,cs.SE","published":"2025-04-22T06:56:15Z"}
{"aid":"http://arxiv.org/abs/2504.15641v1","title":"Diffuse X-ray emission in M51: a hierarchical Bayesian\n  spatially-resolved spectral analysis","summary":"X-ray observations can be used to effectively probe the galactic ecosystem,\nparticularly its hot and energetic components. However, existing X-ray studies\nof nearby star-forming galaxies are limited by insufficient data statistics and\na lack of suitable spectral modeling to account for X-ray emission and\nabsorption geometry. We present results from an X-ray spectral study of M51\nusing 1.3-Ms Chandra data, the most extensive for such a galaxy. This allows\nthe extraction of diffuse X-ray emission spectra from spiral arm\nphase-dependent regions using a logarithmic spiral coordinate system. A\nhierarchical Bayesian approach analyzes these spectra, testing models from\nsimple 1-T hot plasma to those including distributed hot plasma and\nX-ray-absorbing cool gas. We recommend a model fitting the spectra well,\nfeaturing a galactic corona with a lognormal temperature distribution and a\ndisk with mixed X-ray emissions and absorption. In this model, only half of the\ncoronal emission is subject to internal absorption. The best-fit absorbing gas\ncolumn density is roughly twice that inferred from optical extinction of\nstellar light. The temperature distribution shows a mean temperature of $\\sim\n0.1$ keV and an average one-dex dispersion that is enhanced on the spiral arms.\nThe corona's radiative cooling might balance the mechanical energy input from\nstellar feedback. These results highlight the effectiveness of X-ray mapping of\nthe corona and cool gas in spiral galaxies.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-04-22T06:57:57Z"}
{"aid":"http://arxiv.org/abs/2504.15661v1","title":"DiTPainter: Efficient Video Inpainting with Diffusion Transformers","summary":"Many existing video inpainting algorithms utilize optical flows to construct\nthe corresponding maps and then propagate pixels from adjacent frames to\nmissing areas by mapping. Despite the effectiveness of the propagation\nmechanism, they might encounter blurry and inconsistencies when dealing with\ninaccurate optical flows or large masks. Recently, Diffusion Transformer (DiT)\nhas emerged as a revolutionary technique for video generation tasks. However,\npretrained DiT models for video generation all contain a large amount of\nparameters, which makes it very time consuming to apply to video inpainting\ntasks. In this paper, we present DiTPainter, an end-to-end video inpainting\nmodel based on Diffusion Transformer (DiT). DiTPainter uses an efficient\ntransformer network designed for video inpainting, which is trained from\nscratch instead of initializing from any large pretrained models. DiTPainter\ncan address videos with arbitrary lengths and can be applied to video\ndecaptioning and video completion tasks with an acceptable time cost.\nExperiments show that DiTPainter outperforms existing video inpainting\nalgorithms with higher quality and better spatial-temporal consistency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T07:36:45Z"}
{"aid":"http://arxiv.org/abs/2504.15666v1","title":"Symbolic Runtime Verification and Adaptive Decision-Making for\n  Robot-Assisted Dressing","summary":"We present a control framework for robot-assisted dressing that augments\nlow-level hazard response with runtime monitoring and formal verification. A\nparametric discrete-time Markov chain (pDTMC) models the dressing process,\nwhile Bayesian inference dynamically updates this pDTMC's transition\nprobabilities based on sensory and user feedback. Safety constraints from\nhazard analysis are expressed in probabilistic computation tree logic, and\nsymbolically verified using a probabilistic model checker. We evaluate\nreachability, cost, and reward trade-offs for garment-snag mitigation and\nescalation, enabling real-time adaptation. Our approach provides a formal yet\nlightweight foundation for safety-aware, explainable robotic assistance.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T07:42:16Z"}
{"aid":"http://arxiv.org/abs/2504.15673v1","title":"Emergent epithelial elasticity governed by interfacial surface mechanics\n  and substrate interaction","summary":"During the life of animals, epithelial tissues undergo extensive\ndeformations--first to form organs during embryogensis and later to preserve\nintegrity and function in adulthood. To what extent these deformations resemble\nthat of non-living elastic materials is not well understood. We derive an\nelasticity theory of epithelia, supported by a thin layer of extracellular\nmaterial and the stroma, in which the mechanics of individual cells are\ndominated by differential interfacial tensions stemming from cell cortical\ntension and adhesion. Upon coarse-graining a discrete single-cell-level\nmechanics model, we obtain a harmonic deformation energy and derive the\ncritical conditions for the elastic instability, where an initially flat tissue\neither buckles out of plane or forms wrinkles. Due to the distinct origin of\nelasticity, the scaling of the critical load to induce an instability and the\nwrinkling wavelength with layer thickness is fundamentally different than in\nsolid plates. The theory also naturally describes reversal of the\ngroove-to-crest thickness-modulation phase--a recently observed epithelial\nshape feature which cannot be explained by the classical elasticity theory. Our\nwork provides a guideline for understanding the relative role of cell surface\ntensions and the interaction of tissues with substrates during epithelial\nmorphogenesis.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-04-22T07:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.15676v1","title":"Trustworthy Decentralized Autonomous Machines: A New Paradigm in\n  Automation Economy","summary":"Decentralized Autonomous Machines (DAMs) represent a transformative paradigm\nin automation economy, integrating artificial intelligence (AI), blockchain\ntechnology, and Internet of Things (IoT) devices to create self-governing\neconomic agents participating in Decentralized Physical Infrastructure Networks\n(DePIN). Capable of managing both digital and physical assets and unlike\ntraditional Decentralized Autonomous Organizations (DAOs), DAMs extend autonomy\ninto the physical world, enabling trustless systems for Real and Digital World\nAssets (RDWAs). In this paper, we explore the technological foundations, and\nchallenges of DAMs and argue that DAMs are pivotal in transitioning from\ntrust-based to trustless economic models, offering scalable, transparent, and\nequitable solutions for asset management. The integration of AI-driven\ndecision-making, IoT-enabled operational autonomy, and blockchain-based\ngovernance allows DAMs to decentralize ownership, optimize resource allocation,\nand democratize access to economic opportunities. Therefore, in this research,\nwe highlight the potential of DAMs to address inefficiencies in centralized\nsystems, reduce wealth disparities, and foster a post-labor economy.","main_category":"cs.MA","categories":"cs.MA,cs.CR","published":"2025-04-22T07:59:46Z"}
{"aid":"http://arxiv.org/abs/2504.15678v1","title":"Zoozve: A Strip-Mining-Free RISC-V Vector Extension with Arbitrary\n  Register Grouping Compilation Support (WIP)","summary":"Vector processing is crucial for boosting processor performance and\nefficiency, particularly with data-parallel tasks. The RISC-V \"V\" Vector\nExtension (RVV) enhances algorithm efficiency by supporting vector registers of\ndynamic sizes and their grouping. Nevertheless, for very long vectors, the\nstatic number of RVV vector registers and its power-of-two grouping can lead to\nperformance restrictions. To counteract this limitation, this work introduces\nZoozve, a RISC-V vector instruction extension that eliminates the need for\nstrip-mining. Zoozve allows for flexible vector register length and count\nconfigurations to boost data computation parallelism. With a data-adaptive\nregister allocation approach, Zoozve permits any register groupings and\naccurately aligns vector lengths, cutting down register overhead and\nalleviating performance declines from strip-mining. Additionally, the paper\ndetails Zoozve's compiler and hardware implementations using LLVM and\nSystemVerilog. Initial results indicate Zoozve yields a minimum 10.10$\\times$\nreduction in dynamic instruction count for fast Fourier transform (FFT), with a\nmere 5.2\\% increase in overall silicon area.","main_category":"cs.PL","categories":"cs.PL,cs.AR","published":"2025-04-22T08:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.15680v1","title":"Dynamics of late time universe in $f(Q)$ gravity","summary":"We construct cosmological model in nonmetricity scalar functional\ngravitational Lagrangian $f(Q)$ which describes the dynamical evolution of the\nlate accelerating universe. Cosmological models are constructed considering\ndifferent functional of $f(Q)$ gravity where $Q$ in the gravitational action.\nWe obtain cosmological model probing late universe with a constant jerk\nparameter. The observational constraints that are imposed on the model\nparameters for a realistic scenario estimated using the observational Hubble\ndata and the Pantheon dataset. The evolution of the deceleration parameter,\nenergy density and the equation of state (EoS) parameter are also explored. The\ntransition of the universe from a deceleration to an accelerating phase is\ninvestigated in different framework of $f(Q)$ theories. We also analyzed the\nvariation of the effective EoS parameter and found that the matter content in\nthe universe favours quintessence type fluid in all the $f(Q)$-gravity. The\nenergy conditions for a realistic scenario are examined and noted that the\neffective fluid violates the strong energy condition.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-22T08:04:29Z"}
{"aid":"http://arxiv.org/abs/2504.15684v1","title":"Hydrogen-poor Superluminous Supernovae with Bumpy Light Curves Powered\n  by Precessing Magnetars","summary":"Recent observations and statistical studies have revealed that a significant\nfraction of hydrogen-poor superluminous supernovae (SLSNe-I) exhibit light\ncurves that deviate from the smooth evolution predicted by the magnetar-powered\nmodel, instead showing one or more bumps after the primary peak. However, the\nformation mechanisms of these post-peak bumps remain a matter of debate.\nFurthermore, previous studies employing the magnetar-powered model have\ntypically assumed a fixed magnetic inclination angle and neglected the effects\nof magnetar precession. However, recent research has shown that the precession\nof newborn magnetars forming during the collapse of massive stars causes the\nmagnetic inclination angle to evolve over time, thereby influencing magnetic\ndipole radiation. In this paper, therefore, we incorporate the effects of\nmagnetar precession into the magnetar-powered model to develop the precessing\nmagnetar-powered model. Using this model, we successfully reproduce the\nmulti-band light curves of 6 selected representative SLSNe-I with post-peak\nbumps. Moreover, the derived model parameters fall within the typical parameter\nrange for SLSNe-I. By combining the precessing magnetars in SLSNe-I and long\nGRBs, we find that the ellipticity of magnetars is related to the dipole\nmagnetic field strength, which may suggest a common origin for the two\nphenomena. Our work provides a potential explanation for the origin of\npost-peak bumps in SLSNe-I and offers evidence for the early precession of\nnewborn magnetars formed in supernova explosions.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-22T08:07:50Z"}
{"aid":"http://arxiv.org/abs/2504.15686v1","title":"Invariant Learning with Annotation-free Environments","summary":"Invariant learning is a promising approach to improve domain generalization\ncompared to Empirical Risk Minimization (ERM). However, most invariant learning\nmethods rely on the assumption that training examples are pre-partitioned into\ndifferent known environments. We instead infer environments without the need\nfor additional annotations, motivated by observations of the properties within\nthe representation space of a trained ERM model. We show the preliminary\neffectiveness of our approach on the ColoredMNIST benchmark, achieving\nperformance comparable to methods requiring explicit environment labels and on\npar with an annotation-free method that poses strong restrictions on the ERM\nreference model.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-22T08:10:06Z"}
{"aid":"http://arxiv.org/abs/2504.15691v1","title":"Transfer Learning for High-dimensional Reduced Rank Time Series Models","summary":"The objective of transfer learning is to enhance estimation and inference in\na target data by leveraging knowledge gained from additional sources. Recent\nstudies have explored transfer learning for independent observations in\ncomplex, high-dimensional models assuming sparsity, yet research on time series\nmodels remains limited. Our focus is on transfer learning for sequences of\nobservations with temporal dependencies and a more intricate model parameter\nstructure. Specifically, we investigate the vector autoregressive model (VAR),\na widely recognized model for time series data, where the transition matrix can\nbe deconstructed into a combination of a sparse matrix and a low-rank one. We\npropose a new transfer learning algorithm tailored for estimating\nhigh-dimensional VAR models characterized by low-rank and sparse structures.\nAdditionally, we present a novel approach for selecting informative\nobservations from auxiliary datasets. Theoretical guarantees are established,\nencompassing model parameter consistency, informative set selection, and the\nasymptotic distribution of estimators under mild conditions. The latter\nfacilitates the construction of entry-wise confidence intervals for model\nparameters. Finally, we demonstrate the empirical efficacy of our methodologies\nthrough both simulated and real-world datasets.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-22T08:15:59Z"}
{"aid":"http://arxiv.org/abs/2504.15703v1","title":"Susceptibilities of conserved charges of hadronic matter","summary":"An effective description of hadronic matter in terms of \"effective free\nparticles\" is presented. Repulsive interactions among the hadrons have been\nmodelled by Excluded volume correction by considering the hadrons as liquid\ndrops, whose volume is inversely proportional to the cube root of the mass of\nthe species. The only adjustable parameter in the model is pion radius. We get\nbetter agreement to the lattice results as compared to the previous studies.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-22T08:45:39Z"}
{"aid":"http://arxiv.org/abs/2504.15725v1","title":"Low-overhead error detection with spacetime codes","summary":"We introduce a low-overhead approach for detecting errors in arbitrary\nClifford circuits on arbitrary qubit connectivities. Our method is based on the\nframework of spacetime codes, and is particularly suited to near-term hardware\nsince it has a much milder overhead in qubits and gates compared to error\ncorrection, while achieving a better sampling overhead than existing error\nmitigation methods. We present efficient algorithms for finding valid checks\nthat are simultaneously low weight, satisfy connectivity constraints, and cover\nlarge detecting regions within the circuit. Using this approach, we\nexperimentally demonstrate error detection on circuits of up to 50 logical\nqubits containing 2450 CZ gates, and show physical to logical fidelity gains of\nup to $236\\times$. Furthermore, we show our algorithm can efficiently find\nchecks in universal circuits, but the space of valid checks diminishes\nexponentially with the non-Cliffordness of the circuit. These theoretical and\nexperimental results suggest that Clifford-dominated circuits are promising\ncandidates for near-term quantum advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T09:20:25Z"}
{"aid":"http://arxiv.org/abs/2504.15736v1","title":"Riemannian Neural Geodesic Interpolant","summary":"Stochastic interpolants are efficient generative models that bridge two\narbitrary probability density functions in finite time, enabling flexible\ngeneration from the source to the target distribution or vice versa. These\nmodels are primarily developed in Euclidean space, and are therefore limited in\ntheir application to many distribution learning problems defined on Riemannian\nmanifolds in real-world scenarios. In this work, we introduce the Riemannian\nNeural Geodesic Interpolant (RNGI) model, which interpolates between two\nprobability densities on a Riemannian manifold along the stochastic geodesics,\nand then samples from one endpoint as the final state using the continuous flow\noriginating from the other endpoint. We prove that the temporal marginal\ndensity of RNGI solves a transport equation on the Riemannian manifold. After\ntraining the model's the neural velocity and score fields, we propose the\nEmbedding Stochastic Differential Equation (E-SDE) algorithm for stochastic\nsampling of RNGI. E-SDE significantly improves the sampling quality by reducing\nthe accumulated error caused by the excessive intrinsic discretization of\nRiemannian Brownian motion in the classical Geodesic Random Walk (GRW)\nalgorithm. We also provide theoretical bounds on the generative bias measured\nin terms of KL-divergence. Finally, we demonstrate the effectiveness of the\nproposed RNGI and E-SDE through experiments conducted on both collected and\nsynthetic distributions on S2 and SO(3).","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-22T09:28:29Z"}
{"aid":"http://arxiv.org/abs/2504.15756v1","title":"DSDNet: Raw Domain Demoiréing via Dual Color-Space Synergy","summary":"With the rapid advancement of mobile imaging, capturing screens using\nsmartphones has become a prevalent practice in distance learning and conference\nrecording. However, moir\\'e artifacts, caused by frequency aliasing between\ndisplay screens and camera sensors, are further amplified by the image signal\nprocessing pipeline, leading to severe visual degradation. Existing sRGB domain\ndemoir\\'eing methods struggle with irreversible information loss, while recent\ntwo-stage raw domain approaches suffer from information bottlenecks and\ninference inefficiency. To address these limitations, we propose a single-stage\nraw domain demoir\\'eing framework, Dual-Stream Demoir\\'eing Network (DSDNet),\nwhich leverages the synergy of raw and YCbCr images to remove moir\\'e while\npreserving luminance and color fidelity. Specifically, to guide luminance\ncorrection and moir\\'e removal, we design a raw-to-YCbCr mapping pipeline and\nintroduce the Synergic Attention with Dynamic Modulation (SADM) module. This\nmodule enriches the raw-to-sRGB conversion with cross-domain contextual\nfeatures. Furthermore, to better guide color fidelity, we develop a\nLuminance-Chrominance Adaptive Transformer (LCAT), which decouples luminance\nand chrominance representations. Extensive experiments demonstrate that DSDNet\noutperforms state-of-the-art methods in both visual quality and quantitative\nevaluation, and achieves an inference speed $\\mathrm{\\textbf{2.4x}}$ faster\nthan the second-best method, highlighting its practical advantages. We provide\nan anonymous online demo at https://xxxxxxxxdsdnet.github.io/DSDNet/.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-22T10:09:33Z"}
{"aid":"http://arxiv.org/abs/2504.15758v1","title":"Observability conditions for neural state-space models with eigenvalues\n  and their roots of unity","summary":"We operate through the lens of ordinary differential equations and control\ntheory to study the concept of observability in the context of neural\nstate-space models and the Mamba architecture. We develop strategies to enforce\nobservability, which are tailored to a learning context, specifically where the\nhidden states are learnable at initial time, in conjunction to over its\ncontinuum, and high-dimensional. We also highlight our methods emphasize\neigenvalues, roots of unity, or both. Our methods effectuate computational\nefficiency when enforcing observability, sometimes at great scale. We formulate\nobservability conditions in machine learning based on classical control theory\nand discuss their computational complexity. Our nontrivial results are\nfivefold. We discuss observability through the use of permutations in neural\napplications with learnable matrices without high precision. We present two\nresults built upon the Fourier transform that effect observability with high\nprobability up to the randomness in the learning. These results are worked with\nthe interplay of representations in Fourier space and their eigenstructure,\nnonlinear mappings, and the observability matrix. We present a result for Mamba\nthat is similar to a Hautus-type condition, but instead employs an argument\nusing a Vandermonde matrix instead of eigenvectors. Our final result is a\nshared-parameter construction of the Mamba system, which is computationally\nefficient in high exponentiation. We develop a training algorithm with this\ncoupling, showing it satisfies a Robbins-Monro condition under certain\northogonality, while a more classical training procedure fails to satisfy a\ncontraction with high Lipschitz constant.","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY,math.DS,math.OC","published":"2025-04-22T10:10:52Z"}
{"aid":"http://arxiv.org/abs/2504.15768v1","title":"Distributed model predictive control without terminal cost under inexact\n  distributed optimization","summary":"This paper presents a novel distributed model predictive control (MPC)\nformulation without terminal cost and a corresponding distributed synthesis\napproach for distributed linear discrete-time systems with coupled constraints.\nThe proposed control scheme introduces an explicit stability condition as an\nadditional constraint based on relaxed dynamic programming. As a result,\ncontrary to other related approaches, system stability with the developed\ncontroller does not rely on designing a terminal cost. A distributed synthesis\napproach is then introduced to handle the stability constraint locally within\neach local agent. To solve the underlying optimization problem for distributed\nMPC, a violation-free distributed optimization approach is developed, using\nconstraint tightening to ensure feasibility throughout iterations. A numerical\nexample demonstrates that the proposed distributed MPC approach ensures\nclosed-loop stability for each feasible control sequence, with each agent\ncomputing its control input in parallel.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T10:25:36Z"}
{"aid":"http://arxiv.org/abs/2504.15777v1","title":"Tina: Tiny Reasoning Models via LoRA","summary":"How cost-effectively can strong reasoning abilities be achieved in language\nmodels? Driven by this fundamental question, we present Tina, a family of tiny\nreasoning models achieved with high cost-efficiency. Notably, Tina demonstrates\nthat substantial reasoning performance can be developed using only minimal\nresources, by applying parameter-efficient updates during reinforcement\nlearning (RL), using low-rank adaptation (LoRA), to an already tiny 1.5B\nparameter base model. This minimalist approach produces models that achieve\nreasoning performance which is competitive with, and sometimes surpasses, SOTA\nRL reasoning models built upon the same base model. Crucially, this is achieved\nat a tiny fraction of the computational post-training cost employed by existing\nSOTA models. In fact, the best Tina model achieves a >20\\% reasoning\nperformance increase and 43.33\\% Pass@1 accuracy on AIME24, at only \\$9 USD\npost-training and evaluation cost (i.e., an estimated 260x cost reduction). Our\nwork reveals the surprising effectiveness of efficient RL reasoning via LoRA.\nWe validate this across multiple open-source reasoning datasets and various\nablation settings starting with a single, fixed set of hyperparameters.\nFurthermore, we hypothesize that this effectiveness and efficiency stem from\nLoRA rapidly adapting the model to the structural format of reasoning rewarded\nby RL, while largely preserving the base model's underlying knowledge. In\nservice of accessibility and open research, we fully open-source all code,\ntraining logs, and model weights \\& checkpoints.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-22T10:38:00Z"}
{"aid":"http://arxiv.org/abs/2504.15780v1","title":"TrustGeoGen: Scalable and Formal-Verified Data Engine for Trustworthy\n  Multi-modal Geometric Problem Solving","summary":"Mathematical geometric problem solving (GPS) often requires effective\nintegration of multimodal information and verifiable logical coherence. Despite\nthe fast development of large language models in general problem solving, it\nremains unresolved regarding with both methodology and benchmarks, especially\ngiven the fact that exiting synthetic GPS benchmarks are often not\nself-verified and contain noise and self-contradicted information due to the\nillusion of LLMs. In this paper, we propose a scalable data engine called\nTrustGeoGen for problem generation, with formal verification to provide a\nprincipled benchmark, which we believe lays the foundation for the further\ndevelopment of methods for GPS. The engine synthesizes geometric data through\nfour key innovations: 1) multimodal-aligned generation of diagrams, textual\ndescriptions, and stepwise solutions; 2) formal verification ensuring\nrule-compliant reasoning paths; 3) a bootstrapping mechanism enabling\ncomplexity escalation via recursive state generation and 4) our devised\nGeoExplore series algorithms simultaneously produce multi-solution variants and\nself-reflective backtracking traces. By formal logical verification,\nTrustGeoGen produces GeoTrust-200K dataset with guaranteed modality integrity,\nalong with GeoTrust-test testset. Experiments reveal the state-of-the-art\nmodels achieve only 49.17\\% accuracy on GeoTrust-test, demonstrating its\nevaluation stringency. Crucially, models trained on GeoTrust achieve OOD\ngeneralization on GeoQA, significantly reducing logical inconsistencies\nrelative to pseudo-label annotated by OpenAI-o1. Our code is available at\nhttps://github.com/Alpha-Innovator/TrustGeoGen","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-22T10:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.15792v1","title":"Development and evaluation of a deep learning algorithm for German word\n  recognition from lip movements","summary":"When reading lips, many people benefit from additional visual information\nfrom the lip movements of the speaker, which is, however, very error prone.\nAlgorithms for lip reading with artificial intelligence based on artificial\nneural networks significantly improve word recognition but are not available\nfor the German language. A total of 1806 video clips with only one\nGerman-speaking person each were selected, split into word segments, and\nassigned to word classes using speech-recognition software. In 38,391 video\nsegments with 32 speakers, 18 polysyllabic, visually distinguishable words were\nused to train and validate a neural network. The 3D Convolutional Neural\nNetwork and Gated Recurrent Units models and a combination of both models\n(GRUConv) were compared, as were different image sections and color spaces of\nthe videos. The accuracy was determined in 5000 training epochs. Comparison of\nthe color spaces did not reveal any relevant different correct classification\nrates in the range from 69% to 72%. With a cut to the lips, a significantly\nhigher accuracy of 70% was achieved than when cut to the entire speaker's face\n(34%). With the GRUConv model, the maximum accuracies were 87% with known\nspeakers and 63% in the validation with unknown speakers. The neural network\nfor lip reading, which was first developed for the German language, shows a\nvery high level of accuracy, comparable to English-language algorithms. It\nworks with unknown speakers as well and can be generalized with more word\nclasses.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T11:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.15800v1","title":"FinDER: Financial Dataset for Question Answering and Evaluating\n  Retrieval-Augmented Generation","summary":"In the fast-paced financial domain, accurate and up-to-date information is\ncritical to addressing ever-evolving market conditions. Retrieving this\ninformation correctly is essential in financial Question-Answering (QA), since\nmany language models struggle with factual accuracy in this domain. We present\nFinDER, an expert-generated dataset tailored for Retrieval-Augmented Generation\n(RAG) in finance. Unlike existing QA datasets that provide predefined contexts\nand rely on relatively clear and straightforward queries, FinDER focuses on\nannotating search-relevant evidence by domain experts, offering 5,703\nquery-evidence-answer triplets derived from real-world financial inquiries.\nThese queries frequently include abbreviations, acronyms, and concise\nexpressions, capturing the brevity and ambiguity common in the realistic search\nbehavior of professionals. By challenging models to retrieve relevant\ninformation from large corpora rather than relying on readily determined\ncontexts, FinDER offers a more realistic benchmark for evaluating RAG systems.\nWe further present a comprehensive evaluation of multiple state-of-the-art\nretrieval models and Large Language Models, showcasing challenges derived from\na realistic benchmark to drive future research on truthful and precise RAG in\nthe financial domain.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-22T11:30:13Z"}
{"aid":"http://arxiv.org/abs/2504.15805v1","title":"No-Regret Model Predictive Control with Online Learning of Koopman\n  Operators","summary":"We study a problem of simultaneous system identification and model predictive\ncontrol of nonlinear systems. Particularly, we provide an algorithm for systems\nwith unknown residual dynamics that can be expressed by Koopman operators. Such\nresidual dynamics can model external disturbances and modeling errors, such as\nwind and wave disturbances to aerial and marine vehicles, or inaccurate model\nparameters. The algorithm has finite-time near-optimality guarantees and\nasymptotically converges to the optimal non-causal controller. Specifically,\nthe algorithm enjoys sublinear \\textit{dynamic regret}, defined herein as the\nsuboptimality against an optimal clairvoyant controller that knows how the\nunknown dynamics will adapt to its states and actions. To this end, we assume\nthe algorithm is given Koopman observable functions such that the unknown\ndynamics can be approximated by a linear dynamical system. Then, it employs\nmodel predictive control based on the current learned model of the unknown\nresidual dynamics. This model is updated online using least squares in a\nself-supervised manner based on the data collected while controlling the\nsystem. We validate our algorithm in physics-based simulations of a cart-pole\nsystem aiming to maintain the pole upright despite inaccurate model parameters.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-22T11:40:21Z"}
{"aid":"http://arxiv.org/abs/2504.15806v1","title":"DAE-KAN: A Kolmogorov-Arnold Network Model for High-Index\n  Differential-Algebraic Equations","summary":"Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to\nMulti-Layer Perceptrons (MLPs) due to their superior function-fitting abilities\nin data-driven modeling. In this paper, we propose a novel framework, DAE-KAN,\nfor solving high-index differential-algebraic equations (DAEs) by integrating\nKANs with Physics-Informed Neural Networks (PINNs). This framework not only\npreserves the ability of traditional PINNs to model complex systems governed by\nphysical laws but also enhances their performance by leveraging the\nfunction-fitting strengths of KANs. Numerical experiments demonstrate that for\nDAE systems ranging from index-1 to index-3, DAE-KAN reduces the absolute\nerrors of both differential and algebraic variables by 1 to 2 orders of\nmagnitude compared to traditional PINNs. To assess the effectiveness of this\napproach, we analyze the drift-off error and find that both PINNs and DAE-KAN\noutperform classical numerical methods in controlling this phenomenon. Our\nresults highlight the potential of neural network methods, particularly\nDAE-KAN, in solving high-index DAEs with substantial computational accuracy and\ngeneralization, offering a promising solution for challenging partial\ndifferential-algebraic equations.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T11:42:02Z"}
{"aid":"http://arxiv.org/abs/2504.15811v1","title":"KOMPASS: the new cold neutron triple-axis-spectrometer specialized for\n  polarization analysis","summary":"KOMPASS is a polarized triple-axis cold neutron spectrometer recently\ninstalled at the FRM II neutron source. The instrument is designed to operate\nexclusively with polarized neutrons and is specialized in longitudinal\npolarization analysis using Helmholtz coils and spherical zero-field neutron\npolarimetry using a Cryopad device. The advanced guide system polarizes and\nfocuses flexibly in the scattering plane. A first, fixed parabolic focusing\npart contains a series of three polarizing supermirror V-cavities that produce\na highly polarized beam. By exchanging straight and parabolic front-end guide\nsections, the resolution of the instrument can be optimized to meet\nexperimental requirements. Large, double-focusing monochromator and analyzer\nunits with pyrolytic graphite crystals enable efficient and adaptive energy\nselection, and a compact supermirror cavity analyzes the final neutron\npolarization. Alternatively, or in combination with this cavity, a Heusler\npolarization analyzer can be used. KOMPASS offers full- and half-polarized\nconfigurations with or without secondary energy analysis and provides a wide\nrange of polarization options. Therefore, KOMPASS is well suited for various\nstudies of static and dynamic magnetic correlations with energy transfers on\nthe neutron energy loss side up to ~12 meV.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-22T11:50:57Z"}
{"aid":"http://arxiv.org/abs/2504.15815v1","title":"What's the Difference? Supporting Users in Identifying the Effects of\n  Prompt and Model Changes Through Token Patterns","summary":"Prompt engineering for large language models is challenging, as even small\nprompt perturbations or model changes can significantly impact the generated\noutput texts. Existing evaluation methods, either automated metrics or human\nevaluation, have limitations, such as providing limited insights or being\nlabor-intensive. We propose Spotlight, a new approach that combines both\nautomation and human analysis. Based on data mining techniques, we\nautomatically distinguish between random (decoding) variations and systematic\ndifferences in language model outputs. This process provides token patterns\nthat describe the systematic differences and guide the user in manually\nanalyzing the effects of their prompt and model changes efficiently. We create\nthree benchmarks to quantitatively test the reliability of token pattern\nextraction methods and demonstrate that our approach provides new insights into\nestablished prompt data. From a human-centric perspective, through\ndemonstration studies and a user study, we show that our token pattern approach\nhelps users understand the systematic differences of language model outputs,\nand we are able to discover relevant differences caused by prompt and model\nchanges (e.g. related to gender or culture), thus supporting the prompt\nengineering process and human-centric model behavior research.","main_category":"cs.CL","categories":"cs.CL,cs.HC,cs.LG","published":"2025-04-22T11:53:33Z"}
{"aid":"http://arxiv.org/abs/2504.15828v1","title":"Circularity and repetitiveness in non-injective DF0L systems","summary":"We study circularity in DF0L systems, a generalization of D0L systems. We\nfocus on two different types of circularity, called weak and strong\ncircularity. When the morphism is injective on the language of the system, the\ntwo notions are equivalent, but they may differ otherwise. Our main result\nshows that failure of weak circularity implies unbounded repetitiveness, and\nthat unbounded repetitiveness implies failure of strong circularity. This\nextends previous work by the second and third authors for injective systems. To\nhelp motivate this work, we also give examples of non-injective but strongly\ncircular systems.","main_category":"cs.DM","categories":"cs.DM","published":"2025-04-22T12:20:34Z"}
{"aid":"http://arxiv.org/abs/2504.15829v1","title":"Generative AI for Research Data Processing: Lessons Learnt From Three\n  Use Cases","summary":"There has been enormous interest in generative AI since ChatGPT was launched\nin 2022. However, there are concerns about the accuracy and consistency of the\noutputs of generative AI. We have carried out an exploratory study on the\napplication of this new technology in research data processing. We identified\ntasks for which rule-based or traditional machine learning approaches were\ndifficult to apply, and then performed these tasks using generative AI.\n  We demonstrate the feasibility of using the generative AI model Claude 3 Opus\nin three research projects involving complex data processing tasks:\n  1) Information extraction: We extract plant species names from historical\nseedlists (catalogues of seeds) published by botanical gardens.\n  2) Natural language understanding: We extract certain data points (name of\ndrug, name of health indication, relative effectiveness, cost-effectiveness,\netc.) from documents published by Health Technology Assessment organisations in\nthe EU.\n  3) Text classification: We assign industry codes to projects on the\ncrowdfunding website Kickstarter.\n  We share the lessons we learnt from these use cases: How to determine if\ngenerative AI is an appropriate tool for a given data processing task, and if\nso, how to maximise the accuracy and consistency of the results obtained.","main_category":"cs.AI","categories":"cs.AI,I.2.7","published":"2025-04-22T12:21:07Z"}
{"aid":"http://arxiv.org/abs/2504.15832v1","title":"Restoring of quantum state transferred along XY-spin chain and\n  entanglement evolution","summary":"We propose a protocol restoring the state transferred along the spin chain\ngoverned by the XY-Hamiltonian. Such dynamics does not preserve the excitation\nnumber and leads to mixing multiple-quantum coherence matrices of orders having\nthe same parities. Depending on the initial state, this results in\n  generating ether all possible or only even-order multiple-quantum coherence\nmatrices. Restoring is established via the special unitary transformation\napplied to the receiver side of the chain (extended receiver). An example of\nrestoring $\\pm1$ and $\\pm 2$-order coherence matrices in two-qubit state\ntransfer is considered. Entanglement transfer in such process is also studied\nand possibility of its amplification is demonstrated.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T12:25:01Z"}
{"aid":"http://arxiv.org/abs/2504.15838v1","title":"Gaussian behaviors: representations and data-driven control","summary":"We propose a modeling framework for stochastic systems based on Gaussian\nprocesses. Finite-length trajectories of the system are modeled as random\nvectors from a Gaussian distribution, which we call a Gaussian behavior. The\nproposed model naturally quantifies the uncertainty in the trajectories, yet it\nis simple enough to allow for tractable formulations. We relate the proposed\nmodel to existing descriptions of dynamical systems including deterministic and\nstochastic behaviors, and linear time-invariant (LTI) state-space models with\nGaussian process and measurement noise. Gaussian behaviors can be estimated\ndirectly from observed data as the empirical sample covariance under the\nassumption that the measured trajectories are from independent experiments. The\ndistribution of future outputs conditioned on inputs and past outputs provides\na predictive model that can be incorporated in predictive control frameworks.\nWe show that subspace predictive control (SPC) is a certainty-equivalence\ncontrol formulation with the estimated Gaussian behavior. Furthermore, the\nregularized data-enabled predictive control (DeePC) method is shown to be a\ndistributionally optimistic formulation that optimistically accounts for\nuncertainty in the Gaussian behavior. To mitigate the excessive optimism of\nDeePC, we propose a novel distributionally robust control formulation, and\nprovide a convex reformulation allowing for efficient implementation.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-22T12:31:10Z"}
{"aid":"http://arxiv.org/abs/2504.15845v1","title":"Contrasting Deadlock-Free Session Processes (Extended Version)","summary":"Deadlock freedom is a crucial property for message-passing programs. Over the\nyears, several different type systems for concurrent processes that ensure\ndeadlock freedom have been proposed; this diversity raises the question of how\nthey compare. This paper addresses this question, considering two type systems\nnot covered in prior work: Kokke et al.'s HCP, a type system based on a linear\nlogic with hypersequents, and Padovani's priority-based type system for\nasynchronous processes, dubbed P. Their distinctive features make formal\ncomparisons relevant and challenging. Our findings are two-fold: (1) the\nhypersequent setting does not drastically change the class of deadlock-free\nprocesses induced by linear logic, and (2) we precisely relate the classes of\ndeadlock-free processes induced by HCP and P. We also prove that our results\nhold in an asynchronous setting. Our results provide new insights into the\nessential mechanisms involved in statically avoiding deadlocks in concurrency.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-22T12:42:37Z"}
{"aid":"http://arxiv.org/abs/2504.15856v1","title":"FailLite: Failure-Resilient Model Serving for Resource-Constrained Edge\n  Environments","summary":"Model serving systems have become popular for deploying deep learning models\nfor various latency-sensitive inference tasks. While traditional\nreplication-based methods have been used for failure-resilient model serving in\nthe cloud, such methods are often infeasible in edge environments due to\nsignificant resource constraints that preclude full replication. To address\nthis problem, this paper presents FailLite, a failure-resilient model serving\nsystem that employs (i) a heterogeneous replication where failover models are\nsmaller variants of the original model, (ii) an intelligent approach that uses\nwarm replicas to ensure quick failover for critical applications while using\ncold replicas, and (iii) progressive failover to provide low mean time to\nrecovery (MTTR) for the remaining applications. We implement a full prototype\nof our system and demonstrate its efficacy on an experimental edge testbed. Our\nresults using 27 models show that FailLite can recover all failed applications\nwith 175.5ms MTTR and only a 0.6% reduction in accuracy.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-22T12:52:11Z"}
{"aid":"http://arxiv.org/abs/2504.15872v1","title":"Multiscale detection of practically significant changes in a gradually\n  varying time series","summary":"In many change point problems it is reasonable to assume that compared to a\nbenchmark at a given time point $t_0$ the properties of the observed stochastic\nprocess change gradually over time for $t >t_0$. Often, these gradual changes\nare not of interest as long as they are small (nonrelevant), but one is\ninterested in the question if the deviations are practically significant in the\nsense that the deviation of the process compared to the time $t_0$ (measured by\nan appropriate metric) exceeds a given threshold, which is of practical\nsignificance (relevant change).\n  In this paper we develop novel and powerful change point analysis for\ndetecting such deviations in a sequence of gradually varying means, which is\ncompared with the average mean from a previous time period. Current approaches\nto this problem suffer from low power, rely on the selection of smoothing\nparameters and require a rather regular (smooth) development for the means. We\ndevelop a multiscale procedure that alleviates all these issues, validate it\ntheoretically and demonstrate its good finite sample performance on both\nsynthetic and real data.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-22T13:16:44Z"}
{"aid":"http://arxiv.org/abs/2504.15882v1","title":"Searching for heavy vector-like B quark via pair production in fully\n  hadronic channels at the CLIC","summary":"Vector-like quarks (VLQs) are introduced in many new physics senarios beyond\nthe Standard Model (SM) to address some problems faced by SM. In this paper, we\nexplore the pair production of TeV-scale vector-like B quark (VLQ-$B$) at the\nfuture 3 TeV Compact Linear Collider (CLIC) in simplified effective lagrangian\nframework. We consider the decay modes of $B\\rightarrow bZ$ and $B\\rightarrow\nbh$ followed by hadronic decay of $Z$ and $h$ bosons. The large mass of VLQ-$B$\nwill induce highly boosted bosons $Z$ or $h$ which are more likely to form as\nfat-jets. By performing a rapid detector simulation of the signal and\nbackground events and clustering the jets with a large radius R,\nsignal-background analyses are carried out. And the exclusion limit at the 95\\%\nconfidence level and the 5$\\sigma$ discovery prospects are obtained with an\nintegrated luminosity of 5$\\text{ab}^{-1}$.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-22T13:25:55Z"}
{"aid":"http://arxiv.org/abs/2504.15884v1","title":"3D Printing of Invariant Manifolds in Dynamical Systems","summary":"Invariant manifolds are one of the key features that organize the dynamics of\na differential equation. We introduce a novel approach to visualizing and\nstudying invariant manifolds by using 3D printing technology, combining\nadvanced computational techniques with modern 3D printing processes to\ntransform mathematical abstractions into tangible models. Our work addresses\nthe challenges of translating complex manifolds into printable meshes,\nshowcasing results for the following systems of differential equations: the\nLorenz system, the Arneodo-Coullet-Tresser system, and the Langford system. By\nbridging abstract mathematics and physical reality, this approach promises new\ntools for research and education in nonlinear dynamics. We conclude with\npractical guidelines for reproducing and extending our results, emphasizing the\npotential of 3D-printed manifolds to enhance understanding and exploration in\ndynamical systems theory.","main_category":"math.DS","categories":"math.DS","published":"2025-04-22T13:28:55Z"}
{"aid":"http://arxiv.org/abs/2504.15889v1","title":"Zinbiel bialgebras, relative Rota-Baxter operators and the related\n  Yang-Baxter Equation","summary":"In this paper, we first introduce the notion of a Zinbiel bialgebra and show\nthat Zinbiel bialgebras, matched pairs of Zinbiel algebras and Manin triples of\nZinbiel algebras are equivalent. Then we study the coboundary Zinbiel\nbialgebras, which leads to an analogue of the classical Yang-Baxter equation.\nMoreover, we introduce the notions of quasi-triangular and factorizable Zinbiel\nbialgebras as special cases. A quasi-triangular Zinbiel bialgebra can give rise\nto a relative Rota-Baxter operator of weight $-1$. A factorizable Zinbiel\nbialgebra can give a factorization of the underlying Zinbiel algebra.\n  As an example, we define the Zinbiel double of a Zinbiel bialgebra, which\nenjoys a natural factorizable Zinbiel bialgebra structure. Finally, we\nintroduce the notion of quadratic Rota-Baxter Zinbiel algebras, as the\nRota-Baxter characterization of factorizable Zinbiel bialgebras. We show that\nthere is a one-to-one correspondence between quadratic Rota-Baxter Zinbiel\nalgebras and factorizable Zinbiel bialgebras.","main_category":"math.RA","categories":"math.RA","published":"2025-04-22T13:34:18Z"}
{"aid":"http://arxiv.org/abs/2504.15890v1","title":"Tracing the imprints of large-scale magnetized structure on $γ$\n  rays from GRB 221009A","summary":"We search for possible GeV-TeV gamma-ray imprints of ultrahigh-energy (UHE;\n$\\gtrsim 0.1$ EeV) cosmic ray (CR) acceleration in the large-scale structures\nsurrounding the brightest gamma-ray burst (GRB) explosion, GRB 221009A. Using\n1.25 years of post-event Fermi Large Area Telescope (LAT) data, we construct a\n1 GeV - 1 TeV test-statistic (TS) map within 15 Mpc of the burst. We identify\ntwo peaks in the TS map with TS $\\geq 9$. The most significant peak,\nJ1911.8+2044, exhibits gamma-ray emission in pre-burst LAT data. The other\npeak, J1913.2+1901, coincides with a 664.6 GeV photon recorded $\\sim191.9$ days\nafter the GRB trigger and located at about $0.75^{\\circ}$ from the GRB\nlocalization. The per-photon 95% containment angle for the LAT is about\n$0.25^{\\circ}$ in the 100 GeV - 1 TeV energy range. We explore two possible\norigins for the $\\gamma$-ray emission: (1) UHECRs from GRB 221009A propagating\nthrough a magnetized cosmological volume in its vicinity, and (2) UHE or\nvery-high-energy (VHE; $\\gtrsim 100$ GeV) $\\gamma$-ray emission from GRB\n221009A, propagating in the same volume. In both cases, electromagnetic cascade\nemission is induced in the structured region embedding the burst. If any TS\nfeatures are related to large-scale imprints induced by cosmic rays, it might\nbe further evidence that GRB 221009A accelerated UHECRs. However, our results\nshow that alternative scenarios without invoking UHECRs cannot be ruled out,\nand the observed high-energy photon could be unrelated to GRB 221009A.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-22T13:34:35Z"}
{"aid":"http://arxiv.org/abs/2504.15904v1","title":"Dimensional Uplift in Conformal Field Theories","summary":"The n-point functions of any Conformal Field Theory (CFT) in $d$ dimensions\ncan always be interpreted as spatial restrictions of corresponding functions in\na higher-dimensional CFT with dimension $d'> d$. In particular, when a\nfour-point function in $d$ dimensions has a known conformal block expansion,\nthis expansion can be easily extended to $d'=d+2$ due to a remarkable identity\namong conformal blocks, discovered by Kaviraj, Rychkov, and Trevisani (KRT) as\na consequence of Parisi-Sourlas supersymmetry and confirmed to hold in any CFT\nwith $d > 1$. In this note, we provide an elementary proof of this identity\nusing simple algebraic properties of the Casimir operators. Additionally, we\nconstruct five differential operators, $\\Lambda_i$, which promote a conformal\nblock in $d$ dimensions to five conformal blocks in $d+2$ dimensions. These\noperators can be normalized such that $\\sum_i \\Lambda_i = 1$, from which the\nKRT identity immediately follows. Similar, simpler identities have been\nproposed, all of which can be reformulated in the same way.","main_category":"hep-th","categories":"hep-th","published":"2025-04-22T13:44:16Z"}
{"aid":"http://arxiv.org/abs/2504.15919v1","title":"Lax dynamics","summary":"A novel approach is proposed to characterize the dynamics of perturbed\nmany-body integrable systems. Focusing on the paradigmatic case of the Toda\nchain under non-integrable Hamiltonian perturbations, this study introduces a\nmethod based the time evolution of the Lax eigenvalues $\\lambda_\\alpha$ as a\nproxy of the quasi-particles velocities and of the perturbed Toda actions. A\nset of exact equations of motion for the $\\lambda_\\alpha$ is derived that\nclosely resemble those for eigenenergies of a quantum problem (also known as\nthe Pechukas-Yukawa gas). Numerical simulations suggest that the invariant\nmeasure of such dynamics is basically the thermal density of states of the Toda\nlattice, regardless of the form of the perturbation.","main_category":"nlin.SI","categories":"nlin.SI,cond-mat.stat-mech","published":"2025-04-22T14:04:27Z"}
{"aid":"http://arxiv.org/abs/2504.15922v1","title":"Language Models to Support Multi-Label Classification of Industrial Data","summary":"Multi-label requirements classification is a challenging task, especially\nwhen dealing with numerous classes at varying levels of abstraction. The\ndifficulties increases when a limited number of requirements is available to\ntrain a supervised classifier. Zero-shot learning (ZSL) does not require\ntraining data and can potentially address this problem. This paper investigates\nthe performance of zero-shot classifiers (ZSCs) on a multi-label industrial\ndataset. We focuse on classifying requirements according to a taxonomy designed\nto support requirements tracing. We compare multiple variants of ZSCs using\ndifferent embeddings, including 9 language models (LMs) with a reduced number\nof parameters (up to 3B), e.g., BERT, and 5 large LMs (LLMs) with a large\nnumber of parameters (up to 70B), e.g., Llama. Our ground truth includes 377\nrequirements and 1968 labels from 6 output spaces. For the evaluation, we adopt\ntraditional metrics, i.e., precision, recall, F1, and $F_\\beta$, as well as a\nnovel label distance metric Dn. This aims to better capture the\nclassification's hierarchical nature and provides a more nuanced evaluation of\nhow far the results are from the ground truth. 1) The top-performing model on 5\nout of 6 output spaces is T5-xl, with maximum $F_\\beta$ = 0.78 and Dn = 0.04,\nwhile BERT base outperformed the other models in one case, with maximum\n$F_\\beta$ = 0.83 and Dn = 0.04. 2) LMs with smaller parameter size produce the\nbest classification results compared to LLMs. Thus, addressing the problem in\npractice is feasible as limited computing power is needed. 3) The model\narchitecture (autoencoding, autoregression, and sentence-to-sentence)\nsignificantly affects the classifier's performance. We conclude that using ZSL\nfor multi-label requirements classification offers promising results. We also\npresent a novel metric that can be used to select the top-performing model for\nthis problem","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-22T14:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.15924v1","title":"Achieving Distributive Justice in Federated Learning via Uncertainty\n  Quantification","summary":"Client-level fairness metrics for federated learning are used to ensure that\nall clients in a federation either: a) have similar final performance on their\nlocal data distributions (i.e., client parity), or b) obtain final performance\non their local data distributions relative to their contribution to the\nfederated learning process (i.e., contribution fairness). While a handful of\nworks that propose either client-parity or contribution-based fairness metrics\nground their definitions and decisions in social theories of equality -- such\nas distributive justice -- most works arbitrarily choose what notion of\nfairness to align with which makes it difficult for practitioners to choose\nwhich fairness metric aligns best with their fairness ethics. In this work, we\npropose UDJ-FL (Uncertainty-based Distributive Justice for Federated Learning),\na flexible federated learning framework that can achieve multiple distributive\njustice-based client-level fairness metrics. Namely, by utilizing techniques\ninspired by fair resource allocation, in conjunction with performing aleatoric\nuncertainty-based client weighing, our UDJ-FL framework is able to achieve\negalitarian, utilitarian, Rawls' difference principle, or desert-based\nclient-level fairness. We empirically show the ability of UDJ-FL to achieve all\nfour defined distributive justice-based client-level fairness metrics in\naddition to providing fairness equivalent to (or surpassing) other popular fair\nfederated learning works. Further, we provide justification for why aleatoric\nuncertainty weighing is necessary to the construction of our UDJ-FL framework\nas well as derive theoretical guarantees for the generalization bounds of\nUDJ-FL. Our code is publicly available at\nhttps://github.com/alycia-noel/UDJ-FL.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML,I.2.0","published":"2025-04-22T14:07:56Z"}
{"aid":"http://arxiv.org/abs/2504.15935v1","title":"A Ginzburg-Landau problem on a circular cone","summary":"We carry out an asymptotic analysis for a Ginzburg-Landau type model for\ntangent vector fields defined on a cone. The results, in the spirit of Brezis,\nBethuel and Helein, establish the degree and asymptotic location of vortices,\none of which must be situated at the tip of the cone.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T14:24:28Z"}
{"aid":"http://arxiv.org/abs/2504.15938v1","title":"Differentiable graph neural network simulator for forward and inverse\n  modeling of multi-layered slope system with multiple material properties","summary":"Graph neural network simulators (GNS) have emerged as a computationally\nefficient tool for simulating granular flows. Previous efforts have been\nlimited to simplified geometries and material characterizations, typically\nconsidering only friction angle, which does not reflect the complexity of\nrealistic geotechnical systems such as slopes encountered in engineering\npractice. This study introduces a differentiable GNS framework designed for\nmulti-layered slope systems comprising both forward and inverse modeling\ncomponents. The forward component relies on a fine-tuned GNS that incorporates\nboth friction angle and cohesion. Its performance is demonstrated through\ncolumn collapse and multi-layered slope runout simulations, where GNS\nreplicates multi-material flow dynamics while achieving up to 145x\ncomputational speedup over the Material Point Method (MPM). The inverse\nmodeling component leverages the trained GNS, reverse-mode automatic\ndifferentiation, and L-BFGS-B optimization to infer material properties from a\ntarget runout geometry. Its performance is demonstrated by back-calculating the\nmaterial strengths that led to failure-induced runout in a dam system composed\nof multiple materials. Results are obtained within minutes and show good\nagreement with the target strength values. The framework introduced in this\nstudy provides an efficient approach for forward runout assessments and inverse\nstrength back-calculation in realistic slope systems.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-22T14:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.15947v1","title":"Over-the-Air Transmission of Zak-OTFS with Spread Pilots on Sub-THz\n  Communications Testbed","summary":"Looking towards 6G wireless systems, frequency bands like the sub-terahertz\n(sub-THz) band (100 GHz - 300 GHz) are gaining traction for their promises of\nlarge available swaths of bandwidth to support the ever-growing data demands.\nHowever, challenges with harsh channel conditions and hardware nonlinearities\nin the sub-THz band require robust communication techniques with favorable\nproperties, such as good spectral efficiency and low peak-to-average power\nratio (PAPR). Recently, OTFS and its variants have garnered significant\nattention for their performance in severe conditions (like high delay and\nDoppler), making it a promising candidate for future communications. In this\nwork, we implement Zak-OTFS for the over-the-air experiments with traditional\npoint pilots and the new spread pilots. Notably, we design our spread-pilot\nwaveforms with communications and sensing coexisting in the same radio\nresources. We define the system model and the signal design for integration\nonto our state-of-the-art sub-THz wireless testbed. We show successful data\ntransmission over-the-air at 140 GHz and 240 GHz in a variety of\nsignal-to-noise ratio (SNR) conditions. In addition, we demonstrate integrated\nsensing and communications (ISAC) capabilities and show PAPR improvement of\nover 5 dB with spread pilots compared to point pilots.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-22T14:46:11Z"}
{"aid":"http://arxiv.org/abs/2504.15951v1","title":"Understanding the Role of Covariates in Numerical Reconstructions of\n  Real-World Vehicle-to-Pedestrian Collisions","summary":"Traumatic Brain Injuries (TBIs) are a pressing global public health issue,\nimpacting tens of millions of individuals annually. Vulnerable road users\n(VRUs), such as pedestrians, are vastly overrepresented in the worldwide TBI\nstatistics. To evaluate the effectiveness of injury prevention measures,\nresearchers often employ Finite Element (FE) models of the human body to\nvirtually simulate the human response to impact in real-world road traffic\naccident scenarios. However, VRU accidents occur in a highly uncontrolled\nenvironment and, in consequence, there is a large amount of variables\n(covariates), e.g. the vehicle impact speed and VRU body posture, that together\ndictate the injurious outcome of the collision. At the same time, since FE\nanalysis is a computationally heavy task, researchers often need to apply\nextensive simplifications to FE models when attempting to predict real-world\nVRU head trauma. To help researchers make informed decisions when conducting FE\naccident reconstructions, this literature review aims to create an overarching\nsummary of covariates that have been reported influential in literature. The\nreview provides researchers with an overview of variables proven to have an\ninfluence on head injury predictions. The material could potentially be useful\nas a basis for choosing parameters to include when performing sensitivity\nanalyses of car-to-pedestrian impact simulations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T14:48:06Z"}
{"aid":"http://arxiv.org/abs/2504.15960v1","title":"The Value Problem for Multiple-Environment MDPs with Parity Objective","summary":"We consider multiple-environment Markov decision processes (MEMDP), which\nconsist of a finite set of MDPs over the same state space, representing\ndifferent scenarios of transition structure and probability. The value of a\nstrategy is the probability to satisfy the objective, here a parity objective,\nin the worst-case scenario, and the value of an MEMDP is the supremum of the\nvalues achievable by a strategy.\n  We show that deciding whether the value is 1 is a PSPACE-complete problem,\nand even in P when the number of environments is fixed, along with new insights\nto the almost-sure winning problem, which is to decide if there exists a\nstrategy with value 1. Pure strategies are sufficient for theses problems,\nwhereas randomization is necessary in general when the value is smaller than 1.\nWe present an algorithm to approximate the value, running in double exponential\nspace. Our results are in contrast to the related model of partially-observable\nMDPs where all these problems are known to be undecidable.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-22T14:58:09Z"}
{"aid":"http://arxiv.org/abs/2504.15970v1","title":"Recent Advances and Future Directions in Extended Reality (XR):\n  Exploring AI-Powered Spatial Intelligence","summary":"Extended Reality (XR), encompassing Augmented Reality (AR), Virtual Reality\n(VR) and Mixed Reality (MR), is a transformative technology bridging the\nphysical and virtual world and it has diverse potential which will be\nubiquitous in the future. This review examines XR's evolution through\nfoundational framework - hardware ranging from monitors to sensors and software\nranging from visual tasks to user interface; highlights state of the art (SOTA)\nXR products with the comparison and analysis of performance based on their\nfoundational framework; discusses how commercial XR devices can support the\ndemand of high-quality performance focusing on spatial intelligence. For future\ndirections, attention should be given to the integration of multi-modal AI and\nIoT-driven digital twins to enable adaptive XR systems. With the concept of\nspatial intelligence, future XR should establish a new digital space with\nrealistic experience that benefits humanity. This review underscores the\npivotal role of AI in unlocking XR as the next frontier in human-computer\ninteraction.","main_category":"cs.HC","categories":"cs.HC,cs.CV,cs.MA","published":"2025-04-22T15:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.15983v1","title":"W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight\n  Language Models","summary":"The demand for efficient natural language processing (NLP) systems has led to\nthe development of lightweight language models. Previous work in this area has\nprimarily focused on manual design or training-based neural architecture search\n(NAS) methods. Recently, zero-shot NAS methods have been proposed for\nevaluating language models without the need for training. However, prevailing\napproaches to zero-shot NAS often face challenges such as biased evaluation\nmetrics and computational inefficiencies. In this paper, we introduce\nweight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored\nfor lightweight language models. Our approach utilizes two evaluation proxies:\nthe parameter count and the number of principal components with cumulative\ncontribution exceeding $\\eta$ in the feed-forward neural (FFN) layer.\nAdditionally, by eliminating the need for gradient computations, we optimize\nthe evaluation time, thus enhancing the efficiency of designing and evaluating\nlightweight language models. We conduct a comparative analysis on the GLUE and\nSQuAD datasets to evaluate our approach. The results demonstrate that our\nmethod significantly reduces training time compared to one-shot NAS methods and\nachieves higher scores in the testing phase compared to previous\nstate-of-the-art training-based methods. Furthermore, we perform ranking\nevaluations on a dataset sampled from the FlexiBERT search space. Our approach\nexhibits superior ranking correlation and further reduces solving time compared\nto other zero-shot NAS methods that require gradient computation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T15:33:01Z"}
{"aid":"http://arxiv.org/abs/2504.15999v1","title":"Infinitely many collisions between a recurrent simple random walk and\n  arbitrary many transient random walks in a subballistic random environment","summary":"We consider $d$ random walks $\\big(S_n^{(j)}\\big)_{n\\in\\mathbb{N}}$, $1\\leq j\n\\leq d$, in the same random environment $\\omega$ in $\\mathbb{Z}$, and a\nrecurrent simple random walk $(Z_n)_{n\\in\\mathbb{N}}$ on $\\mathbb{Z}$. We\nassume that, conditionally on the environment $\\omega$, all the random walks\nare independent and start from even initial locations. Our assumption on the\nlaw of the environment is such that a single random walk in the environment\n$\\omega$ is transient to the right but subballistic, with parameter\n$0<\\kappa<1/2$. We show that - for every value of $d$ - there are almost surely\ninfinitely many times for which all these random walks,\n$(Z_n)_{n\\in\\mathbb{N}}$ and $\\big(S_n^{(j)}\\big)_{n\\in\\mathbb{N}}$, $1\\leq j\n\\leq d$, are simultaneously at the same location, even though one of them is\nrecurrent and the $d$ others ones are transient.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T16:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.16011v1","title":"Asian Basket Spread Options: A New Approximation Based on Stochastic\n  Taylor Expansions","summary":"We present closed analytical approximations for the pricing of Asian basket\nspread options under the Black-Scholes model. The formulae are obtained by\nusing a stochastic Taylor expansion around a log-normal proxy model and are\nfound to be highly accurate for Asian and spread options in practice. Unlike\nother approaches, they do not require any numerical integration or root\nsolving.","main_category":"q-fin.PR","categories":"q-fin.PR,q-fin.MF","published":"2025-04-22T16:19:27Z"}
{"aid":"http://arxiv.org/abs/2504.16014v1","title":"Probing New Physics Through CP Violation in $B_{(s)}\\to Vμ^+μ^-$\n  Decays","summary":"Rare decays of the kind $B\\to K^*\\mu^+\\mu^-$ and $B_s\\to \\phi\\mu^+\\mu^-$ are\nkey players for testing the Standard Model. The current experimental data for\ntheir decay rates and angular observables show tensions with the theoretical\npredictions that may be indications of New Physics. We present a strategy to\nextract the relevant short-distance coefficients in the presence of new sources\nof CP violation, utilizing a synergy with $B\\to K\\mu^+\\mu^-$ decays. Using the\ncurrent data as a guideline, we illustrate the new method to determine the\ncomplex coefficients $C_9^{(\\prime)}$ and $C_{10}^{(\\prime)}$ using only four\nangular observables. Interestingly, the current experimental picture leaves\nsignificant room for CP-violating New Physics. We discuss also the link to\nleptonic $B^0_s\\to\\mu^+\\mu^-$ decays. We are looking forward to the\nimplementation of these strategies at the future high-precision frontier of\nflavour physics.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-22T16:26:17Z"}
{"aid":"http://arxiv.org/abs/2504.16022v1","title":"Non-Renormalizable SU(5) GUTs: Leptoquark-Induced Neutrino Masses","summary":"We revisit the doublet-triplet splitting problem within the $SU(5)$ gauge\ngroup framework to advocate a viable regime with the light scalar leptoquark of\nthe doublet-triplet splitting notoriety that is compatible with the current\nexperimental bounds on partial proton decay lifetimes. We explicitly\ndemonstrate, through a consistent use of higher-dimensional operators, how to\nimplement suppression of baryon number violating interactions of the\naforementioned color triplet. Our study thus offers an alternative approach to\nthe doublet-triplet splitting problem as it removes a need for an extreme mass\nhierarchy between the partners residing in the same representation. We\nfurthermore pursue two different extensions of two distinct symmetry breaking\nscenarios of $SU(5)$, one with a $24$-dimensional representation and the other\none with a $75$-dimensional representation, to produce comparative study of\nnovel consequences for the gauge coupling unification and the one-loop level\nneutrino mass generation. Our results point towards qualitatively novel $SU(5)$\nscenarios, where the light scalar leptoquarks, responsible for the neutrino\nmass generation, might be even accessible at colliders and thus serve as an\naccelerator accessible portal to the high-scale physics.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-22T16:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.16024v1","title":"EnsAI: An Emulator for Atmospheric Chemical Ensembles","summary":"Ensemble-based methods for data assimilation and emission inversions are a\npopular way to encode flow-dependency within the model error covariance. While\nmost ensemble methods do not require the use of an adjoint model, the need to\nrepeatedly run a geophysical model to generate the ensemble can be a\nsignificant computational burden. In this paper, we introduce EnsAI, a new\nAI-based ensemble generation system for atmospheric chemical constituents. When\ntrained on an existing ensemble for ammonia generated by the GEM-MACH air\nquality model, it was shown that the ensembles produced by EnsAI can accurately\nreproduce the meteorology-dependent features of the original ensemble, while\ngenerating the ensemble 3,300 times faster than the original GEM-MACH ensemble.\nWhile EnsAI requires an upfront cost for generating an ensemble used for\ntraining, as well as the training itself, the long term computational savings\ncan greatly exceed these initial computational costs. When used in an emissions\ninversion system, EnsAI produced similar inversion results to those in which\nthe original GEM-MACH ensemble was used while using significantly less\ncomputational resources.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-22T16:41:26Z"}
{"aid":"http://arxiv.org/abs/2504.16035v1","title":"Universal differential equations for optimal control problems and its\n  application on cancer therapy","summary":"This paper highlights a parallel between the forward backward sweeping method\nfor optimal control and deep learning training procedures. We reformulate a\nclassical optimal control problem, constrained by a differential equation\nsystem, into an optimization framework that uses neural networks to represent\ncontrol variables. We demonstrate that this deep learning method adheres to\nPontryagin Maximum Principle and mitigates numerical instabilities by employing\nbackward propagation instead of a backward sweep for the adjoint equations. As\na case study, we solve an optimal control problem to find the optimal\ncombination of immunotherapy and chemotherapy. Our approach holds significant\npotential across various fields, including epidemiology, ecological modeling,\nengineering, and financial mathematics, where optimal control under complex\ndynamic constraints is crucial.","main_category":"math.OC","categories":"math.OC,math.DS","published":"2025-04-22T16:58:37Z"}
{"aid":"http://arxiv.org/abs/2504.16039v1","title":"A Comparative and Measurement-Based Study on Real-Time Network KPI\n  Extraction Methods for 5G and Beyond Applications","summary":"Key performance indicators (KPIs), which can be extracted from the\nstandardized interfaces of network equipment defined by current standards,\nconstitute a primary data source that can be leveraged in the development of\nnon-standardized new equipment, architectures, and computational tools. In\nnext-generation technologies, the demand for data has evolved beyond the\nconventional log generation or export capabilities provided by existing\nlicensed network monitoring tools. There is now a growing need to collect such\ndata at specific time intervals and with defined granularities. At this stage,\nthe development of real-time KPI extraction methods and enabling their exchange\nbetween both standardized/commercialized and non-standardized components or\ntools has become increasingly critical. This study presents a comprehensive\nevaluation of three distinct KPI extraction methodologies applied to two\ncommercially available devices. The analysis aims to uncover the strengths,\nweaknesses, and overall efficacy of these approaches under varying conditions,\nand highlights the critical insights into the practical capabilities and\nlimitations. The findings serve as a foundational guide for the seamless\nintegration and robust testing of novel technologies and approaches within\ncommercial telecommunication networks. This work aspires to bridge the gap\nbetween technological innovation and real-world applicability, fostering\nenhanced decision-making in network deployment and optimization.","main_category":"cs.NI","categories":"cs.NI,eess.SP","published":"2025-04-22T17:04:02Z"}
{"aid":"http://arxiv.org/abs/2504.16041v1","title":"Muon Optimizer Accelerates Grokking","summary":"This paper investigates the impact of different optimizers on the grokking\nphenomenon, where models exhibit delayed generalization. We conducted\nexperiments across seven numerical tasks (primarily modular arithmetic) using a\nmodern Transformer architecture. The experimental configuration systematically\nvaried the optimizer (Muon vs. AdamW) and the softmax activation function\n(standard softmax, stablemax, and sparsemax) to assess their combined effect on\nlearning dynamics. Our empirical evaluation reveals that the Muon optimizer,\ncharacterized by its use of spectral norm constraints and second-order\ninformation, significantly accelerates the onset of grokking compared to the\nwidely used AdamW optimizer. Specifically, Muon reduced the mean grokking epoch\nfrom 153.09 to 102.89 across all configurations, a statistically significant\ndifference (t = 5.0175, p = 6.33e-08). This suggests that the optimizer choice\nplays a crucial role in facilitating the transition from memorization to\ngeneralization.","main_category":"cs.LG","categories":"cs.LG,cs.AI,I.2","published":"2025-04-22T17:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.16047v1","title":"Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive\n  Analysis","summary":"Foundation models, trained on vast amounts of data using self-supervised\ntechniques, have emerged as a promising frontier for advancing artificial\nintelligence (AI) applications in medicine. This study evaluates three\ndifferent vision-language foundation models (RAD-DINO, CheXagent, and\nBiomedCLIP) on their ability to capture fine-grained imaging features for\nradiology tasks. The models were assessed across classification, segmentation,\nand regression tasks for pneumothorax and cardiomegaly on chest radiographs.\nSelf-supervised RAD-DINO consistently excelled in segmentation tasks, while\ntext-supervised CheXagent demonstrated superior classification performance.\nBiomedCLIP showed inconsistent performance across tasks. A custom segmentation\nmodel that integrates global and local features substantially improved\nperformance for all foundation models, particularly for challenging\npneumothorax segmentation. The findings highlight that pre-training methodology\nsignificantly influences model performance on specific downstream tasks. For\nfine-grained segmentation tasks, models trained without text supervision\nperformed better, while text-supervised models offered advantages in\nclassification and interpretability. These insights provide guidance for\nselecting foundation models based on specific clinical applications in\nradiology.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T17:20:34Z"}
{"aid":"http://arxiv.org/abs/2504.16055v1","title":"SAR4SLPs: An Asynchronous Survey of Speech-Language Pathologists'\n  Perspectives on Socially Assistive Robots","summary":"Socially Assistive Robots (SARs) offer unique opportunities within speech\nlanguage pathology (SLP) education and practice by supporting interactive\ninterventions for children with communication disorders. This paper explores\nthe implementation of SAR4SLPs (Socially Assistive Robots for Speech-Language\nPathologists) to investigate aspects such as engagement, therapeutic strategy\ndiscipline, and consistent intervention support. We assessed the current\napplication of technology to clinical and educational settings, especially with\nrespect to how SLPs might use SAR in their therapeutic work. An asynchronous\nremote community (ARC) collaborated with a cohort of practicing SLPs to\nconsider the feasibility, potential effectiveness, and anticipated challenges\nwith implementing SARs in day-to-day interventions and as practice\nfacilitators. We focus in particular on the expressive functionality of SARs,\nmodeling a foundational strategy that SLPs employ across various intervention\ntargets. This paper highlights clinician-driven insights and design\nimplications for developing SARs that support specific treatment goals through\ncollaborative and iterative design.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T17:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.16056v1","title":"Honey, I Shrunk the Language Model: Impact of Knowledge Distillation\n  Methods on Performance and Explainability","summary":"Artificial Intelligence (AI) has increasingly influenced modern society,\nrecently in particular through significant advancements in Large Language\nModels (LLMs). However, high computational and storage demands of LLMs still\nlimit their deployment in resource-constrained environments. Knowledge\ndistillation addresses this challenge by training a small student model from a\nlarger teacher model. Previous research has introduced several distillation\nmethods for both generating training data and for training the student model.\nDespite their relevance, the effects of state-of-the-art distillation methods\non model performance and explainability have not been thoroughly investigated\nand compared. In this work, we enlarge the set of available methods by applying\ncritique-revision prompting to distillation for data generation and by\nsynthesizing existing methods for training. For these methods, we provide a\nsystematic comparison based on the widely used Commonsense Question-Answering\n(CQA) dataset. While we measure performance via student model accuracy, we\nemploy a human-grounded study to evaluate explainability. We contribute new\ndistillation methods and their comparison in terms of both performance and\nexplainability. This should further advance the distillation of small language\nmodels and, thus, contribute to broader applicability and faster diffusion of\nLLM technology.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T17:32:48Z"}
{"aid":"http://arxiv.org/abs/2504.16058v1","title":"How to make CLEAN variants faster? Using clustered components informed\n  by the autocorrelation function","summary":"Deconvolution, imaging and calibration of data from radio interferometers is\na challenging computational (inverse) problem. The upcoming generation of radio\ntelescopes poses significant challenges to existing, and well proven data\nreduction pipelines due to the large data sizes expected from these\nexperiments, and the high resolution and dynamic range. In this manuscript, we\ndeal with the deconvolution problem. A variety of multiscalar variants to the\nclassical CLEAN algorithm (the de-facto standard) have been proposed in the\npast, often outperforming CLEAN at the cost of significantly increasing\nnumerical resources. In this work, we aim to combine some of these ideas for a\nnew algorithm, Autocorr-CLEAN, to accelerate the deconvolution and prepare the\ndata reduction pipelines for the data sizes expected by the upcoming generation\nof instruments. To this end, we propose to use a cluster of CLEAN components\nfitted to the autocorrelation function of the residual in a subminor loop, to\nderive continuously changing, and potentially non-radially symmetric, basis\nfunctions for CLEANing the residual. Autocorr-CLEAN allows for the superior\nreconstruction fidelity achieved by modern multiscalar approaches, and their\nsuperior convergence speed. It achieves this without utilizing any substep of\nsuper-linear complexity in the minor loops, keeping the single minor loop and\nsubminor loop iterations at an execution time comparable to CLEAN. Combining\nthese advantages, Autocorr-CLEAN is found to be up to a magnitude faster than\nthe classical CLEAN procedure. Autocorr-CLEAN fits well in the algorithmic\nframework common for radio interferometry, making it relatively straightforward\nto include in future data reduction pipelines. With its accelerated convergence\nspeed, and smaller residual, Autocorr-CLEAN may be an important asset for the\ndata analysis in the future.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.GA","published":"2025-04-22T17:33:55Z"}
{"aid":"http://arxiv.org/abs/2504.16060v1","title":"Vision-Language Models Are Not Pragmatically Competent in Referring\n  Expression Generation","summary":"Referring Expression Generation (REG) is a core task for evaluating the\npragmatic competence of vision-language systems, requiring not only accurate\nsemantic grounding but also adherence to principles of cooperative\ncommunication (Grice, 1975). However, current evaluations of vision-language\nmodels (VLMs) often overlook the pragmatic dimension, reducing REG to a\nregion-based captioning task and neglecting Gricean maxims. In this work, we\nrevisit REG from a pragmatic perspective, introducing a new dataset (RefOI) of\n1.5k images annotated with both written and spoken referring expressions.\nThrough a systematic evaluation of state-of-the-art VLMs, we identify three key\nfailures of pragmatic competence: (1) failure to uniquely identify the\nreferent, (2) inclusion of excessive or irrelevant information, and (3)\nmisalignment with human pragmatic preference, such as the underuse of minimal\nspatial cues. We also show that standard automatic evaluations fail to capture\nthese pragmatic violations, reinforcing superficial cues rather than genuine\nreferential success. Our findings call for a renewed focus on pragmatically\ninformed models and evaluation frameworks that align with real human\ncommunication.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T17:37:16Z"}
{"aid":"http://arxiv.org/abs/2504.16070v1","title":"Reconstruction of source function in a parabolic equation using partial\n  boundary measurements","summary":"In this paper, we present the analytical and numerical study of the\noptimization approach for determining the space-dependent source function in\nthe parabolic inverse source problem using partial boundary measurements. The\nLagrangian approach for the solution of the optimization problem is presented,\nand optimality conditions are derived. The proof of the Fr\\'echet\ndifferentiability of the regularized Tikhonov functional and the existence\nresult for the solution of the inverse source problem are established. A local\nstability estimate for the unknown source term is also presented. The numerical\nexamples justify the theoretical investigations using the conjugate gradient\nmethod (CGM) in 2D and 3D tests with noisy data.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-22T17:51:31Z"}
{"aid":"http://arxiv.org/abs/2504.16076v1","title":"Optimal intrinsic alignment estimators in the presence of redshift-space\n  distortions","summary":"We present estimators for quantifying intrinsic alignments in large\nspectroscopic surveys that efficiently capture line-of-sight (LOS) information\nwhile being relatively insensitive to redshift-space distortions (RSD). We\ndemonstrate that changing the LOS integration range, {\\Pi}max, as a function of\ntransverse separation outperforms the conventional choice of a single {\\Pi}max\nvalue. This is further improved by replacing the flat {\\Pi}max cut with a LOS\nweighting based on shape projection and RSD. Although these estimators\nincorporate additional LOS information, they are projected correlations that\nexhibit signal-to-noise ratios comparable to 3D correlation functions, such as\nthe IA quadrupole. Using simulations from Abacus Summit, we evaluate these\nestimators and provide recommended {\\Pi}max values and weights for projected\nseparations of 1 - 100 Mpc/h. These will improve measurements of intrinsic\nalignments in large cosmological surveys and the constraints they provide for\nboth weak lensing and direct cosmological applications.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-22T17:55:52Z"}
{"aid":"http://arxiv.org/abs/2504.16077v1","title":"Intent-aware Diffusion with Contrastive Learning for Sequential\n  Recommendation","summary":"Contrastive learning has proven effective in training sequential\nrecommendation models by incorporating self-supervised signals from augmented\nviews. Most existing methods generate multiple views from the same interaction\nsequence through stochastic data augmentation, aiming to align their\nrepresentations in the embedding space. However, users typically have specific\nintents when purchasing items (e.g., buying clothes as gifts or cosmetics for\nbeauty). Random data augmentation used in existing methods may introduce noise,\ndisrupting the latent intent information implicit in the original interaction\nsequence. Moreover, using noisy augmented sequences in contrastive learning may\nmislead the model to focus on irrelevant features, distorting the embedding\nspace and failing to capture users' true behavior patterns and intents. To\naddress these issues, we propose Intent-aware Diffusion with contrastive\nlearning for sequential Recommendation (InDiRec). The core idea is to generate\nitem sequences aligned with users' purchasing intents, thus providing more\nreliable augmented views for contrastive learning. Specifically, InDiRec first\nperforms intent clustering on sequence representations using K-means to build\nintent-guided signals. Next, it retrieves the intent representation of the\ntarget interaction sequence to guide a conditional diffusion model, generating\npositive views that share the same underlying intent. Finally, contrastive\nlearning is applied to maximize representation consistency between these\nintent-aligned views and the original sequence. Extensive experiments on five\npublic datasets demonstrate that InDiRec achieves superior performance compared\nto existing baselines, learning more robust representations even under noisy\nand sparse data conditions.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-22T17:55:56Z"}
{"aid":"http://arxiv.org/abs/2504.16078v1","title":"LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making\n  Abilities","summary":"The success of Large Language Models (LLMs) has sparked interest in various\nagentic applications. A key hypothesis is that LLMs, leveraging common sense\nand Chain-of-Thought (CoT) reasoning, can effectively explore and efficiently\nsolve complex domains. However, LLM agents have been found to suffer from\nsub-optimal exploration and the knowing-doing gap, the inability to effectively\nact on knowledge present in the model. In this work, we systematically study\nwhy LLMs perform sub-optimally in decision-making scenarios. In particular, we\nclosely examine three prevalent failure modes: greediness, frequency bias, and\nthe knowing-doing gap. We propose mitigation of these shortcomings by\nfine-tuning via Reinforcement Learning (RL) on self-generated CoT rationales.\nOur experiments across multi-armed bandits, contextual bandits, and\nTic-tac-toe, demonstrate that RL fine-tuning enhances the decision-making\nabilities of LLMs by increasing exploration and narrowing the knowing-doing\ngap. Finally, we study both classic exploration mechanisms, such as\n$\\epsilon$-greedy, and LLM-specific approaches, such as self-correction and\nself-consistency, to enable more effective fine-tuning of LLMs for\ndecision-making.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T17:57:14Z"}
{"aid":"http://arxiv.org/abs/2504.16382v1","title":"Fully Scalable MPC Algorithms for Euclidean k-Center","summary":"The $k$-center problem is a fundamental optimization problem with numerous\napplications in machine learning, data analysis, data mining, and communication\nnetworks. The $k$-center problem has been extensively studied in the classical\nsequential setting for several decades, and more recently there have been some\nefforts in understanding the problem in parallel computing, on the Massively\nParallel Computation (MPC) model. For now, we have a good understanding of\n$k$-center in the case where each local MPC machine has sufficient local memory\nto store some representatives from each cluster, that is, when one has\n$\\Omega(k)$ local memory per machine. While this setting covers the case of\nsmall values of $k$, for a large number of clusters these algorithms require\nundesirably large local memory, making them poorly scalable. The case of large\n$k$ has been considered only recently for the fully scalable low-local-memory\nMPC model for the Euclidean instances of the $k$-center problem. However, the\nearlier works have been considering only the constant dimensional Euclidean\nspace, required a super-constant number of rounds, and produced only\n$k(1+o(1))$ centers whose cost is a super-constant approximation of $k$-center.\n  In this work, we significantly improve upon the earlier results for the\n$k$-center problem for the fully scalable low-local-memory MPC model. In the\nlow dimensional Euclidean case in $\\mathbb{R}^d$, we present the first\nconstant-round fully scalable MPC algorithm for\n$(2+\\varepsilon)$-approximation. We push the ratio further to $(1 +\n\\varepsilon)$-approximation albeit using slightly more $(1 + \\varepsilon)k$\ncenters. All these results naturally extends to slightly super-constant values\nof $d$. In the high-dimensional regime, we provide the first fully scalable MPC\nalgorithm that in a constant number of rounds achieves an $O(\\log n/ \\log \\log\nn)$-approximation for $k$-center.","main_category":"cs.DS","categories":"cs.DS,cs.DC","published":"2025-04-23T03:24:15Z"}
{"aid":"http://arxiv.org/abs/2504.16384v1","title":"Study of Auto-igniting Spray Flame in Vitiated Swirling Hot Coflow using\n  flamelet generated model","summary":"Swirl-stabilized auto-igniting spray flames are essential for designing\nefficient and clean combustion systems. The present study performs large eddy\nsimulations (LES) of the dilute auto-igniting methanol flame in a vitiated, hot\ncoflow of varying swirl intensities. The six-dimensional Flamelet Generated\nManifold (FGM) technique is used to solve the reactive flow accurately and\neconomically. The swirl numbers (SN), i.e. 0.2, 0.6, 1.0, and 1.4, are used to\nassess their effect on auto-ignition and flame stability. At lower to moderate\nswirl numbers (SN =0.2, 0.6), the increase in swirl is found to increase the\nlift-off height. Beyond the critical swirl number (SN=0.6), the lift-off height\ndrops. Also, the time-averaged flame structure transitions from a tubular-like\nflame into a uniformly distributed combustion region at these high swirl\nnumbers. It also results in a more compact flame for the higher swirl numbers.\nThese effects on flame dynamics are analyzed in detail using the mean gas-phase\nflow field distribution, particle statistics, and proper orthogonal\ndecomposition (POD).","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T03:26:37Z"}
{"aid":"http://arxiv.org/abs/2504.16392v1","title":"Joint Topology and Power Optimization for Multi-UAV Collaborative Secure\n  Communication","summary":"In this paper, we investigate an unmanned aerial vehicle (UAV)-enabled secure\ncommunication scenario that a cluster of UAVs performs a virtual non-uniform\nlinear array (NULA) to communicate with a base station (BS) in the presence of\neavesdroppers (Eves). Our goal is to design the UAV topology, trajectory, and\nprecoding to maximize the system channel capacity. To this end, we convert the\noriginal problem into equivalent two-stage problems. Specifically, we first try\nto maximize the channel gain by meticulously designing the UAV topology. We\nthen study the joint optimization of the trajectory and precoding for total\ntransmit power minimization while satisfying the constraints on providing\nquality of service (QoS) assurance to the BS, the leakage tolerance to Eves,\nthe per-UAV transmit power, the initial/final locations, and the cylindrical\nno-fly zones. For the UAV topology design, we prove that the topology follows\nthe Fekete-point distribution. The design of trajectory and precoding is\nformulated as a non-convex optimization problem which is generally intractable.\nSubsequently, the non-convex constraints are converted into convex terms, and a\ndouble-loop search algorithm is proposed to solve the transmit power\nminimization problem. Introduce random rotation offsets so as to perform a\ndynamic stochastic channel to enhance the security. Numerical results\ndemonstrate the superiority of the proposed method in promoting capacity.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T03:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.16397v1","title":"Circinus: Efficient Query Planner for Compound ML Serving","summary":"The rise of compound AI serving -- integrating multiple operators in a\npipeline that may span edge and cloud tiers -- enables end-user applications\nsuch as autonomous driving, generative AI-powered meeting companions, and\nimmersive gaming. Achieving high service goodput -- i.e., meeting service level\nobjectives (SLOs) for pipeline latency, accuracy, and costs -- requires\neffective planning of operator placement, configuration, and resource\nallocation across infrastructure tiers. However, the diverse SLO requirements,\nvarying edge capabilities, and high query volumes create an enormous planning\nsearch space, rendering current solutions fundamentally limited for real-time\nserving and cost-efficient deployments.\n  This paper presents Circinus, an SLO-aware query planner for large-scale\ncompound AI workloads. Circinus novelly decomposes multi-query planning and\nmulti-dimensional SLO objectives while preserving global decision quality. By\nexploiting plan similarities within and across queries, it significantly\nreduces search steps. It further improves per-step efficiency with a\nprecision-aware plan profiler that incrementally profiles and strategically\napplies early stopping based on imprecise estimates of plan performance. At\nscale, Circinus selects query-plan combinations to maximize global SLO goodput.\nEvaluations in real-world settings show that Circinus improves service goodput\nby 3.2-5.0$\\times$, accelerates query planning by 4.2-5.8$\\times$, achieving\nquery response in seconds, while reducing deployment costs by 3.2-4.0$\\times$\nover state of the arts even in their intended single-tier deployments.","main_category":"cs.DB","categories":"cs.DB,cs.LG","published":"2025-04-23T03:57:24Z"}
{"aid":"http://arxiv.org/abs/2504.16401v1","title":"Stability threshold of Couette flow for 3D Boussinesq system in Sobolev\n  spaces","summary":"In this paper, we investigate the nonlinear stability and transition\nthreshold for the 3D Boussinesq system in Sobolev space under the high Reynolds\nnumber and small thermal diffusion in\n$\\mathbb{T}\\times\\mathbb{R}\\times\\mathbb{T} $. It is proved that if the initial\nvelocity $v_{\\rm in}$ and the initial temperature $ \\theta_{\\rm in} $ satisfy $\n\\|v_{\\rm in}-(y,0,0)\\|_{H^{2}}\\leq \\varepsilon\\nu, \\|\\theta_{\\rm\nin}\\|_{H^{2}}\\leq \\varepsilon\\nu^{2} $, respectively for some $ \\varepsilon>0 $\nindependent of the Reynolds number or thermal diffusion, then the solutions of\n3D Boussinesq system are global in time.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T04:09:55Z"}
{"aid":"http://arxiv.org/abs/2504.16403v1","title":"On the four-body limaçon choreography: maximal superintegrability\n  and choreographic fragmentation","summary":"In this paper, as a continuation of [Fernandez-Guasti, \\textit{Celest Mech\nDyn Astron} 137, 4 (2025)], we demonstrate the maximal superintegrability of\nthe reduced Hamiltonian, which governs the four-body choreographic planar\nmotion along the lima\\c{c}on trisectrix (resembling a folded figure eight), in\nthe six-dimensional space of relative motion. The corresponding eleven\nintegrals of motion in the Liouville-Arnold sense are presented explicitly.\nSpecifically, it is shown that the reduced Hamiltonian admits complete\nseparation of variables in Jacobi-like variables. The emergence of this\nchoreography is not a direct consequence of maximal superintegrability. Rather,\nit originates from the existence of \\textit{particular integrals} and the\nphenomenon of \\textit{particular involution}. The fragmentation of a more\ngeneral four-body choreographic motion into two isomorphic two-body\nchoreographies is discussed in detail. This model combines choreographic motion\nwith maximal superintegrability, a seldom-studied interplay in classical\nmechanics.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-23T04:16:50Z"}
{"aid":"http://arxiv.org/abs/2504.16420v1","title":"A Survey of Foundation Model-Powered Recommender Systems: From\n  Feature-Based, Generative to Agentic Paradigms","summary":"Recommender systems (RS) have become essential in filtering information and\npersonalizing content for users. RS techniques have traditionally relied on\nmodeling interactions between users and items as well as the features of\ncontent using models specific to each task. The emergence of foundation models\n(FMs), large scale models trained on vast amounts of data such as GPT, LLaMA\nand CLIP, is reshaping the recommendation paradigm. This survey provides a\ncomprehensive overview of the Foundation Models for Recommender Systems\n(FM4RecSys), covering their integration in three paradigms: (1) Feature-Based\naugmentation of representations, (2) Generative recommendation approaches, and\n(3) Agentic interactive systems. We first review the data foundations of RS,\nfrom traditional explicit or implicit feedback to multimodal content sources.\nWe then introduce FMs and their capabilities for representation learning,\nnatural language understanding, and multi-modal reasoning in RS contexts. The\ncore of the survey discusses how FMs enhance RS under different paradigms.\nAfterward, we examine FM applications in various recommendation tasks. Through\nan analysis of recent research, we highlight key opportunities that have been\nrealized as well as challenges encountered. Finally, we outline open research\ndirections and technical challenges for next-generation FM4RecSys. This survey\nnot only reviews the state-of-the-art methods but also provides a critical\nanalysis of the trade-offs among the feature-based, the generative, and the\nagentic paradigms, outlining key open issues and future research directions.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-23T05:02:51Z"}
{"aid":"http://arxiv.org/abs/2504.16432v1","title":"iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold\n  Network","summary":"As time evolves, data within specific domains exhibit predictability that\nmotivates time series forecasting to predict future trends from historical\ndata. However, current deep forecasting methods can achieve promising\nperformance but generally lack interpretability, hindering trustworthiness and\npractical deployment in safety-critical applications such as auto-driving and\nhealthcare. In this paper, we propose a novel interpretable model, iTFKAN, for\ncredible time series forecasting. iTFKAN enables further exploration of model\ndecision rationales and underlying data patterns due to its interpretability\nachieved through model symbolization. Besides, iTFKAN develops two strategies,\nprior knowledge injection, and time-frequency synergy learning, to effectively\nguide model learning under complex intertwined time series data. Extensive\nexperimental results demonstrated that iTFKAN can achieve promising forecasting\nperformance while simultaneously possessing high interpretive capabilities.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-23T05:34:49Z"}
{"aid":"http://arxiv.org/abs/2504.16445v1","title":"Power-based control of output oscillations with online estimation of\n  biased harmonics","summary":"The recently introduced discrete power-based control (Ruderman (2024b))\nreduces largely the communication efforts in the control loop when compensating\nfor the marginally damped or even slowly diverging output oscillations. The\ncontrol commutates twice per oscillations period (at the amplitude peaks) and\nuses the measured harmonic output only. The power-based control scheme requires\nthe knowledge of the instantaneous frequency, amplitude, and bias parameters of\nthe harmonic signal. This paper extends the power-based control by the\nfinite-time estimation of the biased harmonics (Ahmed et al. (2022)). Also an\nimproved analytic calculation of the impulse weighting factor is provided. The\npower-based oscillations control with online estimation of the harmonic\nparameters is evaluated experimentally on the fifth-order actuator system with\na free hanging load under gravity and measurement noise.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-23T06:12:46Z"}
{"aid":"http://arxiv.org/abs/2504.16490v1","title":"Microscopic theory of the inverse Faraday effect in a multiorbital\n  model: Role of orbital magnetic moment and electric dipole","summary":"We theoretically investigate the inverse Faraday effect (IFE), a phenomenon\nwhere circularly-polarized light induces a magnetic moment, in a multiorbital\nmetallic system. We demonstrate that the total magnetic moment can be\ndecomposed into several contributions in multiorbital tight-binding models. In\nparticular, we reveal that the electric dipole moment of Wannier orbitals also\ncontributes to the orbital magnetic moment, which is not included in the\nconventional expression for the orbital magnetic moment in lattice systems. To\naccount for all possible contributions, we adopt an $s$-$p$ tight-binding\nsystem as a minimal model for the IFE. Using an analytical approach based on\nthe Schrieffer-Wolff transformation, we clarify the physical origins of these\ncontributions. Additionally, we quantitatively evaluate each contribution on an\nequal footing through a numerical approach based on the Floquet formalism. Our\nresults reveal that the orbital magnetic moment exhibits a significantly larger\nresponse compared to the spin magnetic moment, with all contributions to the\norbital magnetic moment being comparable in magnitude. These findings highlight\nthe essential role of orbital degrees of freedom in the IFE.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.str-el","published":"2025-04-23T08:04:22Z"}
{"aid":"http://arxiv.org/abs/2504.16504v1","title":"Intelligent Depression Prevention via LLM-Based Dialogue Analysis:\n  Overcoming the Limitations of Scale-Dependent Diagnosis through Precise\n  Emotional Pattern Recognition","summary":"Existing depression screening predominantly relies on standardized\nquestionnaires (e.g., PHQ-9, BDI), which suffer from high misdiagnosis rates\n(18-34% in clinical studies) due to their static, symptom-counting nature and\nsusceptibility to patient recall bias. This paper presents an AI-powered\ndepression prevention system that leverages large language models (LLMs) to\nanalyze real-time conversational cues--including subtle emotional expressions\n(e.g., micro-sentiment shifts, self-referential language patterns)--for more\naccurate and dynamic mental state assessment. Our system achieves three key\ninnovations: (1) Continuous monitoring through natural dialogue, detecting\ndepression-indicative linguistic features (anhedonia markers, hopelessness\nsemantics) with 89% precision (vs. 72% for PHQ-9); (2) Adaptive risk\nstratification that updates severity levels based on conversational context,\nreducing false positives by 41% compared to scale-based thresholds; and (3)\nPersonalized intervention strategies tailored to users' emotional granularity,\ndemonstrating 2.3x higher adherence rates than generic advice. Clinical\nvalidation with 450 participants shows the system identifies 92% of at-risk\ncases missed by traditional scales, while its explainable AI interface bridges\nthe gap between automated analysis and clinician judgment. This work\nestablishes conversational AI as a paradigm shift from episodic scale-dependent\ndiagnosis to continuous, emotionally intelligent mental health monitoring.","main_category":"q-bio.NC","categories":"q-bio.NC,cs.HC","published":"2025-04-23T08:31:51Z"}
{"aid":"http://arxiv.org/abs/2504.16508v1","title":"Nondestructive beam envelope measurements using beam position monitors\n  for low-beta heavy ion beams in superconducting linear accelerator","summary":"In superconducting linear accelerators (linacs), accurately monitoring beam\ndynamics is essential for minimizing beam losses and ensuring stable\noperations. However, destructive diagnostics must be avoided in superconducting\nsections to prevent the occurrence of particulates and outgassing, rendering\ndirect measurements of the beam envelope particularly challenging. This study\npresents a non-destructive method that uses beam position monitors (BPMs) to\nestimate the transverse beam envelope based on measurements of the quadrupole\nmoment of the beam distribution. Although this concept was originally proposed\nin the 1980s, its application, especially to hadron beams, has been limited\nbecause of low signal sensitivity and the accuracy constraints associated with\nconventional BPM geometries. To overcome these challenges, we employed\n$\\cos{2\\theta}$-type BPMs, which offer improved sensitivity to quadrupole\ncomponents and are well-suited for low-$\\beta$ heavy ion beams. This method was\napplied to the heavy ion beams in the superconducting RIKEN linac (SRILAC), for\nwhich data from eight BPMs were combined with transfer matrix calculations and\nsupplemental wire scanner data. The resulting beam envelope estimates exhibited\ngood agreement with conventional quadrupole scan results, demonstrating the\nfeasibility of this technique for routine, non-destructive beam monitoring in\nsuperconducting accelerator sections.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-23T08:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.16513v1","title":"The bracket of the exceptional Lie algebra E8","summary":"An explicit formula for the bracket of the exceptional simple Lie algebra E8\nbased on triality and oct-octonions is obtained, following the Barton-Sudbery\ndescription of E8.","main_category":"math.DG","categories":"math.DG,math.GR,math.RA","published":"2025-04-23T08:39:19Z"}
{"aid":"http://arxiv.org/abs/2504.16529v1","title":"6G EdgeAI: Performance Evaluation and Analysis","summary":"Generative AI (GenAI) services powered by large language models (LLMs)\nincreasingly deliver real-time interactions, yet existing 5G multi-access edge\ncomputing (MEC) architectures often treat communication and computing as\nseparate domains, limiting their ability to meet stringent latency\nrequirements. To address this challenge, we introduce an Integrated\nCommunication and Computing (ICC) framework where computing capabilities are\nenabled to reside directly in radio access network (RAN) nodes and jointly\nmanage bandwidth and computing resources. Our queueing-theoretic analysis shows\nthat ICC outperforms 5G MEC, achieving higher service capacity (defined as the\nmaximum arrival rate that maintains a specified fraction of jobs completed\nwithin a given delay budget) by 98%. We corroborate these gains through\nsystem-level simulations that account for transformer-based LLM workloads,\nrealistic GPU specifications, and a priority-based scheduling scheme. The\nsimulations show that ICC improves service capacity by 60%, demonstrating its\npotential to enable efficient, cost-effective real-time GenAI services in 6G.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-23T08:54:10Z"}
{"aid":"http://arxiv.org/abs/2504.16538v1","title":"Streetscape Analysis with Generative AI (SAGAI): Vision-Language\n  Assessment and Mapping of Urban Scenes","summary":"Streetscapes are an essential component of urban space. Their assessment is\npresently either limited to morphometric properties of their mass skeleton or\nrequires labor-intensive qualitative evaluations of visually perceived\nqualities. This paper introduces SAGAI: Streetscape Analysis with Generative\nArtificial Intelligence, a modular workflow for scoring street-level urban\nscenes using open-access data and vision-language models. SAGAI integrates\nOpenStreetMap geometries, Google Street View imagery, and a lightweight version\nof the LLaVA model to generate structured spatial indicators from images via\ncustomizable natural language prompts. The pipeline includes an automated\nmapping module that aggregates visual scores at both the point and street\nlevels, enabling direct cartographic interpretation. It operates without\ntask-specific training or proprietary software dependencies, supporting\nscalable and interpretable analysis of urban environments. Two exploratory case\nstudies in Nice and Vienna illustrate SAGAI's capacity to produce geospatial\noutputs from vision-language inference. The initial results show strong\nperformance for binary urban-rural scene classification, moderate precision in\ncommercial feature detection, and lower estimates, but still informative, of\nsidewalk width. Fully deployable by any user, SAGAI can be easily adapted to a\nwide range of urban research themes, such as walkability, safety, or urban\ndesign, through prompt modification alone.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-23T09:08:06Z"}
{"aid":"http://arxiv.org/abs/2504.16539v1","title":"Self-organized fractal architectures driven by motility-dependent\n  chemotactic feedback","summary":"Complex spatial patterns in biological systems often arise through\nself-organization without a central coordination, guided by local interactions\nand chemical signaling. In this study, we explore how motility-dependent\nchemical deposition and concentration-sensitive feedback can give rise to\nfractal-like networks, using a minimal agent-based model. Agents deposit\nchemicals only while moving, and their future motion is biased by local\nchemical gradients. This interaction generates a rich variety of self-organized\nstructures resembling those seen in processes like early vasculogenesis and\nepithelial cell dispersal. We identify a diverse phase diagram governed by the\nrates of chemical deposition and decay, revealing transitions from uniform\ndistributions to sparse and dense networks, and ultimately to full phase\nseparation. At low chemical decay rates, agents form stable, system-spanning\nnetworks; further reduction leads to re-entry into a uniform state. A continuum\nmodel capturing the co-evolution of agent density and chemical fields confirms\nthese transitions and reveals how linear stability criteria determine the\nobserved phases. At low chemical concentrations, diffusion dominates and\npromotes fractal growth, while higher concentrations favor nucleation and\ncompact clustering. These findings unify a range of biological phenomena - such\nas chemotaxis, tissue remodeling, and self-generated gradient navigation -\nwithin a simple, physically grounded framework. Our results also offer insights\ninto designing artificial systems with emergent collective behavior, including\nrobotic swarms or synthetic active matter.","main_category":"physics.bio-ph","categories":"physics.bio-ph,cond-mat.soft,cond-mat.stat-mech","published":"2025-04-23T09:09:29Z"}
{"aid":"http://arxiv.org/abs/2504.16541v1","title":"Determining Strong Contextuality on rank-one Projectors","summary":"The strength of quantum contextuality is closely related to quantum\ncomputation power. Yu-Oh set is the minimal quantum system with\nstate-independent contextuality(SIC). However, its strength of the\ncontextuality has not been taken into account. In this paper, we present a\ngeneral method to determine whether there is a quantum state with strong\ncontextuality in the quantum system composed of rank-one projectors. Based on\nthis method, we conclude that Yu-Oh set does not have quantum states with\nstrong contextuality. This indicates that strong contextuality and SIC are\nmutually independent.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T09:10:55Z"}
{"aid":"http://arxiv.org/abs/2504.16545v1","title":"ToF-Splatting: Dense SLAM using Sparse Time-of-Flight Depth and\n  Multi-Frame Integration","summary":"Time-of-Flight (ToF) sensors provide efficient active depth sensing at\nrelatively low power budgets; among such designs, only very sparse measurements\nfrom low-resolution sensors are considered to meet the increasingly limited\npower constraints of mobile and AR/VR devices. However, such extreme sparsity\nlevels limit the seamless usage of ToF depth in SLAM. In this work, we propose\nToF-Splatting, the first 3D Gaussian Splatting-based SLAM pipeline tailored for\nusing effectively very sparse ToF input data. Our approach improves upon the\nstate of the art by introducing a multi-frame integration module, which\nproduces dense depth maps by merging cues from extremely sparse ToF depth,\nmonocular color, and multi-view geometry. Extensive experiments on both\nsynthetic and real sparse ToF datasets demonstrate the viability of our\napproach, as it achieves state-of-the-art tracking and mapping performances on\nreference datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T09:19:43Z"}
{"aid":"http://arxiv.org/abs/2504.16548v1","title":"Exploring human-SAV interaction using large language models: The impact\n  of psychological ownership and anthropomorphism on user experience","summary":"There has been extensive prior work exploring how psychological factors such\nas anthropomorphism affect the adoption of shared autonomous vehicles (SAVs).\nHowever, limited research has been conducted on how prompt strategies in large\nlanguage model (LLM)-powered SAV User Interfaces (UIs) affect users'\nperceptions, experiences, and intentions to adopt such technology. In this\nwork, we investigate how conversational UIs powered by LLMs drive these\npsychological factors and psychological ownership, the sense of possession a\nuser may come to feel towards an entity or object they may not legally own. We\ndesigned four SAV UIs with varying levels of anthropomorphic characteristics\nand psychological ownership triggers. Quantitative measures of psychological\nownership, anthropomorphism, quality of service, disclosure tendency, sentiment\nof SAV responses, and overall acceptance were collected after participants\ninteracted with each SAV. Qualitative feedback was also gathered regarding the\nexperience of psychological ownership during the interactions. The results\nindicate that an SAV conversational UI designed to be more anthropomorphic and\nto induce psychological ownership improved users' perceptions of the SAV's\nhuman-like qualities and improved the sentiment of responses compared to a\ncontrol condition. These findings provide practical guidance for designing\nLLM-based conversational UIs that enhance user experience and adoption of SAVs.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.ET","published":"2025-04-23T09:25:22Z"}
{"aid":"http://arxiv.org/abs/2504.16555v1","title":"Confidence Sequences for Generalized Linear Models via Regret Analysis","summary":"We develop a methodology for constructing confidence sets for parameters of\nstatistical models via a reduction to sequential prediction. Our key\nobservation is that for any generalized linear model (GLM), one can construct\nan associated game of sequential probability assignment such that achieving low\nregret in the game implies a high-probability upper bound on the excess\nlikelihood of the true parameter of the GLM. This allows us to develop a scheme\nthat we call online-to-confidence-set conversions, which effectively reduces\nthe problem of proving the desired statistical claim to an algorithmic\nquestion. We study two varieties of this conversion scheme: 1) analytical\nconversions that only require proving the existence of algorithms with low\nregret and provide confidence sets centered at the maximum-likelihood estimator\n2) algorithmic conversions that actively leverage the output of the online\nalgorithm to construct confidence sets (and may be centered at other,\nadaptively constructed point estimators). The resulting methodology recovers\nall state-of-the-art confidence set constructions within a single framework,\nand also provides several new types of confidence sets that were previously\nunknown in the literature.","main_category":"math.ST","categories":"math.ST,cs.LG,stat.ML,stat.TH","published":"2025-04-23T09:32:40Z"}
{"aid":"http://arxiv.org/abs/2504.16569v1","title":"The versal deformation of elliptic m-fold point curve singularities","summary":"We give explicit, highly symmetric equations for the versal deformation of\nthe singularity $L_{n+1}^n$ consisting of n+1 lines through the origin in\nn-dimensional affine space in generic position. These make evident that the\nbase space of the versal deformation of $L_{n+1}^n$ is isomorphic to the total\nspace for $L_{n}^{n-1}$, if n>4. By induction it follows that the base space is\nirreducible and Gorenstein. We discuss the known connection to a modular\ncompactification of the moduli space of (n+1)-pointed curves of genus 1.\n  For other elliptic partition curves it seems unfeasable to compute the versal\ndeformation in general. It is doubtful whether the base space is Gorenstein.\nFor rational partition curves we show that the base space in general has\ncomponents of different dimensions.","main_category":"math.AG","categories":"math.AG","published":"2025-04-23T09:47:01Z"}
{"aid":"http://arxiv.org/abs/2504.16584v1","title":"Case Study: Fine-tuning Small Language Models for Accurate and Private\n  CWE Detection in Python Code","summary":"Large Language Models (LLMs) have demonstrated significant capabilities in\nunderstanding and analyzing code for security vulnerabilities, such as Common\nWeakness Enumerations (CWEs). However, their reliance on cloud infrastructure\nand substantial computational requirements pose challenges for analyzing\nsensitive or proprietary codebases due to privacy concerns and inference costs.\nThis work explores the potential of Small Language Models (SLMs) as a viable\nalternative for accurate, on-premise vulnerability detection. We investigated\nwhether a 350-million parameter pre-trained code model (codegen-mono) could be\neffectively fine-tuned to detect the MITRE Top 25 CWEs specifically within\nPython code. To facilitate this, we developed a targeted dataset of 500\nexamples using a semi-supervised approach involving LLM-driven synthetic data\ngeneration coupled with meticulous human review. Initial tests confirmed that\nthe base codegen-mono model completely failed to identify CWEs in our samples.\nHowever, after applying instruction-following fine-tuning, the specialized SLM\nachieved remarkable performance on our test set, yielding approximately 99%\naccuracy, 98.08% precision, 100% recall, and a 99.04% F1-score. These results\nstrongly suggest that fine-tuned SLMs can serve as highly accurate and\nefficient tools for CWE detection, offering a practical and privacy-preserving\nsolution for integrating advanced security analysis directly into development\nworkflows.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-23T10:05:27Z"}
{"aid":"http://arxiv.org/abs/2504.16592v1","title":"Algorithmic Pricing and Algorithmic Collusion","summary":"The rise of algorithmic pricing in online retail platforms has attracted\nsignificant interest in how autonomous software agents interact under\ncompetition. This article explores the potential emergence of algorithmic\ncollusion - supra-competitive pricing outcomes that arise without explicit\nagreements - as a consequence of repeated interactions between learning agents.\nMost of the literature focuses on oligopoly pricing environments modeled as\nrepeated Bertrand competitions, where firms use online learning algorithms to\nadapt prices over time. While experimental research has demonstrated that\nspecific reinforcement learning algorithms can learn to maintain prices above\ncompetitive equilibrium levels in simulated environments, theoretical\nunderstanding of when and why such outcomes occur remains limited. This work\nhighlights the interdisciplinary nature of this challenge, which connects\ncomputer science concepts of online learning with game-theoretical literature\non equilibrium learning. We examine implications for the Business & Information\nSystems Engineering (BISE) community and identify specific research\nopportunities to address challenges of algorithmic competition in digital\nmarketplaces.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T10:18:57Z"}
{"aid":"http://arxiv.org/abs/2504.16596v1","title":"Learning Weighted Automata over Number Rings, Concretely and\n  Categorically","summary":"We develop a generic reduction procedure for active learning problems. Our\napproach is inspired by a recent polynomial-time reduction of the exact\nlearning problem for weighted automata over integers to that for weighted\nautomata over rationals (Buna-Marginean et al. 2024). Our procedure improves\nthe efficiency of a category-theoretic automata learning algorithm, and poses\nnew questions about the complexity of its implementation when instantiated to\nconcrete categories. As our second main contribution, we address these\ncomplexity aspects in the concrete setting of learning weighted automata over\nnumber rings, that is, rings of integers in an algebraic number field. Assuming\na full representation of a number ring OK, we obtain an exact learning\nalgorithm of OK-weighted automata that runs in polynomial time in the size of\nthe target automaton, the logarithm of the length of the longest\ncounterexample, the degree of the number field, and the logarithm of its\ndiscriminant. Our algorithm produces an automaton that has at most one more\nstate than the minimal one, and we prove that doing better requires solving the\nprincipal ideal problem, for which the best currently known algorithm is in\nquantum polynomial time.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-23T10:25:13Z"}
{"aid":"http://arxiv.org/abs/2504.16597v1","title":"Self-sorting of bidisperse particles in evaporating sessile droplets","summary":"This study investigates the dispersion and self-sorting dynamics of\nbidisperse particles, i.e., a mixture of two distinct particle sizes, during\nthe evaporation of ethanol droplets on a heated substrate, focusing on the\ninfluence of surface wettability, Marangoni stresses, and relative particle\ndensity. To this end, numerical simulations are carried out using a two-stage\nnumerical approach: the first stage simulates the gas-liquid flow along with\nthe heat and vapor distribution, while the second stage models the particle\nbehavior using Lagrangian particle tracking. The results reveal that for an\nethanol droplet evaporating with a constant contact angle in the absence of\nthermocapillary Marangoni stresses, the flow induced by the receding motion of\nthe contact line supersedes the capillary flow, moving the fluid from the\ncontact line to the apex of the droplet. This flow moves the particles from the\nbulk of the droplet to the apex of the droplet and suppresses size-based\nself-sorting of the particles. However, in the presence of Marangoni stresses,\na flow along the interface near the apex of the droplet promotes the\nself-sorting of particles based on their size, whereby smaller particles\nconcentrate near the droplet apex and larger particles form an outer shell\naround them.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T10:25:38Z"}
{"aid":"http://arxiv.org/abs/2504.16598v1","title":"Cohomologies of Reynolds Lie algebras with derivations and its\n  applications","summary":"The aim of this paper is to study the cohomology theory of Reynolds Lie\nalgebras equipped with derivations and to explore related applications. We\nbegin by introducing the concept of Reynolds LieDer pairs. Subsequently, we\nconstruct the associated cohomology. Finally, we investigate formal\ndeformations, abelian extensions, and extensions of a pair of derivations, all\ninterpreted through the lens of cohomology groups.","main_category":"math.RA","categories":"math.RA","published":"2025-04-23T10:26:56Z"}
{"aid":"http://arxiv.org/abs/2504.16609v1","title":"Information Leakage of Sentence Embeddings via Generative Embedding\n  Inversion Attacks","summary":"Text data are often encoded as dense vectors, known as embeddings, which\ncapture semantic, syntactic, contextual, and domain-specific information. These\nembeddings, widely adopted in various applications, inherently contain rich\ninformation that may be susceptible to leakage under certain attacks. The GEIA\nframework highlights vulnerabilities in sentence embeddings, demonstrating that\nthey can reveal the original sentences they represent. In this study, we\nreproduce GEIA's findings across various neural sentence embedding models.\nAdditionally, we contribute new analysis to examine whether these models leak\nsensitive information from their training datasets. We propose a simple yet\neffective method without any modification to the attacker's architecture\nproposed in GEIA. The key idea is to examine differences between log-likelihood\nfor masked and original variants of data that sentence embedding models have\nbeen pre-trained on, calculated on the embedding space of the attacker. Our\nfindings indicate that following our approach, an adversary party can recover\nmeaningful sensitive information related to the pre-training knowledge of the\npopular models used for creating sentence embeddings, seriously undermining\ntheir security. Our code is available on: https://github.com/taslanidis/GEIA","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-23T10:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.16612v1","title":"Federated EndoViT: Pretraining Vision Transformers via Federated\n  Learning on Endoscopic Image Collections","summary":"Purpose: In this study, we investigate the training of foundation models\nusing federated learning to address data-sharing limitations and enable\ncollaborative model training without data transfer for minimally invasive\nsurgery. Methods: Inspired by the EndoViT study, we adapt the Masked\nAutoencoder for federated learning, enhancing it with adaptive Sharpness-Aware\nMinimization (FedSAM) and Stochastic Weight Averaging (SWA). Our model is\npretrained on the Endo700k dataset collection and later fine-tuned and\nevaluated for tasks such as Semantic Segmentation, Action Triplet Recognition,\nand Surgical Phase Recognition. Results: Our findings demonstrate that\nintegrating adaptive FedSAM into the federated MAE approach improves\npretraining, leading to a reduction in reconstruction loss per patch. The\napplication of FL-EndoViT in surgical downstream tasks results in performance\ncomparable to CEN-EndoViT. Furthermore, FL-EndoViT exhibits advantages over\nCEN-EndoViT in surgical scene segmentation when data is limited and in action\ntriplet recognition when large datasets are used. Conclusion: These findings\nhighlight the potential of federated learning for privacy-preserving training\nof surgical foundation models, offering a robust and generalizable solution for\nsurgical data science. Effective collaboration requires adapting federated\nlearning methods, such as the integration of FedSAM, which can accommodate the\ninherent data heterogeneity across institutions. In future, exploring FL in\nvideo-based models may enhance these capabilities by incorporating\nspatiotemporal dynamics crucial for real-world surgical environments.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-23T10:54:32Z"}
{"aid":"http://arxiv.org/abs/2504.16614v1","title":"On the $in$existence of a \":splay(-bend)\" nematic phase","summary":"On the basis of the application of the (Onsager) second-virial density\nfunctional theory to an artificial system that is so designed as to be the best\npromoter of a ``splay(-bend)'' nematic phase, it is argued that this\n``modulated'' nematic phase cannot exist.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-23T11:00:03Z"}
{"aid":"http://arxiv.org/abs/2504.16624v1","title":"Compositional Active Learning of Synchronous Systems through Automated\n  Alphabet Refinement","summary":"Active automata learning infers automaton models of systems from behavioral\nobservations, a technique successfully applied to a wide range of domains.\nCompositional approaches for concurrent systems have recently emerged. We take\na significant step beyond available results, including those by the authors,\nand develop a general technique for compositional learning of a synchronizing\nparallel system with an unknown decomposition. Our approach automatically\nrefines the global alphabet into component alphabets while learning the\ncomponent models. We develop a theoretical treatment of distributions of\nalphabets, i.e., sets of possibly overlapping component alphabets. We\ncharacterize counter-examples that reveal inconsistencies with global\nobservations, and show how to systematically update the distribution to restore\nconsistency. We present a compositional learning algorithm implementing these\nideas, where learning counterexamples precisely correspond to distribution\ncounterexamples under well-defined conditions. We provide an implementation,\ncalled CoalA, using the state-of-the-art active learning library LearnLib. Our\nexperiments show that in more than 630 subject systems, CoalA delivers orders\nof magnitude improvements (up to five orders) in membership queries and in\nsystems with significant concurrency, it also achieves better scalability in\nthe number of equivalence queries.","main_category":"cs.LG","categories":"cs.LG,cs.FL","published":"2025-04-23T11:30:01Z"}
{"aid":"http://arxiv.org/abs/2504.16637v1","title":"RouteWinFormer: A Route-Window Transformer for Middle-range Attention in\n  Image Restoration","summary":"Transformer models have recently garnered significant attention in image\nrestoration due to their ability to capture long-range pixel dependencies.\nHowever, long-range attention often results in computational overhead without\npractical necessity, as degradation and context are typically localized.\nNormalized average attention distance across various degradation datasets shows\nthat middle-range attention is enough for image restoration. Building on this\ninsight, we propose RouteWinFormer, a novel window-based Transformer that\nmodels middle-range context for image restoration. RouteWinFormer incorporates\nRoute-Windows Attnetion Module, which dynamically selects relevant nearby\nwindows based on regional similarity for attention aggregation, extending the\nreceptive field to a mid-range size efficiently. In addition, we introduce\nMulti-Scale Structure Regularization during training, enabling the sub-scale of\nthe U-shaped network to focus on structural information, while the\noriginal-scale learns degradation patterns based on generalized image structure\npriors. Extensive experiments demonstrate that RouteWinFormer outperforms\nstate-of-the-art methods across 9 datasets in various image restoration tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T11:57:22Z"}
{"aid":"http://arxiv.org/abs/2504.16643v1","title":"Multiple Rota-Baxter algebra and multiple Rota-Baxter modules","summary":"In this paper, we develop the theory of multiple Rota-Baxter modules over\nmultiple Rota-Baxter algebras. We introduce left, right, and bimodule\nstructures and construct free $\\Omega$-operated modules with mixable tensor\nestablishing free commutative multiple Rota-Baxter modules. We provide a\nnecessary and sufficient condition for a free module to admit a free multiple\nRota-Baxter module structure. Furthermore, we define projective and injective\nmultiple Rota-Baxter modules, showing that their category has enough projective\nand injective objects to support derived $\\mathrm{Hom}$ functors. Finally, we\nintroduce the tensor product of multiple Rota-Baxter algebras and define flat\nmultiple Rota-Baxter modules, proving that both free and projective modules\nsatisfy the flatness property.","main_category":"math.RA","categories":"math.RA","published":"2025-04-23T12:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.16653v1","title":"Photo-generated charge-transfer excitons in NiO revealed by ultrafast\n  time-resolved resonant inelastic x-ray scattering","summary":"Strong electronic correlation can lead to insulating behavior and to the\nopening of large optical gaps, even in materials with partly filled valence\nshells. Although the non-equilibrium optical response encodes both local (quasi\natomic) and collective (long range) responses, optical spectroscopy is usually\nmore sensitive to the latter. Resonant x-ray techniques are better suited to\ninvestigate the quasi-atomic properties of correlated solids. Using\ntime-resolved resonant inelastic x-ray scattering (RIXS), here we study the\nultrafast non-equilibrium processes in NiO following photo-excitation by\nultraviolet photons with energy exceeding the optical gap. We observe the\ncreation of charge-transfer excitons that decay with a time constant of about\n2\\,ps, while itinerant photo-doping persists for tens of picoseconds. Following\nour discovery, which establishes time-resolved high-resolution RIXS as a\npowerful tool for the study of transient phenomena in condensed matter, the\npossible presence of charge-transfer excitons will need to be considered when\ninterpreting optical pump-probe experiments on correlated quantum materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-23T12:19:33Z"}
{"aid":"http://arxiv.org/abs/2504.16655v1","title":"WiFi based Human Fall and Activity Recognition using Transformer based\n  Encoder Decoder and Graph Neural Networks","summary":"Human pose estimation and action recognition have received attention due to\ntheir critical roles in healthcare monitoring, rehabilitation, and assistive\ntechnologies. In this study, we proposed a novel architecture named Transformer\nbased Encoder Decoder Network (TED Net) designed for estimating human skeleton\nposes from WiFi Channel State Information (CSI). TED Net integrates\nconvolutional encoders with transformer based attention mechanisms to capture\nspatiotemporal features from CSI signals. The estimated skeleton poses were\nused as input to a customized Directed Graph Neural Network (DGNN) for action\nrecognition. We validated our model on two datasets: a publicly available multi\nmodal dataset for assessing general pose estimation, and a newly collected\ndataset focused on fall related scenarios involving 20 participants.\nExperimental results demonstrated that TED Net outperformed existing approaches\nin pose estimation, and that the DGNN achieves reliable action classification\nusing CSI based skeletons, with performance comparable to RGB based systems.\nNotably, TED Net maintains robust performance across both fall and non fall\ncases. These findings highlight the potential of CSI driven human skeleton\nestimation for effective action recognition, particularly in home environments\nsuch as elderly fall detection. In such settings, WiFi signals are often\nreadily available, offering a privacy preserving alternative to vision based\nmethods, which may raise concerns about continuous camera monitoring.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T12:22:24Z"}
{"aid":"http://arxiv.org/abs/2504.16660v1","title":"Five Specific Cases of the Simple Equations Method (SEsM)","summary":"We discuss the Simple Equations Method (SEsM) for obtaining exact solutions\nof nonlinear partial differential equations. We show that the Jacobi Elliptic\nFunction Expansion Method, F-Expansion method, Modified Simple Equation method,\nTrial Function Method, General Projective Riccati Equations Method and the\nFirst Integral Method are specific cases of SEsM.","main_category":"nlin.SI","categories":"nlin.SI","published":"2025-04-23T12:26:53Z"}
{"aid":"http://arxiv.org/abs/2504.16670v1","title":"Open Source Software Lifecycle Classification: Developing Wrangling\n  Techniques for Complex Sociotechnical Systems","summary":"Open source software is a rapidly evolving center for distributed work, and\nunderstanding the characteristics of this work across its different contexts is\nvital for informing policy, economics, and the design of enabling software. The\nsteep increase in open source projects and corporate participation have\ntransformed a peripheral, cottage industry component of the global technology\necosystem into a large, infinitely complex \"technology parts supplier\" wired\ninto every corner of contemporary life. The lack of theory and tools for\nbreaking this complexity down into identifiable project types or strategies for\nunderstanding them more systematically is incommensurate with current industry,\nsociety, and developer needs. This paper reviews previous attempts to classify\nopen source software and other organizational ecosystems, using open source\nscientific software ecosystems in contrast with those found in corporatized\nopen source software. It then examines the divergent and sometimes conflicting\npurposes that may exist for classifying open source projects and how these\ncompeting interests impede our progress in developing a comprehensive\nunderstanding of how open source software projects and companies operate.\nFinally, we will present an empirical, mixed-methods study demonstrating how to\nclassify open-source projects by their lifecycle position. This is the first\nstep forward, advancing our scientific and practical knowledge of open source\nsoftware through the lens of dynamic and evolving open source genres. It\nconcludes with examples and a proposed path forward.","main_category":"cs.SE","categories":"cs.SE,cs.HC,H.4","published":"2025-04-23T12:37:53Z"}
{"aid":"http://arxiv.org/abs/2504.16676v1","title":"Volumes of divisors in a family and variation of singularities of linear\n  systems","summary":"We study the behavior of volumes of divisors in a family. We show that the\nvolume of a divisor on the generic fiber equals the infimum of its volumes on\nfibers over any dense subset of the base. As an application, we show that the\nvolume function is upper semicontinuous in flat families with reduced and\nirreducible fibers.\n  We also prove that for a $\\mathbb{Q}$-Cartier divisor $B$ on a family of\nvarieties $X\\rightarrow T$, if $(X_t,|B_t|_{\\mathbb{Q}})$ is $\\epsilon$-lc and\nthe volume of $B_t$ is a constant for densely many closed points $t\\in T$, then\nthe generic fiber $(X_\\eta,|B_\\eta|_{\\mathbb{Q}})$ is also $\\epsilon$-lc.","main_category":"math.AG","categories":"math.AG","published":"2025-04-23T12:46:23Z"}
{"aid":"http://arxiv.org/abs/2504.16690v1","title":"Logic and Concepts in the 2-category of Topoi","summary":"We use Kan injectivity to axiomatise concepts in the 2-category of topoi. We\nshowcase the expressivity of this language through many examples, and we\nestablish some aspects of the formal theory of Kan extension in this 2-category\n(pointwise Kan extensions, fully faithful morphisms, etc.). We use this\ntechnology to introduce fragments of geometric logic, and we accommodate\nessentially algebraic, disjunctive, regular, and coherent logic in our\nframework, together with some more exotic examples. We show that each fragment\n$\\mathcal{H}$ in our sense identifies a lax-idempotent (relative) pseudomonad\n$\\mathsf{T}^{\\mathcal{H}}$ on $\\mathsf{lex}$, the $2$-category of finitely\ncomplete categories. We show that the algebras for $\\mathsf{T}^{\\mathcal{H}}$\nadmit a notion of classifying topos, for which we deliver several\nDiaconescu-type results. The construction of classifying topoi allows us to\ndefine conceptually complete fragments of geometric logic.","main_category":"math.LO","categories":"math.LO,cs.LO,math.CT","published":"2025-04-23T13:21:57Z"}
{"aid":"http://arxiv.org/abs/2504.16693v1","title":"PIN-WM: Learning Physics-INformed World Models for Non-Prehensile\n  Manipulation","summary":"While non-prehensile manipulation (e.g., controlled pushing/poking)\nconstitutes a foundational robotic skill, its learning remains challenging due\nto the high sensitivity to complex physical interactions involving friction and\nrestitution. To achieve robust policy learning and generalization, we opt to\nlearn a world model of the 3D rigid body dynamics involved in non-prehensile\nmanipulations and use it for model-based reinforcement learning. We propose\nPIN-WM, a Physics-INformed World Model that enables efficient end-to-end\nidentification of a 3D rigid body dynamical system from visual observations.\nAdopting differentiable physics simulation, PIN-WM can be learned with only\nfew-shot and task-agnostic physical interaction trajectories. Further, PIN-WM\nis learned with observational loss induced by Gaussian Splatting without\nneeding state estimation. To bridge Sim2Real gaps, we turn the learned PIN-WM\ninto a group of Digital Cousins via physics-aware randomizations which perturb\nphysics and rendering parameters to generate diverse and meaningful variations\nof the PIN-WM. Extensive evaluations on both simulation and real-world tests\ndemonstrate that PIN-WM, enhanced with physics-aware digital cousins,\nfacilitates learning robust non-prehensile manipulation skills with Sim2Real\ntransfer, surpassing the Real2Sim2Real state-of-the-arts.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-23T13:27:07Z"}
{"aid":"http://arxiv.org/abs/2504.16697v1","title":"On deciding transcendence of power series","summary":"It is well known that algebraic power series are differentially finite\n(D-finite): they satisfy linear differential equations with polynomial\ncoefficients. The converse problem, whether a given D-finite power series is\nalgebraic or transcendental, is notoriously difficult. We prove that this\nproblem is decidable: we give two theoretical algorithms and a transcendence\ntest that is efficient in practice.","main_category":"math.NT","categories":"math.NT,cs.SC,math.CA","published":"2025-04-23T13:28:05Z"}
{"aid":"http://arxiv.org/abs/2504.16701v1","title":"Spinning top in quadratic potential and matrix dressing chain","summary":"We show that the equations of motion of the rigid body about a fixed point in\nthe Newtonian field with a quadratic potential are special reduction of\nperiod-one closure of the Darboux dressing chain for the Schr\\\"odinger\noperators with matrix potentials. Some new explicit solutions of the\ncorresponding matrix system and the spectral properties of the related\nSchr\\\"odinger operators are discussed.","main_category":"math-ph","categories":"math-ph,math.MP,math.SP","published":"2025-04-23T13:29:15Z"}
{"aid":"http://arxiv.org/abs/2504.16716v1","title":"Invertible Orbifolds over Finite Fields","summary":"In the context of Berglund-Huebsch mirror symmetry, we compute the\neigenvalues of the Frobenius endomorphism acting on a p-adic version of\nBorisov's complex. As a result, we conjecture an explicit formula for the\nnumber of points of crepant resolutions of invertible Calabi-Yau orbifolds\ndefined over a finite field.","main_category":"math.NT","categories":"math.NT,hep-th,math.AG","published":"2025-04-23T13:44:29Z"}
{"aid":"http://arxiv.org/abs/2504.16726v1","title":"Partial orders and contraction for BISO channels","summary":"A fundamental question in information theory is to quantify the loss of\ninformation under a noisy channel. Partial orders and contraction coefficients\nare typical tools to that end, however, they are often also challenging to\nevaluate. For the special class of binary input symmetric output (BISO)\nchannels, Geng et al. showed that among channels with the same capacity, the\nbinary symmetric channel (BSC) and binary erasure channel (BEC) are extremal\nwith respect to the more capable order. Here, we show two main results. First,\nfor channels with the same KL contraction coefficient, the same holds with\nrespect to the less noisy order. Second, for channels with the same Dobrushin\ncoefficient, or equiv. maximum leakage or Doeblin coefficient, the same holds\nwith respect to the degradability order. In the process, we provide a\nclosed-form expression for the contraction coefficients of BISO channels. We\nalso discuss the comparability of BISO channels and extensions to binary\nchannels in general.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-23T14:00:36Z"}
{"aid":"http://arxiv.org/abs/2504.16730v1","title":"Extremal divisors on moduli spaces of K3 surfaces","summary":"We establish numerical criteria for when a Noether-Lefschetz divisor on a\nmoduli space of quasi-polarized K3 surfaces $F_{2d}$, or more generally on an\northogonal modular variety, generates an extremal ray in the cone of\npseudoeffective divisors. In particular, for all d, we exhibit many extremal\nrays of the cone of pseudoeffective divisors of both $F_{2d}$ and any normal\nprojective $\\mathbb{Q}$-factorial compactification of $F_{2d}$ lying over its\nBaily-Borel compactification.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-04-23T14:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.16735v1","title":"An Expressive Coalgebraic Modal Logic for Cellular Automata","summary":"Cellular automata provide models of parallel computation based on cells,\nwhose connectivity is given by an action of a monoid on the cells. At each step\nin the computation, every cell is decorated with a state that evolves in\ndiscrete steps according to a local update rule, which determines the next\nstate of a cell based on its neighbour's states. In this paper, we consider a\ncoalgebraic view on cellular automata, which does not require typical\nrestrictions, such as uniform neighbourhood connectivity and uniform local\nrules. Using the coalgebraic view, we devise a behavioural equivalence for\ncellular automata and a modal logic to reason about their behaviour. We then\nprove a Hennessy-Milner style theorem, which states that pairs of cells satisfy\nthe same modal formulas exactly if they are identified under cellular\nbehavioural equivalence.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-23T14:05:29Z"}
{"aid":"http://arxiv.org/abs/2504.16736v1","title":"A Survey of AI Agent Protocols","summary":"The rapid development of large language models (LLMs) has led to the\nwidespread deployment of LLM agents across diverse industries, including\ncustomer service, content generation, data analysis, and even healthcare.\nHowever, as more LLM agents are deployed, a major issue has emerged: there is\nno standard way for these agents to communicate with external tools or data\nsources. This lack of standardized protocols makes it difficult for agents to\nwork together or scale effectively, and it limits their ability to tackle\ncomplex, real-world tasks. A unified communication protocol for LLM agents\ncould change this. It would allow agents and tools to interact more smoothly,\nencourage collaboration, and triggering the formation of collective\nintelligence. In this paper, we provide a systematic overview of existing\ncommunication protocols for LLM agents. We classify them into four main\ncategories and make an analysis to help users and developers select the most\nsuitable protocols for specific applications. Additionally, we conduct a\ncomparative performance analysis of these protocols across key dimensions such\nas security, scalability, and latency. Finally, we explore future challenges,\nsuch as how protocols can adapt and survive in fast-evolving environments, and\nwhat qualities future protocols might need to support the next generation of\nLLM agent ecosystems. We expect this work to serve as a practical reference for\nboth researchers and engineers seeking to design, evaluate, or integrate robust\ncommunication infrastructures for intelligent agents.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-23T14:07:26Z"}
{"aid":"http://arxiv.org/abs/2504.16739v1","title":"Prompt-Tuning SAM: From Generalist to Specialist with only 2048\n  Parameters and 16 Training Images","summary":"The Segment Anything Model (SAM) is widely used for segmenting a diverse\nrange of objects in natural images from simple user prompts like points or\nbounding boxes. However, SAM's performance decreases substantially when applied\nto non-natural domains like microscopic imaging. Furthermore, due to SAM's\ninteractive design, it requires a precise prompt for each image and object,\nwhich is unfeasible in many automated biomedical applications. Previous\nsolutions adapt SAM by training millions of parameters via fine-tuning large\nparts of the model or of adapter layers. In contrast, we show that as little as\n2,048 additional parameters are sufficient for turning SAM into a use-case\nspecialist for a certain downstream task. Our novel PTSAM (prompt-tuned SAM)\nmethod uses prompt-tuning, a parameter-efficient fine-tuning technique, to\nadapt SAM for a specific task. We validate the performance of our approach on\nmultiple microscopic and one medical dataset. Our results show that\nprompt-tuning only SAM's mask decoder already leads to a performance on-par\nwith state-of-the-art techniques while requiring roughly 2,000x less trainable\nparameters. For addressing domain gaps, we find that additionally prompt-tuning\nSAM's image encoder is beneficial, further improving segmentation accuracy by\nup to 18% over state-of-the-art results. Since PTSAM can be reliably trained\nwith as little as 16 annotated images, we find it particularly helpful for\napplications with limited training data and domain shifts.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T14:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.16741v1","title":"Search Timelines: Visualizing Search History to Enable Cross-Session\n  Exploratory Search","summary":"Purpose: The timespan over which exploratory searching can occur, as well as\nthe scope and volume of the search activities undertaken, can make it difficult\nfor searchers to remember key details about their search activities. These\ndifficulties are present both in the midst of searching as well as when\nresuming a search that spans multiple sessions. In this paper, we present a\nsearch interface designed to support cross-session exploratory search in a\npublic digital library context. Methods: Search Timelines provides a\nvisualization of current and past search activities via a dynamic timeline of\nthe search activity (queries and saved resources). This timeline is presented\nat two levels of detail. An overview timeline is provided alongside the search\nresults in a typical search engine results page design. A detailed timeline is\nprovided in the workspace, where searchers can review the history of their\nsearch activities and their saved resources. A controlled laboratory study was\nconducted to compare this approach to a baseline interface modelled after a\ntypical public digital library search/workspace interface. Results:\nParticipants who used Search Timelines reported higher levels of user\nengagement, usability, and perceived knowledge gain, during an initial search\nsession and when resuming the search after a 7-8 day interval. This came at the\nexpense of the searchers taking more time to complete the search task, which we\nview as positive evidence of engagement in cross-session exploratory search\nprocesses. Conclusion: Search Timelines serves as an example of how lightweight\nvisualization approaches can be used to enhance typical search interface\ndesigns to support exploratory search. The results highlight the value of\nproviding persistent representations of past search activities within the\nsearch interface.","main_category":"cs.HC","categories":"cs.HC,cs.IR","published":"2025-04-23T14:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.16746v1","title":"Beating the break-even point with autonomous quantum error correction","summary":"Quantum error correction (QEC) is essential for practical quantum computing,\nas it protects fragile quantum information from errors by encoding it in\nhigh-dimensional Hilbert spaces. Conventional QEC protocols typically require\nrepeated syndrome measurements, real-time feedback, and the use of multiple\nphysical qubits for encoding. Such implementations pose significant technical\ncomplexities, particularly for trapped-ion systems, with high demands on\nprecision and scalability. Here, we realize autonomous QEC with a logical qubit\nencoded in multiple internal spin states of a single trapped ion, surpassing\nthe break-even point for qubit lifetime. Our approach leverages engineered\nspin-motion couplings to transfer error-induced entropy into motional modes,\nwhich are subsequently dissipated through sympathetic cooling with an ancilla\nion, fully eliminating the need for measurement and feedback. By repetitively\napplying this autonomous QEC protocol under injected low-frequency noise, we\nextend the logical qubit lifetime to approximately 11.6 ms, substantially\noutperforming lifetime for both the physical qubit ($\\simeq$0.9 ms) and the\nuncorrected logical qubit ($\\simeq$0.8 ms), thereby beating the break-even\npoint with autonomous protection of quantum information without measurement or\npost-selection. This work presents an efficient approach to fault-tolerant\nquantum computing that harnesses the intrinsic multi-level structure of trapped\nions, providing a distinctive path toward scalable architectures and robust\nquantum memories with reduced overhead.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T14:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.16750v1","title":"Tunable Inter-Edge Interactions in a Bilayer Graphene Quantum Hall\n  Antidot","summary":"Electronic interferometers in the quantum Hall regime are one of the best\ntools to study the statistical properties of localized quasiparticles in the\ntopologically protected bulk. However, since their behavior is probed via\nchiral edge modes, bulk-to-edge and inter-edge interactions are two important\neffects that affect the observations. Moreover, almost all kinds of\ninterferometers heavily rely on a pair of high-quality quantum point contacts\nwhere the presence of impurities significantly modifies the behavior of such\nconstrictions, which in turn can alter the outcome of the measurements.\nAntidots, potential hills in the quantum Hall regime, are particularly valuable\nin this context, as they overcome the geometric limitations of conventional\ngeometries and act as controlled impurities within a quantum point contact.\nFurthermore, antidots allow for quasiparticle charge detection through simple\nconductance measurements, replacing the need for complex techniques such as\nshot noise. Here, we use a gate-defined bilayer graphene antidot, operated in\nthe Coulomb-dominated regime. By varying the antidot potential, we can tune\ninter-edge interactions, enabling a crossover from a single-dot to a double-dot\nbehavior. In the latter, strong coupling between the two edge states leads to\nedge-state pairing, resulting in a measured doubling of the tunneling charge.\nWe find that in certain regimes, the inter-edge coupling completely dominates\nover other energy scales of the system, overshadowing the interference effects\nthese devices are mainly designed to probe. These results highlight the\nsignificant role of inter-edge interactions and establish antidots as a\nversatile platform for exploring quantum Hall interferometry.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-23T14:19:20Z"}
{"aid":"http://arxiv.org/abs/2504.16756v1","title":"The root-exponential convergence of lightning plus polynomial\n  approximation on corner domains (II)","summary":"This paper builds rigorous analysis on the root-exponential convergence for\nthe lightning schemes via rational functions in approximating corner\nsingularity problems with uniform exponentially clustered poles proposed by\nGopal and Trefethen. The start point is to set up the representations of\n$z^\\alpha$ and $z^\\alpha\\log z$ in the slit disk and develop results akin to\nPaley-Wiener theorem, from which, together with the Poisson summation formula,\nthe root-exponential convergence of the lightning plus polynomial scheme with\nan exact order for each clustered parameter is established in approximation of\nprototype functions $g(z)z^\\alpha$ or $g(z)z^\\alpha\\log z$ on a sector-shaped\ndomain, which includes $[0,1]$ as a special case. In addition, the fastest\nconvergence rate is confirmed based upon the best choice of the clustered\nparameter. Furthermore, the optimal choice of the clustered parameter and the\nconvergence rate for corner singularity problems in solving Laplace equations\nare attested based on Lehman and Wasow's study of corner singularities and\nalong with the decomposition of Gopal and Trefethen. The thorough analysis\nprovides a solid foundation for lightning schemes and rational approximation.\nAmple numerical evidences demonstrate the optimality and sharpness of the\nestimates.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-23T14:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.16758v1","title":"The Interplay of Single Ion Anisotropy and Magnetic 3d-4f Interactions\n  in V$^{\\rm III}_2$Ln$^{\\rm III}_2$ Butterfly Complexes","summary":"Within the framework of 3d-4f molecular magnets, the most thoroughly\ninvestigated architecture is that of butterfly-shaped coordination clusters as\nit provides an ideal testbed to study fundamental magnetic interactions. Here,\nwe report the synthesis and characterisation of a series of isostructural\nV$^{\\rm III}_2$Ln$^{\\rm III}_2$ butterfly complexes, where Ln = Y (1Y), Tb\n(2Tb), Dy (3Dy), Ho (4Ho), Er (5Er), Tm (6Tm), Yb (7Yb), which extends the\nprevious study on isostructural butterflies with Cr$^{\\rm III}$, Mn$^{\\rm III}$\nand Fe$^{\\rm III}$. In zero external field, compounds 2Tb, 3Dy and 4Ho show\nclear maxima in the out-of-phase component of the ac susceptibility whereas\nsmall magnetic fields are needed to suppress quantum tunneling in 6Tm. Combined\nhigh-field electron paramagnetic resonance spectroscopy and magnetisation\nmeasurements unambiguously reveal an easy-plane anisotropy of the V$^{\\rm III}$\nion and antiferromagnetic Ising-like 3d-4f exchange couplings. The strength of\n$J_{\\rm 3d-4f}$ is shown to decrease upon variation of the 4f ion from Tb to\nHo, while increasing antiferromagnetic interaction can be observed from Ho to\nTm. The exact inverse chemical trend is found for the relative angle between\nthe 3d and 4f main anisotropy axes, which highlights the important role of the\nlanthanide 4f electron distribution anisotropy for 3d-4f exchange.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-23T14:32:15Z"}
{"aid":"http://arxiv.org/abs/2504.16776v1","title":"Building sets, Chow rings, and their Hilbert series","summary":"We establish formulas for the Hilbert series of the Feichtner--Yuzvinsky Chow\nring of a polymatroid using arbitrary building sets. For braid matroids and\nminimal building sets, our results produce new formulas for the Poincar\\'e\npolynomial of the moduli space $\\overline{\\mathcal{M}}_{0,n+1}$ of pointed\nstable rational curves, and recover several previous results by Keel, Getzler,\nManin, and Aluffi--Marcolli--Nascimento. We also use our methods to produce\nexamples of matroids and building sets for which the corresponding Chow ring\nhas Hilbert series with non-log-concave coefficients. This contrasts with the\nreal-rootedness and log-concavity conjectures of Ferroni--Schr\\\"oter for\nmatroids with maximal building sets, and of Aluffi--Chen--Marcolli for braid\nmatroids with minimal building sets.","main_category":"math.CO","categories":"math.CO","published":"2025-04-23T14:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.16782v1","title":"Graph2Nav: 3D Object-Relation Graph Generation to Robot Navigation","summary":"We propose Graph2Nav, a real-time 3D object-relation graph generation\nframework, for autonomous navigation in the real world. Our framework fully\ngenerates and exploits both 3D objects and a rich set of semantic relationships\namong objects in a 3D layered scene graph, which is applicable to both indoor\nand outdoor scenes. It learns to generate 3D semantic relations among objects,\nby leveraging and advancing state-of-the-art 2D panoptic scene graph works into\nthe 3D world via 3D semantic mapping techniques. This approach avoids previous\ntraining data constraints in learning 3D scene graphs directly from 3D data. We\nconduct experiments to validate the accuracy in locating 3D objects and\nlabeling object-relations in our 3D scene graphs. We also evaluate the impact\nof Graph2Nav via integration with SayNav, a state-of-the-art planner based on\nlarge language models, on an unmanned ground robot to object search tasks in\nreal environments. Our results demonstrate that modeling object relations in\nour scene graphs improves search efficiency in these navigation tasks.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T14:58:56Z"}
{"aid":"http://arxiv.org/abs/2504.16783v1","title":"Response to Comment on \"Non-Polaritonic Effects in Cavity-Modified\n  Photochemistry\": On the Importance of Experimental Details","summary":"This note responds to Schwartz and Hutchison's Comment (arXiv:2403.06001) on\nour article (DOI:10.1002/adma.202309393). We think differences have arisen not\nin the experimental results themselves but in their interpretation: our more\nextensive experiments allowed us to distinguish between \"true positive\" and\n\"false positive\" results. We identify potential evidence of non-polaritonic\neffects in Schwartz and Hutchison's own work. We hope our work will encourage\nothers to produce more systematic investigations of strong coupling.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-23T15:01:20Z"}
{"aid":"http://arxiv.org/abs/2504.16791v1","title":"Radiometer Calibration using Machine Learning","summary":"Radiometers are crucial instruments in radio astronomy, forming the primary\ncomponent of nearly all radio telescopes. They measure the intensity of\nelectromagnetic radiation, converting this radiation into electrical signals. A\nradiometer's primary components are an antenna and a Low Noise Amplifier (LNA),\nwhich is the core of the ``receiver'' chain. Instrumental effects introduced by\nthe receiver are typically corrected or removed during calibration. However,\nimpedance mismatches between the antenna and receiver can introduce unwanted\nsignal reflections and distortions. Traditional calibration methods, such as\nDicke switching, alternate the receiver input between the antenna and a\nwell-characterised reference source to mitigate errors by comparison. Recent\nadvances in Machine Learning (ML) offer promising alternatives. Neural\nnetworks, which are trained using known signal sources, provide a powerful\nmeans to model and calibrate complex systems where traditional analytical\napproaches struggle. These methods are especially relevant for detecting the\nfaint sky-averaged 21-cm signal from atomic hydrogen at high redshifts. This is\none of the main challenges in observational Cosmology today. Here, for the\nfirst time, we introduce and test a machine learning-based calibration\nframework capable of achieving the precision required for radiometric\nexperiments aiming to detect the 21-cm line.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO,cs.AI","published":"2025-04-23T15:10:25Z"}
{"aid":"http://arxiv.org/abs/2504.16796v1","title":"Phase locking of ring-shaped exciton-polariton condensates to coherent\n  optical drive","summary":"The effect of an additional quasi-resonant drive on the dynamics of the\nring-shaped incoherently pumped polariton condensates carrying angular momentum\n(vorticity) is studied theoretically. Numerical simulations of the 2D and 1D\nGross-Pitaevskii equations show that the difference of the topological\ncharges(vorticities) $\\Delta n$ of the condensate and the quasi-resonant\ncoherent drive plays a crucial role in the synchronization dynamics. It is\nshown that in an axially symmetric system, synchronization can only occur if\n$|\\Delta n| = 0$, whereas in the other cases the phase of the condensate cannot\nbe locked to the phase of the coherent drive. To explain this effect observed\nin the numerical simulations a perturbation theory is developed. The theory\nshows that the phase slip between the condensate and the coherent drive can be\nunderstood in terms of the motion of 2$\\pi$ kinks. It is shown that the\nbreaking of the axial symmetry can stop the motion of the kinks, allowing the\nphase locking of the condensate to the coherent drive.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-23T15:16:22Z"}
{"aid":"http://arxiv.org/abs/2504.16833v1","title":"LRASGen: LLM-based RESTful API Specification Generation","summary":"REpresentation State Transfer (REST) is an architectural style for designing\nweb applications that enable scalable, stateless communication between clients\nand servers via common HTTP techniques. Web APIs that employ the REST style are\nknown as RESTful (or REST) APIs. When using or testing a RESTful API,\ndevelopers may need to employ its specification, which is often defined by\nopen-source standards such as the OpenAPI Specification (OAS). However, it can\nbe very time-consuming and error-prone to write and update these\nspecifications, which may negatively impact the use of RESTful APIs, especially\nwhen the software requirements change. Many tools and methods have been\nproposed to solve this problem, such as Respector and Swagger Core. OAS\ngeneration can be regarded as a common text-generation task that creates a\nformal description of API endpoints derived from the source code. A potential\nsolution for this may involve using Large Language Models (LLMs), which have\nstrong capabilities in both code understanding and text generation. Motivated\nby this, we propose a novel approach for generating the OASs of RESTful APIs\nusing LLMs: LLM-based RESTful API-Specification Generation (LRASGen). To the\nbest of our knowledge, this is the first use of LLMs and API source code to\ngenerate OASs for RESTful APIs. Compared with existing tools and methods,\nLRASGen can generate the OASs, even when the implementation is incomplete (with\npartial code, and/or missing annotations/comments, etc.). To evaluate the\nLRASGen performance, we conducted a series of empirical studies on 20\nreal-world RESTful APIs. The results show that two LLMs (GPT-4o mini and\nDeepSeek V3) can both support LARSGen to generate accurate specifications, and\nLRASGen-generated specifications cover an average of 48.85% more missed\nentities than the developer-provided specifications.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T15:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.16837v1","title":"Approximating Optimal Labelings for Temporal Connectivity","summary":"In a temporal graph the edge set dynamically changes over time according to a\nset of time-labels associated with each edge that indicates at which time-steps\nthe edge is available. Two vertices are connected if there is a path connecting\nthem in which the edges are traversed in increasing order of their labels. We\nstudy the problem of scheduling the availability time of the edges of a\ntemporal graph in such a way that all pairs of vertices are connected within a\ngiven maximum allowed time $a$ and the overall number of labels is minimized.\n  The problem, known as \\emph{Minimum Aged Labeling} (MAL), has several\napplications in logistics, distribution scheduling, and information spreading\nin social networks, where carefully choosing the time-labels can significantly\nreduce infrastructure costs, fuel consumption, or greenhouse gases.\n  The problem MAL has previously been proved to be NP-complete on undirected\ngraphs and \\APX-hard on directed graphs. In this paper, we extend our knowledge\non the complexity and approximability of MAL in several directions. We first\nshow that the problem cannot be approximated within a factor better than\n$O(\\log n)$ when $a\\geq 2$, unless $\\text{P} = \\text{NP}$, and a factor better\nthan $2^{\\log ^{1-\\epsilon} n}$ when $a\\geq 3$, unless $\\text{NP}\\subseteq\n\\text{DTIME}(2^{\\text{polylog}(n)})$, where $n$ is the number of vertices in\nthe graph. Then we give a set of approximation algorithms that, under some\nconditions, almost match these lower bounds. In particular, we show that the\napproximation depends on a relation between $a$ and the diameter of the input\ngraph.\n  We further establish a connection with a foundational optimization problem on\nstatic graphs called \\emph{Diameter Constrained Spanning Subgraph} (DCSS) and\nshow that our hardness results also apply to DCSS.","main_category":"cs.DS","categories":"cs.DS,cs.AI","published":"2025-04-23T16:00:33Z"}
{"aid":"http://arxiv.org/abs/2504.16838v1","title":"Real Quantum Mechanics in a Kahler Space","summary":"In this paper, we demonstrate the equivalence between the complex Hilbert\nspace and real Kahler space formulations of quantum mechanics.\n  Complex numbers play an important role in the traditional formulation of\nquantum mechanics in complex Hilbert spaces. However, the necessity of complex\nnumbers--as opposed to their mere convenience--remains a subject of debate.\nSeveral alternative formulations of quantum mechanics using real numbers have\nbeen proposed. In this paper, we demonstrate that standard quantum mechanics,\nformulated in a complex Hilbert space, admits an equivalent reformulation in a\nreal Kahler space. By establishing a natural isomorphism between the operator\ntheories of the complex Hilbert space and the real Kahler space, we prove the\nequivalence of the two formulations including composite system.\n  This Kahler-space framework preserves all essential features of quantum\nmechanics while offering a key advantage: it inherently incorporates a\nHamiltonian symplectic structure analogous to classical mechanics. This\nstructural alignment provides a unified geometric perspective for both\nclassical and quantum dynamics. Additionally, we show that the ergodicity of\nfinite-dimensional quantum systems becomes manifest in this framework,\nresolving interpretational ambiguities present in conventional complex\nformulations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T16:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.16839v1","title":"SMART: Tuning a symbolic music generation system with an audio domain\n  aesthetic reward","summary":"Recent work has proposed training machine learning models to predict\naesthetic ratings for music audio. Our work explores whether such models can be\nused to finetune a symbolic music generation system with reinforcement\nlearning, and what effect this has on the system outputs. To test this, we use\ngroup relative policy optimization to finetune a piano MIDI model with Meta\nAudiobox Aesthetics ratings of audio-rendered outputs as the reward. We find\nthat this optimization has effects on multiple low-level features of the\ngenerated outputs, and improves the average subjective ratings in a preliminary\nlistening study with $14$ participants. We also find that over-optimization\ndramatically reduces diversity of model outputs.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-23T16:02:25Z"}
{"aid":"http://arxiv.org/abs/2504.16844v1","title":"Boundary anomalous dimensions from BCFT: O($N$)-symmetric $φ^{2n}$\n  theories with a boundary and higher-derivative generalizations","summary":"We investigate the $\\phi^{2n}$ deformations of the O($N$)-symmetric\n(generalized) free theories with a flat boundary, where $n\\geqslant 2$ is an\ninteger. The generalized free theories refer to the $\\Box^k$ free scalar\ntheories with a higher-derivative kinetic term, which is related to the\nmulticritical generalizations of the Lifshitz type. We assume that the\n(generalized) free theories and the deformed theories have boundary conformal\nsymmetry and O($N$) global symmetry. The leading anomalous dimensions of some\nboundary operators are derived from the bulk multiplet recombination and\nanalyticity constraints. We find that the $\\epsilon^{1/2}$ expansion in the\n$\\phi^6$-tricritical version of the special transition extends to other\nmulticritical cases with larger odd integer $n$, and most of the higher\nderivative cases involve a noninteger power expansion in $\\epsilon$. Using the\nanalytic bootstrap, we further verify that the multiplet-recombination results\nare consistent with boundary crossing symmetry.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech","published":"2025-04-23T16:08:28Z"}
{"aid":"http://arxiv.org/abs/2504.16848v1","title":"Improving QoS Prediction in Urban V2X Networks by Leveraging Data from\n  Leading Vehicles and Historical Trends","summary":"With the evolution of Vehicle-to-Everything (V2X) technology and increased\ndeployment of 5G networks and edge computing, Predictive Quality of Service\n(PQoS) is seen as an enabler for resilient and adaptive V2X communication\nsystems. PQoS incorporates data-driven techniques, such as Machine Learning\n(ML), to forecast/predict Key Performing Indicators (KPIs) such as throughput,\nlatency, etc. In this paper, we aim to predict downlink throughput in an urban\nenvironment using the Berlin V2X cellular dataset. We select features from the\nego and lead vehicles to train different ML models to help improve the\npredicted throughput for the ego vehicle. We identify these features based on\nan in-depth exploratory data analysis. Results show an improvement in model\nperformance when adding features from the lead vehicle. Moreover, we show that\nthe improvement in model performance is model-agnostic.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-23T16:10:31Z"}
{"aid":"http://arxiv.org/abs/2504.16851v1","title":"Hyperspectral Vision Transformers for Greenhouse Gas Estimations from\n  Space","summary":"Hyperspectral imaging provides detailed spectral information and holds\nsignificant potential for monitoring of greenhouse gases (GHGs). However, its\napplication is constrained by limited spatial coverage and infrequent revisit\ntimes. In contrast, multispectral imaging offers broader spatial and temporal\ncoverage but often lacks the spectral detail that can enhance GHG detection. To\naddress these challenges, this study proposes a spectral transformer model that\nsynthesizes hyperspectral data from multispectral inputs. The model is\npre-trained via a band-wise masked autoencoder and subsequently fine-tuned on\nspatio-temporally aligned multispectral-hyperspectral image pairs. The\nresulting synthetic hyperspectral data retain the spatial and temporal benefits\nof multispectral imagery and improve GHG prediction accuracy relative to using\nmultispectral data alone. This approach effectively bridges the trade-off\nbetween spectral resolution and coverage, highlighting its potential to advance\natmospheric monitoring by combining the strengths of hyperspectral and\nmultispectral systems with self-supervised deep learning.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T16:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.16857v1","title":"Physical ageing from generalised time-translation-invariance","summary":"A generalised form of time-translation-invariance permits to re-derive the\nknown generic phenomenology of ageing, which arises in many-body systems after\na quench from an initially disordered system to a temperature $T\\leq T_c$, at\nor below the critical temperature $T_c$. Generalised\ntime-translation-invariance is obtained, out of equilibrium, from a change of\nrepresentation of the Lie algebra generators of the dynamical symmetries of\nscale-invariance and time-translation-invariance. Observable consequences\ninclude the algebraic form of the scaling functions for large arguments of the\ntwo-time auto-correlators and auto-responses, the equality of the\nauto-correlation and the auto-response exponents $\\lambda_C=\\lambda_R$, the\ncross-over scaling form for an initially magnetised critical system and the\nexplanation of a novel finite-size scaling if the auto-correlator or\nauto-response converge for large arguments $y=t/s\\gg 1$ to a plateau. For\nglobal two-time correlators, the time-dependence involving the initial critical\nslip exponent $\\Theta$ is confirmed and is generalised to all temperatures\nbelow criticality and to the global two-time response function, and their\nfinite-size scaling is derived as well. This also includes the time-dependence\nof the squared global order-parameter. The celebrate Janssen-Schaub-Schmittmann\nscaling relation with the auto-correlation exponent is thereby extended to all\ntemperatures below the critical temperature. A simple criterion on the\nrelevance of non-linear terms in the stochastic equation of motion is derived,\ntaking the dimensionality of couplings into account. Its applicability in a\nwide class of models is confirmed, for temperatures $T\\leq T_c$. Relevance to\nexperiments is also discussed.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,hep-th,math-ph,math.MP","published":"2025-04-23T16:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.16864v1","title":"Common Functional Decompositions Can Mis-attribute Differences in\n  Outcomes Between Populations","summary":"In science and social science, we often wish to explain why an outcome is\ndifferent in two populations. For instance, if a jobs program benefits members\nof one city more than another, is that due to differences in program\nparticipants (particular covariates) or the local labor markets (outcomes given\ncovariates)? The Kitagawa-Oaxaca-Blinder (KOB) decomposition is a standard tool\nin econometrics that explains the difference in the mean outcome across two\npopulations. However, the KOB decomposition assumes a linear relationship\nbetween covariates and outcomes, while the true relationship may be\nmeaningfully nonlinear. Modern machine learning boasts a variety of nonlinear\nfunctional decompositions for the relationship between outcomes and covariates\nin one population. It seems natural to extend the KOB decomposition using these\nfunctional decompositions. We observe that a successful extension should not\nattribute the differences to covariates -- or, respectively, to outcomes given\ncovariates -- if those are the same in the two populations. Unfortunately, we\ndemonstrate that, even in simple examples, two common decompositions --\nfunctional ANOVA and Accumulated Local Effects -- can attribute differences to\noutcomes given covariates, even when they are identical in two populations. We\nprovide a characterization of when functional ANOVA misattributes, as well as a\ngeneral property that any discrete decomposition must satisfy to avoid\nmisattribution. We show that if the decomposition is independent of its input\ndistribution, it does not misattribute. We further conjecture that\nmisattribution arises in any reasonable additive decomposition that depends on\nthe distribution of the covariates.","main_category":"stat.ME","categories":"stat.ME,cs.LG,econ.EM,stat.ML","published":"2025-04-23T16:36:55Z"}
{"aid":"http://arxiv.org/abs/2504.16879v1","title":"Learning Verifiable Control Policies Using Relaxed Verification","summary":"To provide safety guarantees for learning-based control systems, recent work\nhas developed formal verification methods to apply after training ends.\nHowever, if the trained policy does not meet the specifications, or there is\nconservatism in the verification algorithm, establishing these guarantees may\nnot be possible. Instead, this work proposes to perform verification throughout\ntraining to ultimately aim for policies whose properties can be evaluated\nthroughout runtime with lightweight, relaxed verification algorithms. The\napproach is to use differentiable reachability analysis and incorporate new\ncomponents into the loss function. Numerical experiments on a quadrotor model\nand unicycle model highlight the ability of this approach to lead to learned\ncontrol policies that satisfy desired reach-avoid and invariance\nspecifications.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-23T16:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.16886v1","title":"Exploring zero-shot structure-based protein fitness prediction","summary":"The ability to make zero-shot predictions about the fitness consequences of\nprotein sequence changes with pre-trained machine learning models enables many\npractical applications. Such models can be applied for downstream tasks like\ngenetic variant interpretation and protein engineering without additional\nlabeled data. The advent of capable protein structure prediction tools has led\nto the availability of orders of magnitude more precomputed predicted\nstructures, giving rise to powerful structure-based fitness prediction models.\nThrough our experiments, we assess several modeling choices for structure-based\nmodels and their effects on downstream fitness prediction. Zero-shot fitness\nprediction models can struggle to assess the fitness landscape within\ndisordered regions of proteins, those that lack a fixed 3D structure. We\nconfirm the importance of matching protein structures to fitness assays and\nfind that predicted structures for disordered regions can be misleading and\naffect predictive performance. Lastly, we evaluate an additional\nstructure-based model on the ProteinGym substitution benchmark and show that\nsimple multi-modal ensembles are strong baselines.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.LG,q-bio.BM","published":"2025-04-23T17:01:09Z"}
{"aid":"http://arxiv.org/abs/2504.16888v1","title":"A first encounter with exceptional points in a quantum model","summary":"An exceptional point is a special point in parameter space at which two (or\nmore) eigenvalues and eigenvectors coincide. The discovery of exceptional\npoints within mechanical and optical systems has uncovered peculiar effects in\ntheir vicinity. Here we consider perhaps the simplest quantum model which\nexhibits an exceptional point and which allows for an analytical treatment. In\nparticular, we re-examine a two-level atom driven by a laser and suffering from\nlosses. The same exceptional point arises in several non-Hermitian matrices\nwhich determine various aspects of the dynamics of the system. There are\nconsequences for some important observables, for example the spectrum evolves\nfrom being a Lorentzian-like singlet to a Mollow triplet upon passing through\nthe exceptional point. Our analysis supports the perspective that viewing\ncertain quantum systems through the lens of exceptional points offers some\ndesirable explanatory advantages.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T17:07:17Z"}
{"aid":"http://arxiv.org/abs/2504.16889v1","title":"Characterization of a GAGG detector for neutron measurements in\n  underground laboratories","summary":"In rare events experiments, such as those devoted to the direct search of\ndark matter, a precise knowledge of the environmental gamma and neutron\nbackgrounds is crucial for reaching the design experiment sensitivity. The\nneutron component is often poorly known due to the lack of a scalable detector\ntechnology for the precise measurement of low-flux neutron spectra.\nGd$_3$Al$_2$Ga$_3$O$_{12}$ (GAGG) is a newly developed, high-density\nscintillating crystal with a high gadolinium content, which could allow to\nexploit the high $(n,\\gamma)$ cross section of $^{155}$Gd and $^{157}$Gd for\nneutron measurements in underground environments. GAGG crystals feature a high\nscintillation light yield, good timing performance, and the capability of\nparticle identification via pulse-shape discrimination. In a low-background\nenvironment, the distinctive signature produced by neutron capture on\ngadolinium, namely a $\\beta/\\gamma$ cascade releasing up to 9 MeV of total\nenergy, and the efficient particle identification provided by GAGG could yield\na background-free neutron capture signal. In this work, we present the\ncharacterization of a first GAGG detector prototype in terms of particle\ndiscrimination performance, intrinsic radioactive contamination, and neutron\nresponse.","main_category":"physics.ins-det","categories":"physics.ins-det,nucl-ex","published":"2025-04-23T17:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.16890v1","title":"Computing Optimal Transport Plans via Min-Max Gradient Flows","summary":"We pose the Kantorovich optimal transport problem as a min-max problem with a\nNash equilibrium that can be obtained dynamically via a two-player game,\nproviding a framework for approximating optimal couplings. We prove convergence\nof the timescale-separated gradient descent dynamics to the optimal transport\nplan, and implement the gradient descent algorithm with a particle method,\nwhere the marginal constraints are enforced weakly using the KL divergence,\nautomatically selecting a dynamical adaptation of the regularizer. The\nnumerical results highlight the different advantages of using the standard\nKullback-Leibler (KL) divergence versus the reverse KL divergence with this\napproach, opening the door for new methodologies.","main_category":"math.OC","categories":"math.OC,math.AP","published":"2025-04-23T17:11:34Z"}
{"aid":"http://arxiv.org/abs/2504.16902v1","title":"Building A Secure Agentic AI Application Leveraging A2A Protocol","summary":"As Agentic AI systems evolve from basic workflows to complex multi agent\ncollaboration, robust protocols such as Google's Agent2Agent (A2A) become\nessential enablers. To foster secure adoption and ensure the reliability of\nthese complex interactions, understanding the secure implementation of A2A is\nessential. This paper addresses this goal by providing a comprehensive security\nanalysis centered on the A2A protocol. We examine its fundamental elements and\noperational dynamics, situating it within the framework of agent communication\ndevelopment. Utilizing the MAESTRO framework, specifically designed for AI\nrisks, we apply proactive threat modeling to assess potential security issues\nin A2A deployments, focusing on aspects such as Agent Card management, task\nexecution integrity, and authentication methodologies.\n  Based on these insights, we recommend practical secure development\nmethodologies and architectural best practices designed to build resilient and\neffective A2A systems. Our analysis also explores how the synergy between A2A\nand the Model Context Protocol (MCP) can further enhance secure\ninteroperability. This paper equips developers and architects with the\nknowledge and practical guidance needed to confidently leverage the A2A\nprotocol for building robust and secure next generation agentic applications.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-23T17:27:49Z"}
{"aid":"http://arxiv.org/abs/2504.16905v1","title":"The Galactic inner spiral arms revealed by the Gaia ESO Survey chemical\n  abundances. Metallicity and [Mg/Fe] ratios","summary":"Recent observational advances, such as Gaia DR3 GSP-Spec, have highlighted\nthe potential of chemical abundances in tracing and revealing the structure of\nspiral arms. Building on these studies, we aim to trace the Milky Way's inner\nspiral arms using chemical abundance data from the Gaia-ESO Survey (GES). By\nmapping over-densities in [Fe/H] and [Mg/Fe], we seek to identify spiral arms\nin both radial and vertical planes, detect substructures, and compare our\nresults with recent Galactic chemical evolution models. We used chemical\nabundance data from the Gaia-ESO Survey to create spatial maps of [Fe/H],\n[Mg/H], and [Mg/Fe] excess across the Galactic inner disc. We compared our\nresults with the spiral arm models proposed by Spitoni et al. (2023) and\nBarbillon et al. (2024). For the first time, the inner spiral arms were\nrevealed using chemical abundance patterns. We detected [Fe/H] enhancements and\n[Mg/Fe] under-abundances that consistently trace the Scutum and Sagittarius\narms. A connecting spur between these arms is observed in the [Mg/H] plane. The\nalignment between our observations and the results of our 2D chemical evolution\nmodels reinforces the significance of spiral arm transits in driving both\nazimuthal and radial variations in chemical abundances. Our results confirm\nthat spiral arms can be traced using stellar chemical abundances with GES data,\nproviding a new perspective on the structure of the inner Galaxy. The\nconsistency between enhanced [Fe/H] and lower [Mg/Fe] ratios, as observed in\nprevious studies, further strengthens the reliability of our findings. The\nobserved spur, bifurcation, and vertical substructures align well with recent\nmodels and studies, indicating that chemical maps can significantly contribute\nto our understanding of Galactic spiral arms.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-23T17:28:37Z"}
{"aid":"http://arxiv.org/abs/2504.16912v1","title":"Definition, Identification, and Estimation of the Direct and Indirect\n  Number Needed to Treat","summary":"The number needed to treat (NNT) is an efficacy and effect size measure\ncommonly used in epidemiological studies and meta-analyses. The NNT was\noriginally defined as the average number of patients needed to be treated to\nobserve one less adverse effect. In this study, we introduce the novel direct\nand indirect number needed to treat (DNNT and INNT, respectively). The DNNT and\nthe INNT are efficacy measures defined as the average number of patients that\nneeded to be treated to benefit from the treatment's direct and indirect\neffects, respectively. We start by formally defining these measures using\nnested potential outcomes. Next, we formulate the conditions for the\nidentification of the DNNT and INNT, as well as for the direct and indirect\nnumber needed to expose (DNNE and INNE, respectively) and the direct and\nindirect exposure impact number (DEIN and IEIN, respectively) in observational\nstudies. Next, we present an estimation method with two analytical examples. A\ncorresponding simulation study follows the examples. The simulation study\nillustrates that the estimators of the novel indices are consistent, and their\nanalytical confidence intervals meet the nominal coverage rates.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-23T17:39:47Z"}
{"aid":"http://arxiv.org/abs/2504.16921v1","title":"IberBench: LLM Evaluation on Iberian Languages","summary":"Large Language Models (LLMs) remain difficult to evaluate comprehensively,\nparticularly for languages other than English, where high-quality data is often\nlimited. Existing benchmarks and leaderboards are predominantly\nEnglish-centric, with only a few addressing other languages. These benchmarks\nfall short in several key areas: they overlook the diversity of language\nvarieties, prioritize fundamental Natural Language Processing (NLP)\ncapabilities over tasks of industrial relevance, and are static. With these\naspects in mind, we present IberBench, a comprehensive and extensible benchmark\ndesigned to assess LLM performance on both fundamental and industry-relevant\nNLP tasks, in languages spoken across the Iberian Peninsula and Ibero-America.\nIberBench integrates 101 datasets from evaluation campaigns and recent\nbenchmarks, covering 22 task categories such as sentiment and emotion analysis,\ntoxicity detection, and summarization. The benchmark addresses key limitations\nin current evaluation practices, such as the lack of linguistic diversity and\nstatic evaluation setups by enabling continual updates and community-driven\nmodel and dataset submissions moderated by a committee of experts. We evaluate\n23 LLMs ranging from 100 million to 14 billion parameters and provide empirical\ninsights into their strengths and limitations. Our findings indicate that (i)\nLLMs perform worse on industry-relevant tasks than in fundamental ones, (ii)\nperformance is on average lower for Galician and Basque, (iii) some tasks show\nresults close to random, and (iv) in other tasks LLMs perform above random but\nbelow shared task systems. IberBench offers open-source implementations for the\nentire evaluation pipeline, including dataset normalization and hosting,\nincremental evaluation of LLMs, and a publicly accessible leaderboard.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T17:48:25Z"}
{"aid":"http://arxiv.org/abs/2504.16930v1","title":"Procedural Dataset Generation for Zero-Shot Stereo Matching","summary":"Synthetic datasets are a crucial ingredient for training stereo matching\nnetworks, but the question of what makes a stereo dataset effective remains\nlargely unexplored. We investigate the design space of synthetic datasets by\nvarying the parameters of a procedural dataset generator, and report the\neffects on zero-shot stereo matching performance using standard benchmarks. We\ncollect the best settings to produce Infinigen-Stereo, a procedural generator\nspecifically optimized for zero-shot stereo datasets. Models trained only on\ndata from our system outperform robust baselines trained on a combination of\nexisting synthetic datasets and have stronger zero-shot stereo matching\nperformance than public checkpoints from prior works. We open source our system\nat https://github.com/princeton-vl/InfinigenStereo to enable further research\non procedural stereo datasets.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T17:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.17591v1","title":"Evidence for neutron-induced $\\boldsymbolγ$-ray emissions in the\n  vicinity of the $\\boldsymbol{Q}$ value of $^{76}\\text{Ge}$ $0νββ$\n  decay","summary":"Neutrinoless double-beta decay of nuclei represents one of the most promising\nmethods for uncovering physics beyond the Standard Model. In this context,\n$^{76}$Ge stands out as a particularly attractive candidate, as it can serve as\nan intrinsic component in semiconductor detectors. If the neutrinoless process\noccurs in $^{76}$Ge, its signature would appear as a distinct peak at the $Q$\nvalue of 2039 keV. A neutron activation measurement was performed on a\ngermanium sample isotopically enriched in $^{76}$Ge at the DT neutron generator\nof TU Dresden. The measurement confirmed the presence of $\\gamma$ rays with\nenergies of 2033.1$\\pm$0.5 keV, 2035.5$\\pm$0.4 keV, and 2040.22$\\pm$0.26 keV\noriginating from the decays of $^{74}$Ga and $^{76}$Ga. These $\\gamma$ rays lie\nin close proximity to the expected neutrinoless double-beta decay signal of\n$^{76}$Ge.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-24T14:21:46Z"}
{"aid":"http://arxiv.org/abs/2504.17592v1","title":"Well-posed Questions for Ill-posed Inverse Problems: a Note in Memory of\n  Pierre Sabatier","summary":"Professor Pierre Sabatier contributed much to the study of inverse problems\nin theory and practice. Two of these contributions were a focus on theory that\nactually supports practice, and the identification of well-posed aspects of\ninverse problems that may quite ill-posed. This paper illustrates these two\nthemes in the context of Electrical Impedance Tomography (EIT), which is both\nvery ill-posed and very practical. We show that for a highly constrained\nversion of this inverse problem, in which a small elliptical inclusion in a\nhomogeneous background is to be identified, optimization of the experimental\ndesign (that is, electrode locations) vastly improves the stability of the\nsolution.","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T14:21:53Z"}
{"aid":"http://arxiv.org/abs/2504.17595v1","title":"RGB-D Tracking via Hierarchical Modality Aggregation and Distribution\n  Network","summary":"The integration of dual-modal features has been pivotal in advancing\nRGB-Depth (RGB-D) tracking. However, current trackers are less efficient and\nfocus solely on single-level features, resulting in weaker robustness in fusion\nand slower speeds that fail to meet the demands of real-world applications. In\nthis paper, we introduce a novel network, denoted as HMAD (Hierarchical\nModality Aggregation and Distribution), which addresses these challenges. HMAD\nleverages the distinct feature representation strengths of RGB and depth\nmodalities, giving prominence to a hierarchical approach for feature\ndistribution and fusion, thereby enhancing the robustness of RGB-D tracking.\nExperimental results on various RGB-D datasets demonstrate that HMAD achieves\nstate-of-the-art performance. Moreover, real-world experiments further validate\nHMAD's capacity to effectively handle a spectrum of tracking challenges in\nreal-time scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T14:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.17600v1","title":"Model Choice Matters for Age Inference on the Red Giant Branch","summary":"Galactic archaeology relies on accurate stellar parameters to reconstruct the\ngalaxy's history, including information on stellar ages. While the precision of\ndata has improved significantly in recent years, stellar models used for age\ninference have not improved at a similar rate. In fact, different models yield\nnotably different age predictions for the same observational data. In this\npaper, we assess the difference in age predictions of various widely used model\ngrids for stars along the red giant branch. Using open source software, we\nconduct a comparison of four different evolution grids and we find that age\nestimations become less reliable if stellar mass is not known, with differences\noccasionally exceeding $80\\%$. Additionally, we note significant disagreements\nin the models' age estimations at non-solar metallicity. Finally, we present a\nmethod for including theoretical uncertainties from stellar evolutionary tracks\nin age inferences of red giants, aimed at improving the accuracy of age\nestimation techniques used in the galactic archaeology community.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.IM","published":"2025-04-24T14:26:17Z"}
{"aid":"http://arxiv.org/abs/2504.17602v1","title":"Scalar-Induced Gravitational Waves from self-resonant preheating in\n  $α$-attractor models","summary":"After the inflationary phase, the universe enters the preheating phase,\nduring which the inflaton field rolls down its potential and oscillates. When\nthe potential significantly deviates from a parabolic shape at its minimum,\nthese oscillations trigger an instability in the scalar perturbations, leading\nto their amplification. This phenomenon, known as self-resonance, has important\nimplications in cosmology. Notably, since scalar perturbations couple to tensor\nperturbations at second order in the equations of motion, this amplification\nresults in the production of Gravitational Waves (GWs), referred to as\nScalar-Induced Gravitational Waves (SIGWs). In this study, we investigate the\nproduction of SIGWs during the preheating phase for a class of inflationary\nmodels known as $\\alpha$-attractors, characterized by a single parameter\n$\\alpha$. We focus on small values of this parameter, specifically $\\alpha \\sim\nO(10^{-1} - 10^{-4})$, where the self-resonance effect is particularly\npronounced. We obtain lower bounds on this parameter, $\\log_{10}(\\alpha)>-3.54$\nfor the T-model and $\\log_{10}(\\alpha)>-3.17$ for the E-model, based on the\nenergy density of SIGWs constrained by Big Bang nucleosynthesis, which\nultimately translates into lower bounds on the tensor-to-scalar ratio,\n$r>9.61\\times10^{-7}$ for the T-model and $r>2.25\\times10^{-6}$ for the\nE-model.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-24T14:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.17604v1","title":"Measurement of the Parity-Violating Asymmetry in the N to $Δ$\n  Transition at Low $Q^2$","summary":"We report the measurement of the parity-violating asymmetry in the N to\n$\\Delta$ transition via the $e^- + p \\rightarrow e^- + \\Delta ^+$ reaction at\ntwo different kinematic points with low four-momentum transfer Q$^2$.\nMeasurements were made with incident electron beam energies of 0.877 and 1.16\nGeV, corresponding to $Q^2$ values of 0.0111 and 0.0208 (GeV/c)$^2$,\nrespectively. These measurements put constraints on a low-energy constant in\nthe weak Lagrangian, $d_\\Delta$, corresponding to a parity-violating\nelectric-dipole transition matrix element. This matrix element has been shown\nto be large in the strangeness-changing channel, via weak hyperon decays such\nas $\\Sigma ^+ \\rightarrow p\\gamma$. The measurements reported here constrain\n$d_\\Delta$ in the strangeness-conserving channel. The final asymmetries were\n-0.65 +- 1.00 (stat.) +- 1.02 (syst) ppm (parts per million) for 0.877 GeV and\n-3.59 +- 0.82 (stat.) +- 1.33 (syst.} ppm for 1.16 GeV. With these results we\ndeduce a small value for $d_\\Delta$, consistent with zero, in the\nstrangeness-conserving channel, in contrast to the large value for $d_\\Delta$\npreviously reported in the strangeness-changing channel.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-24T14:29:08Z"}
{"aid":"http://arxiv.org/abs/2504.17610v1","title":"Modeling Communication Perception in Development Teams Using Monte Carlo\n  Methods","summary":"Software development is a collaborative task involving diverse development\nteams, where toxic communication can negatively impact team mood and project\nsuccess. Mood surveys enable the early detection of underlying tensions or\ndissatisfaction within development teams, allowing communication issues to be\naddressed before they escalate, fostering a positive and productive work\nenvironment. The mood can be surveyed indirectly by analyzing the text-based\ncommunication of the team. However, emotional subjectivity leads to varying\nsentiment interpretations across team members; a statement perceived neutrally\nby one developer might be seen as problematic by another developer with a\ndifferent conversational culture. Early identification of perception volatility\ncan help prevent misunderstandings and enhance team morale while safeguarding\nthe project. This paper analyzes the diversity of perceptions within arbitrary\ndevelopment teams and determines how many team members should report their\nsentiment to accurately reflect the team's mood. Through a Monte Carlo\nexperiment involving 45 developers, we present a preliminary mathematical model\nto calculate the minimum agreement among a subset of developers based on the\nwhole team's agreement. This model can guide leadership in mood assessment,\ndemonstrating that omitting even a single member in an average-sized 7-member\nteam can misrepresent the overall mood. Therefore, including all developers in\nmood surveying is recommended to ensure a reliable evaluation of the team's\nmood.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-24T14:35:18Z"}
{"aid":"http://arxiv.org/abs/2504.17627v1","title":"Fragmentation, Zero Modes, and Collective Bound States in Constrained\n  Models","summary":"Kinetically constrained models were originally introduced to capture slow\nrelaxation in glassy systems, where dynamics are hindered by local constraints\ninstead of energy barriers. Their quantum counterparts have recently drawn\nattention for exhibiting highly degenerate eigenstates at zero energy -- known\nas zero modes -- stemming from chiral symmetry. Yet, the structure and\nimplications of these zero modes remain poorly understood. In this work, we\nfocus on the properties of the zero mode subspace in quantum kinetically\nconstrained models with a $U(1)$ particle-conservation symmetry. We use the\n$U(1)$ East, which lacks inversion symmetry, and the inversion-symmetric $U(1)$\nEast-West models to illustrate our two main results. First, we observe that the\nsimultaneous presence of constraints and chiral symmetry generally leads to a\nparametric increase in the number of zero modes due to the fragmentation of the\nmany-body Hilbert space into disconnected sectors. Second, we generalize the\nconcept of compact localized states from single particle physics and introduce\nthe notion of collective bound states. We formulate sufficient criteria for\ntheir existence, arguing that the degenerate zero mode subspace plays a central\nrole, and demonstrate bound states in both example models. Our results motivate\na systematic study of bound states and their relation to ergodicity breaking,\ntransport, and other properties of quantum kinetically constrained models.","main_category":"quant-ph","categories":"quant-ph,cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-24T14:49:16Z"}
{"aid":"http://arxiv.org/abs/2504.17660v1","title":"Effortless, Simulation-Efficient Bayesian Inference using Tabular\n  Foundation Models","summary":"Simulation-based inference (SBI) offers a flexible and general approach to\nperforming Bayesian inference: In SBI, a neural network is trained on synthetic\ndata simulated from a model and used to rapidly infer posterior distributions\nfor observed data. A key goal for SBI is to achieve accurate inference with as\nfew simulations as possible, especially for expensive simulators. In this work,\nwe address this challenge by repurposing recent probabilistic foundation models\nfor tabular data: We show how tabular foundation models -- specifically TabPFN\n-- can be used as pre-trained autoregressive conditional density estimators for\nSBI. We propose Neural Posterior Estimation with Prior-data Fitted Networks\n(NPE-PF) and show that it is competitive with current SBI approaches in terms\nof accuracy for both benchmark tasks and two complex scientific inverse\nproblems. Crucially, it often substantially outperforms them in terms of\nsimulation efficiency, sometimes requiring orders of magnitude fewer\nsimulations. NPE-PF eliminates the need for inference network selection,\ntraining, and hyperparameter tuning. We also show that it exhibits superior\nrobustness to model misspecification and can be scaled to simulation budgets\nthat exceed the context size limit of TabPFN. NPE-PF provides a new direction\nfor SBI, where training-free, general-purpose inference models offer efficient,\neasy-to-use, and flexible solutions for a wide range of stochastic inverse\nproblems.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T15:29:39Z"}
{"aid":"http://arxiv.org/abs/2504.17669v1","title":"Towards a HIPAA Compliant Agentic AI System in Healthcare","summary":"Agentic AI systems powered by Large Language Models (LLMs) as their\nfoundational reasoning engine, are transforming clinical workflows such as\nmedical report generation and clinical summarization by autonomously analyzing\nsensitive healthcare data and executing decisions with minimal human oversight.\nHowever, their adoption demands strict compliance with regulatory frameworks\nsuch as Health Insurance Portability and Accountability Act (HIPAA),\nparticularly when handling Protected Health Information (PHI). This\nwork-in-progress paper introduces a HIPAA-compliant Agentic AI framework that\nenforces regulatory compliance through dynamic, context-aware policy\nenforcement. Our framework integrates three core mechanisms: (1)\nAttribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid\nPHI sanitization pipeline combining regex patterns and BERT-based model to\nminimize leakage, and (3) immutable audit trails for compliance verification.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.ET","published":"2025-04-24T15:38:20Z"}
{"aid":"http://arxiv.org/abs/2504.17671v1","title":"Data-Driven Calibration of Prediction Sets in Large Vision-Language\n  Models Based on Inductive Conformal Prediction","summary":"This study addresses the critical challenge of hallucination mitigation in\nLarge Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks\nthrough a Split Conformal Prediction (SCP) framework. While LVLMs excel in\nmulti-modal reasoning, their outputs often exhibit hallucinated content with\nhigh confidence, posing risks in safety-critical applications. We propose a\nmodel-agnostic uncertainty quantification method that integrates dynamic\nthreshold calibration and cross-modal consistency verification. By partitioning\ndata into calibration and test sets, the framework computes nonconformity\nscores to construct prediction sets with statistical guarantees under\nuser-defined risk levels ($\\alpha$). Key innovations include: (1) rigorous\ncontrol of \\textbf{marginal coverage} to ensure empirical error rates remain\nstrictly below $\\alpha$; (2) dynamic adjustment of prediction set sizes\ninversely with $\\alpha$, filtering low-confidence outputs; (3) elimination of\nprior distribution assumptions and retraining requirements. Evaluations on\nbenchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces\ntheoretical guarantees across all $\\alpha$ values. The framework achieves\nstable performance across varying calibration-to-test split ratios,\nunderscoring its robustness for real-world deployment in healthcare, autonomous\nsystems, and other safety-sensitive domains. This work bridges the gap between\ntheoretical reliability and practical applicability in multi-modal AI systems,\noffering a scalable solution for hallucination detection and uncertainty-aware\ndecision-making.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-24T15:39:46Z"}
{"aid":"http://arxiv.org/abs/2504.17672v1","title":"Cross-region Model Training with Communication-Computation Overlapping\n  and Delay Compensation","summary":"Training large language models (LLMs) requires massive computational\nresources, often necessitating the aggregation of geographically distributed\ndata centers (\\ie, cross-region training). However, the high communication\nlatency in wide-area networks severely degrades the efficiency of traditional\ndistributed training. While methods like DiLoCo reduce communication frequency,\nthey suffer from blocking synchronization. Streaming DiLoCo alleviates this\nissue via communication-computation overlapping but introduces update staleness\nand model inconsistency due to delayed global updates and partial\nsynchronization. These factors impair convergence, especially when aggressive\noverlap is needed to mask high latency. We propose CoCoDC, a novel distributed\ntraining framework with communication-computation overlapping and delay\ncompensation, to explicitly tackle these challenges. Within the CoCoDC\nframework, we specifically develop a novel Delay Compensation strategy based on\nTaylor expansion to effectively mitigate the staleness and an Adaptive\nTransmission strategy that dynamically schedules model fragment synchronization\nto optimize bandwidth usage and accelerate convergence. Extensive experiments\nhighlight the superior performance of CoCoDC over both DiLoCo and Streaming\nDiLoCo regarding final accuracy and training speed. Specifically, CoCoDC\nreduces the training steps needed to reach a comparable perplexity by up to\n21.0% compared to Streaming DiLoCo. Our work provides an effective solution for\nscalable and efficient cross-region LLM training.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-24T15:40:17Z"}
{"aid":"http://arxiv.org/abs/2504.17675v1","title":"Optimized Cloud Resource Allocation Using Genetic Algorithms for Energy\n  Efficiency and QoS Assurance","summary":"Cloud computing environments demand dynamic and efficient resource management\nto ensure optimal performance, reduced energy consumption, and adherence to\nService Level Agreements (SLAs). This paper presents a Genetic Algorithm\n(GA)-based approach for Virtual Machine (VM) placement and consolidation,\naiming to minimize power usage while maintaining QoS constraints. The proposed\nmethod dynamically adjusts VM allocation based on real-time workload\nvariations, outperforming traditional heuristics such as First Fit Decreasing\n(FFD) and Best Fit Decreasing (BFD). Experimental results show notable\nreductions in energy consumption, VM migrations, SLA violation rates, and\nexecution time. A correlation heatmap further illustrates strong relationships\namong these key performance indicators, confirming the effectiveness of our\napproach in optimizing cloud resource utilization.","main_category":"cs.DC","categories":"cs.DC,cs.AI","published":"2025-04-24T15:45:40Z"}
{"aid":"http://arxiv.org/abs/2504.17678v1","title":"MindFlow: A Network Traffic Anomaly Detection Model Based on MindSpore","summary":"With the wide application of IoT and industrial IoT technologies, the network\nstructure is becoming more and more complex, and the traffic scale is growing\nrapidly, which makes the traditional security protection mechanism face serious\nchallenges in dealing with high-frequency, diversified, and stealthy\ncyber-attacks. To address this problem, this study proposes MindFlow, a\nmulti-dimensional dynamic traffic prediction and anomaly detection system\ncombining convolutional neural network (CNN) and bi-directional long and\nshort-term memory network (BiLSTM) architectures based on the MindSpore\nframework, and conducts systematic experiments on the NF-BoT-IoT dataset. The\nexperimental results show that the proposed model achieves 99% in key metrics\nsuch as accuracy, precision, recall and F1 score, effectively verifying its\naccuracy and robustness in network intrusion detection.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-24T15:48:02Z"}
{"aid":"http://arxiv.org/abs/2504.17682v1","title":"Nonlinear Derivative-free Constrained Optimization with a\n  Penalty-Interior Point Method and Direct Search","summary":"In this work, we propose the joint use of a mixed penalty-interior point\nmethod and direct search, for addressing nonlinearly constrained\nderivative-free optimization problems. A merit function is considered, wherein\nthe set of nonlinear inequality constraints is divided into two groups: one\ntreated with a logarithmic barrier approach, and another, along with the\nequality constraints, addressed using a penalization term. This strategy, is\nadapted and incorporated into a direct search method, enabling the effective\nhandling of general nonlinear constraints. Convergence to KKT-stationary points\nis established under continuous differentiability assumptions, without\nrequiring any kind of convexity. Using CUTEst test problems, numerical\nexperiments demonstrate the robustness, efficiency, and overall effectiveness\nof the proposed method, when compared with state-of-the-art solvers","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T15:54:01Z"}
{"aid":"http://arxiv.org/abs/2504.17690v1","title":"On the Generalization of Adversarially Trained Quantum Classifiers","summary":"Quantum classifiers are vulnerable to adversarial attacks that manipulate\ntheir input classical or quantum data. A promising countermeasure is\nadversarial training, where quantum classifiers are trained by using an\nattack-aware, adversarial loss function. This work establishes novel bounds on\nthe generalization error of adversarially trained quantum classifiers when\ntested in the presence of perturbation-constrained adversaries. The bounds\nquantify the excess generalization error incurred to ensure robustness to\nadversarial attacks as scaling with the training sample size $m$ as\n$1/\\sqrt{m}$, while yielding insights into the impact of the quantum embedding.\nFor quantum binary classifiers employing \\textit{rotation embedding}, we find\nthat, in the presence of adversarial attacks on classical inputs $\\mathbf{x}$,\nthe increase in sample complexity due to adversarial training over conventional\ntraining vanishes in the limit of high dimensional inputs $\\mathbf{x}$. In\ncontrast, when the adversary can directly attack the quantum state\n$\\rho(\\mathbf{x})$ encoding the input $\\mathbf{x}$, the excess generalization\nerror depends on the choice of embedding only through its Hilbert space\ndimension. The results are also extended to multi-class classifiers. We\nvalidate our theoretical findings with numerical experiments.","main_category":"quant-ph","categories":"quant-ph,cs.LG","published":"2025-04-24T15:59:55Z"}
{"aid":"http://arxiv.org/abs/2504.17691v1","title":"Predictability of north Pacific blocking events : Analogue based\n  analysis of historical MIROC6 simulations","summary":"Atmospheric blocking exerts a profound influence on mid-latitude circulation,\nyet its predictability remains elusive due to intrinsic non-linearities and\nsensitivity to initial-conditions. While blocking dynamics have been\nextensively studied, the impact of geographical positioning on predictability\nremains largely unexplored. This study provides a comparative assessment of the\npredictability of Western and Eastern North Pacific blocking events, leveraging\nanalogue-based diagnostics applied to CMIP6 MIROC6 simulations. Blocking\nstructures are identified using geopotential height gradient reversal, with\ntheir temporal evolution analysed through trajectory tracking and error growth\nmetrics. Results reveal that Eastern blocks exhibit lower predictability,\ncharacterized by rapid error divergence and heightened mean logarithmic growth\nrates, whereas Western blocks display dynamical stability. Persistence analysis\ngives no significant difference between eastern and western North Pacific\nblocking events. Sensitivity analyses across varying detection thresholds\nvalidate the robustness of these findings.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-24T16:00:26Z"}
{"aid":"http://arxiv.org/abs/2504.17692v1","title":"User Profiles: The Achilles' Heel of Web Browsers","summary":"Web browsers provide the security foundation for our online experiences.\nSignificant research has been done into the security of browsers themselves,\nbut relatively little investigation has been done into how they interact with\nthe operating system or the file system. In this work, we provide the first\nsystematic security study of browser profiles, the on-disk persistence layer of\nbrowsers, used for storing everything from users' authentication cookies and\nbrowser extensions to certificate trust decisions and device permissions. We\nshow that, except for the Tor Browser, all modern browsers store sensitive data\nin home directories with little to no integrity or confidentiality controls. We\nshow that security measures like password and cookie encryption can be easily\nbypassed. In addition, HTTPS can be sidestepped entirely by deploying malicious\nroot certificates within users' browser profiles. The Public Key Infrastructure\n(PKI), the backbone of the secure Web. HTTPS can be fully bypassed with the\ndeployment of custom potentially malicious root certificates. More worryingly,\nwe show how these powerful attacks can be fully mounted directly from web\nbrowsers themselves, through the File System Access API, a recent feature added\nby Chromium browsers that enables a website to directly manipulate a user's\nfile system via JavaScript. In a series of case studies, we demonstrate how an\nattacker can install malicious browser extensions, inject additional root\ncertificates, hijack HTTPS traffic, and enable websites to access hardware\ndevices like the camera and GPS. Based on our findings, we argue that\nresearchers and browser vendors need to develop and deploy more secure\nmechanisms for protecting users' browser data against file system attackers.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T16:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.17709v1","title":"Fault Diagnosis in New Wind Turbines using Knowledge from Existing\n  Turbines by Generative Domain Adaptation","summary":"Intelligent condition monitoring of wind turbines is essential for reducing\ndowntimes. Machine learning models trained on wind turbine operation data are\ncommonly used to detect anomalies and, eventually, operation faults. However,\ndata-driven normal behavior models (NBMs) require a substantial amount of\ntraining data, as NBMs trained with scarce data may result in unreliable fault\ndiagnosis. To overcome this limitation, we present a novel generative deep\nlearning approach to make SCADA samples from one wind turbine lacking training\ndata resemble SCADA data from wind turbines with representative training data.\nThrough CycleGAN-based domain mapping, our method enables the application of an\nNBM trained on an existing wind turbine to one with severely limited data. We\ndemonstrate our approach on field data mapping SCADA samples across 7\nsubstantially different WTs. Our findings show significantly improved fault\ndiagnosis in wind turbines with scarce data. Our method achieves the most\nsimilar anomaly scores to an NBM trained with abundant data, outperforming NBMs\ntrained on scarce training data with improvements of +10.3% in F1-score when 1\nmonth of training data is available and +16.8% when 2 weeks are available. The\ndomain mapping approach outperforms conventional fine-tuning at all considered\ndegrees of data scarcity, ranging from 1 to 8 weeks of training data. The\nproposed technique enables earlier and more reliable fault diagnosis in newly\ninstalled wind farms, demonstrating a novel and promising research direction to\nimprove anomaly detection when faced with training data scarcity.","main_category":"cs.LG","categories":"cs.LG,cs.SY,eess.SY","published":"2025-04-24T16:14:04Z"}
{"aid":"http://arxiv.org/abs/2504.17711v1","title":"Study on P-Type Doping of Mid-Wave and Long-Wave Infrared Mercury\n  Cadmium Telluride","summary":"We present in depth study of p-type doping concentration of mid-wave infrared\n(MWIR) and long-wave infrared (LWIR) mercury cadmium Telluride (HgCdTe) thin\nfilms. Annealing time was changed under specific conditions to achieve a stable\ncopper (Cu) doping concentration for HgCdTe thin films. Both MWIR and LWIR\nHgCdTe material were grown by molecular beam epitaxy (MBE), where different\ntrends were observed between LWIR and MWIR HgCdTe thin films by increasing\nanneal time. We also report the impact of different thickness (4 micron, 6\nmicron and 9 micron) along with annealing time on doping level of LWIR HgCdTe\nthin films.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-24T16:14:33Z"}
{"aid":"http://arxiv.org/abs/2504.17715v1","title":"Operational experience and performance of the Silicon Vertex Detector\n  after the first long shutdown of Belle II","summary":"In 2024, the Belle II experiment resumed data taking after the Long Shutdown\n1, which was required to install a two-layer pixel detector and upgrade\naccelerator components. We describe the challenges of this shutdown and the\noperational experience thereafter. With new data, the silicon-strip vertex\ndetector (SVD) confirmed the high hit efficiency, the large signal-to-noise\nratio, and the excellent cluster position resolution. In the coming years, the\nSuperKEKB peak luminosity is expected to increase to its target value,\nresulting in a larger SVD occupancy caused by beam background. Considerable\nefforts have been made to improve SVD reconstruction software by exploiting the\nexcellent SVD hit-time resolution to determine the collision time and reject\noff-time particle hits. A novel procedure to group SVD hits event-by-event,\nbased on their time, has been developed using the grouping information during\nreconstruction, significantly reducing the fake rate while preserving the\ntracking efficiency. The front-end chip (APV25) is operated in the multi-peak\nmode, which reads six samples. A 3/6-mixed acquisition mode, based on the\ntiming precision of the trigger, reduces background occupancy, trigger\ndead-time, and data size. Studies of the radiation damage show that the SVD\nperformance will not seriously degrade during the lifetime of the detector,\ndespite moderate radiation-induced increases in sensor current and strip noise.","main_category":"physics.ins-det","categories":"physics.ins-det,hep-ex","published":"2025-04-24T16:17:21Z"}
{"aid":"http://arxiv.org/abs/2504.17721v1","title":"Conformal Segmentation in Industrial Surface Defect Detection with\n  Statistical Guarantees","summary":"In industrial settings, surface defects on steel can significantly compromise\nits service life and elevate potential safety risks. Traditional defect\ndetection methods predominantly rely on manual inspection, which suffers from\nlow efficiency and high costs. Although automated defect detection approaches\nbased on Convolutional Neural Networks(e.g., Mask R-CNN) have advanced rapidly,\ntheir reliability remains challenged due to data annotation uncertainties\nduring deep model training and overfitting issues. These limitations may lead\nto detection deviations when processing the given new test samples, rendering\nautomated detection processes unreliable. To address this challenge, we first\nevaluate the detection model's practical performance through calibration data\nthat satisfies the independent and identically distributed (i.i.d) condition\nwith test data. Specifically, we define a loss function for each calibration\nsample to quantify detection error rates, such as the complement of recall rate\nand false discovery rate. Subsequently, we derive a statistically rigorous\nthreshold based on a user-defined risk level to identify high-probability\ndefective pixels in test images, thereby constructing prediction sets (e.g.,\ndefect regions). This methodology ensures that the expected error rate (mean\nerror rate) on the test set remains strictly bounced by the predefined risk\nlevel. Additionally, we observe a negative correlation between the average\nprediction set size and the risk level on the test set, establishing a\nstatistically rigorous metric for assessing detection model uncertainty.\nFurthermore, our study demonstrates robust and efficient control over the\nexpected test set error rate across varying calibration-to-test partitioning\nratios, validating the method's adaptability and operational effectiveness.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T16:33:56Z"}
{"aid":"http://arxiv.org/abs/2504.17722v1","title":"What makes a good public EV charging station? A revealed preference\n  study","summary":"To determine the optimal locations for electric vehicle charging stations,\noptimisation models need to predict which charging stations users will select.\nWe estimate discrete choice models to predict the usage of charging stations\nusing only readily available information for charging network operators. Our\nparameter values are estimated from a unique, revealed preferences dataset of\ncharging sessions in Montreal, Quebec. We find that user distance to stations,\nproximity to home areas, and the number of outlets at each station are\nsignificant factors for predicting station usage. Additionally, amenities near\ncharging stations have a neutral effect overall, with some users demonstrating\nstrong preference or aversion for these locations. High variability among the\npreferences of users highlight the importance of models which incorporate panel\neffects. Moreover, integrating mixed logit models within the optimization of\ncharging station network design yields high-quality solutions, even when\nevaluated under other model specifications.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T16:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.17731v1","title":"Synchronization of Quasi-Particle Excitations in a Quantum Gas with\n  Cavity-Mediated Interactions","summary":"Driven-dissipative quantum systems can undergo transitions from stationary to\ndynamical phases, reflecting the emergence of collective non-equilibrium\nbehavior. We study such a transition in a Bose-Einstein condensate coupled to\nan optical cavity and develop a cavity-assisted Bragg spectroscopy technique to\nresolve its collective modes. We observe dissipation-induced synchronization at\nthe quasiparticle level, where two roton-like modes coalesce at an exceptional\npoint. This reveals how dissipation microscopically drives collective dynamics\nand signals a precursor to a dynamical phase transition.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,quant-ph","published":"2025-04-24T16:44:07Z"}
{"aid":"http://arxiv.org/abs/2504.17740v1","title":"Embedding Empirical Distributions for Computing Optimal Transport Maps","summary":"Distributional data have become increasingly prominent in modern signal\nprocessing, highlighting the necessity of computing optimal transport (OT) maps\nacross multiple probability distributions. Nevertheless, recent studies on\nneural OT methods predominantly focused on the efficient computation of a\nsingle map between two distributions. To address this challenge, we introduce a\nnovel approach to learning transport maps for new empirical distributions.\nSpecifically, we employ the transformer architecture to produce embeddings from\ndistributional data of varying length; these embeddings are then fed into a\nhypernetwork to generate neural OT maps. Various numerical experiments were\nconducted to validate the embeddings and the generated OT maps. The model\nimplementation and the code are provided on\nhttps://github.com/jiangmingchen/HOTET.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T16:52:48Z"}
{"aid":"http://arxiv.org/abs/2504.17771v1","title":"Integrating Learning-Based Manipulation and Physics-Based Locomotion for\n  Whole-Body Badminton Robot Control","summary":"Learning-based methods, such as imitation learning (IL) and reinforcement\nlearning (RL), can produce excel control policies over challenging agile robot\ntasks, such as sports robot. However, no existing work has harmonized\nlearning-based policy with model-based methods to reduce training complexity\nand ensure the safety and stability for agile badminton robot control. In this\npaper, we introduce \\ourmethod, a novel hybrid control system for agile\nbadminton robots. Specifically, we propose a model-based strategy for chassis\nlocomotion which provides a base for arm policy. We introduce a\nphysics-informed ``IL+RL'' training framework for learning-based arm policy. In\nthis train framework, a model-based strategy with privileged information is\nused to guide arm policy training during both IL and RL phases. In addition, we\ntrain the critic model during IL phase to alleviate the performance drop issue\nwhen transitioning from IL to RL. We present results on our self-engineered\nbadminton robot, achieving 94.5% success rate against the serving machine and\n90.7% success rate against human players. Our system can be easily generalized\nto other agile mobile manipulation tasks such as agile catching and table\ntennis. Our project website: https://dreamstarring.github.io/HAMLET/.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-24T17:46:29Z"}
{"aid":"http://arxiv.org/abs/2504.17776v1","title":"Fitting Tree Metrics and Ultrametrics in Data Streams","summary":"Fitting distances to tree metrics and ultrametrics are two widely used\nmethods in hierarchical clustering, primarily explored within the context of\nnumerical taxonomy. Given a positive distance function\n$D:\\binom{V}{2}\\rightarrow\\mathbb{R}_{>0}$, the goal is to find a tree (or\nultrametric) $T$ including all elements of set $V$ such that the difference\nbetween the distances among vertices in $T$ and those specified by $D$ is\nminimized. In this paper, we initiate the study of ultrametric and tree metric\nfitting problems in the semi-streaming model, where the distances between pairs\nof elements from $V$ (with $|V|=n$), defined by the function $D$, can arrive in\nan arbitrary order. We study these problems under various distance norms:\n  For the $\\ell_0$ objective, we provide a single-pass polynomial-time\n$\\tilde{O}(n)$-space $O(1)$ approximation algorithm for ultrametrics and prove\nthat no single-pass exact algorithm exists, even with exponential time.\n  Next, we show that the algorithm for $\\ell_0$ implies an $O(\\Delta/\\delta)$\napproximation for the $\\ell_1$ objective, where $\\Delta$ is the maximum and\n$\\delta$ is the minimum absolute difference between distances in the input.\nThis bound matches the best-known approximation for the RAM model using a\ncombinatorial algorithm when $\\Delta/\\delta=O(n)$.\n  For the $\\ell_\\infty$ objective, we provide a complete characterization of\nthe ultrametric fitting problem. We present a single-pass polynomial-time\n$\\tilde{O}(n)$-space 2-approximation algorithm and show that no better than\n2-approximation is possible, even with exponential time. We also show that,\nwith an additional pass, it is possible to achieve a polynomial-time exact\nalgorithm for ultrametrics.\n  Finally, we extend the results for all these objectives to tree metrics by\nusing only one additional pass through the stream and without asymptotically\nincreasing the approximation factor.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T17:49:25Z"}
{"aid":"http://arxiv.org/abs/2504.17791v1","title":"LiDPM: Rethinking Point Diffusion for Lidar Scene Completion","summary":"Training diffusion models that work directly on lidar points at the scale of\noutdoor scenes is challenging due to the difficulty of generating fine-grained\ndetails from white noise over a broad field of view. The latest works\naddressing scene completion with diffusion models tackle this problem by\nreformulating the original DDPM as a local diffusion process. It contrasts with\nthe common practice of operating at the level of objects, where vanilla DDPMs\nare currently used. In this work, we close the gap between these two lines of\nwork. We identify approximations in the local diffusion formulation, show that\nthey are not required to operate at the scene level, and that a vanilla DDPM\nwith a well-chosen starting point is enough for completion. Finally, we\ndemonstrate that our method, LiDPM, leads to better results in scene completion\non SemanticKITTI. The project page is https://astra-vision.github.io/LiDPM .","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-24T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.19939v1","title":"Stability inequalities with explicit constants for a family of reverse\n  Sobolev inequalities on the sphere","summary":"We prove a stability inequality associated to the reverse Sobolev inequality\non the sphere $\\mathbb S^n$, for the full admissible parameter range $s -\n\\frac{n}{2} \\in (0,1) \\cup (1,2)$. To implement the classical proof of Bianchi\nand Egnell, we overcome the main difficulty that the underlying operator\n$A_{2s}$ is not positive definite.\n  As a consequence of our analysis and recent results from Gong et al.\n(arXiv:2503.20350 [math.AP]), the case $s - \\frac{n}{2} \\in (1,2)$ remarkably\nconstitutes the first example of a Sobolev-type stability inequality (i) whose\nbest constant is explicit and (ii) which does not admit an optimizer.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T16:09:42Z"}
{"aid":"http://arxiv.org/abs/2504.19943v1","title":"SUSY hierarchies of Jaynes-Cummings Hamiltonians with different detuning\n  parameters","summary":"The aim of this work is to show how supersymmetric (SUSY) quantum mechanics\ncan be applied to the Jaynes-Cummings (JC) Hamiltonian of quantum optics. These\nSUSY transformations connect pairs of Jaynes-Cummings Hamiltonians\ncharacterized by different detuning parameters as well as Jaynes-Cummings to\nanti-Jaynes-Cummings Hamiltonians. Therefore, JC Hamiltonians can be classified\nin hierarchies or sequences which are connected through SUSY transformations.\nAs a byproduct, the symmetries of JC Hamiltonians are found as well as the\nspecial case of a sequence of resonant-like interacting systems having the form\nof a simple shape invariant JC Hamiltonian hierarchy.","main_category":"math-ph","categories":"math-ph,math.MP,quant-ph","published":"2025-04-28T16:13:17Z"}
{"aid":"http://arxiv.org/abs/2504.19960v1","title":"Analytical solutions for the Extracellular-Membrane-Intracellular model","summary":"The Extracellular-Membrane-Intracellular (EMI) model is a novel mathematical\nframework for cardiac electrophysiology simulations. The EMI model provides a\nmore detailed description of the heart's electrical activity compared to\ntraditional monodomain and bidomain models, potentially making it better-suited\nfor understanding the electrical dynamics of the heart under pathological\nconditions. In this paper, we derive and verify several analytical solutions\nfor the EMI model. Specifically, we obtain a family of solutions for a single\ntwo-dimensional cell in polar coordinates and for a pair of coupled\nthree-dimensional cells in spherical coordinates. We also introduce a\nmanufactured solution for N three-dimensional cells in Cartesian coordinates.\nTo verify the analytical solutions, we conduct numerical experiments using the\nmortar finite element method combined with operator splitting. The results\ndemonstrate that the analytical solutions are effective for verifying the\naccuracy of numerical simulations of the EMI model.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-04-28T16:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.19961v1","title":"Ultrafast Electronic Structure Engineering in 1$T$-TaS$_2$: Role of\n  Doping and Amplitude Mode Dynamics","summary":"In strongly correlated transition metal dichalcogenides, an intricate\ninterplay of polaronic distortions, stacking arrangement, and electronic\ncorrelations determines the nature of the insulating state. Here, we study the\nresponse of the electronic structure to optical excitations to reveal the\neffect of chemical electron doping on this complex interplay. Transient changes\nin pristine and electron-doped 1$T$ -TaS$_2$ are measured by femtosecond\ntime-resolved photoelectron spectroscopy and compared to theoretical modeling\nbased on non-equilibrium dynamical mean-field theory and density functional\ntheory. The fine changes in the oscillatory signal of the charge density wave\namplitude mode indicate phase-dependent modifications in the Coulomb\ninteraction and the hopping. Furthermore, we find an enhanced fraction of\nmonolayers in the doped system. Our work demonstrates how the combination of\ntime-resolved spectroscopy and advanced theoretical modeling provides insights\ninto the physics of correlated transition metal dichalcogenides.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-28T16:33:47Z"}
{"aid":"http://arxiv.org/abs/2504.19968v1","title":"How Group Lives Go Well","summary":"This paper explores the ontological space of group well being, proposing a\nframework for representing collective welfare, group functions, and long term\ncontributions within an ontology engineering context. Traditional well being\ntheories focus on individual states, often relying on hedonistic, desire\nsatisfaction, or objective list models. Such approaches struggle to account for\ncases where individual sacrifices contribute to broader social progress, a\ncritical challenge in modeling group flourishing. To address this, the paper\nrefines and extends the Counterfactual Account (CT) of well being, which\nevaluates goodness of an event by comparing an individual's actual well being\nwith a hypothetical counterpart in a nearby possible world. While useful, this\nframework is insufficient for group level ontologies, where well being depends\non functional persistence, institutional roles, and historical impact rather\nthan immediate individual outcomes. Drawing on Basic Formal Ontology (BFO), the\npaper introduces a model in which group flourishing is evaluated in terms of\ngroup functional, where members bear roles and exhibit persistence conditions\nakin to biological systems or designed artifacts. This approach enables\nsemantic interoperability for modeling longitudinal social contributions,\nallowing for structured reasoning about group welfare, social institutions, and\ngroup flourishing over time.","main_category":"cs.AI","categories":"cs.AI,cs.GT","published":"2025-04-28T16:40:06Z"}
{"aid":"http://arxiv.org/abs/2504.19971v1","title":"Quantum Gravity Signatures of Gravitons in a Squeezed Coherent State on\n  Detectors within a Harmonic Trap Potential","summary":"We have studied the quantum gravity signatures that emerge in a gravitational\nwave detector placed inside a harmonic potential trap, where the quantum state\nof the graviton is either coherent, squeezed, or squeezed coherent. We compared\nthe transition probabilities of the detector in scenarios where the\ngravitational wave is quantized versus when it is treated classically. Assuming\nthe gravitational wave propagates in one direction and has only one type of\npolarization, we found that for graviton states such as coherent, squeezed, and\nsqueezed coherent states, quantum gravity signatures can emerge in events that\nwould not be possible when the graviton state is a quantum state with $n_G$\nparticles $(\\ket{n_G})$, such as graviton annihilation and the increasing\nenergy level of the detector by two levels in final state.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-28T16:45:57Z"}
{"aid":"http://arxiv.org/abs/2504.19979v1","title":"Transfer Learning Under High-Dimensional Network Convolutional\n  Regression Model","summary":"Transfer learning enhances model performance by utilizing knowledge from\nrelated domains, particularly when labeled data is scarce. While existing\nresearch addresses transfer learning under various distribution shifts in\nindependent settings, handling dependencies in networked data remains\nchallenging. To address this challenge, we propose a high-dimensional transfer\nlearning framework based on network convolutional regression (NCR), inspired by\nthe success of graph convolutional networks (GCNs). The NCR model incorporates\nrandom network structure by allowing each node's response to depend on its\nfeatures and the aggregated features of its neighbors, capturing local\ndependencies effectively. Our methodology includes a two-step transfer learning\nalgorithm that addresses domain shift between source and target networks, along\nwith a source detection mechanism to identify informative domains.\nTheoretically, we analyze the lasso estimator in the context of a random graph\nbased on the Erdos-Renyi model assumption, demonstrating that transfer learning\nimproves convergence rates when informative sources are present. Empirical\nevaluations, including simulations and a real-world application using Sina\nWeibo data, demonstrate substantial improvements in prediction accuracy,\nparticularly when labeled data in the target domain is limited.","main_category":"cs.LG","categories":"cs.LG,stat.ME","published":"2025-04-28T16:52:28Z"}
{"aid":"http://arxiv.org/abs/2504.19981v1","title":"Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided\n  GFlowNets","summary":"Achieving both accuracy and diverse reasoning remains challenging for Large\nLanguage Models (LLMs) in complex domains like mathematics. A key bottleneck is\nevaluating intermediate reasoning steps to guide generation without costly\nhuman annotations. To address this, we first introduce a novel Process Reward\nModel (PRM) trained automatically using Monte Carlo Tree Search coupled with a\nsimilarity-based data augmentation technique, effectively capturing step-level\nreasoning quality. Leveraging this PRM, we then adapt Generative Flow Networks\n(GFlowNets) to operate at the reasoning step level. Unlike traditional\nreinforcement learning focused on maximizing a single reward, GFlowNets\nnaturally sample diverse, high-quality solutions proportional to their rewards,\nas measured by our PRM. Empirical evaluation shows strong improvements in both\naccuracy and solution diversity on challenging mathematical benchmarks (e.g.,\n+2.59% absolute accuracy on MATH Level 5 for Llama3.2-3B), with effective\ngeneralization to unseen datasets (+9.4% absolute on SAT MATH). Our work\ndemonstrates the potential of PRM-guided, step-level GFlowNets for developing\nmore robust and versatile mathematical reasoning in LLMs.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-28T16:56:41Z"}
{"aid":"http://arxiv.org/abs/2504.19986v1","title":"exoALMA III: Line-intensity Modeling and System Property Extraction from\n  Protoplanetary Disks","summary":"The ALMA large program exoALMA offers a unique window into the\nthree-dimensional physical and dynamical properties of 15 circumstellar disks\nwhere planets may be actively forming. Here, we present an analysis methodology\nto map the gas disk structure and substructure encoded in 12CO, 13CO, and CS\nline emission from our targets. To model and characterize the disk structure\nprobed by optically thin species, such as CS and, in some cases, 13CO, we\nintroduce a composite line profile kernel that accounts for increased\nintensities caused by the projected overlap between the disk's front and back\nside emission. Our workflow, built on the Discminer modelling framework,\nincorporates an improved iterative two-component fitting method for inclined\nsources ($i>40^\\circ$), to mitigate the impact of the disk backside on the\nextraction of velocity maps. Also, we report best-fit parameters for the\nKeplerian stellar masses, as well as inclinations, position angles, systemic\nvelocities, rotation direction, and emission surfaces of the disks in our\nsample.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-28T17:02:28Z"}
{"aid":"http://arxiv.org/abs/2504.19995v1","title":"Separability of unipotent-free abelian subgroups in linear groups","summary":"Let ${\\bf F}$ be a field of characteristic zero. It is proved that for any\nfinitely generated linear group $\\Gamma<\\mathsf{GL}_n({\\bf F})$, every\nunipotent-free abelian subgroup of $\\Gamma$ is separable.","main_category":"math.GR","categories":"math.GR","published":"2025-04-28T17:15:47Z"}
{"aid":"http://arxiv.org/abs/2504.19997v1","title":"Simplified and Secure MCP Gateways for Enterprise AI Integration","summary":"The increased adoption of the Model Context Protocol (MCP) for AI Agents\nnecessitates robust security for Enterprise integrations. This paper introduces\nthe MCP Gateway to simplify self-hosted MCP server integration. The proposed\narchitecture integrates security principles, authentication, intrusion\ndetection, and secure tunneling, enabling secure self-hosting without exposing\ninfrastructure. Key contributions include a reference architecture, threat\nmodel mapping, simplified integration strategies, and open-source\nimplementation recommendations. This work focuses on the unique challenges of\nenterprise-centric, self-hosted AI integrations, unlike existing public MCP\nserver solutions.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-28T17:17:42Z"}
{"aid":"http://arxiv.org/abs/2504.20005v1","title":"On the lower bound of the curvature exponent on step-two Carnot groups","summary":"In this work, we show that there exists a step-two Carnot group on which the\nnew lower bound of the curvature exponent given in arXiv:2308.15811v2 can be\nstrictly less than the curvature exponent by studying the convergence of the\nstructure constants of Lie algebra.","main_category":"math.DG","categories":"math.DG,math.MG","published":"2025-04-28T17:24:15Z"}
{"aid":"http://arxiv.org/abs/2504.20008v1","title":"Disentangling the global multiplicity and spectral shape fluctuations in\n  radial flow","summary":"Radial flow is a key collective phenomenon in heavy-ion collisions, manifests\nthrough event-by-event fluctuations in transverse momentum ($p_{\\mathrm{T}}$)\nspectra. The $p_{\\mathrm{T}}$-differential radial flow, $v_0(p_{\\mathrm{T}})$,\ninitially conceived to capture local spectral shape fluctuations, is influenced\nby global multiplicity fluctuations. Using the HIJING model, we explore how\ndifferent definitions of event activity for centrality and spectral\nnormalization schemes affect $v_0(p_{\\mathrm{T}})$. We find these\nmethodological variations induce a constant offset in $v_0(p_{\\mathrm{T}})$\nwithout altering its shape, indicating that the dynamic\n$p_{\\mathrm{T}}$-differential information on radial flow remains robust, but\nits absolute magnitude is meaningful only up to a baseline offset dictated by\nglobal multiplicity fluctuations.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex","published":"2025-04-28T17:29:10Z"}
{"aid":"http://arxiv.org/abs/2504.20017v1","title":"Constructing Magic Squares: an integer linear programming model and a\n  fast heuristic","summary":"Magic squares are a fascinating mathematical challenge that has intrigued\nmathematicians for centuries. Given a positive (and possibly large) integer\n$n$, one of the main challenges that still remains is to find, within a\nreliable computational time, a magic square of order $n$, that is, a square\nmatrix of order $n$ with unique integers from $a_{\\min}$ to $a_{\\max}$, such\nthat the sum of each row, column, and diagonal equals a constant $\n\\mathcal{C}(A) $. In this work, we first present an Integer Linear Programming\n(ILP) model for constructing a magic square of order $n$, which is formulated\nas a feasibility problem. Nonetheless, the solution time of this ILP model\ngrows exponentially as the order increases. To overcome this limitation, we\nalso propose a heuristic that constructs magic squares depending on whether $n$\nis odd, singly even, or doubly even. Our numerical results show that the\nproposed heuristic can construct magic squares of order up to $70000$ in less\nthan $140$ seconds, demonstrating its efficiency and scalability.","main_category":"math.OC","categories":"math.OC","published":"2025-04-28T17:35:55Z"}
{"aid":"http://arxiv.org/abs/2504.20019v1","title":"Modelling of Underwater Vehicles using Physics-Informed Neural Networks\n  with Control","summary":"Physics-informed neural networks (PINNs) integrate physical laws with\ndata-driven models to improve generalization and sample efficiency. This work\nintroduces an open-source implementation of the Physics-Informed Neural Network\nwith Control (PINC) framework, designed to model the dynamics of an underwater\nvehicle. Using initial states, control actions, and time inputs, PINC extends\nPINNs to enable physically consistent transitions beyond the training domain.\nVarious PINC configurations are tested, including differing loss functions,\ngradient-weighting schemes, and hyperparameters. Validation on a simulated\nunderwater vehicle demonstrates more accurate long-horizon predictions compared\nto a non-physics-informed baseline","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.RO","published":"2025-04-28T17:38:57Z"}
{"aid":"http://arxiv.org/abs/2504.20024v1","title":"SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning","summary":"Recent studies in 3D spatial reasoning explore data-driven approaches and\nachieve enhanced spatial reasoning performance with reinforcement learning\n(RL). However, these methods typically perform spatial reasoning in an implicit\nmanner, and it remains underexplored whether the acquired 3D knowledge\ngeneralizes to unseen question types at any stage of the training. In this work\nwe introduce SpatialReasoner, a novel large vision-language model (LVLM) that\naddress 3D spatial reasoning with explicit 3D representations shared between\nstages -- 3D perception, computation, and reasoning. Explicit 3D\nrepresentations provide a coherent interface that supports advanced 3D spatial\nreasoning and enable us to study the factual errors made by LVLMs. Results show\nthat our SpatialReasoner achieve improved performance on a variety of spatial\nreasoning benchmarks and generalizes better when evaluating on novel 3D spatial\nreasoning questions. Our study bridges the 3D parsing capabilities of prior\nvisual foundation models with the powerful reasoning abilities of large\nlanguage models, opening new directions for 3D spatial reasoning.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T17:48:43Z"}
{"aid":"http://arxiv.org/abs/2504.20025v1","title":"Local primordial non-Gaussianity from 'zero-bias' 21cm radiation during\n  reionization","summary":"We revisit the potential of 21cm radiation fluctuations, during the epoch of\nreionization, in constraining the amplitude of local primordial non-Gaussianity\n(PNG) $f_{\\rm NL}^{\\rm loc}$. There generically exists an epoch at which the\nlinear bias of the 21cm field crosses zero, independent of the precise\nastrophysics of reionization. This epoch implies the 21cm radiation is a\nnatural \"zero-bias tracer\" in the sense of Castorina et al (2018). We identify\nnew noise-like contributions which directly compete with the zero-bias effect,\nbut which should be mitigated through sophisticated analysis techniques such as\nfield-level reconstruction. These noise-like terms act to hinder the\nconstraining power on local PNG of the brightness temperature fluctuations,\nmaking $\\sigma (f_{\\rm NL}^{\\rm loc}) \\leq 1$ unachievable even in simplified\nforecasts. We show that analyses which can reach the 'sampling noise' floor for\nthis tracer and harness its full power can potentially unlock a 10-fold\nreduction in error bars, even in the presence of large-scale cuts from\nforegrounds. The potential of this epoch motivates searching for it in future\n21cm surveys, along with developing analysis techniques that can reach the\nnoise floor required for the zero-bias epoch to saturate Fisher information.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-28T17:48:49Z"}
{"aid":"http://arxiv.org/abs/2504.20027v1","title":"All-Subsets Important Separators with Applications to Sample Sets,\n  Balanced Separators and Vertex Sparsifiers in Directed Graphs","summary":"Given a directed graph $G$ with $n$ vertices and $m$ edges, a parameter $k$\nand two disjoint subsets $S,T \\subseteq V(G)$, we show that the number of\nall-subsets important separators, which is the number of $A$-$B$ important\nvertex separators of size at most $k$ over all $A \\subseteq S$ and $B \\subseteq\nT$, is at most $\\beta(|S|, |T|, k) = 4^k {|S| \\choose \\leq k} {|T| \\choose \\leq\n2k}$, where ${x \\choose \\leq c} = \\sum_{i = 1}^c {x \\choose i}$, and that they\ncan be enumerated in time $O(\\beta(|S|,|T|,k)k^2(m+n))$. This is a\ngeneralization of the folklore result stating that the number of $A$-$B$\nimportant separators for two fixed sets $A$ and $B$ is at most $4^k$ (first\nimplicitly shown by Chen, Liu and Lu Algorithmica '09). From this result, we\nobtain the following applications: We give a construction for detection sets\nand sample sets in directed graphs, generalizing the results of Kleinberg\n(Internet Mathematics' 03) and Feige and Mahdian (STOC' 06) to directed graphs.\nVia our new sample sets, we give the first FPT algorithm for finding balanced\nseparators in directed graphs parameterized by $k$, the size of the separator.\nOur algorithm runs in time $2^{O(k)} (m + n)$. We also give a $O({\\sqrt{\\log\nk}})$ approximation algorithm for the same problem. Finally, we present new\nresults on vertex sparsifiers for preserving small cuts.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-28T17:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.20029v1","title":"Invertible Morava motives in quadrics","summary":"We associate to any element in the Milnor K-theory of a field $k$ modulo 2 an\ninvertible Morava K-theory motive over $k$. Specifically, for $\\alpha$ in\n$\\mathrm{K}^{\\mathrm{M}}_{n+1}(k)/2$ we construct an invertible\n$\\mathrm{K}(n)$-motive $L_\\alpha$ in a way that is natural in the base field\nand additive in $\\alpha$. This can be seen as categorification of\n$\\mathrm{K}^{\\mathrm{M}}_{n+1}(k)/2$ in motives.\n  The motives $L_\\alpha$ are constructed as direct summands of the\n$\\mathrm{K}(n)$-motives of quadrics, and we develop the necessary framework for\nthe study of the latter. We show that passing to the field of functions of\nquadrics of dimension greater than or equal to $2^{n+1}-1$ does not lose any\ninformation about the structure of $\\mathrm{K}(n)$-motives. This is based on\nthe study of \"decomposition of the diagonal\" in Morava K-theory of quadrics.\n  For quadrics of dimension less than $2^{n+1}-1$, we show that their Chow\nmotives can be \"reconstructed\" from their $\\mathrm{K}(n)$-motives, although the\nlatter appear structurally simpler. Our proof of this result relies on the use\nof the unstable symmetric operations of Vishik on algebraic cobordism.\n  The occurrence of the motive $L_\\alpha$ as a direct summand of the\n$\\mathrm{K}(n)$-motive of $X$ can be seen as evidence that $\\alpha$ is a\ncohomological invariant of $X$. We study this occurrence for quadrics and\nrelate it to Kahn's Descent conjecture.","main_category":"math.AG","categories":"math.AG,math.KT","published":"2025-04-28T17:52:46Z"}
{"aid":"http://arxiv.org/abs/2504.20033v1","title":"Mitigating Catastrophic Forgetting in the Incremental Learning of\n  Medical Images","summary":"This paper proposes an Incremental Learning (IL) approach to enhance the\naccuracy and efficiency of deep learning models in analyzing T2-weighted (T2w)\nMRI medical images prostate cancer detection using the PI-CAI dataset. We used\nmultiple health centers' artificial intelligence and radiology data, focused on\ndifferent tasks that looked at prostate cancer detection using MRI (PI-CAI). We\nutilized Knowledge Distillation (KD), as it employs generated images from past\ntasks to guide the training of models for subsequent tasks. The approach\nyielded improved performance and faster convergence of the models. To\ndemonstrate the versatility and robustness of our approach, we evaluated it on\nthe PI-CAI dataset, a diverse set of medical imaging modalities including OCT\nand PathMNIST, and the benchmark continual learning dataset CIFAR-10. Our\nresults indicate that KD can be a promising technique for IL in medical image\nanalysis in which data is sourced from individual health centers and the\nstorage of large datasets is not feasible. By using generated images from prior\ntasks, our method enables the model to retain and apply previously acquired\nknowledge without direct access to the original data.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T17:56:04Z"}
{"aid":"http://arxiv.org/abs/2504.20034v1","title":"Pan-genome Analysis of Angiosperm Plastomes using PGR-TK","summary":"We present a novel approach for taxonomic analysis of chloroplast genomes in\nangiosperms using the Pan-genome Research Toolkit (PGR-TK). Comparative plots\ngenerated by PGR-TK across diverse angiosperm genera reveal a wide range of\nstructural complexity, from straightforward to highly intricate patterns.\nNotably, the characteristic quadripartite plastome structure, comprising the\nlarge single copy (LSC), small single copy (SSC), and inverted repeat (IR)\nregions, is clearly identifiable in over 75% of the genera analyzed. Our\nfindings also underscore several occurrences of species mis-annotations in\npublic genomic databases, which are readily detected through visual anomalies\nin the PGR-TK plots. While more complex plot patterns remain difficult to\ninterpret, they likely reflect underlying biological variation or technical\ninconsistencies in genome assembly. Overall, this approach effectively\nintegrates classical botanical visualization with modern molecular taxonomy,\nproviding a powerful tool for genome-based classification in plant systematics.","main_category":"q-bio.GN","categories":"q-bio.GN,q-bio.BM","published":"2025-04-28T17:56:13Z"}
{"aid":"http://arxiv.org/abs/2504.20036v1","title":"exoALMA. VI. Rotating under Pressure: Rotation curves, azimuthal\n  velocity substructures, and pressure variations","summary":"The bulk motion of the gas in protoplanetary disks around newborn stars is\nnearly Keplerian. By leveraging the high angular and spectral resolution of\nALMA, we can detect small-scale velocity perturbations in molecular line\nobservations caused by local gas pressure variations in the disk, possibly\ninduced by embedded protoplanets. This paper presents the azimuthally averaged\nrotational velocity and its deviations from Keplerian rotation\n($\\delta\\upsilon_{\\phi}$) for the exoALMA sample, as measured in the $^{12}$CO\nand $^{13}$CO emission lines. The rotation signatures show evidence for\nvertically stratified disks, in which $^{13}$CO rotates faster than $^{12}$CO\ndue to a distinct thermal gas pressure gradient at their emitting heights. We\nfind $\\delta\\upsilon_{\\phi}$-substructures in the sample on both small\n($\\sim$10 au) and large ($\\sim$100 au) radial scales, reaching deviations up to\n15% from background Keplerian velocity in the most extreme cases. More than 75%\nof the rings and 80% of the gaps in the dust continuum emission resolved in\n$\\delta\\upsilon_{\\phi}$ are co-located with gas pressure maxima and minima,\nrespectively. Additionally, gas pressure substructures are observed far beyond\nthe dust continuum emission. For the first time, we determined the gas pressure\nderivative at the midplane from observations and found it to align well with\nthe dust substructures within the given uncertainties. Based on our findings,\nwe conclude that gas pressure variations are likely the dominant mechanism for\nring and gap formation in the dust continuum.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-28T17:57:27Z"}
{"aid":"http://arxiv.org/abs/2504.20385v1","title":"Weighted GKAT: Completeness and Complexity","summary":"We propose Weighted Guarded Kleene Algebra with Tests (wGKAT), an\nuninterpreted weighted programming language equipped with branching,\nconditionals, and loops. We provide an operational semantics for wGKAT using a\nvariant of weighted automata and introduce a sound and complete axiomatization.\nWe also provide a polynomial time decision procedure for bisimulation\nequivalence.","main_category":"cs.LO","categories":"cs.LO,cs.FL,cs.PL","published":"2025-04-29T03:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.20389v1","title":"CloudQC: A Network-aware Framework for Multi-tenant Distributed Quantum\n  Computing","summary":"Distributed quantum computing (DQC) that allows a large quantum circuit to be\nexecuted simultaneously on multiple quantum processing units (QPUs) becomes a\npromising approach to increase the scalability of quantum computing. It is\nnatural to envision the near-future DQC platform as a multi-tenant cluster of\nQPUs, called a Quantum Cloud. However, no existing DQC work has addressed the\ntwo key problems of running DQC in a multi-tenant quantum cloud: placing\nmultiple quantum circuits to QPUs and scheduling network resources to complete\nthese jobs. This work is the first attempt to design a circuit placement and\nresource scheduling framework for a multi-tenant environment. The proposed\nframework is called CloudQC, which includes two main functional components,\ncircuit placement and network scheduler, with the objectives of optimizing both\nquantum network cost and quantum computing time. Experimental results with real\nquantum circuit workloads show that CloudQC significantly reduces the average\njob completion time compared to existing DQC placement algorithms for both\nsingle-circuit and multi-circuit DQC. We envision this work will motivate more\nfuture work on network-aware quantum cloud.","main_category":"cs.DC","categories":"cs.DC,quant-ph","published":"2025-04-29T03:19:35Z"}
{"aid":"http://arxiv.org/abs/2504.20397v1","title":"On DR-semigroups satisfying the ample conditions","summary":"A DR-semigroup $S$ (also known as a reduced E-semiabundant or reduced\nE-Fountain semigroup) is here viewed as a semigroup equipped with two unary\noperations $D,R$ satisfying finitely many equational laws. Examples include\nDRC-semigroups (hence Ehresmann semigroups), which also satisfy the congruence\nconditions. The ample conditions on DR-semigroups are studied here and are\ndefined by the laws $$xD(y)=D(xD(y))x\\mbox{ and }R(y)x=xR(R(y)x).$$ Two natural\npartial orders may be defined on a DR-semigroup and we show that the ample\nconditions hold if and only if the two orders are equal and the projections\n(elements of the form $D(x)$) commute with one-another. Restriction semigroups\nsatisfy the generalized ample conditions, but we give other examples using\nstrongly order-preserving functions on a quasiordered set as well as so-called\n``double demonic\" composition on binary relations. Following the work of Stein,\nwe show how to construct a certain partial algebra $C(S)$ from any\nDR-semigroup, which is a category if $S$ satisfies the congruence conditions,\nbut is ``almost\" a category if the ample conditions hold. We then characterise\nthe ample conditions in terms of a converse of the condition on $S$ ensuring\nthat $C(S)$ is a category. Our main result is an ESN-style theorem for\nDR-semigroups satisfying the ample conditions, based on the $C(S)$\nconstruction. We also obtain an embedding theorem, generalizing a result for\nrestriction semigroups due to Lawson.","main_category":"math.RA","categories":"math.RA,math.CT","published":"2025-04-29T03:39:20Z"}
{"aid":"http://arxiv.org/abs/2504.20403v1","title":"Creating Your Editable 3D Photorealistic Avatar with\n  Tetrahedron-constrained Gaussian Splatting","summary":"Personalized 3D avatar editing holds significant promise due to its\nuser-friendliness and availability to applications such as AR/VR and virtual\ntry-ons. Previous studies have explored the feasibility of 3D editing, but\noften struggle to generate visually pleasing results, possibly due to the\nunstable representation learning under mixed optimization of geometry and\ntexture in complicated reconstructed scenarios. In this paper, we aim to\nprovide an accessible solution for ordinary users to create their editable 3D\navatars with precise region localization, geometric adaptability, and\nphotorealistic renderings. To tackle this challenge, we introduce a\nmeticulously designed framework that decouples the editing process into local\nspatial adaptation and realistic appearance learning, utilizing a hybrid\nTetrahedron-constrained Gaussian Splatting (TetGS) as the underlying\nrepresentation. TetGS combines the controllable explicit structure of\ntetrahedral grids with the high-precision rendering capabilities of 3D Gaussian\nSplatting and is optimized in a progressive manner comprising three stages: 3D\navatar instantiation from real-world monocular videos to provide accurate\npriors for TetGS initialization; localized spatial adaptation with explicitly\npartitioned tetrahedrons to guide the redistribution of Gaussian kernels; and\ngeometry-based appearance generation with a coarse-to-fine activation strategy.\nBoth qualitative and quantitative experiments demonstrate the effectiveness and\nsuperiority of our approach in generating photorealistic 3D editable avatars.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-29T03:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.20405v1","title":"SCOPE-MRI: Bankart Lesion Detection as a Case Study in Data Curation and\n  Deep Learning for Challenging Diagnoses","summary":"While deep learning has shown strong performance in musculoskeletal imaging,\nexisting work has largely focused on pathologies where diagnosis is not a\nclinical challenge, leaving more difficult problems underexplored, such as\ndetecting Bankart lesions (anterior-inferior glenoid labral tears) on standard\nMRIs. Diagnosing these lesions is challenging due to their subtle imaging\nfeatures, often leading to reliance on invasive MRI arthrograms (MRAs). This\nstudy introduces ScopeMRI, the first publicly available, expert-annotated\ndataset for shoulder pathologies, and presents a deep learning (DL) framework\nfor detecting Bankart lesions on both standard MRIs and MRAs. ScopeMRI includes\n586 shoulder MRIs (335 standard, 251 MRAs) from 558 patients who underwent\narthroscopy. Ground truth labels were derived from intraoperative findings, the\ngold standard for diagnosis. Separate DL models for MRAs and standard MRIs were\ntrained using a combination of CNNs and transformers. Predictions from\nsagittal, axial, and coronal views were ensembled to optimize performance. The\nmodels were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71\nstandard MRIs). The models achieved an AUC of 0.91 and 0.93, sensitivity of 83%\nand 94%, and specificity of 91% and 86% for standard MRIs and MRAs,\nrespectively. Notably, model performance on non-invasive standard MRIs matched\nor surpassed radiologists interpreting MRAs. External validation demonstrated\ninitial generalizability across imaging protocols. This study demonstrates that\nDL models can achieve radiologist-level diagnostic performance on standard\nMRIs, reducing the need for invasive MRAs. By releasing ScopeMRI and a modular\ncodebase for training and evaluating deep learning models on 3D medical imaging\ndata, we aim to accelerate research in musculoskeletal imaging and support the\ndevelopment of new datasets for clinically challenging diagnostic tasks.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV,cs.LG","published":"2025-04-29T04:02:44Z"}
{"aid":"http://arxiv.org/abs/2504.20406v1","title":"Skill Discovery for Software Scripting Automation via Offline\n  Simulations with LLMs","summary":"Scripting interfaces enable users to automate tasks and customize software\nworkflows, but creating scripts traditionally requires programming expertise\nand familiarity with specific APIs, posing barriers for many users. While Large\nLanguage Models (LLMs) can generate code from natural language queries, runtime\ncode generation is severely limited due to unverified code, security risks,\nlonger response times, and higher computational costs. To bridge the gap, we\npropose an offline simulation framework to curate a software-specific skillset,\na collection of verified scripts, by exploiting LLMs and publicly available\nscripting guides. Our framework comprises two components: (1) task creation,\nusing top-down functionality guidance and bottom-up API synergy exploration to\ngenerate helpful tasks; and (2) skill generation with trials, refining and\nvalidating scripts based on execution feedback. To efficiently navigate the\nextensive API landscape, we introduce a Graph Neural Network (GNN)-based link\nprediction model to capture API synergy, enabling the generation of skills\ninvolving underutilized APIs and expanding the skillset's diversity.\nExperiments with Adobe Illustrator demonstrate that our framework significantly\nimproves automation success rates, reduces response time, and saves runtime\ntoken costs compared to traditional runtime code generation. This is the first\nattempt to use software scripting interfaces as a testbed for LLM-based\nsystems, highlighting the advantages of leveraging execution feedback in a\ncontrolled environment and offering valuable insights into aligning AI\ncapabilities with user needs in specialized software domains.","main_category":"cs.AI","categories":"cs.AI,cs.SE","published":"2025-04-29T04:03:37Z"}
{"aid":"http://arxiv.org/abs/2504.20408v1","title":"FourierSpecNet: Neural Collision Operator Approximation Inspired by the\n  Fourier Spectral Method for Solving the Boltzmann Equation","summary":"The Boltzmann equation, a fundamental model in kinetic theory, describes the\nevolution of particle distribution functions through a nonlinear,\nhigh-dimensional collision operator. However, its numerical solution remains\ncomputationally demanding, particularly for inelastic collisions and\nhigh-dimensional velocity domains. In this work, we propose the Fourier Neural\nSpectral Network (FourierSpecNet), a hybrid framework that integrates the\nFourier spectral method with deep learning to approximate the collision\noperator in Fourier space efficiently. FourierSpecNet achieves\nresolution-invariant learning and supports zero-shot super-resolution, enabling\naccurate predictions at unseen resolutions without retraining. Beyond empirical\nvalidation, we establish a consistency result showing that the trained operator\nconverges to the spectral solution as the discretization is refined. We\nevaluate our method on several benchmark cases, including Maxwellian and\nhard-sphere molecular models, as well as inelastic collision scenarios. The\nresults demonstrate that FourierSpecNet offers competitive accuracy while\nsignificantly reducing computational cost compared to traditional spectral\nsolvers. Our approach provides a robust and scalable alternative for solving\nthe Boltzmann equation across both elastic and inelastic regimes.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NA,math.NA,physics.comp-ph","published":"2025-04-29T04:07:03Z"}
{"aid":"http://arxiv.org/abs/2504.20410v1","title":"Terahertz Wireless Data Center: Gaussian Beam or Airy Beam?","summary":"Terahertz (THz) communication is emerging as a pivotal enabler for 6G and\nbeyond wireless systems owing to its multi-GHz bandwidth. One of its novel\napplications is in wireless data centers, where it enables ultra-high data\nrates while enhancing network reconfigurability and scalability. However, due\nto numerous racks, supporting walls, and densely deployed antennas, the\nline-of-sight (LoS) path in data centers is often instead of fully obstructed,\nresulting in quasi-LoS propagation and degradation of spectral efficiency. To\naddress this issue, Airy beam-based hybrid beamforming is investigated in this\npaper as a promising technique to mitigate quasi-LoS propagation and enhance\nspectral efficiency in THz wireless data centers. Specifically, a cascaded\ngeometrical and wave-based channel model (CGWCM) is proposed for quasi-LoS\nscenarios, which accounts for diffraction effects while being more simplified\nthan conventional wave-based model. Then, the characteristics and generation of\nthe Airy beam are analyzed, and beam search methods for quasi-LoS scenarios are\nproposed, including hierarchical focusing-Airy beam search, and low-complexity\nbeam search. Simulation results validate the effectiveness of the CGWCM and\ndemonstrate the superiority of the Airy beam over Gaussian beams in mitigating\nblockages, verifying its potential for practical THz wireless communication in\ndata centers.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-29T04:15:52Z"}
{"aid":"http://arxiv.org/abs/2504.20411v1","title":"ADiff4TPP: Asynchronous Diffusion Models for Temporal Point Processes","summary":"This work introduces a novel approach to modeling temporal point processes\nusing diffusion models with an asynchronous noise schedule. At each step of the\ndiffusion process, the noise schedule injects noise of varying scales into\ndifferent parts of the data. With a careful design of the noise schedules,\nearlier events are generated faster than later ones, thus providing stronger\nconditioning for forecasting the more distant future. We derive an objective to\neffectively train these models for a general family of noise schedules based on\nconditional flow matching. Our method models the joint distribution of the\nlatent representations of events in a sequence and achieves state-of-the-art\nresults in predicting both the next inter-event time and event type on\nbenchmark datasets. Additionally, it flexibly accommodates varying lengths of\nobservation and prediction windows in different forecasting settings by\nadjusting the starting and ending points of the generation process. Finally,\nour method shows superior performance in long-horizon prediction tasks,\noutperforming existing baseline methods.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T04:17:39Z"}
{"aid":"http://arxiv.org/abs/2504.20432v1","title":"An Algebraic Approach to Asymmetric Delegation and Polymorphic Label\n  Inference (Technical Report)","summary":"Language-based information flow control (IFC) enables reasoning about and\nenforcing security policies in decentralized applications. While information\nflow properties are relatively extensional and compositional, designing\nexpressive systems that enforce such properties remains challenging. In\nparticular, it can be difficult to use IFC labels to model certain security\nassumptions, such as semi-honest agents.\n  Motivated by these modeling limitations, we study the algebraic semantics of\nlattice-based IFC label models, and propose a semantic framework that allows\nformalizing asymmetric delegation, which is partial delegation of\nconfidentiality or integrity. Our framework supports downgrading of information\nand ensures their safety through nonmalleable information flow (NMIF).\n  To demonstrate the practicality of our framework, we design and implement a\nnovel algorithm that statically checks NMIF and a label inference procedure\nthat efficiently supports bounded label polymorphism, allowing users to write\ncode generic with respect to labels.","main_category":"cs.PL","categories":"cs.PL,cs.CR","published":"2025-04-29T05:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.20446v1","title":"FT-MoE: Sustainable-learning Mixture of Experts Model for Fault-Tolerant\n  Computing with Multiple Tasks","summary":"Intelligent fault-tolerant (FT) computing has recently demonstrated\nsignificant advantages of predicting and diagnosing faults in advance, enabling\nreliable service delivery. However, due to heterogeneity of fault knowledge and\ncomplex dependence relationships of time series log data, existing deep\nlearning-based FT algorithms further improve detection performance relying on\nsingle neural network model with difficulty. To this end, we propose FT-MoE, a\nsustainable-learning mixture-of-experts model for fault-tolerant computing with\nmultiple tasks, which enables different parameters learning distinct fault\nknowledge to achieve high-reliability for service system. Firstly, we use\ndecoder-based transformer models to obtain fault prototype vectors of\ndecoupling long-distance dependencies. Followed by, we present a dual mixture\nof experts networks for high-accurate prediction for both fault detection and\nclassification tasks. Then, we design a two-stage optimization scheme of\noffline training and online tuning, which allows that in operation FT-MoE can\nalso keep learning to adapt to dynamic service environments. Finally, to verify\nthe effectiveness of FT-MoE, we conduct extensive experiments on the FT\nbenchmark. Experimental results show that FT-MoE achieves superior performance\ncompared to the state-of-the-art methods. Code will be available upon\npublication.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T05:44:59Z"}
{"aid":"http://arxiv.org/abs/2504.20453v1","title":"Shadow-point Enhanced Inexact Accelerated Proximal Gradient Method with\n  Preserved Convergence Guarantees","summary":"We consider the problem of optimizing the sum of a smooth convex function and\na non-smooth convex function using the inexact accelerated proximal gradient\n(APG) method. A key limitation of existing approaches is their reliance on\nfeasible approximate solutions to subproblems, which is often computationally\nexpensive or even unrealistic to obtain in practice. To address this\nlimitation, we develop a shadow-point enhanced inexact accelerated proximal\ngradient method (SpinAPG), which can eliminate the feasibility requirement\nwhile preserving all desirable convergence properties of the APG method,\nincluding the iterate convergence and an $o(1/k^2)$ convergence rate for the\nobjective function value, under suitable summable-error conditions. Our method\nalso provides a more flexible and computationally efficient inexact framework\nfor the APG method, with a fairly easy-to-implement error criterion. Finally,\nwe demonstrate the practical advantages of our SpinAPG through numerical\nexperiments on a relaxation of the quadratic assignment problem, showcasing its\neffectiveness while bypassing the explicit computation of a feasible point.","main_category":"math.OC","categories":"math.OC","published":"2025-04-29T06:04:29Z"}
{"aid":"http://arxiv.org/abs/2504.20454v1","title":"LymphAtlas- A Unified Multimodal Lymphoma Imaging Repository Delivering\n  AI-Enhanced Diagnostic Insight","summary":"This study integrates PET metabolic information with CT anatomical structures\nto establish a 3D multimodal segmentation dataset for lymphoma based on\nwhole-body FDG PET/CT examinations, which bridges the gap of the lack of\nstandardised multimodal segmentation datasets in the field of haematological\nmalignancies. We retrospectively collected 483 examination datasets acquired\nbetween March 2011 and May 2024, involving 220 patients (106 non-Hodgkin\nlymphoma, 42 Hodgkin lymphoma); all data underwent ethical review and were\nrigorously de-identified. Complete 3D structural information was preserved\nduring data acquisition, preprocessing and annotation, and a high-quality\ndataset was constructed based on the nnUNet format. By systematic technical\nvalidation and evaluation of the preprocessing process, annotation quality and\nautomatic segmentation algorithm, the deep learning model trained based on this\ndataset is verified to achieve accurate segmentation of lymphoma lesions in\nPET/CT images with high accuracy, good robustness and reproducibility, which\nproves the applicability and stability of this dataset in accurate segmentation\nand quantitative analysis. The deep fusion of PET/CT images achieved with this\ndataset not only significantly improves the accurate portrayal of the\nmorphology, location and metabolic features of tumour lesions, but also\nprovides solid data support for early diagnosis, clinical staging and\npersonalized treatment, and promotes the development of automated image\nsegmentation and precision medicine based on deep learning. The dataset and\nrelated resources are available at https://github.com/SuperD0122/LymphAtlas-.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-29T06:10:12Z"}
{"aid":"http://arxiv.org/abs/2504.20462v1","title":"TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with\n  Multi-Modality Observation Data","summary":"With the development of distributed systems, microservices and cloud native\ntechnologies have become central to modern enterprise software development.\nDespite bringing significant advantages, these technologies also increase\nsystem complexity and operational challenges. Traditional root cause analysis\n(RCA) struggles to achieve automated fault response, heavily relying on manual\nintervention. In recent years, large language models (LLMs) have made\nbreakthroughs in contextual inference and domain knowledge integration,\nproviding new solutions for Artificial Intelligence for Operations (AIOps).\nHowever, Existing LLM-based approaches face three key challenges: text input\nconstraints, dynamic service dependency hallucinations, and context window\nlimitations. To address these issues, we propose a tool-assisted LLM agent with\nmulti-modality observation data, namely TAMO, for fine-grained RCA. It unifies\nmulti-modal observational data into time-aligned representations to extract\nconsistent features and employs specialized root cause localization and fault\nclassification tools for perceiving the contextual environment. This approach\novercomes the limitations of LLM in handling real-time changing service\ndependencies and raw observational data and guides LLM to generate repair\nstrategies aligned with system contexts by structuring key information into a\nprompt. Experimental results show that TAMO performs well in root cause\nanalysis when dealing with public datasets characterized by heterogeneity and\ncommon fault types, demonstrating its effectiveness.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T06:50:48Z"}
{"aid":"http://arxiv.org/abs/2504.20465v1","title":"Exact multiple complex mobility edges and quantum state engineering in\n  coupled 1D quasicystals","summary":"The key concept of mobility edge, which marks the critical transition between\nextended and localized states in energy domain, has attracted significant\ninterest in the cutting-edge frontiers of modern physics due to its profound\nimplications for understanding localization and transport properties in\ndisordered systems. However, a generic way to construct multiple mobility edges\n(MME) is still ambiguous and lacking. In this work, we propose a brief scheme\nto engineer both real and complex exact multiple mobility edges exploiting a\nfew coupled one-dimensional quasiperiodic chains. We study the\nextended-localized transitions of coupled one-dimensional quasiperiodic chains\nalong the chain direction. The model combines both the well-established\nquasiperiodicity and a kind of freshly introduced staggered non-reciprocity,\nwhich are aligned in two mutually perpendicular directions, within a unified\nframework. Based on analytical analysis, we predict that when the couplings\nbetween quasiperiodic chains are weak, the system will be in a mixed phase in\nwhich the localized states and extended states coexist and intertwine, thus\nlacking explicit energy separations. However, as the inter-chain couplings\nincrease to certain strength, exact multiple mobility edges emerge. This\nprediction is clearly verified by concrete numerical calculations of the\nFractal Dimension and the scaling index $\\beta$. Moreover, we show that the\ncombination of quasiperiodicity and the staggered non-reciprocity can be\nutilized to design and realize quantum states of various configurations. Our\nresults reveal a brief and general scheme to implement exact multiple mobility\nedges for synthetic materials engineering.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-29T06:57:04Z"}
{"aid":"http://arxiv.org/abs/2504.20466v1","title":"LMM4Gen3DHF: Benchmarking and Evaluating Multimodal 3D Human Face\n  Generation with LMMs","summary":"The rapid advancement in generative artificial intelligence have enabled the\ncreation of 3D human faces (HFs) for applications including media production,\nvirtual reality, security, healthcare, and game development, etc. However,\nassessing the quality and realism of these AI-generated 3D human faces remains\na significant challenge due to the subjective nature of human perception and\ninnate perceptual sensitivity to facial features. To this end, we conduct a\ncomprehensive study on the quality assessment of AI-generated 3D human faces.\nWe first introduce Gen3DHF, a large-scale benchmark comprising 2,000 videos of\nAI-Generated 3D Human Faces along with 4,000 Mean Opinion Scores (MOS)\ncollected across two dimensions, i.e., quality and authenticity, 2,000\ndistortion-aware saliency maps and distortion descriptions. Based on Gen3DHF,\nwe propose LMME3DHF, a Large Multimodal Model (LMM)-based metric for Evaluating\n3DHF capable of quality and authenticity score prediction, distortion-aware\nvisual question answering, and distortion-aware saliency prediction.\nExperimental results show that LMME3DHF achieves state-of-the-art performance,\nsurpassing existing methods in both accurately predicting quality scores for\nAI-generated 3D human faces and effectively identifying distortion-aware\nsalient regions and distortion types, while maintaining strong alignment with\nhuman perceptual judgments. Both the Gen3DHF database and the LMME3DHF will be\nreleased upon the publication.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T07:00:06Z"}
{"aid":"http://arxiv.org/abs/2504.20477v1","title":"Combining Quality of Service and System Health Metrics in MAPE-K based\n  ROS Systems through Behavior Trees","summary":"In recent years, the field of robotics has witnessed a significant shift from\noperating in structured environments to handling dynamic and unpredictable\nsettings. To tackle these challenges, methodologies from the field of\nself-adaptive systems enabling these systems to react to unforeseen\ncircumstances during runtime have been applied. The Monitoring-Analysis-\nPlanning-Execution over Knowledge (MAPE-K) feedback loop model is a popular\napproach, often implemented in a managing subsystem, responsible for monitoring\nand adapting a managed subsystem. This work explores the implementation of the\nMAPE- K feedback loop based on Behavior Trees (BTs) within the Robot Operating\nSystem 2 (ROS2) framework. By delineating the managed and managing subsystems,\nour approach enhances the flexibility and adaptability of ROS-based systems,\nensuring they not only meet Quality-of-Service (QoS), but also system health\nmetric requirements, namely availability of ROS nodes and communication\nchannels. Our implementation allows for the application of the method to new\nmanaged subsystems without needing custom BT nodes as the desired behavior can\nbe configured within a specific rule set. We demonstrate the effectiveness of\nour method through various experiments on a system showcasing an aerial\nperception use case. By evaluating different failure cases, we show both an\nincreased perception quality and a higher system availability. Our code is open\nsource","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-29T07:19:23Z"}
{"aid":"http://arxiv.org/abs/2504.20485v1","title":"Sleeping Giants -- Activating Dormant Java Deserialization Gadget Chains\n  through Stealthy Code Changes","summary":"Java deserialization gadget chains are a well-researched critical software\nweakness. The vast majority of known gadget chains rely on gadgets from\nsoftware dependencies. Furthermore, it has been shown that small code changes\nin dependencies have enabled these gadget chains. This makes gadget chain\ndetection a purely reactive endeavor. Even if one dependency's deployment\npipeline employs gadget chain detection, a gadget chain can still result from\ngadgets in other dependencies. In this work, we assess how likely small code\nchanges are to enable a gadget chain. These changes could either be accidental\nor intentional as part of a supply chain attack. Specifically, we show that\nclass serializability is a strongly fluctuating property over a dependency's\nevolution. Then, we investigate three change patterns by which an attacker\ncould stealthily introduce gadgets into a dependency. We apply these patterns\nto 533 dependencies and run three state-of-the-art gadget chain detectors both\non the original and the modified dependencies. The tools detect that applying\nthe modification patterns can activate/inject gadget chains in 26.08% of the\ndependencies we selected. Finally, we verify the newly detected chains. As\nsuch, we identify dormant gadget chains in 53 dependencies that could be added\nthrough minor code modifications. This both shows that Java deserialization\ngadget chains are a broad liability to software and proves dormant gadget\nchains as a lucrative supply chain attack vector.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-04-29T07:24:34Z"}
{"aid":"http://arxiv.org/abs/2504.20500v1","title":"UniDetox: Universal Detoxification of Large Language Models via Dataset\n  Distillation","summary":"We present UniDetox, a universally applicable method designed to mitigate\ntoxicity across various large language models (LLMs). Previous detoxification\nmethods are typically model-specific, addressing only individual models or\nmodel families, and require careful hyperparameter tuning due to the trade-off\nbetween detoxification efficacy and language modeling performance. In contrast,\nUniDetox provides a detoxification technique that can be universally applied to\na wide range of LLMs without the need for separate model-specific tuning.\nSpecifically, we propose a novel and efficient dataset distillation technique\nfor detoxification using contrastive decoding. This approach distills\ndetoxifying representations in the form of synthetic text data, enabling\nuniversal detoxification of any LLM through fine-tuning with the distilled\ntext. Our experiments demonstrate that the detoxifying text distilled from\nGPT-2 can effectively detoxify larger models, including OPT, Falcon, and\nLLaMA-2. Furthermore, UniDetox eliminates the need for separate hyperparameter\ntuning for each model, as a single hyperparameter configuration can be\nseamlessly applied across different models. Additionally, analysis of the\ndetoxifying text reveals a reduction in politically biased content, providing\ninsights into the attributes necessary for effective detoxification of LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-29T07:40:00Z"}
{"aid":"http://arxiv.org/abs/2504.20507v1","title":"Taxonomic Trace Links: Rethinking Traceability and its Benefits","summary":"Traceability greatly supports knowledge-intensive tasks, e.g., coverage check\nand impact analysis. Despite its clear benefits, the \\emph{practical}\nimplementation of traceability poses significant challenges, leading to a\nreduced focus on the creation and maintenance of trace links. We propose a new\napproach -- Taxonomic Trace Links (TTL) -- which rethinks traceability and its\nbenefits. With TTL, trace links are created indirectly through a\ndomain-specific taxonomy, a simplified version of a domain model. TTL has the\npotential to address key traceability challenges, such as the granularity of\ntrace links, the lack of a common data structure among software development\nartifacts, and unclear responsibility for traceability. We explain how TTL\naddresses these challenges and perform an initial validation with\npractitioners. We identified six challenges associated with TTL implementation\nthat need to be addressed. Finally, we propose a research roadmap to further\ndevelop and evaluate the technical solution of TTL. TTL appears to be\nparticularly feasible in practice where a domain taxonomy is already\nestablished","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-29T07:47:38Z"}
{"aid":"http://arxiv.org/abs/2504.20508v1","title":"The Panel Complexity of Sortition: Is 12 Angry Men Enough?","summary":"Sortition is the practice of delegating public decision-making to randomly\nselected panels. Recently, it has gained momentum worldwide through its use in\ncitizens' assemblies, sparking growing interest within the computer science\ncommunity. One key appeal of sortition is that random panels tend to be more\nrepresentative of the population than elected committees or parliaments. Our\nmain conceptual contribution is a novel definition of representative panels,\nbased on the Wasserstein distance from statistical learning theory. Using this\ndefinition, we develop a framework for analyzing the panel complexity problem\n-- determining the required panel size to ensure desirable properties. We focus\non three key desiderata: (1) that efficiency at the panel level extends to the\nwhole population, measured by social welfare; (2) that fairness guarantees for\nthe panel translate to fairness for the population, captured by the core; and\n(3) that the probability of an outlier panel, for which the decision\nsignificantly deviates from the optimal one, remains low. We establish\nnear-tight panel complexity guarantees for these desiderata across two\nfundamental social choice settings: participatory budgeting and facility\nlocation.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-29T07:48:39Z"}
{"aid":"http://arxiv.org/abs/2504.20521v1","title":"Quantifying the Influence of Climate on Storm Activity Using Machine\n  Learning","summary":"Extratropical storms shape midlatitude weather and vary due to both the\nslowly evolving climate and the rapid changes in synoptic conditions. While the\ninfluence of each factor has been studied extensively, their relative\nimportance remains unclear. Here, we quantify the climate's relative importance\nin both mean storm activity and individual storm development using 84 years of\nERA-5 data and Convolutional Neural Networks (CNN). We find that the\nconstructed CNN model predicts more than 90% of the variability in the mean\nstorm activity. However, a similar model predicts up to a third of the\nvariability in individual storm features, such as intensity, growth time, and\nstorm trajectory, showing their variability is dominated by synoptic\nconditions. Isolating present-day climate change yields a signal-to-noise ratio\n(SNR) of about 0.16% for storm-intensity attribution, whereas the SNR for heat\nanomalies is ~50 times higher, highlighting that focusing on variables more\ndirectly tied to warming provides a clearer attribution pathway.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-29T08:02:10Z"}
{"aid":"http://arxiv.org/abs/2504.20525v1","title":"Geometry-aware Temporal Aggregation Network for Monocular 3D Lane\n  Detection","summary":"Monocular 3D lane detection aims to estimate 3D position of lanes from\nfrontal-view (FV) images. However, current monocular 3D lane detection methods\nsuffer from two limitations, including inaccurate geometric information of the\npredicted 3D lanes and difficulties in maintaining lane integrity. To address\nthese issues, we seek to fully exploit the potential of multiple input frames.\nFirst, we aim at enhancing the ability to perceive the geometry of scenes by\nleveraging temporal geometric consistency. Second, we strive to improve the\nintegrity of lanes by revealing more instance information from temporal\nsequences. Therefore, we propose a novel Geometry-aware Temporal Aggregation\nNetwork (GTA-Net) for monocular 3D lane detection. On one hand, we develop the\nTemporal Geometry Enhancement Module (TGEM), which exploits geometric\nconsistency across successive frames, facilitating effective geometry\nperception. On the other hand, we present the Temporal Instance-aware Query\nGeneration (TIQG), which strategically incorporates temporal cues into query\ngeneration, thereby enabling the exploration of comprehensive instance\ninformation. Experiments demonstrate that our GTA-Net achieves SoTA results,\nsurpassing existing monocular 3D lane detection solutions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T08:10:17Z"}
{"aid":"http://arxiv.org/abs/2504.20530v1","title":"Beyond the Horizon: Decoupling UAVs Multi-View Action Recognition via\n  Partial Order Transfer","summary":"Action recognition in unmanned aerial vehicles (UAVs) poses unique challenges\ndue to significant view variations along the vertical spatial axis. Unlike\ntraditional ground-based settings, UAVs capture actions from a wide range of\naltitudes, resulting in considerable appearance discrepancies. We introduce a\nmulti-view formulation tailored to varying UAV altitudes and empirically\nobserve a partial order among views, where recognition accuracy consistently\ndecreases as the altitude increases. This motivates a novel approach that\nexplicitly models the hierarchical structure of UAV views to improve\nrecognition performance across altitudes. To this end, we propose the Partial\nOrder Guided Multi-View Network (POG-MVNet), designed to address drastic view\nvariations by effectively leveraging view-dependent information across\ndifferent altitude levels. The framework comprises three key components: a View\nPartition (VP) module, which uses the head-to-body ratio to group views by\naltitude; an Order-aware Feature Decoupling (OFD) module, which disentangles\naction-relevant and view-specific features under partial order guidance; and an\nAction Partial Order Guide (APOG), which leverages the partial order to\ntransfer informative knowledge from easier views to support learning in more\nchallenging ones. We conduct experiments on Drone-Action, MOD20, and UAV\ndatasets, demonstrating that POG-MVNet significantly outperforms competing\nmethods. For example, POG-MVNet achieves a 4.7% improvement on Drone-Action\ndataset and a 3.5% improvement on UAV dataset compared to state-of-the-art\nmethods ASAT and FAR. The code for POG-MVNet will be made available soon.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T08:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.20548v1","title":"Asymptotic Pythagorean identity for the Jacobi polynomials","summary":"Radial eigenfunctions of the Laplace-Beltrami operator on compact rank-one\nsymmetric spaces may be expressed in terms of Jacobi polynomials. We use this\nfact to prove an identity for Jacobi polynomials which is inspired by results\nof Minakshisundaram-Pleijel and Zelditch on the Fourier coefficients of a\nsmooth measure supported on a compact submanifold of a compact Riemannian\nmanifold.","main_category":"math.SP","categories":"math.SP","published":"2025-04-29T08:51:49Z"}
{"aid":"http://arxiv.org/abs/2504.20554v1","title":"Small brains but big challenges: white matter tractography in early life\n  samples","summary":"In the human brain, white matter development is a complex and long-lasting\nprocess involving intermingling micro-and macrostructural mechanisms, such as\nfiber growth, pruning and myelination. Did you know that all these\nneurodevelopmental changes strongly affect MRI signals, with consequences on\ntractography performances and reliability? This communication aims to elaborate\non these aspects, highlighting the importance of tracking and studying the\ndeveloping connections with dedicated approaches.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-29T08:56:21Z"}
{"aid":"http://arxiv.org/abs/2504.20556v1","title":"Mutual Information Minimization for Side-Channel Attack Resistance via\n  Optimal Noise Injection","summary":"Side-channel attacks (SCAs) pose a serious threat to system security by\nextracting secret keys through physical leakages such as power consumption,\ntiming variations, and electromagnetic emissions. Among existing\ncountermeasures, artificial noise injection is recognized as one of the most\neffective techniques. However, its high power consumption poses a major\nchallenge for resource-constrained systems such as Internet of Things (IoT)\ndevices, motivating the development of more efficient protection schemes. In\nthis paper, we model SCAs as a communication channel and aim to suppress\ninformation leakage by minimizing the mutual information between the secret\ninformation and side-channel observations, subject to a power constraint on the\nartificial noise. We propose an optimal artificial noise injection method to\nminimize the mutual information in systems with Gaussian inputs. Specifically,\nwe formulate two convex optimization problems: 1) minimizing the total mutual\ninformation, and 2) minimizing the maximum mutual information across\nobservations. Numerical results show that the proposed methods significantly\nreduce both total and maximum mutual information compared to conventional\ntechniques, confirming their effectiveness for resource-constrained,\nsecurity-critical systems.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T08:57:21Z"}
{"aid":"http://arxiv.org/abs/2504.20560v1","title":"Generate more than one child in your co-evolutionary semi-supervised\n  learning GAN","summary":"Generative Adversarial Networks (GANs) are very useful methods to address\nsemi-supervised learning (SSL) datasets, thanks to their ability to generate\nsamples similar to real data. This approach, called SSL-GAN has attracted many\nresearchers in the last decade. Evolutionary algorithms have been used to guide\nthe evolution and training of SSL-GANs with great success. In particular,\nseveral co-evolutionary approaches have been applied where the two networks of\na GAN (the generator and the discriminator) are evolved in separate\npopulations. The co-evolutionary approaches published to date assume some\nspatial structure of the populations, based on the ideas of cellular\nevolutionary algorithms. They also create one single individual per generation\nand follow a generational replacement strategy in the evolution. In this paper,\nwe re-consider those algorithmic design decisions and propose a new\nco-evolutionary approach, called Co-evolutionary Elitist SSL-GAN (CE-SSLGAN),\nwith panmictic population, elitist replacement, and more than one individual in\nthe offspring. We evaluate the performance of our proposed method using three\nstandard benchmark datasets. The results show that creating more than one\noffspring per population and using elitism improves the results in comparison\nwith a classical SSL-GAN.","main_category":"cs.NE","categories":"cs.NE,cs.AI,cs.LG","published":"2025-04-29T09:04:22Z"}
{"aid":"http://arxiv.org/abs/2504.20561v1","title":"BEER: Biochemical Estimator and Explorer of Residues -- A Comprehensive\n  Software Suite for Protein Sequence Analysis","summary":"Protein sequence analysis underpins research in biophysics, computational\nbiology, and bioinformatics. We introduce BEER, a crossplatform graphical\ninterface that accepts FASTA or Protein Data Bank (PDB) files, or manual\nsequence entry, and instantly computes a suite of physicochemical metrics, such\nas amino acid composition, Kyte Doolittle hydrophobicity profiles, net charge\nversus pH curves with automatic isoelectric point determination, solubility\npredictions, and key indices such as molecular weight, extinction coefficient,\nGRAVY (grand average of hydropathicity) score, instability index, and\naromaticity. BEER's interactive visualizations, including bar and pie charts,\nhydropathy plots, residue level bead models, and radar diagrams make it easy to\nexplore physicochemical properties of protein chains. A multichain module also\nenables direct comparison of complex assemblies. Built in Python with\nBioPython, PyQt5, and matplotlib, BEER delivers complete analyses of sequences\nup to 10000 residues in under one second.","main_category":"q-bio.BM","categories":"q-bio.BM","published":"2025-04-29T09:04:40Z"}
{"aid":"http://arxiv.org/abs/2504.20565v1","title":"DLCM: a versatile multi-level solver for heterogeneous multicellular\n  systems","summary":"Computational modeling of multicellular systems may aid in untangling\ncellular dynamics and emergent properties of biological cell populations. A key\nchallenge is to balance the level of model detail and the computational\nefficiency, while using physically interpretable parameters to facilitate\nmeaningful comparisons with biological data.\n  For this purpose, we present the DLCM-solver (discrete Laplacian cell\nmechanics), a flexible and efficient computational solver for spatial and\nstochastic simulations of populations of cells, developed from first principle\nto support mechanistic investigations. The solver has been designed as a module\nin URDME, the unstructured reaction-diffusion master equation open software\nframework, to allow for the integration of intra-cellular models with\nextra-cellular features handled by the DLCM. The solver manages discrete cells\non a fixed lattice and reaction-transport events in a continuous-time Markov\nchain. Space-continuous micro-environment quantities such as pressure and\nchemical substances are supported by the framework, permitting a variety of\nmodeling choices concerning chemotaxis, mechanotaxis, nutrient-driven cell\ngrowth and death, among others.\n  An essential and novel feature of the DLCM-solver is the coupling of cellular\npressure to the curvature of the cell populations by elliptic projection onto\nthe computational grid, with which we can include effects from surface tension\nbetween populations.\n  We demonstrate the flexibility of the framework by implementing benchmark\nproblems of cell sorting, cellular signaling, tumor growth, and chemotaxis\nmodels. We additionally formally analyze the computational complexity and show\nthat it is theoretically optimal for systems based on pressure-driven cell\nmigration. In summary, the solver balances efficiency and a relatively fine\nresolution, while supporting a high level of interpretability.","main_category":"q-bio.QM","categories":"q-bio.QM,q-bio.PE","published":"2025-04-29T09:12:16Z"}
{"aid":"http://arxiv.org/abs/2504.20566v1","title":"Inclusive Training Separation and Implicit Knowledge Interaction for\n  Balanced Online Class-Incremental Learning","summary":"Online class-incremental learning (OCIL) focuses on gradually learning new\nclasses (called plasticity) from a stream of data in a single-pass, while\nconcurrently preserving knowledge of previously learned classes (called\nstability). The primary challenge in OCIL lies in maintaining a good balance\nbetween the knowledge of old and new classes within the continually updated\nmodel. Most existing methods rely on explicit knowledge interaction through\nexperience replay, and often employ exclusive training separation to address\nbias problems. Nevertheless, it still remains a big challenge to achieve a\nwell-balanced learner, as these methods often exhibit either reduced plasticity\nor limited stability due to difficulties in continually integrating knowledge\nin the OCIL setting. In this paper, we propose a novel replay-based method,\ncalled Balanced Online Incremental Learning (BOIL), which can achieve both high\nplasticity and stability, thus ensuring more balanced performance in OCIL. Our\nBOIL method proposes an inclusive training separation strategy using dual\nclassifiers so that knowledge from both old and new classes can effectively be\nintegrated into the model, while introducing implicit approaches for\ntransferring knowledge across the two classifiers. Extensive experimental\nevaluations over three widely-used OCIL benchmark datasets demonstrate the\nsuperiority of BOIL, showing more balanced yet better performance compared to\nstate-of-the-art replay-based OCIL methods.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-29T09:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.20567v1","title":"Explanation format does not matter; but explanations do -- An Eggsbert\n  study on explaining Bayesian Optimisation tasks","summary":"Bayesian Optimisation (BO) is a family of methods for finding optimal\nparameters when the underlying function to be optimised is unknown. BO is used,\nfor example, for hyperparameter tuning in machine learning and as an expert\nsupport tool for tuning cyberphysical systems. For settings where humans are\ninvolved in the tuning task, methods have been developed to explain BO\n(Explainable Bayesian Optimization, XBO). However, there is little guidance on\nhow to present XBO results to humans so that they can tune the system\neffectively and efficiently. In this paper, we investigate how the XBO\nexplanation format affects users' task performance, task load, understanding\nand trust in XBO. We chose a task that is accessible to a wide range of users.\nSpecifically, we set up an egg cooking scenario with 6 parameters that\nparticipants had to adjust to achieve a perfect soft-boiled egg. We compared\nthree different explanation formats: a bar chart, a list of rules and a textual\nexplanation in a between-subjects online study with 213 participants. Our\nresults show that adding any type of explanation increases task success,\nreduces the number of trials needed to achieve success, and improves\ncomprehension and confidence. While explanations add more information for\nparticipants to process, we found no increase in user task load. We also found\nthat the aforementioned results were independent of the explanation format; all\nformats had a similar effect.This is an interesting finding for practical\napplications, as it suggests that explanations can be added to BO tuning tasks\nwithout the burden of designing or selecting specific explanation formats. In\nthe future, it would be interesting to investigate scenarios of prolonged use\nof the explanation formats and whether they have different effects on users'\nmental models of the underlying system.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-29T09:16:33Z"}
{"aid":"http://arxiv.org/abs/2504.20573v1","title":"Odd coloring of $k$-trees","summary":"An odd coloring of a graph is a proper coloring such that every non-isolated\nvertex has a color that appears at an odd number of its neighbors. This notion\nwas introduced by Petr\\v{s}evski and \\v{S}krekovski in 2022. In this paper, we\nfocus on odd coloring of $k$-trees, where a $k$-tree is a graph obtained from\nthe complete graph of order $k+1$ by recursively adding a new vertex that is\njoined to a clique of order $k$ in the former graph. It follows from a result\nof Cranston, Lafferty, and Song in 2023 that every $k$-tree is odd\n$(2k+1)$-colorable. We improve this bound to show that every $k$-tree is odd\n$\\left(k+2\\left\\lfloor\\log_2 k\\right\\rfloor+3\\right)$-colorable. Furthermore,\nwhen $k=2,3$, we show the tight bound that every 2-tree is odd $4$-colorable\nand that every 3-tree is odd $5$-colorable.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T09:27:26Z"}
{"aid":"http://arxiv.org/abs/2504.20584v1","title":"Hydra: Marker-Free RGB-D Hand-Eye Calibration","summary":"This work presents an RGB-D imaging-based approach to marker-free hand-eye\ncalibration using a novel implementation of the iterative closest point (ICP)\nalgorithm with a robust point-to-plane (PTP) objective formulated on a Lie\nalgebra. Its applicability is demonstrated through comprehensive experiments\nusing three well known serial manipulators and two RGB-D cameras. With only\nthree randomly chosen robot configurations, our approach achieves approximately\n90% successful calibrations, demonstrating 2-3x higher convergence rates to the\nglobal optimum compared to both marker-based and marker-free baselines. We also\nreport 2 orders of magnitude faster convergence time (0.8 +/- 0.4 s) for 9\nrobot configurations over other marker-free methods. Our method exhibits\nsignificantly improved accuracy (5 mm in task space) over classical approaches\n(7 mm in task space) whilst being marker-free. The benchmarking dataset and\ncode are open sourced under Apache 2.0 License, and a ROS 2 integration with\nrobot abstraction is provided to facilitate deployment.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-29T09:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.20586v1","title":"Faster Random Walk-based Capacitance Extraction with Generalized\n  Antithetic Sampling","summary":"Floating random walk-based capacitance extraction has emerged in recent years\nas a tried and true approach for extracting parasitic capacitance in very large\nscale integrated circuits. Being a Monte Carlo method, its performance is\ndependent on the variance of sampled quantities and variance reduction methods\nare crucial for the challenges posed by ever denser process technologies and\nlayout-dependent effects. In this work, we present a novel, universal variance\nreduction method for floating random walk-based capacitance extraction, which\nis conceptually simple, highly efficient and provably reduces variance in all\nextractions, especially when layout-dependent effects are present. It is\ncomplementary to existing mathematical formulations for variance reduction and\nits performance gains are experienced on top of theirs. Numerical experiments\ndemonstrate substantial such gains of up to 30% in number of walks necessary\nand even more in actual extraction times compared to the best previously\nproposed variance reduction approaches for the floating random-walk.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cs.CE,stat.AP","published":"2025-04-29T09:40:21Z"}
{"aid":"http://arxiv.org/abs/2504.20589v1","title":"Quasi-normal f-modes of anisotropic quark stars in full general\n  relativity","summary":"We investigate f-mode oscillations of anisotropic quark stars within the\nframework of full general relativity. We consider two different equations of\nstate (EOSs), one is the MIT bag model EOS and the other is EOS-A. Our study\nexamines the impact of the pressure anisotropy on the equilibrium structure, as\nwell as on the frequencies and damping times of f-mode oscillations. Our\nresults confirm that the f-mode frequency scales linearly with the square root\nof the average density, with anisotropy influencing both the slope and\nintercept of this relation. The dependence of the f-mode frequency on total\nmass reveals distinct trends based on the relative dominance of tangential and\nradial pressure. When the tangential pressure exceeds the radial pressure, the\nfrequency increases with mass, exhibiting rapid growth for massive quark stars.\nWhen the radial pressure dominates, the frequency increases with mass; however,\nin cases where the radial pressure is significantly greater than the tangential\npressure, the frequency decreases as mass increases. For low-mass quark stars,\nstronger tangential pressure leads to an increase in frequency, while beyond a\nthreshold mass, a further increase in tangential pressure results in a decrease\nin frequency. For the chosen range of anisotropic strengths, the frequency\nvaries between 1.3 kHz and 2.3 kHz for the MIT bag EOS and between 1.8 kHz and\n3.4 kHz for EOS-A. We find that the normalized damping time follows a linear\ntrend with compactness. For a fixed stellar mass, an increase in tangential\npressure relative to radial pressure reduces the damping time, whereas a\ndecrease in tangential pressure significantly increases it. The damping time\nranges from 83 ms to 900 ms for the MIT bag EOS and from 60 ms to 761 ms for\nEOS-A. We present semi-empirical expressions for both the frequency and damping\ntime as functions of mass, radius, and anisotropic strength.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-29T09:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.20598v1","title":"Natural Language Processing tools for Pharmaceutical Manufacturing\n  Information Extraction from Patents Natural Language Processing (NLP) tools\n  for Pharmaceutical Manufacturing Information Extraction from Patents","summary":"Abundant and diverse data on medicines manufacturing and other lifecycle\ncomponents has been made easily accessible in the last decades. However, a\nsignificant proportion of this information is characterised by not being\ntabulated and usable for machine learning purposes. Thus, natural language\nprocessing tools have been used to build databases in domains such as\nbiomedical and chemical to address this limitation. This has allowed the\ndevelopment of artificial intelligence applications, which have improved drug\ndiscovery and treatments. In the pharmaceutical manufacturing context, some\ninitiatives and datasets for primary processing can be found, but the\nmanufacturing of drug products is an area which is still lacking, to the best\nof our knowledge. This works aims to explore and adapt NLP tools used in other\ndomains to extract information on both primary and secondary manufacturing,\nemploying patents as the main source of data. Thus, two independent, but\ncomplementary, models were developed comprising a method to select fragments of\ntext that contain manufacturing data, and a named entity recognition system\nthat enables extracting information on operations, materials, and conditions of\na process. For the first model, the identification of relevant sections was\nachieved using an unsupervised approach combining Latent Dirichlet Allocation\nand k-Means clustering. The performance of this model measured as a Cohen's\nkappa between model output and manual revision was higher than 90%. NER model\nconsisted of a deep neural network, and an f1-score micro average of 84.2% was\nobtained which is comparable to other works. Some considerations for these\ntools to be used in data extraction are discussed throughout this document.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-29T09:56:23Z"}
{"aid":"http://arxiv.org/abs/2504.20599v1","title":"PartHOI: Part-based Hand-Object Interaction Transfer via Generalized\n  Cylinders","summary":"Learning-based methods to understand and model hand-object interactions (HOI)\nrequire a large amount of high-quality HOI data. One way to create HOI data is\nto transfer hand poses from a source object to another based on the objects'\ngeometry. However, current methods for transferring hand poses between objects\nrely on shape matching, limiting the ability to transfer poses across different\ncategories due to differences in their shapes and sizes. We observe that HOI\noften involves specific semantic parts of objects, which often have more\nconsistent shapes across categories. In addition, constructing size-invariant\ncorrespondences between these parts is important for cross-category transfer.\nBased on these insights, we introduce a novel method PartHOI for part-based HOI\ntransfer. Using a generalized cylinder representation to parameterize an object\nparts' geometry, PartHOI establishes a robust geometric correspondence between\nobject parts, and enables the transfer of contact points. Given the transferred\npoints, we optimize a hand pose to fit the target object well. Qualitative and\nquantitative results demonstrate that our method can generalize HOI transfers\nwell even for cross-category objects, and produce high-fidelity results that\nare superior to the existing methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T09:56:29Z"}
{"aid":"http://arxiv.org/abs/2504.20606v1","title":"Monoidal Relative Categories Model Monoidal $\\infty$-Categories","summary":"We show that the homotopy theory of monoidal relative categories is\nequivalent to that of monoidal $\\infty$-categories, as well as its symmetric\nmonoidal version. As an application, we give a concise and complete proof of\nthe fact that every presentably monoidal or presentably symmetric monoidal\n$\\infty$-category is presented by a monoidal or symmetric monoidal model\ncategory, which, in the monoidal case, was sketched by Lurie, and in the\nsymmetric monoidal case, was proved by Nikolaus--Sagave.","main_category":"math.CT","categories":"math.CT,math.AT","published":"2025-04-29T10:15:32Z"}
{"aid":"http://arxiv.org/abs/2504.20625v1","title":"DiffusionRIR: Room Impulse Response Interpolation using Diffusion Models","summary":"Room Impulse Responses (RIRs) characterize acoustic environments and are\ncrucial in multiple audio signal processing tasks. High-quality RIR estimates\ndrive applications such as virtual microphones, sound source localization,\naugmented reality, and data augmentation. However, obtaining RIR measurements\nwith high spatial resolution is resource-intensive, making it impractical for\nlarge spaces or when dense sampling is required. This research addresses the\nchallenge of estimating RIRs at unmeasured locations within a room using\nDenoising Diffusion Probabilistic Models (DDPM). Our method leverages the\nanalogy between RIR matrices and image inpainting, transforming RIR data into a\nformat suitable for diffusion-based reconstruction.\n  Using simulated RIR data based on the image method, we demonstrate our\napproach's effectiveness on microphone arrays of different curvatures, from\nlinear to semi-circular. Our method successfully reconstructs missing RIRs,\neven in large gaps between microphones. Under these conditions, it achieves\naccurate reconstruction, significantly outperforming baseline Spline Cubic\nInterpolation in terms of Normalized Mean Square Error and Cosine Distance\nbetween actual and interpolated RIRs.\n  This research highlights the potential of using generative models for\neffective RIR interpolation, paving the way for generating additional data from\nlimited real-world measurements.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-29T10:52:07Z"}
{"aid":"http://arxiv.org/abs/2504.20643v1","title":"Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM\n  Creativity through Structured Representations","summary":"Large Language Models (LLMs) excel at countless tasks, yet struggle with\ncreativity. In this paper, we introduce a novel approach that couples LLMs with\nstructured representations and cognitively inspired manipulations to generate\nmore creative and diverse ideas. Our notion of creativity goes beyond\nsuperficial token-level variations; rather, we explicitly recombine structured\nrepresentations of existing ideas, allowing our algorithm to effectively\nexplore the more abstract landscape of ideas. We demonstrate our approach in\nthe culinary domain with DishCOVER, a model that generates creative recipes.\nExperiments comparing our model's results to those of GPT-4o show greater\ndiversity. Domain expert evaluations reveal that our outputs, which are mostly\ncoherent and feasible culinary creations, significantly surpass GPT-4o in terms\nof novelty, thus outperforming it in creative generation. We hope our work\ninspires further research into structured creativity in AI.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-29T11:13:06Z"}
{"aid":"http://arxiv.org/abs/2504.20672v1","title":"Detection of $J$-band photometric periodicity in the T8 dwarfs 2MASS\n  J09393548-2448279 and EQ J1959-3338","summary":"Aims: We aim to study the near-infrared variability of the T8 dwarfs 2MASS\nJ09393548-2448279 and EQ J1959-3338 by analyzing their $J$-band photometric\nsignal, which can provide new insights into the atmospheric dynamics of cold\nbrown dwarfs. Methods: We used FLAMINGOS-2 on the Gemini South telescope to\nperform $J$-band differential photometry continuously over 4 h for each target.\nThe resulting light curves have a cadence of 20 s and a photometric uncertainty\nof 2-4 mmag. Results: We detect periodic variability in both T8 dwarfs, with an\namplitude of $16.6\\pm0.9$ mmag and a period of $1.364\\pm0.012$ h for EQ\nJ1959-3338, which we attribute to rotational modulation. For 2MASS\nJ09393548-2448279, we observe an amplitude of $4.6\\pm0.4$ mmag and a period of\n$1.733\\pm0.040$ h, though this periodicity could represent a fraction of a\nlonger period. Conclusions: With the detection of variability in 2MASS\nJ09393548-2448279 and EQ J1959-3338, the number of known variable T8 dwarfs has\ndoubled, making them prime candidates for infrared space-based monitoring and\nradio observations to investigate atmospheric dynamics and the influence of the\nmagnetic field in very cool atmospheres.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,physics.space-ph","published":"2025-04-29T11:56:41Z"}
{"aid":"http://arxiv.org/abs/2504.20677v1","title":"Occlusion-aware Driver Monitoring System using the Driver Monitoring\n  Dataset","summary":"This paper presents a robust, occlusion-aware driver monitoring system (DMS)\nutilizing the Driver Monitoring Dataset (DMD). The system performs driver\nidentification, gaze estimation by regions, and face occlusion detection under\nvarying lighting conditions, including challenging low-light scenarios. Aligned\nwith EuroNCAP recommendations, the inclusion of occlusion detection enhances\nsituational awareness and system trustworthiness by indicating when the\nsystem's performance may be degraded. The system employs separate algorithms\ntrained on RGB and infrared (IR) images to ensure reliable functioning. We\ndetail the development and integration of these algorithms into a cohesive\npipeline, addressing the challenges of working with different sensors and\nreal-car implementation. Evaluation on the DMD and in real-world scenarios\ndemonstrates the effectiveness of the proposed system, highlighting the\nsuperior performance of RGB-based models and the pioneering contribution of\nrobust occlusion detection in DMS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T11:58:37Z"}
{"aid":"http://arxiv.org/abs/2504.20680v1","title":"Overcoming Quadratic Hardware Scaling for a Fully Connected Digital\n  Oscillatory Neural Network","summary":"Computing with coupled oscillators or oscillatory neural networks (ONNs) has\nrecently attracted a lot of interest due to their potential for massive\nparallelism and energy-efficient computing. However, to date, ONNs have\nprimarily been explored either analytically or through analog circuit\nimplementations. This paper shifts the focus to the digital implementation of\nONNs, examining various design architectures. We first report on an existing\ndigital ONN design based on a recurrent architecture. The major challenge for\nscaling such recurrent architectures is the quadratic increase in coupling\nhardware with the network size. To overcome this challenge, we introduce a\nnovel hybrid architecture that balances serialization and parallelism in the\ncoupling elements that shows near-linear hardware scaling, on the order of\nabout 1.2 with the network size. Furthermore, we evaluate the benefits and\ncosts of these different digital ONN architectures in terms time to solution\nand resource usage on FPGA emulation. The proposed hybrid architecture allows\nfor a 10.5$\\times$ increase in the number of oscillators while using 5-bits to\nrepresent the coupling weights and 4-bits to represent the oscillator phase on\na Zynq-7020 FPGA board. The near-linear scaling is a major step towards\nimplementing large scale ONN architectures. To the best of our knowledge, this\nwork presents the largest fully connected digital ONN architecture implemented\nthus far with a total of 506 fully connected oscillators.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-29T12:01:33Z"}
{"aid":"http://arxiv.org/abs/2504.20682v1","title":"OG-HFYOLO :Orientation gradient guidance and heterogeneous feature\n  fusion for deformation table cell instance segmentation","summary":"Table structure recognition is a key task in document analysis. However, the\ngeometric deformation in deformed tables causes a weak correlation between\ncontent information and structure, resulting in downstream tasks not being able\nto obtain accurate content information. To obtain fine-grained spatial\ncoordinates of cells, we propose the OG-HFYOLO model, which enhances the edge\nresponse by Gradient Orientation-aware Extractor, combines a Heterogeneous\nKernel Cross Fusion module and a scale-aware loss function to adapt to\nmulti-scale objective features, and introduces mask-driven non-maximal\nsuppression in the post-processing, which replaces the traditional bounding box\nsuppression mechanism. Furthermore, we also propose a data generator, filling\nthe gap in the dataset for fine-grained deformation table cell spatial\ncoordinate localization, and derive a large-scale dataset named Deformation\nWired Table (DWTAL). Experiments show that our proposed model demonstrates\nexcellent segmentation accuracy on all mainstream instance segmentation models.\nThe dataset and the source code are open source:\nhttps://github.com/justliulong/OGHFYOLO.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T12:02:01Z"}
{"aid":"http://arxiv.org/abs/2504.20696v1","title":"Simultaneous IM/DD Data Transmission and High-Rate Secret Key\n  Distribution over a Single C-band Channel","summary":"We demonstrate hierarchical multiscale PAM-4 transmission combining 500 Mbps\ndata transfer with optical-layer cryptographic key distribution at rates 24.14\nMbps and 8.38 Mbps secure against passive eavesdropper advantage 0 dB and 6 dB\nrespectively.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T12:21:23Z"}
{"aid":"http://arxiv.org/abs/2504.20700v1","title":"Building Trust in Healthcare with Privacy Techniques: Blockchain in the\n  Cloud","summary":"This study introduces a cutting-edge architecture developed for the\nNewbornTime project, which uses advanced AI to analyze video data at birth and\nduring newborn resuscitation, with the aim of improving newborn care. The\nproposed architecture addresses the crucial issues of patient consent, data\nsecurity, and investing trust in healthcare by integrating Ethereum blockchain\nwith cloud computing. Our blockchain-based consent application simplifies\npatient consent's secure and transparent management. We explain the smart\ncontract mechanisms and privacy measures employed, ensuring data protection\nwhile permitting controlled data sharing among authorized parties. This work\ndemonstrates the potential of combining blockchain and cloud technologies in\nhealthcare, emphasizing their role in maintaining data integrity, with\nimplications for computer science and healthcare innovation.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T12:31:37Z"}
{"aid":"http://arxiv.org/abs/2504.20704v1","title":"Asymptotic Fair Division: Chores Are Easier Than Goods","summary":"When dividing items among agents, two of the most widely studied fairness\nnotions are envy-freeness and proportionality. We consider a setting where $m$\nchores are allocated to $n$ agents and the disutility of each chore for each\nagent is drawn from a probability distribution. We show that an envy-free\nallocation exists with high probability provided that $m \\ge 2n$, and moreover,\n$m$ must be at least $n+\\Theta(n)$ in order for the existence to hold. On the\nother hand, we prove that a proportional allocation is likely to exist as long\nas $m = \\omega(1)$, and this threshold is asymptotically tight. Our results\nreveal a clear contrast with the allocation of goods, where a larger number of\nitems is necessary to ensure existence for both notions.","main_category":"cs.GT","categories":"cs.GT,math.PR","published":"2025-04-29T12:35:35Z"}
{"aid":"http://arxiv.org/abs/2504.20709v1","title":"Periodicity and local complexity of Delone sets","summary":"We study complexity and periodicity of Delone sets by applying an algebraic\napproach to multidimensional symbolic dynamics. In this algebraic approach,\n$\\mathbb{Z}^d$-configurations $c: \\mathbb{Z}^d \\to \\mathcal{A}$ for a finite\nset $\\mathcal{A} \\subseteq \\mathbb{C}$ and finite $\\mathbb{Z}^d$-patterns are\nregarded as formal power series and Laurent polynomials, respectively. In this\npaper we study also functions $c: \\mathbb{R}^d \\to \\mathcal{A}$ where\n$\\mathcal{A}$ is as above. These functions are called\n$\\mathbb{R}^d$-configurations. Any Delone set may be regarded as an\n$\\mathbb{R}^d$-configuration by simply presenting it as its indicator function.\nConversely, any $\\mathbb{R}^d$-configuration whose support (that is, the set of\ncells for which the configuration gets non-zero values) is a Delone set can be\nseen as a colored Delone set. We generalize the concept of annihilators and\nperiodizers of $\\mathbb{Z}^d$-configurations for $\\mathbb{R}^d$-configurations.\nWe show that if an $\\mathbb{R}^d$-configuration has a non-trivial annihilator,\nthat is, if a linear combination of some finitely many of its translations is\nthe zero function, then it has an annihilator of a particular form. Moreover,\nwe show that $\\mathbb{R}^d$-configurations with integer coefficients that have\nnon-trivial annihilators are sums of finitely many periodic functions\n$c_1,\\ldots,c_m: \\mathbb{R}^d \\to \\mathbb{Z}$. Also, $\\mathbb{R}^d$-pattern\ncomplexity is studied alongside with the classical patch-complexity of Delone\nsets. We point out the fact that sufficiently low $\\mathbb{R}^d$-pattern\ncomplexity of an $\\mathbb{R}^d$-configuration implies the existence of\nnon-trivial annihilators. Moreover, it is shown that if a Meyer set has\nsufficiently slow patch-complexity growth, then it has a non-trivial\nannihilator. Finally, a condition for forced periodicity of colored Delone sets\nof finite local complexity is provided.","main_category":"math.DS","categories":"math.DS,cs.DM,math.CO","published":"2025-04-29T12:41:01Z"}
{"aid":"http://arxiv.org/abs/2504.20724v1","title":"Multipolar Angular Scattering of Substrated Metasurfaces","summary":"Properly modeling and predicting the scattering response of a metasurface is\na particularly challenging task. This has been shown to be especially difficult\nif the metasurface supports both local and nonlocal interactions, in the form\nof lattice coupling effects, multipolar contributions or bianisotropic\nresponses. So far, existing methods to approach this problem have been\nrestricted to normal incidence in a homogeneous background medium. We overcome\nthese limitations by providing a rigorous and comprehensive formalism that\naccommodates both oblique incidence and the presence of different superstrate\nand substrate. This is achieved by extending our existing metasurface modeling\nframework to account for nonlocal and multipolar contributions up to the\noctupolar order and properly accounting for the scattering effects due to an\ninhomogeneous background medium. Additionally, our method is based on exact\nspherical multipole decomposition, which intrinsically accounts for toroidal\ncontributions. We demonstrate the effectiveness of our approach by modeling the\nresponse of several dielectric and plasmonic metasurfaces that exhibit sharp\nspectral features including bound states in the continuum. Overall, our\nformalism yields excellent agreement with full-wave simulations.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T13:03:42Z"}
{"aid":"http://arxiv.org/abs/2504.20742v1","title":"Non-Equilibrium Phase Changes in Aircraft Exhaust: A Computational Study\n  on Early Contrail Formation","summary":"A numerical framework is developed to model contrail formation in the\nnear-field exhaust of aircraft engines, resolving non-equilibrium phase\ntransitions in compressible, multi-component, non-ideal fluid flows. The\napproach combines well-established methods from steam turbine modeling for\nliquid-phase transitions with cloud microphysics models for ice formation. It\nresolves homogeneous and heterogeneous nucleation, interphase momentum\nexchange, and polydispersed size distributions of droplets, ice crystals, and\nsoot particles. These models are implemented in a parallelized finite-volume\nsolver and applied to a high-bypass turbofan exhaust configuration with\nsimplified geometry. Results indicate that non-equilibrium effects strongly\ninfluence condensation and freezing dynamics, while nozzle geometry and water\nvapor content modulate local supersaturation and phase transition pathways. The\nfindings underscore the limitations of equilibrium-based models and highlight\nthe value of physics-based, scalable tools for analyzing contrail formation\nacross fuels and propulsion systems.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.ao-ph,physics.comp-ph","published":"2025-04-29T13:24:24Z"}
{"aid":"http://arxiv.org/abs/2504.20750v1","title":"Limits of absolute vector magnetometry with NV centers in diamond","summary":"The nitrogen-vacancy (NV) center in diamond has become a widely used platform\nfor quantum sensing. The four NV axes in mono-crystalline diamond specifically\nallow for vector magnetometry, with magnetic-field sensitivities reaching down\nto $\\mathrm{fT}/ \\sqrt{\\mathrm{Hz}}$. The current literature primarily focuses\non improving the precision of NV-based magnetometers. Here, we study the\nexperimental accuracy of determining the magnetic field from measured\nspin-resonance frequencies via solving the NV Hamiltonian. We derive exact,\nanalytical, and fast-to-compute formulas for calculating resonance frequencies\nfrom a known magnetic-field vector, and vice versa, formulas for calculating\nthe magnetic-field vector from measured resonance frequencies. Additionally,\nthe accuracy of often-used approximations is assessed. Finally, we promote\nusing the Voigt profile as a fit model to determine the linewidth of measured\nresonances accurately. An open-source Python package accompanies our analysis.","main_category":"quant-ph","categories":"quant-ph,physics.data-an","published":"2025-04-29T13:32:09Z"}
{"aid":"http://arxiv.org/abs/2504.20760v1","title":"Flexible Perovskite/Silicon Monolithic Tandem Solar Cells Approaching\n  30% Efficiency","summary":"Thanks to their excellent properties of low cost, lightweight, portability,\nand conformity, flexible perovskite-based tandem solar cells show great\npotentials for energy harvesting applications, with flexible\nperovskite/c-silicon tandem solar cells particularly promising for achieving\nhigh efficiency. However, performance of flexible perovskite/c-silicon\nmonolithic tandem solar cells still greatly lags, due to challenges in\nsimultaneously achieving both efficient photocarrier transport and reliable\nmitigation of residual stress. Here, we reveal the critical role of perovskite\nphase homogeneity, for achieving high-efficient and mechanical-stable flexible\nperovskite/c-silicon heterojunction monolithic tandem solar cells (PSTs) with\ntextured surface. Through ensuring high phase homogeneity, which promotes\ncharge transfer across all facets of the pyramid on the textured substrates and\nreleases the residual stress at the perovskite/c-silicon interface, we\ndemonstrate flexible PSTs with a bending curvature of 0.44 cm-1, and a\ncertified power conversion efficiency of 29.88% (1.04 cm2 aperture area),\nsurpassing all other types of flexible perovskite-based photovoltaic devices.\nOur results can lead to broad applications and commercialization of flexible\nperovskite/c-silicon tandem photovoltaics.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-29T13:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.20761v1","title":"Confidence-based Intent Prediction for Teleoperation in Bimanual Robotic\n  Suturing","summary":"Robotic-assisted procedures offer enhanced precision, but while fully\nautonomous systems are limited in task knowledge, difficulties in modeling\nunstructured environments, and generalisation abilities, fully manual\nteleoperated systems also face challenges such as delay, stability, and reduced\nsensory information. To address these, we developed an interactive control\nstrategy that assists the human operator by predicting their motion plan at\nboth high and low levels. At the high level, a surgeme recognition system is\nemployed through a Transformer-based real-time gesture classification model to\ndynamically adapt to the operator's actions, while at the low level, a\nConfidence-based Intention Assimilation Controller adjusts robot actions based\non user intent and shared control paradigms. The system is built around a\nrobotic suturing task, supported by sensors that capture the kinematics of the\nrobot and task dynamics. Experiments across users with varying skill levels\ndemonstrated the effectiveness of the proposed approach, showing statistically\nsignificant improvements in task completion time and user satisfaction compared\nto traditional teleoperation.","main_category":"cs.RO","categories":"cs.RO,cs.HC","published":"2025-04-29T13:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.20766v1","title":"The specific heat anomaly stems from a third-order phase transition in\n  the 2D lattice sine-Gordon model","summary":"The specific heat anomaly (SHA) is broadly observed in statistical mechanics,\nappearing as a smooth, system-size-independent peak in the specific heat, in\ncontrast to the singular behavior typical of second-order phase transitions\n(PTs). Its origin remains heavily debated: some attribute it to finite-size\neffects, others to unidentified phase transitions. Here we investigate SHA\nusing the two-dimensional sine-Gordon (2D-sG) model and microcanonical\ninflection point analysis (MIPA), uncovering two key results. First, we show\nthat the roughening transition in the 2D-sG model is a genuine third-order PT\nunder MIPA, where the standard thermodynamic quantities remain continuous. This\nclarifies the ambiguity in the literature, where this transition was often,\nthough inconclusively, attributed to a Berezinskii-Kosterlitz-Thouless (BKT)\ntransition. Through the use of MIPA and a comprehensive analysis of standard\nthermodynamic observables, we provide a coherent thermodynamic characterization\nthat redefines the nature of this transition. Second, we find that the SHA is\nnot itself a PT but rather the thermodynamic fingerprint of this third-order\ntransition. These findings clarify the nature of SHA within the 2D-sG model and\nsuggest that similar anomalies in other systems, such as the XY model, may\nlikewise originate from third-order PTs, rather than mere crossovers. Our\nresults provide a consistent thermodynamic interpretation of the SHA and\nhighlight the broader relevance of third-order transitions in systems\npreviously thought to exhibit only low-order or crossover transition.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-29T13:45:47Z"}
{"aid":"http://arxiv.org/abs/2504.20770v1","title":"JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular\n  Generation","summary":"The discovery of new molecules based on the original chemical molecule\ndistributions is of great importance in medicine. The graph transformer, with\nits advantages of high performance and scalability compared to traditional\ngraph networks, has been widely explored in recent research for applications of\ngraph structures. However, current transformer-based graph decoders struggle to\neffectively utilize graph information, which limits their capacity to leverage\nonly sequences of nodes rather than the complex topological structures of\nmolecule graphs. This paper focuses on building a graph transformer-based\nframework for molecular generation, which we call \\textbf{JTreeformer} as it\ntransforms graph generation into junction tree generation. It combines GCN\nparallel with multi-head attention as the encoder. It integrates a directed\nacyclic GCN into a graph-based Transformer to serve as a decoder, which can\niteratively synthesize the entire molecule by leveraging information from the\npartially constructed molecular structure at each step. In addition, a\ndiffusion model is inserted in the latent space generated by the encoder, to\nenhance the efficiency and effectiveness of sampling further. The empirical\nresults demonstrate that our novel framework outperforms existing molecule\ngeneration methods, thus offering a promising tool to advance drug discovery\n(https://anonymous.4open.science/r/JTreeformer-C74C).","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-29T13:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.20772v1","title":"Hodge Decomposition and Potentials in Variable Exponent Lebesgue and\n  Sobolev Spaces","summary":"The objective of this work is to establish a systematic study of boundary\nvalue problems within the framework of differential forms and variable exponent\nspaces. Specifically, we investigate the Hodge Laplacian and related first\norder systems like the div-curl systems, Hodge-Dirac systems, and\nBogovskii-type problems in the context of variable exponent spaces. Our\napproach yields both existence theorems and elliptic estimates. These estimates\nprovide key results such as the Hodge decomposition theorem, Gaffney\ninequality, and gauge fixing. These findings are crucial for advancing the\nnonlinear theory related to problems involving differential forms.","main_category":"math.AP","categories":"math.AP","published":"2025-04-29T13:52:56Z"}
{"aid":"http://arxiv.org/abs/2504.20784v1","title":"Approximate Lifted Model Construction","summary":"Probabilistic relational models such as parametric factor graphs enable\nefficient (lifted) inference by exploiting the indistinguishability of objects.\nIn lifted inference, a representative of indistinguishable objects is used for\ncomputations. To obtain a relational (i.e., lifted) representation, the\nAdvanced Colour Passing (ACP) algorithm is the state of the art. The ACP\nalgorithm, however, requires underlying distributions, encoded as\npotential-based factorisations, to exactly match to identify and exploit\nindistinguishabilities. Hence, ACP is unsuitable for practical applications\nwhere potentials learned from data inevitably deviate even if associated\nobjects are indistinguishable. To mitigate this problem, we introduce the\n$\\varepsilon$-Advanced Colour Passing ($\\varepsilon$-ACP) algorithm, which\nallows for a deviation of potentials depending on a hyperparameter\n$\\varepsilon$. $\\varepsilon$-ACP efficiently uncovers and exploits\nindistinguishabilities that are not exact. We prove that the approximation\nerror induced by $\\varepsilon$-ACP is strictly bounded and our experiments show\nthat the approximation error is close to zero in practice.","main_category":"cs.AI","categories":"cs.AI,cs.DS,cs.LG","published":"2025-04-29T14:01:10Z"}
{"aid":"http://arxiv.org/abs/2504.20800v1","title":"Adept: Annotation-Denoising Auxiliary Tasks with Discrete Cosine\n  Transform Map and Keypoint for Human-Centric Pretraining","summary":"Human-centric perception is the core of diverse computer vision tasks and has\nbeen a long-standing research focus. However, previous research studied these\nhuman-centric tasks individually, whose performance is largely limited to the\nsize of the public task-specific datasets. Recent human-centric methods\nleverage the additional modalities, e.g., depth, to learn fine-grained semantic\ninformation, which limits the benefit of pretraining models due to their\nsensitivity to camera views and the scarcity of RGB-D data on the Internet.\nThis paper improves the data scalability of human-centric pretraining methods\nby discarding depth information and exploring semantic information of RGB\nimages in the frequency space by Discrete Cosine Transform (DCT). We further\npropose new annotation denoising auxiliary tasks with keypoints and DCT maps to\nenforce the RGB image extractor to learn fine-grained semantic information of\nhuman bodies. Our extensive experiments show that when pretrained on\nlarge-scale datasets (COCO and AIC datasets) without depth annotation, our\nmodel achieves better performance than state-of-the-art methods by +0.5 mAP on\nCOCO, +1.4 PCKh on MPII and -0.51 EPE on Human3.6M for pose estimation, by\n+4.50 mIoU on Human3.6M for human parsing, by -3.14 MAE on SHA and -0.07 MAE on\nSHB for crowd counting, by +1.1 F1 score on SHA and +0.8 F1 score on SHA for\ncrowd localization, and by +0.1 mAP on Market1501 and +0.8 mAP on MSMT for\nperson ReID. We also validate the effectiveness of our method on MPII+NTURGBD\ndatasets","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T14:14:29Z"}
{"aid":"http://arxiv.org/abs/2504.20807v1","title":"Semi-discrete optimal transport techniques for the compressible\n  semi-geostrophic equations","summary":"We prove existence of weak solutions of the 3D compressible semi-geostrophic\n(SG) equations with compactly supported measure-valued initial data. These\nequations model large-scale atmospheric flows. Our proof uses a particle\ndiscretisation and semi-discrete optimal transport techniques. We show that, if\nthe initial data is a discrete measure, then the compressible SG equations\nadmit a unique, twice continuously differentiable, energy-conserving and\nglobal-in-time solution. In general, by discretising the initial measure by\nparticles and sending the number of particles to infinity, we show that for any\ncompactly supported initial measure there exists a global-in-time solution of\nthe compressible SG equations that is Lipschitz in time. This significantly\ngeneralises the original results due to Cullen and Maroofi (2003), and it\nprovides the theoretical foundation for the design of numerical schemes using\nsemi-discrete optimal transport to solve the 3D compressible SG equations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-29T14:21:04Z"}
{"aid":"http://arxiv.org/abs/2504.20808v1","title":"SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from\n  Gameplay Recordings","summary":"This paper introduces SoccerDiffusion, a transformer-based diffusion model\ndesigned to learn end-to-end control policies for humanoid robot soccer\ndirectly from real-world gameplay recordings. Using data collected from RoboCup\ncompetitions, the model predicts joint command trajectories from multi-modal\nsensor inputs, including vision, proprioception, and game state. We employ a\ndistillation technique to enable real-time inference on embedded platforms that\nreduces the multi-step diffusion process to a single step. Our results\ndemonstrate the model's ability to replicate complex motion behaviors such as\nwalking, kicking, and fall recovery both in simulation and on physical robots.\nAlthough high-level tactical behavior remains limited, this work provides a\nrobust foundation for subsequent reinforcement learning or preference\noptimization methods. We release the dataset, pretrained models, and code\nunder: https://bit-bots.github.io/SoccerDiffusion","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-29T14:21:08Z"}
{"aid":"http://arxiv.org/abs/2504.20809v1","title":"Periodic Proprioceptive Stimuli Learning and Internal Model Development\n  for Avian-inspired Flapping-wing Flight State Estimation","summary":"This paper presents a novel learning-based approach for online state\nestimation in flapping wing aerial vehicles (FWAVs). Leveraging low-cost\nMagnetic, Angular Rate, and Gravity (MARG) sensors, the proposed method\neffectively mitigates the adverse effects of flapping-induced oscillations that\nchallenge conventional estimation techniques. By employing a divide-and-conquer\nstrategy grounded in cycle-averaged aerodynamics, the framework decouples the\nslow-varying components from the high-frequency oscillatory components, thereby\npreserving critical transient behaviors while delivering an smooth internal\nstate representation. The complete oscillatory state of FWAV can be\nreconstructed based on above two components, leading to substantial\nimprovements in accurate state prediction. Experimental validations on an\navian-inspired FWAV demonstrate that the estimator enhances accuracy and\nsmoothness, even under complex aerodynamic disturbances. These encouraging\nresults highlight the potential of learning algorithms to overcome issues of\nflapping-wing induced oscillation dynamics.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-29T14:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.20815v1","title":"A Teacher-Student MPC-PPO Coupled Reinforcement Learning Framework for\n  Winter Temperature Control of Solar Greenhouses in Northern China","summary":"Solar greenhouses are crucial infrastructure of modern agricultural\nproduction in northern China. However, highly fluctuating temperature in winter\nseason results in poor greenhouse temperature control, which affects crop\ngrowth and increases energy consumption. To tackle these challenges, an\nadvanced control system that can efficiently optimize multiple objectives under\ndramatic climate conditions is essential. Therefore, this study propose a model\npredictive control-coupled proximal policy optimization (MPC-PPO) control\nframework. A teacher-student control framework is constructed in which the MPC\ngenerating high-quality control experiences to guide the PPO agent's learning\nprocess. An adaptive dynamic weighting mechanism is employed to balance the\ninfluence of MPC experiences during PPO training. Evaluation conducted in solar\ngreenhouses across three provinces in northern China (Beijing, Hebei, and\nShandong) demonstrates that: (1) the MPC-PPO method achieved the highest\ntemperature control performance (96.31 on a 100-point scale), with a 5.46-point\nimprovement compared to the non-experience integration baseline, when reduced\nstandard deviation by nearly half and enhanced exploration efficiency; (2) the\nMPC-PPO method achieved a ventilation control reward of 99.19, optimizing\nventilation window operations with intelligent time-differentiated strategies\nthat reduced energy loss during non-optimal hours; (3) feature analysis reveals\nthat historical window opening, air temperature, and historical temperature are\nthe most influential features for effective control, i.e., SHAP values of\n7.449, 4.905, and 4.747 respectively; and (4) cross-regional tests indicated\nthat MPC-PPO performs best in all test regions, confirming generalization of\nthe method.","main_category":"math.OC","categories":"math.OC","published":"2025-04-29T14:32:40Z"}
{"aid":"http://arxiv.org/abs/2504.20825v1","title":"Numerical Relativity Simulations of Dark Matter Admixed Binary Neutron\n  Stars","summary":"Binary neutron star mergers provide insight into strong-field gravity and the\nproperties of ultra-dense nuclear matter. These events offer the potential to\nsearch for signatures of physics beyond the standard model, including dark\nmatter. We present the first numerical-relativity simulations of binary neutron\nstar mergers admixed with dark matter, based on constraint-solved initial data.\nModeling dark matter as a non-interacting fermionic gas, we investigate the\nimpact of varying dark matter fractions and particle masses on the merger\ndynamics, ejecta mass, post-merger remnant properties, and the emitted\ngravitational waves. Our simulations suggest that the dark matter morphology -\na dense core or a diluted halo - may alter the merger outcome. Scenarios with a\ndark matter core tend to exhibit a higher probability of prompt collapse, while\nthose with a dark matter halo develop a common envelope, embedding the whole\nbinary. Furthermore, gravitational wave signals from mergers with dark matter\nhalo configurations exhibit significant deviations from standard models when\nthe tidal deformability is calculated in a two-fluid framework. This highlights\nthe need for refined models in calculating the tidal deformability when\nconsidering mergers with extended dark matter structures. These initial results\nprovide a basis for further exploration of dark matter's role in binary neutron\nstar mergers and their associated gravitational wave emission and can serve as\na benchmark for future observations from advanced detectors and multi-messenger\nastrophysics.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-29T14:46:04Z"}
{"aid":"http://arxiv.org/abs/2504.20829v1","title":"GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for\n  Targeted Scene Confusion","summary":"As 3D Gaussian Splatting (3DGS) emerges as a breakthrough in scene\nrepresentation and novel view synthesis, its rapid adoption in safety-critical\ndomains (e.g., autonomous systems, AR/VR) urgently demands scrutiny of\npotential security vulnerabilities. This paper presents the first systematic\nstudy of backdoor threats in 3DGS pipelines. We identify that adversaries may\nimplant backdoor views to induce malicious scene confusion during inference,\npotentially leading to environmental misperception in autonomous navigation or\nspatial distortion in immersive environments. To uncover this risk, we propose\nGuassTrap, a novel poisoning attack method targeting 3DGS models. GuassTrap\ninjects malicious views at specific attack viewpoints while preserving\nhigh-quality rendering in non-target views, ensuring minimal detectability and\nmaximizing potential harm. Specifically, the proposed method consists of a\nthree-stage pipeline (attack, stabilization, and normal training) to implant\nstealthy, viewpoint-consistent poisoned renderings in 3DGS, jointly optimizing\nattack efficacy and perceptual realism to expose security risks in 3D\nrendering. Extensive experiments on both synthetic and real-world datasets\ndemonstrate that GuassTrap can effectively embed imperceptible yet harmful\nbackdoor views while maintaining high-quality rendering in normal views,\nvalidating its robustness, adaptability, and practical applicability.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-29T14:52:14Z"}
{"aid":"http://arxiv.org/abs/2504.20830v1","title":"CMT: A Cascade MAR with Topology Predictor for Multimodal Conditional\n  CAD Generation","summary":"While accurate and user-friendly Computer-Aided Design (CAD) is crucial for\nindustrial design and manufacturing, existing methods still struggle to achieve\nthis due to their over-simplified representations or architectures incapable of\nsupporting multimodal design requirements. In this paper, we attempt to tackle\nthis problem from both methods and datasets aspects. First, we propose a\ncascade MAR with topology predictor (CMT), the first multimodal framework for\nCAD generation based on Boundary Representation (B-Rep). Specifically, the\ncascade MAR can effectively capture the ``edge-counters-surface'' priors that\nare essential in B-Reps, while the topology predictor directly estimates\ntopology in B-Reps from the compact tokens in MAR. Second, to facilitate\nlarge-scale training, we develop a large-scale multimodal CAD dataset, mmABC,\nwhich includes over 1.3 million B-Rep models with multimodal annotations,\nincluding point clouds, text descriptions, and multi-view images. Extensive\nexperiments show the superior of CMT in both conditional and unconditional CAD\ngeneration tasks. For example, we improve Coverage and Valid ratio by +10.68%\nand +10.3%, respectively, compared to state-of-the-art methods on ABC in\nunconditional generation. CMT also improves +4.01 Chamfer on image conditioned\nCAD generation on mmABC. The dataset, code and pretrained network shall be\nreleased.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T14:52:28Z"}
{"aid":"http://arxiv.org/abs/2504.20831v1","title":"Field energy and angular momentum in spontaneous emission: A\n  Schrödinger-picture approach","summary":"A Schr\\\"odinger-picture approach is used to calculate the field energy and\nangular momentum radiated by an atom undergoing spontaneous emission. The\ncalculation is carried out using both the rotating-wave approximation (RWA) and\nWeisskopf-Wigner approximation (WWA). It is shown that a consistent application\nof the WWA leads to expressions for both the energy and angular momentum in the\nfield that are finite for all times, in contrast to the results for a classical\npoint dipole oscillator. Moreover, it is shown that the total angular momentum\nin the field is a sum of its spin and orbital components, again in contrast to\nthe analogous results for a classical point dipole oscillator. Analytic\nexpressions for the energy, spin angular momentum, and orbital angular momentum\nin the field are obtained for an atom undergoing spontaneous emission from a\nstate having angular momentum H to a state having angular momentum G via an\nelectric dipole transition. It is shown that the spin and orbital angular\nmomenta in the field are equal, independent of the values of H and G. With a\nslight modification of the WWA, it can also be shown that the energy density in\nthe field, the Poynting vector of the field, and the angular momentum flux of\nthe field do not diverge at the origin.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T14:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.20858v1","title":"Chaos Meets Attention: Transformers for Large-Scale Dynamical Prediction","summary":"Generating long-term trajectories of dissipative chaotic systems\nautoregressively is a highly challenging task. The inherent positive Lyapunov\nexponents amplify prediction errors over time. Many chaotic systems possess a\ncrucial property - ergodicity on their attractors, which makes long-term\nprediction possible. State-of-the-art methods address ergodicity by preserving\nstatistical properties using optimal transport techniques. However, these\nmethods face scalability challenges due to the curse of dimensionality when\nmatching distributions. To overcome this bottleneck, we propose a scalable\ntransformer-based framework capable of stably generating long-term\nhigh-dimensional and high-resolution chaotic dynamics while preserving\nergodicity. Our method is grounded in a physical perspective, revisiting the\nVon Neumann mean ergodic theorem to ensure the preservation of long-term\nstatistics in the $\\mathcal{L}^2$ space. We introduce novel modifications to\nthe attention mechanism, making the transformer architecture well-suited for\nlearning large-scale chaotic systems. Compared to operator-based and\ntransformer-based methods, our model achieves better performances across five\nmetrics, from short-term prediction accuracy to long-term statistics. In\naddition to our methodological contributions, we introduce a new chaotic system\nbenchmark: a machine learning dataset of 140$k$ snapshots of turbulent channel\nflow along with various evaluation metrics for both short- and long-term\nperformances, which is well-suited for machine learning research on chaotic\nsystems.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-29T15:32:36Z"}
{"aid":"http://arxiv.org/abs/2504.20870v1","title":"Capacity Formulas for the Lossy Bosonic Compound Wiretap Channel","summary":"We consider the bosonic compound wiretap channel. A pair of lossy channels\nconnects a sender with both a (legitimate) receiver and an eavesdropper. The\nsender and receiver have only partial information about the actual state of the\nchannels. In this situation, their task is to transmit the maximum amount of\nmessages over an asymptotically large number of uses of their channel while\nguaranteeing at the same time that only an (asymptotically) negligible amount\nof information leaks to the eavesdropper. We prove capacity formulas for the\ncase where both sender and receiver have the same information about the system\nand for the case where the sender has channel state information.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T15:43:18Z"}
{"aid":"http://arxiv.org/abs/2504.20872v1","title":"FLIM-based Salient Object Detection Networks with Adaptive Decoders","summary":"Salient Object Detection (SOD) methods can locate objects that stand out in\nan image, assign higher values to their pixels in a saliency map, and binarize\nthe map outputting a predicted segmentation mask. A recent tendency is to\ninvestigate pre-trained lightweight models rather than deep neural networks in\nSOD tasks, coping with applications under limited computational resources. In\nthis context, we have investigated lightweight networks using a methodology\nnamed Feature Learning from Image Markers (FLIM), which assumes that the\nencoder's kernels can be estimated from marker pixels on discriminative regions\nof a few representative images. This work proposes flyweight networks, hundreds\nof times lighter than lightweight models, for SOD by combining a FLIM encoder\nwith an adaptive decoder, whose weights are estimated for each input image by a\ngiven heuristic function. Such FLIM networks are trained from three to four\nrepresentative images only and without backpropagation, making the models\nsuitable for applications under labeled data constraints as well. We study five\nadaptive decoders; two of them are introduced here. Differently from the\nprevious ones that rely on one neuron per pixel with shared weights, the\nheuristic functions of the new adaptive decoders estimate the weights of each\nneuron per pixel. We compare FLIM models with adaptive decoders for two\nchallenging SOD tasks with three lightweight networks from the\nstate-of-the-art, two FLIM networks with decoders trained by backpropagation,\nand one FLIM network whose labeled markers define the decoder's weights. The\nexperiments demonstrate the advantages of the proposed networks over the\nbaselines, revealing the importance of further investigating such methods in\nnew applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T15:44:02Z"}
{"aid":"http://arxiv.org/abs/2504.20891v1","title":"Mesoscopic Quantum Dynamics and Bosonization of Noise","summary":"Quantum systems that interact non-locally with an environment (or bath) serve\nas paradigms for exploring collective phenomena. These systems naturally arise\nin physical setups featuring long-range many-body interactions, and are\nexperimentally realized in platforms such as Rydberg atom arrays, cold atoms in\noptical cavities, ion traps, and dipolar systems. They hold broad potential for\napplications in quantum computing and quantum sensing. In this work, we reveal\nan exact theoretical mechanism governing such non-locally and mesoscopically\ncoupled systems. We demonstrate that the effect of general environments on the\nsystem exhibits a universal bosonic character. Specifically, the exact effect\nthat environments have on the system, regardless of their microscopic details,\nis equivalently produced by the interaction with a reservoir of non-interacting\nbosonic modes. The emergent 'bosonization' of the environment results from the\nmesoscopic coupling in the thermodynamic limit and can be interpreted as a\nmanifestation of the central limit theorem. While this effect has been observed\nin specific models before, we show that it is, in fact, a universal feature.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-29T16:07:44Z"}
{"aid":"http://arxiv.org/abs/2504.20894v1","title":"Does Feedback Help in Bandits with Arm Erasures?","summary":"We study a distributed multi-armed bandit (MAB) problem over arm erasure\nchannels, motivated by the increasing adoption of MAB algorithms over\ncommunication-constrained networks. In this setup, the learner communicates the\nchosen arm to play to an agent over an erasure channel with probability\n$\\epsilon \\in [0,1)$; if an erasure occurs, the agent continues pulling the\nlast successfully received arm; the learner always observes the reward of the\narm pulled. In past work, we considered the case where the agent cannot convey\nfeedback to the learner, and thus the learner does not know whether the arm\nplayed is the requested or the last successfully received one. In this paper,\nwe instead consider the case where the agent can send feedback to the learner\non whether the arm request was received, and thus the learner exactly knows\nwhich arm was played. Surprisingly, we prove that erasure feedback does not\nimprove the worst-case regret upper bound order over the previously studied\nno-feedback setting. In particular, we prove a regret lower bound of\n$\\Omega(\\sqrt{KT} + K / (1 - \\epsilon))$, where $K$ is the number of arms and\n$T$ the time horizon, that matches no-feedback upper bounds up to logarithmic\nfactors. We note however that the availability of feedback enables simpler\nalgorithm designs that may achieve better constants (albeit not better order)\nregret bounds; we design one such algorithm and evaluate its performance\nnumerically.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-29T16:10:05Z"}
{"aid":"http://arxiv.org/abs/2504.20895v1","title":"Almgren's Three-Legged Starfish","summary":"In this note we use classical tools from min-max and hyperbolic geometry to\nsubstantiate a folklore example in Almgren--Pitts min-max theory, the\nthree-legged starfish metric on a 2-sphere, whose systolic length,\nAlmgren--Pitts width, and Gromov--Guth width are attained by ``figure-eight''\ngeodesics. We also recover a hyperbolic geometry fact about ``figure-eight''\ngeodesics using min-max.","main_category":"math.DG","categories":"math.DG","published":"2025-04-29T16:13:40Z"}
{"aid":"http://arxiv.org/abs/2504.20898v1","title":"CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report\n  Generation with Multi-Agent RAG and Concept Bottleneck Models","summary":"Advancements in generative Artificial Intelligence (AI) hold great promise\nfor automating radiology workflows, yet challenges in interpretability and\nreliability hinder clinical adoption. This paper presents an automated\nradiology report generation framework that combines Concept Bottleneck Models\n(CBMs) with a Multi-Agent Retrieval-Augmented Generation (RAG) system to bridge\nAI performance with clinical explainability. CBMs map chest X-ray features to\nhuman-understandable clinical concepts, enabling transparent disease\nclassification. Meanwhile, the RAG system integrates multi-agent collaboration\nand external knowledge to produce contextually rich, evidence-based reports.\nOur demonstration showcases the system's ability to deliver interpretable\npredictions, mitigate hallucinations, and generate high-quality, tailored\nreports with an interactive interface addressing accuracy, trust, and usability\nchallenges. This framework provides a pathway to improving diagnostic\nconsistency and empowering radiologists with actionable insights.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.IR","published":"2025-04-29T16:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.20903v1","title":"Modeling AI-Human Collaboration as a Multi-Agent Adaptation","summary":"We develop an agent-based simulation to formalize AI-human collaboration as a\nfunction of task structure, advancing a generalizable framework for strategic\ndecision-making in organizations. Distinguishing between heuristic-based human\nadaptation and rule-based AI search, we model interactions across modular\n(parallel) and sequenced (interdependent) tasks using an NK model. Our results\nreveal that in modular tasks, AI often substitutes for humans - delivering\nhigher payoffs unless human expertise is very high, and the AI search space is\neither narrowly focused or extremely broad. In sequenced tasks, interesting\ncomplementarities emerge. When an expert human initiates the search and AI\nsubsequently refines it, aggregate performance is maximized. Conversely, when\nAI leads, excessive heuristic refinement by the human can reduce payoffs. We\nalso show that even \"hallucinatory\" AI - lacking memory or structure - can\nimprove outcomes when augmenting low-capability humans by helping escape local\noptima. These results yield a robust implication: the effectiveness of AI-human\ncollaboration depends less on context or industry, and more on the underlying\ntask structure. By elevating task decomposition as the central unit of\nanalysis, our model provides a transferable lens for strategic decision-making\ninvolving humans and an agentic AI across diverse organizational settings.","main_category":"cs.MA","categories":"cs.MA,cs.AI,cs.HC","published":"2025-04-29T16:19:53Z"}
{"aid":"http://arxiv.org/abs/2504.20908v1","title":"MOSIC: Model-Agnostic Optimal Subgroup Identification with\n  Multi-Constraint for Improved Reliability","summary":"Identifying subgroups that benefit from specific treatments using\nobservational data is a critical challenge in personalized medicine. Most\nexisting approaches solely focus on identifying a subgroup with an improved\ntreatment effect. However, practical considerations, such as ensuring a minimum\nsubgroup size for representativeness or achieving sufficient confounder balance\nfor reliability, are also important for making findings clinically meaningful\nand actionable. While some studies address these constraints individually, none\noffer a unified approach to handle them simultaneously. To bridge this gap, we\npropose a model-agnostic framework for optimal subgroup identification under\nmultiple constraints. We reformulate this combinatorial problem as an\nunconstrained min-max optimization problem with novel modifications and solve\nit by a gradient descent ascent algorithm. We further prove its convergence to\na feasible and locally optimal solution. Our method is stable and highly\nflexible, supporting various models and techniques for estimating and\noptimizing treatment effectiveness with observational data. Extensive\nexperiments on both synthetic and real-world datasets demonstrate its\neffectiveness in identifying subgroups that satisfy multiple constraints,\nachieving higher treatment effects and better confounder balancing results\nacross different group sizes.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T16:25:23Z"}
{"aid":"http://arxiv.org/abs/2504.20909v1","title":"Bayesian and Statistical Analysis of the Open Star Cluster NGC 6416","summary":"In our Bayesian and Statistical Analysis investigation of the open cluster\nNGC 6416, we utilized Gaia EDR3 astrometry data and ensemble-based unsupervised\nmachine learning techniques to identify 406 cluster members. Using the MESA\nIsochrones and Stellar Tracks (MIST) with Gaia EDR3 data, we determined the\nfollowing parameters for NGC 6416: a distance of approximately 1021pc, an age\nof about $12.58\\pm 0.1$ Myr, a metallicity (z) of roughly $0.032\\pm0.0015$, a\nbinarity fraction near $0.419\\pm0.021$, and an extinction ($A_V$) of\napproximately $0.995\\pm0.058$ mag for an $R_V$ value of around $3.064\\pm0.102$.\nWe also fitted the radial surface density profile and conducted orbit analysis\nof the cluster using galpy. And finally found that the star formation scenarios\nare not observed in the open star cluster NGC 6416.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-29T16:25:56Z"}
{"aid":"http://arxiv.org/abs/2504.20911v1","title":"An Empirical Study on the Capability of LLMs in Decomposing Bug Reports","summary":"Background: Bug reports are essential to the software development life cycle.\nThey help developers track and resolve issues, but are often difficult to\nprocess due to their complexity, which can delay resolution and affect software\nquality. Aims: This study investigates whether large language models (LLMs) can\nassist developers in automatically decomposing complex bug reports into\nsmaller, self-contained units, making them easier to understand and address.\nMethod: We conducted an empirical study on 127 resolved privacy-related bug\nreports collected from Apache Jira. We evaluated ChatGPT and DeepSeek using\ndifferent prompting strategies. We first tested both LLMs with zero-shot\nprompts, then applied improved prompts with demonstrations (using few-shot\nprompting) to measure their abilities in bug decomposition. Results: Our\nfindings show that LLMs are capable of decomposing bug reports, but their\noverall performance still requires further improvement and strongly depends on\nthe quality of the prompts. With zero-shot prompts, both studied LLMs (ChatGPT\nand DeepSeek) performed poorly. After prompt tuning, ChatGPT's true\ndecomposition rate increased by 140\\% and DeepSeek's by 163.64\\%. Conclusions:\nLLMs show potential in helping developers analyze and decompose complex bug\nreports, but they still need improvement in terms of accuracy and bug\nunderstanding.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-29T16:29:12Z"}
{"aid":"http://arxiv.org/abs/2504.20915v1","title":"Statistical and Predictive Analysis to Identify Risk Factors and Effects\n  of Post COVID-19 Syndrome","summary":"Based on recent studies, some COVID-19 symptoms can persist for months after\ninfection, leading to what is termed long COVID. Factors such as vaccination\ntiming, patient characteristics, and symptoms during the acute phase of\ninfection may contribute to the prolonged effects and intensity of long COVID.\nEach patient, based on their unique combination of factors, develops a specific\nrisk or intensity of long COVID. In this work, we aim to achieve two\nobjectives: (1) conduct a statistical analysis to identify relationships\nbetween various factors and long COVID, and (2) perform predictive analysis of\nlong COVID intensity using these factors. We benchmark and interpret various\ndata-driven approaches, including linear models, random forests, gradient\nboosting, and neural networks, using data from the Lifelines COVID-19 cohort.\nOur results show that Neural Networks (NN) achieve the best performance in\nterms of MAPE, with predictions averaging 19\\% error. Additionally,\ninterpretability analysis reveals key factors such as loss of smell, headache,\nmuscle pain, and vaccination timing as significant predictors, while chronic\ndisease and gender are critical risk factors. These insights provide valuable\nguidance for understanding long COVID and developing targeted interventions.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T16:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.20916v1","title":"A generalization of Ramanujan's sum over finite groups","summary":"Let $G$ be a finite group, and let $x \\in G$. Denote by $\\langle x^G \\rangle$\nthe normal subgroup of $G$ generated by the conjugacy class of $x$, and define\n$[x^G] := \\{ y \\in G : \\langle x^G \\rangle = \\langle y^G \\rangle \\}$. For any\nirreducible character $\\chi$ of $G$, we define the character sum \\begin{align}\nC_{\\chi}(x):= \\frac{1}{\\chi(\\textbf{1})} \\sum_{s \\in [x^G]} \\chi(s),\\nonumber\n\\end{align} where $\\textbf{1}$ is the identity of $G$. In 1979, Babai proved\nthat $C_{\\chi}(x)$ is an eigenvalue of the Cayley graph $\\text{Cay}(G, [x^G])$.\nWhen $G$ is a finite cyclic group and $x$ is a generator, this sum coincides\nwith the classical Ramanujan sum. Thus, $C_{\\chi}(x)$ can be viewed as a\ngeneralization of the Ramanujan sum to arbitrary finite groups. A well-known\nformula for the classical Ramanujan sum involves the M$\\ddot{\\text{o}}$bius\nfunction and Euler's phi function. In this work, we derive an explicit formula\nfor the character sum $C_{\\chi}(x)$, which extends the formula of classical\nRamanujan sum to the context of finite groups. This generalization not only\nenrich the theory of Ramanujan's sum but also provide new tools in spectral\ngraph theory, representation theory, and algebraic number theory.","main_category":"math.NT","categories":"math.NT,math.CO","published":"2025-04-29T16:35:01Z"}
{"aid":"http://arxiv.org/abs/2504.20941v1","title":"Conformal-DP: Differential Privacy on Riemannian Manifolds via Conformal\n  Transformation","summary":"Differential Privacy (DP) has been established as a safeguard for private\ndata sharing by adding perturbations to information release. Prior research on\nDP has extended beyond data in the flat Euclidean space and addressed data on\ncurved manifolds, e.g., diffusion tensor MRI, social networks, or organ shape\nanalysis, by adding perturbations along geodesic distances. However, existing\nmanifold-aware DP methods rely on the assumption that samples are uniformly\ndistributed across the manifold. In reality, data densities vary, leading to a\nbiased noise imbalance across manifold regions, weakening the privacy-utility\ntrade-offs. To address this gap, we propose a novel mechanism: Conformal-DP,\nutilizing conformal transformations on the Riemannian manifold to equalize\nlocal sample density and to redefine geodesic distances accordingly while\npreserving the intrinsic geometry of the manifold. Our theoretical analysis\nyields two main results. First, we prove that the conformal factor computed\nfrom local kernel-density estimates is explicitly data-density-aware; Second,\nunder the conformal metric, the mechanism satisfies $ \\varepsilon\n$-differential privacy on any complete Riemannian manifold and admits a\nclosed-form upper bound on the expected geodesic error that depends only on the\nmaximal density ratio, not on global curvatureof the manifold. Our experimental\nresults validate that the mechanism achieves high utility while providing the $\n\\varepsilon $-DP guarantee for both homogeneous and especially heterogeneous\nmanifold data.","main_category":"cs.CR","categories":"cs.CR,math.DG,stat.OT","published":"2025-04-29T17:05:55Z"}
{"aid":"http://arxiv.org/abs/2504.20944v1","title":"Deep Learning Characterizes Depression and Suicidal Ideation from Eye\n  Movements","summary":"Identifying physiological and behavioral markers for mental health conditions\nis a longstanding challenge in psychiatry. Depression and suicidal ideation, in\nparticular, lack objective biomarkers, with screening and diagnosis primarily\nrelying on self-reports and clinical interviews. Here, we investigate eye\ntracking as a potential marker modality for screening purposes. Eye movements\nare directly modulated by neuronal networks and have been associated with\nattentional and mood-related patterns; however, their predictive value for\ndepression and suicidality remains unclear. We recorded eye-tracking sequences\nfrom 126 young adults as they read and responded to affective sentences, and\nsubsequently developed a deep learning framework to predict their clinical\nstatus. The proposed model included separate branches for trials of positive\nand negative sentiment, and used 2D time-series representations to account for\nboth intra-trial and inter-trial variations. We were able to identify\ndepression and suicidal ideation with an area under the receiver operating\ncurve (AUC) of 0.793 (95% CI: 0.765-0.819) against healthy controls, and\nsuicidality specifically with 0.826 AUC (95% CI: 0.797-0.852). The model also\nexhibited moderate, yet significant, accuracy in differentiating depressed from\nsuicidal participants, with 0.609 AUC (95% CI 0.571-0.646). Discriminative\npatterns emerge more strongly when assessing the data relative to response\ngeneration than relative to the onset time of the final word of the sentences.\nThe most pronounced effects were observed for negative-sentiment sentences,\nthat are congruent to depressed and suicidal participants. Our findings\nhighlight eye tracking as an objective tool for mental health assessment and\nunderscore the modulatory impact of emotional stimuli on cognitive processes\naffecting oculomotor control.","main_category":"cs.LG","categories":"cs.LG,eess.SP","published":"2025-04-29T17:11:13Z"}
{"aid":"http://arxiv.org/abs/2504.20949v1","title":"Prekosmic Grothendieck/Galois Categories","summary":"We establish a generalized version of the duality between groups and the\ncategories of their representations on sets. Given an abstract symmetric\nmonoidal category $K$ called Galois prekosmos, we define pre-Galois objects in\n$K$ and study the categories of their representations internal to $K$. The\nmotivating example of $K$ is the cartesian monoidal category $\\textit{Set}$ of\nsets, and pre-Galois objects in $\\textit{Set}$ are groups. We present an\naxiomatic definition of pre-Galois $K$-categories, which is a complete abstract\ncharacterization of the categories of representations of pre-Galois objects in\n$K$. The category of covering spaces over a well-connected topological space is\na prototype of a pre-Galois $\\textit{Set}$-category. We establish a perfect\ncorrespondence between pre-Galois objects in $K$ and pre-Galois $K$-categories\npointed with pre-fiber functors.\n  We also establish a generalized version of the duality between flat affine\ngroup schemes and the categories of their linear representations. Given an\nabstract symmetric monoidal category $K$ called Grothendieck prekosmos, we\ndefine what are pre-Grothendieck objects in $K$ and study the categories of\ntheir representations internal to $K$. The motivating example of $K$ is the\nsymmetric monoidal category $\\textit{Vec}_k$ of vector spaces over a field $k$,\nand pre-Grothendieck objects in $\\textit{Vec}_k$ are affine group $k$-schemes.\nWe present an axiomatic definition of pre-Grothendieck $K$-categories, which is\na complete abstract characterization of the categories of representations of\npre-Grothendieck objects in $K$. The indization of a neutral Tannakian category\nover a field $k$ is a prototype of a pre-Grothendieck\n$\\textit{Vec}_k$-category. We establish a perfect correspondence between\npre-Grothendieck objects in $K$ and pre-Grothendieck $K$-categories pointed\nwith pre-fiber functors.","main_category":"math.AG","categories":"math.AG","published":"2025-04-29T17:15:40Z"}
{"aid":"http://arxiv.org/abs/2504.20951v1","title":"Information Gravity: A Field-Theoretic Model for Token Selection in\n  Large Language Models","summary":"We propose a theoretical model called \"information gravity\" to describe the\ntext generation process in large language models (LLMs). The model uses\nphysical apparatus from field theory and spacetime geometry to formalize the\ninteraction between user queries and the probability distribution of generated\ntokens. A query is viewed as an object with \"information mass\" that curves the\nsemantic space of the model, creating gravitational potential wells that\n\"attract\" tokens during generation. This model offers a mechanism to explain\nseveral observed phenomena in LLM behavior, including hallucinations (emerging\nfrom low-density semantic voids), sensitivity to query formulation (due to\nsemantic field curvature changes), and the influence of sampling temperature on\noutput diversity.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T17:21:20Z"}
{"aid":"http://arxiv.org/abs/2504.20953v1","title":"Optimal Local Simulations of a Quantum Singlet","summary":"Bell's seminal work showed that no local hidden variable (LHV) model can\nfully reproduce the quantum correlations of a two-qubit singlet state. His\nargument and later developments by Clauser et al. effectively rely on gaps\nbetween the anticorrelations achievable by classical models and quantum theory\nfor projective measurements along randomly chosen axes separated by a fixed\nangle. However, the size of these gaps has to date remained unknown. Here we\nnumerically determine the LHV models maximizing anticorrelations for random\naxes separated by any fixed angle, by mapping the problem onto ground state\nconfigurations of fixed-range spin models. We identify angles where this gap is\nlargest and thus best suited for Bell tests. These findings enrich the\nunderstanding of Bell non-locality as a physical resource in quantum\ninformation theory and quantum cryptography.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T17:24:32Z"}
{"aid":"http://arxiv.org/abs/2504.20963v1","title":"Exponential moments of truncated branching random walk martingales","summary":"For a branching random walk that drifts to infinity, consider its Malthusian\nmartingale, i.e.~the additive martingale with parameter $\\theta$ being the\nsmallest root of the characteristic equation. When particles are killed below\nthe origin, we show that the limit of this martingale admits an exponential\ntail, contrary to the case without killing, where the tail is polynomial. In\nthe critical case, where the characteristic equation has a single root, the\nsame holds for the (truncated) derivative martingale, as we show. This study is\nmotivated by recent work on first passage percolation on Erd\\H{o}s-R\\'enyi\ngraphs.","main_category":"math.PR","categories":"math.PR","published":"2025-04-29T17:32:43Z"}
{"aid":"http://arxiv.org/abs/2504.20967v1","title":"Trapezodial property of the generalized Alexander polynomial","summary":"Fox's conjecture from 1962, that the absolute values of the coefficients of\nthe Alexander polynomial of an alternating link are trapezoidal, has remained\nstubbornly open to this date. Recently Fox's conjecture was settled for all\nspecial alternating links. In this paper we take a broad view of the Alexander\npolynomials of special alternating links, showing that they are a generating\nfunction for a statistic on certain vector configurations. We study three types\nof vector configurations: (1) vectors arising from cographic matroids, (2)\nvectors arising from graphic matroids, (3) vectors arising from totally\npositive matrices. We prove that Alexander polynomials of special alternating\nlinks belong to both classes (1) and (2), and prove log-concavity, respectively\ntrapezoidal, properties for classes (2) and (3). As a special case of our\nresults, we obtain a new proof of Fox's conjecture for special alternating\nlinks.","main_category":"math.CO","categories":"math.CO,math.GT","published":"2025-04-29T17:37:31Z"}
{"aid":"http://arxiv.org/abs/2504.20968v1","title":"The Redei-Berge function in noncommuting variables","summary":"Recently, Stanley and Grinberg introduced a symmetric function associated to\ndigraphs, called the Redei-Berge symmetric function. This function, however,\ndoes not satisfy the deletion-contraction property, which is a very powerful\ntool for proving various identities using induction. In this paper, we\nintroduce an analogue of this function in noncommuting variables which does\nhave such property. Furthermore, it specializes to the ordinary Redei-Berge\nfunction when the variables are allowed to commute. This modification allows us\nto further generalize properties that are already proved for the original\nfunction and to deduce many new ones.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T17:37:44Z"}
{"aid":"http://arxiv.org/abs/2504.20974v1","title":"Equivariant non-linear maps for neural networks on homogeneous spaces","summary":"This paper presents a novel framework for non-linear equivariant neural\nnetwork layers on homogeneous spaces. The seminal work of Cohen et al. on\nequivariant $G$-CNNs on homogeneous spaces characterized the representation\ntheory of such layers in the linear setting, finding that they are given by\nconvolutions with kernels satisfying so-called steerability constraints.\nMotivated by the empirical success of non-linear layers, such as self-attention\nor input dependent kernels, we set out to generalize these insights to the\nnon-linear setting. We derive generalized steerability constraints that any\nsuch layer needs to satisfy and prove the universality of our construction. The\ninsights gained into the symmetry-constrained functional dependence of\nequivariant operators on feature maps and group elements informs the design of\nfuture equivariant neural network layers. We demonstrate how several common\nequivariant network architectures - $G$-CNNs, implicit steerable kernel\nnetworks, conventional and relative position embedded attention based\ntransformers, and LieTransformers - may be derived from our framework.","main_category":"cs.LG","categories":"cs.LG,math.RT,stat.ML","published":"2025-04-29T17:42:56Z"}
{"aid":"http://arxiv.org/abs/2504.20977v1","title":"Integral of the double-emission eikonal function for a massive and a\n  massless emitter at an arbitrary angle","summary":"We present an analytic calculation of the integrated double-emission eikonal\nfunction of a massive and a massless emitter whose momenta are at an arbitrary\nangle to each other. This quantity provides one of the required ingredients for\nextending the nested soft-collinear subtraction scheme to processes with\nmassive final-state particles. To calculate it, we use the standard methodology\ninvolving reverse unitarity and its extension to cases with Heaviside\nfunctions, integration-by-parts technology and reduction to master integrals,\nand differential equations. In addition, we also describe a semi-numerical\nmethod based on the subtraction of infra-red and collinear singularities from\nthe eikonal function, allowing us to extract divergences of the integrated\neikonal function analytically, and to derive a simple integral representation\nfor the finite remainder.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-29T17:48:17Z"}
{"aid":"http://arxiv.org/abs/2504.20979v1","title":"A Complete Characterization of Passive Unitary Normalizable (PUN)\n  Gaussian States","summary":"We provide a complete characterization of the class of multimode quantum\nGaussian states that can be reduced to a tensor product of thermal states using\nonly a passive unitary operator. We call these states \\textit{passive unitary\nnormalizable} (PUN) Gaussian states. The characterization of PUN Gaussian\nstates is given in three different ways: $(i)$ in terms of their covariance\nmatrices, $(ii)$ using gauge-invariance (a special class of Glauber--Sudarshan\n$p$-functions), and $(iii)$ with respect to the recently obtained $(A,\\Lambda)$\nparametrization of Gaussian states in [J. Math. Phys. 62, 022102 (2021)]. In\nterms of the covariance matrix, our characterization states that an $n$-mode\nquantum Gaussian state is PUN if and only if its $2n\\times 2n$ quantum\ncovariance matrix $S$ commutes with the standard symplectic matrix $J$. It is\nwell-known that the so-called gauge-invariant Gaussian states are PUN, but\nwhether the converse is true is not known in the literature to the best of our\nknowledge. We establish the converse in affirmation. Lastly, in terms of the\n$(A,\\Lambda)$-parameterization, we show that a Gaussian state with parameters\n$(A,\\Lambda)$ is PUN if and only if $A=0$.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-29T17:49:28Z"}
{"aid":"http://arxiv.org/abs/2504.21261v1","title":"Multi-Domain Causal Discovery in Bijective Causal Models","summary":"We consider the problem of causal discovery (a.k.a., causal structure\nlearning) in a multi-domain setting. We assume that the causal functions are\ninvariant across the domains, while the distribution of the exogenous noise may\nvary. Under causal sufficiency (i.e., no confounders exist), we show that the\ncausal diagram can be discovered under less restrictive functional assumptions\ncompared to previous work. What enables causal discovery in this setting is\nbijective generation mechanisms (BGM), which ensures that the functional\nrelation between the exogenous noise $E$ and the endogenous variable $Y$ is\nbijective and differentiable in both directions at every level of the cause\nvariable $X = x$. BGM generalizes a variety of models including additive noise\nmodel, LiNGAM, post-nonlinear model, and location-scale noise model. Further,\nwe derive a statistical test to find the parents set of the target variable.\nExperiments on various synthetic and real-world datasets validate our\ntheoretical findings.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ME","published":"2025-04-30T02:30:10Z"}
{"aid":"http://arxiv.org/abs/2504.21272v1","title":"Quadratic spaces and Selmer groups of abelian varieties with\n  multiplication","summary":"For certain symmetric isogeny $\\lambda: A\\ra A^\\vee$ of abelian varieties\nover a global field $F$, B. Poonen and E. Rains put an orthogonal quadratic\nstructure on $\\RH^1(\\BA_F,A[\\lambda])$ and realize the Selmer group\n$\\Sel_\\lambda(A)$ as an intersection of two maximal isotropic subspaces of\n$\\RH^1(\\BA_F,A[\\lambda])$. With this understanding of Selmer groups, they\nexpect to model the Selmer groups of elliptic curves and Jacobian varieties of\nhyperelliptic curves as the intersections of random maximal isotropic subspaces\nof orthogonal spaces. We extend this phenomenon properly to abelian varieties\nwith multiplication.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T03:00:47Z"}
{"aid":"http://arxiv.org/abs/2504.21285v1","title":"Induced Diffusion of Internal Gravity Waves: Directionality and Role in\n  Ocean Mixing","summary":"Induced diffusion (ID), an important mechanism of spectral energy transfer in\nthe internal gravity wave (IGW) field, plays a significant role in driving\nturbulent dissipation in the ocean interior. In this study, we revisit the ID\nmechanism to elucidate its directionality and role in ocean mixing under\nvarying IGW spectral forms, with particular attention to deviations from the\nstandard Garrett-Munk (GM) spectrum. The original interpretation of ID as an\naction diffusion process, as proposed by McComas et al., suggests that ID is\ninherently bidirectional, with its direction governed by the\nvertical-wavenumber spectral slope $\\sigma$ of the IGW action spectrum, $n\n\\propto m^\\sigma$. In contrast, by evaluating the wave kinetic equation, we\nreveal a more complete depiction of ID, comprising both diffusive and\nscale-separated transfers that are rooted in energy conservation within wave\ntriads. Although the action diffusion may reverse direction depending on the\nsign of $\\sigma$ (i.e., between red and blue spectral cases), the combined ID\ntransfer consistently leads to a forward energy cascade at the dissipation\nscale, thereby contributing positively to turbulent dissipation. This supports\nthe viewpoint of ID as a dissipative mechanism in physical oceanography. This\nstudy presents a physically grounded overview of ID and offers insights into\nthe specific types of wave-wave interactions responsible for turbulent\ndissipation.","main_category":"physics.ao-ph","categories":"physics.ao-ph,physics.flu-dyn","published":"2025-04-30T03:34:02Z"}
{"aid":"http://arxiv.org/abs/2504.21287v1","title":"The new compact triple system: discovery of bright third star around\n  contact binary using LAMOST-MRS spectra and photometry","summary":"We present a study of the third star orbiting around known contact eclipsing\nbinary J04+25 using spectra from the LAMOST medium-resolution survey (MRS) and\npublicly available photometry. This is a rare case of a hierarchical triple,\nwhere the third star is significantly brighter than the inner contact\nsubsystem. We successfully extracted radial velocities for all three\ncomponents, using the binary spectral model in two steps. Third star radial\nvelocities have high precision and allow direct fitting of the orbit. The low\nprecision of radial velocity measurements in the contact system is compensated\nby large number statistics. We employed a template matching technique for light\ncurves to find periodic variation due to the light time travel effect (LTTE)\nusing several photometric datasets. Joint fit of third star radial velocities\nand LTTE allowed us to get a consistent orbital solution with\n$P_3=941.40\\pm0.03$ day and $e_3=0.059\\pm0.007$. We made estimations of the\nmasses $M_{\\rm 12,~3}\\sin^3{i_3}=1.05\\pm0.02,~0.90\\pm0.02~M_\\odot$ in a wide\nsystem and discussed possible determination of an astrometric orbit in the\nfuture data release of Gaia. Additionally, we propose an empirical method for\nmeasuring a period and minimal mass of contact systems, based on variation of\nthe projected rotational velocity ($V\\sin{i}$) from the spectra.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM","published":"2025-04-30T03:40:41Z"}
{"aid":"http://arxiv.org/abs/2504.21299v1","title":"BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language\n  Models","summary":"Identifying bias in LLM-generated content is a crucial prerequisite for\nensuring fairness in LLMs. Existing methods, such as fairness classifiers and\nLLM-based judges, face limitations related to difficulties in understanding\nunderlying intentions and the lack of criteria for fairness judgment. In this\npaper, we introduce BiasGuard, a novel bias detection tool that explicitly\nanalyzes inputs and reasons through fairness specifications to provide accurate\njudgments. BiasGuard is implemented through a two-stage approach: the first\nstage initializes the model to explicitly reason based on fairness\nspecifications, while the second stage leverages reinforcement learning to\nenhance its reasoning and judgment capabilities. Our experiments, conducted\nacross five datasets, demonstrate that BiasGuard outperforms existing tools,\nimproving accuracy and reducing over-fairness misjudgments. We also highlight\nthe importance of reasoning-enhanced decision-making and provide evidence for\nthe effectiveness of our two-stage optimization pipeline.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T04:13:03Z"}
{"aid":"http://arxiv.org/abs/2504.21318v1","title":"Phi-4-reasoning Technical Report","summary":"We introduce Phi-4-reasoning, a 14-billion parameter reasoning model that\nachieves strong performance on complex reasoning tasks. Trained via supervised\nfine-tuning of Phi-4 on carefully curated set of \"teachable\" prompts-selected\nfor the right level of complexity and diversity-and reasoning demonstrations\ngenerated using o3-mini, Phi-4-reasoning generates detailed reasoning chains\nthat effectively leverage inference-time compute. We further develop\nPhi-4-reasoning-plus, a variant enhanced through a short phase of outcome-based\nreinforcement learning that offers higher performance by generating longer\nreasoning traces. Across a wide range of reasoning tasks, both models\noutperform significantly larger open-weight models such as\nDeepSeek-R1-Distill-Llama-70B model and approach the performance levels of full\nDeepSeek-R1 model. Our comprehensive evaluations span benchmarks in math and\nscientific reasoning, coding, algorithmic problem solving, planning, and\nspatial understanding. Interestingly, we observe a non-trivial transfer of\nimprovements to general-purpose benchmarks as well. In this report, we provide\ninsights into our training data, our training methodologies, and our\nevaluations. We show that the benefit of careful data curation for supervised\nfine-tuning (SFT) extends to reasoning language models, and can be further\namplified by reinforcement learning (RL). Finally, our evaluation points to\nopportunities for improving how we assess the performance and robustness of\nreasoning models.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-30T05:05:09Z"}
{"aid":"http://arxiv.org/abs/2504.21319v1","title":"Combinatorial Identities Using the Matrix Tree Theorem","summary":"The matrix tree theorem, initially formulated by Kirchhoff, is a fundamental\nresult in algebraic graph theory that provides an elegant way to count spanning\ntrees using the Laplacian determinant. In this paper, we explore some\ninteresting applications of the matrix tree theorem. In particular, we present\na combinatorial interpretation of a distribution of $(n-1)^{n-1}$, in the\ncontext of uprooted spanning trees of the complete graph $K_{n}$, which was\npreviously obtained by Chauve--Dulucq--Guibert. Furthermore, we establish a\ncombinatorial explanation for the distribution of $m^{n-1}n^{m-1}$, related to\nspanning trees of the complete bipartite graph $K_{m,n}$, which seems new.","main_category":"math.CO","categories":"math.CO","published":"2025-04-30T05:06:08Z"}
{"aid":"http://arxiv.org/abs/2504.21327v1","title":"A Generalized Meta Federated Learning Framework with Theoretical\n  Convergence Guarantees","summary":"Meta federated learning (FL) is a personalized variant of FL, where multiple\nagents collaborate on training an initial shared model without exchanging raw\ndata samples. The initial model should be trained in a way that current or new\nagents can easily adapt it to their local datasets after one or a few\nfine-tuning steps, thus improving the model personalization. Conventional meta\nFL approaches minimize the average loss of agents on the local models obtained\nafter one step of fine-tuning. In practice, agents may need to apply several\nfine-tuning steps to adapt the global model to their local data, especially\nunder highly heterogeneous data distributions across agents. To this end, we\npresent a generalized framework for the meta FL by minimizing the average loss\nof agents on their local model after any arbitrary number $\\nu$ of fine-tuning\nsteps. For this generalized framework, we present a variant of the well-known\nfederated averaging (FedAvg) algorithm and conduct a comprehensive theoretical\nconvergence analysis to characterize the convergence speed as well as behavior\nof the meta loss functions in both the exact and approximated cases. Our\nexperiments on real-world datasets demonstrate superior accuracy and faster\nconvergence for the proposed scheme compared to conventional approaches.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-30T05:29:46Z"}
{"aid":"http://arxiv.org/abs/2504.21332v1","title":"MagicCraft: Natural Language-Driven Generation of Dynamic and\n  Interactive 3D Objects for Commercial Metaverse Platforms","summary":"Metaverse platforms are rapidly evolving to provide immersive spaces for user\ninteraction and content creation. However, the generation of dynamic and\ninteractive 3D objects remains challenging due to the need for advanced 3D\nmodeling and programming skills. To address this challenge, we present\nMagicCraft, a system that generates functional 3D objects from natural language\nprompts for metaverse platforms. MagicCraft uses generative AI models to manage\nthe entire content creation pipeline: converting user text descriptions into\nimages, transforming images into 3D models, predicting object behavior, and\nassigning necessary attributes and scripts. It also provides an interactive\ninterface for users to refine generated objects by adjusting features such as\norientation, scale, seating positions, and grip points.\n  Implemented on Cluster, a commercial metaverse platform, MagicCraft was\nevaluated by 7 expert CG designers and 51 general users. Results show that\nMagicCraft significantly reduces the time and skill required to create 3D\nobjects. Users with no prior experience in 3D modeling or programming\nsuccessfully created complex, interactive objects and deployed them in the\nmetaverse. Expert feedback highlighted the system's potential to improve\ncontent creation workflows and support rapid prototyping. By integrating\nAI-generated content into metaverse platforms, MagicCraft makes 3D content\ncreation more accessible.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-30T05:36:39Z"}
{"aid":"http://arxiv.org/abs/2504.21335v1","title":"Efficient hybrid variational quantum algorithm for solving graph\n  coloring problem","summary":"In the era of Noisy Intermediate Scale Quantum (NISQ) computing, available\nquantum resources are limited. Many NP-hard problems can be efficiently\naddressed using hybrid classical and quantum computational methods. This paper\nproposes a hybrid variational quantum algorithm designed to solve the\n$k$-coloring problem of graph vertices. The hybrid classical and quantum\nalgorithms primarily partition the graph into multiple subgraphs through\nhierarchical techniques. The Quantum Approximate Optimization Algorithm (QAOA)\nis employed to determine the coloring within the subgraphs, while a classical\ngreedy algorithm is utilized to find the coloring of the interaction graph.\nFixed coloring is applied to the interaction graph, and feedback is provided to\ncorrect any conflicting colorings within the subgraphs. The merging process\ninto the original graph is iteratively optimized to resolve any arising\nconflicts. We employ a hierarchical framework that integrates feedback\ncorrection and conflict resolution to achieve $k$-coloring of arbitrary graph\nvertices. Through experimental analysis, we demonstrate the effectiveness of\nthe algorithm, highlighting the rapid convergence of conflict evolution and the\nfact that iterative optimization allows the classical algorithm to approximate\nthe number of colorings. Finally, we apply the proposed algorithm to optimize\nthe scheduling of a subway transportation network, demonstrating a high degree\nof fairness.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T05:45:15Z"}
{"aid":"http://arxiv.org/abs/2504.21340v1","title":"Towards Improved Cervical Cancer Screening: Vision Transformer-Based\n  Classification and Interpretability","summary":"We propose a novel approach to cervical cell image classification for\ncervical cancer screening using the EVA-02 transformer model. We developed a\nfour-step pipeline: fine-tuning EVA-02, feature extraction, selecting important\nfeatures through multiple machine learning models, and training a new\nartificial neural network with optional loss weighting for improved\ngeneralization. With this design, our best model achieved an F1-score of\n0.85227, outperforming the baseline EVA-02 model (0.84878). We also utilized\nKernel SHAP analysis and identified key features correlating with cell\nmorphology and staining characteristics, providing interpretable insights into\nthe decision-making process of the fine-tuned model. Our code is available at\nhttps://github.com/Khoa-NT/isbi2025_ps3c.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-30T05:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.21348v1","title":"Impact of Non-metricity and Matter Source on the Geometry of Anisotropic\n  Spheres","summary":"This paper delves into the impact of extended symmetric teleparallel theory\non anisotropic compact stellar structures. The explicit field equations were\nformulated by considering a minimum model of this extended gravity. Basically,\nthe Darmois junction conditions are used to determine the unknown constants of\nmetric coefficients. We explore some significant properties of the compact\nstars under consideration to check their viable existence in this modified\nframework. The Tolman-Oppenheimer-Volkoff equation assess the equilibrium state\nof the compact stars. Moreover, the stability analysis is defined by using\nmethods based on sound speed (related to how disturbances propagate in the\nstar) and adiabatic index (related to the thermodynamic behavior of the star).\nWe find that the proposed compact stars in the $f(\\mathbb{Q}, \\mathbb{T})$\ngravity are physically viable and stable.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-30T06:17:11Z"}
{"aid":"http://arxiv.org/abs/2504.21352v1","title":"How one can assess the chaos?","summary":"We propose an uncertainty principle for chaos, focusing on two key\ncharacteristics: alpha unpredictability and Lorenz sensitivity. This principle\noutlines a limitation on the relationship between two infinite sequences that\nunderpin these concepts. It is applicable to both deterministic and stochastic\ndynamics, marking a significant step toward integrating these two fields. Our\ninitial progress in this area was achieved through research on Markov chains\nutilizing alpha labeling.\n  Additionally, we offer suggestions on how this principle can assess the\ndegree of chaos in specific processes. We also outline open questions regarding\nthe relationships among various types of chaos, including a modification of the\nrecurrence theorem.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-30T06:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.21362v1","title":"Enhancing New-item Fairness in Dynamic Recommender Systems","summary":"New-items play a crucial role in recommender systems (RSs) for delivering\nfresh and engaging user experiences. However, traditional methods struggle to\neffectively recommend new-items due to their short exposure time and limited\ninteraction records, especially in dynamic recommender systems (DRSs) where\nnew-items get continuously introduced and users' preferences evolve over time.\nThis leads to significant unfairness towards new-items, which could accumulate\nover the successive model updates, ultimately compromising the stability of the\nentire system. Therefore, we propose FairAgent, a reinforcement learning\n(RL)-based new-item fairness enhancement framework specifically designed for\nDRSs. It leverages knowledge distillation to extract collaborative signals from\ntraditional models, retaining strong recommendation capabilities for old-items.\nIn addition, FairAgent introduces a novel reward mechanism for recommendation\ntailored to the characteristics of DRSs, which consists of three components: 1)\na new-item exploration reward to promote the exposure of dynamically introduced\nnew-items, 2) a fairness reward to adapt to users' personalized fairness\nrequirements for new-items, and 3) an accuracy reward which leverages users'\ndynamic feedback to enhance recommendation accuracy. Extensive experiments on\nthree public datasets and backbone models demonstrate the superior performance\nof FairAgent. The results present that FairAgent can effectively boost new-item\nexposure, achieve personalized new-item fairness, while maintaining high\nrecommendation accuracy.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-30T06:49:36Z"}
{"aid":"http://arxiv.org/abs/2504.21371v1","title":"2025 Santorini-Amorgos crisis triggered by a transition from volcanic to\n  regular tectonic activity","summary":"Fluid movement beneath volcanic regions can influence earthquake activity,\nbut the processes linking seismic and volcanic systems are not fully\nunderstood. In early 2025, an unusual seismic sequence occurred close to\nSantorini, providing new insight into these interactions. Here we show that the\nsequence was likely initiated by the accumulation and migration of fluids\nbeneath the volcanic complex. Seismic and ground deformation data reveal a\nprogression from deep fluid buildup and microfracturing to the concentration of\nshallow earthquakes beneath Columbo volcano. This culminated in a four-day\nseismic episode that behaved like a single, slow-propagating rupture along a\n16-kilometer fault, releasing energy equivalent to a magnitude 6.2 earthquake.\nThe rupture was followed by a typical aftershock sequence. These observations\nsuggest that fluid-driven processes can generate large earthquakes and\nredistribute stress in ways similar to tectonic mainshocks. This challenges\nconventional views on how seismic and volcanic hazards are connected and\nassessed.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-30T07:07:50Z"}
{"aid":"http://arxiv.org/abs/2504.21374v1","title":"Topology of univoque sets in double-base expansions","summary":"Given two real numbers $q_0,q_1>1$ satisfying $q_0+q_1\\geq q_0q_1$ and two\nreal numbers $d_0\\ne d_1$, by a {double-base expansion} of a real number $x$ we\nmean a sequence $(i_k)\\in \\{0,1\\}^{\\infty}$ such that \\begin{equation*}\nx=\\sum_{k=1}^{\\infty}\\frac{d_{i_k}}{q_{{i_1}}q_{{i_2}}\\cdots q_{{i_k}}}.\n\\end{equation*} We denote by $\\mathcal{U}_{{q_0,q_1}}$ the set of numbers $x$\nhaving a unique expansion. The topological properties of\n$\\mathcal{U}_{{q_0,q_1}}$ have been investigated in the equal-base case\n$q_0=q_1$ for a long time. We extend this research to the case $q_0\\neq q_1$.\nWhile many results remain valid, a great number of new phenomena appear due to\nthe increased complexity of double-base expansions.","main_category":"math.DS","categories":"math.DS,math.NT","published":"2025-04-30T07:13:42Z"}
{"aid":"http://arxiv.org/abs/2504.21375v1","title":"Synergy-CLIP: Extending CLIP with Multi-modal Integration for Robust\n  Representation Learning","summary":"Multi-modal representation learning has become a pivotal area in artificial\nintelligence, enabling the integration of diverse modalities such as vision,\ntext, and audio to solve complex problems. However, existing approaches\npredominantly focus on bimodal interactions, such as image-text pairs, which\nlimits their ability to fully exploit the richness of multi-modal data.\nFurthermore, the integration of modalities in equal-scale environments remains\nunderexplored due to the challenges of constructing large-scale, balanced\ndatasets. In this study, we propose Synergy-CLIP, a novel framework that\nextends the contrastive language-image pre-training (CLIP) architecture to\nenhance multi-modal representation learning by integrating visual, textual, and\naudio modalities. Unlike existing methods that focus on adapting individual\nmodalities to vanilla-CLIP, Synergy-CLIP aligns and captures latent information\nacross three modalities equally. To address the high cost of constructing\nlarge-scale multi-modal datasets, we introduce VGG-sound+, a triple-modal\ndataset designed to provide equal-scale representation of visual, textual, and\naudio data. Synergy-CLIP is validated on various downstream tasks, including\nzero-shot classification, where it outperforms existing baselines.\nAdditionally, we introduce a missing modality reconstruction task,\ndemonstrating Synergy-CLIP's ability to extract synergy among modalities in\nrealistic application scenarios. These contributions provide a robust\nfoundation for advancing multi-modal representation learning and exploring new\nresearch directions.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-30T07:14:58Z"}
{"aid":"http://arxiv.org/abs/2504.21376v1","title":"Prediction of $p\\barΩ$ states and femtoscopic study","summary":"Inspired by recent researches on the $p \\Omega$ and $p \\bar{\\Lambda}$\nsystems, we investigate the $p \\bar{\\Omega}$ systems within the framework of a\nquark model. Our results show that the attraction between a nucleon and\n$\\bar{\\Omega}$ is slightly stronger than that between a nucleon and $\\Omega$,\nsuggesting that the $p \\bar{\\Omega}$ system is more likely to form bound\nstates. The dynamic calculations indicate that the $p \\bar{\\Omega}$ systems\nwith both $J^{P}=1^{-}$ and $2^{-}$ can form bound states, with binding\nenergies deeper than those of the $p \\Omega$ systems with $J^{P}=2^{+}$. The\nscattering phase shift and scattering parameter calculations also support the\nexistence of $p \\bar{\\Omega}$ states. Additionally, we discuss the behavior of\nthe femtoscopic correlation function for the $p \\bar{\\Omega}$ pairs for the\nfirst time. Considering the significant progress in experimental measurements\nof the correlation function of the $p \\Omega$ system, the further study of the\n$p \\bar{\\Omega}$ systems using femtoscopic techniques will be a very valuable\nwork.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat,hep-th","published":"2025-04-30T07:22:38Z"}
{"aid":"http://arxiv.org/abs/2504.21387v1","title":"Comparison of Different Deep Neural Network Models in the Cultural\n  Heritage Domain","summary":"The integration of computer vision and deep learning is an essential part of\ndocumenting and preserving cultural heritage, as well as improving visitor\nexperiences. In recent years, two deep learning paradigms have been established\nin the field of computer vision: convolutional neural networks and transformer\narchitectures. The present study aims to make a comparative analysis of some\nrepresentatives of these two techniques of their ability to transfer knowledge\nfrom generic dataset, such as ImageNet, to cultural heritage specific tasks.\nThe results of testing examples of the architectures VGG, ResNet, DenseNet,\nVisual Transformer, Swin Transformer, and PoolFormer, showed that DenseNet is\nthe best in terms of efficiency-computability ratio.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T07:38:20Z"}
{"aid":"http://arxiv.org/abs/2504.21389v1","title":"Enhanced Semi-Supervised Stamping Process Monitoring with\n  Physically-Informed Feature Extraction","summary":"In tackling frequent anomalies in stamping processes, this study introduces a\nnovel semi-supervised in-process anomaly monitoring framework, utilizing\naccelerometer signals and physics information, to capture the process anomaly\neffectively. The proposed framework facilitates the construction of a\nmonitoring model with imbalanced sample distribution, which enables in-process\ncondition monitoring in real-time to prevent batch anomalies, which helps to\nreduce batch defects risk and enhance production yield. Firstly, to effectively\ncapture key features from raw data containing redundant information, a hybrid\nfeature extraction algorithm is proposed to utilize data-driven methods and\nphysical mechanisms simultaneously. Secondly, to address the challenge brought\nby imbalanced sample distribution, a semi-supervised anomaly detection model is\nestablished, which merely employs normal samples to build a golden baseline\nmodel, and a novel deviation score is proposed to quantify the anomaly level of\neach online stamping stroke. The effectiveness of the proposed feature\nextraction method is validated with various classification algorithms. A\nreal-world in-process dataset from stamping manufacturing workshop is employed\nto illustrate the superiority of proposed semi-supervised framework with\nenhance performance for process anomaly monitoring.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-30T07:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.21393v1","title":"JAvaScript Multimodal INformation Explorer","summary":"Astronomical data is rich in volume, information and facets. Although this\noffers multiple research perspectives, processing the data remains a challenge.\nInfrastructures for analyzing, inspecting, exploring and communicating with\ndata are mandatory. To address this issue, we introduce Jasmine, the JAvaScript\nMultimodal INformation Explorer. Jasmine allows users to open different data\nviewer modals that show a specific data point from a set. The viewer currently\nsupports image data, as well as point cloud objects. Users can decide on which\ninformation about the data point they like to have displayed. Point clouds are\ninteractive and allow for zooming, tossing, and turning. Picking a data point\nis enabled by providing a structured view of the set, arranged by a key\nproperty. This arrangement is achieved by autoencoding.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-30T07:48:46Z"}
{"aid":"http://arxiv.org/abs/2504.21396v1","title":"Square Root Operators and the Well-Posedness of Pseudodifferential\n  Parabolic Models of Wave Phenomena","summary":"Pseudodifferential parabolic equations with an operator square root arise in\nwave propagation problems as a one-way counterpart of the Helmholtz equation.\nThe expression under the square root usually involves a differential operator\nand a known function. We discuss a rigorous definition of such operator square\nroots and show well-posedness of the pseudodifferential parabolic equation by\nusing the theory of strongly continuous semigroups. This provides a\njustification for a family of widely-used numerical methods for wavefield\nsimulations in various areas of physics.","main_category":"physics.ao-ph","categories":"physics.ao-ph,math.AP,math.FA","published":"2025-04-30T07:52:48Z"}
{"aid":"http://arxiv.org/abs/2504.21424v1","title":"Analysis of modulated linear wave packets and gap solitons in coupled\n  optical fibers","summary":"A coupled pair of waveguides with refractive indices of different signs is\nconsidered. It is shown that the gap in the linear wave spectrum closes if\nthese waves are amplitude modulated. To look for solitons as envelopes of\nexponentially modulated wave packets, the dispersion law of these packets is\nused. Different decompositions of the dispersion law lead to solutions related\nto different parts of the spectrum. Numerical calculations demonstrate a good\nagreement with analytical predictions.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-30T08:28:41Z"}
{"aid":"http://arxiv.org/abs/2504.21427v1","title":"MPEC: Manifold-Preserved EEG Classification via an Ensemble of\n  Clustering-Based Classifiers","summary":"Accurate classification of EEG signals is crucial for brain-computer\ninterfaces (BCIs) and neuroprosthetic applications, yet many existing methods\nfail to account for the non-Euclidean, manifold structure of EEG data,\nresulting in suboptimal performance. Preserving this manifold information is\nessential to capture the true geometry of EEG signals, but traditional\nclassification techniques largely overlook this need. To this end, we propose\nMPEC (Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based\nClassifiers), that introduces two key innovations: (1) a feature engineering\nphase that combines covariance matrices and Radial Basis Function (RBF) kernels\nto capture both linear and non-linear relationships among EEG channels, and (2)\na clustering phase that employs a modified K-means algorithm tailored for the\nRiemannian manifold space, ensuring local geometric sensitivity. Ensembling\nmultiple clustering-based classifiers, MPEC achieves superior results,\nvalidated by significant improvements on the BCI Competition IV dataset 2a.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-30T08:34:15Z"}
{"aid":"http://arxiv.org/abs/2504.21436v1","title":"Whispers of Data: Unveiling Label Distributions in Federated Learning\n  Through Virtual Client Simulation","summary":"Federated Learning enables collaborative training of a global model across\nmultiple geographically dispersed clients without the need for data sharing.\nHowever, it is susceptible to inference attacks, particularly label inference\nattacks.\n  Existing studies on label distribution inference exhibits sensitive to the\nspecific settings of the victim client and typically underperforms under\ndefensive strategies. In this study, we propose a novel label distribution\ninference attack that is stable and adaptable to various scenarios.\nSpecifically, we estimate the size of the victim client's dataset and construct\nseveral virtual clients tailored to the victim client. We then quantify the\ntemporal generalization of each class label for the virtual clients and utilize\nthe variation in temporal generalization to train an inference model that\npredicts the label distribution proportions of the victim client.\n  We validate our approach on multiple datasets, including MNIST,\nFashion-MNIST, FER2013, and AG-News. The results demonstrate the superiority of\nour method compared to state-of-the-art techniques. Furthermore, our attack\nremains effective even under differential privacy defense mechanisms,\nunderscoring its potential for real-world applications.","main_category":"cs.LG","categories":"cs.LG,cs.CR","published":"2025-04-30T08:51:06Z"}
{"aid":"http://arxiv.org/abs/2504.21440v1","title":"QuantumToolbox.jl: An efficient Julia framework for simulating open\n  quantum systems","summary":"We present QuantumToolbox.jl, an open-source Julia package for simulating\nopen quantum systems. Designed with a syntax familiar to users of QuTiP\n(Quantum Toolbox in Python), it harnesses Julia's high-performance ecosystem to\ndeliver fast and scalable simulations. The package includes a suite of\ntime-evolution solvers supporting distributed computing and GPU acceleration,\nenabling efficient simulation of large-scale quantum systems. We also show how\nQuantumToolbox.jl can integrate with automatic differentiation tools, making it\nwell-suited for gradient-based optimization tasks such as quantum optimal\ncontrol. Benchmark comparisons demonstrate substantial performance gains over\nexisting frameworks. With its flexible design and computational efficiency,\nQuantumToolbox.jl serves as a powerful tool for both theoretical studies and\npractical applications in quantum science.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph","published":"2025-04-30T08:56:12Z"}
{"aid":"http://arxiv.org/abs/2504.21453v1","title":"Analysis and Mitigation of Crosstalk in a Multi-Parameter Laser Beam\n  Diagnostic System","summary":"Accurate characterization of laser beams is crucial for applications ranging\nfrom laser-based material processing to gravitational wave detection, where\neven minor measurement deviations can significantly impact system performance.\nThis work investigates crosstalk effects in a multi-parameter laser beam\ndiagnostic system designed to simultaneously measure six beam parameters:\npointing angles, centroid positions, wavefront curvature, and beam diameter.\nUsing sequential ray-optical simulations in Zemax, a comprehensive analysis of\nparameter interdependencies is performed through a systematic parameter sweep\nacross 15625 unique combinations within specified measurement ranges. The\nresults reveal significant crosstalk effects between several parameters, which\nare traced back to specific optical components in the system. To address these\nissues and improve accuracy, a mathematical framework for crosstalk mitigation\nbased on Taylor series expansions is developed. The mitigation method reduces\nmeasurement deviations significantly by up to one order of magnitude. This work\nprovides insights into the origins and mitigation of crosstalk effects in\noptical measurement systems, particularly relevant for high-accuracy\napplications.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-30T09:21:45Z"}
{"aid":"http://arxiv.org/abs/2504.21475v1","title":"Advancing Arabic Reverse Dictionary Systems: A Transformer-Based\n  Approach with Dataset Construction Guidelines","summary":"This study addresses the critical gap in Arabic natural language processing\nby developing an effective Arabic Reverse Dictionary (RD) system that enables\nusers to find words based on their descriptions or meanings. We present a novel\ntransformer-based approach with a semi-encoder neural network architecture\nfeaturing geometrically decreasing layers that achieves state-of-the-art\nresults for Arabic RD tasks. Our methodology incorporates a comprehensive\ndataset construction process and establishes formal quality standards for\nArabic lexicographic definitions. Experiments with various pre-trained models\ndemonstrate that Arabic-specific models significantly outperform general\nmultilingual embeddings, with ARBERTv2 achieving the best ranking score\n(0.0644). Additionally, we provide a formal abstraction of the reverse\ndictionary task that enhances theoretical understanding and develop a modular,\nextensible Python library (RDTL) with configurable training pipelines. Our\nanalysis of dataset quality reveals important insights for improving Arabic\ndefinition construction, leading to eight specific standards for building\nhigh-quality reverse dictionary resources. This work contributes significantly\nto Arabic computational linguistics and provides valuable tools for language\nlearning, academic writing, and professional communication in Arabic.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-30T09:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.21498v1","title":"Domain Wall as Cosmological Oscillator","summary":"In this study, we examine the domain wall within the framework of a\ncosmological harmonic oscillator. We investigate the interaction between the\ndomain wall and a periodic background field, which can induce perturbations in\nthe oscillatory behavior of the wall. We propose a novel mechanism for\nresolving the domain wall problem through the phenomenon of resonant\noscillation. Resonant oscillation occurs when the frequency of the external\ndriving force aligns with the intrinsic frequency of the domain wall. This\nsynchrony can significantly amplify the amplitude of the oscillation. If the\namplitude of oscillation exceeds a predetermined critical deformation\nthreshold, the domain wall may be deconstructed. Furthermore, we demonstrate\nthat this mechanism remains valid in models that preserve discrete symmetry.","main_category":"hep-ph","categories":"hep-ph,gr-qc,hep-th","published":"2025-04-30T10:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.21506v1","title":"Multi-lump, lump-kink and interaction of breather with other nonlinear\n  waves of a couple Boussinesq system","summary":"We investigate the interaction characteristics of nonlinear coherent\nstructures in the couple Boussinesq (CB) system using the Hirota bilinear\napproach. First, we derive the lump solutions using a positive quadratic\npolynomial within the Hirota perturbation technique. Next, We study the\nexplicit interactions between lumps and one or two-kink waves, and observe\ndouble lump patterns. Furthermore, we discover the interactions of breathers,\nrevealing a diffusion-like behavior. We notice that breather waves can interact\nwith periodic, kink, and bright solitons for specific parameter sets in the CB\nsystem. Interactions between two chains of double breathers are also found. We\nanalyze our results using a combination of symbolic computations and graphical\nrepresentations, providing a deeper understanding of their behavior. This study\nreveals previously unreported nonlinear dynamics in the CB system.","main_category":"nlin.PS","categories":"nlin.PS,math-ph,math.MP","published":"2025-04-30T10:55:49Z"}
{"aid":"http://arxiv.org/abs/2504.21521v1","title":"Adaptive Neural Control with Desired Approximation: An Integral Lyapunov\n  Function Approach","summary":"The inherent approximation ability of neural networks plays an essential role\nin adaptive neural control, where the prerequisite for existence of the compact\nset is crucial in the control designs. Instead of using practical system state,\nin this paper, the desired approximation approach is characterized to tackle\nsuch a problem, where the desired state signal is required only as the input to\nthe network. An integral Lyapunov function-based adaptive controller is\ndesigned, in the sense of the error tracking, where the treatment of the\nstate-dependent input gain is adopted. Theoretical results for the performance\nanalysis of the integral and incremental adaptation algorithms are presented in\ndetails. In particular, the boundedness of the variables in the closed-loop is\ncharacterized, while the transient performance of the output error is\nanalytically quantified. It is shown that the proposed control schemes assure\nthat the tracking error converges to an adjustable set without any requirement\non the knowledge of the region that the practical variables evolve, and remove\nthe requirement for the setting of initial conditions including system states\nand weight estimates.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-30T11:16:07Z"}
{"aid":"http://arxiv.org/abs/2504.21523v1","title":"Sibuya probability distributions and numerical evaluation of\n  fractional-order operators","summary":"In this work we explore the Sibuya discrete probability distribution, which\nserves as the basis and the main instrument for numerical simulations of\nGrunwald--Letnikov fractional derivatives by the Monte Carlo method. We provide\nthree methods for simulating the Sibuya distribution. We also introduce the\nSibuya-like sieved probability distributions, and apply them to numerical\nfractional-order differentiation. Additionally, we use the Monte Carlo method\nfor evaluating fractional-order integrals, and suggest the notion of the\ncontinuous Sibuya probability distribution. The developed methods and tools are\nillustrated by examples of computation. We provide the MATLAB toolboxes for\nsimulation of the Sibuya probability distribution, and for the numerical\nexamples.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR","published":"2025-04-30T11:18:39Z"}
{"aid":"http://arxiv.org/abs/2504.21525v1","title":"Systematic Review of Smart Factories Production in Industry 5.0","summary":"Technology plays an undeniable role in today's industrial world, especially\nin manufacturing and smart factories. Unlike previous industrial revolutions,\nhumans are at the core of the fifth generation of the Industrial Revolution.\nOne of the critical aspects of Industry 5.0 (I 5.0) is its emphasis on\nhuman-centricity. The integration of modern technologies can be clearly\nobserved in smart factories, which offer enhanced comfort and professionalism.\nThis study highlights the significance of I 5.0 and smart factory production\n(SFP). A total of 36 articles are reviewed and systematically categorized using\nthe meta-synthesis methodology. The research emphasizes the influence of I 5.0\non SFP through the use of modern technologies and comprehensive policy\nframeworks. This new paradigm has the potential to streamline people's lives\nand bring a transformative shift to smart factory production lines. Enhancing\nthe structure of factories appears feasible under this optimistic perspective.","main_category":"math.OC","categories":"math.OC","published":"2025-04-30T11:18:47Z"}
{"aid":"http://arxiv.org/abs/2504.21529v1","title":"Schwinger's non-commutative coordinates and duality between helicity and\n  Dirac quantisation conditions","summary":"The helicity operator of massless particles has only two polarisations like\nit takes place for photons and gravitons. For them not all of the 2s+1 spin\nmagnetic quantum states exist, with two exceptions, and the spin operator\nceases to be defined properly and consistently. The problem was solved by\nSchwinger, who introduced non-commutative space coordinates that completely\neliminate the spin operator and ensure that only helicity operator appears\nexplicitly. We further investigate the violation of the associativity relation\nof the momentum translation operator that emerges due to the failure of the\ncorresponding Jacobi identity. The associativity relation is broken by a phase\nfactor which satisfies a 3-cocycle relation. The associativity is restored when\na 3-cocycle is an integer number, and leads to the quantisation of massless\nparticle's helicity. We discuss the correspondence (duality) between the\nhelicity and the Dirac quantisation conditions.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-30T11:23:47Z"}
{"aid":"http://arxiv.org/abs/2504.21540v1","title":"Improving Informally Romanized Language Identification","summary":"The Latin script is often used to informally write languages with non-Latin\nnative scripts. In many cases (e.g., most languages in India), there is no\nconventional spelling of words in the Latin script, hence there will be high\nspelling variability in written text. Such romanization renders languages that\nare normally easily distinguished based on script highly confusable, such as\nHindi and Urdu. In this work, we increase language identification (LID)\naccuracy for romanized text by improving the methods used to synthesize\ntraining sets. We find that training on synthetic samples which incorporate\nnatural spelling variation yields higher LID system accuracy than including\navailable naturally occurring examples in the training set, or even training\nhigher capacity models. We demonstrate new state-of-the-art LID performance on\nromanized text from 20 Indic languages in the Bhasha-Abhijnaanam evaluation set\n(Madhani et al., 2023a), improving test F1 from the reported 74.7% (using a\npretrained neural model) to 85.4% using a linear classifier trained solely on\nsynthetic data and 88.2% when also training on available harvested text.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T11:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.21542v1","title":"The intersection of the subgroups of finite $p$-index in a multiple\n  HNN-extension of an infinite cyclic group","summary":"Let $G$ be a multiple HNN-extension of an infinite cyclic group. We will\ncalculate the intersection $(N_{p}){_\\omega}(G)$ of the normal subgroups of\nfinite $p$-index in $G$ thus generalizing the result of Moldavanskii for\nBaumslag-Solitar groups.","main_category":"math.GR","categories":"math.GR","published":"2025-04-30T11:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.21547v1","title":"TartuNLP at SemEval-2025 Task 5: Subject Tagging as Two-Stage\n  Information Retrieval","summary":"We present our submission to the Task 5 of SemEval-2025 that aims to aid\nlibrarians in assigning subject tags to the library records by producing a list\nof likely relevant tags for a given document. We frame the task as an\ninformation retrieval problem, where the document content is used to retrieve\nsubject tags from a large subject taxonomy. We leverage two types of encoder\nmodels to build a two-stage information retrieval system -- a bi-encoder for\ncoarse-grained candidate extraction at the first stage, and a cross-encoder for\nfine-grained re-ranking at the second stage. This approach proved effective,\ndemonstrating significant improvements in recall compared to single-stage\nmethods and showing competitive results according to qualitative evaluation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T11:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.21554v1","title":"Co-maximal Hypergraph on Dn","summary":"Let $G$ be a group and $S$ be the set of all non-trivial proper subgroups of\n$G$. \\textit{The co-maximal hypergraph of $G$}, denoted by $Co_\\mathcal{H}(G)$,\nis a hypergraph whose vertex set is $\\{H \\in S \\,\\, | \\,\\, H K = G \\,\\,\n\\text{for some} \\, K \\in S \\}$ and hyperedges are the maximal subsets of the\nvertex set with the property that the product of any two vertices is equal to\n$G$. The aim of this paper is to study the co-maximal hypergraph of dihedral\ngroups, $Co_\\mathcal{H}(D_n)$. We examine some of the structural properties,\nviz., diameter, girth and chromatic number of $Co_\\mathcal{H}(D_n)$. Also, we\nprovide characterizations for hypertrees, star structures and 3-uniform\nhypergraphs of $Co_\\mathcal{H}(D_n)$. Further, we discuss the possibilities of\n$Co_\\mathcal{H}(D_n)$ which can be embedded on the plane, torus and projective\nplane.","main_category":"math.CO","categories":"math.CO","published":"2025-04-30T11:52:39Z"}
{"aid":"http://arxiv.org/abs/2504.21558v1","title":"The minimum crossing number and minimum size of maximal 1-plane graphs\n  with given connectivity","summary":"A 1-planar graph is a graph which has a drawing on the plane such that each\nedge is crossed at most once. If a 1-planar graph is drawn in that way, the\ndrawing is called a {\\it 1-plane graph}. A graph is maximal 1-plane (or\n1-planar) if no additional edge can be added without violating 1-planarity or\nsimplicity. It is known that any maximal 1-plane graph is $k$-connected for\nsome $k$ with $2\\le k\\le 7$. Recently, Huang et al. proved that any maximal\n1-plane graph with $n$ ($\\ge 5$) vertices has at least\n$\\lceil\\frac{7}{3}n\\rceil-3$ edges, which is tight for all integers $n\\ge 5$.\nIn this paper, we study $k$-connected maximal 1-plane graphs for each $k$ with\n$3\\le k\\le 7$, and establish a lower bound for their crossing numbers and a\nlower bound for their edge numbers, respectively.","main_category":"math.CO","categories":"math.CO","published":"2025-04-30T11:57:00Z"}
{"aid":"http://arxiv.org/abs/2504.21562v1","title":"eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes","summary":"Wireless Capsule Endoscopy is a non-invasive imaging method for the entire\ngastrointestinal tract, and is a pain-free alternative to traditional\nendoscopy. It generates extensive video data that requires significant review\ntime, and localizing the capsule after ingestion is a challenge. Techniques\nlike bleeding detection and depth estimation can help with localization of\npathologies, but deep learning models are typically too large to run directly\non the capsule. Neural Cellular Automata (NCA) for bleeding segmentation and\ndepth estimation are trained on capsule endoscopic images. For monocular depth\nestimation, we distill a large foundation model into the lean NCA architecture,\nby treating the outputs of the foundation model as pseudo ground truth. We then\nport the trained NCA to the ESP32 microcontroller, enabling efficient image\nprocessing on hardware as small as a camera capsule. NCA are more accurate\n(Dice) than other portable segmentation models, while requiring more than 100x\nfewer parameters stored in memory than other small-scale models. The visual\nresults of NCA depth estimation look convincing, and in some cases beat the\nrealism and detail of the pseudo ground truth. Runtime optimizations on the\nESP32-S3 accelerate the average inference speed significantly, by more than\nfactor 3. With several algorithmic adjustments and distillation, it is possible\nto eNCApsulate NCA models into microcontrollers that fit into wireless capsule\nendoscopes. This is the first work that enables reliable bleeding segmentation\nand depth estimation on a miniaturized device, paving the way for precise\ndiagnosis combined with visual odometry as a means of precise localization of\nthe capsule -- on the capsule.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-30T12:06:56Z"}
{"aid":"http://arxiv.org/abs/2504.21563v1","title":"A User-Centered Teleoperation GUI for Automated Vehicles: Identifying\n  and Evaluating Information Requirements for Remote Driving and Assistance","summary":"Teleoperation emerged as a promising fallback for situations beyond the\ncapabilities of automated vehicles. Nevertheless, teleoperation still faces\nchallenges, such as reduced situational awareness. Since situational awareness\nis primarily built through the remote operator's visual perception, the\nGraphical User Interface (GUI) design is critical. In addition to video feeds,\nsupplemental informational elements are crucial - not only for the\npredominantly studied Remote Driving but also for the arising desk-based Remote\nAssistance concepts. This work develops a GUI for different teleoperation\nconcepts by identifying key informational elements during the teleoperation\nprocess through expert interviews (N = 9). Following this, a static and dynamic\nGUI prototype is developed and evaluated in a click-dummy study (N = 36).\nThereby, the dynamic GUI adapts the number of displayed elements according to\nthe teleoperation phase. Results show that both GUIs achieve good System\nUsability Scale (SUS) ratings, with the dynamic GUI significantly outperforming\nthe static version in both usability and task completion time. The User\nExperience Questionnaire (UEQ) score shows potential for improvement. To\nenhance the user experience, the GUI should be evaluated in a follow-up study\nthat includes interaction with a real vehicle.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-30T12:09:11Z"}
{"aid":"http://arxiv.org/abs/2504.21576v1","title":"Marcinkiewicz-type laws of large numbers for pseudo-independent random\n  variables under sublinear expectations","summary":"As a kind of independence of random variables under sublinear expectations,\npseudo-independence is weaker than Peng's independence. We shall give\nMarcinkiewicz-type weak and strong laws of large numbers for pseudo-independent\nrandom variables under the framework of sublinear expectations.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T12:27:35Z"}
{"aid":"http://arxiv.org/abs/2504.21579v1","title":"Uncertainty, bias and the institution bootstrapping problem","summary":"Institutions play a critical role in enabling communities to manage\ncommon-pool resources and avert tragedies of the commons. However, a\nfundamental issue arises: Individuals typically perceive participation as\nadvantageous only after an institution is established, creating a paradox: How\ncan institutions form if no one will join before a critical mass exists? We\nterm this conundrum the institution bootstrapping problem and propose that\nmisperception, specifically, agents' erroneous belief that an institution\nalready exists, could resolve this paradox. By integrating well-documented\npsychological phenomena, including cognitive biases, probability distortion,\nand perceptual noise, into a game-theoretic framework, we demonstrate how these\nfactors collectively mitigate the bootstrapping problem. Notably, unbiased\nperceptual noise (e.g., noise arising from agents' heterogeneous physical or\nsocial contexts) drastically reduces the critical mass of cooperators required\nfor institutional emergence. This effect intensifies with greater diversity of\nperceptions. We explain this counter-intuitive result through asymmetric\nboundary conditions: proportional underestimation of low-probability sanctions\nproduces distinct outcomes compared to equivalent overestimation. Furthermore,\nthe type of perceptual distortion, proportional versus absolute, yields\nqualitatively different evolutionary pathways. These findings challenge\nconventional assumptions about rationality in institutional design,\nhighlighting how \"noisy\" cognition can paradoxically enhance cooperation.\nFinally, we contextualize these insights within broader discussions of\nmulti-agent system design and collective action. Our analysis underscores the\nimportance of incorporating human-like cognitive constraints, not just\nidealized rationality, into models of institutional emergence and resilience.","main_category":"cs.MA","categories":"cs.MA,cs.CY,cs.GT","published":"2025-04-30T12:36:06Z"}
{"aid":"http://arxiv.org/abs/2504.21582v1","title":"MF-LLM: Simulating Collective Decision Dynamics via a Mean-Field Large\n  Language Model Framework","summary":"Simulating collective decision-making involves more than aggregating\nindividual behaviors; it arises from dynamic interactions among individuals.\nWhile large language models (LLMs) show promise for social simulation, existing\napproaches often exhibit deviations from real-world data. To address this gap,\nwe propose the Mean-Field LLM (MF-LLM) framework, which explicitly models the\nfeedback loop between micro-level decisions and macro-level population. MF-LLM\nalternates between two models: a policy model that generates individual actions\nbased on personal states and group-level information, and a mean field model\nthat updates the population distribution from the latest individual decisions.\nTogether, they produce rollouts that simulate the evolving trajectories of\ncollective decision-making. To better match real-world data, we introduce\nIB-Tune, a fine-tuning method for LLMs grounded in the information bottleneck\nprinciple, which maximizes the relevance of population distributions to future\nactions while minimizing redundancy with historical data. We evaluate MF-LLM on\na real-world social dataset, where it reduces KL divergence to human population\ndistributions by 47 percent over non-mean-field baselines, and enables accurate\ntrend forecasting and intervention planning. It generalizes across seven\ndomains and four LLM backbones, providing a scalable foundation for\nhigh-fidelity social simulation.","main_category":"cs.MA","categories":"cs.MA,cs.AI","published":"2025-04-30T12:41:51Z"}
{"aid":"http://arxiv.org/abs/2504.21601v1","title":"Efficient Decomposition of Forman-Ricci Curvature on Vietoris-Rips\n  Complexes and Data Applications","summary":"Discrete Forman-Ricci curvature (FRC) is an efficient tool that characterizes\nessential geometrical features and associated transitions of real-world\nnetworks, extending seamlessly to higher-dimensional computations in simplicial\ncomplexes. In this article, we provide two major advancements: First, we give a\ndecomposition for FRC, enabling local computations of FRC. Second, we construct\na set-theoretical proof enabling an efficient algorithm for the local\ncomputation of FRC in Vietoris-Rips (VR) complexes.Strikingly, this approach\nreveals critical information and geometric insights often overlooked by\nconventional classification techniques. Our findings open new avenues for\ngeometric computations in VR complexes and highlight an essential yet\nunder-explored aspect of data classification: the geometry underpinning\nstatistical patterns.","main_category":"math.GT","categories":"math.GT,cs.CG,cs.DM,cs.DS,math.CO","published":"2025-04-30T12:59:23Z"}
{"aid":"http://arxiv.org/abs/2504.21606v1","title":"Measurement-Based Line-Impedance Estimation in the Absence of Phasor\n  Measurement Units","summary":"This paper proposes and compares experimentally several methods to estimate\nthe series resistance and reactance (i.e., the transversal components of the\n$\\pi$-model of a line) of low-voltage lines in distribution grids. It first\nshows that if phasor measurements are available and the grid nodal voltages and\npower injections are known, the problem can be formulated and solved as a\nconventional load flow with properly adjusted unknowns. To solve this problem,\nwe propose an analytical derivation of the Jacobian matrix. If only RMS values\nare available, such as from smart meters, integrating information from multiple\nintervals becomes necessary, ultimately opening to least-squares estimations,\nwidely adopted in the literature. In this context, applying the proposed\nJacobian contributes to accelerating the problem resolution of existing\nalgorithms. The methods are compared in terms of estimation performance and\nconvergence by using measurements from an experimental distribution grid\ninterfacing real-world components and with realistic size implemented at the\nGridlab at HES-SO Valais.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-30T13:06:50Z"}
{"aid":"http://arxiv.org/abs/2504.21639v1","title":"Sparsity for Infinite-Parametric Holomorphic Functions on Gaussian\n  Spaces","summary":"We investigate the sparsity of Wiener polynomial chaos expansions of\nholomorphic maps $\\mathcal{G}$ on Gaussian Hilbert spaces, as arise in the\ncoefficient-to-solution maps of linear, second order, divergence-form elliptic\nPDEs with log-Gaussian diffusion coefficient. Representing the Gaussian random\nfield input as an affine-parametric expansion, the nonlinear map becomes a\ncountably-parametric, deterministic holomorphic map of the coordinate sequence\n$\\boldsymbol{y} = (y_j)_{j\\in\\mathbb{N}} \\in \\mathbb{R}^\\infty$. We establish\nweighted summability results for the Wiener-Hermite coefficient sequences of\nimages of affine-parametric expansions of the log-Gaussian input under\n$\\mathcal{G}$. These results give rise to $N$-term approximation rate bounds\nfor the full range of input summability exponents $p\\in (0,2)$. We show that\nthese approximation rate bounds apply to parameter-to-solution maps for\nelliptic diffusion PDEs with lognormal coefficients.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T13:40:56Z"}
{"aid":"http://arxiv.org/abs/2504.21641v1","title":"Universal scaling law for quantum droplet formation","summary":"Given the right set of circumstances, ultracold quantum gases are able to\nchange character and condense into a liquid state of quantum droplets. The size\ndistribution of the droplets is determined dynamically in the condensation\nprocess. A semi-quantitative argument is presented which suggests that, at zero\ntemperature, a multiple droplet system has is a preferred scale $\\propto\nv^{-d}$, with $d\\approx 0.5$, where $v$ is the rate of change of parameters at\nthe time of droplet formation. Numerical simulations of two dimensional systems\nstrongly support a power law, but with an exponent $d\\in(0.3,0.4)$.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-30T13:44:45Z"}
{"aid":"http://arxiv.org/abs/2504.21644v1","title":"Computer-assisted construction of $SU(2)$-invariant negative Einstein\n  metrics","summary":"We construct a 2-parameter family of new triaxial $SU(2)$-invariant complete\nnegative Einstein metrics on the complex line bundle $\\mathcal{O}(-4)$ over\n$\\mathbb{C}P^1$. The metrics are conformally compact and generically neither\nK\\\"ahler nor self-dual. The proof involves using rigorous numerics to produce\nan approximate Einstein metric to high precision in a bounded region containing\nthe singular orbit or \"bolt\", which is then perturbed to a genuine Einstein\nmetric using fixed-point methods. At the boundary of this region, the latter\nmetric is sufficiently close to hyperbolic space for us to show that it indeed\nextends to a complete, asymptotically hyperbolic Einstein metric.","main_category":"math.DG","categories":"math.DG","published":"2025-04-30T13:47:27Z"}
{"aid":"http://arxiv.org/abs/2504.21652v1","title":"Coning off totally geodesic boundary components of a hyperbolic manifold","summary":"Let M be a compact hyperbolic manifold with totally geodesic boundary. If the\ninjectivity radius of the boundary is larger than an explicit function of the\nnormal injectivity radius of the boundary, we show that there is a negatively\ncurved metric on the space obtained by coning each boundary component of M to a\npoint. Moreover, we give explicit geometric conditions under which a locally\nconvex subset of M gives rise to a locally convex subset of the cone-off.\n  Group-theoretically, we conclude that the fundamental group of the cone-off\nis hyperbolic and the image of the fundamental group of the coned-off locally\nconvex subset is a quasi-convex subgroup.","main_category":"math.GT","categories":"math.GT,math.GR","published":"2025-04-30T13:55:54Z"}
{"aid":"http://arxiv.org/abs/2504.21665v1","title":"Discrete coagulation--fragmentation systems in weighted $\\ell^1$ spaces","summary":"We study an infinite system of ordinary differential equations that models\nthe evolution of coagulating and fragmenting clusters, which we assume to be\ncomposed of identical units. Under very mild assumptions on the coefficients we\nprove existence, uniqueness and positivity of solutions of a corresponding\nsemi-linear Cauchy problem in a weighted $\\ell^1$ space. This requires the\napplication of novel results, which we prove for abstract semi-linear Cauchy\nproblems in Banach lattices where the non-linear term is defined only on a\ndense subspace.","main_category":"math.FA","categories":"math.FA","published":"2025-04-30T14:09:22Z"}
{"aid":"http://arxiv.org/abs/2504.21683v1","title":"Extension-ranking Semantics for Abstract Argumentation Preprint","summary":"In this paper, we present a general framework for ranking sets of arguments\nin abstract argumentation based on their plausibility of acceptance. We present\na generalisation of Dung's extension semantics as extension-ranking semantics,\nwhich induce a preorder over the power set of all arguments, allowing us to\nstate that one set is \"closer\" to being acceptable than another. To evaluate\nthe extension-ranking semantics, we introduce a number of principles that a\nwell-behaved extension-ranking semantics should satisfy. We consider several\nsimple base relations, each of which models a single central aspect of\nargumentative reasoning. The combination of these base relations provides us\nwith a family of extension-ranking semantics. We also adapt a number of\napproaches from the literature for ranking extensions to be usable in the\ncontext of extension-ranking semantics, and evaluate their behaviour.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-30T14:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.21684v1","title":"Using quantum annealing to generate test cases for cyber-physical\n  systems","summary":"Quantum computing has emerged as a powerful tool to efficiently solve\ncomputational challenges, particularly in simulation and optimisation. However,\nhardware limitations prevent quantum computers from achieving the full\ntheoretical potential. Among the quantum algorithms, quantum annealing is a\nprime candidate to solve optimisation problems. This makes it a natural\ncandidate for search-based software testing in the Cyber-Physical Systems (CPS)\ndomain, which demands effective test cases due to their safety-critical nature.\nThis work explores the use of quantum annealing to enhance test case generation\nfor CPS through a mutation-based approach. We encode test case mutation as a\nbinary optimisation problem, and use quantum annealing to identify and target\ncritical regions of the test cases for improvement. Our approach mechanises\nthis process into an algorithm that uses D-Wave's quantum annealer to find the\nsolution. As a main contribution, we offer insights into how quantum annealing\ncan advance software testing methodologies by empirically evaluating the\ncorrelation between problem size, hardware limitations, and the effectiveness\nof the results. Moreover, we compare the proposed method against\nstate-of-the-art classical optimisation algorithms, targeting efficiency (time\nto generate test cases) and effectiveness (fault detection rates). Results\nindicate that quantum annealing enables faster test case generation while\nachieving comparable fault detection performance to state-of-the-art\nalternatives.","main_category":"cs.ET","categories":"cs.ET,cs.SE","published":"2025-04-30T14:20:58Z"}
{"aid":"http://arxiv.org/abs/2504.21691v1","title":"Landau-Zener-Stückelberg spectroscopy of a fluxonium quantum circuit","summary":"In this work, we study the time-averaged populations obtained for a fluxonium\ncircuit under a large amplitude nonresonant periodic drive. We present\nnumerical simulations of the time evolution which consider the multi-level\nstructure of the driven quantum circuit, looking for a realistic modeling\ncloser to experimental implementations. The Landau-Zener-St\\\"uckelberg spectra\nshow resonances that can be understood as originated from constructive\ninterference favoring transitions to higher levels. For a truncated two-level\nsystem (TLS) the resonance patterns can be interpreted using a simplified\ndescription of the avoided crossing that takes into account the dynamic phase\naccumulated at each operation point. For the multilevel case, we derive an\neffective two-level Hamiltonian using a Schrieffer-Wolff transformation\nstarting from the Floquet Hamiltonian in the Sambe space. Our study provides\npredictive insight into experimental outcomes, offering an intuitive\ninterpretation that could also support the implementation of fast-non-adiabatic\nsingle-qubit gates and entangling protocols.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-30T14:28:03Z"}
{"aid":"http://arxiv.org/abs/2504.21696v1","title":"MovementVR: An open-source tool for the study of motor control and\n  learning in virtual reality","summary":"Virtual reality (VR) is increasingly used to enhance the ecological validity\nof motor control and learning studies by providing immersive, interactive\nenvironments with precise motion tracking. However, designing realistic\nVR-based motor tasks remains complex, requiring advanced programming skills and\nlimiting accessibility in research and clinical settings. MovementVR is an\nopen-source platform designed to address these challenges by enabling the\ncreation of customizable, naturalistic reaching tasks in VR without coding\nexpertise. It integrates physics-based hand-object interactions, real-time hand\ntracking, and flexible experimental paradigms, including motor adaptation and\nreinforcement learning. The intuitive graphical user interface (GUI) allows\nresearchers to customize task parameters and paradigm structure. Unlike\nexisting platforms, MovementVR eliminates the need for scripting while\nsupporting extensive customization and preserving ecological validity and\nrealism. In addition to reducing technical barriers, MovementVR lowers\nfinancial constraints by being compatible with consumer-grade VR headsets. It\nis freely available with comprehensive documentation, facilitating broader\nadoption in movement research and rehabilitation.","main_category":"q-bio.QM","categories":"q-bio.QM","published":"2025-04-30T14:39:01Z"}
{"aid":"http://arxiv.org/abs/2504.21697v1","title":"Effective interface forces to model boundary effects in a finite-size\n  metamaterial through the reduced relaxed micromorphic model","summary":"We use the reduced relaxed micromorphic model (RRMM) to capture the effective\n\"bulk\" dynamical response of finite size metamaterial specimens made out of a\nLabyrinthine unit cell. We show that for small finite-size specimens, boundary\neffects can play a major role, so that the RRMM needs an enrichment to capture\nthe metamaterial's bulk response, as well as the boundary effects. A benchmark\ntest is introduced to show that different metamaterial/ homogeneous material\ninterfaces can drive completely different responses even if the bulk\nmetamaterial remains the same. We show with no remaining doubts that the\nconcept of \"interface forces\" must necessarily be introduced if one wants to\nmodel finite-size metamaterials in a homogenized framework.","main_category":"physics.app-ph","categories":"physics.app-ph,J.2","published":"2025-04-30T14:42:04Z"}
{"aid":"http://arxiv.org/abs/2504.21698v1","title":"Dilepton emission in heavy ion collisions and chemical equilibrium of\n  QCD matter","summary":"We study thermal dilepton production and anisotropic flow in Pb+Pb collisions\nat $\\sqrt{s_{NN}} = 5.02 \\, \\mathrm{TeV}$ using next-to-leading-order (NLO)\nthermal QCD dilepton emission rates. A hybrid model\n(IP-Glasma+\\kompost+MUSIC+UrQMD) simulates the collision evolution. The role of\nthe pre-equilibrium stage in dilepton observables is examined. We also explore\nhow chemical equilibrium in QCD matter affect dilepton observables.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-30T14:43:35Z"}
{"aid":"http://arxiv.org/abs/2504.21729v1","title":"Diffusion Limit and the optimal convergence rate of the classical\n  solution to the one-species Vlasov-Maxwell-Boltzmann system","summary":"In the present paper, we study the diffusion limit of the strong solution to\nthe one-species Vlasov-Maxwell-Boltzmann (VMB) system with initial data near a\nglobal Maxwellian. Based on spectral analysis techniques, we prove the\nconvergence and establish the convergence rate of the classical solution to the\nVMB system towards the solution to the incompressible Navier--Stokes--Maxwell\nsystem with a precise estimation on the initial layer.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T15:20:46Z"}
{"aid":"http://arxiv.org/abs/2504.21741v1","title":"Asymptotic diameter of preferential attachment model","summary":"We study the asymptotic diameter of the preferential attachment model\n$\\operatorname{PA}\\!_n^{(m,\\delta)}$ with parameters $m \\ge 2$ and $\\delta >\n0$. Building on the recent work \\cite{VZ25}, we prove that the diameter of $G_n\n\\sim \\operatorname{PA}\\!_n^{(m,\\delta)}$ is $(1+o(1))\\log_\\nu n$ with high\nprobability, where $\\nu$ is the exponential growth rate of the local weak limit\nof $G_n$. Our result confirms the conjecture in \\cite{VZ25} and closes the\nremaining gap in understanding the asymptotic diameter of preferential\nattachment graphs with general parameters $m \\ge 1$ and $\\delta >-m$. Our proof\nfollows a general recipe that relates the diameter of a random graph to its\ntypical distance, which we expect to have applicability in a broader range of\nmodels.","main_category":"math.PR","categories":"math.PR,math.CO","published":"2025-04-30T15:38:50Z"}
{"aid":"http://arxiv.org/abs/2504.21743v1","title":"Obstructive Sleep Apnea Characterization: A Multimodal\n  Cross-Recurrence-Based Approach for Investigating Atrial Fibrillation","summary":"Obstructive sleep apnea (OSA) is believed to contribute significantly to\natrial fibrillation (AF) development in certain patients. Recent studies\nindicate a rising risk of AF with increasing OSA severity. However, the\ncommonly used apnea-hypopnea index in clinical practice may not adequately\naccount for the potential cardiovascular risks associated with OSA. (1)\nObjective: to propose and explore a novel method for assessing OSA severity\nconsidering potential connection to cardiac arrhythmias. (2) Method: the\napproach utilizes cross-recurrence features to characterize OSA and AF by\nconsidering the relationships among oxygen desaturation, pulse arrival time,\nand heart-beat intervals. Multinomial logistic regression models were trained\nto predict four levels of OSA severity and four groups related to heart rhythm\nissues. The rank biserial correlation coefficient, rrb, was used to estimate\neffect size for statistical analysis. The investigation was conducted using the\nMESA database, which includes polysomnography data from 2055 subjects. (3)\nResults: a derived cross-recurrence-based index showed a significant\nassociation with a higher OSA severity (p < 0.01) and the presence of AF (p <\n0.01). Additionally, the proposed index had a significantly larger effect, rrb,\nthan the conventional apnea-hypopnea index in differentiating increasingly\nsevere heart rhythm issue groups: 0.14 > 0.06, 0.33 > 0.10, and 0.41 > 0.07.\n(4) Significance: the proposed method holds relevance as a supplementary\ndiagnostic tool for assessing the authentic state of sleep apnea in clinical\npractice.","main_category":"physics.med-ph","categories":"physics.med-ph,eess.SP","published":"2025-04-30T15:39:07Z"}
{"aid":"http://arxiv.org/abs/2504.21747v1","title":"Improving Retrieval-Augmented Neural Machine Translation with\n  Monolingual Data","summary":"Conventional retrieval-augmented neural machine translation (RANMT) systems\nleverage bilingual corpora, e.g., translation memories (TMs). Yet, in many\nsettings, in-domain monolingual target-side corpora are often available. This\nwork explores ways to take advantage of such resources by retrieving relevant\nsegments directly in the target language, based on a source-side query. For\nthis, we design improved cross-lingual retrieval systems, trained with both\nsentence level and word-level matching objectives. In our experiments with two\nRANMT architectures, we first demonstrate the benefits of such cross-lingual\nobjectives in a controlled setting, obtaining translation performances that\nsurpass standard TM-based models. We then showcase our method on a real-world\nset-up, where the target monolingual resources far exceed the amount of\nparallel data and observe large improvements of our new techniques, which\noutperform both the baseline setting, and general-purpose cross-lingual\nretrievers.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-04-30T15:41:03Z"}
{"aid":"http://arxiv.org/abs/2504.21749v1","title":"Common3D: Self-Supervised Learning of 3D Morphable Models for Common\n  Objects in Neural Feature Space","summary":"3D morphable models (3DMMs) are a powerful tool to represent the possible\nshapes and appearances of an object category. Given a single test image, 3DMMs\ncan be used to solve various tasks, such as predicting the 3D shape, pose,\nsemantic correspondence, and instance segmentation of an object. Unfortunately,\n3DMMs are only available for very few object categories that are of particular\ninterest, like faces or human bodies, as they require a demanding 3D data\nacquisition and category-specific training process. In contrast, we introduce a\nnew method, Common3D, that learns 3DMMs of common objects in a fully\nself-supervised manner from a collection of object-centric videos. For this\npurpose, our model represents objects as a learned 3D template mesh and a\ndeformation field that is parameterized as an image-conditioned neural network.\nDifferent from prior works, Common3D represents the object appearance with\nneural features instead of RGB colors, which enables the learning of more\ngeneralizable representations through an abstraction from pixel intensities.\nImportantly, we train the appearance features using a contrastive objective by\nexploiting the correspondences defined through the deformable template mesh.\nThis leads to higher quality correspondence features compared to related works\nand a significantly improved model performance at estimating 3D object pose and\nsemantic correspondence. Common3D is the first completely self-supervised\nmethod that can solve various vision tasks in a zero-shot manner.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T15:42:23Z"}
{"aid":"http://arxiv.org/abs/2504.21753v1","title":"Tailored Hotspots from Airy-Based Surface Plasmon Polaritons","summary":"Surface plasmons have attracted growing interest from the photonics community\ndue to their inherent ability to controllably confine light below the\ndiffraction limit and their direct application in trapping and transporting\nmatter at the nanoscale. This method, known as plasmonic tweezers, employs\nconfined fields generated by either localized plasmons or surface plasmon\npolaritons (SPP), which originate in the vicinity of nanostructure-based traps\nor across structureless platforms, respectively. Herein, we present a new\ntheoretical method for generating intense light hotspots and engineering their\nfeatures by overlapping Airy SPPs (ASPP) at a smooth dielectric-metal\ninterface. We coherently add pairs of Hermite-Gauss modes that belong to a\nnovel complete basis set of finite-energy ASPPs, which yield highly confined\nplasmonic hotspots ($\\approx \\lambda$/10) without the need of using any\nnanostructured platform. Mode order and relative spacing parameters can be used\nto tailor the intensity and quality factor of said hotspots, largely\noutperforming their Gaussian-only-based counterparts. Our method opens a\npromising venue to confine light at the nanoscale using ASPP-based structured\nlight, which helps to advance the development of structureless plasmonic\ntweezers and holds promising potential for its application in optical signal\nprocessing and plasmonic circuitry.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-30T15:48:54Z"}
{"aid":"http://arxiv.org/abs/2504.21756v1","title":"Ends of the strata of differentials","summary":"We enumerate the ends of each stratum of meromorphic 1-forms on Riemann\nsurfaces with prescribed multiplicities of zeroes and poles. Our proof uses\ndegeneration techniques based on the construction by\nBainbridge-Chen-Gendron-Grushevsky-Moeller of the moduli space of multi-scale\ndifferentials, together with recent classification of connected components of\ngeneralized strata by Lee-Wong. In particular, from these results we quickly\ndeduce the theorem for holomorphic 1-forms, originally proved by Boissy.","main_category":"math.GT","categories":"math.GT,math.AG,math.DS","published":"2025-04-30T15:54:50Z"}
{"aid":"http://arxiv.org/abs/2504.21758v1","title":"Quantum Mpemba effect from initial system-reservoir entanglement","summary":"The Mpemba effect -- where hot systems cool faster than colder ones -- has\nintrigued both classical and quantum thermodynamics. As compared to classical\nsystems, quantum systems add complexity due to quantum correlations. Recent\nworks have explored anomalous relaxation and Mpemba-like effects in several\nquantum systems, considering isolated systems at zero temperature or open\nsystems in contact with reservoirs under Markovian or non-Markovian dynamics.\nHowever, these models typically assume an initial unentangled system-bath\nstate, overlooking the role of initial system-environment correlations. Here we\npropose a type of quantum Mpemba effect, distinct from the strong Mpemba\neffect, originating from initial system-bath entanglement solely. It is shown\nthat the degree of initial entanglement significantly influences the early\nrelaxation dynamics, with certain conditions causing backflow and retarded\nthermalization. As an example, we investigate the spontaneous emission of a\ntwo-level atom in a photonic waveguide at zero temperature, where an initial\natom-photon entangled state results in delayed relaxation and pronounced Mpemba\neffect. These findings highlight the crucial role of quantum correlations in\nthermalization processes and open new avenues for identifying and engineering\nquantum Mpemba phenomena. Controlling relaxation dynamics through\nsystem-environment entanglement may have potential applications in quantum\nthermal machines, state initialization protocols, and quantum information\nprocessing, where precise control over thermalization is essential.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-30T15:58:17Z"}
{"aid":"http://arxiv.org/abs/2504.21761v1","title":"Is Stephen Curry really a guard? New perspective on players typology\n  using functional data analysis","summary":"We present a novel representation of NBA players' shooting patterns based on\nFunctional Data Analysis (FDA). Each player's charts of made and missed shots\nare treated as smooth functional data defined over a two-dimensional domain\ncorresponding to the offensive half-court. This continuous representation\nenables a parsimonious multivariate functional principal components analysis\n(MFPCA) decomposition, producing a set of common principal component functions\nthat capture the primary modes of variability in shooting patterns, along with\nplayer-specific scores that quantify individual deviations from the average\nbehavior. We first interpret the principal component functions to characterize\nthe main sources of variation in shooting tendencies. We then apply $k$-medoids\nclustering to the principal component scores to construct a data-driven\ntaxonomy of players. Comparing our empirical clusters to conventional NBA\nposition labels reveals low agreement, suggesting that our shooting-pattern\nrepresentation might capture aspects of playing style not fully reflected in\nofficial designations. The proposed methodology provides a flexible,\ninterpretable, and continuous framework for analyzing player tendencies, with\npotential applications in coaching, scouting, and historical player or match\ncomparisons.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-30T16:01:56Z"}
{"aid":"http://arxiv.org/abs/2504.21763v1","title":"Biases from Missing a Small Planet in High Multiplicity Systems","summary":"In an era when we are charting multiple planets per system, one might wonder\nthe extent to which \"missing\" (or failing to detect) a planet can skew our\ninterpretation of the system architecture. We address this question with a\nsimple experiment: starting from a large, homogeneous catalog, we remove\nplanets and monitor how several well-defined metrics of the system architecture\nchange. We first perform this test on a catalog of observed exoplanets. We then\nrepeat our test on a catalog of synthetic planetary systems with underlying\nhyperparameters that have been fit to reproduce the observed systems as\nfaithfully as possible (though imperfectly). For both samples, we find that the\nfailure to detect one or more planets tends to create more irregularly spaced\nplanets, whereas the planet mass similarity and coplanarity are essentially\nunaffected. One key difference between the synthetic and observed data sets is\nthat the observed systems have more evenly spaced planets than the\nobservation-bias-applied synthetic systems. Since our tests show that detection\nbias tends to increase irregularity in spacing, the even spacing in the\nobserved planetary systems is likely astrophysical rather than the result of\nthe Kepler missions' inherent detection biases. Our findings support the\ninterpretation that planets in the same system have similar sizes and regular\nspacing and reinforce the need to develop an underlying model of planetary\narchitectures that reproduces these observed patterns.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-30T16:02:58Z"}
{"aid":"http://arxiv.org/abs/2504.21774v1","title":"Is Intermediate Fusion All You Need for UAV-based Collaborative\n  Perception?","summary":"Collaborative perception enhances environmental awareness through inter-agent\ncommunication and is regarded as a promising solution to intelligent\ntransportation systems. However, existing collaborative methods for Unmanned\nAerial Vehicles (UAVs) overlook the unique characteristics of the UAV\nperspective, resulting in substantial communication overhead. To address this\nissue, we propose a novel communication-efficient collaborative perception\nframework based on late-intermediate fusion, dubbed LIF. The core concept is to\nexchange informative and compact detection results and shift the fusion stage\nto the feature representation level. In particular, we leverage vision-guided\npositional embedding (VPE) and box-based virtual augmented feature (BoBEV) to\neffectively integrate complementary information from various agents.\nAdditionally, we innovatively introduce an uncertainty-driven communication\nmechanism that uses uncertainty evaluation to select high-quality and reliable\nshared areas. Experimental results demonstrate that our LIF achieves superior\nperformance with minimal communication bandwidth, proving its effectiveness and\npracticality. Code and models are available at https://github.com/uestchjw/LIF.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-30T16:22:14Z"}
{"aid":"http://arxiv.org/abs/2504.21777v1","title":"Near-Optimal Distributed Ruling Sets for Trees and High-Girth Graphs","summary":"Given a graph $G=(V,E)$, a $\\beta$-ruling set is a subset $S\\subseteq V$ that\nis i) independent, and ii) every node $v\\in V$ has a node of $S$ within\ndistance $\\beta$. In this paper we present almost optimal distributed\nalgorithms for finding ruling sets in trees and high girth graphs in the\nclassic LOCAL model. As our first contribution we present an $O(\\log\\log\nn)$-round randomized algorithm for computing $2$-ruling sets on trees, almost\nmatching the $\\Omega(\\log\\log n/\\log\\log\\log n)$ lower bound given by Balliu et\nal. [FOCS'20]. Second, we show that $2$-ruling sets can be solved in\n$\\widetilde{O}(\\log^{5/3}\\log n)$ rounds in high-girth graphs. Lastly, we show\nthat $O(\\log\\log\\log n)$-ruling sets can be computed in $\\widetilde{O}(\\log\\log\nn)$ rounds in high-girth graphs matching the lower bound up to triple-log\nfactors. All of these results either improve polynomially or exponentially on\nthe previously best algorithms and use a smaller domination distance $\\beta$.","main_category":"cs.DS","categories":"cs.DS,cs.DC","published":"2025-04-30T16:29:14Z"}
{"aid":"http://arxiv.org/abs/2504.21779v1","title":"Normality of 8-Bit Bent Function","summary":"Bent functions are Boolean functions in an even number of variables that are\nindicators of Hadamard difference sets in elementary abelian 2-groups. A bent\nfunction in m variables is said to be normal if it is constant on an affine\nspace of dimension m/2. In this paper, we demonstrate that all bent functions\nin m = 8 variables -- whose exact count, determined by Langevin and Leander\n(Des. Codes Cryptogr. 59(1--3): 193--205, 2011), is approximately $2^106$ share\na common algebraic property: every 8-variable bent function is normal, up to\nthe addition of a linear function. With this result, we complete the analysis\nof the normality of bent functions for the last unresolvedcase, m= 8. It is\nalready known that all bent functions in m variables are normal for m <= 6,\nwhile for m > = 10, there exist bent functions that cannot be made normal by\nadding linear functions. Consequently, we provide a complete solution to an\nopen problem by Charpin (J. Complex. 20(2-3): 245-265, 2004)","main_category":"cs.DM","categories":"cs.DM","published":"2025-04-30T16:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.21782v1","title":"Transformations and summations for bilateral basic hypergeometric series","summary":"We derive transformation and summation formulas for bilateral basic\nhypergeometric series. As a starting point, we use two transformations of\nbilateral basic very-well-poised ${}_8\\Psi_8$. The first transformation is\ngiven as a sum of two nonterminating ${}_8W_7$'s and the second is given in\nterms of a sum of a ${}_4\\psi_4$ and two balanced ${}_4\\phi_3$'s. From these\ntransformations we derive limiting transformations with vanishing denominator\nelements which shed light on the transformation properties of these bilateral\nbasic hypergeometric series. We also study tuple product identities, namely\ntriple, quintuple, sextuple, septuple, octuple, nonuple and undecuple, which\nare given in terms of sums of bilateral basic hypergeometric series.","main_category":"math.CA","categories":"math.CA","published":"2025-04-30T16:38:36Z"}
{"aid":"http://arxiv.org/abs/2504.21789v1","title":"Anomaly-Driven Approach for Enhanced Prostate Cancer Segmentation","summary":"Magnetic Resonance Imaging (MRI) plays an important role in identifying\nclinically significant prostate cancer (csPCa), yet automated methods face\nchallenges such as data imbalance, variable tumor sizes, and a lack of\nannotated data. This study introduces Anomaly-Driven U-Net (adU-Net), which\nincorporates anomaly maps derived from biparametric MRI sequences into a deep\nlearning-based segmentation framework to improve csPCa identification. We\nconduct a comparative analysis of anomaly detection methods and evaluate the\nintegration of anomaly maps into the segmentation pipeline. Anomaly maps,\ngenerated using Fixed-Point GAN reconstruction, highlight deviations from\nnormal prostate tissue, guiding the segmentation model to potential cancerous\nregions. We compare the performance by using the average score, computed as the\nmean of the AUROC and Average Precision (AP). On the external test set, adU-Net\nachieves the best average score of 0.618, outperforming the baseline nnU-Net\nmodel (0.605). The results demonstrate that incorporating anomaly detection\ninto segmentation improves generalization and performance, particularly with\nADC-based anomaly maps, offering a promising direction for automated csPCa\nidentification.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-30T16:48:00Z"}
{"aid":"http://arxiv.org/abs/2504.21793v1","title":"Reconciling Discrete-Time Mixed Policies and Continuous-Time Relaxed\n  Controls in Reinforcement Learning and Stochastic Control","summary":"Reinforcement learning (RL) is currently one of the most popular methods,\nwith breakthrough results in a variety of fields. The framework relies on the\nconcept of Markov decision process (MDP), which corresponds to a discrete time\noptimal control problem. In the RL literature, such problems are usually\nformulated with mixed policies, from which a random action is sampled at each\ntime step. Recently, the optimal control community has studied continuous-time\nversions of RL algorithms, replacing MDPs with mixed policies by continuous\ntime stochastic processes with relaxed controls. In this work, we rigorously\nconnect the two problems: we prove the strong convergence of the former towards\nthe latter when the time discretization goes to $0$.","main_category":"math.OC","categories":"math.OC","published":"2025-04-30T16:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.21796v1","title":"On point interactions in two dimensions via additive functionals","summary":"By taking the viewpoint of Brownian additive functionals, we extend an\nexisting approximation theorem of the two-dimensional Laplacian singularly\nperturbed at the origin. The approximate operators are defined by adding a\nrescaled function to the two-dimensional Laplacian such that the support of the\nperturbation thus produced converges to a point in the limit of the rescaling,\nand we also impose suitable renormalizations of the coupling constants. The\nfirst main theorem assumes the zero total mass of the function for rescaling\nand proves limits of the approximate resolvents up to an extended criticality\ndefined by two levels of phase transitions. The second main theorem handles the\ncase of positive total mass of the function for rescaling and proves an\nasymptotic expansion of a multivariate density induced by the approximate\nresolvent. Moreover, this expansion is valid beyond criticality.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T16:52:58Z"}
{"aid":"http://arxiv.org/abs/2504.21798v1","title":"SWE-smith: Scaling Data for Software Engineering Agents","summary":"Despite recent progress in Language Models (LMs) for software engineering,\ncollecting training data remains a significant pain point. Existing datasets\nare small, with at most 1,000s of training instances from 11 or fewer GitHub\nrepositories. The procedures to curate such datasets are often complex,\nnecessitating hundreds of hours of human labor; companion execution\nenvironments also take up several terabytes of storage, severely limiting their\nscalability and usability. To address this pain point, we introduce SWE-smith,\na novel pipeline for generating software engineering training data at scale.\nGiven any Python codebase, SWE-smith constructs a corresponding execution\nenvironment, then automatically synthesizes 100s to 1,000s of task instances\nthat break existing test(s) in the codebase. Using SWE-smith, we create a\ndataset of 50k instances sourced from 128 GitHub repositories, an order of\nmagnitude larger than all previous works. We train SWE-agent-LM-32B, achieving\n40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art\namong open source models. We open source SWE-smith (collection procedure, task\ninstances, trajectories, models) to lower the barrier of entry for research in\nLM systems for automated software engineering. All assets available at\nhttps://swesmith.com.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL","published":"2025-04-30T16:56:06Z"}
{"aid":"http://arxiv.org/abs/2504.21809v1","title":"Particle, kinetic and hydrodynamic models for sea ice floes. Part I:\n  non-rotating floes","summary":"We introduce a comprehensive modeling framework for the dynamics of sea ice\nfloes using particle, kinetic, and hydrodynamic approaches. Building upon the\nfoundational work of Ha and Tadmor on the Cucker-Smale model for flocking, we\nderive a Vlasov-type kinetic formulation and a corresponding hydrodynamic\ndescription. The particle model incorporates essential physical properties of\nsea ice floes, including size, position, velocity, and interactions governed by\nNewtonian mechanics. By extending these principles, the kinetic model captures\nlarge-scale features through the phase-space distribution, and we also present\na hydrodynamic model using the velocity moments and a suitable closure\ncondition. In this paper, as an idea-introductory step, we assume that ice\nfloes are non-rotating and focus on the linear velocity dynamics. Our approach\nhighlights the role of contact forces, ocean drag effects, and conservation\nlaws in the multiscale description of sea ice dynamics, offering a pathway for\nthe improved understanding and prediction of sea ice behaviors in changing\nclimatic conditions.","main_category":"math.DS","categories":"math.DS,physics.app-ph","published":"2025-04-30T17:13:10Z"}
{"aid":"http://arxiv.org/abs/2504.21819v1","title":"On spatial systems of cities","summary":"Are there multiple equilibria in the spatial economy? This paper develops a\nunified framework that integrates systems of cities and regional models to\naddress this question within a general geographic space. A key feature is the\nendogenous formation of commuting areas linking a continuum of residential\nlocations to a finite set of potential business districts. Using tools from\ncomputational geometry and shape optimization, we derive sufficient conditions\nfor the existence and uniqueness of spatial equilibria. For plausible parameter\nvalues, urban location is indeterminate, but, conditional on an urban system,\ncity sizes are uniquely determined. The framework reconciles seemingly\nconflicting empirical findings on the role of geography and scale economies in\nshaping the spatial economy.","main_category":"econ.TH","categories":"econ.TH,math.OC","published":"2025-04-30T17:24:43Z"}
{"aid":"http://arxiv.org/abs/2504.21821v1","title":"Local Weak Degeneracy of Planar Graphs","summary":"Thomassen showed that planar graphs are 5-list-colourable, and that planar\ngraphs of girth at least five are 3-list-colourable. An easy degeneracy\nargument shows that planar graphs of girth at least four are 4-list-colourable.\nIn 2022, Postle and Smith-Roberge proved a common strengthening of these three\nresults: with $g(v)$ denoting the length of a shortest cycle containing a\nvertex $v$, they showed that if $G$ is a planar graph and $L$ a list assignment\nfor $G$ where $|L(v)| \\geq \\max\\{3,8-g(v)\\}$ for all $v \\in V(G)$, then $G$ is\n$L$-colourable. Moreover, they conjectured that an analogous theorem should\nhold for correspondence colouring. We prove this conjecture; in fact, our main\ntheorem holds in the still more restrictive setting of weak degeneracy, and\nmoreover acts as a joint strengthening of the fact that planar graphs are\nweakly 4-degenerate (originally due to Bernshteyn, Lee, and Smith-Roberge), and\nthat planar graphs of girth at least five are weakly 2-degenerate (originally\ndue to Han et al.).","main_category":"math.CO","categories":"math.CO","published":"2025-04-30T17:26:36Z"}
{"aid":"http://arxiv.org/abs/2504.21825v1","title":"Rovibrational computation of H$_3^+$ with permutationally invariant\n  Pekeris coordinates","summary":"The Pekeris coordinates provide a permutationally invariant set of\ncoordinates for H$_3^+$. They are defined as the linear combination of the\nthree internuclear distances that automatically fulfils the triangle inequality\nfor all non-negative coordinate values. In this work, we test three discrete\nvariable representations (DVR) for tightly converging the rovibrational\nenergies up to and beyond the barrier to linearity using the Pekeris\ncoordinates. The best performing representation is a cot-DVR-type approach\nadapted to the Pekeris problem. The two- and three-proton near coalescence\nregion, which is also part of the direct product Pekeris grid but dynamically\nnot relevant, is avoided by coordinate mapping.","main_category":"physics.chem-ph","categories":"physics.chem-ph,quant-ph","published":"2025-04-30T17:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.21830v1","title":"Existence of Large Boundary Layer Solutions to Inflow Problem of 1D Full\n  Compressible Navier-Stokes Equations","summary":"We present the existence/non-existence criteria for large-amplitude boundary\nlayer solutions to the inflow problem of the one-dimensional (1D) full\ncompressible Navier-Stokes equations on a half line $\\mathbb{R}_+$. Instead of\nthe classical center manifold approach for the existence of small-amplitude\nboundary layer solutions in the previous results, the delicate global phase\nplane analysis, based on the qualitative theory of ODEs, is utilized to obtain\nthe sufficient and necessary conditions for the existence/non-existence of\nlarge boundary layer solutions to the half-space inflow problem when the right\nend state belongs to the supersonic, transonic, and subsonic regions,\nrespectively, which completely answers the existence/non-existence of boundary\nlayer solutions to the half-space inflow problem of 1D full compressible\nNavier-Stokes equations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T17:34:59Z"}
{"aid":"http://arxiv.org/abs/2504.21833v1","title":"Non-standard quantum algebras and infinite-dimensional PT-symmetric\n  systems","summary":"In this work, we introduce a PT-symmetric infinite-dimensional representation\nof the Uz(sl(2,R)) Hopf algebra, and we analyse a multiparametric family of\nHamiltonians constructed from such representation of the generators of this\nnon-standard quantum algebra. It is shown that all these Hamiltonians can be\nmapped to equivalent systems endowed with a position-dependent mass. From the\nlatter presentation, it is shown how appropriate point canonical\ntransformations can be further defined in order to transform them into\nHamiltonians with constant mass over suitable domains. By following this\napproach, the bound-state spectrum and the corresponding eigenfunctions of the\ninitial PT-symmetric Hamiltonians can be determined. It is worth stressing that\na relevant feature of some of the new Uz(sl(2,R)) systems here presented is\nfound to be their connection with double-well and P\\\"oschl-Teller potentials.\nIn fact, as an application we present a particular Hamiltonian that can be\nexpressed as an effective double-well trigonometric potential, which is\ncommonly used to model several relevant systems in molecular physics.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-30T17:40:56Z"}
{"aid":"http://arxiv.org/abs/2504.21843v1","title":"Accretion inside astrophysical objects : Effects of rotation and\n  viscosity","summary":"Sub-solar mass black holes could show up in gravitational observations in\nfuture and near-solar mass black holes might have been involved in the events\nGW190425 and GW190814. Since they cannot form from the stellar evolution, their\ncreation requires exotic mechanisms. One such mechanism involves the capture of\ndark matter particles by stellar objects and their thermalization. When the\ncriterion for the collapse of these dark matter particles is satisfied, a tiny\nendoparasitic black hole (EBH) forms and then it accretes matter from the host.\nThe EBH may transmute the host into a black hole of nearly the same mass as the\nhost or lesser, depending on the type of accretion. We examine this complex and\npoorly explored accretion mechanism, considering the effects of rotation and\nviscosity but ignoring some other effects, such as those of pressure and\nmagnetic field, as the first step. Using a general framework to assess the\neffects of rotation and viscosity on accretion, we show that the accretion\ncould be stalled in some white dwarfs, but not in neutron stars. The stalled\naccretion should cause an opening in the host's polar regions, the extent of\nwhich depends on the mass and spin of the host.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.CO,gr-qc,hep-th","published":"2025-04-30T17:52:25Z"}
{"aid":"http://arxiv.org/abs/2504.21849v1","title":"Public Opinion and The Rise of Digital Minds: Perceived Risk, Trust, and\n  Regulation Support","summary":"Governance institutions must respond to societal risks, including those posed\nby generative AI. This study empirically examines how public trust in\ninstitutions and AI technologies, along with perceived risks, shape preferences\nfor AI regulation. Using the nationally representative 2023 Artificial\nIntelligence, Morality, and Sentience (AIMS) survey, we assess trust in\ngovernment, AI companies, and AI technologies, as well as public support for\nregulatory measures such as slowing AI development or outright bans on advanced\nAI. Our findings reveal broad public support for AI regulation, with risk\nperception playing a significant role in shaping policy preferences.\nIndividuals with higher trust in government favor regulation, while those with\ngreater trust in AI companies and AI technologies are less inclined to support\nrestrictions. Trust in government and perceived risks significantly predict\npreferences for both soft (e.g., slowing development) and strong (e.g., banning\nAI systems) regulatory interventions. These results highlight the importance of\npublic opinion in AI governance. As AI capabilities advance, effective\nregulation will require balancing public concerns about risks with trust in\ninstitutions. This study provides a foundational empirical baseline for\npolicymakers navigating AI governance and underscores the need for further\nresearch into public trust, risk perception, and regulatory strategies in the\nevolving AI landscape.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC","published":"2025-04-30T17:56:23Z"}
{"aid":"http://arxiv.org/abs/2505.00250v1","title":"Hard-jet correlations in large and small systems","summary":"Hard-jet correlations probe parton energy loss and the microscopic structure\nof the quark-gluon plasma formed in ultra-relativistic heavy-ion collisions.\nThe correlation of high-$p_\\mathrm{T}$ jets with other jets, hadrons, or\nelectroweak bosons, offers differential sensitivity to medium-induced effects\nsuch as momentum broadening, color decoherence, and medium response in\ndifferent types of nuclear reactions. Such correlations can also be used to\nstudy cold nuclear matter effects arising in $p$+A collisions. This proceeding\nsummarizes recent advances achieved by studying hard-jet correlations in large\nand small systems discussed at Hard Probes 2024, complementing the experimental\njet overview.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-05-01T02:26:52Z"}
{"aid":"http://arxiv.org/abs/2505.00255v1","title":"Numerical analysis on locally risk-minimizing strategies for\n  Barndorff-Nielsen and Shephard models","summary":"We develop a numerical method for locally risk-minimizing (LRM) strategies\nfor Barndorff-Nielsen and Shephard (BNS) models. Arai et al. (2017) derived a\nmathematical expression for LRM strategies in BNS models using Malliavin\ncalculus for L\\'evy processes and presented some numerical results only for the\ncase where the asset price process is a martingale. Subsequently, Arai and Imai\n(2024) developed the first Monte Carlo (MC) method available for non-martingale\nBNS models with infinite active jumps. Here, we modify the expression obtained\nby Arai et al. (2017) into a numerically tractable form, and, using the MC\nmethod developed by Arai and Imai (2024), propose a numerical method of LRM\nstrategies available for non-martingale BNS models with infinite active jumps.\nIn the final part of this paper, we will conduct some numerical experiments.","main_category":"q-fin.CP","categories":"q-fin.CP","published":"2025-05-01T02:41:11Z"}
{"aid":"http://arxiv.org/abs/2505.00265v1","title":"Field-scale soil moisture estimated from Sentinel-1 SAR data using a\n  knowledge-guided deep learning approach","summary":"Soil moisture (SM) estimation from active microwave data remains challenging\ndue to the complex interactions between radar backscatter and surface\ncharacteristics. While the water cloud model (WCM) provides a semi-physical\napproach for understanding these interactions, its empirical component often\nlimits performance across diverse agricultural landscapes. This research\npresents preliminary efforts for developing a knowledge-guided deep learning\napproach, which integrates WCM principles into a long short-term memory (LSTM)\nmodel, to estimate field SM using Sentinel-1 Synthetic Aperture Radar (SAR)\ndata. Our proposed approach leverages LSTM's capacity to capture spatiotemporal\ndependencies while maintaining physical consistency through a modified\ndual-component loss function, including a WCM-based semi-physical component and\na boundary condition regularisation. The proposed approach is built upon the\nsoil backscatter coefficients isolated from the total backscatter, together\nwith Landsat-resolution vegetation information and surface characteristics. A\nfour-fold spatial cross-validation was performed against in-situ SM data to\nassess the model performance. Results showed the proposed approach reduced SM\nretrieval uncertainties by 0.02 m$^3$/m$^3$ and achieved correlation\ncoefficients (R) of up to 0.64 in areas with varying vegetation cover and\nsurface conditions, demonstrating the potential to address the\nover-simplification in WCM.","main_category":"cs.LG","categories":"cs.LG,eess.IV","published":"2025-05-01T03:12:25Z"}
{"aid":"http://arxiv.org/abs/2505.00283v1","title":"High Dimensional Ensemble Kalman Filter","summary":"The ensemble Kalman Filter (EnKF), as a fundamental data assimilation\napproach, has been widely used in many fields of earth science, engineering and\nbeyond. However, there are several unknown theoretical aspects of the EnKF,\nespecially when the state variable is of high dimensional accompanied with high\nresolution observation and physical models. This paper first proposes several\nhigh dimensional EnKF methods which provide consistent estimators for the\nimportant forecast error covariance and the Kalman gain matrix. It then studies\nthe theoretical properties of the EnKF under both the fixed and high\ndimensional state variables, which provides the mean square errors of the\nanalysis states to the underlying oracle states offered by the Kalman filter\nand gives the much needed insight into the roles played by forecast error\ncovariance on the accuracy of the EnKF. The accuracy of the data assimilation\nunder the misspecified physical model is also considered. Numerical studies on\nthe Lorenz-96 and the Shallow Water Equation models illustrate that the\nproposed high dimensional EnKF algorithms perform better than the standard EnKF\nmethods as they provide more robust and accurate assimilated results. The high\ndimensional EnKF is applied to assimilate sea temperature in Northwest Pacific,\nwhich showed more accurate out-sample performance than the existing methods.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-01T04:12:10Z"}
{"aid":"http://arxiv.org/abs/2505.00288v1","title":"Nyström Type Exponential Integrators for Strongly Magnetized Charged\n  Particle Dynamics","summary":"Calculating the dynamics of charged particles in electromagnetic fields (i.e.\nthe particle pushing problem) is one of the most computationally intensive\ncomponents of particle-in-cell (PIC) methods for plasma physics simulations.\nThis task is especially challenging when the plasma is strongly magnetized,\nsince in this case the particle motion consists of a wide range of temporal\nscales from highly oscillatory fast gyromotion to slow macroscopic behavior and\nthe resulting numerical model is very stiff. Current state-of-the-art time\nintegrators used to simulate particle motion have limitations given the severe\nnumerical stiffness of the problem and more efficient methods are of interest.\nRecently, exponential integrators have been proposed as a promising new\napproach for these simulations and shown to offer computational advantages over\ncommonly used schemes. Exponential methods can solve linear problems exactly\nand are $A$-stable. In this paper, the standard exponential algorithms\nframework is extended to derive Nystr\\\"om-type exponential methods that\nintegrate the Newtonian equations of motion as a second-order differential\nequation. Specific Nystr\\\"om-type schemes of second and third orders are\nderived and applied to strongly magnetized particle pushing problems. Numerical\nexperiments are presented to demonstrate that the Nystr\\\"om-type exponential\nintegrators can provide significant improvement in computational efficiency\nover the standard exponential methods.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cs.NA,math.NA,physics.plasm-ph","published":"2025-05-01T04:22:49Z"}
{"aid":"http://arxiv.org/abs/2505.00307v1","title":"Gateformer: Advancing Multivariate Time Series Forecasting through\n  Temporal and Variate-Wise Attention with Gated Representations","summary":"There has been a recent surge of interest in time series modeling using the\nTransformer architecture. However, forecasting multivariate time series with\nTransformer presents a unique challenge as it requires modeling both temporal\n(cross-time) and variate (cross-variate) dependencies. While Transformer-based\nmodels have gained popularity for their flexibility in capturing both\nsequential and cross-variate relationships, it is unclear how to best integrate\nthese two sources of information in the context of the Transformer architecture\nwhile optimizing for both performance and efficiency. We re-purpose the\nTransformer architecture to effectively model both cross-time and cross-variate\ndependencies. Our approach begins by embedding each variate independently into\na variate-wise representation that captures its cross-time dynamics, and then\nmodels cross-variate dependencies through attention mechanisms on these learned\nembeddings. Gating operations in both cross-time and cross-variate modeling\nphases regulate information flow, allowing the model to focus on the most\nrelevant features for accurate predictions. Our method achieves\nstate-of-the-art performance across 13 real-world datasets and can be\nseamlessly integrated into other Transformer-based and LLM-based forecasters,\ndelivering performance improvements up to 20.7\\% over original models. Code is\navailable at this repository: https://github.com/nyuolab/Gateformer.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T04:59:05Z"}
{"aid":"http://arxiv.org/abs/2505.00318v1","title":"FedEMA: Federated Exponential Moving Averaging with Negative Entropy\n  Regularizer in Autonomous Driving","summary":"Street Scene Semantic Understanding (denoted as S3U) is a crucial but complex\ntask for autonomous driving (AD) vehicles. Their inference models typically\nface poor generalization due to domain-shift. Federated Learning (FL) has\nemerged as a promising paradigm for enhancing the generalization of AD models\nthrough privacy-preserving distributed learning. However, these FL AD models\nface significant temporal catastrophic forgetting when deployed in dynamically\nevolving environments, where continuous adaptation causes abrupt erosion of\nhistorical knowledge. This paper proposes Federated Exponential Moving Average\n(FedEMA), a novel framework that addresses this challenge through two integral\ninnovations: (I) Server-side model's historical fitting capability preservation\nvia fusing current FL round's aggregation model and a proposed previous FL\nround's exponential moving average (EMA) model; (II) Vehicle-side negative\nentropy regularization to prevent FL models' possible overfitting to\nEMA-introduced temporal patterns. Above two strategies empower FedEMA a\ndual-objective optimization that balances model generalization and\nadaptability. In addition, we conduct theoretical convergence analysis for the\nproposed FedEMA. Extensive experiments both on Cityscapes dataset and Camvid\ndataset demonstrate FedEMA's superiority over existing approaches, showing\n7.12% higher mean Intersection-over-Union (mIoU).","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-05-01T05:37:43Z"}
{"aid":"http://arxiv.org/abs/2505.00338v1","title":"New Distributed Interactive Proofs for Planarity: A Matter of Left and\n  Right","summary":"We provide new distributed interactive proofs (DIP) for planarity and related\ngraph families. The notion of a \\emph{distributed interactive proof} (DIP) was\nintroduced by Kol, Oshman, and Saxena (PODC 2018). In this setting, the\nverifier consists of $n$ nodes connected by a communication graph $G$. The\nprover is a single entity that communicates with all nodes by short messages.\nThe goal is to verify that the graph $G$ satisfies a certain property (e.g.,\nplanarity) in a small number of rounds, and with a small communication bound,\ndenoted as the \\emph{proof size}.\n  Prior work by Naor, Parter and Yogev (SODA 2020) presented a DIP for\nplanarity that uses three interaction rounds and a proof size of $O(\\log n)$.\nFeuilloley et al.\\ (PODC 2020) showed that the same can be achieved with a\nsingle interaction round and without randomization, by providing a proof\nlabeling scheme with a proof size of $O(\\log n)$. In a subsequent work,\nBousquet, Feuilloley, and Pierron (OPODIS 2021) achieved the same bound for\nrelated graph families such as outerplanarity, series-parallel graphs, and\ngraphs of treewidth at most $2$. In this work, we design new DIPs that use\nexponentially shorter proofs compared to the state-of-the-art bounds.","main_category":"cs.DS","categories":"cs.DS,cs.DC","published":"2025-05-01T06:35:42Z"}
{"aid":"http://arxiv.org/abs/2505.00339v1","title":"Enhancing AI-Driven Education: Integrating Cognitive Frameworks,\n  Linguistic Feedback Analysis, and Ethical Considerations for Improved Content\n  Generation","summary":"Artificial intelligence (AI) is rapidly transforming education, presenting\nunprecedented opportunities for personalized learning and streamlined content\ncreation. However, realizing the full potential of AI in educational settings\nnecessitates careful consideration of the quality, cognitive depth, and ethical\nimplications of AI-generated materials. This paper synthesizes insights from\nfour related studies to propose a comprehensive framework for enhancing\nAI-driven educational tools. We integrate cognitive assessment frameworks\n(Bloom's Taxonomy and SOLO Taxonomy), linguistic analysis of AI-generated\nfeedback, and ethical design principles to guide the development of effective\nand responsible AI tools. We outline a structured three-phase approach\nencompassing cognitive alignment, linguistic feedback integration, and ethical\nsafeguards. The practical application of this framework is demonstrated through\nits integration into OneClickQuiz, an AI-powered Moodle plugin for quiz\ngeneration. This work contributes a comprehensive and actionable guide for\neducators, researchers, and developers aiming to harness AI's potential while\nupholding pedagogical and ethical standards in educational content generation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T06:36:21Z"}
{"aid":"http://arxiv.org/abs/2505.00351v1","title":"Integral Representations of Sobolev Spaces via ReLU$^k$ Activation\n  Function and Optimal Error Estimates for Linearized Networks","summary":"This paper presents two main theoretical results concerning shallow neural\nnetworks with ReLU$^k$ activation functions. We establish a novel integral\nrepresentation for Sobolev spaces, showing that every function in\n$H^{\\frac{d+2k+1}{2}}(\\Omega)$ can be expressed as an $L^2$-weighted integral\nof ReLU$^k$ ridge functions over the unit sphere. This result mirrors the known\nrepresentation of Barron spaces and highlights a fundamental connection between\nSobolev regularity and neural network representations. Moreover, we prove that\nlinearized shallow networks -- constructed by fixed inner parameters and\noptimizing only the linear coefficients -- achieve optimal approximation rates\n$O(n^{-\\frac{1}{2}-\\frac{2k+1}{2d}})$ in Sobolev spaces.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-01T06:50:41Z"}
{"aid":"http://arxiv.org/abs/2505.00363v1","title":"Dust density enhancements and the direct formation of planetary cores in\n  gravitationally unstable discs","summary":"Planet formation via core accretion involves the growth of solids that can\naccumulate to form planetary cores. There are a number of barriers to the\ncollisional growth of solids in protostellar discs, one of which is the drift,\nor metre, barrier. Solid particles experience a drag force that will tend to\ncause them to drift towards the central star in smooth, laminar discs,\npotentially removing particles before they grow large enough to decouple from\nthe disc gas. Here we present 3-dimensional, shearing box simulations that\nexplore the dynamical evolution of solids in a protostellar disc that is\nmassive enough for the gravitational instability to manifest as spiral density\nwaves. We expand on earlier work by considering a range of particle sizes and\nfind that the spirals can still enhance the local solid density by more than an\norder of magnitude, potentially aiding grain growth. Furthermore, if solid\nparticles have enough mass, and the particle size distribution extends to\nsufficiently large particle sizes, the solid component of the disc can undergo\ndirect gravitational collapse to form bound clumps with masses typically\nbetween $1$ and $10$ M$_\\oplus$. Thus, the concentration of dust in a\nself-gravitating disc could bypass the size barrier for collisional growth and\ndirectly form planetary cores early in the lifetime of the disc.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-05-01T07:22:15Z"}
{"aid":"http://arxiv.org/abs/2505.00378v1","title":"Cues3D: Unleashing the Power of Sole NeRF for Consistent and Unique\n  Instances in Open-Vocabulary 3D Panoptic Segmentation","summary":"Open-vocabulary 3D panoptic segmentation has recently emerged as a\nsignificant trend. Top-performing methods currently integrate 2D segmentation\nwith geometry-aware 3D primitives. However, the advantage would be lost without\nhigh-fidelity 3D point clouds, such as methods based on Neural Radiance Field\n(NeRF). These methods are limited by the insufficient capacity to maintain\nconsistency across partial observations. To address this, recent works have\nutilized contrastive loss or cross-view association pre-processing for view\nconsensus. In contrast to them, we present Cues3D, a compact approach that\nrelies solely on NeRF instead of pre-associations. The core idea is that NeRF's\nimplicit 3D field inherently establishes a globally consistent geometry,\nenabling effective object distinction without explicit cross-view supervision.\nWe propose a three-phase training framework for NeRF,\ninitialization-disambiguation-refinement, whereby the instance IDs are\ncorrected using the initially-learned knowledge. Additionally, an instance\ndisambiguation method is proposed to match NeRF-rendered 3D masks and ensure\nglobally unique 3D instance identities. With the aid of Cues3D, we obtain\nhighly consistent and unique 3D instance ID for each object across views with a\nbalanced version of NeRF. Our experiments are conducted on ScanNet v2,\nScanNet200, ScanNet++, and Replica datasets for 3D instance, panoptic, and\nsemantic segmentation tasks. Cues3D outperforms other 2D image-based methods\nand competes with the latest 2D-3D merging based methods, while even surpassing\nthem when using additional 3D point clouds. The code link could be found in the\nappendix and will be released on\n\\href{https://github.com/mRobotit/Cues3D}{github}","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T08:12:03Z"}
{"aid":"http://arxiv.org/abs/2505.00386v1","title":"Exact treatment of the quantum Langevin equation under time-dependent\n  system-bath coupling via a train of delta distributions","summary":"In this paper, we consider the quantum Langevin equation for the\nCaldeira-Leggett model with an arbitrary time-dependent coupling constant. We\nsolve this equation exactly by employing a train of Dirac-delta switchings.\nThis method also enables us to visualize the memory effect in the environment.\nFurthermore, we compute the two-time correlation functions of the system's\nquadratures and show that the discrete-time Fourier transform is well-suited\nfor defining spectral densities, as the Dirac-delta switchings turn continuous\nfunctions into discretized samples.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-05-01T08:22:46Z"}
{"aid":"http://arxiv.org/abs/2505.00412v1","title":"Maximum list $r$-colorable induced subgraphs in $kP_3$-free graphs","summary":"We show that, for every fixed positive integers $r$ and $k$,\n\\textsc{Max-Weight List $r$-Colorable Induced Subgraph} admits a\npolynomial-time algorithm on $kP_3$-free graphs. This problem is a common\ngeneralization of \\textsc{Max-Weight Independent Set}, \\textsc{Odd Cycle\nTransversal} and \\textsc{List $r$-Coloring}, among others. Our result has\nseveral consequences.\n  First, it implies that, for every fixed $r \\geq 5$, assuming $\\mathsf{P}\\neq\n\\mathsf{NP}$, \\textsc{Max-Weight List $r$-Colorable Induced Subgraph} is\npolynomial-time solvable on $H$-free graphs if and only if $H$ is an induced\nsubgraph of either $kP_3$ or $P_5+kP_1$, for some $k \\geq 1$. Second, it makes\nconsiderable progress toward a complexity dichotomy for \\textsc{Odd Cycle\nTransversal} on $H$-free graphs, allowing to answer a question of Agrawal,\nLima, Lokshtanov, Rz{\\k{a}}{\\.z}ewski, Saurabh, and Sharma [TALG 2024]. Third,\nit gives a short and self-contained proof of the known result of Chudnovsky,\nHajebi, and Spirkl [Combinatorica 2024] that \\textsc{List $r$-Coloring} on\n$kP_3$-free graphs is polynomial-time solvable for every fixed $r$ and $k$.\n  We also consider two natural distance-$d$ generalizations of\n\\textsc{Max-Weight Independent Set} and \\textsc{List $r$-Coloring} and provide\npolynomial-time algorithms on $kP_3$-free graphs for every fixed integers $r$,\n$k$, and $d \\geq 6$.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-05-01T09:15:53Z"}
{"aid":"http://arxiv.org/abs/2505.00416v1","title":"ScaleTrack: Scaling and back-tracking Automated GUI Agents","summary":"Automated GUI agents aims to facilitate user interaction by automatically\nperforming complex tasks in digital environments, such as web, mobile, desktop\ndevices. It receives textual task instruction and GUI description to generate\nexecutable actions (\\emph{e.g.}, click) and operation boxes step by step.\nTraining a GUI agent mainly involves grounding and planning stages, in which\nthe GUI grounding focuses on finding the execution coordinates according to the\ntask, while the planning stage aims to predict the next action based on\nhistorical actions. However, previous work suffers from the limitations of\ninsufficient training data for GUI grounding, as well as the ignorance of\nbacktracking historical behaviors for GUI planning. To handle the above\nchallenges, we propose ScaleTrack, a training framework by scaling grounding\nand backtracking planning for automated GUI agents. We carefully collected GUI\nsamples of different synthesis criterions from a wide range of sources, and\nunified them into the same template for training GUI grounding models.\nMoreover, we design a novel training strategy that predicts the next action\nfrom the current GUI image, while also backtracking the historical actions that\nled to the GUI image. In this way, ScaleTrack explains the correspondence\nbetween GUI images and actions, which effectively describes the evolution rules\nof the GUI environment. Extensive experimental results demonstrate the\neffectiveness of ScaleTrack. Data and code will be available at url.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-01T09:27:13Z"}
{"aid":"http://arxiv.org/abs/2505.00419v1","title":"Self-supervised surface-related multiple suppression with\n  multidimensional convolution","summary":"Surface-related multiples pose significant challenges in seismic data\nprocessing, often obscuring primary reflections and reducing imaging quality.\nTraditional methods rely on computationally expensive algorithms, the prior\nknowledge of subsurface model, or accurate wavelet estimation, while supervised\nlearning approaches require clean labels, which are impractical for real data.\nThus, we propose a self-supervised learning framework for surface-related\nmultiple suppression, leveraging multi-dimensional convolution to generate\nmultiples from the observed data and a two-stage training strategy comprising a\nwarm-up and an iterative data refinement stage, so the network learns to remove\nthe multiples. The framework eliminates the need for labeled data by\niteratively refining predictions using multiples augmented inputs and\npseudo-labels. Numerical examples demonstrate that the proposed method\neffectively suppresses surface-related multiples while preserving primary\nreflections. Migration results confirm its ability to reduce artifacts and\nimprove imaging quality.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-05-01T09:33:15Z"}
{"aid":"http://arxiv.org/abs/2505.00428v1","title":"Cwikel-Lieb-Rozenblum type estimates for the Pauli and magnetic\n  Schrödinger operator in dimension two","summary":"We prove a Cwikel-Lieb-Rozenblum type inequality for the number of negative\neigenvalues of Pauli operators in dimension two. The resulting upper bound is\nsharp both in the weak as well as in the strong coupling limit. We also derive\ndifferent upper bounds for magnetic Schr\\\"odinger operators. The nature of the\ntwo estimates depends on whether or not the spin-orbit coupling is taken into\naccount.","main_category":"math-ph","categories":"math-ph,math.MP,math.SP","published":"2025-05-01T09:57:08Z"}
{"aid":"http://arxiv.org/abs/2505.00438v1","title":"A Temporal Broadening-Aware Pulse Width Adaptation Scheme for ISI\n  Mitigation and Energy Efficiency in THz Communication","summary":"Terahertz (THz) communication ensures the provision of ultra-high data rates\nowing to its abundant bandwidth; however, its performance is impeded by complex\npropagation mechanisms. In particular, molecular absorption induces a temporal\nbroadening effect (TBE), which causes pulse spreading and inter-symbol\ninterference (ISI), especially in ON-OFF keying-based systems. To address this,\nwe propose an adaptive pulse-width transmission scheme that dynamically adjusts\npulse durations based on the anticipated TBE. This approach suppresses ISI by\nconfining energy within symbol durations while also exploiting TBE\nconstructively to reduce pulse transmissions in specific bit patterns, leading\nto improved energy efficiency (EE) as an additional advantage of the proposed\nscheme. Analytical derivations and simulation results confirm that the proposed\nscheme substantially improves EE and bit error rate under practical THz channel\nconditions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-01T10:30:45Z"}
{"aid":"http://arxiv.org/abs/2505.00440v1","title":"Error bounds for function approximation using generated sets","summary":"This paper explores the use of \"generated sets\" $\\{ \\{ k \\boldsymbol{\\zeta}\n\\} : k = 1, \\ldots, n \\}$ for function approximation in reproducing kernel\nHilbert spaces which consist of multi-dimensional functions with an absolutely\nconvergent Fourier series. The algorithm is a least squares algorithm that\nsamples the function at the points of a generated set. We show that there exist\n$\\boldsymbol{\\zeta} \\in [0,1]^d$ for which the worst-case $L_2$ error has the\noptimal order of convergence if the space has polynomially converging\napproximation numbers. In fact, this holds for a significant portion of the\ngenerators. Additionally we show that a restriction to rational generators is\npossible with a slight increase of the bound. Furthermore, we specialise the\nresults to the weighted Korobov space, where we derive a bound applicable to\nlow values of sample points, and state tractability results.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-01T10:33:19Z"}
{"aid":"http://arxiv.org/abs/2505.00444v1","title":"Unveiling hidden features of the Kitaev model through a complex-network\n  analysis","summary":"We introduce a density matrix-based network analysis to explore the ground\nstate of the Kitaev chain, uncovering previously hidden structural and\nentanglement features. This approach successfully identifies the critical point\nassociated with the topological phase transition and reveals a singular point\nwhere the ground state exhibits uniform, nonzero entanglement between all\nfermion pairs, corresponding to a fully connected network structure. We provide\nan analytical explanation for this singular behavior and establish a connection\nto the concept of ground state factorization observed in spin chains. Moreover,\nwe analyze the open chain scenario and observe characteristic symmetry changes\nin the ground state corresponding to Majorana zero modes. These results\ndemonstrate the power of complex network analysis in revealing hidden features\nin such systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T10:37:46Z"}
{"aid":"http://arxiv.org/abs/2505.00450v1","title":"Spatial vertical regression for spatial panel data: Evaluating the\n  effect of the Florentine tramway's first line on commercial vitality","summary":"Synthetic control methods are commonly used in panel data settings to\nevaluate the effect of an intervention. In many of these cases, the treated and\ncontrol units correspond to spatial units such as regions or neighborhoods. Our\napproach addresses the challenge of understanding how an intervention applied\nat specific locations influences the surrounding area. Traditional synthetic\ncontrol applications may struggle with defining the effective area of impact,\nthe extent of treatment propagation across space, and the variation of effects\nwith distance from the treatment sites. To address these challenges, we\nintroduce Spatial Vertical Regression (SVR) within the Bayesian paradigm. This\ninnovative approach allows us to accurately predict the outcomes in varying\nproximities to the treatment sites, while meticulously accounting for the\nspatial structure inherent in the data. Specifically, rooted on the vertical\nregression framework of the synthetic control method, SVR employs a Gaussian\nprocess to ensure that the imputation of missing potential outcomes for areas\nof different distance around the treatment sites is spatially coherent,\nreflecting the expectation that nearby areas experience similar outcomes and\nhave similar relationships to control areas. This approach is particularly\npertinent to our study on the Florentine tramway's first line construction. We\nstudy its influence on the local commercial landscape, focusing on how business\nprevalence varies at different distances from the tram stops.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-05-01T10:52:51Z"}
{"aid":"http://arxiv.org/abs/2505.00451v1","title":"The iterated Dirichlet process and applications to Bayesian inference","summary":"Consider an i.i.d. sequence of random variables, taking values in some space\n$S$, whose underlying distribution is unknown. In problems of Bayesian\ninference, one models this unknown distribution as a random measure, and the\nlaw of this random measure is the prior. When $S = \\{0, 1\\}$, a commonly used\nprior is the uniform distribution on $[0, 1]$, or more generally, the beta\ndistribution. When $S$ is finite, the analogous choice is the Dirichlet\ndistribution. For a general space $S$, we are led naturally to the Dirichlet\nprocess (see [Ferguson, 1973]).\n  Here, we consider an array of random variables, and in so doing are led to\nwhat we call the iterated Dirichlet process (IDP). We define the IDP and then\nshow how to compute the posterior distribution, given a finite set of\nobservations, using the method of sequential imputation. Ordinarily, this\nmethod requires the existence of certain joint density functions, which the IDP\nlacks. We therefore present a new, more general proof of the validity of\nsequential imputation, and show that the hypotheses of our proof are satisfied\nby the IDP.","main_category":"math.ST","categories":"math.ST,math.PR,stat.TH","published":"2025-05-01T10:53:49Z"}
{"aid":"http://arxiv.org/abs/2505.00452v1","title":"ClearLines - Camera Calibration from Straight Lines","summary":"The problem of calibration from straight lines is fundamental in geometric\ncomputer vision, with well-established theoretical foundations. However, its\npractical applicability remains limited, particularly in real-world outdoor\nscenarios. These environments pose significant challenges due to diverse and\ncluttered scenes, interrupted reprojections of straight 3D lines, and varying\nlighting conditions, making the task notoriously difficult. Furthermore, the\nfield lacks a dedicated dataset encouraging the development of respective\ndetection algorithms. In this study, we present a small dataset named\n\"ClearLines\", and by detailing its creation process, provide practical insights\nthat can serve as a guide for developing and refining straight 3D line\ndetection algorithms.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T10:55:36Z"}
{"aid":"http://arxiv.org/abs/2505.00453v1","title":"Lévy processes under level-dependent Poissonian switching","summary":"In this paper, we derive identities for the upward and downward exit problems\nand resolvents for a process whose motion changes between two L\\'evy processes\nif it is above (or below) a barrier $b$ and coincides with a Poissonian arrival\ntime. This can be expressed in the form of a (hybrid) stochastic differential\nequation, for which the existence of its solution is also discussed. All\nidentities are given in terms of new generalisations of scale functions\n(counterparts of the scale functions from the theory of L\\'evy processes). To\nillustrate the applicability of our results, the probability of ruin is\nobtained for a risk process with delays in the dividend payments.","main_category":"math.PR","categories":"math.PR","published":"2025-05-01T11:02:11Z"}
{"aid":"http://arxiv.org/abs/2505.00457v1","title":"On estimating the quantum $\\ell_α$ distance","summary":"We study the computational complexity of estimating the quantum\n$\\ell_{\\alpha}$ distance ${\\mathrm{T}_\\alpha}(\\rho_0,\\rho_1)$, defined via the\nSchatten $\\alpha$-norm $\\|A\\|_{\\alpha} = \\mathrm{tr}(|A|^{\\alpha})^{1/\\alpha}$,\ngiven $\\operatorname{poly}(n)$-size state-preparation circuits of $n$-qubit\nquantum states $\\rho_0$ and $\\rho_1$. This quantity serves as a lower bound on\nthe trace distance for $\\alpha > 1$. For any constant $\\alpha > 1$, we develop\nan efficient rank-independent quantum estimator for\n${\\mathrm{T}_\\alpha}(\\rho_0,\\rho_1)$ with time complexity\n$\\operatorname{poly}(n)$, achieving an exponential speedup over the prior best\nresults of $\\exp(n)$ due to Wang, Guan, Liu, Zhang, and Ying (TIT 2024). Our\nimprovement leverages efficiently computable uniform polynomial approximations\nof signed positive power functions within quantum singular value\ntransformation, thereby eliminating the dependence on the rank of the quantum\nstates.\n  Our quantum algorithm reveals a dichotomy in the computational complexity of\nthe Quantum State Distinguishability Problem with Schatten $\\alpha$-norm\n(QSD$_{\\alpha}$), which involves deciding whether\n${\\mathrm{T}_\\alpha}(\\rho_0,\\rho_1)$ is at least $2/5$ or at most $1/5$. This\ndichotomy arises between the cases of constant $\\alpha > 1$ and $\\alpha=1$:\n  - For any $1+\\Omega(1) \\leq \\alpha \\leq O(1)$, QSD$_{\\alpha}$ is\n$\\mathsf{BQP}$-complete.\n  - For any $1 \\leq \\alpha \\leq 1+\\frac{1}{n}$, QSD$_{\\alpha}$ is\n$\\mathsf{QSZK}$-complete, implying that no efficient quantum estimator for\n$\\mathrm{T}_\\alpha(\\rho_0,\\rho_1)$ exists unless $\\mathsf{BQP} =\n\\mathsf{QSZK}$.\n  The hardness results follow from reductions based on new rank-dependent\ninequalities for the quantum $\\ell_{\\alpha}$ distance with $1\\leq \\alpha \\leq\n\\infty$, which are of independent interest.","main_category":"quant-ph","categories":"quant-ph,cs.CC,cs.DS","published":"2025-05-01T11:15:20Z"}
{"aid":"http://arxiv.org/abs/2505.00460v1","title":"Subspace-Distance-Enabled Active Learning for Efficient Data-Driven\n  Model Reduction of Parametric Dynamical Systems","summary":"In situations where the solution of a high-fidelity dynamical system needs to\nbe evaluated repeatedly, over a vast pool of parametric configurations and in\nabsence of access to the underlying governing equations, data-driven model\nreduction techniques are preferable. We propose a novel active learning\napproach to build a parametric data-driven reduced-order model (ROM) by\ngreedily picking the most important parameter samples from the parameter\ndomain. As a result, during the ROM construction phase, the number of\nhigh-fidelity solutions dynamically grow in a principled fashion. The\nhigh-fidelity solution snapshots are expressed in several parameter-specific\nlinear subspaces, with the help of proper orthogonal decomposition (POD), and\nthe relative distance between these subspaces is used as a guiding mechanism to\nperform active learning. For successfully achieving this, we provide a distance\nmeasure to evaluate the similarity between pairs of linear subspaces with\ndifferent dimensions, and also show that this distance measure is a metric. The\nusability of the proposed subspace-distance-enabled active learning (SDE-AL)\nframework is demonstrated by augmenting two existing non-intrusive\nreduced-order modeling approaches, and providing their active-learning-driven\n(ActLearn) extensions, namely, SDE-ActLearn-POD-KSNN, and SDE-ActLearn-POD-NN.\nFurthermore, we report positive results for two parametric physical models,\nhighlighting the efficiency of the proposed SDE-AL approach.","main_category":"math.NA","categories":"math.NA,cs.CE,cs.LG,cs.NA,math.DS,physics.comp-ph","published":"2025-05-01T11:28:18Z"}
{"aid":"http://arxiv.org/abs/2505.00465v1","title":"HoneyWin: High-Interaction Windows Honeypot in Enterprise Environment","summary":"Windows operating systems (OS) are ubiquitous in enterprise Information\nTechnology (IT) and operational technology (OT) environments. Due to their\nwidespread adoption and known vulnerabilities, they are often the primary\ntargets of malware and ransomware attacks. With 93% of the ransomware targeting\nWindows-based systems, there is an urgent need for advanced defensive\nmechanisms to detect, analyze, and mitigate threats effectively. In this paper,\nwe propose HoneyWin a high-interaction Windows honeypot that mimics an\nenterprise IT environment. The HoneyWin consists of three Windows 11 endpoints\nand an enterprise-grade gateway provisioned with comprehensive network traffic\ncapturing, host-based logging, deceptive tokens, endpoint security and\nreal-time alerts capabilities. The HoneyWin has been deployed live in the wild\nfor 34 days and receives more than 5.79 million unsolicited connections, 1.24\nmillion login attempts, 5 and 354 successful logins via remote desktop protocol\n(RDP) and secure shell (SSH) respectively. The adversary interacted with the\ndeceptive token in one of the RDP sessions and exploited the public-facing\nendpoint to initiate the Simple Mail Transfer Protocol (SMTP) brute-force bot\nattack via SSH sessions. The adversary successfully harvested 1,250 SMTP\ncredentials after attempting 151,179 credentials during the attack.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-01T11:31:18Z"}
{"aid":"http://arxiv.org/abs/2505.00475v1","title":"Quantum mechanics of inverted potential well -- Hermitian Hamiltonian\n  with imaginary eigenvalues, quantum-classical correspondence","summary":"We in this paper study the quantization of a particle in an inverted\npotential well. The Hamiltonian is Hermitian, while the potential is unbounded\nbelow. Classically the particle moves away acceleratingly from the center of\npotential top. The existing eigenstates must be unstable with imaginary\neigenvalues, which characterize the decay rate of states. We solve the\nHamiltonian problem of inverted potential well by the algebraic method with\nimaginary-frequency raising and lowering boson operators similar to the normal\noscillator case. The boson number operator is non-Hermitian, while the\ninteger-number eigenvalues are, of course, real. Dual sets of eigenstates,\ndenoted by \"bra\" and \"ket\", are requested corresponding respectively to the\ncomplex conjugate number-operators. Orthonormal condition exists between the\n\"bra\" and \"ket\" states. We derive a spatially non-localized generating\nfunction, from which $n$-th eigenfunctions can be generated by the raising\noperators in coordinate representation. The \"bra\" and \"ket\" generating\nfunctions are mutually normalized with the imaginary integration measure. The\nprobability density operators defined between the \"bra\" and \"ket\" states are\nnon-Hermitian invariants, which lead to the Schr\\H{o}dinger equations\nrespectively for the \"bra\" and \"ket\" states. While probabilities of \"bra\" and\n\"ket\" states themselves are not conserved quantities because of the decay. The\nimaginary-frequency boson coherent states are defined as eigenstates of\nlowering operators. The minimum uncertainty relation is proved explicitly in\nthe coherent states. Finally the probability average of Heisenberg equation in\nthe coherent states is shown precisely in agreement with the classical equation\nof motion. The quantum-classical correspondence exists in the imaginary\neigenvalue system.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T11:59:33Z"}
{"aid":"http://arxiv.org/abs/2505.00482v1","title":"JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers","summary":"We present JointDiT, a diffusion transformer that models the joint\ndistribution of RGB and depth. By leveraging the architectural benefit and\noutstanding image prior of the state-of-the-art diffusion transformer, JointDiT\nnot only generates high-fidelity images but also produces geometrically\nplausible and accurate depth maps. This solid joint distribution modeling is\nachieved through two simple yet effective techniques that we propose, i.e.,\nadaptive scheduling weights, which depend on the noise levels of each modality,\nand the unbalanced timestep sampling strategy. With these techniques, we train\nour model across all noise levels for each modality, enabling JointDiT to\nnaturally handle various combinatorial generation tasks, including joint\ngeneration, depth estimation, and depth-conditioned image generation by simply\ncontrolling the timestep of each branch. JointDiT demonstrates outstanding\njoint generation performance. Furthermore, it achieves comparable results in\ndepth estimation and depth-conditioned image generation, suggesting that joint\ndistribution modeling can serve as a replaceable alternative to conditional\ngeneration. The project page is available at\nhttps://byungki-k.github.io/JointDiT/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-01T12:21:23Z"}
{"aid":"http://arxiv.org/abs/2505.00485v1","title":"Direct and inverse spectral continuity for Dirac operators","summary":"The half-line Dirac operators with $L^2$-potentials can be characterized by\ntheir spectral data. It is known that the spectral correspondence is a\nhomeomorphism: close potentials give rise to close spectral data and vice\nversa. We prove the first explicit two-sided uniform estimate related to this\ncontinuity in the general $L^2$-case. The proof is based on an exact solution\nof the inverse spectral problem for Dirac operators with $\\delta$-interactions\non a half-lattice in terms of the Schur's algorithm for analytic functions.","main_category":"math.SP","categories":"math.SP","published":"2025-05-01T12:33:18Z"}
{"aid":"http://arxiv.org/abs/2505.00506v1","title":"HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World\n  Hallucination Detection","summary":"As large language models (LLMs) are increasingly deployed in high-stakes\ndomains, detecting hallucinated content$\\unicode{x2013}$text that is not\ngrounded in supporting evidence$\\unicode{x2013}$has become a critical\nchallenge. Existing benchmarks for hallucination detection are often\nsynthetically generated, narrowly focused on extractive question answering, and\nfail to capture the complexity of real-world scenarios involving multi-document\ncontexts and full-sentence outputs. We introduce the HalluMix Benchmark, a\ndiverse, task-agnostic dataset that includes examples from a range of domains\nand formats. Using this benchmark, we evaluate seven hallucination detection\nsystems$\\unicode{x2013}$both open and closed\nsource$\\unicode{x2013}$highlighting differences in performance across tasks,\ndocument lengths, and input representations. Our analysis highlights\nsubstantial performance disparities between short and long contexts, with\ncritical implications for real-world Retrieval Augmented Generation (RAG)\nimplementations. Quotient Detections achieves the best overall performance,\nwith an accuracy of 0.82 and an F1 score of 0.84.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T13:22:45Z"}
{"aid":"http://arxiv.org/abs/2505.00518v1","title":"An evaluation of unconditional 3D molecular generation methods","summary":"Unconditional molecular generation is a stepping stone for conditional\nmolecular generation, which is important in \\emph{de novo} drug design. Recent\nunconditional 3D molecular generation methods report saturated benchmarks,\nsuggesting it is time to re-evaluate our benchmarks and compare the latest\nmodels. We assess five recent high-performing 3D molecular generation methods\n(EQGAT-diff, FlowMol, GCDM, GeoLDM, and SemlaFlow), in terms of both standard\nbenchmarks and chemical and physical validity. Overall, the best method,\nSemlaFlow, has a success rate of 87% in generating valid, unique, and novel\nmolecules without post-processing and 92.4% with post-processing.","main_category":"physics.chem-ph","categories":"physics.chem-ph,q-bio.QM","published":"2025-05-01T13:40:10Z"}
{"aid":"http://arxiv.org/abs/2505.00519v1","title":"Linear Phase Balancing Scheme using Voltage Unbalance Sensitivities in\n  Multi-phase Power Distribution Grids","summary":"Power distribution networks, especially in North America, are often\nunbalanced due to the mix of single-, two- and three-phase networks as well as\ndue to the high penetration of single-phase devices at the distribution level\nsuch as electric vehicle (EV) chargers and single-phase solar plants. However,\nthe network operator must adhere to the voltage unbalance levels within the\nlimits specified by IEEE, IEC, and NEMA standards for the safety of the\nequipment as well as the efficiency of the network operation. Existing works\nhave proposed active and reactive power control in the network to minimize\nimbalances. However, these optimization problems are highly nonlinear and\nnonconvex due to the inherent non-linearity of unbalanced metrics and\npower-flow equations. In this work, we propose a linearization approach of\nunbalance metrics such as voltage unbalance factors (VUF), phase voltage\nunbalance rate (PVUR), and line voltage unbalance rate (LVUR) using the first\norder Taylor's approximation. This linearization is then applied to the phase\nbalancing control scheme; it is formulated as a feedback approach where the\nlinearization is updated successively after the active/reactive control\nsetpoint has been actuated and shows improvement in voltage imbalances. We\ndemonstrate the application of the proposed scheme on a standard IEEE benchmark\ntest case, demonstrating its effectiveness.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-01T13:40:31Z"}
{"aid":"http://arxiv.org/abs/2505.00523v1","title":"A complement of the Erdős-Hajnal problem on paths with equal-degree\n  endpoints","summary":"Answering a question of Erd\\H{o}s and Hajnal, Chen and Ma proved that for all\n$n\\geq600$ every graph with $2n + 1$ vertices and at least $n^2 + n+1$ edges\ncontains two vertices of equal degree connected by a path of length three, and\nthe complete bipartite graph $K_{n,n+1}$ shows that this edge bound is sharp.\nIn this paper, we obtain the above result for all $n\\ge2$, and thus resolve the\nquestion of Erd\\H{o}s and Hajnal completely.","main_category":"math.CO","categories":"math.CO","published":"2025-05-01T13:44:43Z"}
{"aid":"http://arxiv.org/abs/2505.00527v1","title":"DeCo: Task Decomposition and Skill Composition for Zero-Shot\n  Generalization in Long-Horizon 3D Manipulation","summary":"Generalizing language-conditioned multi-task imitation learning (IL) models\nto novel long-horizon 3D manipulation tasks remains a significant challenge. To\naddress this, we propose DeCo (Task Decomposition and Skill Composition), a\nmodel-agnostic framework compatible with various multi-task IL models, designed\nto enhance their zero-shot generalization to novel, compositional, long-horizon\n3D manipulation tasks. DeCo first decomposes IL demonstrations into a set of\nmodular atomic tasks based on the physical interaction between the gripper and\nobjects, and constructs an atomic training dataset that enables models to learn\na diverse set of reusable atomic skills during imitation learning. At inference\ntime, DeCo leverages a vision-language model (VLM) to parse high-level\ninstructions for novel long-horizon tasks, retrieve the relevant atomic skills,\nand dynamically schedule their execution; a spatially-aware skill-chaining\nmodule then ensures smooth, collision-free transitions between sequential\nskills. We evaluate DeCo in simulation using DeCoBench, a benchmark\nspecifically designed to assess zero-shot generalization of multi-task IL\nmodels in compositional long-horizon 3D manipulation. Across three\nrepresentative multi-task IL models (RVT-2, 3DDA, and ARP), DeCo achieves\nsuccess rate improvements of 66.67%, 21.53%, and 57.92%, respectively, on 12\nnovel compositional tasks. Moreover, in real-world experiments, a DeCo-enhanced\nmodel trained on only 6 atomic tasks successfully completes 9 novel\nlong-horizon tasks, yielding an average success rate improvement of 53.33% over\nthe base multi-task IL model. Video demonstrations are available at:\nhttps://deco226.github.io.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T13:52:19Z"}
{"aid":"http://arxiv.org/abs/2505.00531v1","title":"Superintuitionistic predicate logics of linear frames: undecidability\n  with two individual variables","summary":"The paper presents a solution to the long-standing question about the\ndecidability of the two-variable fragment of the superintuitionistic predicate\nlogic $\\mathbf{QLC}$ defined by the class of linear Kripke frames, which is\nalso the `superintuitionistic' fragment of the modal predicate logic\n$\\mathbf{QS4.3}$, under the G\\\"odel translation. We prove that the fragment is\nundecidable ($\\Sigma^0_1$-complete). The result remains true for the positive\nfragment, even with a single binary predicate letter and an infinite set of\nunary predicate letters. Also, we prove that the logic defined by ordinal\n$\\omega$ as a Kripke frame is not recursively enumerable (even both\n$\\Sigma^0_1$-hard and $\\Pi^0_1$-hard) with the same restrictions on the\nlanguage. The results remain true if we add also the constant domain condition.\nThe proofs are based on two techniques: a modification of the method proposed\nby M.Marx and M.Reynolds, which allows us to describe tiling problems using\nnatural numbers rather than pairs of numbers within an enumeration of Cantor's,\nand an idea of `double labeling' the elements from the domains, which allows us\nto use only two individual variables in the proof when applying the former\nmethod.","main_category":"math.LO","categories":"math.LO","published":"2025-05-01T13:57:26Z"}
{"aid":"http://arxiv.org/abs/2505.00541v1","title":"KnowEEG: Explainable Knowledge Driven EEG Classification","summary":"Electroencephalography (EEG) is a method of recording brain activity that\nshows significant promise in applications ranging from disease classification\nto emotion detection and brain-computer interfaces. Recent advances in deep\nlearning have improved EEG classification performance yet model explainability\nremains an issue. To address this key limitation of explainability we introduce\nKnowEEG; a novel explainable machine learning approach for EEG classification.\nKnowEEG extracts a comprehensive set of per-electrode features, filters them\nusing statistical tests, and integrates between-electrode connectivity\nstatistics. These features are then input to our modified Random Forest model\n(Fusion Forest) that balances per electrode statistics with between electrode\nconnectivity features in growing the trees of the forest. By incorporating\nknowledge from both the generalized time-series and EEG-specific domains,\nKnowEEG achieves performance comparable to or exceeding state-of-the-art deep\nlearning models across five different classification tasks: emotion detection,\nmental workload classification, eyes open/closed detection, abnormal EEG\nclassification, and event detection. In addition to high performance, KnowEEG\nprovides inherent explainability through feature importance scores for\nunderstandable features. We demonstrate by example on the eyes closed/open\nclassification task that this explainability can be used to discover knowledge\nabout the classes. This discovered knowledge for eyes open/closed\nclassification was proven to be correct by current neuroscience literature.\nTherefore, the impact of KnowEEG will be significant for domains where EEG\nexplainability is critical such as healthcare.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T14:05:55Z"}
{"aid":"http://arxiv.org/abs/2505.00577v1","title":"Topologically conjugate classification of diagonal operators","summary":"Let $\\ell^{p}$, $1\\leq p<\\infty$, be the Banach space of absolutely $p$-th\npower summable sequences and let $\\pi_{n}$ be the natural projection to the\n$n$-th coordinate for $n\\in\\mathbb{N}$. Let\n$\\mathfrak{W}=\\{w_{n}\\}_{n=1}^{\\infty}$ be a bounded sequence of complex\nnumbers. Define the operator $D_{\\mathfrak{W}}: \\ell^{p}\\rightarrow\\ell^{p}$\nby, for any $x=(x_{1},x_{2},\\ldots)\\in \\ell^p$, $\\pi_{n}\\circ\nD_{\\mathfrak{W}}(x)=w_{n}x_{n}$ for all $n\\geq1$. We call $D_{\\mathfrak{W}}$ a\ndiagonal operator on $\\ell^{p}$. In this article, we study the topological\nconjugate classification of the diagonal operators on $\\ell^{p}$. More\nprecisely, we obtained the following results. $D_{\\mathfrak{W}}$ and\n$D_{\\vert\\mathfrak{W}\\vert}$ are topologically conjugate, where\n$\\vert\\mathfrak{W}\\vert=\\{\\vert w_{n}\\vert\\}_{n=1}^{\\infty}$. If $\\inf_{n}\\vert\nw_n\\vert>1$, then $D_{\\mathfrak{W}}$ is topologically conjugate to\n$2\\mathbf{I}$, where $\\mathbf{I}$ means the identity operator. Similarly, if\n$\\inf_{n}\\vert w_n\\vert>0$ and $\\sup_{n}\\vert w_n\\vert<1$, then\n$D_{\\mathfrak{W}}$ is topologically conjugate to $\\frac{1}{2}\\mathbf{I}$. In\naddition, if $\\inf_{n}\\vert w_n\\vert=1$ and $\\inf_{n}\\vert t_n\\vert>1$, then\n$D_{\\mathfrak{W}}$ and $D_{\\mathfrak{T}}$ are not topologically conjugate.","main_category":"math.DS","categories":"math.DS,math.FA,math.GN","published":"2025-05-01T15:07:06Z"}
{"aid":"http://arxiv.org/abs/2505.00596v1","title":"A Finite-State Controller Based Offline Solver for Deterministic POMDPs","summary":"Deterministic partially observable Markov decision processes (DetPOMDPs)\noften arise in planning problems where the agent is uncertain about its\nenvironmental state but can act and observe deterministically. In this paper,\nwe propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI)\nalgorithm for DetPOMDPs, which builds policies in the form of finite-state\ncontrollers (FSCs). DetMCVI solves large problems with a high success rate,\noutperforming existing baselines for DetPOMDPs. We also verify the performance\nof the algorithm in a real-world mobile robot forest mapping scenario.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-05-01T15:30:26Z"}
{"aid":"http://arxiv.org/abs/2505.00615v1","title":"Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face\n  Reconstruction","summary":"We address the 3D reconstruction of human faces from a single RGB image. To\nthis end, we propose Pixel3DMM, a set of highly-generalized vision transformers\nwhich predict per-pixel geometric cues in order to constrain the optimization\nof a 3D morphable face model (3DMM). We exploit the latent features of the DINO\nfoundation model, and introduce a tailored surface normal and uv-coordinate\nprediction head. We train our model by registering three high-quality 3D face\ndatasets against the FLAME mesh topology, which results in a total of over\n1,000 identities and 976K images. For 3D face reconstruction, we propose a\nFLAME fitting opitmization that solves for the 3DMM parameters from the\nuv-coordinate and normal estimates. To evaluate our method, we introduce a new\nbenchmark for single-image face reconstruction, which features high diversity\nfacial expressions, viewing angles, and ethnicities. Crucially, our benchmark\nis the first to evaluate both posed and neutral facial geometry. Ultimately,\nour method outperforms the most competitive baselines by over 15% in terms of\ngeometric accuracy for posed facial expressions.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-01T15:47:03Z"}
{"aid":"http://arxiv.org/abs/2505.00617v1","title":"The equations of Einstein and Cartan","summary":"A formulation of Einstein's gravitational field equations in four space-time\ndimensions is presented using generalized differential forms and Cartan's\nequations for metric geometries. Cartan's structure equations are extended by\nusing generalized metric connections. They are then employed to represent\nEinstein's field equations and their solutions. When the energy-momentum tensor\nis zero the generalized connections can be chosen to be flat and different\nsolutions of Einstein's equations can be related by generalizations of the\nPoincar\\'e group. An action for the vacuum field equations is constructed by\ngeneralizing the Nieh-Yan three-form.","main_category":"gr-qc","categories":"gr-qc","published":"2025-05-01T15:48:19Z"}
{"aid":"http://arxiv.org/abs/2505.00644v1","title":"Predatory dynamics in susceptible and resistant $\\textit{Eriopis\n  connexa}$ populations","summary":"The ladybird $\\textit{Eriopis connexa}$ (Germar, 1824), a voracious aphid\npredator, faces challenges from insecticide applications, compromising\nbiological control. As a result, there has been an increase in the number of\nstudies analysing the resistance and susceptibility of ladybirds. Some studies\nhave found that resistant populations exhibit distinct predation and foraging\nbehaviour compared to susceptible ones. This study models the population\ndynamics of resistant and susceptible $\\textit{E. connexa}$ preying on\n$\\textit{Aphis gossypii}$ Glover, 1877 and $\\textit{Myzus persicae}$ (Sulzer,\n1776). We constructed a logistic model with density dependence and type-II\nfunctional response to analyse predation dynamics, incorporating bifurcation\nanalysis on predation parameters (attack rate and handling time) and the\nmortality rate of susceptible ladybirds. We simulated scenarios with/without\ninsecticide application and with/without aphid resistance. To simulate the\neffects of insecticide applications, the parameters related to aphids'\nintrinsic growth rate ($r_1$ and $r_2$) change to reflect the responses of\nsusceptible and resistant populations. The same approach is used concerning the\nmortality rate of ladybirds ($d_2$ and $d_3$). Our results demonstrate that\nmortality, attack rate, and handling time are critical in shaping predator-prey\ninteractions. Temporal simulations revealed fluctuating abundances,\nhighlighting the fragility of these interactions under insecticide stress.\nTherefore, this study contributes to understanding the ecological implications\nof insecticides, which disrupt natural predation dynamics, and shows how\nvariations in behavioural rates can impact prey control. This research\ndemonstrated the importance of integrated strategies that balance insecticide\napplications with preserving natural enemies and promoting sustainable\nagricultural practices.","main_category":"q-bio.PE","categories":"q-bio.PE,q-bio.QM","published":"2025-05-01T16:33:24Z"}
{"aid":"http://arxiv.org/abs/2505.00645v1","title":"Generalized Kac-Paljutkin algebras","summary":"In this note, we construct a family of semisimple Hopf algebras $H_{n,m}$ of\ndimension $n^m m!$ over a field of characteristic zero containing a primitive\n$n$th root of unity, where $n, m \\geq 2$ are integers. The well-known\neight-dimensional Kac--Paljutkin algebra arises as the special case $H_{2,2}$,\nwhile the Hopf algebras previously constructed by Pansera correspond to the\ninstances $H_{n,2}$. Each algebra $H_{n,m}$ is defined as an extension of the\ngroup algebra $\\mathbb{K} \\Sigma_m$ of the symmetric group by the $m$-fold\ntensor product $R = \\mathbb{K} \\mathbb{Z}_n^{\\otimes m}$, where $\\mathbb{Z}_n$\ndenotes the cyclic group of order $n$. This extension admits a realization as a\ncrossed product: $H_{n,m} = \\mathbb{K} \\mathbb{Z}_n^{\\otimes m} \\#_\\gamma\n\\Sigma_m$. In the final section, we construct a family of irreducible\n$m$-dimensional representations of $H_{n,m}$ that are inner faithful as\n$R$-modules and exhibit a nontrivial inner-faithful action of a subalgebra of\n$H_{n,m}$ on a quantum polynomial algebra.","main_category":"math.QA","categories":"math.QA,math.RA","published":"2025-05-01T16:35:47Z"}
{"aid":"http://arxiv.org/abs/2505.00648v1","title":"Adaptive Nonoverlapping Preconditioners for the Helmholtz Equation","summary":"The Helmholtz equation poses significant computational challenges due to its\noscillatory solutions, particularly for large wavenumbers. Inspired by the\nSchur complement system for elliptic problems, this paper presents a novel\nsubstructuring approach to mitigate the potential ill-posedness of local\nDirichlet problems for the Helmholtz equation. We propose two types of\npreconditioners within the framework of nonoverlapping spectral additive\nSchwarz (NOSAS) methods. The first type of preconditioner focuses on the real\npart of the Helmholtz problem, while the second type addresses both the real\nand imaginary components, providing a comprehensive strategy to enhance\nscalability and reduce computational cost. Our approach is purely algebraic,\nwhich allows for adaptability to various discretizations and heterogeneous\nHelmholtz coefficients while maintaining theoretical convergence for thresholds\nclose to zero. Numerical experiments confirm the effectiveness of the proposed\npreconditioners, demonstrating robust convergence rates and scalability, even\nfor large wavenumbers.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-01T16:45:14Z"}
{"aid":"http://arxiv.org/abs/2505.00649v1","title":"Investigating Task Arithmetic for Zero-Shot Information Retrieval","summary":"Large Language Models (LLMs) have shown impressive zero-shot performance\nacross a variety of Natural Language Processing tasks, including document\nre-ranking. However, their effectiveness degrades on unseen tasks and domains,\nlargely due to shifts in vocabulary and word distributions. In this paper, we\ninvestigate Task Arithmetic, a technique that combines the weights of LLMs\npre-trained on different tasks or domains via simple mathematical operations,\nsuch as addition or subtraction, to adapt retrieval models without requiring\nadditional fine-tuning. Our method is able to synthesize diverse tasks and\ndomain knowledge into a single model, enabling effective zero-shot adaptation\nin different retrieval contexts. Extensive experiments on publicly available\nscientific, biomedical, and multilingual datasets show that our method improves\nstate-of-the-art re-ranking performance by up to 18% in NDCG@10 and 15% in\nP@10. In addition to these empirical gains, our analysis provides insights into\nthe strengths and limitations of Task Arithmetic as a practical strategy for\nzero-shot learning and model adaptation. We make our code publicly available at\nhttps://github.com/DetectiveMB/Task-Arithmetic-for-ZS-IR.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.LG","published":"2025-05-01T16:48:37Z"}
{"aid":"http://arxiv.org/abs/2505.00650v1","title":"OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery\n  and Survival Stratification","summary":"Unsupervised learning of disease subtypes from multi-omics data presents a\nsignificant opportunity for advancing personalized medicine. We introduce\nOmicsCL, a modular contrastive learning framework that jointly embeds\nheterogeneous omics modalities-such as gene expression, DNA methylation, and\nmiRNA expression-into a unified latent space. Our method incorporates a\nsurvival-aware contrastive loss that encourages the model to learn\nrepresentations aligned with survival-related patterns, without relying on\nlabeled outcomes. Evaluated on the TCGA BRCA dataset, OmicsCL uncovers\nclinically meaningful clusters and achieves strong unsupervised concordance\nwith patient survival. The framework demonstrates robustness across\nhyperparameter configurations and can be tuned to prioritize either subtype\ncoherence or survival stratification. Ablation studies confirm that integrating\nsurvival-aware loss significantly enhances the predictive power of learned\nembeddings. These results highlight the promise of contrastive objectives for\nbiological insight discovery in high-dimensional, heterogeneous omics data.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.GN,q-bio.QM","published":"2025-05-01T16:51:48Z"}
{"aid":"http://arxiv.org/abs/2505.00660v1","title":"AI-based CSI Feedback with Digital Twins: Real-World Validation and\n  Insights","summary":"Deep learning (DL) has shown great potential for enhancing channel state\ninformation (CSI) feedback in multiple-input multiple-output (MIMO)\ncommunication systems, a subject currently under study by the 3GPP standards\nbody. Digital twins (DTs) have emerged as an effective means to generate\nsite-specific datasets for training DL-based CSI feedback models. However, most\nexisting studies rely solely on simulations, leaving the effectiveness of DTs\nin reducing DL training costs yet to be validated through realistic\nexperimental setups. This paper addresses this gap by establishing a real-world\n(RW) environment and corresponding virtual channels using ray tracing with\nreplicated 3D models and accurate antenna properties. We evaluate whether\nmodels trained in DT environments can effectively operate in RW scenarios and\nquantify the benefits of online learning (OL) for performance enhancement.\nResults show that a dedicated DT remains essential even with OL to achieve\nsatisfactory performance in RW scenarios.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-05-01T17:02:22Z"}
{"aid":"http://arxiv.org/abs/2505.00668v1","title":"Deep Reinforcement Learning for Urban Air Quality Management:\n  Multi-Objective Optimization of Pollution Mitigation Booth Placement in\n  Metropolitan Environments","summary":"Urban air pollution remains a pressing global concern, particularly in\ndensely populated and traffic-intensive metropolitan areas like Delhi, where\nexposure to harmful pollutants severely impacts public health. Delhi, being one\nof the most polluted cities globally, experiences chronic air quality issues\ndue to vehicular emissions, industrial activities, and construction dust, which\nexacerbate its already fragile atmospheric conditions. Traditional pollution\nmitigation strategies, such as static air purifying installations, often fail\nto maximize their impact due to suboptimal placement and limited adaptability\nto dynamic urban environments. This study presents a novel deep reinforcement\nlearning (DRL) framework to optimize the placement of air purification booths\nto improve the air quality index (AQI) in the city of Delhi. We employ Proximal\nPolicy Optimization (PPO), a state-of-the-art reinforcement learning algorithm,\nto iteratively learn and identify high-impact locations based on multiple\nspatial and environmental factors, including population density, traffic\npatterns, industrial influence, and green space constraints. Our approach is\nbenchmarked against conventional placement strategies, including random and\ngreedy AQI-based methods, using multi-dimensional performance evaluation\nmetrics such as AQI improvement, spatial coverage, population and traffic\nimpact, and spatial entropy. Experimental results demonstrate that the RL-based\napproach outperforms baseline methods by achieving a balanced and effective\ndistribution of air purification infrastructure. Notably, the DRL framework\nachieves an optimal trade-off between AQI reduction and high-coverage\ndeployment, ensuring equitable environmental benefits across urban regions. The\nfindings underscore the potential of AI-driven spatial optimization in\nadvancing smart city initiatives and data-driven urban air quality management.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-05-01T17:19:48Z"}
{"aid":"http://arxiv.org/abs/2505.00688v1","title":"The Architecture Tradeoff and Risk Analysis Framework (ATRAF): A Unified\n  Approach for Evaluating Software Architectures, Reference Architectures, and\n  Architectural Frameworks","summary":"Modern software systems are guided by hierarchical architectural concepts --\nsoftware architectures, reference architectures, and architectural frameworks\n-- each operating at a distinct level of abstraction. These artifacts promote\nreuse, scalability, and consistency, but also embed tradeoffs that shape\ncritical quality attributes such as modifiability, performance, and security.\nExisting evaluation methods, such as the Architecture Tradeoff Analysis Method\n(ATAM), focus on system-specific architectures and are not designed to address\nthe broader generality and variability of higher-level architectural forms. To\nclose this gap, we introduce the Architecture Tradeoff and Risk Analysis\nFramework (ATRAF) -- a unified, scenario-driven framework for evaluating\ntradeoffs and risks across architectural levels. ATRAF encompasses three\nmethods: the Architecture Tradeoff and Risk Analysis Method (ATRAM), extending\nATAM with enhanced risk identification for concrete systems; the Reference\nArchitecture Tradeoff and Risk Analysis Method (RATRAM), adapting ATRAM to the\nevaluation of domain-level reference architectures; and the Architectural\nFramework Tradeoff and Risk Analysis Method (AFTRAM), supporting the evaluation\nof architectural frameworks that guide entire system families. All three\nmethods follow an iterative spiral process that enables the identification of\nsensitivities, tradeoffs, and risks while supporting continuous refinement of\narchitectural artifacts. We demonstrate ATRAF through progressively abstracted\nexamples derived from the Remote Temperature Sensor (RTS) case, originally\nintroduced in the ATAM literature. ATRAF equips architects, reference modelers,\nand framework designers with a practical, systematic approach for analyzing\ndesign alternatives and managing quality attribute tradeoffs early in the\nlifecycle and across all levels of architectural abstraction.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-01T17:48:52Z"}
{"aid":"http://arxiv.org/abs/2505.07177v1","title":"Exact closed-form solutions for Lamb's problem (III): The case for\n  buried source and receiver","summary":"In this article, we derive the exact closed-form solution for the\ndisplacement in the interior of an elastic half-space due to a buried point\nforce with Heaviside step function time history. It is referred to as the\ntensor Green's function for the elastic wave equation in a uniform half-space,\nalso a natural generalization of the classical 3-D Lamb's problem, for which\nprevious solutions have been restricted to the cases of either the source or\nthe receiver or both are located on the free surface. Starting from the complex\nintegral solutions of Johnson, we follow the similar procedures presented by\nFeng and Zhang to obtain the closed-form expressions in terms of elementary\nfunctions as well as elliptic integrals. Numerical results obtained from our\nclosed-form expressions agree perfectly with those of Johnson, which validates\nour explicit formulae conclusively.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-05-12T02:10:39Z"}
{"aid":"http://arxiv.org/abs/2505.07187v1","title":"Violation of NCQ scaling in hadron elliptic flow in Au+Au collisions at\n  $\\sqrt{s_{NN}}=3.0-7.7 \\,\\mathrm{GeV}$","summary":"We investigate the number-of-constituent-quark (NCQ) scaling of elliptic flow\nfor various hadrons in non-central Au+Au collisions at \\(\\sqrt{s_{NN}} =\n3.0\\text{--}7.7\\,\\mathrm{GeV}\\) using the AMPT model with string melting (SM)\nand pure hadron cascade (HC) modes. For the SM case, NCQ scaling is absent at\n\\(\\sqrt{s_{NN}} =3.0\\,\\mathrm{GeV}\\) but is largely restored by \\(\\sqrt{s_{NN}}\n=3.9\\,\\mathrm{GeV}\\). Although quark coalescence occurs at \\(\\sqrt{s_{NN}}\n=3.0\\,\\mathrm{GeV}\\), the lack of NCQ scaling is attributed to the insufficient\ndevelopment of quark elliptic flow and the limited production of strange quarks\nand antiquarks. This finding suggests that NCQ scaling could not be considered\na definitive signature of quark-gluon plasma (QGP) formation in the RHIC\nfixed-target energy region. For the HC case, as expected, no NCQ scaling is\nobserved. However, a mass ordering in the elliptic flow emerges at\n\\(\\sqrt{s_{NN}} =4.5\\,\\mathrm{GeV}\\), indicating that full thermalization may\nnot be a prerequisite for mass ordering.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex","published":"2025-05-12T02:35:50Z"}
{"aid":"http://arxiv.org/abs/2505.07189v1","title":"Unified theory of photovoltaic Hall effect by field- and light-induced\n  Berry curvatures","summary":"Photovoltaic Hall effect is an interesting platform of Berry curvature\nengineering by external fields. Floquet engineering aims at generation of\nlight-induced Berry curvature associated with topological phase transition in\nsolids, which may manifest itself as a light-induced anomalous Hall effect.\nHowever, recent studies have pointed out an important role of the bias electric\nfield, which adds a field-induced circular photogalvanic effect to the\nphotovoltaic Hall effect. Except for numerical studies, the two mechanisms have\nbeen described by different theoretical frameworks, hindering a coherent\nunderstanding. Here, we develop a unified theory of the photovoltaic Hall\neffect capable of describing both mechanisms on an equal footing. We reveal\nthat the bias electric field alters the interband transition dipole moment,\ntransition energy, and intraband velocity, all contributing to the\nfield-induced circular photogalvanic effect in nonmagnetic materials. The first\nprocess can be expressed as a manifestation of the electric field-induced Berry\ncurvature. Shift vector plays an essential role in determining the transition\nenergy shift. We also clearly distinguish the anomalous Hall effect by\nlight-dressed states within the density matrix calculation using the length\ngauge. Our theory unifies a number of nonlinear optical processes in a\nphysically transparent way and reveals their geometric aspect.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-12T02:39:13Z"}
{"aid":"http://arxiv.org/abs/2505.07206v1","title":"Ultracompact 4H-silicon carbide optomechanical resonator with $f_m\\cdot\n  Q_m$ exceeding $10^{13}$ Hz","summary":"Silicon carbide (SiC) has great potential for optomechanical applications due\nto its outstanding optical and mechanical properties. However, challenges\nassociated with SiC nanofabrication have constrained its adoption in\noptomechanical devices, as embodied by the considerable optical loss or lack of\nintegrated optical access in existing mechanical resonators. In this work, we\novercome such challenges and demonstrate a low-loss, ultracompact\noptomechanical resonator in an integrated 4H-SiC-on-insulator (4H-SiCOI)\nphotonic platform for the first time. Based on a suspended $4.3$-$\\mu$m-radius\nmicrodisk, the SiC optomechanical resonator features low optical loss ($<1$\ndB/cm), a high mechanical frequency $f_m$ of $0.95 \\times 10^9$ Hz, a\nmechanical quality factor $Q_m$ of $1.92\\times10^4$, and a footprint of\n$<1\\times 10^{-5}$ mm$^2$. The corresponding $f_m\\cdot Q_m$ product is\nestimated to be $1.82 \\times 10^{13}$ Hz, which is among the highest reported\nvalues of optomechanical cavities tested in an ambient environment at room\ntemperature. In addition, the strong optomechanical coupling in the SiC\nmicrodisk enables coherent regenerative optomechanical oscillations at a\nthreshold optical dropped power of 14 $\\mu$W, which also supports efficient\nharmonic generation at increased power levels. With such competitive\nperformance, we envision a range of chip-scale optomechanical applications to\nbe enabled by the low-loss 4H-SiCOI platform.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-05-12T03:29:50Z"}
{"aid":"http://arxiv.org/abs/2505.07212v1","title":"The Language of Influence: Sentiment, Emotion, and Hate Speech in State\n  Sponsored Influence Operations","summary":"State-sponsored influence operations (SIOs) on social media have become an\ninstrumental tool for manipulating public opinion and spreading unverified\ninformation. This study analyzes the sentiment, emotion, and abusive speech in\ntweets circulated by influence campaigns originating from three distinct\ncountries: China, Iran, and Russia. We examined 1.5 million tweets to uncover\npatterns in the content of the influence operations using the dataset provided\nby Twitter. Our findings reveal distinct patterns of sentiment, emotion, and\nabusive nature in different SIOs. Our experimental result shows that Russian\ninfluence operations predominantly employ negative sentiment and toxic language\nto polarize audiences, Iranian operations balance negative and positive tones\nto provoke hostility while fostering support, and Chinese campaigns focus on\npositive messaging to promote favorable narratives.","main_category":"cs.SI","categories":"cs.SI","published":"2025-05-12T03:43:48Z"}
{"aid":"http://arxiv.org/abs/2505.07215v1","title":"Measuring General Intelligence with Generated Games","summary":"We present gg-bench, a collection of game environments designed to evaluate\ngeneral reasoning capabilities in language models. Unlike most static\nbenchmarks, gg-bench is a data generating process where new evaluation\ninstances can be generated at will. In particular, gg-bench is synthetically\ngenerated by (1) using a large language model (LLM) to generate natural\nlanguage descriptions of novel games, (2) using the LLM to implement each game\nin code as a Gym environment, and (3) training reinforcement learning (RL)\nagents via self-play on the generated games. We evaluate language models by\ntheir winrate against these RL agents by prompting models with the game\ndescription, current board state, and a list of valid moves, after which models\noutput the moves they wish to take. gg-bench is challenging: state-of-the-art\nLLMs such as GPT-4o and Claude 3.7 Sonnet achieve winrates of 7-9% on gg-bench\nusing in-context learning, while reasoning models such as o1, o3-mini and\nDeepSeek-R1 achieve average winrates of 31-36%. We release the generated games,\ndata generation process, and evaluation code in order to support future\nmodeling work and expansion of our benchmark.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-12T04:01:03Z"}
{"aid":"http://arxiv.org/abs/2505.07226v1","title":"How Does Monetary Policy Influence the U.S. Treasury Bond Yields, and\n  What are the Implications for Portfolio Managers?","summary":"This paper investigates the impact of monetary policy surprises on U.S.\nTreasury bond yields and the implications for portfolio managers. Based on the\nsupply and demand model, traditional economic theories suggest that Federal\nReserve bond purchases should increase bond prices and decrease yields.\nHowever, New Keynesian models challenge this view, proposing that bond prices\nshould not necessarily rise due to future expectations influencing investor\nbehavior. By analyzing the effects of monetary policy surprises within narrow\nwindows around Federal Open Market Committee (FOMC) announcements, this study\naims to isolate the true impact of these surprises on bond yields. The research\ncovers Treasury bonds of various maturities--3 months, 1 year, 10 years, and 30\nyears--and utilizes cross-sectional regression analysis. The findings reveal\nthat financial crises significantly decrease short-term yields, while no\nobvious evidence of factors that might affect long-term yields. This paper\nprovides insights into how monetary policy influences bond yields and offers\npractical implications for portfolio management, particularly during\nquantitative easing and financial crises.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-05-12T04:44:40Z"}
{"aid":"http://arxiv.org/abs/2505.07246v1","title":"Evaluating Cognitive Assessment Tools:A Comparative Analysis of MMSE,\n  RUDAS, SAGE, ADAS and MoCA for Early Dementia Detection","summary":"Early detection of dementia is very crucial to ensure treatment begins on\ntime, however it is difficult to choose appropriate cognitive assessment tools\nbecause each test is designed differently and may not be tailored to the needs\nof a patient. This review compares five commonly used tests the Mini-Mental\nState Examination (MMSE), Rowland Universal Dementia Assessment Scale (RUDAS),\nSelf-Administered Gerocognitive Examination (SAGE), Alzheimer's Disease\nAssessment Scale (ADAS), and Montreal Cognitive Assessment (MoCA). Each test\nhas different criteria's and vary in their coverage of cognitive domains. MMSE\nfocuses on memory and language but lacks in the evaluation of executive and\nvisuospatial abilities. RUDAS and SAGE focus on memory, language and visual\nthinking while ADAS mainly targets memory, executive function and language. The\nMoCA is most complete as it focuses on areas like attention, memory skills,\nproblem solving and visual skills. This review evaluates how accurate and\nreliable these tools are to help doctors decide the most efficient tool for\ndiagnosis.","main_category":"q-bio.QM","categories":"q-bio.QM,q-bio.NC","published":"2025-05-12T05:41:32Z"}
{"aid":"http://arxiv.org/abs/2505.07250v1","title":"Topological surface states induced by magnetic proximity effect in\n  narrow-gap semiconductor alpha-Sn","summary":"The combination of magnetism and topological properties in one material\nplatform is attracting significant attention due to the potential of realizing\nlow power consumption and error-robust electronic devices. Common practice is\nto start from a topological material with band inversion and incorporates\nferromagnetism via chemical doping or magnetic proximity effect (MPE). In this\nwork, we show that a topological material is not necessary and that both\nferromagnetism and band inversion can be established simultaneously in a\ntrivial insulating material by MPE from a neighbouring ferromagnetic layer.\nThis novel route is demonstrated using quantum transport measurements and first\nprinciples calculations in a heterostructure consisting of 5 nm thick FeOx/1\nmonolayer of FeAs/ 3 nm thick alpha Sn. The Shubnikov de Haas oscillations show\nthat there is linear band dispersion with high mobility in the heterostructure\neven though a 3 nm thick alpha Sn single layer is a trivial semiconductor.\nFurthermore, first principles calculations reveal that band inversion indeed\noccurs in this heterostructure, suggesting that the observed linear band is a\ntopological surface state within this inverted gap. This work significantly\nexpands the foundation for realizing magnetic topological materials in a myriad\nof trivial narrow gap semiconductors.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-12T05:57:29Z"}
{"aid":"http://arxiv.org/abs/2505.07253v1","title":"The weak coupling limit of the Pauli-Fierz model","summary":"We investigate the weak coupling limit of the Pauli- Fierz Hamiltonian within\na mathematically rigorous framework. Furthermore, we establish the asymptotic\nbehavior of the effective mass in this regime.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-05-12T06:08:07Z"}
{"aid":"http://arxiv.org/abs/2505.07268v1","title":"Reconfiguring Multiple Connected Components with Size Multiset\n  Constraints","summary":"We propose a novel generalization of Independent Set Reconfiguration (ISR):\nConnected Components Reconfiguration (CCR). In CCR, we are given a graph $G$,\ntwo vertex subsets $A$ and $B$, and a multiset $\\mathcal{M}$ of positive\nintegers. The question is whether $A$ and $B$ are reconfigurable under a\ncertain rule, while ensuring that each vertex subset induces connected\ncomponents whose sizes match the multiset $\\mathcal{M}$. ISR is a special case\nof CCR where $\\mathcal{M}$ only contains 1. We also propose new reconfiguration\nrules: component jumping (CJ) and component sliding (CS), which regard\nconnected components as tokens. Since CCR generalizes ISR, the problem is\nPSPACE-complete. In contrast, we show three positive results: First, CCR-CS and\nCCR-CJ are solvable in linear and quadratic time, respectively, when $G$ is a\npath. Second, we show that CCR-CS is solvable in linear time for cographs.\nThird, when $\\mathcal{M}$ contains only the same elements (i.e., all connected\ncomponents have the same size), we show that CCR-CJ is solvable in linear time\nif $G$ is chordal. The second and third results generalize known results for\nISR and exhibit an interesting difference between the reconfiguration rules.","main_category":"cs.DS","categories":"cs.DS","published":"2025-05-12T06:46:45Z"}
{"aid":"http://arxiv.org/abs/2505.07272v1","title":"ALPCAH: Subspace Learning for Sample-wise Heteroscedastic Data","summary":"Principal component analysis (PCA) is a key tool in the field of data\ndimensionality reduction. However, some applications involve heterogeneous data\nthat vary in quality due to noise characteristics associated with each data\nsample. Heteroscedastic methods aim to deal with such mixed data quality. This\npaper develops a subspace learning method, named ALPCAH, that can estimate the\nsample-wise noise variances and use this information to improve the estimate of\nthe subspace basis associated with the low-rank structure of the data. Our\nmethod makes no distributional assumptions of the low-rank component and does\nnot assume that the noise variances are known. Further, this method uses a soft\nrank constraint that does not require subspace dimension to be known.\nAdditionally, this paper develops a matrix factorized version of ALPCAH, named\nLR-ALPCAH, that is much faster and more memory efficient at the cost of\nrequiring subspace dimension to be known or estimated. Simulations and real\ndata experiments show the effectiveness of accounting for data\nheteroscedasticity compared to existing algorithms. Code available at\nhttps://github.com/javiersc1/ALPCAH.","main_category":"stat.ML","categories":"stat.ML,cs.LG,eess.SP","published":"2025-05-12T06:49:47Z"}
{"aid":"http://arxiv.org/abs/2505.07275v1","title":"Reduction of multiple filamentation due to atmospheric turbulence during\n  the propagation of a laser pulse","summary":"Multiple filamentation poses a significant challenge for laser pulse\npropagation in the atmosphere. This article investigates how atmospheric\nturbulence influences the development of modulational instability, which leads\nto multiple filamentations. Through various analytical approaches, we\ndemonstrate that the growth rate of this instability decreases when the\nrefractive index exhibits stochastic behavior.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-05-12T06:57:01Z"}
{"aid":"http://arxiv.org/abs/2505.07279v1","title":"Dark photon in parity-violating electron scatterings","summary":"We proposed that parity-violating electron scattering (PVES) offers a\npowerful tool to probe the hypothetical dark photon. We calculated the dark\nphoton contributions to PVES asymmetries in both elastic and deep-inelastic\nscattering (DIS). These contributions are characterised by the corrections to\nthe standard model couplings $C_{1q}, \\, C_{2q}$, and $C_{3q}$. At low scales,\nthe corrections to $C_{1q}$ and $C_{3q}$ could be as large as $5\\%$ were a dark\nphoton to exist. In DIS at very high $Q^2$, of relevance to HERA or the EIC,\nthe dark photon could induce substantial corrections to $C_{2q}$, suggesting as\nlarge as $10\\%$ uncertainties in the extraction of valence parton distribution\nfunctions. We also extracted the favoured regions of the dark photon parameter\nspace by fitting the parity violation data and the CDF $W$ boson mass, which\nprefer a heavy dark photon with mass above the $Z$-boson mass.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-05-12T07:03:04Z"}
{"aid":"http://arxiv.org/abs/2505.07287v1","title":"Learning Quasi-LPV Models and Robust Control Invariant Sets with Reduced\n  Conservativeness","summary":"We present an approach to identify a quasi Linear Parameter Varying (qLPV)\nmodel of a plant, with the qLPV model guaranteed to admit a robust control\ninvariant (RCI) set. It builds upon the concurrent synthesis framework\npresented in [1], in which the requirement of existence of an RCI set is\nmodeled as a control-oriented regularization. Here, we reduce the\nconservativeness of the approach by bounding the qLPV system with an uncertain\nLTI system, which we derive using bound propagation approaches. The resulting\nregularization function is the optimal value of a nonlinear robust optimization\nproblem that we solve via a differentiable algorithm. We numerically\ndemonstrate the benefits of the proposed approach over two benchmark\napproaches.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-05-12T07:18:12Z"}
{"aid":"http://arxiv.org/abs/2505.07288v1","title":"Large quadrupole moment in $^{20}$Ne:Localization and tensor-force\n  effects","summary":"Using the Beyond-Skyrme-Hartree-Fock approach with various Skyrme-type $NN$\neffective interactions, we explore the large spectroscopic quadrupole moment\n$Q_s$ of the first excited $2_{1}^{+}$ state in $^{20}$Ne. Our calculated\n$Q_s(2_{1}^{+}) \\approx -0.20~e\\textrm{b}$ aligns closely with the experimental\nvalue of $-0.22(2)~e\\textrm{b}$. Consistent with other theoretical methods, our\nresults confirm the presence of an $\\alpha$ cluster structure in this state. We\nalso investigate the robustness of the $\\alpha$ cluster against tensor-force,\ndemonstrating that incorporating tensor components significantly enhances\n$Q_s(2_{1}^{+})$ and strengthens the cluster structure along the symmetrical\naxis.","main_category":"nucl-th","categories":"nucl-th","published":"2025-05-12T07:20:52Z"}
{"aid":"http://arxiv.org/abs/2505.07292v1","title":"Weyl laws for exponentially small singular values of the\n  $\\overline{\\partial}$ operator","summary":"We study the number of exponentially small singular values of the\nsemiclassical $\\overline{\\partial}$ operator on exponentially weighted $L^2$\nspaces on the two-dimensional torus. Accurate upper and lower bounds on the\nnumber of such singular values are established with the help of auxiliary\nnotions of upper and lower bound weights. Assuming that the Laplacian of the\nexponential weight changes sign along a curve, we construct optimal such\nweights by solving a free boundary problem, which yields a Weyl asymptotics for\nthe counting function of the singular values in an interval of the form\n$[0,\\mathrm{e}^{-\\tau/h}]$, for $\\tau>0$ smaller than the oscillation of the\nweight. We also provide a precise description of the leading term in the Weyl\nasymptotics, in the regime of small $\\tau > 0$.","main_category":"math.SP","categories":"math.SP,math.AP,math.CV","published":"2025-05-12T07:25:34Z"}
{"aid":"http://arxiv.org/abs/2505.07298v1","title":"Adaptive Learning-based Surrogate Method for Stochastic Programs with\n  Implicitly Decision-dependent Uncertainty","summary":"We consider a class of stochastic programming problems where the implicitly\ndecision-dependent random variable follows a nonparametric regression model\nwith heteroscedastic error. The Clarke subdifferential and surrogate functions\nare not readily obtainable due to the latent decision dependency. To deal with\nsuch a computational difficulty, we develop an adaptive learning-based\nsurrogate method that integrates the simulation scheme and statistical\nestimates to construct estimation-based surrogate functions in a way that the\nsimulation process is adaptively guided by the algorithmic procedure. We\nestablish the non-asymptotic convergence rate analysis in terms of $(\\nu,\n\\delta)$-near stationarity in expectation under variable proximal parameters\nand batch sizes, which exhibits the superior convergence performance and\nenhanced stability in both theory and practice. We provide numerical results\nwith both synthetic and real data which illustrate the benefits of the proposed\nalgorithm in terms of algorithmic stability and efficiency.","main_category":"math.OC","categories":"math.OC,stat.ML","published":"2025-05-12T07:35:06Z"}
{"aid":"http://arxiv.org/abs/2505.07316v1","title":"Nitrogen and oxygen transport and reactions during plasma nitridation of\n  zirconium thin films","summary":"Zirconium nitride (ZrN) is a refractory material with good mechanical and\nthermal properties. It is therefore a good candidate for hard surface treatment\nat high temperature. In this work, we report the growth and characterization of\nZrN by plasma assisted thermal nitridation of zirconium films in a NH3\natmosphere. The process was monitored by in situ monochromatic ellipsometry and\nthe nitrides grown were profiled and analyzed by Auger electron spectroscopy.\nBy using temperatures in the 700--800___{\\textdegree}C range, the material\nobtained is quite close to ZrN, but, depending on experimental conditions,\nresidual oxygen (impurities) can be easily incorporated by reaction with\nzirconium. The analysis of the ellipsometric data has shown that the\nnitridation did not occur by simple growth of nitride on zirconium. Auger\nprofiles confirmed the presence of an oxidized zirconium layer localized\nbetween the nitrided surface and the remaining metal. This oxidation was\nobserved to occur preferentially during temperature ramping, that is, in the\nlow temperature regime. At high temperature, nitridation is dominant and the\nincorporated oxygen is exchanged with nitrogen. Oxygen is then partly rejected\nby diffusion out of the film through the ZrN surface layer and partly by\ndiffusion in the deep zirconium sublayer. By using these observations, a new\nmodel of growth with a layered ZrN/ZrOx/Zr film was used to describe in situ\nellipsometric data. By comparing the pure thermal and the plasma treatments,\nthe advantages of the plasma assisted treatment become clearly: complete\nnitridation of the zirconium layer was achieved and the oxygen amounts in the\nfilm were substantially reduced.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-12T08:01:33Z"}
{"aid":"http://arxiv.org/abs/2505.07329v1","title":"Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption","summary":"Preserving data confidentiality during the fine-tuning of open-source Large\nLanguage Models (LLMs) is crucial for sensitive applications. This work\nintroduces an interactive protocol adapting the Low-Rank Adaptation (LoRA)\ntechnique for private fine-tuning. Homomorphic Encryption (HE) protects the\nconfidentiality of training data and gradients handled by remote worker nodes\nperforming the bulk of computations involving the base model weights. The data\nowner orchestrates training, requiring minimal local computing power and\nmemory, thus alleviating the need for expensive client-side GPUs. We\ndemonstrate feasibility by fine-tuning a Llama-3.2-1B model, presenting\nconvergence results using HE-compatible quantization and performance benchmarks\nfor HE computations on GPU hardware. This approach enables applications such as\nconfidential knowledge base question answering, private codebase fine-tuning\nfor AI code assistants, AI agents for drafting emails based on a company's\nemail archive, and adapting models to analyze sensitive legal or healthcare\ndocuments.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-05-12T08:14:33Z"}
{"aid":"http://arxiv.org/abs/2505.07333v1","title":"Link to the Past: Temporal Propagation for Fast 3D Human Reconstruction\n  from Monocular Video","summary":"Fast 3D clothed human reconstruction from monocular video remains a\nsignificant challenge in computer vision, particularly in balancing\ncomputational efficiency with reconstruction quality. Current approaches are\neither focused on static image reconstruction but too computationally\nintensive, or achieve high quality through per-video optimization that requires\nminutes to hours of processing, making them unsuitable for real-time\napplications. To this end, we present TemPoFast3D, a novel method that\nleverages temporal coherency of human appearance to reduce redundant\ncomputation while maintaining reconstruction quality. Our approach is a\n\"plug-and play\" solution that uniquely transforms pixel-aligned reconstruction\nnetworks to handle continuous video streams by maintaining and refining a\ncanonical appearance representation through efficient coordinate mapping.\nExtensive experiments demonstrate that TemPoFast3D matches or exceeds\nstate-of-the-art methods across standard metrics while providing high-quality\ntextured reconstruction across diverse pose and appearance, with a maximum\nspeed of 12 FPS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T08:16:19Z"}
{"aid":"http://arxiv.org/abs/2505.07335v1","title":"Swarm Antenna Arrays: From Deterministic to Stochastic Modeling","summary":"Swarm antenna arrays, composed of spatially distributed antennas mounted on\nunmanned agents, offer unprecedented flexibility and adaptability for wireless\nsensing and communication. However, their reconfigurable architecture,\nsusceptibility to collisions, and inherently stochastic nature present\nsignificant challenges to realizing collaborative gain. It remains unclear how\nspatial coordination, positional perturbations, and large-scale topological\nconfigurations affect coherent signal aggregation and overall system\nperformance. This paper investigates the feasibility of achieving coherent\nbeamforming in such systems from both deterministic and stochastic\nperspectives. First, we develop a rigorous theoretical framework that\ncharacterizes the necessary and sufficient conditions for the emergence of\ngrating lobes in multiple linear configurations. Notably, we show that for dual\nlinear arrays, the classical half-wavelength spacing constraint can be safely\nrelaxed without introducing spatial aliasing. This result challenges\ntraditional array design principles and enables more flexible, collision-aware\ntopologies. Second, we present a theoretical analysis, supported by empirical\nvalidation, demonstrating that coherent gain can be approximately preserved\nunder realistic positional perturbations. Our results reveal that spatial\nperturbations introduce measurable degradation in the main lobe, an effect that\ncannot be mitigated merely by increasing the number of antennas. Instead, the\nprimary benefit of scaling lies in reducing the variance of\nperturbation-induced fluctuations.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-12T08:21:20Z"}
{"aid":"http://arxiv.org/abs/2505.07338v1","title":"A Systems Biology view of Breast cancer via Fractal Geometry and\n  Fractional Calculus","summary":"Breast cancer (BC) is the most widespread cancer globally, yet current\ndiagnostic and prognostic methods inadequately capture its biological\ncomplexity, despite the benefits of early detection. Cancer systems biology\n(SB) has advanced over the past two decades as a multiscale approach, but often\nneglects morphological complexity observable at cellular, tissue, and tumor\nlevels. Structural organization significantly influences system behavior,\nnecessitating the identification of scales where morphological features emerge.\nFractal geometry (FG) provides quantitative tools to assess the irregular,\nscale-invariant structures typical of cancer. Alongside FG, fractional calculus\n(FC) offers a framework to model memory-dependent and non-local dynamics.\nHowever, existing research remains constrained to mono-fractal analyses or\nlimited imaging scopes, lacking integration into broader SB models. This review\naims to bridge that gap by presenting core FG concepts, both mono- and\nmulti-fractal measures, and their application to BC across histological,\ncytological, and radiological data. It further explores how FC enhances dynamic\nmorphological modeling. Finally, it considers how number-theoretic tools like\np-adic analysis may represent hierarchical genomic and morphological patterns,\nunifying insights from tumor morphology to genome organization.","main_category":"q-bio.QM","categories":"q-bio.QM","published":"2025-05-12T08:24:03Z"}
{"aid":"http://arxiv.org/abs/2505.07340v1","title":"Thalamus: A User Simulation Toolkit for Prototyping Multimodal Sensing\n  Studies","summary":"Conducting user studies that involve physiological and behavioral\nmeasurements is very time-consuming and expensive, as it not only involves a\ncareful experiment design, device calibration, etc. but also a careful software\ntesting. We propose Thalamus, a software toolkit for collecting and simulating\nmultimodal signals that can help the experimenters to prepare in advance for\nunexpected situations before reaching out to the actual study participants and\neven before having to install or purchase a specific device. Among other\nfeatures, Thalamus allows the experimenter to modify, synchronize, and\nbroadcast physiological signals (as coming from various data streams) from\ndifferent devices simultaneously and not necessarily located in the same place.\nThalamus is cross-platform, cross-device, and simple to use, making it thus a\nvaluable asset for HCI research.","main_category":"cs.HC","categories":"cs.HC","published":"2025-05-12T08:25:43Z"}
{"aid":"http://arxiv.org/abs/2505.07348v1","title":"Stiffness-based Analytic Centre Method for Cable-Driven Parallel Robots","summary":"Nowadays, being fast and precise are key requirements in Robotics. This work\nintroduces a novel methodology to tune the stiffness of Cable-Driven Parallel\nRobots (CDPRs) while simultaneously addressing the tension distribution\nproblem. In particular, the approach relies on the Analytic-Centre method.\nIndeed, weighting the barrier functions makes natural the stiffness adaptation.\nThe intrinsic ability to adjust the stiffness during the execution of the task\nenables the CDPRs to effectively meet above-mentioned requirements. The\ncapabilities of the method are demonstrated through simulations by comparing it\nwith the existing approach.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-05-12T08:41:49Z"}
{"aid":"http://arxiv.org/abs/2505.07350v1","title":"All-optical electric field sensing with nanodiamond-doped polymer thin\n  films","summary":"The nitrogen-vacancy (NV) center is a photoluminescent defect in diamond that\nexists in different charge states, NV$^-$ and NV$^0$, that are sensitive to the\nNV's nanoscale environment. Here, we show that photoluminescence (PL) from NV\ncenters in fluorescent nanodiamonds (FNDs) can be employed for all-optical\nvoltage sensing based on electric field-induced NV charge state modulation.\nMore than 95% of FNDs integrated into a capacitor device show a transient\nincrease in NV$^-$ PL intensity of up to 31% within 0.1 ms after application of\nan external voltage, accompanied by a simultaneous decrease in NV$^0$ PL. The\nchange in NV$^-$ PL increases with increasing applied voltage from 0 to 100 V,\ncorresponding to an electric field of 0 to 625 kV cm$^ {-1}$ in our devices.\nThe electric field sensitivity of a single FND is 19 V cm$^{-1}$ Hz$^ {-1/2}$.\nWe investigate the NV charge state photodynamics on the millisecond timescale\nand find that the change in NV PL strongly depends on the rate of\nphotoexcitation. We propose a model that qualitatively explains the observed\nchanges in NV PL based on an electric field-induced redistribution of\nphotoexcited electrons from substitutional nitrogen defects to NV centers,\nleading to a transient conversion of NV$^0$ to NV$^-$ centers upon application\nof an external voltage. Our results contribute to the development of FNDs as\nreliable, all-optical, nanoscale electric field sensors in solid-state systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-05-12T08:44:10Z"}
{"aid":"http://arxiv.org/abs/2505.07359v1","title":"Parton helicities at arbitrary x and Q2 in double-logarithmic\n  approximation","summary":"Description of spin-dependent hadronic processes at high energies in terms of\nparton helicities is a both effective and technically convenient means. In the\npresent paper, we obtain explicit expressions for the parton helicities when\neither Collinear or KT forms of QCD Factorization are used. Starting our\nstudies with calculation of the helicities in the double-logarithmic\napproximation (DLA) in the region of small x and large Q2, we generalize the\nresults in order to obtain formulae valid at arbitrary x and Q2. We argue\nagainst using Collinear Factorization, when the parton orbital angular momenta\nare accounted for, and prove that KT-Factorization should be used instead. We\nalso consider in detail the small-x asymptotics of the parton helicities,\ncompare them with the DGLAP-asymptotics and prove a property of the\nasymptot1ics often used in the literature though without a proof. Namely, the\nasymptotics of all parton helicities and the asymptotics of the spin structure\nfunction g1 are the same despite the parent formulae for these objects are\nquite different.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-05-12T08:52:41Z"}
{"aid":"http://arxiv.org/abs/2505.07373v1","title":"Geometric Prior-Guided Neural Implicit Surface Reconstruction in the\n  Wild","summary":"Neural implicit surface reconstruction using volume rendering techniques has\nrecently achieved significant advancements in creating high-fidelity surfaces\nfrom multiple 2D images. However, current methods primarily target scenes with\nconsistent illumination and struggle to accurately reconstruct 3D geometry in\nuncontrolled environments with transient occlusions or varying appearances.\nWhile some neural radiance field (NeRF)-based variants can better manage\nphotometric variations and transient objects in complex scenes, they are\ndesigned for novel view synthesis rather than precise surface reconstruction\ndue to limited surface constraints. To overcome this limitation, we introduce a\nnovel approach that applies multiple geometric constraints to the implicit\nsurface optimization process, enabling more accurate reconstructions from\nunconstrained image collections. First, we utilize sparse 3D points from\nstructure-from-motion (SfM) to refine the signed distance function estimation\nfor the reconstructed surface, with a displacement compensation to accommodate\nnoise in the sparse points. Additionally, we employ robust normal priors\nderived from a normal predictor, enhanced by edge prior filtering and\nmulti-view consistency constraints, to improve alignment with the actual\nsurface geometry. Extensive testing on the Heritage-Recon benchmark and other\ndatasets has shown that the proposed method can accurately reconstruct surfaces\nfrom in-the-wild images, yielding geometries with superior accuracy and\ngranularity compared to existing techniques. Our approach enables high-quality\n3D reconstruction of various landmarks, making it applicable to diverse\nscenarios such as digital preservation of cultural heritage sites.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T09:17:30Z"}
{"aid":"http://arxiv.org/abs/2505.07381v1","title":"Few-shot Semantic Encoding and Decoding for Video Surveillance","summary":"With the continuous increase in the number and resolution of video\nsurveillance cameras, the burden of transmitting and storing surveillance video\nis growing. Traditional communication methods based on Shannon's theory are\nfacing optimization bottlenecks. Semantic communication, as an emerging\ncommunication method, is expected to break through this bottleneck and reduce\nthe storage and transmission consumption of video. Existing semantic decoding\nmethods often require many samples to train the neural network for each scene,\nwhich is time-consuming and labor-intensive. In this study, a semantic encoding\nand decoding method for surveillance video is proposed. First, the sketch was\nextracted as semantic information, and a sketch compression method was proposed\nto reduce the bit rate of semantic information. Then, an image translation\nnetwork was proposed to translate the sketch into a video frame with a\nreference frame. Finally, a few-shot sketch decoding network was proposed to\nreconstruct video from sketch. Experimental results showed that the proposed\nmethod achieved significantly better video reconstruction performance than\nbaseline methods. The sketch compression method could effectively reduce the\nstorage and transmission consumption of semantic information with little\ncompromise on video quality. The proposed method provides a novel semantic\nencoding and decoding method that only needs a few training samples for each\nsurveillance scene, thus improving the practicality of the semantic\ncommunication system.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-12T09:27:28Z"}
{"aid":"http://arxiv.org/abs/2505.07386v1","title":"Towards a physically realistic computationally efficient DVS pixel model","summary":"Dynamic Vision Sensor (DVS) event camera models are important tools for\npredicting camera response, optimizing biases, and generating realistic\nsimulated datasets. Existing DVS models have been useful, but have not\ndemonstrated high realism for challenging HDR scenes combined with adequate\ncomputational efficiency for array-level scene simulation. This paper reports\nprogress towards a physically realistic and computationally efficient DVS model\nbased on large-signal differential equations derived from circuit analysis,\nwith parameters fitted from pixel measurements and circuit simulation. These\nare combined with an efficient stochastic event generation mechanism based on\nfirst-passage-time theory, allowing accurate noise generation with timesteps\ngreater than 1000x longer than previous methods","main_category":"eess.IV","categories":"eess.IV","published":"2025-05-12T09:31:24Z"}
{"aid":"http://arxiv.org/abs/2505.07403v1","title":"Investigating sub-MeV dark matter annihilation to neutrinos using direct\n  detection experiments","summary":"Dark matter (DM) could self-annihilate into neutrinos in dense regions of the\nUniverse. We consider the resulting flux of neutrinos from the Milky Way DM\nhalo and derive exclusion limits on the annihilation cross-section using\nXENONnT electron recoil data. Assuming a $J$-factor independent of the\nannihilation cross-section, we find leading limits for DM masses below\n$\\mathcal{O}$(MeV). Self-annihilating DM affects the DM halo via dissolution,\nintroducing a cross-section dependency on the halo profile and thus the\n$J$-factor. We discuss such a situation in more detail, finding that the signal\nrate is below the experimental sensitivity of XENONnT, leaving the annihilation\ncross-section unconstrained.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-05-12T09:57:49Z"}
{"aid":"http://arxiv.org/abs/2505.07409v1","title":"Computational Fact-Checking of Online Discourse: Scoring scientific\n  accuracy in climate change related news articles","summary":"Democratic societies need reliable information. Misinformation in popular\nmedia such as news articles or videos threatens to impair civic discourse.\nCitizens are, unfortunately, not equipped to verify this content flood consumed\ndaily at increasing rates. This work aims to semi-automatically quantify\nscientific accuracy of online media. By semantifying media of unknown veracity,\ntheir statements can be compared against equally processed trusted sources. We\nimplemented a workflow using LLM-based statement extraction and knowledge graph\nanalysis. Our neurosymbolic system was able to evidently streamline\nstate-of-the-art veracity quantification. Evaluated via expert interviews and a\nuser survey, the tool provides a beneficial veracity indication. This\nindicator, however, is unable to annotate public media at the required\ngranularity and scale. Further work towards a FAIR (Findable, Accessible,\nInteroperable, Reusable) ground truth and complementary metrics are required to\nscientifically support civic discourse.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-12T10:03:15Z"}
{"aid":"http://arxiv.org/abs/2505.07417v1","title":"LA-IMR: Latency-Aware, Predictive In-Memory Routing and Proactive\n  Autoscaling for Tail-Latency-Sensitive Cloud Robotics","summary":"Hybrid cloud-edge infrastructures now support latency-critical workloads\nranging from autonomous vehicles and surgical robotics to immersive AR/VR.\nHowever, they continue to experience crippling long-tail latency spikes\nwhenever bursty request streams exceed the capacity of heterogeneous edge and\ncloud tiers. To address these long-tail latency issues, we present\nLatency-Aware, Predictive In-Memory Routing and Proactive Autoscaling (LA-IMR).\nThis control layer integrates a closed-form, utilization-driven latency model\nwith event-driven scheduling, replica autoscaling, and edge-to-cloud offloading\nto mitigate 99th-percentile (P99) delays. Our analytic model decomposes\nend-to-end latency into processing, network, and queuing components, expressing\ninference latency as an affine power-law function of instance utilization. Once\ncalibrated, it produces two complementary functions that drive: (i)\nmillisecond-scale routing decisions for traffic offloading, and (ii) capacity\nplanning that jointly determines replica pool sizes. LA-IMR enacts these\ndecisions through a quality-differentiated, multi-queue scheduler and a\ncustom-metric Kubernetes autoscaler that scales replicas proactively -- before\nqueues build up -- rather than reactively based on lagging CPU metrics. Across\nrepresentative vision workloads (YOLOv5m and EfficientDet) and bursty arrival\ntraces, LA-IMR reduces P99 latency by up to 20.7 percent compared to\ntraditional latency-only autoscaling, laying a principled foundation for\nnext-generation, tail-tolerant cloud-edge inference services.","main_category":"cs.DC","categories":"cs.DC","published":"2025-05-12T10:12:24Z"}
{"aid":"http://arxiv.org/abs/2505.07418v1","title":"Relative Quantifier Elimination for Separable-Algebraically Maximal\n  Kaplansky Fields","summary":"Let $C$ be the class of separable-algebraically maximal equi-characteristic\nKaplansky fields of a given imperfection degree, admitting an angular component\nmap. We prove that the common theory of the class $C$ resplendently eliminates\nquantifiers down to the residue field and the value group, in a three sorted\nlanguage of valued fields with a symbol for an angular component map and\nsymbols for the parameterized lambda-functions. As a consequence, we obtain\nthat equi-characteristic NIP and NIP$_n$ henselian fields with an angular\ncomponent map resplendently eliminate field quantifiers in this language. We\nalso prove that this elimination reduces existential formulas to existential\nformulas without quantifiers from the home sort. Finally, we draw several\nconclusions following the AKE philosophy for elements of the class $C$,\nincluding the usual AKE principles for\n$\\equiv,\\equiv_{\\exists},\\preceq,\\preceq_{\\exists}$ and for relative\ndecidability.","main_category":"math.LO","categories":"math.LO","published":"2025-05-12T10:18:12Z"}
{"aid":"http://arxiv.org/abs/2505.07428v1","title":"Interaction Effects on the Electronic Floquet Spectra: Excitonic Effects","summary":"Floquet engineering of electronic states by light is a central topic in\nmodern experiments. However, the impact of many-body interactions on the\nsingle-electron properties remains unclear in this non-equilibrium situation.\nWe propose that interaction effects could be reasonably understood by\nperforming perturbative expansion in both the pump field and the\nelectron-electron interaction when computing physical quantities. As an\nexample, we apply this approach to semiconductors and show analytically that\nexcitonic effects, i.e., effects of electron-hole interaction, lead to dramatic\ncorrections to the single-electron Floquet spectra even when the excitons are\nonly virtually excited by the pump light. We compute these effects in\nphosphorene and monolayer MoS$_2$ for time- and angle-resolved photoemission\nspectroscopy (Tr-ARPES) and ultrafast optical experiments.","main_category":"cond-mat.other","categories":"cond-mat.other,cond-mat.quant-gas,cond-mat.stat-mech,physics.optics,quant-ph","published":"2025-05-12T10:36:54Z"}
{"aid":"http://arxiv.org/abs/2505.07453v1","title":"How well do LLMs reason over tabular data, really?","summary":"Large Language Models (LLMs) excel in natural language tasks, but less is\nknown about their reasoning capabilities over tabular data. Prior analyses\ndevise evaluation strategies that poorly reflect an LLM's realistic performance\non tabular queries. Moreover, we have a limited understanding of the robustness\nof LLMs towards realistic variations in tabular inputs. Therefore, we ask: Can\ngeneral-purpose LLMs reason over tabular data, really?, and focus on two\nquestions 1) are tabular reasoning capabilities of general-purpose LLMs robust\nto real-world characteristics of tabular inputs, and 2) how can we\nrealistically evaluate an LLM's performance on analytical tabular queries?\nBuilding on a recent tabular reasoning benchmark, we first surface shortcomings\nof its multiple-choice prompt evaluation strategy, as well as commonly used\nfree-form text metrics such as SacreBleu and BERT-score. We show that an\nLLM-as-a-judge procedure yields more reliable performance insights and unveil a\nsignificant deficit in tabular reasoning performance of LLMs. We then extend\nthe tabular inputs reflecting three common characteristics in practice: 1)\nmissing values, 2) duplicate entities, and 3) structural variations.\nExperiments show that the tabular reasoning capabilities of general-purpose\nLLMs suffer from these variations, stressing the importance of improving their\nrobustness for realistic tabular inputs.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-12T11:35:28Z"}
{"aid":"http://arxiv.org/abs/2505.07460v1","title":"A Survey on Collaborative Mechanisms Between Large and Small Language\n  Models","summary":"Large Language Models (LLMs) deliver powerful AI capabilities but face\ndeployment challenges due to high resource costs and latency, whereas Small\nLanguage Models (SLMs) offer efficiency and deployability at the cost of\nreduced performance. Collaboration between LLMs and SLMs emerges as a crucial\nparadigm to synergistically balance these trade-offs, enabling advanced AI\napplications, especially on resource-constrained edge devices. This survey\nprovides a comprehensive overview of LLM-SLM collaboration, detailing various\ninteraction mechanisms (pipeline, routing, auxiliary, distillation, fusion),\nkey enabling technologies, and diverse application scenarios driven by\non-device needs like low latency, privacy, personalization, and offline\noperation. While highlighting the significant potential for creating more\nefficient, adaptable, and accessible AI, we also discuss persistent challenges\nincluding system overhead, inter-model consistency, robust task allocation,\nevaluation complexity, and security/privacy concerns. Future directions point\ntowards more intelligent adaptive frameworks, deeper model fusion, and\nexpansion into multimodal and embodied AI, positioning LLM-SLM collaboration as\na key driver for the next generation of practical and ubiquitous artificial\nintelligence.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-05-12T11:48:42Z"}
{"aid":"http://arxiv.org/abs/2505.07461v1","title":"Chern-Simons potentials of higher-dimensional Pontryagin densities","summary":"We develop a novel and systematic approach to computing the Chern-Simons\npotentials given the Pontryagin densities in arbitrary even dimensions $ D\\geq4\n$. Throughout we work with a generic affine connection, that results in a\nnon-vanishing torsion in general and allows for non-metricity, which\naccommodates the existence of non-trivial Pontryagin densities in $ D=4n-2 \\,\n(n \\geq 2) $ dimensions. We outline an algorithm, with its implementation as a\ncode, which lets one to determine the Chern-Simons potential of the Pontryagin\ndensity given an arbitrary even dimension.","main_category":"math-ph","categories":"math-ph,gr-qc,hep-th,math.MP","published":"2025-05-12T11:48:50Z"}
{"aid":"http://arxiv.org/abs/2505.07471v1","title":"Understanding the IBEX ribbon using the kinetic model of pickup proton\n  transport in a scatter-free limit","summary":"One of the most remarkable discoveries by the IBEX is the ribbon - a narrow\nband of enhanced ENA fluxes observed in the sky. The prevailing explanation\nattributes the IBEX ribbon to the secondary ENA mechanism. In this process,\nprimary H ENAs, produced via charge exchange between solar wind (SW) protons\nand interstellar H atoms within the heliosphere, travel beyond the heliopause\n(HP) and undergo further charge exchange with protons of the LISM, generating\npickup protons. Some of these pickup protons subsequently experience charge\nexchange with interstellar H atoms, forming secondary ENAs, some of which\ntravel back toward the Sun and are detected by the IBEX. This paper presents a\nkinetic model developed to simulate secondary ENA fluxes. Ribbon simulations\nare performed using global distributions of plasma and H atoms in the\nheliosphere derived from a kinetic-MHD model of the SW/LISM interaction. The\nmodel accounts for all relevant primary ENA populations, including neutralized\nthermal SW protons, neutralized pickup protons, and ENAs originating in the\ninner heliosheath (IHS). The transport of pickup protons beyond the HP is\ndescribed by the focused transport equation for a gyrotropic velocity\ndistribution in the scatter-free limit, assuming no pitch-angle scattering or\nenergy diffusion. Our simulations qualitatively reproduce IBEX-Hi ribbon\nobservations and exhibit good quantitative agreement at low heliolatitudes.\nHowever, the model underestimates fluxes at high heliolatitudes, likely due to\nthe omission of non-stationary SW behavior in the stationary framework used in\nthis work. The study highlights the importance of ENAs from the IHS, a\npopulation considered for the ribbon production in the frame of the kinetic\nmodel of pickup proton transport in the heliosphere for the first time, for\naccurately reproducing ribbon fluxes observed by IBEX-Hi at the highest energy\nsteps.","main_category":"physics.space-ph","categories":"physics.space-ph,astro-ph.EP,astro-ph.SR","published":"2025-05-12T12:04:15Z"}
{"aid":"http://arxiv.org/abs/2505.07478v1","title":"Low-energy effective Hamiltonian and end states of an inverted HgTe\n  nanowire","summary":"The band inversion transition in a cylindrical HgTe nanowire is inducible via\nvarying the nanowire radius. Here we derive the low-energy effective\nHamiltonian describing the band structure of the HgTe nanowire close to the\nfundamental band gap. Because both the $E_{1}$ and $H_{1}$ subbands have\nquadratic dependence on $k_{z}$ when the gap closes, we need to consider at\nleast three subbands, i.e., the $E_{1}$, $H_{1}$, and $H_{2}$ subbands, in\nbuilding the effective Hamiltonian. The resulted effective Hamiltonian is block\ndiagonal and each block is a $3\\times3$ matrix. End states are found in the\ninverted regime when we solve the effective Hamiltonian with open boundary\ncondition.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-05-12T12:10:59Z"}
{"aid":"http://arxiv.org/abs/2505.07485v1","title":"Generically-constrained quantum isotropy","summary":"Let $V$ be a finite-dimensional unitary representation of a compact quantum\ngroup $\\mathrm{G}$ and denote by $\\mathrm{G}_W$ the isotropy subgroup of a\nlinear subspace $W\\le V$ regarded as a point in the Grassmannian\n$\\mathbb{G}(V)$. We show that the space of those $W\\in \\mathbb{G}(V)$ for which\n$\\mathrm{G}_W$ acts trivially on $W$ (or $V$) is open in the Zariski topology\nof the Weil restriction $\\mathrm{Res}_{\\mathbb{C}/\\mathbb{R}}\\mathbb{G}(V)$.\nMore generally, this holds for the space of $W$ for which (a) the\n$\\mathrm{G}_W$-action factors through its abelianization, or (b) the summands\nof the $\\mathrm{G}_W$-representation on $W$ (or $V$) are otherwise\ndimensionally constrained.\n  The results generalize analogous classical generic rigidity statements useful\nin establishing the triviality of the classical automorphism groups of random\nquantum graphs in the matrix algebra $M_n$, and can be put to similar use in\nfully non-commutative versions of those results (quantum graphs, quantum\ngroups).","main_category":"math.QA","categories":"math.QA,math.AG,math.OA,math.RA,math.RT","published":"2025-05-12T12:16:29Z"}
{"aid":"http://arxiv.org/abs/2505.07491v1","title":"Rapid formation of a very massive star >50000 $M_\\odot$ and subsequently\n  an IMBH from runaway collisions. Direct N-body and Monte Carlo simulations of\n  dense star clusters","summary":"Context. We present simulations of a massive young star cluster using\n\\textsc{Nbody6++GPU} and \\textsc{MOCCA}. The cluster is initially more compact\nthan previously published models, with one million stars, a total mass of $5.86\n\\times 10^5~\\mathrm{M}_{\\odot}$, and a half-mass radius of $0.1~\\mathrm{pc}$.\n  Aims. We analyse the formation and growth of a very massive star (VMS)\nthrough successive stellar collisions and investigate the subsequent formation\nof an intermediate-mass black hole (IMBH) in the core of a dense star cluster.\n  Methods. We use both direct \\textit{N}-body and Monte Carlo simulations,\nincorporating updated stellar evolution prescriptions (SSE/BSE) tailored to\nmassive stars and VMSs. These include revised treatments of stellar radii,\nrejuvenation, and mass loss during collisions. While the prescriptions\nrepresent reasonable extrapolations into the VMS regime, the internal structure\nand thermal state of VMSs formed through stellar collisions remain uncertain,\nand future work may require further refinement.\n  Results. We find that runaway stellar collisions in the cluster core produce\na VMS exceeding $5 \\times 10^4~\\mathrm{M}_{\\odot}$ within 5 Myr, which\nsubsequently collapses into an IMBH.\n  Conclusions. Our model suggests that dense stellar environments may enable\nthe formation of very massive stars and massive black hole seeds through\nrunaway stellar collisions. These results provide a potential pathway for early\nblack hole growth in star clusters and offer theoretical context for\ninterpreting recent JWST observations of young, compact clusters at high\nredshift.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE,astro-ph.SR","published":"2025-05-12T12:21:38Z"}
{"aid":"http://arxiv.org/abs/2505.07505v1","title":"On discrete X-ray transform","summary":"We consider a discrete version of X-ray transform going back, in particular,\nto Strichartz (1982). We suggest non-overdetermined reconstruction for this\ndiscrete transform. Extensions to weighted (attenuated) analogues are given.\nConnections to the continuous case are presented.","main_category":"math.FA","categories":"math.FA","published":"2025-05-12T12:41:05Z"}
{"aid":"http://arxiv.org/abs/2505.07509v1","title":"HALO: Half Life-Based Outdated Fact Filtering in Temporal Knowledge\n  Graphs","summary":"Outdated facts in temporal knowledge graphs (TKGs) result from exceeding the\nexpiration date of facts, which negatively impact reasoning performance on\nTKGs. However, existing reasoning methods primarily focus on positive\nimportance of historical facts, neglecting adverse effects of outdated facts.\nBesides, training on these outdated facts yields extra computational cost. To\naddress these challenges, we propose an outdated fact filtering framework named\nHALO, which quantifies the temporal validity of historical facts by exploring\nthe half-life theory to filter outdated facts in TKGs. HALO consists of three\nmodules: the temporal fact attention module, the dynamic relation-aware encoder\nmodule, and the outdated fact filtering module. Firstly, the temporal fact\nattention module captures the evolution of historical facts over time to\nidentify relevant facts. Secondly, the dynamic relation-aware encoder module is\ndesigned for efficiently predicting the half life of each fact. Finally, we\nconstruct a time decay function based on the half-life theory to quantify the\ntemporal validity of facts and filter outdated facts. Experimental results show\nthat HALO outperforms the state-of-the-art TKG reasoning methods on three\npublic datasets, demonstrating its effectiveness in detecting and filtering\noutdated facts (Codes are available at\nhttps://github.com/yushuowiki/K-Half/tree/main ).","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-12T12:47:20Z"}
{"aid":"http://arxiv.org/abs/2505.07518v1","title":"On Lambda functions in henselian and separably tame valued fields","summary":"Given a field extension $F/C$, the ``Lambda closure'' $\\Lambda_{F}C$ of $C$\nin $F$ is a subextension of $F/C$ that is minimal with respect to inclusion\nsuch that $F/\\Lambda_{F}C$ is separable. The existence and uniqueness of\n$\\Lambda_{F}C$ was proved by Deveney and Mordeson in 1977. We show that it\nadmits a simple description in terms of given generators for $C$: we expand the\nlanguage of rings by the parameterized Lambda functions, and then\n$\\Lambda_{F}C$ is the subfield of $F$ generated over $C$ by additionally\nclosing under these functions. We then show that, given particular generators\nof $C$, $\\Lambda_{F}C$ is the subfield of $F$ generated iteratively by the\nimages of the generators under Lambda functions taken with respect to\n$p$-independent tuples also drawn from those generators.\n  We apply these results to given a ``local description'' of existentially\ndefinable sets in fields equipped with a henselian topology. Let $X(K)$ be an\nexistentially definable set in the theory of a field $K$ equipped with a\nhenselian topology $\\tau$. We show that there is a definable injection into\n$X(K)$ from a Zariski-open subset $U_{1}^{\\circ}$ of a set with nonempty\n$\\tau$-interior, and that each element of $U_{1}^{\\circ}$ is interalgebraic\n(over parameters) with its image in $X(K)$. This can be seen as a kind of {\\em\nvery weak local quantifier elimination}, and it shows that existentially\ndefinable sets are (at least generically and locally) definably pararameterized\nby ``big'' sets.\n  In the final section we extend the theory of separably tame valued fields,\ndeveloped by Kuhlmann and Pal, to include the case of infinite degree of\nimperfection, and to allow expansions of the residue field and value group\nstructures. We prove an embedding theorem which allows us to deduce the usual\nkinds of resplendent Ax--Kochen/Ershov principles.","main_category":"math.LO","categories":"math.LO","published":"2025-05-12T12:58:32Z"}
{"aid":"http://arxiv.org/abs/2505.07519v1","title":"Quantum mechanical closure of partial differential equations with\n  symmetries","summary":"We develop a framework for the dynamical closure of spatiotemporal dynamics\ngoverned by partial differential equations. We employ the mathematical\nframework of quantum mechanics to embed the original classical dynamics into an\ninfinite dimensional quantum mechanical system, using the space of quantum\nstates to model the unresolved degrees of freedom of the original dynamics and\nthe technology of quantum measurement to predict their contributions to the\nresolved dynamics. We use a positivity preserving discretization to project the\nembedded dynamics to finite dimension. Combining methods from operator valued\nkernels and delay embedding, we derive a compressed representation of the\ndynamics that is invariant under the spatial symmetries of the original\ndynamics. We develop a data driven formulation of the scheme that can be\nrealized numerically and apply it to a dynamical closure problem for the\nshallow water equations, demonstrating that our closure model can accurately\npredict the main features of the true dynamics, including for out of sample\ninitial conditions.","main_category":"math.DS","categories":"math.DS,physics.comp-ph","published":"2025-05-12T13:00:36Z"}
{"aid":"http://arxiv.org/abs/2505.07534v1","title":"The Human-Data-Model Interaction Canvas for Visual Analytics","summary":"Visual Analytics (VA) integrates humans, data, and models as key actors in\ninsight generation and data-driven decision-making. This position paper values\nand reflects on 16 VA process models and frameworks and makes nine high-level\nobservations that motivate a fresh perspective on VA. The contribution is the\nHDMI Canvas, a perspective to VA that complements the strengths of existing VA\nprocess models and frameworks. It systematically characterizes diverse roles of\nhumans, data, and models, and how these actors benefit from and contribute to\nVA processes. The descriptive power of the HDMI Canvas eases the\ndifferentiation between a series of VA building blocks, rather than describing\ngeneral VA principles only. The canvas includes modern human-centered\nmethodologies, including human knowledge externalization and forms of feedback\nloops, while interpretable and explainable AI highlight model contributions\nbeyond their conventional outputs. The HDMI Canvas has generative power,\nguiding the design of new VA processes and is optimized for external\nstakeholders, improving VA outreach, interdisciplinary collaboration, and\nuser-centered design. The utility of the HDMI Canvas is demonstrated through\ntwo preliminary case studies.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.LG","published":"2025-05-12T13:15:31Z"}
{"aid":"http://arxiv.org/abs/2505.07537v1","title":"The Exploratory Multi-Asset Mean-Variance Portfolio Selection using\n  Reinforcement Learning","summary":"In this paper, we study the continuous-time multi-asset mean-variance (MV)\nportfolio selection using a reinforcement learning (RL) algorithm, specifically\nthe soft actor-critic (SAC) algorithm, in the time-varying financial market. A\nfamily of Gaussian portfolio selections is derived, and a policy iteration\nprocess is crafted to learn the optimal exploratory portfolio selection. We\nprove the convergence of the policy iteration process theoretically, based on\nwhich the SAC algorithm is developed. To improve the algorithm's stability and\nthe learning accuracy in the multi-asset scenario, we divide the model\nparameters that influence the optimal portfolio selection into three parts, and\nlearn each part progressively. Numerical studies in the simulated and real\nfinancial markets confirm the superior performance of the proposed SAC\nalgorithm under various criteria.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-05-12T13:18:49Z"}
{"aid":"http://arxiv.org/abs/2505.07543v1","title":"Overcoming Intrinsic Dispersion Locking for Achieving Spatio-Spectral\n  Selectivity with Misaligned Bi-metagratings","summary":"Spatio-spectral selectivity, the capability to select a single mode with a\nspecific wavevector (angle) and wavelength, is imperative for light emission\nand imaging. Continuous band dispersion of a conventional periodic structure,\nhowever, sets up an intrinsic locking between wavevectors and wavelengths of\nphotonic modes, making it difficult to single out just one mode. Here, we show\nthat the radiation asymmetry of a photonic mode can be explored to tailor the\ntransmission/reflection properties of a photonic structure, based on Fano\ninterferences between the mode and the background. In particular, we find that\na photonic system supporting a band dispersion with certain angle-dependent\nradiation-directionality can exhibit Fano-like perfect reflection at a single\nfrequency and a single incident angle, thus overcoming the dispersion locking\nand enabling the desired spatio-spectral selectivity. We present a phase\ndiagram to guide designing angle-controlled radiation-directionality and\nexperimentally demonstrate double narrow Fano-like reflection in angular\n(5{\\deg}) and wavelength (14 nm) bandwidths, along with high-contrast\nspatio-spectral selective imaging, using a misaligned bilayer metagrating with\ntens-of-nanometer-scale thin spacer. Our scheme promises new opportunities in\napplications in directional thermal emission, nonlocal beam shaping, augmented\nreality, precision bilayer nanofabrication, and biological spectroscopy.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-12T13:25:54Z"}
{"aid":"http://arxiv.org/abs/2505.07544v1","title":"Identifying Proca-star mergers via consistent ultralight-boson mass\n  estimates across gravitational-wave events","summary":"While black-hole and neutron-star mergers are the most plausible sources of\ncurrent gravitational-wave observations, mergers of exotic compact objects may\nmimic these signals. Proca stars -- Bose-Einstein condensates of complex vector\nultralight bosons -- have gained significant attention for their potential to\nreplicate certain gravitational-wave events while yielding consistent estimates\nof the boson mass $\\mu_{B}$ forming the stars. Using a mixture model within a\nBayesian framework, we demonstrate that consistent boson-mass estimates across\nevents can yield conclusive evidence for the existence for a number $n$ of\nProca-star families characterized by respective boson masses $\\mu_{B}^{i}$,\neven if no individual event can be conclusively identified as such. Our method\nprovides posterior distributions for $n$ and $\\mu_{B}^{i}$. Applying this\nframework to the high-mass events GW190521, GW190426\\_190642, GW200220\\_061928,\nwe obtain a Bayes Factor ${\\cal{B}}^{n=0}_{n=1} \\simeq 2$ against the\nProca-star hypothesis, primarily rooted in the limitation of current Proca-star\nmerger simulations to intrinsically weak head-on cases. We discuss the use of\npriors that mitigate the impact of these limitations, which yields\n${\\cal{B}}^{n=1}_{n=0} \\simeq 8$ in favour of a single Proca family hypothesis;\nand the inclusion of the gravitational-wave trigger S200114$\\_$020818. Finally,\nwe show that conclusive evidence $\\log{\\cal{B}}^{n=1}_{n=0} \\geq 5$ could be\nachieved after 5 to 9 observations of similar event sets, at the $90\\%$\ncredible level. This method provides a new way to detect exotic compact\nobjects, somewhat using gravitational-wave detectors as particle detectors.","main_category":"gr-qc","categories":"gr-qc","published":"2025-05-12T13:26:04Z"}
{"aid":"http://arxiv.org/abs/2505.07549v1","title":"Exponential Relative Entropy Decay Along Quantum Markov Semigroups","summary":"We establish the equivalence between exponential decay of the relative\nentropy along a quantum Markov semigroup and the modified logarithmic Sobolev\ninequality for general von Neumann algebras. We also extend an intertwining\ncriterion for the modified logarithmic Sobolev inequality to GNS-symmetric\nquantum Markov semigroups on infinite-dimensional von Neumann algebras.","main_category":"math.OA","categories":"math.OA,math-ph,math.MP,quant-ph","published":"2025-05-12T13:29:34Z"}
{"aid":"http://arxiv.org/abs/2505.07555v1","title":"Energy-Efficient Resource Allocation for NOMA-Assisted Uplink\n  Pinching-Antenna Systems","summary":"The pinching-antenna architecture has emerged as a promising solution for\nreconfiguring wireless propagation environments and enhancing system\nperformance. While prior research has primarily focused on sum-rate\nmaximization or transmit power minimization of pinching-antenna systems, the\ncritical aspect of energy efficiency (EE) has received limited attention. Given\nthe increasing importance of EE in future wireless communication networks, this\nwork investigates EE optimization in a non-orthogonal multiple access\n(NOMA)-assisted multi-user pinching-antenna uplink system. The problem entails\nthe joint optimization of the users' transmit power and the pinching-antenna\nposition. The resulting optimization problem is non-convex due to tightly\ncoupled variables. To tackle this, we employ an alternating optimization\nframework to decompose the original problem into two subproblems: one focusing\non power allocation and the other on antenna positioning. A low-complexity\noptimal solution is derived for the power allocation subproblem, while the\npinching-antenna positioning subproblem is addressed using a particle swarm\noptimization algorithm to obtain a high-quality near-optimal solution.\nSimulation results demonstrate that the proposed scheme significantly\noutperforms both conventional-antenna configurations and orthogonal multiple\naccess-based pinching-antenna systems in terms of EE.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-05-12T13:31:55Z"}
{"aid":"http://arxiv.org/abs/2505.07571v1","title":"Oxyfluoride glasses obtained through incorporation of CaF$_2$ into\n  photovoltaic cover glass melts","summary":"The glass industry has limited options to mitigate its environmental\nfootprint, and the demand for cover glass to produce photovoltaic panels is\nincreasing. Currently, the majority of this special type of glass is not being\nrecycled, and in this work, we propose to reuse it as raw material to obtain\noxyfluoride glasses. The incorporation of CaF$_2$ and the increasing\nNa$_2$CO$_3$ content resulted in a melting temperature of about 1200$^o$C,\nsignificantly lower than in soda-lime glasses, which adds up to the\nenvironmental benefits of reusing end-of-life cover glass. The obtained samples\nshow high transparency and thermal stability, allowing the cover glass to make\nup to 80\\% of its weight. XRF analysis was employed to determine the elemental\ncomposition of the samples, while XRD and Raman indicated that by adding\nCaF$_2$, the glass network was depolymerized. In situ XRD as a function of\ntemperature showed the formation of a few crystalline phases in these\noxyfluoride samples, evidencing that it can be explored as a matrix to obtain\ndifferent glass-ceramics. The combination of the glass properties indicates\nthat this method and the resulting material can contribute to reducing the\nenvironmental impact of the glass industry, by creating new glass or\nglass-ceramic materials that can be obtained at a reduced temperature compared\nto the soda-lime glass, while cover glass being the primary raw material could\nreduce the need to extract minerals from nature.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph,physics.chem-ph","published":"2025-05-12T13:52:35Z"}
{"aid":"http://arxiv.org/abs/2505.07584v1","title":"SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark\n  for Large Language Models","summary":"The increasing deployment of large language models in security-sensitive\ndomains necessitates rigorous evaluation of their resilience against\nadversarial prompt-based attacks. While previous benchmarks have focused on\nsecurity evaluations with limited and predefined attack domains, such as\ncybersecurity attacks, they often lack a comprehensive assessment of\nintent-driven adversarial prompts and the consideration of real-life\nscenario-based multi-turn attacks. To address this gap, we present\nSecReEvalBench, the Security Resilience Evaluation Benchmark, which defines\nfour novel metrics: Prompt Attack Resilience Score, Prompt Attack Refusal Logic\nScore, Chain-Based Attack Resilience Score and Chain-Based Attack Rejection\nTime Score. Moreover, SecReEvalBench employs six questioning sequences for\nmodel assessment: one-off attack, successive attack, successive reverse attack,\nalternative attack, sequential ascending attack with escalating threat levels\nand sequential descending attack with diminishing threat levels. In addition,\nwe introduce a dataset customized for the benchmark, which incorporates both\nneutral and malicious prompts, categorised across seven security domains and\nsixteen attack techniques. In applying this benchmark, we systematically\nevaluate five state-of-the-art open-weighted large language models, Llama 3.1,\nGemma 2, Mistral v0.3, DeepSeek-R1 and Qwen 3. Our findings offer critical\ninsights into the strengths and weaknesses of modern large language models in\ndefending against evolving adversarial threats. The SecReEvalBench dataset is\npublicly available at\nhttps://kaggle.com/datasets/5a7ee22cf9dab6c93b55a73f630f6c9b42e936351b0ae98fbae6ddaca7fe248d,\nwhich provides a groundwork for advancing research in large language model\nsecurity.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-12T14:09:24Z"}
{"aid":"http://arxiv.org/abs/2505.07586v1","title":"Primordial Black Holes and Gravitational Waves in Extensions of the\n  Standard Model","summary":"We investigate the phenomenology of a Standard Model extension incorporating\nan inert scalar doublet and a gauged $U(1)_{B-L}$ symmetry. Our analysis\nreveals regions of the parameter space that support strong first-order phase\ntransitions, including cases featuring two successive transitions. Each\ntransition can generate a stochastic gravitational wave background within the\nsensitivity reach of upcoming experiments. Remarkably, the high-scale\ntransition may also produce primordial black holes with appreciable abundance.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-12T14:14:13Z"}
{"aid":"http://arxiv.org/abs/2505.07590v1","title":"Wormholes in Lorentz-violating gravity","summary":"We investigate the possibility of obtaining traversable wormholes supported\nby phantom scalar fields in Lorentz-violating gravity with an antisymmetric\nrank-2 tensor with a non-zero vacuum expectation value non-minimally coupled to\nthe curvature tensor. This Lorentz violation framework shows to be a suitable\nscenario to search for wormhole solutions in the presence of Lorentz violation,\nsince it introduces mild constraints on the areal radius. The vacuum\nexpectation value of the antisymmetric rank-2 tensor, nonetheless, imposes\nconstraints on the lapse function. As a consequence, under the vacuum\nconfiguration adopted, the allowed lapse functions can be either constant,\nlinear or quadratic, depending on the self-interaction potential that drives\nthe spontaneous breaking of the Lorentz symmetry. Thus, we find the\nEllis-Bronnikov counterpart in this Lorentz-violating scenario as well as\nLorentz-violating wormholes with a Rindler-type acceleration and an effective\ncosmological constant. Properties of these wormholes, such as their non-flat\nasymptotics, are investigated.","main_category":"gr-qc","categories":"gr-qc","published":"2025-05-12T14:15:43Z"}
{"aid":"http://arxiv.org/abs/2505.07603v1","title":"AgentFlow: Resilient Adaptive Cloud-Edge Framework for Multi-Agent\n  Coordination","summary":"This paper presents AgentFlow, a MAS-based framework for programmable\ndistributed systems in heterogeneous cloud-edge environments. It introduces\nlogistics objects and abstract agent interfaces to enable dynamic service flows\nand modular orchestration. AgentFlow supports decentralized publish-subscribe\nmessaging and many-to-many service elections, enabling decision coordination\nwithout a central server. It features plug-and-play node discovery, flexible\ntask reorganization, and highly adaptable fault tolerance and substitution\nmechanisms. AgentFlow advances scalable, real-time coordination for resilient\nand autonomous mission-critical systems.","main_category":"cs.DC","categories":"cs.DC","published":"2025-05-12T14:25:11Z"}
{"aid":"http://arxiv.org/abs/2505.07607v1","title":"Multi-Objective Reinforcement Learning for Energy-Efficient Industrial\n  Control","summary":"Industrial automation increasingly demands energy-efficient control\nstrategies to balance performance with environmental and cost constraints. In\nthis work, we present a multi-objective reinforcement learning (MORL) framework\nfor energy-efficient control of the Quanser Aero 2 testbed in its\none-degree-of-freedom configuration. We design a composite reward function that\nsimultaneously penalizes tracking error and electrical power consumption.\nPreliminary experiments explore the influence of varying the Energy penalty\nweight, alpha, on the trade-off between pitch tracking and energy savings. Our\nresults reveal a marked performance shift for alpha values between 0.0 and\n0.25, with non-Pareto optimal solutions emerging at lower alpha values, on both\nthe simulation and the real system. We hypothesize that these effects may be\nattributed to artifacts introduced by the adaptive behavior of the Adam\noptimizer, which could bias the learning process and favor bang-bang control\nstrategies. Future work will focus on automating alpha selection through\nGaussian Process-based Pareto front modeling and transitioning the approach\nfrom simulation to real-world deployment.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-05-12T14:28:42Z"}
{"aid":"http://arxiv.org/abs/2505.07617v1","title":"Second-gradient models for incompressible viscous fluids and associated\n  cylindrical flows","summary":"We introduce second-gradient models for incompressible viscous fluids,\nbuilding on the framework introduced by Fried and Gurtin. We propose a new and\nsimple constitutive relation for the hyperpressure to ensure that the models\nare both physically meaningful and mathematically well-posed. The framework is\nfurther extended to incorporate pressure-dependent viscosities. We show that\nfor the pressure-dependent viscosity model, the inclusion of second-gradient\neffects guarantees the ellipticity of the governing pressure equation, in\ncontrast to previous models rooted in classical continuum mechanics. The\nconstant viscosity model is applied to steady cylindrical flows, where explicit\nsolutions are derived under both strong and weak adherence boundary conditions.\nIn each case, we establish convergence of the velocity profiles to the\nclassical Navier-Stokes solutions as the model's characteristic length scales\ntend to zero.","main_category":"math.AP","categories":"math.AP,cond-mat.mtrl-sci,math-ph,math.MP","published":"2025-05-12T14:41:19Z"}
{"aid":"http://arxiv.org/abs/2505.07627v1","title":"Quantum Monte Carlo study of the bond- and site-diluted transverse-field\n  Ising model","summary":"We study the transverse-field Ising model on a square lattice with bond- and\nsite-dilution at zero temperature by stochastic series expansion quantum Monte\nCarlo simulations. Tuning the transverse field $h$ and the dilution $p$, the\nquantum phase diagram of both models is explored. Both quantum phase diagrams\nshow long-range order for small $h$ and small $p$. The ordered phase of each is\nseparated from the disordered (quantum) Griffiths phase by second-order phase\ntransitions on two critical lines touching at a multi-critical point. Using\nBinder ratios we locate quantum critical points with high accuracy. The\norder-parameter critical exponent $\\beta$ and the average correlation-length\nexponent $\\nu_{\\mathrm{av}}$ are determined along the critical lines and at the\nmulti-critical points for the first time via finite-size scaling. We find three\ninternally consistent sets of critical exponents and compare them with\npotentially connected universality classes. The quantum Griffiths phase in the\nvicinity of the phase transition lines is analyzed through the local\nsusceptibility. Our results indicate that activated scaling occurs not only at\nthe percolation transition, but also at the phase transition line for $p$\nsmaller than the percolation threshold $p_c$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-05-12T14:51:56Z"}
{"aid":"http://arxiv.org/abs/2505.07630v1","title":"On the frequency of small gaps between the primes","summary":"In a recent work Friedlander studied the problem of how large consecutive\nprime gaps should be in order that the sum of the reciprocals should be\ndivergent. Supposing a very deep Hypothesis, a generalization of the\nHardy--Littlewood prime $k$-tuple conjecture, he gave an almost precise answer\nfor it. In the present work we give an unconditional answer for a much weaker\nform of the same problem.","main_category":"math.NT","categories":"math.NT","published":"2025-05-12T14:56:44Z"}
{"aid":"http://arxiv.org/abs/2505.07632v1","title":"o-minimal geometry of higher Albanese manifolds","summary":"Let X be a normal quasi-projective variety over $\\mathbb{C}$. We study its\nhigher Albanese manifolds, introduced by Hain and Zucker, from the point of\nview of o-minimal geometry. We show that for each $s$ the higher Albanese\nmanifold $\\operatorname{Alb}^s(X)$ can be functorially endowed with a structure\nof an $\\mathbb{R}_{\\operatorname{alg}}$-definable complex manifold in such a\nway that the natural projections $\\operatorname{Alb}^s(X) \\to\n\\operatorname{Alb}^{s-1}(X)$ are $\\mathbb{R}_{\\operatorname{alg}}$-definable\nand the higher Albanese maps $\\operatorname{alb}^s \\colon X^{\\operatorname{an}}\n\\to \\operatorname{Alb}^s(X)$ are $\\mathbb{R}_{\\operatorname{an},\n\\operatorname{exp}}$-definable. Suppose that for some $s \\ge 3$ the definable\nmanifold $\\operatorname{Alb}^s(X)$ is definably biholomorphic to a\nquasi-projective variety. We show that in this case the higher Albanese tower\nstabilises at the second step, i.e. the maps $\\operatorname{Alb}^r (X) \\to\n\\operatorname{Alb}^{r-1}(X)$ are isomorphisms for $r\\ge 3$. It follows that if\n$\\operatorname{alb}^s \\colon X^{\\operatorname{an}} \\to \\operatorname{Alb}^s(X)$\nis dominant for some $s \\ge 3$, then the higher Albanese tower stabilises at\nthe second step and the pro-unipotent completion of $\\pi_1(X)$ is at most\n2-step nilpotent. This confirms a special case of a conjecture by Campana on\nnilpotent fundamental groups of algebraic varieties. As another application, we\nprove the existence and quasi-projectivity of unipotent Shafarevich reductions.","main_category":"math.AG","categories":"math.AG,math.CV","published":"2025-05-12T15:01:47Z"}
{"aid":"http://arxiv.org/abs/2505.07635v1","title":"Generating Skyline Explanations for Graph Neural Networks","summary":"This paper proposes a novel approach to generate subgraph explanations for\ngraph neural networks GNNs that simultaneously optimize multiple measures for\nexplainability. Existing GNN explanation methods often compute subgraphs\n(called ``explanatory subgraphs'') that optimize a pre-defined, single\nexplainability measure, such as fidelity or conciseness. This can lead to\nbiased explanations that cannot provide a comprehensive explanation to clarify\nthe output of GNN models. We introduce skyline explanation, a GNN explanation\nparadigm that aims to identify k explanatory subgraphs by simultaneously\noptimizing multiple explainability measures. (1) We formulate skyline\nexplanation generation as a multi-objective optimization problem, and pursue\nexplanations that approximate a skyline set of explanatory subgraphs. We show\nthe hardness for skyline explanation generation. (2) We design efficient\nalgorithms with an onion-peeling approach that strategically removes edges from\nneighbors of nodes of interests, and incrementally improves explanations as it\nexplores an interpretation domain, with provable quality guarantees. (3) We\nfurther develop an algorithm to diversify explanations to provide more\ncomprehensive perspectives. Using real-world graphs, we empirically verify the\neffectiveness, efficiency, and scalability of our algorithms.","main_category":"cs.LG","categories":"cs.LG,cs.DB","published":"2025-05-12T15:05:46Z"}
{"aid":"http://arxiv.org/abs/2505.07636v1","title":"Modal analysis of oblique shock-induced flow dynamics in a supersonic\n  reacting shear layer","summary":"Efficient mixing in high-speed compressible flows, crucial for scramjet\noperation, can be significantly enhanced by shock wave interactions. This study\nemploys Direct Numerical Simulations (DNS) to comprehensively examine the\ninteraction between an oblique shock and a spatially developing turbulent\nmixing layer, contrasting inert and reacting (hydrogen-air combustion) cases.\nUtilizing streaming Dynamic Mode Decomposition (sDMD), we analyze four\nconfigurations: inert and reacting shear layers, both with and without shock\nimpingement (at $\\mathrm{Ma}_c = 0.48$). We evaluate the temporal mode growth\nrates, the evolution of vorticity thickness, and the spatial structures of\ndominant DMD modes to elucidate how shocks and heat release synergistically\ninfluence flow stability, mixing, and the underlying coherent dynamics. Results\nreveal that the oblique shock significantly amplifies Kelvin-Helmholtz\ninstabilities, excites a broader spectrum of unstable temporal modes, and\naccelerates the growth of the vorticity thickness. Combustion-induced heat\nrelease further modifies this response, leading to a redistribution of energy\namong the DMD modes and indicating a complex coupled effect with shock\ndynamics, particularly in the enhanced excitation of high-frequency modes and\nthe alteration of spatial structures. The modal analysis identifies distinct\nfrequency bands associated with shock and combustion effects and characterizes\nthe dominant spatial patterns, offering refined insights for controlling and\nenhancing mixing in high-speed propulsion flows.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-05-12T15:06:29Z"}
{"aid":"http://arxiv.org/abs/2505.07638v1","title":"Identifiability of SDEs for reaction networks","summary":"Biochemical reaction networks are widely applied across scientific\ndisciplines to model complex dynamic systems. We investigate the diffusion\napproximation of reaction networks with mass-action kinetics, focusing on the\nidentifiability of the generator of the associated stochastic differential\nequations. We derive conditions under which the law of the diffusion\napproximation is identifiable and provide theorems for verifying\nidentifiability in practice. Notably, our results show that some reaction\nnetworks have non-identifiable reaction rates, even when the law of the\ncorresponding stochastic process is completely known. Moreover, we show that\nreaction networks with distinct graphical structures can generate the same\ndiffusion law under specific choices of reaction rates. Finally, we compare our\nframework with identifiability results in the deterministic ODE setting and the\ndiscrete continuous-time Markov chain models for reaction networks.","main_category":"math.PR","categories":"math.PR,q-bio.MN","published":"2025-05-12T15:10:25Z"}
{"aid":"http://arxiv.org/abs/2505.07654v1","title":"Breast Cancer Classification in Deep Ultraviolet Fluorescence Images\n  Using a Patch-Level Vision Transformer Framework","summary":"Breast-conserving surgery (BCS) aims to completely remove malignant lesions\nwhile maximizing healthy tissue preservation. Intraoperative margin assessment\nis essential to achieve a balance between thorough cancer resection and tissue\nconservation. A deep ultraviolet fluorescence scanning microscope (DUV-FSM)\nenables rapid acquisition of whole surface images (WSIs) for excised tissue,\nproviding contrast between malignant and normal tissues. However, breast cancer\nclassification with DUV WSIs is challenged by high resolutions and complex\nhistopathological features. This study introduces a DUV WSI classification\nframework using a patch-level vision transformer (ViT) model, capturing local\nand global features. Grad-CAM++ saliency weighting highlights relevant spatial\nregions, enhances result interpretability, and improves diagnostic accuracy for\nbenign and malignant tissue classification. A comprehensive 5-fold\ncross-validation demonstrates the proposed approach significantly outperforms\nconventional deep learning methods, achieving a classification accuracy of\n98.33%.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-12T15:22:54Z"}
{"aid":"http://arxiv.org/abs/2505.07683v1","title":"Multimodal Survival Modeling in the Age of Foundation Models","summary":"The Cancer Genome Atlas (TCGA) has enabled novel discoveries and served as a\nlarge-scale reference through its harmonized genomics, clinical, and image\ndata. Prior studies have trained bespoke cancer survival prediction models from\nunimodal or multimodal TCGA data. A modern paradigm in biomedical deep learning\nis the development of foundation models (FMs) to derive meaningful feature\nembeddings, agnostic to a specific modeling task. Biomedical text especially\nhas seen growing development of FMs. While TCGA contains free-text data as\npathology reports, these have been historically underutilized. Here, we\ninvestigate the feasibility of training classical, multimodal survival models\nover zero-shot embeddings extracted by FMs. We show the ease and additive\neffect of multimodal fusion, outperforming unimodal models. We demonstrate the\nbenefit of including pathology report text and rigorously evaluate the effect\nof model-based text summarization and hallucination. Overall, we modernize\nsurvival modeling by leveraging FMs and information extraction from pathology\nreports.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-12T15:47:21Z"}
{"aid":"http://arxiv.org/abs/2505.07684v1","title":"Short- and long-term variations of the high mass accretion rate\n  classical T Tauri star DR Tau","summary":"Classical T Tauri stars are newly formed, low mass stars which may display\nboth periodic and random variations in their brightness. The interaction\nbetween the star and its circumstellar disk is time-dependent, leading to short\nor long-term changes in the environment, and hence variability of the system.\nBy compiling a large dataset with high-cadence photometric (Kepler, TESS), and\nhigh-resolution spectroscopic observations (CFHT/ESPaDOnS) of the highly\nvariable T Tauri star DR Tau, we aim to examine the short- and long-term\nvariability of the system, and identify the underlying physical mechanisms. Our\nresults reveal that DR Tau exhibits stochastic photometric variability not only\non daily, but also on hourly timescale with peak-to-peak amplitude of 1.4 mag\nprobably originating from accretion related variations. Our ground-based\nmultifilter photometry shows that the amplitude of the variability decreases\nwith increasing wavelength. This trend towards the infrared wavelengths\nsuggests that part of the disk may be optically thick and invariable. The\nspectroscopic analysis showed that the H$\\alpha$ line presents the most complex\nline profile with several components but the significance of the components\nchanges over time. This suggests the presence and variation of both accretion\nflow and wind. Broad and narrow components can be clearly distinguished in the\nHe I and the Ca II lines, suggesting contribution from both the accretion flow\nand the post-shock region. DR Tau exhibits high level of photometric and\nspectroscopic variability on both short- and long-timescales, which is caused\nby the combination of accretion, wind, stellar activity, and obscuration by\ncircumstellar matter; and the significance of the physical mechanisms causing\nthe observed variability changes over time.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-05-12T15:48:08Z"}
{"aid":"http://arxiv.org/abs/2505.07696v1","title":"Design Principles for Realizable Discrete Surface Embeddings in Physical\n  Systems","summary":"The isometric embedding of surfaces in three-dimensional space is fundamental\nto various physical systems, from elastic sheets to programmable materials.\nWhile continuous surfaces typically admit unique solutions under suitable\nboundary conditions, their discrete counterparts-represented as networks of\nvertices connected by edges-can exhibit multiple distinct embeddings for\nidentical edge lengths. We present a systematic approach to constructing\ndiscrete meshes that yield a controlled number of embeddings. By analyzing the\nrelationship between mesh connectivity and embedding multiplicity through\nrigidity theory, we develop criteria for designing meshes that minimize\nsolution multiplicity. We demonstrate computational methods based on local\nmatrix operations and trilateration techniques, enabling practical\nimplementation for meshes with approximately a thousand vertices. Our analysis\nprovides both theoretical bounds on the number of possible embeddings based on\nB\\'ezout's theorem and practical guidelines for mesh construction in physical\napplications. Through numerical simulations, we show that this approach\nachieves comparable accuracy to traditional minimization methods while offering\ncomputational advantages through sequential computation. Importantly, we\ndemonstrate that in cases where a unique smooth solution exists, local\nfluctuations in reconstructed shapes derived from the computational grid can\nserve as indicators of insufficient geometric constraints. This work bridges\nthe gap between discrete and continuous embedding problems, providing insights\nfor applications in 4D printing, mechanical meta-materials, and deployable\nstructures.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,physics.comp-ph","published":"2025-05-12T16:05:17Z"}
{"aid":"http://arxiv.org/abs/2505.07700v1","title":"PatchTrack: A Comprehensive Analysis of ChatGPT's Influence on Pull\n  Request Outcomes","summary":"The rapid adoption of large language models (LLMs) like ChatGPT in software\ndevelopment has introduced new ways for developers to interact with AI,\nparticularly in pull request workflows. While prior research has examined\nAI-generated code quality, there is limited understanding of how ChatGPT is\nutilized in real-world pull request decision-making and how its suggestions\ninfluence patch integration and rejection. To explore these aspects, we analyze\nself-admitted ChatGPT usage (SACU), where developers explicitly disclose their\nreliance on ChatGPT within pull request discussions. Our study examines 338\npull requests (285 merged, 53 closed) across 255 GitHub repositories,\ncontaining 645 ChatGPT-generated code snippets and 3,486 patches. We introduce\nPatchTrack, a classification tool that determines whether ChatGPT-generated\npatches were applied (PA, 115 cases), not applied (PN, 64 cases), or not\nsuggested (NE, 106 cases). Our findings reveal that full adoption of\nChatGPT-generated code is rare, developers frequently modify or selectively\nintegrate AI-generated patches to align with project constraints, with a median\nintegration rate of 25%. Through qualitative analysis, we identify key factors\ninfluencing patch integration and pull request rejection, including scope\nmisalignment, maintainability concerns, redundant solutions, and procedural\nbarriers such as incomplete documentation or administrative policies. By\nproviding empirical insights into ChatGPT's role in pull request workflows,\nthis study informs developers, maintainers, and educators on the evolving use\nof generative AI in collaborative software development. It also lays the\ngroundwork for future research on optimizing AI-assisted development, improving\ntransparency in AI adoption, and enhancing patch integration workflows.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-12T16:09:33Z"}
{"aid":"http://arxiv.org/abs/2505.07708v1","title":"Superdirective Mixed-Multipole-based Unidirectional Spherical Dielectric\n  Lens Antennas","summary":"Studies of superdirective dielectric lens antennas are reported emphasizing\nunidirectional properties. The developed antennas are based on the higher-order\ntransverse electric and magnetic modes present in a multilayered sphere\nrealized with high permittivity dielectrics. The superdirective properties of\nthe lenses are empowered by exciting them with a basic unidirectional\nmixed-multipole antenna. Genetic algorithm (GA) optimization was employed to\nidentify configurations that yielded both large directivity and front-to-back\nratio outcomes. The analytical evaluations of several example systems of\nspheres having different outer radii and numbers of layers are described. Their\nradiated field patterns are presented along with comparisons with known\ndirectivity bounds to confirm their superdirective performance characteristics.\nSubsequent numerical assessments with commercial full-wave finite element\nsimulations of more realistic versions of several selected examples illustrate\ntheir potential for experimental realization.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-05-12T16:15:40Z"}
{"aid":"http://arxiv.org/abs/2505.07723v1","title":"The observable impact of runaway OB stars on protoplanetary discs","summary":"UV radiation from OB stars can drive ``external'' photoevaporative winds from\ndiscs in clusters, that have been shown to be important for disc evolution and\nplanet formation. However, cluster dynamics can complicate the interpretation\nof this process. A significant fraction of OB stars are runaways, propagating\nat high velocity which might dominate over the wider cluster dynamics in\nsetting the time variation of the UV field in part of the cluster. We explore\nthe impact of a runaway OB star on discs and the observational impact that may\nhave. We find that discs exposed to even short periods of strong irradiation\nare significantly truncated, and only rebound slightly following the ``flyby''\nof the UV source. This is predicted to leave an observable imprint on a disc\npopulation, with those downstream of the OB star vector being more massive and\nextended than those upstream. Because external photoevaporation acts quickly,\nthis imprint is less susceptible to being washed out by cluster dynamics for\nfaster runaway OB stars. The Gaia proper motion vector of the B star 42 Ori in\nNGC 1977 is transverse to the low mass stellar population and so may make a\ngood region to search for this signature in resolved disc observations.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-05-12T16:32:45Z"}
{"aid":"http://arxiv.org/abs/2505.07724v1","title":"Securing WiFi Fingerprint-based Indoor Localization Systems from\n  Malicious Access Points","summary":"WiFi fingerprint-based indoor localization schemes deliver highly accurate\nlocation data by matching the received signal strength indicator (RSSI) with an\noffline database using machine learning (ML) or deep learning (DL) models.\nHowever, over time, RSSI values degrade due to the malicious behavior of access\npoints (APs), causing low positional accuracy due to RSSI value mismatch with\nthe offline database. Existing literature lacks detection of malicious APs in\nthe online phase and mitigating their effects. This research addresses these\nlimitations and proposes a long-term reliable indoor localization scheme by\nincorporating malicious AP detection and their effect mitigation techniques.\nThe proposed scheme uses a Light Gradient-Boosting Machine (LGBM) classifier to\nestimate locations and integrates simple yet efficient techniques to detect\nmalicious APs based on online query data. Subsequently, a mitigation technique\nis incorporated that updates the offline database and online queries by\nimputing stable values for malicious APs using LGBM Regressors. Additionally,\nwe introduce a noise addition mechanism in the offline database to capture the\ndynamic environmental effects. Extensive experimental evaluation shows that the\nproposed scheme attains a detection accuracy above 95% for each attack type.\nThe mitigation strategy effectively restores the system's performance nearly to\nits original state when no malicious AP is present. The noise addition module\nreduces localization errors by nearly 16%. Furthermore, the proposed solution\nis lightweight, reducing the execution time by approximately 94% compared to\nthe existing methods.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-12T16:32:46Z"}
{"aid":"http://arxiv.org/abs/2505.07727v1","title":"Odd clique minors in graphs with independence number two","summary":"A $K_t$-expansion consists of $t$ vertex-disjoint trees, every two of which\nare joined by an edge. We call such an expansion odd if its vertices can be\ntwo-colored so that the edges of the trees are bichromatic but the edges\nbetween trees are monochromatic. A graph contains an odd $K_t$ minor or an odd\nclique minor of order $t$ if it contains an odd $K_t$-expansion. Gerards and\nSeymour from 1995 conjectured that every graph $G$ contains an odd\n$K_{\\chi(G)}$ minor, where $\\chi(G)$ denotes the chromatic number of $G$. This\nconjecture is referred to as ``Odd Hadwiger's Conjecture\". Let $\\alpha(G)$\ndenote the independence number of a graph $G$. In this paper we investigate the\nOdd Hadwiger's Conjecture for graphs $G$ with $\\alpha(G)\\le2$. We first observe\nthat a graph $G$ on $n$ vertices with $\\alpha(G)\\le2$ contains an odd\n$K_{\\chi(G)}$ minor if and only if $G$ contains an odd clique minor of order\n$\\lceil n/2\\rceil$. We then prove that every graph $G$ on $n$ vertices with\n$\\alpha(G)\\le 2$ contains an odd clique minor of order $\\lceil n/2\\rceil$ if\n$G$ contains a clique of order $n/4$ when $n$ is even and $(n+3)/4$ when $n$ is\nodd, or $G$ does not contain $H$ as an induced subgraph, where $\\alpha(H)\\le 2$\nand $H$ is an induced subgraph of $K_1 + P_4$, $K_2+(K_1\\cup K_3)$,\n$K_1+(K_1\\cup K_4)$, $K_7^-$, $K_7$, or the kite graph.","main_category":"math.CO","categories":"math.CO","published":"2025-05-12T16:35:23Z"}
{"aid":"http://arxiv.org/abs/2505.07729v1","title":"Nonparametric Instrumental Variable Inference with Many Weak Instruments","summary":"We study inference on linear functionals in the nonparametric instrumental\nvariable (NPIV) problem with a discretely-valued instrument under a\nmany-weak-instruments asymptotic regime, where the number of instrument values\ngrows with the sample size. A key motivating example is estimating long-term\ncausal effects in a new experiment with only short-term outcomes, using past\nexperiments to instrument for the effect of short- on long-term outcomes. Here,\nthe assignment to a past experiment serves as the instrument: we have many past\nexperiments but only a limited number of units in each. Since the structural\nfunction is nonparametric but constrained by only finitely many moment\nrestrictions, point identification typically fails. To address this, we\nconsider linear functionals of the minimum-norm solution to the moment\nrestrictions, which is always well-defined. As the number of instrument levels\ngrows, these functionals define an approximating sequence to a target\nfunctional, replacing point identification with a weaker asymptotic notion\nsuited to discrete instruments. Extending the Jackknife Instrumental Variable\nEstimator (JIVE) beyond the classical parametric setting, we propose npJIVE, a\nnonparametric estimator for solutions to linear inverse problems with many weak\ninstruments. We construct automatic debiased machine learning estimators for\nlinear functionals of both the structural function and its minimum-norm\nprojection, and establish their efficiency in the many-weak-instruments regime.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.ML,stat.TH","published":"2025-05-12T16:36:55Z"}
{"aid":"http://arxiv.org/abs/2505.07737v1","title":"Edge-on galaxies relative to edge-on view of the Local Supercluster","summary":"Cosmological theories suggest that the angular momentum of galaxies should be\nclosely linked to the structure of the cosmic web. The Local Supercluster is\nthe closest and most studied structure where the orientation of galaxy spins\ncan be studied. As noted by Navarro et al. (2004), the use of edge-on galaxies\ngreatly simplifies this task by reducing it to an analysis of the distribution\nof position angles in the Supergalactic coordinates. We reexamine this\ncorrelation using modern catalogs that allow us to perform a more robust\nstatistical analysis. We test the dependence on redshift, spatial position,\nluminosity, and color. We find that the spins of galaxies with stellar mass\n$M_*<10^{8.7}$ $M_\\odot$ show a weak tendency to be aligned perpendicular to\nthe plane of the Local Supercluster at the 2-sigma level. Other subsamples do\nnot show statistically significant correlations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-12T16:46:15Z"}
{"aid":"http://arxiv.org/abs/2505.07749v1","title":"Emission Line Diagnostics for IMBHs in Dwarf Galaxies: Accounting for BH\n  Seeding and ULX Excitation","summary":"Dwarf AGN serve as the ideal systems for identifying intermediate mass black\nholes (IMBHs) down to the most elusive regimes ($\\sim 10^3 - 10^4 M_{\\odot}$).\nHowever, the ubiquitously metal-poor nature of dwarf galaxies gives rise to\nultraluminous X-ray sources (ULXs) that can mimic the spectral signatures of\nIMBH excitation. We present a novel photoionization model suite that\nsimultaneously incorporates IMBHs and ULXs in a metal-poor, highly star-forming\nenvironment. We account for changes in $M_{BH}$ according to formation seeding\nchannels and metallicity, and changes in ULX populations with post-starburst\nage and metallicity. We find that broadband X-rays and UV emission lines are\ninsensitive to $M_{BH}$ and largely unable to distinguish between ULXs and\nIMBHs. Many optical diagnostic diagrams cannot correctly identify dwarf AGN.\nThe notable exceptions include He~II~$\\lambda$4686 and [O~I]~$\\lambda$6300, for\nwhich we redefine typical demarcations to account for ULX contributions.\nEmission lines in the mid-IR show the most promise in separating stellar, ULX,\nIMBH, and shock excitation while presenting sensitivity to $M_{BH}$ and\n$f_{\\text{AGN}}$. Overall, our results expose the potential biases in\nidentifying and characterizing dwarf AGN purely on strong line ratios and\ndiagnostic diagrams rather than holistically evaluating the entire spectrum. As\na proof of concept, we argue that recently discovered over-massive BHs in\nhigh-$z$ JWST AGN might not represent the overall BH population, with many\ngalaxies in these samples potentially being falsely classified as purely\nstar-forming.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-12T16:57:07Z"}
{"aid":"http://arxiv.org/abs/2505.07751v1","title":"Naturalistic Metaphysics and the Parity Thesis: Why Scientific Realism\n  Doesn't Lead to Realism about Metaphysics","summary":"In recent work, Nina Emery has defended the view that, in the context of\nnaturalistic metaphysics, one should maintain the same epistemic attitude\ntowards science and metaphysics. That is, naturalists who are scientific\nrealists ought to be realists about metaphysics as well; and naturalists who\nare antirealists about science should also be antirealists about metaphysics.\nWe call this the `parity thesis'. This paper suggests that the parity thesis is\nwidely, albeit often implicitly, accepted among naturalistically inclined\nphilosophers, and essentially for reasons similar to Emery's. Then, reasons are\nprovided for resisting Emery's specific inference from scientific realism to\nrealism about metaphysics. The resulting picture is a more nuanced view of the\nrelationship between science and metaphysics within the naturalistic setting\nthan the one which is currently most popular.","main_category":"physics.hist-ph","categories":"physics.hist-ph,quant-ph","published":"2025-05-12T16:58:08Z"}
{"aid":"http://arxiv.org/abs/2505.07761v1","title":"Singular Control in Inventory Management with Smooth Ambiguity","summary":"We consider singular control in inventory management under Knightian\nuncertainty, where decision makers have a smooth ambiguity preference over\nGaussian-generated priors. We demonstrate that continuous-time smooth ambiguity\nis the infinitesimal limit of Kalman-Bucy filtering with recursive robust\nutility. Additionally, we prove that the cost function can be determined by\nsolving forward-backward stochastic differential equations with quadratic\ngrowth. With a sufficient condition and utilising variational inequalities in a\nviscosity sense, we derive the value function and optimal control policy. By\nthe change-of-coordinate technique, we transform the problem into\ntwo-dimensional singular control, offering insights into model learning and\naligning with classical singular control free boundary problems. We numerically\nimplement our theory using a Markov chain approximation, where inventory is\nmodeled as cash management following an arithmetic Brownian motion. Our\nnumerical results indicate that the continuation region can be divided into\nthree key areas: (i) the target region; (ii) the region where it is optimal to\nlearn and do nothing; and (iii) the region where control becomes predominant\nand learning should inactive. We demonstrate that ambiguity drives the decision\nmaker to act earlier, leading to a smaller continuation region. This effect\nbecomes more pronounced at the target region as the decision maker gains\nconfidence from a longer learning period. However, these dynamics do not extend\nto the third region, where learning is excluded.","main_category":"math.OC","categories":"math.OC,math.PR,q-fin.RM","published":"2025-05-12T17:07:50Z"}
{"aid":"http://arxiv.org/abs/2505.07763v1","title":"Gravitationally Bound Gas Determines Star Formation in the Galaxy","summary":"Stars form from molecular gas under complex conditions influenced by multiple\ncompeting physical mechanisms, such as gravity, turbulence, and magnetic\nfields. However, accurately identifying the fraction of gas actively involved\nin star formation remains challenging. Using dust continuum observations from\nthe Herschel Space Observatory, we derived column density maps and their\nassociated probability distribution functions (N-PDFs). Assuming the power-law\ncomponent in the N-PDFs corresponds to gravitationally bound (and thus\nstar-forming) gas, we analyzed a diverse sample of molecular clouds spanning a\nwide range of mass and turbulence conditions. This sample included 21 molecular\nclouds from the solar neighborhood ($d<$500 pc) and 16 high-mass star-forming\nmolecular clouds. For these two groups, we employed the counts of young stellar\nobjects (YSOs) and mid-/far-infrared luminosities as proxies for star formation\nrates (SFR), respectively. Both groups revealed a tight linear correlation\nbetween the mass of gravitationally bound gas and the SFR, suggesting a\nuniversally constant star formation efficiency in the gravitationally bound gas\nphase. The star-forming gas mass derived from threshold column densities\n($N_{{\\mbox {threshold}}}$) varies from cloud to cloud and is widely\ndistributed over the range of $\\sim$1--17$\\times$10$^{21}$ cm$^{-2}$ based on\nN-PDF analysis. But in solar neighborhood clouds, it is in rough consistency\nwith the traditional approach using $A_{\\rm V}$ $\\ge$ 8 mag. In contrast, in\nhigh turbulent regions (e.g., the Central Molecular Zone) where the classical\napproach fails, the gravitationally bound gas mass and SFR still follow the\nsame correlation as other high-mass star-forming regions in the Milky Way. Our\nfindings also strongly support the interpretation that gas in the power-law\ncomponent of the N-PDF is undergoing self-gravitational collapse to form stars.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-12T17:10:22Z"}
{"aid":"http://arxiv.org/abs/2505.07771v1","title":"Ion energy distributions from the impact of an atmospheric dielectric\n  barrier discharge plasma jet on surfaces","summary":"The ion energy distribution functions (IEDF) have been measured for a helium\natmospheric pressure dielectric barrier discharge jet expanding into the air\nand impacting a metal or ceramic surface. The plasma jet produces ionization\nwaves as guided positive streamers that reach the surface. Molecular beam mass\nspectrometry (MBMS) with an energy filter has been used to monitor the IEDFs at\na distance of 1.5 cm from the dielectric barrier discharge plasma jet exit. The\nspecies are sampled from the supersonic expanding helium beam passing into the\nMBMS through a 40 $\\mu$m (metal) or a 50 $\\mu$m (ceramic) diameter orifice.\nN$_2^+$, O$_2^+$, NO$^+$, O$_3^+$ and water cluster ions (H$_2$O)$_n$H$^+$\n(n=1...4) are abundantly produced in the discharge. The analysis of the\ntime-resolved IEDFs reveals that all ions are predominantly sampled at a\nreference energy $E_{\\rm beam}$ when using the metallic orifice. This energy\n$E_{\\rm beam}$ is determined by the seeding of the ions into the supersonic\nexpanding helium beam into the MBMS. After the impact of the streamer, an\nafterglow of 10 $\\mu$s is observed when ions are continuously sampled at an\nenergy higher than $E_{\\rm beam}$ by a few 0.1 eVs. This is resolved by\npostulating a positive space-charge region in front of a positively charged\nsurface. The temporal sequence of the ion impact is consistent with reaction\nschemes in air plasmas, where O$_2^+$ and N$_2^+$ are created before the\nformation of NO and O$_3$, as well as larger water cluster ions.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-05-12T17:21:53Z"}
{"aid":"http://arxiv.org/abs/2505.07782v1","title":"MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine\n  Learning Engineering","summary":"We introduce MLE-Dojo, a Gym-style framework for systematically reinforcement\nlearning, evaluating, and improving autonomous large language model (LLM)\nagents in iterative machine learning engineering (MLE) workflows. Unlike\nexisting benchmarks that primarily rely on static datasets or single-attempt\nevaluations, MLE-Dojo provides an interactive environment enabling agents to\niteratively experiment, debug, and refine solutions through structured feedback\nloops. Built upon 200+ real-world Kaggle challenges, MLE-Dojo covers diverse,\nopen-ended MLE tasks carefully curated to reflect realistic engineering\nscenarios such as data processing, architecture search, hyperparameter tuning,\nand code debugging. Its fully executable environment supports comprehensive\nagent training via both supervised fine-tuning and reinforcement learning,\nfacilitating iterative experimentation, realistic data sampling, and real-time\noutcome verification. Extensive evaluations of eight frontier LLMs reveal that\nwhile current models achieve meaningful iterative improvements, they still\nexhibit significant limitations in autonomously generating long-horizon\nsolutions and efficiently resolving complex errors. Furthermore, MLE-Dojo's\nflexible and extensible architecture seamlessly integrates diverse data\nsources, tools, and evaluation protocols, uniquely enabling model-based agent\ntuning and promoting interoperability, scalability, and reproducibility. We\nopen-source our framework and benchmarks to foster community-driven innovation\ntowards next-generation MLE agents.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-12T17:35:43Z"}
{"aid":"http://arxiv.org/abs/2505.07793v1","title":"Overflow Prevention Enhances Long-Context Recurrent LLMs","summary":"A recent trend in LLMs is developing recurrent sub-quadratic models that\nimprove long-context processing efficiency. We investigate leading large\nlong-context models, focusing on how their fixed-size recurrent memory affects\ntheir performance. Our experiments reveal that, even when these models are\ntrained for extended contexts, their use of long contexts remains\nunderutilized. Specifically, we demonstrate that a chunk-based inference\nprocedure, which identifies and processes only the most relevant portion of the\ninput can mitigate recurrent memory failures and be effective for many\nlong-context tasks: On LongBench, our method improves the overall performance\nof Falcon3-Mamba-Inst-7B by 14%, Falcon-Mamba-Inst-7B by 28%,\nRecurrentGemma-IT-9B by 50%, and RWKV6-Finch-7B by 51%. Surprisingly, this\nsimple approach also leads to state-of-the-art results in the challenging\nLongBench v2 benchmark, showing competitive performance with equivalent size\nTransformers. Furthermore, our findings raise questions about whether recurrent\nmodels genuinely exploit long-range dependencies, as our single-chunk strategy\ndelivers stronger performance - even in tasks that presumably require\ncross-context relations.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-12T17:45:05Z"}
{"aid":"http://arxiv.org/abs/2505.07798v1","title":"PT symmetry and the square well potential: Antilinear symmetry rather\n  than Hermiticity in scattering processes","summary":"While a Hamiltonian with a real potential acts as a Hermitian operator when\nit operates on bound states, it produces resonances with complex energies in a\nscattering experiment. The scattering states are not square integrable, being\ninstead delta function normalized. This lack of square integrability breaks the\nconnection between Hermiticity and real eigenvalues, to thus allow for real\nbound state sector eigenvalues and complex scattering sector eigenvalues. When\nwritten as contour integrals delta functions take support in the complex plane,\nwith the scattering amplitude being able to take support in the complex energy\nplane too. However, the scattering amplitude is $CPT$ symmetric (or $PT$\nsymmetric if $C$ is conserved), regardless of whether states are square\nintegrable or not. For resonance scattering this antilinear symmetry requires\nthe presence of a complex conjugate pair of energies, one to describe the\nexcitation of the resonance and the other to describe its decay, with it being\ntheir interplay that enforces probability conservation. Each complex pair of\nenergy eigenvalues corresponds to only one observable resonance not two. Our\nanalysis shows that the nonrelativistic square well problem with a real\npotential possesses $PT$ symmetry in both the bound and scattering sectors,\nwith there being complex conjugate pairs of energy eigenvalues in the\nscattering sector.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-12T17:48:56Z"}
{"aid":"http://arxiv.org/abs/2505.07802v1","title":"Improving Trajectory Stitching with Flow Models","summary":"Generative models have shown great promise as trajectory planners, given\ntheir affinity to modeling complex distributions and guidable inference\nprocess. Previous works have successfully applied these in the context of\nrobotic manipulation but perform poorly when the required solution does not\nexist as a complete trajectory within the training set. We identify that this\nis a result of being unable to plan via stitching, and subsequently address the\narchitectural and dataset choices needed to remedy this. On top of this, we\npropose a novel addition to the training and inference procedures to both\nstabilize and enhance these capabilities. We demonstrate the efficacy of our\napproach by generating plans with out of distribution boundary conditions and\nperforming obstacle avoidance on the Franka Panda in simulation and on real\nhardware. In both of these tasks our method performs significantly better than\nthe baselines and is able to avoid obstacles up to four times as large.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-05-12T17:50:10Z"}
{"aid":"http://arxiv.org/abs/2505.07805v1","title":"Classical symmetry enriched topological orders and distinct monopole\n  charges for dipole-octupole spin ices","summary":"Distinct symmetry enriched topological orders often do not have classical\ndistinctions. Motivated by the recent process on the pyrochlore spin ice\nmaterials based on the dipole-octupole doublets, we argue that dipolar spin\nliquid and octupolar spin liquid can be well differentiated through the\nmagnetic charges of the magnetic monopoles in the classical spin ice regime. It\nis observed and predicted that, the long-range dipole-dipole interaction\nrenders the magnetic monopole of the dipolar spin ice a finite magnetic charge\nvia the dumbbell picture even in the classical regime. For the octupolar spin\nice, however, a zero magnetic charge is expected from this mechanism in the\nclassical regime. We expect this smoking-gun observation to resolve the debate\non the nature of Ce$_2$Sn$_2$O$_7$, and more broadly, this work may inspire\nfurther experiments and thoughts on the Ce-pyrochlore spin liquids,\nNd-pyrochlore antiferromagnets, Er-based spinels, and the distinct properties\nof the emergent quasiparticles in various symmetry enriched topological phases.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-05-12T17:54:04Z"}
{"aid":"http://arxiv.org/abs/2505.07813v1","title":"DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies","summary":"Large-scale, diverse robot datasets have emerged as a promising path toward\nenabling dexterous manipulation policies to generalize to novel environments,\nbut acquiring such datasets presents many challenges. While teleoperation\nprovides high-fidelity datasets, its high cost limits its scalability. Instead,\nwhat if people could use their own hands, just as they do in everyday life, to\ncollect data? In DexWild, a diverse team of data collectors uses their hands to\ncollect hours of interactions across a multitude of environments and objects.\nTo record this data, we create DexWild-System, a low-cost, mobile, and\neasy-to-use device. The DexWild learning framework co-trains on both human and\nrobot demonstrations, leading to improved performance compared to training on\neach dataset individually. This combination results in robust robot policies\ncapable of generalizing to novel environments, tasks, and embodiments with\nminimal additional robot-specific data. Experimental results demonstrate that\nDexWild significantly improves performance, achieving a 68.5% success rate in\nunseen environments-nearly four times higher than policies trained with robot\ndata only-and offering 5.8x better cross-embodiment generalization. Video\nresults, codebases, and instructions at https://dexwild.github.io","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV,cs.LG,cs.SY,eess.SY","published":"2025-05-12T17:59:05Z"}
{"aid":"http://arxiv.org/abs/2505.07819v1","title":"H$^{\\mathbf{3}}$DP: Triply-Hierarchical Diffusion Policy for Visuomotor\n  Learning","summary":"Visuomotor policy learning has witnessed substantial progress in robotic\nmanipulation, with recent approaches predominantly relying on generative models\nto model the action distribution. However, these methods often overlook the\ncritical coupling between visual perception and action prediction. In this\nwork, we introduce $\\textbf{Triply-Hierarchical Diffusion\nPolicy}~(\\textbf{H$^{\\mathbf{3}}$DP})$, a novel visuomotor learning framework\nthat explicitly incorporates hierarchical structures to strengthen the\nintegration between visual features and action generation. H$^{3}$DP contains\n$\\mathbf{3}$ levels of hierarchy: (1) depth-aware input layering that organizes\nRGB-D observations based on depth information; (2) multi-scale visual\nrepresentations that encode semantic features at varying levels of granularity;\nand (3) a hierarchically conditioned diffusion process that aligns the\ngeneration of coarse-to-fine actions with corresponding visual features.\nExtensive experiments demonstrate that H$^{3}$DP yields a $\\mathbf{+27.5\\%}$\naverage relative improvement over baselines across $\\mathbf{44}$ simulation\ntasks and achieves superior performance in $\\mathbf{4}$ challenging bimanual\nreal-world manipulation tasks. Project Page: https://lyy-iiis.github.io/h3dp/.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-05-12T17:59:43Z"}
{"aid":"http://arxiv.org/abs/2505.08205v1","title":"Hidden quantum-classical correspondence in chaotic billiards revealed by\n  mutual information","summary":"Avoided level crossings, commonly associated with quantum chaos, are\ntypically interpreted as signatures of eigenstate hybridization and spatial\ndelocalization, often viewed as ergodic spreading. We show that, contrary to\nthis expectation, increasing chaos in quantum billiards enhances mutual\ninformation between conjugate phase space variables, revealing nontrivial\ncorrelations. Using an information-theoretic decomposition of eigenstate\nentropy, we demonstrate that spatial delocalization may coincide with increased\nmutual information between position and momentum. These correlations track\nclassical invariant structures in phase space and persist beyond the\nsemiclassical regime, suggesting a robust information-theoretic manifestation\nof quantum-classical correspondence.","main_category":"nlin.CD","categories":"nlin.CD,physics.optics,quant-ph","published":"2025-05-13T03:37:29Z"}
{"aid":"http://arxiv.org/abs/2505.08213v1","title":"HandCept: A Visual-Inertial Fusion Framework for Accurate Proprioception\n  in Dexterous Hands","summary":"As robotics progresses toward general manipulation, dexterous hands are\nbecoming increasingly critical. However, proprioception in dexterous hands\nremains a bottleneck due to limitations in volume and generality. In this work,\nwe present HandCept, a novel visual-inertial proprioception framework designed\nto overcome the challenges of traditional joint angle estimation methods.\nHandCept addresses the difficulty of achieving accurate and robust joint angle\nestimation in dynamic environments where both visual and inertial measurements\nare prone to noise and drift. It leverages a zero-shot learning approach using\na wrist-mounted RGB-D camera and 9-axis IMUs, fused in real time via a\nlatency-free Extended Kalman Filter (EKF). Our results show that HandCept\nachieves joint angle estimation errors between $2^{\\circ}$ and $4^{\\circ}$\nwithout observable drift, outperforming visual-only and inertial-only methods.\nFurthermore, we validate the stability and uniformity of the IMU system,\ndemonstrating that a common base frame across IMUs simplifies system\ncalibration. To support sim-to-real transfer, we also open-sourced our\nhigh-fidelity rendering pipeline, which is essential for training without\nreal-world ground truth. This work offers a robust, generalizable solution for\nproprioception in dexterous hands, with significant implications for robotic\nmanipulation and human-robot interaction.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-13T04:06:35Z"}
{"aid":"http://arxiv.org/abs/2505.08219v1","title":"Lie Group Symmetry Discovery and Enforcement Using Vector Fields","summary":"Symmetry-informed machine learning can exhibit advantages over machine\nlearning which fails to account for symmetry. Additionally, recent attention\nhas been given to continuous symmetry discovery using vector fields which serve\nas infinitesimal generators for Lie group symmetries. In this paper, we extend\nthe notion of non-affine symmetry discovery to functions defined by neural\nnetworks. We further extend work in this area by introducing symmetry\nenforcement of smooth models using vector fields. Finally, we extend work on\nsymmetry discovery using vector fields by providing both theoretical and\nexperimental material on the restriction of the symmetry search space to\ninfinitesimal isometries.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-05-13T04:24:46Z"}
{"aid":"http://arxiv.org/abs/2505.08221v1","title":"Performance Analysis of Cooperative Integrated Sensing and\n  Communications for 6G Networks","summary":"In this work, we aim to effectively characterize the performance of\ncooperative integrated sensing and communication (ISAC) networks and to reveal\nhow performance metrics relate to network parameters. To this end, we introduce\na generalized stochastic geometry framework to model the cooperative ISAC\nnetworks, which approximates the spatial randomness of the network deployment.\nBased on this framework, we derive analytical expressions for key performance\nmetrics in both communication and sensing domains, with a particular focus on\ncommunication coverage probability and radar information rate. The analytical\nexpressions derived explicitly highlight how performance metrics depend on\nnetwork parameters, thereby offering valuable insights into the deployment and\ndesign of cooperative ISAC networks. In the end, we validate the theoretical\nperformance analysis through Monte Carlo simulation results. Our results\ndemonstrate that increasing the number of cooperative base stations (BSs)\nsignificantly improves both metrics, while increasing the BS deployment density\nhas a limited impact on communication coverage probability but substantially\nenhances the radar information rate. Additionally, increasing the number of\ntransmit antennas is effective when the total number of transmit antennas is\nrelatively small. The incremental performance gain reduces with the increase of\nthe number of transmit antennas, suggesting that indiscriminately increasing\nantennas is not an efficient strategy to improve the performance of the system\nin cooperative ISAC networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-13T04:37:56Z"}
{"aid":"http://arxiv.org/abs/2505.08228v1","title":"Object detection in adverse weather conditions for autonomous vehicles\n  using Instruct Pix2Pix","summary":"Enhancing the robustness of object detection systems under adverse weather\nconditions is crucial for the advancement of autonomous driving technology.\nThis study presents a novel approach leveraging the diffusion model Instruct\nPix2Pix to develop prompting methodologies that generate realistic datasets\nwith weather-based augmentations aiming to mitigate the impact of adverse\nweather on the perception capabilities of state-of-the-art object detection\nmodels, including Faster R-CNN and YOLOv10. Experiments were conducted in two\nenvironments, in the CARLA simulator where an initial evaluation of the\nproposed data augmentation was provided, and then on the real-world image data\nsets BDD100K and ACDC demonstrating the effectiveness of the approach in real\nenvironments.\n  The key contributions of this work are twofold: (1) identifying and\nquantifying the performance gap in object detection models under challenging\nweather conditions, and (2) demonstrating how tailored data augmentation\nstrategies can significantly enhance the robustness of these models. This\nresearch establishes a solid foundation for improving the reliability of\nperception systems in demanding environmental scenarios, and provides a pathway\nfor future advancements in autonomous driving.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-13T05:12:07Z"}
{"aid":"http://arxiv.org/abs/2505.08232v1","title":"Experimental demonstration of kinetic proofreading inherited in\n  ligation-based information replication","summary":"We experimentally demonstrate that information replication by templated\nligation of DNA strands inherits a kinetic proofreading mechanism and achieves\nsignificant error suppression through cascade replication. A simple simulation\nmodel derived from the experimental results shows that templated ligation has a\nsignificant advantage over replication by polymerization for error suppression\nof long strands. This mechanism provides a plausible route for high-fidelity\nreplication in prebiotic chemistry and illustrates how physical principles such\nas nonequilibrium kinetics and network architecture can drive reliable\nmolecular information replication. The approach also offers new strategies for\nerror suppression in biotechnology.","main_category":"physics.bio-ph","categories":"physics.bio-ph,cond-mat.stat-mech","published":"2025-05-13T05:18:24Z"}
{"aid":"http://arxiv.org/abs/2505.08240v1","title":"N$^2$LoS: Single-Tag mmWave Backscatter for Robust Non-Line-of-Sight\n  Localization","summary":"The accuracy of traditional localization methods significantly degrades when\nthe direct path between the wireless transmitter and the target is blocked or\nnon-penetrable. This paper proposes N2LoS, a novel approach for precise\nnon-line-of-sight (NLoS) localization using a single mmWave radar and a\nbackscatter tag. N2LoS leverages multipath reflections from both the tag and\nsurrounding reflectors to accurately estimate the targets position. N2LoS\nintroduces several key innovations. First, we design HFD (Hybrid\nFrequency-Hopping and Direct Sequence Spread Spectrum) to detect and\ndifferentiate reflectors from the target. Second, we enhance signal-to-noise\nratio (SNR) by exploiting the correlation properties of the designed signals,\nimproving detection robustness in complex environments. Third, we propose\nFS-MUSIC (Frequency-Spatial Multiple Signal Classification), a super resolution\nalgorithm that extends the traditional MUSIC method by constructing a\nhigher-rank signal matrix, enabling the resolution of additional multipath\ncomponents. We evaluate N2LoS using a 24 GHz mmWave radar with 250 MHz\nbandwidth in three diverse environments: a laboratory, an office, and an\naround-the-corner corridor. Experimental results demonstrate that N2LoS\nachieves median localization errors of 10.69 cm (X) and 11.98 cm (Y) at a 5 m\nrange in the laboratory setting, showcasing its effectiveness for real-world\nNLoS localization.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-13T05:32:30Z"}
{"aid":"http://arxiv.org/abs/2505.08244v1","title":"The Failure of Plagiarism Detection in Competitive Programming","summary":"Plagiarism in programming courses remains a persistent challenge, especially\nin competitive programming contexts where assignments often have unique, known\nsolutions. This paper examines why traditional code plagiarism detection\nmethods frequently fail in these environments and explores the implications of\nemerging factors such as generative AI (genAI). Drawing on the author's\nexperience teaching a Competitive Programming 1 (CP1) course over seven\nsemesters at Purdue University (with $\\approx 100$ students each term) and\ncompletely redesigning the CP1/2/3 course sequence, we provide an academically\ngrounded analysis. We review literature on code plagiarism in computer science\neducation, survey current detection tools (Moss, Kattis, etc.) and methods\n(manual review, code-authorship interviews), and analyze their strengths and\nlimitations. Experience-based observations are presented to illustrate\nreal-world detection failures and successes. We find that widely-used automated\nsimilarity checkers can be thwarted by simple code transformations or novel\nAI-generated code, while human-centric approaches like oral interviews, though\neffective, are labor-intensive. The paper concludes with opinions and\npreliminary recommendations for improving academic integrity in programming\ncourses, advocating for a multi-faceted approach that combines improved\ndetection algorithms, mastery-based learning techniques, and authentic\nassessment practices to better ensure code originality.","main_category":"cs.CY","categories":"cs.CY,cs.SE","published":"2025-05-13T05:43:49Z"}
{"aid":"http://arxiv.org/abs/2505.08245v1","title":"Large Language Model Psychometrics: A Systematic Review of Evaluation,\n  Validation, and Enhancement","summary":"The rapid advancement of large language models (LLMs) has outpaced\ntraditional evaluation methodologies. It presents novel challenges, such as\nmeasuring human-like psychological constructs, navigating beyond static and\ntask-specific benchmarks, and establishing human-centered evaluation. These\nchallenges intersect with Psychometrics, the science of quantifying the\nintangible aspects of human psychology, such as personality, values, and\nintelligence. This survey introduces and synthesizes an emerging\ninterdisciplinary field of LLM Psychometrics, which leverages psychometric\ninstruments, theories, and principles to evaluate, understand, and enhance\nLLMs. We systematically explore the role of Psychometrics in shaping\nbenchmarking principles, broadening evaluation scopes, refining methodologies,\nvalidating results, and advancing LLM capabilities. This paper integrates\ndiverse perspectives to provide a structured framework for researchers across\ndisciplines, enabling a more comprehensive understanding of this nascent field.\nUltimately, we aim to provide actionable insights for developing future\nevaluation paradigms that align with human-level AI and promote the advancement\nof human-centered AI systems for societal benefit. A curated repository of LLM\npsychometric resources is available at\nhttps://github.com/valuebyte-ai/Awesome-LLM-Psychometrics.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.HC","published":"2025-05-13T05:47:51Z"}
{"aid":"http://arxiv.org/abs/2505.08248v1","title":"Ground-based Observations of Temporal Variation of Cosmic Ray Spectrum\n  during Forbush Decreases","summary":"Observations of temporary Forbush decreases (FDs) in the Galactic cosmic ray\n(GCR) flux due to passage of solar storms are useful for space weather studies\nand alerts. Here we introduce techniques that use global networks of\nground-based neutron monitors and muon detectors to measure variations of GCR\nrigidity spectra in space during FDs by: A) fitting count rate decreases for\npower-law rigidity spectra in space with anisotropy up to second order, and B)\nusing the \"leader fraction\" derived from a single neutron monitor. We\ndemonstrate that both provide consistent results for hourly spectral index\nvariations for five major FDs and they agree with daily space-based data when\navailable from AMS-02. We have also made the neutron monitor leader fraction\npublicly available in real time. This work verifies that ground-based\nobservations can be used to precisely monitor GCR spectral variation over a\nwide range of rigidities during space weather events, with results in real time\nor from short-term post-analysis.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-13T05:57:16Z"}
{"aid":"http://arxiv.org/abs/2505.08260v1","title":"Few-shot Novel Category Discovery","summary":"The recently proposed Novel Category Discovery (NCD) adapt paradigm of\ntransductive learning hinders its application in more real-world scenarios. In\nfact, few labeled data in part of new categories can well alleviate this\nburden, which coincides with the ease that people can label few of new category\ndata. Therefore, this paper presents a new setting in which a trained agent is\nable to flexibly switch between the tasks of identifying examples of known\n(labelled) classes and clustering novel (completely unlabeled) classes as the\nnumber of query examples increases by leveraging knowledge learned from only a\nfew (handful) support examples. Drawing inspiration from the discovery of novel\ncategories using prior-based clustering algorithms, we introduce a novel\nframework that further relaxes its assumptions to the real-world open set level\nby unifying the concept of model adaptability in few-shot learning. We refer to\nthis setting as Few-Shot Novel Category Discovery (FSNCD) and propose\nSemi-supervised Hierarchical Clustering (SHC) and Uncertainty-aware K-means\nClustering (UKC) to examine the model's reasoning capabilities. Extensive\nexperiments and detailed analysis on five commonly used datasets demonstrate\nthat our methods can achieve leading performance levels across different task\nsettings and scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T06:18:03Z"}
{"aid":"http://arxiv.org/abs/2505.08271v1","title":"The Evolutionary Map of the Universe: A new radio atlas for the southern\n  hemisphere sky","summary":"We present the Evolutionary Map of the Universe (EMU) survey conducted with\nthe Australian Square Kilometre Array Pathfinder (ASKAP). EMU aims to deliver\nthe touchstone radio atlas of the southern hemisphere. We introduce EMU and\nreview its science drivers and key science goals, updated and tailored to the\ncurrent ASKAP five-year survey plan. The development of the survey strategy and\nplanned sky coverage is presented, along with the operational aspects of the\nsurvey and associated data analysis, together with a selection of diagnostics\ndemonstrating the imaging quality and data characteristics. We give a general\ndescription of the value-added data pipeline and data products before\nconcluding with a discussion of links to other surveys and projects and an\noutline of EMU's legacy value.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-13T06:36:07Z"}
{"aid":"http://arxiv.org/abs/2505.08276v1","title":"Quantum Time Crystal Clock and its Performance","summary":"Understanding different aspects of time is at the core of many areas in\ntheoretical physics. Minimal models of continuous stochastic and quantum clocks\nhave been proposed to explore fundamental limitations on the performance of\ntimekeeping devices. Owing to the level of complexity in the clock structure\nand its energy consumption, such devices show trade-offs whose characterization\nremains an open challenge. Indeed, even conceptual designs for\nthermodynamically efficient quantum clocks are not yet well understood. In\ncondensed matter theory, time-crystals were found as an exciting new phase of\nmatter, featuring oscillations in (pseudo)-equilibrium with first experimental\nobservations appearing recently. This naturally prompts the question:\n\\textit{can time crystals be used as quantum clocks and what is their\nperformance from a thermodynamic perspective?} We answer this question and find\nthat quantum crystals are indeed genuine quantum clocks with a performance\nenhanced by the spontaneous breaking of time-translation symmetry.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other,cond-mat.stat-mech","published":"2025-05-13T06:41:08Z"}
{"aid":"http://arxiv.org/abs/2505.08283v1","title":"Decoupled Multimodal Prototypes for Visual Recognition with Missing\n  Modalities","summary":"Multimodal learning enhances deep learning models by enabling them to\nperceive and understand information from multiple data modalities, such as\nvisual and textual inputs. However, most existing approaches assume the\navailability of all modalities, an assumption that often fails in real-world\napplications. Recent works have introduced learnable missing-case-aware prompts\nto mitigate performance degradation caused by missing modalities while reducing\nthe need for extensive model fine-tuning. Building upon the effectiveness of\nmissing-case-aware handling for missing modalities, we propose a novel\ndecoupled prototype-based output head, which leverages missing-case-aware\nclass-wise prototypes tailored for each individual modality. This approach\ndynamically adapts to different missing modality scenarios and can be\nseamlessly integrated with existing prompt-based methods. Extensive experiments\ndemonstrate that our proposed output head significantly improves performance\nacross a wide range of missing-modality scenarios and varying missing rates.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-05-13T06:53:37Z"}
{"aid":"http://arxiv.org/abs/2505.08286v1","title":"Observational tests for a class of scalar-tensor gravity","summary":"We study observational bounds in a class of scalar-tensor gravity theories\nrecently proposed. Either an upper or lower bound on a conformal factor in\nthese theories is derived from null observation in composition dependent fifth\nforce search, microscope mission. The important case of a lower bound implies\nthat future improved observations have chances of verifying this class of\ntheories. Future prospect for a particular type of observation is mentioned.\nThe considered class of scalar-tensor gravity was shown elsewhere to explain\nthe conversion of inflationary early phase to late time quintessence type dark\nenergy.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-05-13T07:00:14Z"}
{"aid":"http://arxiv.org/abs/2505.08290v1","title":"Controllable creation of topological boundary states in\n  topological-insulator-based Josephson corner junctions","summary":"Majorana zero modes (MZMs) in condensed matter systems have attracted great\nattention in the past two decades, due to their interesting physics and\npotential application in topological quantum computing (TQC). However, the\ntopologically protected nature of MZMs still need more experimental\nverifications. In this study, we have realized controllable creation of a\ntopological boundary state at the corner of topological insulator (TI)-based\nJosephson corner junctions. This state demonstrates protected existence across\na broad region in parametric space, and exhibits a non-2{\\pi}-period but\n4{\\pi}-period-compatible energy-phase relation. Our study suggests that\nTI-based Josephson junctions, as proposed in the Fu-Kane scheme of TQC, may\nprovide a promising platform for hosting and braiding MZMs.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-05-13T07:07:24Z"}
{"aid":"http://arxiv.org/abs/2505.08291v1","title":"Multireference error mitigation for quantum computation of chemistry","summary":"Quantum error mitigation (QEM) strategies are essential for improving the\nprecision and reliability of quantum chemistry algorithms on noisy\nintermediate-scale quantum devices. Reference-state error mitigation (REM) is a\ncost-effective chemistry-inspired QEM method that performs exceptionally well\nfor weakly correlated problems. However, the effectiveness of REM is often\nlimited when applied to strongly correlated systems. Here, we introduce\nmultireference-state error mitigation (MREM), an extension of REM that\nsystematically captures quantum hardware noise in strongly correlated ground\nstates by utilizing multireference states. A pivotal aspect of MREM is using\nGivens rotations to efficiently construct quantum circuits to generate\nmultireference states. To strike a balance between circuit expressivity and\nnoise sensitivity, we employ compact wavefunctions composed a few dominant\nSlater determinants. These truncated multireference states, engineered to\nexhibit substantial overlap with the target ground state, can effectively\nenhance error mitigation in variational quantum eigensolver experiments. We\ndemonstrate the effectiveness of MREM through comprehensive simulations of\nmolecular systems $\\mathrm{H_2O, ~N_2, ~and ~F_2}$, underscoring its ability to\nrealize significant improvements in computational accuracy compared to the\noriginal REM method. MREM broadens the scope of error mitigation to encompass a\nwider variety of molecular systems, including those exhibiting pronounced\nelectron correlation.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el,physics.chem-ph,physics.comp-ph","published":"2025-05-13T07:11:42Z"}
{"aid":"http://arxiv.org/abs/2505.08305v1","title":"SiameseLSRTM: Enhancing least-squares reverse time migration with a\n  Siamese network","summary":"Least-squares reverse time migration (LSRTM) is an inversion-based imaging\nmethod rooted in optimization theory, which iteratively updates the\nreflectivity model to minimize the difference between observed and simulated\ndata. However, in real data applications, the Born-based simulated data, based\non simplified physics, like the acoustic assumption, often under represent the\ncomplexity within observed data. Thus, we develop SiameseLSRTM, a novel\napproach that employs a Siamese network consisting of two identical\nconvolutional neural networks (CNNs) with shared weights to measure the\ndifference between simulated and observed data. Specifically, the shared-weight\nCNNs in the Siamese network enable the extraction of comparable features from\nboth observed and simulated data, facilitating more effective data matching and\nultimately improving imaging accuracy. SiameseLSRTM is a self-supervised\nframework in which the network parameters are updated during the iterative\nLSRTM process, without requiring extensive labeled data and prolonged training.\nWe evaluate SiameseLSRTM using two synthetic datasets and one field dataset\nfrom a land seismic survey, showing that it produces higher-resolution and more\naccurate imaging results compared to traditional LSRTM.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-05-13T07:32:01Z"}
{"aid":"http://arxiv.org/abs/2505.08308v1","title":"Uniform Universal Sets, Splitters, and Bisectors","summary":"Given a subset of size $k$ of a very large universe a randomized way to find\nthis subset could consist of deleting half of the universe and then searching\nthe remaining part. With a probability of $2^{-k}$ one will succeed. By\nprobability amplification, a randomized algorithm needs about $2^k$ rounds\nuntil it succeeds. We construct bisectors that derandomize this process and\nhave size~$2^{k+o(k)}$. One application is derandomization of reductions\nbetween average case complexity classes. We also construct uniform\n$(n,k)$-universal sets that generalize universal sets in such a way that they\nare bisectors at the same time. This construction needs only linear time and\nproduces families of asymptotically optimal size without using advanced\ncombinatorial constructions as subroutines, which previous families did, but\nare basedmainly on modulo functions and refined brute force search.","main_category":"cs.DS","categories":"cs.DS,cs.IT,math.IT","published":"2025-05-13T07:35:07Z"}
{"aid":"http://arxiv.org/abs/2505.08310v1","title":"Estimating the spins of supermassive black holes in distant\n  ultraluminous quasars","summary":"We estimated spin, inclination angle and corresponding SMBH mass values for\nsample of extremely distant (6 < z < 7.5) ultraluminous quasars. The estimated\nspin values are on average greater that 0.9 and the spin distribution has a\ncharacteristic appearance, similar to ones obtained for other types of AGNs and\nquasars. The dependence of estimated parameters on each other shows strong\ncorrelations between them, from which we can assume that in this early quasars\nthe growth of SMBHs mass should occur mainly due to disk accretion with high\naccretion rate, which very effectively increases the spin.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-13T07:37:06Z"}
{"aid":"http://arxiv.org/abs/2505.08322v1","title":"Black hole interiors in the thermal view of scalar-tensor gravity","summary":"The thermal view of scalar-tensor gravity is an analogy with a dissipative\nfluid. The scalar degree of freedom excites gravity to a positive\n``temperature'', while Einstein gravity is the ``zero-temperature'' equilibrium\nstate. We extend this thermal analogy to the interior region near the\nsingularity of spherical, vacuum, uncharged black holes by using the\nuniversality of the Kasner behaviour near spacelike singularities. The\nsingularity is ``hot'', meaning that gravity diverges from general relativity.\nThe discussion is then extended to black holes in the presence of perfect or\nimperfect fluids with constant equation of state -- the latter determines\nwhether Einstein gravity is approached or not.","main_category":"gr-qc","categories":"gr-qc","published":"2025-05-13T08:00:39Z"}
{"aid":"http://arxiv.org/abs/2505.08333v1","title":"Sustainability of cities under declining population and decreasing\n  distance frictions: The case of Japan","summary":"This study develops a statistical model that integrates economic\nagglomeration theory and power-law distributions of city sizes to project\nfuture population distribution on 1-km grid cells. We focus on Japan -- a\ncountry at the forefront of rapid population decline. Drawing on official\npopulation projections and empirical patterns from past urban evolution in\nresponse to the development of high-speed rail and highway networks, we examine\nhow ongoing demographic contraction and expected reductions in distance\nfrictions may reshape urban geography. Our analysis suggests that urban\neconomies will consolidate around fewer and larger cities, each of which will\nexperience a flattening of population density as the decentralization of urban\npopulations accelerates, while rural areas are expected to experience further\ndepopulation as a result of these spatial and economic shifts. By identifying\nsustainable urban cores capable of anchoring regional economies, our model\nprovides a framework for policymakers to manage population decline while\nmaintaining resilience through optimized infrastructure and resource allocation\nfocused on these key urban centers.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-05-13T08:23:04Z"}
{"aid":"http://arxiv.org/abs/2505.08341v1","title":"Benchmarking AI scientists in omics data-driven biological research","summary":"The rise of large language models and multi-agent systems has sparked growing\ninterest in AI scientists capable of autonomous biological research. However,\nexisting benchmarks either focus on reasoning without data or on data analysis\nwith predefined statistical answers, lacking realistic, data-driven evaluation\nsettings. Here, we introduce the Biological AI Scientist Benchmark (BaisBench),\na benchmark designed to assess AI scientists' ability to generate biological\ndiscoveries through data analysis and reasoning with external knowledge.\nBaisBench comprises two tasks: cell type annotation on 31 expert-labeled\nsingle-cell datasets, and scientific discovery through answering 198\nmultiple-choice questions derived from the biological insights of 41 recent\nsingle-cell studies. Systematic experiments on state-of-the-art AI scientists\nand LLM agents showed that while promising, current models still substantially\nunderperform human experts on both tasks. We hope BaisBench will fill this gap\nand serve as a foundation for advancing and evaluating AI models for scientific\ndiscovery. The benchmark can be found at: https://github.com/EperLuo/BaisBench.","main_category":"cs.AI","categories":"cs.AI,cs.MA,q-bio.GN","published":"2025-05-13T08:33:54Z"}
{"aid":"http://arxiv.org/abs/2505.08348v1","title":"On the Geometry of Semantics in Next-token Prediction","summary":"Modern language models demonstrate a remarkable ability to capture linguistic\nmeaning despite being trained solely through next-token prediction (NTP). We\ninvestigate how this conceptually simple training objective leads models to\nextract and encode latent semantic and grammatical concepts. Our analysis\nreveals that NTP optimization implicitly guides models to encode concepts via\nsingular value decomposition (SVD) factors of a centered data-sparsity matrix\nthat captures next-word co-occurrence patterns. While the model never\nexplicitly constructs this matrix, learned word and context embeddings\neffectively factor it to capture linguistic structure. We find that the most\nimportant SVD factors are learned first during training, motivating the use of\nspectral clustering of embeddings to identify human-interpretable semantics,\nincluding both classical k-means and a new orthant-based method directly\nmotivated by our interpretation of concepts. Overall, our work bridges\ndistributional semantics, neural collapse geometry, and neural network training\ndynamics, providing insights into how NTP's implicit biases shape the emergence\nof meaning representations in language models.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-13T08:46:04Z"}
{"aid":"http://arxiv.org/abs/2505.08389v1","title":"Towards Contamination Resistant Benchmarks","summary":"The rapid development of large language models (LLMs) has transformed the\nlandscape of natural language processing. Evaluating LLMs properly is crucial\nfor understanding their potential and addressing concerns such as safety.\nHowever, LLM evaluation is confronted by various factors, among which\ncontamination stands out as a key issue that undermines the reliability of\nevaluations. In this work, we introduce the concept of contamination resistance\nto address this challenge. We propose a benchmark based on Caesar ciphers\n(e.g., \"ab\" to \"bc\" when the shift is 1), which, despite its simplicity, is an\nexcellent example of a contamination resistant benchmark. We test this\nbenchmark on widely used LLMs under various settings, and we find that these\nmodels struggle with this benchmark when contamination is controlled. Our\nfindings reveal issues in current LLMs and raise important questions regarding\ntheir true capabilities. Our work contributes to the development of\ncontamination resistant benchmarks, enabling more rigorous LLM evaluation and\noffering insights into the true capabilities and limitations of LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-13T09:35:40Z"}
{"aid":"http://arxiv.org/abs/2505.08400v1","title":"A Fourier finite volume approach for the optical inverse problem of\n  quantitative photoacoustic tomography","summary":"A new approach for solving the optical inverse problem of quantitative\nphotoacoustic tomography is introduced, which interpolates between the\nwell-known diffusion approximation and a radiative transfer equation based\nmodel. The proposed formulation combines a spatial finite volume scheme with a\ntruncated Fourier expansion in the direction variable for the radiative\ntransfer equation. The finite volume scheme provides a natural and simple\napproach for representing piecewise constant image data modelled using\ntransport equations. The truncated Fourier expansion in the direction variable\nfacilitates the interpolation between the diffusion approximation at low order,\nand the full radiative transfer model as the truncation limit\n$N\\rightarrow\\infty$. It is therefore possible to tune the precision of the\nmodel to the demands of the imaging application, taking $N=1$ for cases when\nthe diffusion approximation would suffice and increasing the number of terms\notherwise. We will then utilise the non-linear optimisation functionality of\nMatlab to address the corresponding large-scale nonlinear inverse problem using\ngradient based quasi-Newton minimisation via the limited memory\nBroyden-Fletcher-Goldfarb-Shanno algorithm. Numerical experiments for two\ntest-cases of increasing complexity and resolution will be presented, and the\neffect of logarithmically rescaling the problem data on the accuracy of the\nreconstructed solutions will be investigated. We will focus on cases where the\ndiffusion approximation is not sufficient to demonstrate that our approach can\nprovide significant accuracy gains with only a modest increase in the number of\nFourier terms included.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cs.NA,math.NA,physics.med-ph","published":"2025-05-13T09:55:39Z"}
{"aid":"http://arxiv.org/abs/2505.08404v1","title":"Explaining Autonomous Vehicles with Intention-aware Policy Graphs","summary":"The potential to improve road safety, reduce human driving error, and promote\nenvironmental sustainability have enabled the field of autonomous driving to\nprogress rapidly over recent decades. The performance of autonomous vehicles\nhas significantly improved thanks to advancements in Artificial Intelligence,\nparticularly Deep Learning. Nevertheless, the opacity of their decision-making,\nrooted in the use of accurate yet complex AI models, has created barriers to\ntheir societal trust and regulatory acceptance, raising the need for\nexplainability. We propose a post-hoc, model-agnostic solution to provide\nteleological explanations for the behaviour of an autonomous vehicle in urban\nenvironments. Building on Intention-aware Policy Graphs, our approach enables\nthe extraction of interpretable and reliable explanations of vehicle behaviour\nin the nuScenes dataset from global and local perspectives. We demonstrate the\npotential of these explanations to assess whether the vehicle operates within\nacceptable legal boundaries and to identify possible vulnerabilities in\nautonomous driving datasets and models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-13T09:58:32Z"}
{"aid":"http://arxiv.org/abs/2505.08411v1","title":"Lost in Transliteration: Bridging the Script Gap in Neural IR","summary":"Most human languages use scripts other than the Latin alphabet. Search users\nin these languages often formulate their information needs in a transliterated\n-- usually Latinized -- form for ease of typing. For example, Greek speakers\nmight use Greeklish, and Arabic speakers might use Arabizi. This paper shows\nthat current search systems, including those that use multilingual dense\nembeddings such as BGE-M3, do not generalise to this setting, and their\nperformance rapidly deteriorates when exposed to transliterated queries. This\ncreates a ``script gap\" between the performance of the same queries when\nwritten in their native or transliterated form. We explore whether adapting the\npopular ``translate-train\" paradigm to transliterations can enhance the\nrobustness of multilingual Information Retrieval (IR) methods and bridge the\ngap between native and transliterated scripts. By exploring various\ncombinations of non-Latin and Latinized query text for training, we investigate\nwhether we can enhance the capacity of existing neural retrieval techniques and\nenable them to apply to this important setting. We show that by further\nfine-tuning IR models on an even mixture of native and Latinized text, they can\nperform this cross-script matching at nearly the same performance as when the\nquery was formulated in the native script. Out-of-domain evaluation and further\nqualitative analysis show that transliterations can also cause queries to lose\nsome of their nuances, motivating further research in this direction.","main_category":"cs.IR","categories":"cs.IR","published":"2025-05-13T10:09:51Z"}
{"aid":"http://arxiv.org/abs/2505.08417v1","title":"ORACLE-Grasp: Zero-Shot Task-Oriented Robotic Grasping using Large\n  Multimodal Models","summary":"Grasping unknown objects in unstructured environments remains a fundamental\nchallenge in robotics, requiring both semantic understanding and spatial\nreasoning. Existing methods often rely on dense training datasets or explicit\ngeometric modeling, limiting their scalability to real-world tasks. Recent\nadvances in Large Multimodal Models (LMMs) offer new possibilities for\nintegrating vision and language understanding, but their application to\nautonomous robotic grasping remains largely unexplored. We present\nORACLE-Grasp, a zero-shot framework that leverages LMMs as semantic oracles to\nguide grasp selection without requiring additional training or human input. The\nsystem formulates grasp prediction as a structured, iterative decision process,\nusing dual-prompt tool calling to first extract high-level object context and\nthen select task-relevant grasp regions. By discretizing the image space and\nreasoning over candidate areas, ORACLE-Grasp mitigates the spatial imprecision\ncommon in LMMs and produces human-like, task-driven grasp suggestions. Early\nstopping and depth-based refinement steps further enhance efficiency and\nphysical grasp reliability. Experiments demonstrate that the predicted grasps\nachieve low positional and orientation errors relative to human-annotated\nground truth and lead to high success rates in real-world pick up tasks. These\nresults highlight the potential of combining language-driven reasoning with\nlightweight vision techniques to enable robust, autonomous grasping without\ntask-specific datasets or retraining.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-13T10:19:54Z"}
{"aid":"http://arxiv.org/abs/2505.08430v1","title":"GNCAF: A GNN-based Neighboring Context Aggregation Framework for\n  Tertiary Lymphoid Structures Semantic Segmentation in WSI","summary":"Tertiary lymphoid structures (TLS) are organized clusters of immune cells,\nwhose maturity and area can be quantified in whole slide image (WSI) for\nvarious prognostic tasks. Existing methods for assessing these characteristics\ntypically rely on cell proxy tasks and require additional post-processing\nsteps. In this work, We focus on a novel task-TLS Semantic Segmentation\n(TLS-SS)-which segments both the regions and maturation stages of TLS in WSI in\nan end-to-end manner. Due to the extensive scale of WSI and patch-based\nsegmentation strategies, TLS-SS necessitates integrating from neighboring\npatches to guide target patch (target) segmentation. Previous techniques often\nemploy on multi-resolution approaches, constraining the capacity to leverage\nthe broader neighboring context while tend to preserve coarse-grained\ninformation. To address this, we propose a GNN-based Neighboring Context\nAggregation Framework (GNCAF), which progressively aggregates multi-hop\nneighboring context from the target and employs a self-attention mechanism to\nguide the segmentation of the target. GNCAF can be integrated with various\nsegmentation models to enhance their ability to perceive contextual information\noutside of the patch. We build two TLS-SS datasets, called TCGA-COAD and\nINHOUSE-PAAD, and make the former (comprising 225 WSIs and 5041 TLSs) publicly\navailable. Experiments on these datasets demonstrate the superiority of GNCAF,\nachieving a maximum of 22.08% and 26.57% improvement in mF1 and mIoU,\nrespectively. Additionally, we also validate the task scalability of GNCAF on\nsegmentation of lymph node metastases.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-13T10:47:38Z"}
{"aid":"http://arxiv.org/abs/2505.08441v1","title":"Anisotropic fluctuations of momentum and angular momentum of heavy\n  quarks in the pre-equilibrium stage of pA collisions at the LHC","summary":"We simulate the real-time evolution of the $SU(3)$-glasma generated in the\nearly stages of high-energy proton-nucleus collisions, employing classical\nlattice gauge theory techniques. Our setup incorporates a realistic modeling of\nthe proton's internal structure and includes longitudinal fluctuations in the\ninitial state, enabling the study of genuinely non-boost-invariant collision\ndynamics. Focusing on the momentum and angular momentum anisotropies of heavy\nquarks in the infinite mass limit, we find that the system retains significant\nanisotropy well beyond the characteristic timescale $\\tau = 1/Q_s$. This\npersistence of anisotropy is further confirmed in the more realistic,\nnon-boost-invariant scenario, across a range of fluctuation amplitudes. These\nfindings pave the way for future investigations involving dynamical heavy\nquarks and more quantitative initializations of the glasma.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-13T11:07:06Z"}
{"aid":"http://arxiv.org/abs/2505.08453v1","title":"Parameter Estimation using Reinforcement Learning Causal Curiosity:\n  Limits and Challenges","summary":"Causal understanding is important in many disciplines of science and\nengineering, where we seek to understand how different factors in the system\ncausally affect an experiment or situation and pave a pathway towards creating\neffective or optimising existing models. Examples of use cases are autonomous\nexploration and modelling of unknown environments or assessing key variables in\noptimising large complex systems. In this paper, we analyse a Reinforcement\nLearning approach called Causal Curiosity, which aims to estimate as accurately\nand efficiently as possible, without directly measuring them, the value of\nfactors that causally determine the dynamics of a system. Whilst the idea\npresents a pathway forward, measurement accuracy is the foundation of\nmethodology effectiveness. Focusing on the current causal curiosity's robotic\nmanipulator, we present for the first time a measurement accuracy analysis of\nthe future potentials and current limitations of this technique and an analysis\nof its sensitivity and confounding factor disentanglement capability - crucial\nfor causal analysis. As a result of our work, we promote proposals for an\nimproved and efficient design of Causal Curiosity methods to be applied to\nreal-world complex scenarios.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-05-13T11:30:51Z"}
{"aid":"http://arxiv.org/abs/2505.08454v1","title":"Linear instability in planar viscoelastic Taylor-Couette flow with and\n  without explicit polymer diffusion","summary":"Elastic turbulence has been found in computations of planar viscoelastic\nTaylor-Couette flow using the Oldroyd-B model, apparently generated by a linear\ninstability (van Buel et al. Europhys. Lett., 124, 14001, 2018). We demonstrate\nthat no such linear instability exists in the governing equations used unless\nsome diffusion is added to the polymer conformation tensor equation, as might\noccur through a diffusive numerical scheme. With this addition, the polymer\ndiffusive instability (PDI) (Beneitez et al. (Phys. Rev. Fluids, 8, L101901,\n2023)) exists and leads to chaotic flows resembling those found by van Buel et\nal. (2018). We show how finite volume or finite-difference discretisations of\nthe governing equations can naturally introduce diffusive errors near\nboundaries which are sufficient to trigger PDI. This suggests that PDI could\nwell be important in numerical solutions of wall-bounded viscoelastic flows\nmodelled using Oldroyd-B and FENE-P even with no polymer stress diffusion\nexplicitly included.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-05-13T11:31:22Z"}
{"aid":"http://arxiv.org/abs/2505.08456v1","title":"A note on concentration inequalities for the overlapped batch mean\n  variance estimators for Markov chains","summary":"In this paper, we study the concentration properties of quadratic forms\nassociated with Markov chains using the martingale decomposition method\nintroduced by Atchad\\'e and Cattaneo (2014). In particular, we derive\nconcentration inequalities for the overlapped batch mean (OBM) estimators of\nthe asymptotic variance for uniformly geometrically ergodic Markov chains. Our\nmain result provides an explicit control of the $p$-th moment of the difference\nbetween the OBM estimator and the asymptotic variance of the Markov chain with\nexplicit dependence upon $p$ and mixing time of the underlying Markov chain.","main_category":"math.PR","categories":"math.PR,math.ST,stat.ML,stat.TH","published":"2025-05-13T11:36:04Z"}
{"aid":"http://arxiv.org/abs/2505.08462v1","title":"Short and useful quantum proofs for sublogarithmic-space verifiers","summary":"Quantum Merlin-Arthur proof systems are believed to be stronger than both\ntheir classical counterparts and ``stand-alone'' quantum computers when Arthur\nis assumed to operate in $\\Omega(\\log n)$ space. No hint of such an advantage\nover classical computation had emerged from research on smaller space bounds,\nwhich had so far concentrated on constant-space verifiers. We initiate the\nstudy of quantum Merlin-Arthur systems with space bounds in $\\omega(1) \\cap\no(\\log n)$, and exhibit a problem family $\\mathcal{F}$, whose yes-instances\nhave proofs that are verifiable by polynomial-time quantum Turing machines\noperating in this regime. We show that no problem in $\\mathcal{F}$ has proofs\nthat can be verified classically or is solvable by a stand-alone quantum\nmachine in polynomial time if standard complexity assumptions hold. Unlike\nprevious examples of small-space verifiers, our protocols require only\nsubpolynomial-length quantum proofs.","main_category":"cs.CC","categories":"cs.CC","published":"2025-05-13T11:43:20Z"}
{"aid":"http://arxiv.org/abs/2505.08465v1","title":"L-BASS: a project to produce an absolutely calibrated 1.4 GHz sky map, I\n  -- Scientific rationale and system overview","summary":"L-BASS is an instrument designed to produce an absolutely calibrated map of\nthe sky at a wavelength of 21 cm (L-band) with a radiometric accuracy of less\nthan or equal to 0.1 K and with an angular resolution of 23 degrees. The prime\nmotivations are to improve the temperature calibration of higher resolution\nmaps and to investigate the steep spectrum radio background proposed by the\nARCADE 2 team. The instrument consists of a pair of conical horn antennas which\ncan scan independently in elevation; each antenna produces a circularly\npolarized output. The difference in signals from the antennas is measured with\na continuous-comparison receiver connected to a digital spectrometer sampling\nthe signal from 1400 MHz to 1425 MHz within the protected radio astronomy band.\nWe describe the astrophysical motivation for the project, the design\nrequirements and how these will be attained.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO","published":"2025-05-13T11:47:50Z"}
{"aid":"http://arxiv.org/abs/2505.08467v1","title":"The matter with(in) CPL","summary":"We introduce a two-parameter phenomenological extension of the $\\Lambda$CDM\nmodel in which the equation of state parameter of the ``dust'' fluid becomes\ndifferent from zero for redshifts below a transition value $z_t$. Using data\nfrom DESI DR2 BAO, DESY5 Sn~Ia and CMB distance priors ($R,l_A,\\omega_b$) data,\nwe compare our model with the standard CPL parameterization $w_0-w_a$ for\ndynamical dark energy. Using the Deviance Information Criteria (DIC), we find\nthat the two models are essentially indistinguishable ($\\Delta$DIC $<$ 2) and\npreferred over $\\Lambda$CDM with a significance $\\geq 3 \\sigma$. We discuss how\nthis parameterization finds a natural interpretation in the context of\ncosmological backreaction and derive a prediction for the evolution of the\ngrowth factor, discussing its impact on low redshift $f\\sigma_8$ measurements.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-05-13T11:50:01Z"}
{"aid":"http://arxiv.org/abs/2505.08469v1","title":"The Quadrature Gaussian Sum Filter and Smoother for Wiener Systems","summary":"Block-Oriented Nonlinear (BONL) models, particularly Wiener models, are\nwidely used for their computational efficiency and practicality in modeling\nnonlinear behaviors in physical systems. Filtering and smoothing methods for\nWiener systems, such as particle filters and Kalman-based techniques, often\nstruggle with computational feasibility or accuracy. This work addresses these\nchallenges by introducing a novel Gaussian Sum Filter for Wiener system state\nestimation that is built on a Gauss-Legendre quadrature approximation of the\nlikelihood function associated with the output signal. In addition to\nfiltering, a two-filter smoothing strategy is proposed, enabling accurate\ncomputation of smoothed state distributions at single and consecutive time\ninstants. Numerical examples demonstrate the superiority of the proposed method\nin balancing accuracy and computational efficiency compared to traditional\napproaches, highlighting its benefits in control, state estimation and system\nidentification, for Wiener systems.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-13T11:50:14Z"}
{"aid":"http://arxiv.org/abs/2505.08470v1","title":"Origin of the Shell Structure in the Primary Outflow from IRAS\n  15398-3359","summary":"IRAS 15398-3359, a Class 0 protostar in Lupus I star forming region, is\nassociated with three generations of outflows. The primary outflow, i.e., the\nmost recent one, shows internal structure named ``shell structure'' in the near\ninfrared emission map. The shell structure is also seen in the emission lines\nof CO, H$_2$CO, and others species. We find a similar structure in an\nunderexpanded jet produced in aerodynamics and other engineering applications.\nA high pressure gas ejected through a nozzle expands to form a supersonic flow.\nWhen the pressure of the ejected gas becomes lower than that of the ambient\ngas, the jet is compressed to form a shock wave. The shock heated gas expands\nagain to form substructures along the jet. We examine the similarity between\nthe primary outflow of IRAS 15398-3359 and industrial underexpanded jet and the\npossibility that the shell structure of the former is due to repeated expansion\nand compression in the direction perpendicular to the jet propagation.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-05-13T11:51:11Z"}
{"aid":"http://arxiv.org/abs/2505.08479v1","title":"Spectral gap with polynomial rate for random covering surfaces","summary":"In this note we show that the recent work of Magee, Puder and van Handel\n[MPvH25] can be applied to obtain an optimal spectral gap result with\npolynomial error rate for uniformly random covers of closed hyperbolic\nsurfaces. Let $X$ be a closed hyperbolic surface. We show there exists $b,c>0$\nsuch that a uniformly random degree-$n$ cover $X_{n}$ of $X$ has no new\nLaplacian eigenvalues below $\\frac{1}{4}-cn^{-b}$ with probability tending to\n$1$ as $n\\to\\infty$.","main_category":"math.SP","categories":"math.SP,math.DG,math.OA,math.PR","published":"2025-05-13T12:05:04Z"}
{"aid":"http://arxiv.org/abs/2505.08485v1","title":"BAT: Benchmark for Auto-bidding Task","summary":"The optimization of bidding strategies for online advertising slot auctions\npresents a critical challenge across numerous digital marketplaces. A\nsignificant obstacle to the development, evaluation, and refinement of\nreal-time autobidding algorithms is the scarcity of comprehensive datasets and\nstandardized benchmarks.\n  To address this deficiency, we present an auction benchmark encompassing the\ntwo most prevalent auction formats. We implement a series of robust baselines\non a novel dataset, addressing the most salient Real-Time Bidding (RTB) problem\ndomains: budget pacing uniformity and Cost Per Click (CPC) constraint\noptimization. This benchmark provides a user-friendly and intuitive framework\nfor researchers and practitioners to develop and refine innovative autobidding\nalgorithms, thereby facilitating advancements in the field of programmatic\nadvertising. The implementation and additional resources can be accessed at the\nfollowing repository (https://github.com/avito-tech/bat-autobidding-benchmark,\nhttps://doi.org/10.5281/zenodo.14794182).","main_category":"cs.AI","categories":"cs.AI,stat.ML","published":"2025-05-13T12:12:34Z"}
{"aid":"http://arxiv.org/abs/2505.08487v1","title":"An adaptive sampling algorithm for data-generation to build a\n  data-manifold for physical problem surrogate modeling","summary":"Physical models classically involved Partial Differential equations (PDE) and\ndepending of their underlying complexity and the level of accuracy required,\nand known to be computationally expensive to numerically solve them. Thus, an\nidea would be to create a surrogate model relying on data generated by such\nsolver. However, training such a model on an imbalanced data have been shown to\nbe a very difficult task. Indeed, if the distribution of input leads to a poor\nresponse manifold representation, the model may not learn well and\nconsequently, it may not predict the outcome with acceptable accuracy. In this\nwork, we present an Adaptive Sampling Algorithm for Data Generation (ASADG)\ninvolving a physical model. As the initial input data may not accurately\nrepresent the response manifold in higher dimension, this algorithm iteratively\nadds input data into it. At each step the barycenter of each simplicial\ncomplex, that the manifold is discretized into, is added as new input data, if\na certain threshold is satisfied. We demonstrate the efficiency of the data\nsampling algorithm in comparison with LHS method for generating more\nrepresentative input data. To do so, we focus on the construction of a harmonic\ntransport problem metamodel by generating data through a classical solver. By\nusing such algorithm, it is possible to generate the same number of input data\nas LHS while providing a better representation of the response manifold.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-05-13T12:17:10Z"}
{"aid":"http://arxiv.org/abs/2505.08496v1","title":"Weighted Rewriting: Semiring Semantics for Abstract Reduction Systems","summary":"We present novel semiring semantics for abstract reduction systems (ARSs).\nMore precisely, we provide a weighted version of ARSs, where the reduction\nsteps induce weights from a semiring. Inspired by provenance analysis in\ndatabase theory and logic, we obtain a formalism that can be used for\nprovenance analysis of arbitrary ARSs. Our semantics handle (possibly\nunbounded) non-determinism and possibly infinite reductions. Moreover, we\ndevelop several techniques to prove upper and lower bounds on the weights\nresulting from our semantics, and show that in this way one obtains a uniform\napproach to analyze several different properties like termination, derivational\ncomplexity, space complexity, safety, as well as combinations of these\nproperties.","main_category":"cs.LO","categories":"cs.LO","published":"2025-05-13T12:24:38Z"}
{"aid":"http://arxiv.org/abs/2505.08497v1","title":"A new methodology to decompose a parametric domain using reduced order\n  data manifold in machine learning","summary":"We propose a new methodology for parametric domain decomposition using\niterative principal component analysis. Starting with iterative principle\ncomponent analysis, the high dimension manifold is reduced to the lower\ndimension manifold. Moreover, two approaches are developed to reconstruct the\ninverse projector to project from the lower data component to the original one.\nAfterward, we provide a detailed strategy to decompose the parametric domain\nbased on the low dimension manifold. Finally, numerical examples of harmonic\ntransport problem are given to illustrate the efficiency and effectiveness of\nthe proposed method comparing to the classical meta-models such as neural\nnetworks.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-05-13T12:25:16Z"}
{"aid":"http://arxiv.org/abs/2505.08498v1","title":"LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using\n  Large Language Models","summary":"Recent advances in large language models (LLMs) have enabled zero-shot\nautomated essay scoring (AES), providing a promising way to reduce the cost and\neffort of essay scoring in comparison with manual grading. However, most\nexisting zero-shot approaches rely on LLMs to directly generate absolute\nscores, which often diverge from human evaluations owing to model biases and\ninconsistent scoring. To address these limitations, we propose LLM-based\nComparative Essay Scoring (LCES), a method that formulates AES as a pairwise\ncomparison task. Specifically, we instruct LLMs to judge which of two essays is\nbetter, collect many such comparisons, and convert them into continuous scores.\nConsidering that the number of possible comparisons grows quadratically with\nthe number of essays, we improve scalability by employing RankNet to\nefficiently transform LLM preferences into scalar scores. Experiments using AES\nbenchmark datasets show that LCES outperforms conventional zero-shot methods in\naccuracy while maintaining computational efficiency. Moreover, LCES is robust\nacross different LLM backbones, highlighting its applicability to real-world\nzero-shot AES.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-13T12:26:16Z"}
{"aid":"http://arxiv.org/abs/2505.08507v1","title":"InfoPO: On Mutual Information Maximization for Large Language Model\n  Alignment","summary":"We study the post-training of large language models (LLMs) with human\npreference data. Recently, direct preference optimization and its variants have\nshown considerable promise in aligning language models, eliminating the need\nfor reward models and online sampling. Despite these benefits, these methods\nrely on explicit assumptions about the Bradley-Terry (BT) model, which makes\nthem prone to overfitting and results in suboptimal performance, particularly\non reasoning-heavy tasks. To address these challenges, we propose a principled\npreference fine-tuning algorithm called InfoPO, which effectively and\nefficiently aligns large language models using preference data. InfoPO\neliminates the reliance on the BT model and prevents the likelihood of the\nchosen response from decreasing. Extensive experiments confirm that InfoPO\nconsistently outperforms established baselines on widely used open benchmarks,\nparticularly in reasoning tasks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-13T12:37:48Z"}
{"aid":"http://arxiv.org/abs/2505.08513v1","title":"Influence of Self-Absorption on Pulse Shape Discrimination in Organic\n  Glass Scintillators","summary":"Organic glass scintillators are an interesting alternative to liquid\nscintillators, offering many advantageous characteristics with few drawbacks.\nIn this paper we investigate the influence of light self-absorption in the\norganic glass scintillator on its pulse shape discrimination capability. With\nfive scintillators of different heights but same diameter, we measure\nphotoelectron yield and Figure of Merit in neutron-gamma discrimination. The\ndecrease of both values with increasing size is attributed to light\nself-absorption, while normalized Figure of Merit remains constant. The choice\nof gates for charge comparison method is discussed. We also use genetic\nalgorithm to estimate decay times and intensities of fast, medium, and slow\ncomponents of light pulse shapes measured with Bollinger-Thomas setup. We\ncompare the results to trans-stilbene reference sample.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-05-13T12:44:55Z"}
{"aid":"http://arxiv.org/abs/2505.08519v1","title":"Germanium-Based Mid-Infrared Photonics","summary":"The mid-infrared (mid-IR) spectral range is a part of the electromagnetic\nspectrum in which most of the molecules have vibrational and rotational\nresonances. Ge-based photonic integrated circuits in this wavelength range have\nthus seen a burst of interest in the recent years, mainly driven by\napplications related with the detection of chemical and biological substances.\nHere we review the motivations and the recent developments in this field, from\nthe different material platforms to active and nonlinear devices. We also\ndiscuss a few demonstrations of sensing that have already been conducted,\nattesting the potential applications of such devices. Finally, we conclude by\ndiscussing the challenges that have to be solved to transition from lab\ndemonstrations to practical industrial devices.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-13T12:50:24Z"}
{"aid":"http://arxiv.org/abs/2505.08534v1","title":"Holographic geometry/real-space entanglement correspondence and metric\n  reconstruction","summary":"In holography, the boundary entanglement structure is believed to be encoded\nin the bulk geometry. In this work, we investigate the precise correspondence\nbetween the boundary real-space entanglement and the bulk geometry. By the\nboundary real-space entanglement, we refer to the conditional mutual\ninformation (CMI) for two infinitesimal subsystems separated by a distance $l$,\nand the corresponding bulk geometry is at a radial position $z_*$, namely the\nturning point of the entanglement wedge for a boundary region with a length\nscale $l$. In a generic geometry described by a given coordinate system, $z_*$\ncan be determined locally by $l$, while the exact expression for $z_*(l)$\ndepends on the gauge choice, reflecting the inherent nonlocality of this\nseemingly local correspondence. We propose to specify the function $z_*(l)$ as\nthe criterion for a gauge choice, and with the specified gauge function, we\nverify the exact correspondence between the boundary real-space entanglement\nand the bulk geometry. Inspired by this correspondence, we propose a new method\nof bulk metric reconstruction from boundary entanglement data, namely the CMI\nreconstruction. In this CMI proposal, with the gauge fixed a priori by\nspecifying $z_*(l)$, the bulk metric can be reconstructed from the relation\nbetween the bulk geometry and the boundary CMI. The CMI reconstruction method\nestablishes a connection between the differential entropy prescription and\nBilson's general algorithm for metric reconstruction.","main_category":"hep-th","categories":"hep-th","published":"2025-05-13T13:04:37Z"}
{"aid":"http://arxiv.org/abs/2505.08540v1","title":"PoET: the Paranal solar ESPRESSO Telescope","summary":"The detection and characterisation of other \"Earths\", orbiting other suns, is\na bold objective of present-day astrophysics. However, this quest is severely\nchallenged by astrophysical \"noise\" from the host stars, whose signatures\ndistort the observed spectra. Motivated by this problem, we are building a\ndedicated facility, the Paranal solar ESPRESSO Telescope (PoET). PoET will\ncollect solar light and channel it into the ESPRESSO spectrograph, allowing us\nto use the Sun as a proxy to unambiguously identify and understand the sources\nof relevant variability in solar-type stars.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,astro-ph.IM","published":"2025-05-13T13:12:01Z"}
{"aid":"http://arxiv.org/abs/2505.08541v1","title":"Area Comparison of CHERIoT and PMP in Ibex","summary":"Memory safety is a critical concern for modern embedded systems, particularly\nin security-sensitive applications. This paper explores the area impact of\nadding memory safety extensions to the Ibex RISC-V core, focusing on physical\nmemory protection (PMP) and Capability Hardware Extension to RISC-V for\nInternet of Things (CHERIoT). We synthesise the extended Ibex cores using a\ncommercial tool targeting the open FreePDK45 process and provide a detailed\narea breakdown and discussion of the results.\n  The PMP configuration we consider is one with 16 PMP regions. We find that\nthe extensions increase the core size by 24 thousand gate-equivalent (kGE) for\nPMP and 33 kGE for CHERIoT. The increase is mainly due to the additional state\nrequired to store information about protected memory. While this increase\namounts to 42% for PMP and 57% for CHERIoT in Ibex's area, its effect on the\noverall system is minimal. In a complete system-on-chip (SoC), like the secure\nmicrocontroller OpenTitan Earl Grey, where the core represents only a fraction\nof the total area, the estimated system-wide overhead is 0.6% for PMP and 1%\nfor CHERIoT. Given the security benefits these extensions provide, the area\ntrade-off is justified, making Ibex a compelling choice for secure embedded\napplications.","main_category":"cs.AR","categories":"cs.AR,cs.CR","published":"2025-05-13T13:12:30Z"}
{"aid":"http://arxiv.org/abs/2505.08543v1","title":"Tangent point position and atmosphere composition in limb scanning\n  instruments","summary":"In the forward model for limb-scanning instruments, ray tracing must be\naccounted for because variations in air refractivity cause the lines of sight\nto bend from straight paths into curves. The tangent point of a line of sight\nis defined as the minimum height point. The lines of sight can be adjusted by\nvarying the nadir angles of the instrument, which must be calibrated to account\nfor Earth's ellipticity and the actual atmospheric conditions sampled by these\npaths. In this study, we investigate the relationship between the nadir angles,\natmospheric properties, and tangent point positions, using a configuration\nrelevant to the CAIRT instrument. Atmospheric data from reanalysis databases\nare utilized, and the lines of sight are determined by numerically solving the\nEikonal equation. Our findings are compared to those of a previous study\nconducted for the MIPAS instrument, highlighting key differences.","main_category":"physics.ao-ph","categories":"physics.ao-ph,astro-ph.IM","published":"2025-05-13T13:13:48Z"}
{"aid":"http://arxiv.org/abs/2505.08560v1","title":"Evaluating the Sharpness and Limitations of Bounds on the Frobenius\n  Number","summary":"In this paper we study the (classical) Frobenius problem, namely the problem\nof finding the largest integer that cannot be represented as a nonnegative\nintegral combination of given relatively prime (strictly) positive integers\n(known as the Frobenius number). We firstly compare several upper bounds on the\nFrobenius number, assessing their relative tightness through both theoretical\narguments and Monte Carlo simulations. We then explore whether a general upper\nbound with a worst-case exponent strictly less than quadratic can exist, and\nformally demonstrate that such an improvement is impossible. These findings\noffer new insights into the structural properties of established bounds and\nunderscore inherent constraints for future refinement.","main_category":"math.NT","categories":"math.NT,math.OC","published":"2025-05-13T13:34:58Z"}
{"aid":"http://arxiv.org/abs/2505.08565v1","title":"On testing the class of symmetry using entropy characterization and\n  empirical likelihood approach","summary":"In this paper, we obtain a new characterization result for symmetric\ndistributions based on the entropy measure. Using the characterization, we\npropose a nonparametric test to test the symmetry of a distribution. We also\ndevelop the jackknife empirical likelihood and the adjusted jackknife empirical\nlikelihood ratio tests. The asymptotic properties of the proposed test\nstatistics are studied. We conduct extensive Monte Carlo simulation studies to\nassess the finite sample performance of the proposed tests. The simulation\nresults indicate that the jackknife empirical likelihood and adjusted jackknife\nempirical likelihood ratio tests show better performance than the existing\ntests. Finally, two real data sets are analysed to illustrate the applicability\nof the proposed tests.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-05-13T13:40:00Z"}
{"aid":"http://arxiv.org/abs/2505.08577v1","title":"Modeling Quantum Links for the Exploration of Distributed Quantum\n  Computing Systems","summary":"Quantum computing offers the potential to solve certain complex problems,\nyet, scaling monolithic processors remains a major challenge. Modular and\ndistributed architectures are proposed to build large-scale quantum systems\nwhile bringing the security advantages of quantum communication. At present,\nthis requires accurate and computationally efficient models of quantum links\nacross different scales to advance system design and guide experimental\nprototyping. In this work, we review protocols and models for estimating\nlatency, losses, and fidelity in quantum communication primitives relying on\nquantum state distribution via microwave photons. We also propose a scalable\nsimulation framework to support the design and evaluation of future distributed\nquantum computing systems.","main_category":"quant-ph","categories":"quant-ph,physics.comp-ph","published":"2025-05-13T13:53:44Z"}
{"aid":"http://arxiv.org/abs/2505.08578v1","title":"Extreme Conformal Prediction: Reliable Intervals for High-Impact Events","summary":"Conformal prediction is a popular method to construct prediction intervals\nfor black-box machine learning models with marginal coverage guarantees. In\napplications with potentially high-impact events, such as flooding or financial\ncrises, regulators often require very high confidence for such intervals.\nHowever, if the desired level of confidence is too large relative to the amount\nof data used for calibration, then classical conformal methods provide\ninfinitely wide, thus, uninformative prediction intervals. In this paper, we\npropose a new method to overcome this limitation. We bridge extreme value\nstatistics and conformal prediction to provide reliable and informative\nprediction intervals with high-confidence coverage, which can be constructed\nusing any black-box extreme quantile regression method. The advantages of this\nextreme conformal prediction method are illustrated in a simulation study and\nin an application to flood risk forecasting.","main_category":"stat.ME","categories":"stat.ME,stat.AP,stat.ML","published":"2025-05-13T13:54:36Z"}
{"aid":"http://arxiv.org/abs/2505.08580v1","title":"When are Morse resolutions polyhedral?","summary":"It is known that the chain complex of a simplex on $q$ vertices can be used\nto construct a free resolution of any ideal generated by $q$ monomials, and as\na direct result, the Betti numbers always have binomial upper bounds, given by\nthe number of faces of a simplex in each dimension.\n  It is also known that for most monomials the resolution provided by the\nsimplex is far from minimal. Discrete Morse theory provides an algorithm called\n\\say{Morse matchings} by which faces of the simplex can be removed so that the\nchain complex on the remaining faces is still a free resolution of the same\nideal. An immediate positive effect is an often considerable improvement on the\nbounds on Betti numbers. A caveat is the loss of the combinatorial structure of\nthe simplex we started with: the output of the Morse matching process is a cell\ncomplex with no obvious structure besides an \\say{address} for each cell.\n  The main question in this paper is: which Morse matchings lead to Morse\ncomplexes that are polyhedral cell complexes? We prove that if a monomial ideal\nis minimally generated by up to four generators, then there is a maximal Morse\nmatching of the simplex such that the resulting cell complex is a polyhedral\ncell complex. We then give an example of a monomial ideal minimally generated\nby six generators whose minimal free resolution is supported on a Morse complex\nand the Morse complex cannot be polyhedral no matter what Morse matching is\nchosen, and we go further to show that this ideal cannot have any polyhedral\nminimal free resolution.","main_category":"math.AC","categories":"math.AC","published":"2025-05-13T13:55:25Z"}
{"aid":"http://arxiv.org/abs/2505.08593v1","title":"MC-Swarm: Minimal-Communication Multi-Agent Trajectory Planning and\n  Deadlock Resolution for Quadrotor Swarm","summary":"For effective multi-agent trajectory planning, it is important to consider\nlightweight communication and its potential asynchrony. This paper presents a\ndistributed trajectory planning algorithm for a quadrotor swarm that operates\nasynchronously and requires no communication except during the initial planning\nphase. Moreover, our algorithm guarantees no deadlock under asynchronous\nupdates and absence of communication during flight. To effectively ensure these\npoints, we build two main modules: coordination state updater and trajectory\noptimizer. The coordination state updater computes waypoints for each agent\ntoward its goal and performs subgoal optimization while considering deadlocks,\nas well as safety constraints with respect to neighbor agents and obstacles.\nThen, the trajectory optimizer generates a trajectory that ensures collision\navoidance even with the asynchronous planning updates of neighboring agents. We\nprovide a theoretical guarantee of collision avoidance with deadlock resolution\nand evaluate the effectiveness of our method in complex simulation\nenvironments, including random forests and narrow-gap mazes. Additionally, to\nreduce the total mission time, we design a faster coordination state update\nusing lightweight communication. Lastly, our approach is validated through\nextensive simulations and real-world experiments with cluttered environment\nscenarios.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-05-13T14:05:07Z"}
{"aid":"http://arxiv.org/abs/2505.08617v1","title":"OpenThinkIMG: Learning to Think with Images via Visual Tool\n  Reinforcement Learning","summary":"While humans can flexibly leverage interactive visual cognition for complex\nproblem-solving, enabling Large Vision-Language Models (LVLMs) to learn\nsimilarly adaptive behaviors with visual tools remains challenging. A\nsignificant hurdle is the current lack of standardized infrastructure, which\nhinders integrating diverse tools, generating rich interaction data, and\ntraining robust agents effectively. To address these gaps, we introduce\nOpenThinkIMG, the first open-source, comprehensive end-to-end framework for\ntool-augmented LVLMs. It features standardized vision tool interfaces, scalable\ntrajectory generation for policy initialization, and a flexible training\nenvironment. Furthermore, considering supervised fine-tuning (SFT) on static\ndemonstrations offers limited policy generalization for dynamic tool\ninvocation, we propose a novel reinforcement learning (RL) framework V-ToolRL\nto train LVLMs to learn adaptive policies for invoking external vision tools.\nV-ToolRL enables LVLMs to autonomously discover optimal tool-usage strategies\nby directly optimizing for task success using feedback from tool interactions.\nWe empirically validate V-ToolRL on challenging chart reasoning tasks. Our\nRL-trained agent, built upon a Qwen2-VL-2B, significantly outperforms its\nSFT-initialized counterpart (+28.83 points) and surpasses established\nsupervised tool-learning baselines like Taco and CogCom by an average of +12.7\npoints. Notably, it also surpasses prominent closed-source models like GPT-4.1\nby +8.68 accuracy points. We hope OpenThinkIMG can serve as a foundational\nframework for advancing dynamic, tool-augmented visual reasoning, helping the\ncommunity develop AI agents that can genuinely \"think with images\".","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T14:35:51Z"}
{"aid":"http://arxiv.org/abs/2505.08645v1","title":"Topology and geometry optimization of grid-shells under self-weight\n  loading","summary":"This manuscript presents an approach for simultaneously optimizing the\nconnectivity and elevation of grid-shell structures acting in pure compression\n(or pure tension) under the combined effects of a prescribed external loading\nand the design-dependent self-weight of the structure itself. The method\nderived herein involves solving a second-order cone optimization problem,\nthereby ensuring convexity and obtaining globally optimal results for a given\ndiscretization of the design domain. Several numerical examples are presented,\nillustrating characteristics of this class of optimal structures. It is found\nthat, as self-weight becomes more significant, both the optimal topology and\nthe optimal elevation profile of the structure change, highlighting the\nimportance of optimizing both topology and geometry simultaneously from the\nearliest stages of design. It is shown that this approach can obtain solutions\nwith greater accuracy and several orders of magnitude more quickly than a\nstandard 3D layout/truss topology optimization approach.","main_category":"cs.CE","categories":"cs.CE","published":"2025-05-13T15:03:47Z"}
{"aid":"http://arxiv.org/abs/2505.08652v1","title":"Comparative Analysis of Blockchain Systems","summary":"Blockchain is a type of decentralized distributed database. Unlike\ntraditional relational database management systems, it does not require\nmanagement or maintenance by a third party. All data management and update\nprocesses are open and transparent, solving the trust issues of centralized\ndatabase management systems. Blockchain ensures network-wide consistency,\nconsensus, traceability, and immutability. Under the premise of mutual distrust\nbetween nodes, blockchain technology integrates various technologies, such as\nP2P protocols, asymmetric encryption, consensus mechanisms, and chain\nstructures. Data is distributed and stored across multiple nodes, maintained by\nall nodes, ensuring transaction data integrity, undeniability, and security.\nThis facilitates trusted information sharing and supervision. The basic\nprinciples of blockchain form the foundation for all related research.\nUnderstanding the working principles is essential for further study of\nblockchain technology. There are many platforms based on blockchain technology,\nand they differ from one another. This paper will analyze the architecture of\nblockchain systems at each layer, focusing on the principles and technologies\nof blockchain platforms such as Bitcoin, Ethereum, and Hyperledger Fabric. The\nanalysis will cover their scalability and security and highlight their\nsimilarities, differences, advantages, and disadvantages.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-13T15:13:37Z"}
{"aid":"http://arxiv.org/abs/2505.08661v1","title":"Composition Operators on $\\bf H^{p,q,s}(B_{n})$ of $\\bf \\mathbb{C}^{n}$","summary":"Let $B_{n}$ be the unit ball in the complex vector space $\\mathbb{C}^{n}$,\nand let $\\varphi: B_{n}\\rightarrow B_{n}$ be a holomorphic mapping. In this\npaper, we characterize those symbols $\\varphi$ such that composition operators\n$C_{\\varphi}$ are bounded or compact on the general Hardy type space\n$H^{p,q,s}(B_{n})$. These results extend the relevant results on Hardy space\nand some other classical function spaces.","main_category":"math.CV","categories":"math.CV","published":"2025-05-13T15:23:57Z"}
{"aid":"http://arxiv.org/abs/2505.08665v1","title":"SkillFormer: Unified Multi-View Video Understanding for Proficiency\n  Estimation","summary":"Assessing human skill levels in complex activities is a challenging problem\nwith applications in sports, rehabilitation, and training. In this work, we\npresent SkillFormer, a parameter-efficient architecture for unified multi-view\nproficiency estimation from egocentric and exocentric videos. Building on the\nTimeSformer backbone, SkillFormer introduces a CrossViewFusion module that\nfuses view-specific features using multi-head cross-attention, learnable\ngating, and adaptive self-calibration. We leverage Low-Rank Adaptation to\nfine-tune only a small subset of parameters, significantly reducing training\ncosts. In fact, when evaluated on the EgoExo4D dataset, SkillFormer achieves\nstate-of-the-art accuracy in multi-view settings while demonstrating remarkable\ncomputational efficiency, using 4.5x fewer parameters and requiring 3.75x fewer\ntraining epochs than prior baselines. It excels in multiple structured tasks,\nconfirming the value of multi-view integration for fine-grained skill\nassessment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T15:27:24Z"}
{"aid":"http://arxiv.org/abs/2505.08675v1","title":"Dominant orbital magnetization in the prototypical altermagnet MnTe","summary":"Altermagnetism is an unconventional form of antiferromagnetism characterized\nby momentum-dependent spin polarization of electronic states and zero net\nmagnetization, arising from specific crystalline symmetries. In the presence of\nspin-orbit coupling (SOC) and broken time-reversal symmetry, altermagnets can\nexhibit finite net magnetization and anomalous Hall effect (AHE), phenomena\ntypically associated with ferromagnets. Due to the dependence of AHE on\nmagnetization, understanding the interplay between spin and orbital\ncontributions to magnetization is essential for interpreting experiments and\ndesigning altermagnetic devices. In this work, we use density functional theory\nto investigate the intrinsic spin and orbital magnetization of the magnetic\nground state of the prototypical altermagnet {\\alpha}-MnTe. We find that SOC\ninduces weak ferromagnetism through spin canting, accompanied by a slight\nin-plane rotation of the N\\'eel vector. Notably, we identify a significant net\norbital magnetization of 0.176 {\\mu}B per unit cell oriented along the z-axis,\nwhile the spin magnetization in the same direction is much smaller at 0.002\n{\\mu}B. By varying the chemical potential, we show that the spin magnetization\nis tunable through hole doping, whereas the orbital magnetization remains\nrobust against carrier density changes. These results highlight the important\nrole of orbital magnetization and establish its relevance for orbital-based\nphenomena in altermagnets.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cond-mat.str-el","published":"2025-05-13T15:38:54Z"}
{"aid":"http://arxiv.org/abs/2505.08682v1","title":"Joint Communication Scheduling and Resource Allocation for Distributed\n  Edge Learning: Seamless Integration in Next-Generation Wireless Networks","summary":"Distributed edge learning (DL) is considered a cornerstone of intelligence\nenablers, since it allows for collaborative training without the necessity for\nlocal clients to share raw data with other parties, thereby preserving privacy\nand security. Integrating DL into the 6G networks requires a coexistence design\nwith existing services such as high-bandwidth (HB) traffic like eMBB. Current\ndesigns in the literature mainly focus on communication round-wise designs that\nassume a rigid resource allocation throughout each communication round (CR).\nHowever, rigid resource allocation within a CR is a highly inefficient and\ninaccurate representation of the system's realistic behavior. This is due to\nthe heterogeneous nature of the system, as clients inherently may need to\naccess the network at different times. This work zooms into one arbitrary CR,\nand demonstrates the importance of considering a time-dependent resource\nsharing design with HB traffic. We first formulate a time-step-wise\noptimization problem to minimize the consumed time by DL within the CR while\nconstrained by a DL energy budget. Due to its intractability, a session-based\noptimization problem is formulated assuming a CR lasts less than a large-scale\ncoherence time. Some scheduling properties of such multi-server joint\ncommunication scheduling and resource allocation framework have been\nestablished. An iterative algorithm has been designed to solve such non-convex\nand non-block-separable-constrained problems. Simulation results confirm the\nimportance of the efficient and accurate integration design proposed in this\nwork.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-13T15:43:38Z"}
{"aid":"http://arxiv.org/abs/2505.08683v1","title":"Uncertainty-Aware Surrogate-based Amortized Bayesian Inference for\n  Computationally Expensive Models","summary":"Bayesian inference typically relies on a large number of model evaluations to\nestimate posterior distributions. Established methods like Markov Chain Monte\nCarlo (MCMC) and Amortized Bayesian Inference (ABI) can become computationally\nchallenging. While ABI enables fast inference after training, generating\nsufficient training data still requires thousands of model simulations, which\nis infeasible for expensive models. Surrogate models offer a solution by\nproviding approximate simulations at a lower computational cost, allowing the\ngeneration of large data sets for training. However, the introduced\napproximation errors and uncertainties can lead to overconfident posterior\nestimates. To address this, we propose Uncertainty-Aware Surrogate-based\nAmortized Bayesian Inference (UA-SABI) - a framework that combines surrogate\nmodeling and ABI while explicitly quantifying and propagating surrogate\nuncertainties through the inference pipeline. Our experiments show that this\napproach enables reliable, fast, and repeated Bayesian inference for\ncomputationally expensive models, even under tight time constraints.","main_category":"stat.ML","categories":"stat.ML,cs.LG,stat.ME","published":"2025-05-13T15:44:10Z"}
{"aid":"http://arxiv.org/abs/2505.08691v1","title":"VizCV: AI-assisted visualization of researchers' publications tracks","summary":"Analyzing how the publication records of scientists and research groups have\nevolved over the years is crucial for assessing their expertise since it can\nsupport the management of academic environments by assisting with career\nplanning and evaluation. We introduce VizCV, a novel web-based end-to-end\nvisual analytics framework that enables the interactive exploration of\nresearchers' scientific trajectories. It incorporates AI-assisted analysis and\nsupports automated reporting of career evolution. Our system aims to model\ncareer progression through three key dimensions: a) research topic evolution to\ndetect and visualize shifts in scholarly focus over time, b) publication record\nand the corresponding impact, c) collaboration dynamics depicting the growth\nand transformation of a researcher's co-authorship network. AI-driven insights\nprovide automated explanations of career transitions, detecting significant\nshifts in research direction, impact surges, or collaboration expansions. The\nsystem also supports comparative analysis between researchers, allowing users\nto compare topic trajectories and impact growth. Our interactive, multi-tab and\nmultiview system allows for the exploratory analysis of career milestones under\ndifferent perspectives, such as the most impactful articles, emerging research\nthemes, or obtaining a detailed analysis of the contribution of the researcher\nin a subfield. The key contributions include AI/ML techniques for: a) topic\nanalysis, b) dimensionality reduction for visualizing patterns and trends, c)\nthe interactive creation of textual descriptions of facets of data through\nconfigurable prompt generation and large language models, that include key\nindicators, to help understanding the career development of individuals or\ngroups.","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-05-13T15:47:59Z"}
{"aid":"http://arxiv.org/abs/2505.08699v1","title":"Granite-speech: open-source speech-aware LLMs with strong English ASR\n  capabilities","summary":"Granite-speech LLMs are compact and efficient speech language models\nspecifically designed for English ASR and automatic speech translation (AST).\nThe models were trained by modality aligning the 2B and 8B parameter variants\nof granite-3.3-instruct to speech on publicly available open-source corpora\ncontaining audio inputs and text targets consisting of either human transcripts\nfor ASR or automatically generated translations for AST. Comprehensive\nbenchmarking shows that on English ASR, which was our primary focus, they\noutperform several competitors' models that were trained on orders of magnitude\nmore proprietary data, and they keep pace on English-to-X AST for major\nEuropean languages, Japanese, and Chinese. The speech-specific components are:\na conformer acoustic encoder using block attention and self-conditioning\ntrained with connectionist temporal classification, a windowed\nquery-transformer speech modality adapter used to do temporal downsampling of\nthe acoustic embeddings and map them to the LLM text embedding space, and LoRA\nadapters to further fine-tune the text LLM. Granite-speech-3.3 operates in two\nmodes: in speech mode, it performs ASR and AST by activating the encoder,\nprojector, and LoRA adapters; in text mode, it calls the underlying\ngranite-3.3-instruct model directly (without LoRA), essentially preserving all\nthe text LLM capabilities and safety. Both models are freely available on\nHuggingFace (https://huggingface.co/ibm-granite/granite-speech-3.3-2b and\nhttps://huggingface.co/ibm-granite/granite-speech-3.3-8b) and can be used for\nboth research and commercial purposes under a permissive Apache 2.0 license.","main_category":"eess.AS","categories":"eess.AS","published":"2025-05-13T15:58:57Z"}
{"aid":"http://arxiv.org/abs/2505.08708v1","title":"A Reynolds-semi-robust H(div)-conforming method for unsteady\n  incompressible non-Newtonian flows","summary":"In this work, we prove what appear to be the first Reynolds-semi-robust and\npressure-robust velocity error estimates for an H(div)-conforming approximation\nof unsteady incompressible flows of power-law type fluids. The proposed methods\nhinges on a discontinuous Galerkin approximation of the viscous term and a\nreinforced upwind-type stabilization of the convective term. The derived\nvelocity error estimates account for pre-asymptotic orders of convergence\nobserved in convection-dominated flows through regime-dependent estimates of\nthe error contributions. A complete set of numerical results validate the\ntheoretical findings.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-13T16:14:16Z"}
{"aid":"http://arxiv.org/abs/2505.08714v1","title":"Be star demographics: a comprehensive study of thousands of lightcurves\n  in the Magellanic Clouds","summary":"Multi-color OGLE survey light curves of about 20 years duration are analyzed\nfor about 3000 classical Be stars in the Large and Small Magellanic Clouds\n(LMC, SMC) in order to study the properties and variability. Each light curve\nwas manually analyzed to distinguish between different scenarios, such as\nphotospheric baseline levels, and disk build-up and dissipation phases. This\nanalysis was aided by dynamical disk models and photospheric models to coarsely\ndetermine inclination angle and mass. Measured quantities such as the fraction\nof time spent actively ejecting mass (the duty cycle), the fraction of time\nspent with a detectable disk (the disk duty cycle), the build-up and\ndissipation time of isolated disk events, and the number of mass outbursts per\nyear allow us to characterize and compare the behavior of the two populations.\nThere is a wide spread in the duty cycle, with median values of 0.44 (LMC) and\n0.60 (SMC). The disk duty cycle is high for both populations, with median\nvalues of 0.99 (LMC) and 1.0 (SMC), indicating that disks are almost always\npresent for these stars. The occurrence rate of outbursts ranges from zero to\nabout two per year, with median values of 0.31 (LMC) and 0.26 (SMC). There are\nstrong statistical differences in the behavior of the LMC and SMC populations,\nwith the lower metallicity stars being more active in terms of their duty cycle\nand disk duty cycle, and with less frequent but longer lasting outbursts.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-05-13T16:21:56Z"}
{"aid":"http://arxiv.org/abs/2505.08724v1","title":"Optimal Trajectory Planning with Collision Avoidance for Autonomous\n  Vehicle Maneuvering","summary":"To perform autonomous driving maneuvers, such as parallel or perpendicular\nparking, a vehicle requires continual speed and steering adjustments to follow\na generated path. In consequence, the path's quality is a limiting factor of\nthe vehicle maneuver's performance. While most path planning approaches include\nfinding a collision-free route, optimal trajectory planning involves solving\nthe best transition from initial to final states, minimizing the action over\nall paths permitted by a kinematic model. Here we propose a novel method based\non sequential convex optimization, which permits flexible and efficient optimal\ntrajectory generation. The objective is to achieve the fastest time, shortest\ndistance, and fewest number of path segments to satisfy motion requirements,\nwhile avoiding sensor blind-spots. In our approach, vehicle kinematics are\nrepresented by a discretized Dubins model. To avoid collisions, each waypoint\nis constrained by linear inequalities representing closest distance of\nobstacles to a polygon specifying the vehicle's extent. To promote smooth and\nvalid trajectories, the solved kinematic state and control variables are\nconstrained and regularized by penalty terms in the model's cost function,\nwhich enforces physical restrictions including limits for steering angle,\nacceleration and speed. In this paper, we analyze trajectories obtained for\nseveral parking scenarios. Results demonstrate efficient and collision-free\nmotion generated by the proposed technique.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-05-13T16:36:20Z"}
{"aid":"http://arxiv.org/abs/2505.08725v1","title":"Extending Large Vision-Language Model for Diverse Interactive Tasks in\n  Autonomous Driving","summary":"The Large Visual-Language Models (LVLMs) have significantly advanced image\nunderstanding. Their comprehension and reasoning capabilities enable promising\napplications in autonomous driving scenarios. However, existing research\ntypically focuses on front-view perspectives and partial objects within scenes,\nstruggling to achieve comprehensive scene understanding. Meanwhile, existing\nLVLMs suffer from the lack of mapping relationship between 2D and 3D and\ninsufficient integration of 3D object localization and instruction\nunderstanding. To tackle these limitations, we first introduce NuInteract, a\nlarge-scale dataset with over 1.5M multi-view image language pairs spanning\ndense scene captions and diverse interactive tasks. Furthermore, we propose\nDriveMonkey, a simple yet effective framework that seamlessly integrates LVLMs\nwith a spatial processor using a series of learnable queries. The spatial\nprocessor, designed as a plug-and-play component, can be initialized with\npre-trained 3D detectors to improve 3D perception. Our experiments show that\nDriveMonkey outperforms general LVLMs, especially achieving a 9.86% notable\nimprovement on the 3D visual grounding task. The dataset and code will be\nreleased at https://github.com/zc-zhao/DriveMonkey.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T16:36:51Z"}
{"aid":"http://arxiv.org/abs/2505.08735v1","title":"Preference Optimization for Combinatorial Optimization Problems","summary":"Reinforcement Learning (RL) has emerged as a powerful tool for neural\ncombinatorial optimization, enabling models to learn heuristics that solve\ncomplex problems without requiring expert knowledge. Despite significant\nprogress, existing RL approaches face challenges such as diminishing reward\nsignals and inefficient exploration in vast combinatorial action spaces,\nleading to inefficiency. In this paper, we propose Preference Optimization, a\nnovel method that transforms quantitative reward signals into qualitative\npreference signals via statistical comparison modeling, emphasizing the\nsuperiority among sampled solutions. Methodologically, by reparameterizing the\nreward function in terms of policy and utilizing preference models, we\nformulate an entropy-regularized RL objective that aligns the policy directly\nwith preferences while avoiding intractable computations. Furthermore, we\nintegrate local search techniques into the fine-tuning rather than\npost-processing to generate high-quality preference pairs, helping the policy\nescape local optima. Empirical results on various benchmarks, such as the\nTraveling Salesman Problem (TSP), the Capacitated Vehicle Routing Problem\n(CVRP) and the Flexible Flow Shop Problem (FFSP), demonstrate that our method\nsignificantly outperforms existing RL algorithms, achieving superior\nconvergence efficiency and solution quality.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-13T16:47:00Z"}
{"aid":"http://arxiv.org/abs/2505.08742v1","title":"Applying the ACE2 Emulator to SST Green's Functions for the E3SMv3\n  Climate Model","summary":"Green's functions are a useful technique for interpreting atmospheric state\nresponses to changes in the spatial pattern of sea surface temperature (SST).\nHere we train version 2 of the Ai2 Climate Emulator (ACE2) on reference\nhistorical SST simulations of the US Department of Energy's EAMv3 global\natmosphere model. We compare how well the SST Green's functions generated by\nACE2 match those of EAMv3, following the protocol of the Green's Function Model\nIntercomparison Project (GFMIP). The spatial patterns of top-of-atmosphere\n(TOA) radiative response from the individual GFMIP SST patch simulations are\nsimilar for ACE and the EAMv3 reference. The derived sensitivity of global net\nTOA radiation sensitivity to SST patch location is qualitatively similar in ACE\nas in EAMv3, but there are statistically significant discrepancies for some SST\npatches, especially over the subtropical northeast Pacific. These discrepancies\nmay reflect insufficient diversity in the SST patterns sampled over the course\nof the EAMv3 AMIP simulation used for training ACE. Both ACE and EAMv3 Green's\nfunctions reconstruct the historical record of the global annual-mean TOA\nradiative flux from a reference EAMv3 AMIP simulation reasonably well. Notably,\nunder our configuration and compute resources, ACE achieves these results\napproximately 100 times faster in wall-clock time compared to EAMv3,\nhighlighting its potential as a powerful and efficient tool for tackling other\ncomputationally intensive problems in climate science.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-05-13T16:55:15Z"}
{"aid":"http://arxiv.org/abs/2505.08743v1","title":"Understanding Housing and Homelessness System Access by Linking\n  Administrative Data","summary":"This paper uses privacy preserving methods to link over 235,000 records in\nthe housing and homelessness system of care (HHSC) of a major North American\ncity. Several machine learning pairwise linkage and two clustering algorithms\nare evaluated for merging the profiles for latent individuals in the data.\nImportantly, these methods are evaluated using both traditional machine\nlearning metrics and HHSC system use metrics generated using the linked data.\nThe results demonstrate that privacy preserving linkage methods are an\neffective and practical method for understanding how a single person interacts\nwith multiple agencies across an HHSC. They also show that performance\ndifferences between linkage techniques are amplified when evaluated using HHSC\ndomain specific metrics like number of emergency homeless shelter stays, length\nof time interacting with an HHSC and number of emergency shelters visited per\nperson.","main_category":"cs.CY","categories":"cs.CY","published":"2025-05-13T16:57:55Z"}
{"aid":"http://arxiv.org/abs/2505.08749v1","title":"On the Radiation Effects of Strontium Ions on Satellite Solar Cells in\n  Low Earth Orbits","summary":"This study focuses on the radiation effects of Sr+ ions--generated from\nhigh-altitude nuclear explosions (HANE)--on satellite solar cells in low-Earth\norbits (LEO). Along four selected satellite orbits, ion fluences are sampled\ninside the evolving Sr+ ion distributions for days, determined from our newly\ndeveloped HANE environment model. These fluences, along with the help of\nradiation transport codes including the MULASSIS and SRIM models, enable us to\nquantify the radiation damages by determining the values of total ionizing\ndoses and the equivalent 1 MeV electron fluences for displacement damages.\nComparing the dose values to existing experimental data, we conclude that\nHANE-generated Sr+ ions have limited darkening effects to quartz solar cell\ncoverglasses in LEO with apogees of 100s to 1000 km. In addition, with the\nextremely high equivalent fluences, we also conclude that these Sr ions may\ncause severe or even fatal displacement damage to exposed solar photovoltaic\n(PV) cells on satellites in LEO. The radiation effects of Sr+ ions are much\nless significant for the orbits with high apogees beyond ten thousand km. We\nalso conducted model parameter sensitivity studies on the charge exchange\ncross-sections, neutral atmosphere density profiles and explosion local time\npositions, and the above conclusions stay unchanged. The methodology developed\nin this study can be extended to other HANE-generated heavy ion species in the\nfuture.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-05-13T17:02:00Z"}
{"aid":"http://arxiv.org/abs/2505.08750v1","title":"AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large\n  Language Models","summary":"Actual causality (AC), a fundamental aspect of causal reasoning (CR), is\nresponsible for attribution and responsibility assignment in real-world\nscenarios. However, existing LLM-based methods lack grounding in formal AC\ntheory, resulting in limited interpretability. Therefore, we propose AC-Reason,\na semi-formal reasoning framework that identifies causally relevant events\nwithin an AC scenario, infers the values of their formal causal factors (e.g.,\nsufficiency, necessity, and normality), and answers AC queries via a\ntheory-guided algorithm with explanations. While AC-Reason does not explicitly\nconstruct a causal graph, it operates over variables in the underlying causal\nstructure to support principled reasoning. To enable comprehensive evaluation,\nwe introduce AC-Bench, a new benchmark built upon and substantially extending\nBig-Bench Hard Causal Judgment (BBH-CJ). AC-Bench comprises ~1K carefully\nannotated samples, each with detailed reasoning steps and focuses solely on\nactual causation. The case study shows that synthesized samples in AC-Bench\npresent greater challenges for LLMs. Extensive experiments on BBH-CJ and\nAC-Bench show that AC-Reason consistently improves LLM performance over\nbaselines. On BBH-CJ, all tested LLMs surpass the average human rater accuracy\nof 69.60%, with GPT-4 + AC-Reason achieving 75.04%. On AC-Bench, GPT-4 +\nAC-Reason again achieves the highest accuracy of 71.82%. AC-Bench further\nenables fine-grained analysis of reasoning faithfulness, revealing that only\nQwen-2.5-72B-Instruct, Claude-3.5-Sonnet, and GPT-4o exhibit faithful\nreasoning, whereas GPT-4 tends to exploit shortcuts. Finally, our ablation\nstudy proves that integrating AC theory into LLMs is highly effective, with the\nproposed algorithm contributing the most significant performance gains.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-13T17:02:33Z"}
{"aid":"http://arxiv.org/abs/2505.08753v1","title":"A comparison principle for nonlinear parabolic equations with nonlocal\n  source and gradient absorption","summary":"This paper investigates the initial-boundary value problem for a nonlinear\nparabolic equation involving the $p$-Laplacian operator, nonlocal source terms,\ngradient absorption, and various nonlinearities: \\[ \\frac{\\partial u}{\\partial\nt} - \\text{div}(|\\nabla u|^{p-2} \\nabla u ) = \\alpha |u|^{k-1}u \\int_\\Omega\n|u|^s \\, dx - \\beta |u|^{l-1}u |\\nabla u|^q + \\gamma u^m + \\mu |\\nabla u|^r -\n\\nu |u|^{\\sigma-1}u, \\] where $ \\Omega $ is a bounded domain in $\\mathbb{R}^N$,\n$N \\geq 1$, with a smooth boundary $\\partial \\Omega$. The parameters satisfy $\n\\alpha, l, \\sigma > 0 $, $ \\beta, \\nu \\geq 0 $, $ k, m, s \\geq 1 $, $ r \\geq p\n- 1 \\geq \\frac{p}{2}$, and $\\gamma, \\mu \\in \\mathbb{R}$.\n  We establish a comparison principle for this problem. Using this principle,\nwe derive blow-up results as well as global-in-time boundedness of solutions.\nOur results extend and unify previous studies in the literature.","main_category":"math.AP","categories":"math.AP","published":"2025-05-13T17:15:02Z"}
{"aid":"http://arxiv.org/abs/2505.08754v1","title":"3GPP-Compliant Radar Cross Section Characterization of Indoor Factory\n  Targets","summary":"The following paper presents a systematic 3rd Generation Partnership Project\n(3GPP)-compliant characterization of radar cross section (RCS) for indoor\nfactory (InF) objects, including small and mid-sized unmanned aerial vehicles\n(UAVs), robotic arms, and automated guided vehicles (AGVs). Through\nmeasurements in the 25-28 GHz range, we validate the 3GPP standardized\nlog-normal distribution model for RCS for above-mentioned target objects. The\n3GPP-complaint RCS parameters obtained for the small-sized UAV are in close\nagreement (<1 dB deviation) with 3GPP agreed values. The mid-sized UAVs exhibit\nhigher reflectivity compared to the small-sized UAV due to enhanced specular\ncomponents attributed to material and lithium-ion battery packs. The robotic\narm exhibits dynamic RCS behavior due to mechanical articulation, whereas UAVs\nshow clear size-dependent reflectivity patterns in AGVs. Our findings provide\nempirical validation for RCS characterization for integrated sensing and\ncommunication channel modeling in InF environments.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-13T17:15:10Z"}
{"aid":"http://arxiv.org/abs/2505.08782v1","title":"Addressing the Current Challenges of Quantum Machine Learning through\n  Multi-Chip Ensembles","summary":"Quantum Machine Learning (QML) holds significant promise for solving\ncomputational challenges across diverse domains. However, its practical\ndeployment is constrained by the limitations of noisy intermediate-scale\nquantum (NISQ) devices, including noise, limited scalability, and trainability\nissues in variational quantum circuits (VQCs). We introduce the multi-chip\nensemble VQC framework, which partitions high-dimensional computations across\nsmaller quantum chips to enhance scalability, trainability, and noise\nresilience. We show that this approach mitigates barren plateaus, reduces\nquantum error bias and variance, and maintains robust generalization through\ncontrolled entanglement. Designed to align with current and emerging quantum\nhardware, the framework demonstrates strong potential for enabling scalable QML\non near-term devices, as validated by experiments on standard benchmark\ndatasets (MNIST, FashionMNIST, CIFAR-10) and real world dataset (PhysioNet\nEEG).","main_category":"cs.LG","categories":"cs.LG,cs.CE","published":"2025-05-13T17:57:53Z"}
{"aid":"http://arxiv.org/abs/2505.08786v1","title":"Kination-like Era Driven by the Effective Inflaton/Higgs Potential","summary":"Based on the minimal $U(1)_X$ extended Standard Model, we explore cosmic\ninflation where the $U(1)_X$ Higgs field serves as the inflaton. We demonstrate\nthat a stiff era with an equation of state $w > 1/3$ can emerge during the\ninflaton's oscillatory phase after inflation, driven by the Coleman-Weinberg\npotential of the inflaton, arising due to radiative corrections. This leads to\nsignificant modulation and enhancement of the irreducible stochastic\ngravitational wave (GW) background from inflation, deviating from the\nconventional scale-invariant spectrum. Such a distinct GW spectrum could be\ndetectable by next-generation GW interferometer missions, such as U-DECIGO. In\nour framework, the GW spectrum depends on the $U(1)_X$ gauge coupling and the\nmass of the $U(1)_X$ gauge boson ($Z^\\prime$). As a result, future GW\nobservations and $Z^\\prime$ boson resonance searches at high-energy collider\nexperiments are complementary to one another.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-05-13T17:59:01Z"}
