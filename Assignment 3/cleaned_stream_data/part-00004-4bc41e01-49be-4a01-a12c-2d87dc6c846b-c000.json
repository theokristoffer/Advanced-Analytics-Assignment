{"aid":"http://arxiv.org/abs/2504.09886v1","title":"Investigating Syntactic Biases in Multilingual Transformers with RC\n  Attachment Ambiguities in Italian and English","summary":"This paper leverages past sentence processing studies to investigate whether\nmonolingual and multilingual LLMs show human-like preferences when presented\nwith examples of relative clause attachment ambiguities in Italian and English.\nFurthermore, we test whether these preferences can be modulated by lexical\nfactors (the type of verb/noun in the matrix clause) which have been shown to\nbe tied to subtle constraints on syntactic and semantic relations. Our results\noverall showcase how LLM behavior varies interestingly across models, but also\ngeneral failings of these models in correctly capturing human-like preferences.\nIn light of these results, we argue that RC attachment is the ideal benchmark\nfor cross-linguistic investigations of LLMs' linguistic knowledge and biases.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T05:19:23Z"}
{"aid":"http://arxiv.org/abs/2504.09888v1","title":"Scalable fluxonium qubit architecture with tunable interactions between\n  non-computational levels","summary":"The fluxonium qubit has emerged as a promising candidate for superconducting\nquantum computing due to its long coherence times and high-fidelity gates.\nNonetheless, further scaling up and improving performance remain critical\nchallenges for establishing fluxoniums as a viable alternative to transmons. A\nkey obstacle lies in developing scalable coupling architectures. In this work,\nwe introduce a scalable fluxonium architecture that enables decoupling of qubit\nstates while maintaining tunable couplings between non-computational states.\nBeyond the well-studied ZZ crosstalk, we identify that an always-on interaction\ninvolving non-computational levels can significantly degrade the fidelities of\ninitialization, control, and readout in large systems, thereby impeding\nscalability. We demonstrate that this issue can be mitigated by implementing\ntunable couplings for fluxonium's plasmon transitions, meanwhile enabling fast,\nhigh-fidelity gates with passive ZZ suppression. Furthermore, since fluxonium\ntransitions span multiple frequency octaves, we emphasize the importance of\ncarefully designing coupling mechanisms and parameters to suppress residual\ninteractions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T05:31:47Z"}
{"aid":"http://arxiv.org/abs/2504.09895v1","title":"Learning from Reference Answers: Versatile Language Model Alignment\n  without Binary Human Preference Data","summary":"Large language models~(LLMs) are expected to be helpful, harmless, and\nhonest. In various alignment scenarios, such as general human preference,\nsafety, and confidence alignment, binary preference data collection and reward\nmodeling are resource-intensive but necessary for human preference\ntransferring. In this work, we explore using the similarity between sampled\ngenerations and high-quality reference answers as an alternative reward\nfunction for LLM alignment. Using similarity as a reward circumvents training\nreward models, and collecting a single reference answer potentially costs less\ntime than constructing binary preference pairs when multiple candidates are\navailable. Specifically, we develop \\textit{RefAlign}, a versatile\nREINFORCE-style alignment algorithm, which is free of reference and reward\nmodels. Instead, RefAlign utilizes BERTScore between sampled generations and\nhigh-quality reference answers as the surrogate reward. Beyond general human\npreference optimization, RefAlign can be readily extended to diverse scenarios,\nsuch as safety and confidence alignment, by incorporating the similarity reward\nwith task-related objectives. In various scenarios, {RefAlign} demonstrates\ncomparable performance to previous alignment methods while offering high\nefficiency.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T05:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.09916v1","title":"Dynamically assisted Klein tunneling in the Furry picture","summary":"One-dimensional scattering of a wave packet of a relativistic fermion under a\ntemporally oscillating electric field superimposed on a potential step is\ndiscussed by using the Furry-picture perturbation theory, where the oscillating\nelectric field is treated as a perturbation. Reflection and transmission\nprobabilities of the wave packet, which in its single-mode limit are consistent\nwith those in the stationary scattering off the potential step alone, are\ninvestigated up to the second order. We show that even in the absence of the\nso-called Klein region, a positive-frequency incoming wave can penetrate the\nnegative-frequency region below the potential step by emitting its energy to\nthe oscillating electric field with a finite tunneling probability.","main_category":"hep-th","categories":"hep-th,quant-ph","published":"2025-04-14T06:25:07Z"}
{"aid":"http://arxiv.org/abs/2504.09922v1","title":"Enhancement and Suppression of Active Particle Movement Due to Membrane\n  Deformations","summary":"Microswimmers and active colloids often move in confined systems, including\nthose involving interfaces. Such interfaces, especially at the microscale, may\ndeform in response to the stresses of the flow created by the active particle.\nWe develop a theoretical framework to analyze the effect of a nearby membrane\ndue to the motion of an active particle whose flow fields are generated by\nforce-free singularities. We demonstrate our result on a particle represented\nby a combination of a force dipole and a source dipole, while the membrane\nresists deformation due to tension and bending rigidity. We find that the\ndeformation either enhances or suppresses the motion of the active particle,\ndepending on its orientation and the relative strengths between the fundamental\nsingularities that describe its flow. Furthermore, the deformation can generate\nmotion in new directions.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-14T06:32:20Z"}
{"aid":"http://arxiv.org/abs/2504.09925v1","title":"FUSION: Fully Integration of Vision-Language Representations for Deep\n  Cross-Modal Understanding","summary":"We introduce FUSION, a family of multimodal large language models (MLLMs)\nwith a fully vision-language alignment and integration paradigm. Unlike\nexisting methods that primarily rely on late-stage modality interaction during\nLLM decoding, our approach achieves deep, dynamic integration throughout the\nentire processing pipeline. To this end, we propose Text-Guided Unified Vision\nEncoding, incorporating textual information in vision encoding to achieve\npixel-level integration. We further design Context-Aware Recursive Alignment\nDecoding that recursively aggregates visual features conditioned on textual\ncontext during decoding, enabling fine-grained, question-level semantic\nintegration. To guide feature mapping and mitigate modality discrepancies, we\ndevelop Dual-Supervised Semantic Mapping Loss. Additionally, we construct a\nSynthesized Language-Driven Question-Answer (QA) dataset through a new data\nsynthesis method, prioritizing high-quality QA pairs to optimize text-guided\nfeature integration. Building on these foundations, we train FUSION at two\nscales-3B, 8B-and demonstrate that our full-modality integration approach\nsignificantly outperforms existing methods with only 630 vision tokens.\nNotably, FUSION 3B surpasses Cambrian-1 8B and Florence-VL 8B on most\nbenchmarks. FUSION 3B continues to outperform Cambrian-1 8B even when limited\nto 300 vision tokens. Our ablation studies show that FUSION outperforms\nLLaVA-NeXT on over half of the benchmarks under same configuration without\ndynamic resolution, highlighting the effectiveness of our approach. We release\nour code, model weights, and dataset. https://github.com/starriver030515/FUSION","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T06:33:29Z"}
{"aid":"http://arxiv.org/abs/2504.09941v1","title":"FedRecon: Missing Modality Reconstruction in Distributed Heterogeneous\n  Environments","summary":"Multimodal data are often incomplete and exhibit Non-Independent and\nIdentically Distributed (Non-IID) characteristics in real-world scenarios.\nThese inherent limitations lead to both modality heterogeneity through partial\nmodality absence and data heterogeneity from distribution divergence, creating\nfundamental challenges for effective federated learning (FL). To address these\ncoupled challenges, we propose FedRecon, the first method targeting\nsimultaneous missing modality reconstruction and Non-IID adaptation in\nmultimodal FL. Our approach first employs a lightweight Multimodal Variational\nAutoencoder (MVAE) to reconstruct missing modalities while preserving\ncross-modal consistency. Distinct from conventional imputation methods, we\nachieve sample-level alignment through a novel distribution mapping mechanism\nthat guarantees both data consistency and completeness. Additionally, we\nintroduce a strategy employing global generator freezing to prevent\ncatastrophic forgetting, which in turn mitigates Non-IID fluctuations.\nExtensive evaluations on multimodal datasets demonstrate FedRecon's superior\nperformance in modality reconstruction under Non-IID conditions, surpassing\nstate-of-the-art methods.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-14T07:04:10Z"}
{"aid":"http://arxiv.org/abs/2504.09943v1","title":"The Tropical Atmosphere of Jupiter - Shallow Weather, Deep Plumes, and\n  Vortices","summary":"Towering storms, swirling clouds, and vortices are the cloud tops\nmanifestation of complex weather systems shaping the atmosphere of Jupiter. We\nuse observations from Juno's MicroWave Radiometer (MWR), the Very Large Array\n(VLA) and the Hubble Space Telescope (HST) to probe for the first time the\ndepth and impact of weather on Jupiter. We use ammonia, the main source of\nopacity at radio wavelengths on Jupiter, as the tracer for the weather by\nfitting ammonia anomalies to the MWR brightness temperature variations. We show\nthat the majority of the weather on Jupiter is confined to regions where the\nclouds are forming. Both the South Equatorial Belt and the Equatorial Zone have\nsurprisingly shallow weather systems (P < 2 bar), and even in the North\nEquatorial Belt most of the ammonia variations is above the water condensation\nlevel (P ~ 6 bar). This confirms that the water condensation layer plays a\ncrucial role in controlling the dynamics and the weather on Jupiter. However,\nthe shallow nature of the weather cannot explain the deep-seated depletion down\nto 30 bar that the Juno mission has revealed. We do find three features,\nhowever, that extend below the water condensation layer: a vortex in the\nnorthern hemisphere reaching down to 30 bar, an ammonia plume down to 20-30\nbars, and the signature of precipitation down to 20 bar. This work highlights\nthe interplay of large-scale processes (vortices, plumes) and small-scale\nprocesses (storms) are responsible for shaping the atmospheric makeup of\nJupiter.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-14T07:09:39Z"}
{"aid":"http://arxiv.org/abs/2504.09952v1","title":"Secrecy and Privacy in Multi-Access Combinatorial Topology","summary":"In this work, we consider the multi-access combinatorial topology with $C$\ncaches where each user accesses a unique set of $r$ caches. For this setup, we\nconsider secrecy, where each user should not know anything about the files it\ndid not request, and demand privacy, where each user's demand must be kept\nprivate from other non-colluding users. We propose a scheme satisfying both\nconditions and derive a lower bound based on cut-set arguments. Also, we prove\nthat our scheme is optimal when $r\\geq C-1$, and it is order-optimal when the\ncache memory size $M$ is greater than or equal to a certain threshold for\n$r<C-1$. When $r=1$, in most of the memory region, our scheme achieves the same\nrate as the one given by the secretive scheme for the dedicated cache setup by\nRavindrakumar et al. ( 'Private Coded Caching,' in \\textit{IEEE Transactions on\nInformation Forensics and Security}, 2018), while satisfying both secrecy and\ndemand privacy conditions.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-14T07:30:03Z"}
{"aid":"http://arxiv.org/abs/2504.09970v1","title":"IsoSEL: Isometric Structural Entropy Learning for Deep Graph Clustering\n  in Hyperbolic Space","summary":"Graph clustering is a longstanding topic in machine learning. In recent\nyears, deep learning methods have achieved encouraging results, but they still\nrequire predefined cluster numbers K, and typically struggle with imbalanced\ngraphs, especially in identifying minority clusters. The limitations motivate\nus to study a challenging yet practical problem: deep graph clustering without\nK considering the imbalance in reality. We approach this problem from a fresh\nperspective of information theory (i.e., structural information). In the\nliterature, structural information has rarely been touched in deep clustering,\nand the classic definition falls short in its discrete formulation, neglecting\nnode attributes and exhibiting prohibitive complexity. In this paper, we first\nestablish a new Differentiable Structural Information, generalizing the\ndiscrete formalism to continuous realm, so that the optimal partitioning tree,\nrevealing the cluster structure, can be created by the gradient\nbackpropagation. Theoretically, we demonstrate its capability in clustering\nwithout requiring K and identifying the minority clusters in imbalanced graphs,\nwhile reducing the time complexity to O(N) w.r.t. the number of nodes.\nSubsequently, we present a novel IsoSEL framework for deep graph clustering,\nwhere we design a hyperbolic neural network to learn the partitioning tree in\nthe Lorentz model of hyperbolic space, and further conduct Lorentz Tree\nContrastive Learning with isometric augmentation. As a result, the partitioning\ntree incorporates node attributes via mutual information maximization, while\nthe cluster assignment is refined by the proposed tree contrastive learning.\nExtensive experiments on five benchmark datasets show the IsoSEL outperforms 14\nrecent baselines by an average of +1.3% in NMI.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T08:21:41Z"}
{"aid":"http://arxiv.org/abs/2504.09977v1","title":"EthCluster: An Unsupervised Static Analysis Method for Ethereum Smart\n  Contract","summary":"Poorly designed smart contracts are particularly vulnerable, as they may\nallow attackers to exploit weaknesses and steal the virtual currency they\nmanage. In this study, we train a model using unsupervised learning to identify\nvulnerabilities in the Solidity source code of Ethereum smart contracts. To\naddress the challenges associated with real-world smart contracts, our training\ndata is derived from actual vulnerability samples obtained from datasets such\nas SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us to\ndevelop a robust unsupervised static analysis method for detecting five\nspecific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency,\ntx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms to\nidentify outliers, which are subsequently classified as vulnerable smart\ncontracts.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T08:36:21Z"}
{"aid":"http://arxiv.org/abs/2504.09983v1","title":"DeepCompile: A Compiler-Driven Approach to Optimizing Distributed Deep\n  Learning Training","summary":"The increasing scale of deep learning models has led to the development of\nvarious parallelization strategies for distributed training across\naccelerators. For example, fully sharded approaches like DeepSpeed ZeRO-3 and\nFSDP partition the parameters of each layer across multiple GPUs and gather\nthem through communication when needed. These methods rely on optimizations\nsuch as prefetching, which initiates communication early to overlap it with\ncomputation and reduce communication overhead, and unsharding, which retains as\nmany parameters in their unsharded form as possible to reduce communication\nvolume. Although the timing of prefetching should be adjusted in response to\ndynamic memory usage during execution, these systems lack the flexibility to\ncontrol it, which limits the benefits of prefetching. Moreover, they cannot\nanticipate how memory usage will change after prefetching is applied, making it\ndifficult to combine it effectively with other optimizations such as\nunsharding. We present DeepCompile, which compiles user-defined models into\ncomputation graphs and applies a sequence of profiling-guided optimization\npasses for distributed training. Taking dynamic memory usage into account,\nthese passes flexibly insert, reorder, or remove operations to improve\ncommunication-computation overlap, reduce memory pressure, and coordinate\nmultiple optimizations in a unified manner. To evaluate the effectiveness of\nthis design, we implemented a fully sharded approach like ZeRO-3 and FSDP on\ntop of DeepCompile, along with three optimizations: proactive prefetching,\nselective unsharding, and adaptive offloading. We evaluate DeepCompile on the\ntraining of Llama 3 70B and Mixtral 8x7B MoE models. DeepCompile achieves up to\n1.28x and 1.54x performance improvements over ZeRO-3 and FSDP baselines,\nrespectively, and up to a 7.01x throughput increase with limited GPU resources,\nusing offloading.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:51:23Z"}
{"aid":"http://arxiv.org/abs/2504.09984v1","title":"On Precomputation and Caching in Information Retrieval Experiments with\n  Pipeline Architectures","summary":"Modern information retrieval systems often rely on multiple components\nexecuted in a pipeline. In a research setting, this can lead to substantial\nredundant computations (e.g., retrieving the same query multiple times for\nevaluating different downstream rerankers). To overcome this, researchers take\ncached \"result\" files as inputs, which represent the output of another\npipeline. However, these result files can be brittle and can cause a disconnect\nbetween the conceptual design of the pipeline and its logical implementation.\nTo overcome both the redundancy problem (when executing complete pipelines) and\nthe disconnect problem (when relying on intermediate result files), we describe\nour recent efforts to improve the caching capabilities in the open-source\nPyTerrier IR platform. We focus on two main directions: (1) automatic implicit\ncaching of common pipeline prefixes when comparing systems and (2) explicit\ncaching of operations through a new extension package, pyterrier-caching. These\napproaches allow for the best of both worlds: pipelines can be fully expressed\nend-to-end, while also avoiding redundant computations between pipelines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T08:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.09986v1","title":"Diversity Analysis for Indoor Terahertz Communication Systems under\n  Small-Scale Fading","summary":"Harnessing diversity is fundamental to wireless communication systems,\nparticularly in the terahertz (THz) band, where severe path loss and\nsmall-scale fading pose significant challenges to system reliability and\nperformance. In this paper, we present a comprehensive diversity analysis for\nindoor THz communication systems, accounting for the combined effects of path\nloss and small-scale fading, with the latter modeled as an $\\alpha-\\mu$\ndistribution to reflect THz indoor channel conditions. We derive closed-form\nexpressions for the bit error rate (BER) as a function of the reciprocal of the\nsignal-to-noise ratio (SNR) and propose an asymptotic expression. Furthermore,\nwe validate these expressions through extensive simulations, which show strong\nagreement with the theoretical analysis, confirming the accuracy and robustness\nof the proposed methods. Our results show that the diversity order in THz\nsystems is primarily determined by the combined effects of the number of\nindependent paths, the severity of fading, and the degree of channel frequency\nselectivity, providing clear insights into how diversity gains can be optimized\nin high-frequency wireless networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T08:51:52Z"}
{"aid":"http://arxiv.org/abs/2504.09987v1","title":"Gravitational metamaterials from optical properties of spacetime media","summary":"Gravitational optical properties are here investigated under the hypothesis\nof spherically-symmetric spacetimes behaving as media. To do so, we first\nconsider two different definitions of the refractive index, $n_O$, of a\nspacetime medium and show how to pass from one definition to another by means\nof a coordinate transformation. Accordingly, the corresponding physical role of\n$n_O$ is discussed by virtue of the Misner-Sharp mass and the redshift\ndefinition. Afterwards, we discuss the inclusion of the electromagnetic fields\nand the equivalence with nonlinear effects induced by geometry. Accordingly,\nthe infrared and ultraviolet gravity regimes are thus discussed, obtaining\nbounds from the Solar System, neutron stars and white dwarfs, respectively. To\ndo so, we also investigate the Snell's law and propose how to possibly\ndistinguish regular solutions from black holes. As a consequence of our recipe,\nwe speculate on the existence of \\emph{gravitational metamaterials}, whose\nrefractive index may be negative and explore the corresponding physical\nimplications, remarking that $n_O<0$ may lead to invisible optical properties,\nas light is bent in the opposite direction compared to what occurs in ordinary\ncases. Further, we conjecture that gravitational metamaterials exhibit a\nparticle-like behavior, contributing to dark matter and propose three toy\nmodels, highlighting possible advantages and limitations of their use. Finally,\nwe suggest that such particle-like configurations can be ``dressed\" by\ninteraction, giving rise to \\emph{geometric quasiparticles}. We thus construct\nmodifications of the quantum propagator as due to nonminimal couplings between\ncurvature and external matter-like fields, finding the corresponding effective\nmass through a boson mixing mechanism.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T08:51:56Z"}
{"aid":"http://arxiv.org/abs/2504.09994v1","title":"Physical Scales Matter: The Role of Receptive Fields and Advection in\n  Satellite-Based Thunderstorm Nowcasting with Convolutional Neural Networks","summary":"The focus of nowcasting development is transitioning from physically\nmotivated advection methods to purely data-driven Machine Learning (ML)\napproaches. Nevertheless, recent work indicates that incorporating advection\ninto the ML value chain has improved skill for radar-based precipitation\nnowcasts. However, the generality of this approach and the underlying causes\nremain unexplored. This study investigates the generality by probing the\napproach on satellite-based thunderstorm nowcasts for the first time. Resorting\nto a scale argument, we then put forth an explanation when and why skill\nimprovements can be expected. In essence, advection guarantees that\nthunderstorm patterns relevant for nowcasting are contained in the receptive\nfield at long lead times. To test our hypotheses, we train ResU-Nets solving\nsegmentation tasks with lightning observations as ground truth. The input of\nthe Baseline Neural Network (BNN) are short time series of multispectral\nsatellite imagery and lightning observations, whereas the Advection-Informed\nNeural Network (AINN) additionally receives the Lagrangian persistence nowcast\nof all input channels at the desired lead time. Overall, we find only a minor\nskill improvement of the AINN over the BNN when considering fully averaged\nscores. However, assessing skill conditioned on lead time and wind speed, we\ndemonstrate that our scale argument correctly predicts the onset of skill\nimprovement of the AINN over the BNN after 2h lead time. We confirm that\ngenerally advection becomes gradually more important with longer lead times and\nhigher wind speeds. Our work accentuates the importance of considering and\nincorporating the underlying physical scales when designing ML based\nforecasting models.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.LG","published":"2025-04-14T08:57:59Z"}
{"aid":"http://arxiv.org/abs/2504.10000v1","title":"Do We Really Need Curated Malicious Data for Safety Alignment in\n  Multi-modal Large Language Models?","summary":"Multi-modal large language models (MLLMs) have made significant progress, yet\ntheir safety alignment remains limited. Typically, current open-source MLLMs\nrely on the alignment inherited from their language module to avoid harmful\ngenerations. However, the lack of safety measures specifically designed for\nmulti-modal inputs creates an alignment gap, leaving MLLMs vulnerable to\nvision-domain attacks such as typographic manipulation. Current methods utilize\na carefully designed safety dataset to enhance model defense capability, while\nthe specific knowledge or patterns acquired from the high-quality dataset\nremain unclear. Through comparison experiments, we find that the alignment gap\nprimarily arises from data distribution biases, while image content, response\nquality, or the contrastive behavior of the dataset makes little contribution\nto boosting multi-modal safety. To further investigate this and identify the\nkey factors in improving MLLM safety, we propose finetuning MLLMs on a small\nset of benign instruct-following data with responses replaced by simple, clear\nrejection sentences. Experiments show that, without the need for\nlabor-intensive collection of high-quality malicious data, model safety can\nstill be significantly improved, as long as a specific fraction of rejection\ndata exists in the finetuning set, indicating the security alignment is not\nlost but rather obscured during multi-modal pretraining or instruction\nfinetuning. Simply correcting the underlying data bias could narrow the safety\ngap in the vision domain.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.CL,cs.CV,cs.LG","published":"2025-04-14T09:03:51Z"}
{"aid":"http://arxiv.org/abs/2504.10003v1","title":"NaviDiffusor: Cost-Guided Diffusion Model for Visual Navigation","summary":"Visual navigation, a fundamental challenge in mobile robotics, demands\nversatile policies to handle diverse environments. Classical methods leverage\ngeometric solutions to minimize specific costs, offering adaptability to new\nscenarios but are prone to system errors due to their multi-modular design and\nreliance on hand-crafted rules. Learning-based methods, while achieving high\nplanning success rates, face difficulties in generalizing to unseen\nenvironments beyond the training data and often require extensive training. To\naddress these limitations, we propose a hybrid approach that combines the\nstrengths of learning-based methods and classical approaches for RGB-only\nvisual navigation. Our method first trains a conditional diffusion model on\ndiverse path-RGB observation pairs. During inference, it integrates the\ngradients of differentiable scene-specific and task-level costs, guiding the\ndiffusion model to generate valid paths that meet the constraints. This\napproach alleviates the need for retraining, offering a plug-and-play solution.\nExtensive experiments in both indoor and outdoor settings, across simulated and\nreal-world scenarios, demonstrate zero-shot transfer capability of our\napproach, achieving higher success rates and fewer collisions compared to\nbaseline methods. Code will be released at\nhttps://github.com/SYSU-RoboticsLab/NaviD.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-14T09:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.10011v1","title":"KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing\n  DMPs for Occlusion-Rich Tasks","summary":"Dynamic Movement Primitives (DMPs) provide a flexible framework wherein\nsmooth robotic motions are encoded into modular parameters. However, they face\nchallenges in integrating multimodal inputs commonly used in robotics like\nvision and language into their framework. To fully maximize DMPs' potential,\nenabling them to handle multimodal inputs is essential. In addition, we also\naim to extend DMPs' capability to handle object-focused tasks requiring\none-shot complex motion generation, as observation occlusion could easily\nhappen mid-execution in such tasks (e.g., knife occlusion in cake icing, hand\nocclusion in dough kneading, etc.). A promising approach is to leverage\nVision-Language Models (VLMs), which process multimodal data and can grasp\nhigh-level concepts. However, they typically lack enough knowledge and\ncapabilities to directly infer low-level motion details and instead only serve\nas a bridge between high-level instructions and low-level control. To address\nthis limitation, we propose Keyword Labeled Primitive Selection and Keypoint\nPairs Generation Guided Movement Primitives (KeyMPs), a framework that combines\nVLMs with sequencing of DMPs. KeyMPs use VLMs' high-level reasoning capability\nto select a reference primitive through keyword labeled primitive selection and\nVLMs' spatial awareness to generate spatial scaling parameters used for\nsequencing DMPs by generalizing the overall motion through keypoint pairs\ngeneration, which together enable one-shot vision-language guided motion\ngeneration that aligns with the intent expressed in the multimodal input. We\nvalidate our approach through an occlusion-rich manipulation task, specifically\nobject cutting experiments in both simulated and real-world environments,\ndemonstrating superior performance over other DMP-based methods that integrate\nVLMs support.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T09:16:58Z"}
{"aid":"http://arxiv.org/abs/2504.10012v1","title":"EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting","summary":"While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view\nsynthesis, its performance degrades with motion blur. In scenarios with rapid\nmotion or low-light conditions, existing RGB-based deblurring methods struggle\nto model camera pose and radiance changes during exposure, reducing\nreconstruction accuracy. Event cameras, capturing continuous brightness changes\nduring exposure, can effectively assist in modeling motion blur and improving\nreconstruction quality. Therefore, we propose Event-driven Bundle Adjusted\nDeblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D\nGaussians from event streams and severely blurred images. This method jointly\nlearns the parameters of these Gaussians while recovering camera motion\ntrajectories during exposure time. Specifically, we first construct a blur loss\nfunction by synthesizing multiple latent sharp images during the exposure time,\nminimizing the difference between real and synthesized blurred images. Then we\nuse event stream to supervise the light intensity changes between latent sharp\nimages at any time within the exposure period, supplementing the light\nintensity dynamic changes lost in RGB images. Furthermore, we optimize the\nlatent sharp images at intermediate exposure times based on the event-based\ndouble integral (EDI) prior, applying consistency constraints to enhance the\ndetails and texture information of the reconstructed images. Extensive\nexperiments on synthetic and real-world datasets show that EBAD-Gaussian can\nachieve high-quality 3D scene reconstruction under the condition of blurred\nimages and event stream inputs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:17:00Z"}
{"aid":"http://arxiv.org/abs/2504.10014v1","title":"Air Quality Prediction with A Meteorology-Guided Modality-Decoupled\n  Spatio-Temporal Network","summary":"Air quality prediction plays a crucial role in public health and\nenvironmental protection. Accurate air quality prediction is a complex\nmultivariate spatiotemporal problem, that involves interactions across temporal\npatterns, pollutant correlations, spatial station dependencies, and\nparticularly meteorological influences that govern pollutant dispersion and\nchemical transformations. Existing works underestimate the critical role of\natmospheric conditions in air quality prediction and neglect comprehensive\nmeteorological data utilization, thereby impairing the modeling of dynamic\ninterdependencies between air quality and meteorological data. To overcome\nthis, we propose MDSTNet, an encoder-decoder framework that explicitly models\nair quality observations and atmospheric conditions as distinct modalities,\nintegrating multi-pressure-level meteorological data and weather forecasts to\ncapture atmosphere-pollution dependencies for prediction. Meantime, we\nconstruct ChinaAirNet, the first nationwide dataset combining air quality\nrecords with multi-pressure-level meteorological observations. Experimental\nresults on ChinaAirNet demonstrate MDSTNet's superiority, substantially\nreducing 48-hour prediction errors by 17.54\\% compared to the state-of-the-art\nmodel. The source code and dataset will be available on github.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-14T09:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.10015v1","title":"Many-Body Colloidal Dynamics under Stochastic Resetting: Competing\n  Effects of Particle Interactions on the Steady State Distribution","summary":"The random arrest of the diffusion of a single particle and its return to its\norigin has served as the paradigmatic example of a large variety of processes\nundergoing stochastic resetting. While the implications and applications of\nstochastic resetting for a single particle are well understood, less is known\nabout resetting of many interacting particles. In this study, we experimentally\nand numerically investigate a system of six colloidal particles undergoing two\ntypes of stochastic resetting protocols: global resetting, where all particles\nare returned to their origin simultaneously, and local resetting, where\nparticles are reset one at a time. Our particles interact mainly through\nhard-core repulsion and hydrodynamic flows. We find that the most substantial\neffect of interparticle interactions is observed for local resetting,\nspecifically when particles are physically dragged to the origin. In this case,\nhard-core repulsion broadens the steady-state distribution, while hydrodynamic\ninteractions significantly narrow the distribution. The combination results in\na steady-state distribution that is wider compared to that of a single particle\nsystem both for global and local resetting protocols.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-14T09:18:37Z"}
{"aid":"http://arxiv.org/abs/2504.10016v1","title":"Quantifying Privacy Leakage in Split Inference via Fisher-Approximated\n  Shannon Information Analysis","summary":"Split inference (SI) partitions deep neural networks into distributed\nsub-models, enabling privacy-preserving collaborative learning. Nevertheless,\nit remains vulnerable to Data Reconstruction Attacks (DRAs), wherein\nadversaries exploit exposed smashed data to reconstruct raw inputs. Despite\nextensive research on adversarial attack-defense games, a shortfall remains in\nthe fundamental analysis of privacy risks. This paper establishes a theoretical\nframework for privacy leakage quantification using information theory, defining\nit as the adversary's certainty and deriving both average-case and worst-case\nerror bounds. We introduce Fisher-approximated Shannon information (FSInfo), a\nnovel privacy metric utilizing Fisher Information (FI) for operational privacy\nleakage computation. We empirically show that our privacy metric correlates\nwell with empirical attacks and investigate some of the factors that affect\nprivacy leakage, namely the data distribution, model size, and overfitting.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T09:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.10017v1","title":"Bifurcation Theory for a Class of Periodic Superlinear Problems","summary":"We analyze, mainly using bifurcation methods, an elliptic superlinear problem\nin one-dimension with periodic boundary conditions. One of the main novelties\nis that we follow for the first time a bifurcation approach, relying on a\nLyapunov-Schmidt reduction and some recent global bifurcation results, that\nallows us to study the local and global structure of non-trivial solutions at\nbifurcation points where the linearized operator has a two-dimensional kernel.\nIndeed, at such points the classical tools in bifurcation theory, like the\nCrandall-Rabinowitz theorem or some generalizations of it, cannot be applied\nbecause the multiplicity of the eigenvalues is not odd, and a new approach is\nrequired. We apply this analysis to specific examples, obtaining new existence\nand multiplicity results for the considered periodic problems, going beyond the\ninformation variational and fixed point methods like Poincar\\'e-Birkhoff\ntheorem can provide.","main_category":"math.CA","categories":"math.CA,math.DS,math.FA","published":"2025-04-14T09:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.10039v1","title":"Investigating the Role of Bilateral Symmetry for Inpainting Brain MRI","summary":"Inpainting has recently emerged as a valuable and interesting technology to\nemploy in the analysis of medical imaging data, in particular brain MRI. A wide\nvariety of methodologies for inpainting MRI have been proposed and demonstrated\non tasks including anomaly detection. In this work we investigate the\nstatistical relationship between inpainted brain structures and the amount of\nsubject-specific conditioning information, i.e. the other areas of the image\nthat are masked. In particular, we analyse the distribution of inpainting\nresults when masking additional regions of the image, specifically the\ncontra-lateral structure. This allows us to elucidate where in the brain the\nmodel is drawing information from, and in particular, what is the importance of\nhemispherical symmetry? Our experiments interrogate a diffusion inpainting\nmodel through analysing the inpainting of subcortical brain structures based on\nintensity and estimated area change. We demonstrate that some structures show a\nstrong influence of symmetry in the conditioning of the inpainting process.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-14T09:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.10064v1","title":"Parametric Near-Field MMSE Channel Estimation for sub-THz XL-MIMO\n  Systems","summary":"Accurate channel estimation is essential for reliable communication in\nsub-THz extremely large (XL) MIMO systems. Deploying XL-MIMO in high-frequency\nbands not only increases the number of antennas, but also fundamentally alters\nchannel propagation characteristics, placing the user equipments (UE) in the\nradiative near-field of the base station. This paper proposes a parametric\nestimation method using the multiple signal classification (MUSIC) algorithm to\nextract UE location data from uplink pilot signals. These parameters are used\nto reconstruct the spatial correlation matrix, followed by an approximation of\nthe minimum mean square error (MMSE) channel estimator. Numerical results show\nthat the proposed method outperforms the least-squares (LS) estimator in terms\nof the normalized mean-square error (NMSE), even without prior UE location\nknowledge.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T10:08:15Z"}
{"aid":"http://arxiv.org/abs/2504.10094v1","title":"Local-in-time well-posedness for the regular solution to the 2D full\n  compressible Navier-Stokes equations with degenerate viscosities and heat\n  conductivity","summary":"This paper considers the two-dimensional Cauchy problem of the full\ncompressible Navier-Stokes equations with far-field vacuum in $\\mathbb{R}^2$,\nwhere the viscosity and heat-conductivity coefficients depend on the absolute\ntemperature $\\theta$ in the form of $\\theta^\\nu$ with $\\nu>0$. Due to the\nappearance of the vacuum, the momentum equation are both degenerate in the time\nevolution and spatial dissipation, which makes the study on the well-posedness\nchallenged. By establishing some new singular-weighted (negative powers of the\ndensity $\\rho$) estimates of the solution, we establish the local-in-time\nwell-posedness of the regular solution with far-field vacuum in terms of\n$\\rho$, the velocity $u$ and the entropy $S$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T10:58:53Z"}
{"aid":"http://arxiv.org/abs/2504.10104v1","title":"Automated next-to-leading order QCD and electroweak predictions of\n  photon-photon processes in ultraperipheral collisions","summary":"We present automated next-to-leading order QCD and/or electroweak (EW)\npredictions for photon-photon processes in ultraperipheral high-energy\ncollisions of protons and ions, extending the capabilities of the\n\\textsc{MadGraph5\\_aMC@NLO} framework together in combination with the\n\\ttt{gamma-UPC} code. Key aspects of this extension are discussed. We compute\nQCD and/or EW quantum corrections for several phenomenologically interesting\nprocesses at LHC and FCC-hh energies.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-14T11:13:50Z"}
{"aid":"http://arxiv.org/abs/2504.10110v1","title":"Eigengap Sparsity for Covariance Parsimony","summary":"Covariance estimation is a central problem in statistics. An important issue\nis that there are rarely enough samples $n$ to accurately estimate the $p (p+1)\n/ 2$ coefficients in dimension $p$. Parsimonious covariance models are\ntherefore preferred, but the discrete nature of model selection makes inference\ncomputationally challenging. In this paper, we propose a relaxation of\ncovariance parsimony termed \"eigengap sparsity\" and motivated by the good\naccuracy-parsimony tradeoff of eigenvalue-equalization in covariance matrices.\nThis new penalty can be included in a penalized-likelihood framework that we\npropose to solve with a projected gradient descent on a monotone cone. The\nalgorithm turns out to resemble an isotonic regression of mutually-attracted\nsample eigenvalues, drawing an interesting link between covariance parsimony\nand shrinkage.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-14T11:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.10112v1","title":"Benchmarking Practices in LLM-driven Offensive Security: Testbeds,\n  Metrics, and Experiment Design","summary":"Large Language Models (LLMs) have emerged as a powerful approach for driving\noffensive penetration-testing tooling. This paper analyzes the methodology and\nbenchmarking practices used for evaluating Large Language Model (LLM)-driven\nattacks, focusing on offensive uses of LLMs in cybersecurity. We review 16\nresearch papers detailing 15 prototypes and their respective testbeds.\n  We detail our findings and provide actionable recommendations for future\nresearch, emphasizing the importance of extending existing testbeds, creating\nbaselines, and including comprehensive metrics and qualitative analysis. We\nalso note the distinction between security research and practice, suggesting\nthat CTF-based challenges may not fully represent real-world penetration\ntesting scenarios.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-14T11:21:33Z"}
{"aid":"http://arxiv.org/abs/2504.10117v1","title":"AGO: Adaptive Grounding for Open World 3D Occupancy Prediction","summary":"Open-world 3D semantic occupancy prediction aims to generate a voxelized 3D\nrepresentation from sensor inputs while recognizing both known and unknown\nobjects. Transferring open-vocabulary knowledge from vision-language models\n(VLMs) offers a promising direction but remains challenging. However, methods\nbased on VLM-derived 2D pseudo-labels with traditional supervision are limited\nby a predefined label space and lack general prediction capabilities. Direct\nalignment with pretrained image embeddings, on the other hand, fails to achieve\nreliable performance due to often inconsistent image and text representations\nin VLMs. To address these challenges, we propose AGO, a novel 3D occupancy\nprediction framework with adaptive grounding to handle diverse open-world\nscenarios. AGO first encodes surrounding images and class prompts into 3D and\ntext embeddings, respectively, leveraging similarity-based grounding training\nwith 3D pseudo-labels. Additionally, a modality adapter maps 3D embeddings into\na space aligned with VLM-derived image embeddings, reducing modality gaps.\nExperiments on Occ3D-nuScenes show that AGO improves unknown object prediction\nin zero-shot and few-shot transfer while achieving state-of-the-art\nclosed-world self-supervised performance, surpassing prior methods by 4.09\nmIoU.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.10118v1","title":"Stochastic Multigrid Minimization for Ptychographic Phase Retrieval","summary":"We propose a novel stochastic multigrid minimization method for ptychographic\nphase retrieval. In our formulation, the challenging nonconvex and ill-posed\ninverse problem is recast as the iterative minimization of a quadratic\nsurrogate model that majorizes the original objective function. Our general\nframework encompasses the Ptychographic Iterative Engine (PIE) family of\nalgorithms. By efficiently solving the surrogate problem using a multigrid\nmethod, our approach delivers significant improvements in both convergence\nspeed and reconstruction quality compared with conventional PIE techniques.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-14T11:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.10126v1","title":"Polarimetry of exoplanet-exomoon systems","summary":"We investigated the potential of polarimetric observations in the optical\nwavelength range for the detection of exomoons and the characterization of\nexoplanet-exomoon systems. Using the three-dimensional Monte Carlo radiative\ntransfer code POLARIS, we calculated flux and polarization phase curves of\nEarth-like exoplanets with a satellite similar to Earth's moon. Of particular\ninterest are mutual events, when one of the two bodies casts a shadow on the\nother or transits in front of it. We find that the signatures of mutual events\nin the polarization phase curve show significant variations depending on the\ninclination of the lunar orbit. If the planet-satellite pair is spatially\nresolved from the star but the satellite is spatially unresolved, the increase\nin the degree of polarization during a transit of the exomoon in front of the\ncenter of the exoplanet reaches $2.7\\%$ in our model system near quadrature.\nHowever, the change is less than $0.5\\%$ if the orbit of the exomoon is\ninclined such that it transits the planet noncentrally at the same phase\nangles. The influence of an exomoon on the polarization phase curve of an\nexoplanet-exomoon system is dependent on the lunar polarization phase curve.\nObservations of full eclipses and occultations of the exomoon allow the\ndetermination of separate polarization phase curves for the two bodies.\nInformation about the lunar orbital inclination can be obtained with\npolarimetric observations of shadows or transits. Measuring the influence of\nlarge satellites not only on the total flux, but also on the polarization of\nthe reflected stellar radiation during mutual events thus facilitates the\nprediction of future mutual events and the verification of exomoon candidates.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-14T11:34:10Z"}
{"aid":"http://arxiv.org/abs/2504.10129v1","title":"Quasi-Irreducibility of Nonnegative Biquadratic Tensors","summary":"While the adjacency tensor of a bipartite 2-graph is a nonnegative\nbiquadratic tensor, it is inherently reducible. To address this limitation, we\nintroduce the concept of quasi-irreducibility in this paper. The adjacency\ntensor of a bipartite 2-graph is quasi-irreducible if that bipartite 2-graph is\nnot bi-separable. This new concept reveals important spectral properties:\nalthough all M$^+$-eigenvalues are M$^{++}$-eigenvalues for irreducible\nnonnegative biquadratic tensors, the M$^+$-eigenvalues of a quasi-irreducible\nnonnegative biquadratic tensor can be either M$^0$-eigenvalues or\nM$^{++}$-eigenvalues. Furthermore, we establish a max-min theorem for the\nM-spectral radius of a nonnegative biquadratic tensor.","main_category":"math.SP","categories":"math.SP","published":"2025-04-14T11:37:10Z"}
{"aid":"http://arxiv.org/abs/2504.10130v1","title":"A parametrized spin-precessing inspiral-merger-ringdown waveform model\n  for tests of general relativity","summary":"The coalescence of binary black holes (BBHs) provides a unique arena to test\ngeneral relativity (GR) in the dynamical, strong-field regime. To this end, we\npresent pSEOBNRv5PHM, a parametrized, multipolar, spin-precessing waveform\nmodel for BBHs in quasicircular orbits, built within the effective-one-body\nformalism. Compared to its predecessor, pSEOBNRv4HM, our model introduces\nparametrized deviations from GR not only in the plunge-merger-ringdown stages,\nbut also in the inspiral phase through modifications to the conservative\ndynamics. Additionally, it incorporates, for the first time, spin-precession\neffects. The free deviation parameters can be used to perform null tests of GR\nusing current and future gravitational-wave observations. We validate\npSEOBNRv5PHM through Bayesian parameter estimation, focusing on the\nquasinormal-mode frequency and damping time of the $(\\ell,m,n) = (2,2,0)$ mode.\nOur analysis of synthetic signals from numerical-relativity (NR) simulations of\nhighly precessing BH mergers shows that, while pSEOBNRv5PHM correctly recovers\nconsistency with GR, neglecting spin precession can lead to false detections of\ndeviations from GR even at current detector sensitivity. Conversely, when\nanalyzing a synthetic signal from a NR simulation of a binary boson-star\nmerger, the model successfully identifies a deviation from a GR BBH signal.\nFinally, we reanalyze 12 events from the third Gravitational-Wave Transient\nCatalog. Using a hierarchical combination of these events, we constrain\nfractional deviations in the frequency and damping time of the $(2,2,0)$\nquasinormal-mode to $\\delta f_{220}=0.00_{-0.06}^{+0.06}$ and $\\delta\n\\tau_{220}=0.15_{-0.24}^{+0.26}$ at 90% credibility. These results are\nconsistent with those from the LIGO-Virgo-KAGRA Collaboration, which did not\naccount for spin-precession effects.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T11:37:21Z"}
{"aid":"http://arxiv.org/abs/2504.10145v1","title":"Estimating the dense gas mass of molecular clouds using spatially\n  unresolved 3 mm line observations","summary":"We aim to develop a new method to infer the sub-beam probability density\nfunction (PDF) of H2 column densities and the dense gas mass within molecular\nclouds using spatially unresolved observations of molecular emission lines in\nthe 3 mm band. We model spatially unresolved line integrated intensity\nmeasurements as the average of an emission function weighted by the sub-beam\ncolumn density PDF. The emission function, which expresses the line integrated\nintensity as a function of the gas column density, is an empirical fit to high\nresolution (< 0.05 pc) multi-line observations of the Orion B molecular cloud.\nThe column density PDF is assumed to be parametric, composed of a lognormal\ndistribution at moderate column densities and a power law distribution at\nhigher column densities. To estimate the sub-beam column density PDF, the\nemission model is combined with a Bayesian inversion algorithm (the Beetroots\ncode), which takes account of thermal noise and calibration errors. We validate\nour method by demonstrating that it recovers the true column density PDF of the\nOrion B cloud, reproducing the observed emission line integrated intensities.\nWe apply the method to 12CO(J=1-0), 13CO(J=1-0), C18O(J=1-0), HCN(J=1-0),\nHCO+(J=1-0) and N2H+(J=1-0) observations of a 700 x 700 pc2 field of view (FoV)\nin the nearby galaxy M51. On average, the model reproduces the observed\nintensities within 30%. The column density PDFs obtained for the spiral arm\nregion within our test FoV are dominated by a power-law tail at high column\ndensities, with slopes that are consistent with gravitational collapse. Outside\nthe spiral arm, the column density PDFs are predominantly lognormal, consistent\nwith supersonic isothermal turbulence. We calculate the mass associated with\nthe powerlaw tail of the column density PDFs and observe a strong, linear\ncorrelation between this mass and the 24$\\mu$m surface brightness.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.IM","published":"2025-04-14T11:56:40Z"}
{"aid":"http://arxiv.org/abs/2504.10166v1","title":"Fact-Checking with Contextual Narratives: Leveraging Retrieval-Augmented\n  LLMs for Social Media Analysis","summary":"We propose CRAVE (Cluster-based Retrieval Augmented Verification with\nExplanation); a novel framework that integrates retrieval-augmented Large\nLanguage Models (LLMs) with clustering techniques to address fact-checking\nchallenges on social media. CRAVE automatically retrieves multimodal evidence\nfrom diverse, often contradictory, sources. Evidence is clustered into coherent\nnarratives, and evaluated via an LLM-based judge to deliver fact-checking\nverdicts explained by evidence summaries. By synthesizing evidence from both\ntext and image modalities and incorporating agent-based refinement, CRAVE\nensures consistency and diversity in evidence representation. Comprehensive\nexperiments demonstrate CRAVE's efficacy in retrieval precision, clustering\nquality, and judgment accuracy, showcasing its potential as a robust\ndecision-support tool for fact-checkers.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-14T12:21:27Z"}
{"aid":"http://arxiv.org/abs/2504.10170v1","title":"Axion Mixing in the String Axiverse","summary":"The string axiverse presents a fascinating and complex landscape for axion\nphysics. In this work, we study axion mass mixing within the type IIB string\naxiverse, focusing specifically on the LARGE volume scenario (LVS) axiverse.\nThe LVS axiverse necessitates at least two axions to ensure the presence of\nboth a QCD axion candidate and at least one additional axion-like particle\n(ALP). This study presents the first systematic exploration of axion mass\nmixing in scenarios involving more than two axions. The maximal mixing occurs\nwhen the masses of all ALPs are smaller than the zero-temperature mass of the\nQCD axion, with no two ALP masses being equal, and when the decay constants of\nall ALPs are simultaneously either smaller or larger than the decay constant of\nthe QCD axion. Additionally, the transfer of axion energy density ultimately\ntakes place only between the two axions with the closest masses. These findings\nprovide critical insights into axion dynamics not only within type IIB string\naxiverse models but also in broader multi-axion mixing frameworks. The\npotential cosmological implications of axion mass mixing are also addressed at\nthe end. Our work contributes to the understanding of axion physics in string\ntheory.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-14T12:24:46Z"}
{"aid":"http://arxiv.org/abs/2504.10178v1","title":"MSCoT: Structured Chain-of-Thought Generation for Multiple Programming\n  Languages","summary":"With the rapid development of code intelligence, the application of multiple\nprogramming languages is becoming increasingly widespread. However, most\nexisting code generation models mainly focus on a single or a few programming\nlanguages, resulting in unsatisfactory performance in a multilingual\nenvironment. Chain-of-Thought (CoT) reasoning can significantly improve the\nperformance of the model without the need for retraining or fine-tuning the\ncode generation model by reasonably decomposing complex code generation tasks\ninto multiple subtasks and gradually deriving solutions for each subtask.\nNevertheless, the existing CoT generation methods mainly concentrate on Python\ncode, and the performance on other programming languages remains unclear. To\nfill this gap, we first constructed a CoT generation dataset for 12 programming\nlanguages through multi-agent technology. On this basis, we proposed a CoT\ngeneration method MSCoT applicable to multiple programming languages. By\nintroducing CoT into the code generation large model, the performance of the\ncode generation large model in a multilingual environment can be improved.\nThrough large-scale empirical research, we compared the generalization\nabilities of MSCoT and the existing CoT generation methods on multiple\nprogramming languages and proved the effectiveness of MSCoT for multiple\nprogramming languages. In addition, we also designed a human study to prove the\nquality of the CoT generated by MSCoT. Finally, we opensourced the model and\ndataset of MSCoT to promote the research on CoT generation for multiple\nprogramming languages.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-14T12:30:47Z"}
{"aid":"http://arxiv.org/abs/2504.10183v1","title":"Strong decays of singly heavy baryons","summary":"More and more excited baryons have been reported experimentally, but many\nproperties are still unclear. This work attempts to simultaneously study the\nmasses and strong decay widths of some singly heavy baryons, in order to\nprovide possible quantum numbers for these states. The chiral quark model and\nthe $^{3}P_{0}$ decay model are employed to calculate the masses and decay\nwidths of $\\Lambda_{c(b)}$ and $\\Sigma_{c(b)}$ baryons for all quantum numbers\nwith $2S$, $1P$, and $2P$ waves. We considered not only two-body strong decays\nbut also the influence of three-body decays. Our calculations show that: (i)\nFor states with experimentally determined quantum numbers, such as\n$\\Lambda_c(2595)$, $\\Lambda_c(2625)$, $\\Lambda_b(5912)$ and $\\Lambda_b(5920)$,\nthe results are consistent with experimental data and the conclusions of most\ntheoretical studies. (ii) For states whose quantum numbers have not yet been\nfully determined experimentally, we provide possible interpretations. For\nexample, our calculations tend to interpret $\\Lambda_c(2910)$ is interpreted as\na $J^P=\\frac{3}{2}^-$ state with 1P-wave $\\rho$-mode or a $J^P=\\frac{1}{2}^-$\nstate with 2P wave $\\lambda$-mode. $\\Lambda_c(2940)$ can be interpreted as the\n$J^P=\\frac{3}{2}^-$ state with 2P-wave $\\lambda$-mode. For $\\Lambda_c(2860)$,\nwe offer a different interpretation, proposing that its mass and width closely\nmatch those of a 2P-wave $J^P=\\frac{1}{2}^{-}$ state. It is hoped that our\ncalculations can provide valuable information for the experimental and\ntheoretical studies of heavy baryons.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-th","published":"2025-04-14T12:37:20Z"}
{"aid":"http://arxiv.org/abs/2504.10189v1","title":"Topological exciton bands and many-body exciton phases in transition\n  metal dichalcogenide trilayer heterostructures","summary":"Twisted multilayer transition metal dichalcogenides (TMDs) are a promising\nplatform for realizing topological exciton phases. Here we propose that twisted\nTMD heterotrilayers WX$_2$/MX$_2$/WX$_2$ with layer symmetry represents a\nrealistic system for realizing topological exciton bands and interesting\nmany-body excitonic phases, simply by tuning the twist angle. These symmetric\nheterotrilayers form a type-II band alignment, where the electrons are confined\nin the middle layer and holes are distributed among the outer two layers, for\nthe lowest energy excitons. The outer two layers are then rotated at different\ncenters by opposite angles, forming a helical structure. Interlayer excitons\nwith opposite dipoles are hybridized by the coupling between outer two layers,\nresulting in topological moir\\'e exciton bands. Furthermore, by constructing a\nthree-orbital tight-binding model, we map the many-body phase diagram of\ninteracting dipolar and quadrupolar excitons at different twist angles and\nexciton densities and reveal the existence of sublattice-dependent staggered\nsuperfluid and Mott insulator phases. The recent experimental observation of\nquadrupolar excitons in symmetric heterotrilayers brings the intriguing phases\npredicted in this study within immediate experimental reach.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T12:46:52Z"}
{"aid":"http://arxiv.org/abs/2504.10195v1","title":"Simulation of TOPCon/PERC Hybrid Bottom Structure for Perovskite/Silicon\n  Tandem Solar Cells using Quokka3","summary":"This work emphasizes the potential of perovskite/silicon tandem solar cells\nfor increased power conversion efficiencies. By employing crystalline silicon\n(c-Si) as the bottom cell, particularly with p-type PERC technology, there are\ncost-effective and advantageous physical properties. However, traditional\nphosphorus-doped emitters in PERC Si bottom cells are hindered by high surface\nrecombination, which limits their performance. This research introduces a novel\nhybrid PERC/TOPCon structure that integrates a phosphorus-doped poly-Si (n+\nTOPCon) layer as the front emitter to address these challenges. Numerical\nsimulations using Quokka3 confirmed the feasibility of the design, focusing on\noptimizing the rear side metallization to enhance implied open-circuit voltage\n(Voc) and fill factor (FF). A two-step process systematically varied local\ncontact openings to examine their impact on performance metrics. Results\nhighlighted optimal rear metallization parameters, achieving optimal metal\nfractions approximately 2%. This innovative approach demonstrates the\neffectiveness of combining TOPCon and PERC technologies for bottom cells in\ntandem structures, providing valuable insights into their development and\noptimization. The study underscores the potential of the hybrid PERC/TOPCon\nstructure in enhancing the functionality and efficiency of perovskite/silicon\ntandem solar cells.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-14T12:56:45Z"}
{"aid":"http://arxiv.org/abs/2504.10198v1","title":"DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization\n  for Dynamic Retrieval-Augmented Generation","summary":"Dynamic Retrieval-augmented Generation (RAG) has shown great success in\nmitigating hallucinations in large language models (LLMs) during generation.\nHowever, existing dynamic RAG methods face significant limitations in two key\naspects: 1) Lack of an effective mechanism to control retrieval triggers, and\n2) Lack of effective scrutiny of retrieval content. To address these\nlimitations, we propose an innovative dynamic RAG method, DioR (Adaptive\nCognitive Detection and Contextual Retrieval Optimization), which consists of\ntwo main components: adaptive cognitive detection and contextual retrieval\noptimization, specifically designed to determine when retrieval is needed and\nwhat to retrieve for LLMs is useful. Experimental results demonstrate that DioR\nachieves superior performance on all tasks, demonstrating the effectiveness of\nour work.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T13:02:53Z"}
{"aid":"http://arxiv.org/abs/2504.10204v1","title":"Cohomological obstructions to equivariant unirationality","summary":"We study cohomological obstructions to equivariant unirationality, with\nspecial regard to actions of finite groups on del Pezzo surfaces and Fano\nthreefolds.","main_category":"math.AG","categories":"math.AG","published":"2025-04-14T13:12:54Z"}
{"aid":"http://arxiv.org/abs/2504.10207v1","title":"Generalized Natural Density $\\DF(\\mathfrak{F}_n)$ of Fibonacci Word","summary":"This paper explores profound generalizations of the Fibonacci sequence,\ndelving into random Fibonacci sequences, $k$-Fibonacci words, and their\ncombinatorial properties. We established that the $n$-th root of the absolute\nvalue of terms in a random Fibonacci sequence converges to $1.13198824\\ldots$,\na symmetry identity for sums involving Fibonacci words, $\\sum_{n=1}^{b}\n\\frac{(-1)^n F_a}{F_n F_{n+a}} = \\sum_{n=1}^{a} \\frac{(-1)^n F_b}{F_n\nF_{n+b}}$, and an infinite series identity linking Fibonacci terms to the\ngolden ratio. These findings underscore the intricate interplay between number\ntheory and combinatorics, illuminating the rich structure of Fibonacci-related\nsequences. We provide, according to this paper, new concepts of density of\nFibonacci word.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T13:17:38Z"}
{"aid":"http://arxiv.org/abs/2504.10235v1","title":"Eccentric mergers of binary Proca stars","summary":"We present a numerical relativity study of eccentric mergers of equal-mass\nrotating $\\bar m=1$ Proca stars, focusing on their gravitational-wave (GW)\nemission. By systematically varying key binary parameters, such as the initial\norbital boost, which determines the orbital angular momentum, and the relative\nphase between the stars, we examine how the internal phase structure of the\nProca field influences the merger dynamics and the properties of the emitted\nGWs. Our simulations demonstrate that the relative phase has paramount impact\non the post-merger evolution, resulting in prompt black hole formation\naccompanied by a transient Proca remnant, the formation of a hypermassive $\\bar\nm=1$ Proca star or even the emergence of a dynamically-unstable spinning $\\bar\nm=2$ Proca star. Under certain conditions, the GW signal exhibits significant\nodd-modes (e.g., the $\\ell=m=3$ mode) that are absent in conventional black\nhole mergers, potentially serving as unique signatures of these exotic objects.\nOur findings offer new insights into the phenomenology of bosonic star mergers\nand the potential astrophysical role of ultralight bosonic fields.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T13:59:33Z"}
{"aid":"http://arxiv.org/abs/2504.10252v1","title":"MapperEEG: A Topological Approach to Brain State Clustering in EEG\n  Recordings","summary":"Electrical potential scalp recordings (Electroencephalograms-EEGs) are a\ncommon tool used to investigate brain activity. EEG is routinely used in\nclinical applications as well as in research studies thanks to its noninvasive\nnature, relatively inexpensive equipment, and high temporal resolution. But,\nEEG is prone to contamination from movement artifacts and signals from external\nsources. Thus, it requires advanced signal processing and mathematical analysis\nmethods in tasks requiring brain state identification. Recently, tools from\ntopological data analysis have been used successfully across many domains,\nincluding brain research, however these uses have been limited to fMRI\ndatasets. We introduce the topological tool MapperEEG (M-EEG) and provide an\nexample of it's ability to separate different brain states during a simple\nfinger tapping teaming task without any pre-labeling or prior knowledge. M-EEG\nuses the power spectral density applied to traditional EEG frequency bands\ncombined with the Mapper algorithm from topological data analysis to capture\nthe underlying structure of the data and represent that structure as a graph in\ntwo-dimensional space. This tool provides clear separation (clustering) of\nstates during different conditions of the experiment (syncopated vs.\nsynchronized) and we demonstrate that M-EEG outperforms other clustering\nmethods when applied to EEG data.","main_category":"math.GN","categories":"math.GN","published":"2025-04-14T14:13:48Z"}
{"aid":"http://arxiv.org/abs/2504.10253v1","title":"TinyverseGP: Towards a Modular Cross-domain Benchmarking Framework for\n  Genetic Programming","summary":"Over the years, genetic programming (GP) has evolved, with many proposed\nvariations, especially in how they represent a solution. Being essentially a\nprogram synthesis algorithm, it is capable of tackling multiple problem\ndomains. Current benchmarking initiatives are fragmented, as the different\nrepresentations are not compared with each other and their performance is not\nmeasured across the different domains. In this work, we propose a unified\nframework, dubbed TinyverseGP (inspired by tinyGP), which provides support to\nmultiple representations and problem domains, including symbolic regression,\nlogic synthesis and policy search.","main_category":"cs.NE","categories":"cs.NE,cs.LG,cs.SC","published":"2025-04-14T14:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.10260v1","title":"Periodic approximation of topological Lyapunov exponents and the joint\n  spectral radius for cocycles of mapping classes of surfaces","summary":"We study cocycles taking values in the mapping class group of closed surfaces\nand investigate their leading topological Lyapunov exponent. Under a natural\nclosing property, we show that the top topological Lyapunov exponent can be\napproximated by periodic orbits. We also extend the notion of the joint\nspectral radius to this setting, interpreting it via the exponential growth of\ncurves under iterated mapping classes. Our approach connects ideas from ergodic\ntheory, Teichm\\\"uller geometry, and spectral theory, and suggests a broader\nframework for similar results.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-14T14:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.10273v1","title":"Sidecar: A Structure-Preserving Framework for Solving Partial\n  Differential Equations with Neural Networks","summary":"Solving partial differential equations (PDEs) with neural networks (NNs) has\nshown great potential in various scientific and engineering fields. However,\nmost existing NN solvers mainly focus on satisfying the given PDEs, without\nexplicitly considering intrinsic physical properties such as mass conservation\nor energy dissipation. This limitation can result in unstable or nonphysical\nsolutions, particularly in long-term simulations. To address this issue, we\npropose Sidecar, a novel framework that enhances the accuracy and physical\nconsistency of existing NN solvers by incorporating structure-preserving\nknowledge. Inspired by the Time-Dependent Spectral Renormalization (TDSR)\napproach, our Sidecar framework introduces a small copilot network, which is\ntrained to guide the existing NN solver in preserving physical structure. This\nframework is designed to be highly flexible, enabling the incorporation of\nstructure-preserving principles from diverse PDEs into a wide range of NN\nsolvers. Our experimental results on benchmark PDEs demonstrate the improvement\nof the existing neural network solvers in terms of accuracy and consistency\nwith structure-preserving properties.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-14T14:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.10277v1","title":"RealHarm: A Collection of Real-World Language Model Application Failures","summary":"Language model deployments in consumer-facing applications introduce numerous\nrisks. While existing research on harms and hazards of such applications\nfollows top-down approaches derived from regulatory frameworks and theoretical\nanalyses, empirical evidence of real-world failure modes remains underexplored.\nIn this work, we introduce RealHarm, a dataset of annotated problematic\ninteractions with AI agents built from a systematic review of publicly reported\nincidents. Analyzing harms, causes, and hazards specifically from the\ndeployer's perspective, we find that reputational damage constitutes the\npredominant organizational harm, while misinformation emerges as the most\ncommon hazard category. We empirically evaluate state-of-the-art guardrails and\ncontent moderation systems to probe whether such systems would have prevented\nthe incidents, revealing a significant gap in the protection of AI\napplications.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL,cs.CR","published":"2025-04-14T14:44:41Z"}
{"aid":"http://arxiv.org/abs/2504.10279v1","title":"Elastic Planetoids","summary":"Modeling the internal structure of self-gravitating solid and liquid bodies\npresents a challenge, as existing approaches are often limited to either overly\nsimplistic constant-density approximations or more complex numerical equations\nof state. We present a detailed analysis of a tractable and physically\nmotivated model for perfectly elastic, spherically symmetric self-gravitating\nbodies in hydrostatic equilibrium. The model employs a logarithmic equation of\nstate (logotropic EOS) with a non-zero initial density and constant bulk\nmodulus. Importantly, scaling properties of the model allow all solutions to be\nderived from a single, universal solution of an ordinary differential equation,\nresembling the Lane-Emden and Chandrasekhar models. The model provides new\ninsights into stability issues and reveals oscillatory asymptotic behavior in\nthe mass-radius relation, including the existence of both a maximum mass and a\nmaximum radius. We derive useful, simple analytical approximations for key\nproperties, such as central overdensity, moment of inertia, binding energy, and\ngravitational potential, applicable to small, metallic bodies like asteroids\nand moons. These new approximations could aid future research, including space\nmining and the scientific characterization of small Solar System bodies.","main_category":"astro-ph.EP","categories":"astro-ph.EP,cond-mat.mtrl-sci,physics.space-ph","published":"2025-04-14T14:45:38Z"}
{"aid":"http://arxiv.org/abs/2504.10294v1","title":"Ankle Exoskeletons in Walking and Load-Carrying Tasks: Insights into\n  Biomechanics and Human-Robot Interaction","summary":"Background: Lower limb exoskeletons can enhance quality of life, but\nwidespread adoption is limited by the lack of frameworks to assess their\nbiomechanical and human-robot interaction effects, which are essential for\ndeveloping adaptive and personalized control strategies. Understanding impacts\non kinematics, muscle activity, and HRI dynamics is key to achieve improved\nusability of wearable robots. Objectives: We propose a systematic methodology\nevaluate an ankle exoskeleton's effects on human movement during walking and\nload-carrying (10 kg front pack), focusing on joint kinematics, muscle\nactivity, and HRI torque signals. Materials and Methods: Using Xsens MVN\n(inertial motion capture), Delsys EMG, and a unilateral exoskeleton, three\nexperiments were conducted: (1) isolated dorsiflexion/plantarflexion; (2) gait\nanalysis (two subjects, passive/active modes); and (3) load-carrying under\nassistance. Results and Conclusions: The first experiment confirmed that the\nHRI sensor captured both voluntary and involuntary torques, providing\ndirectional torque insights. The second experiment showed that the device\nslightly restricted ankle range of motion (RoM) but supported normal gait\npatterns across all assistance modes. The exoskeleton reduced muscle activity,\nparticularly in active mode. HRI torque varied according to gait phases and\nhighlighted reduced synchronization, suggesting a need for improved support.\nThe third experiment revealed that load-carrying increased GM and TA muscle\nactivity, but the device partially mitigated user effort by reducing muscle\nactivity compared to unassisted walking. HRI increased during load-carrying,\nproviding insights into user-device dynamics. These results demonstrate the\nimportance of tailoring exoskeleton evaluation methods to specific devices and\nusers, while offering a framework for future studies on exoskeleton\nbiomechanics and HRI.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T15:05:02Z"}
{"aid":"http://arxiv.org/abs/2504.10296v1","title":"Siamese Network with Dual Attention for EEG-Driven Social Learning:\n  Bridging the Human-Robot Gap in Long-Tail Autonomous Driving","summary":"Robots with wheeled, quadrupedal, or humanoid forms are increasingly\nintegrated into built environments. However, unlike human social learning, they\nlack a critical pathway for intrinsic cognitive development, namely, learning\nfrom human feedback during interaction. To understand human ubiquitous\nobservation, supervision, and shared control in dynamic and uncertain\nenvironments, this study presents a brain-computer interface (BCI) framework\nthat enables classification of Electroencephalogram (EEG) signals to detect\ncognitively demanding and safety-critical events. As a timely and motivating\nco-robotic engineering application, we simulate a human-in-the-loop scenario to\nflag risky events in semi-autonomous robotic driving-representative of\nlong-tail cases that pose persistent bottlenecks to the safety performance of\nsmart mobility systems and robotic vehicles. Drawing on recent advances in\nfew-shot learning, we propose a dual-attention Siamese convolutional network\npaired with Dynamic Time Warping Barycenter Averaging approach to generate\nrobust EEG-encoded signal representations. Inverse source localization reveals\nactivation in Broadman areas 4 and 9, indicating perception-action coupling\nduring task-relevant mental imagery. The model achieves 80% classification\naccuracy under data-scarce conditions and exhibits a nearly 100% increase in\nthe utility of salient features compared to state-of-the-art methods, as\nmeasured through integrated gradient attribution. Beyond performance, this\nstudy contributes to our understanding of the cognitive architecture required\nfor BCI agents-particularly the role of attention and memory mechanisms-in\ncategorizing diverse mental states and supporting both inter- and intra-subject\nadaptation. Overall, this research advances the development of cognitive\nrobotics and socially guided learning for service robots in complex built\nenvironments.","main_category":"cs.RO","categories":"cs.RO,cs.HC,cs.LG","published":"2025-04-14T15:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.10305v1","title":"Commutator subalgebra of the Lie algebra associated with a right-angled\n  Coxeter group","summary":"We study the graded Lie algebra $L(RC_K)$ associated with the lower central\nseries of a right-angled Coxeter group $RC_K$. We prove that its commutator\nsubalgebra is a quotient of the polynomial ring over an auxiliary Lie\nsubalgebra $N_K$ of the graph Lie algebra $L_K$, and conjecture that the\nquotient map is an isomorphism. The epimorphism is defined in terms of a new\noperation in the associated Lie algebra, which corresponds to the squaring and\nhas an analogue in homotopy theory.","main_category":"math.GR","categories":"math.GR,math.AT","published":"2025-04-14T15:13:49Z"}
{"aid":"http://arxiv.org/abs/2504.10309v1","title":"AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style\n  Matching Text-to-Speech Synthesis","summary":"With the advancement of speech synthesis technology, users have higher\nexpectations for the naturalness and expressiveness of synthesized speech. But\nprevious research ignores the importance of prompt selection. This study\nproposes a text-to-speech (TTS) framework based on Retrieval-Augmented\nGeneration (RAG) technology, which can dynamically adjust the speech style\naccording to the text content to achieve more natural and vivid communication\neffects. We have constructed a speech style knowledge database containing\nhigh-quality speech samples in various contexts and developed a style matching\nscheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and\nMoka, to match with samples in the knowledge database, selecting the most\nappropriate speech style for synthesis. Furthermore, our empirical research\nvalidates the effectiveness of the proposed method. Our demo can be viewed at:\nhttps://thuhcsi.github.io/icme2025-AutoStyle-TTS","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-14T15:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.10325v1","title":"Cumulative-Time Signal Temporal Logic","summary":"Signal Temporal Logic (STL) is a widely adopted specification language in\ncyber-physical systems for expressing critical temporal requirements, such as\nsafety conditions and response time. However, STL's expressivity is not\nsufficient to capture the cumulative duration during which a property holds\nwithin an interval of time. To overcome this limitation, we introduce\nCumulative-Time Signal Temporal Logic (CT-STL) that operates over discrete-time\nsignals and extends STL with a new cumulative-time operator. This operator\ncompares the sum of all time steps for which its nested formula is true with a\nthreshold. We present both a qualitative and a quantitative (robustness)\nsemantics for CT-STL and prove both their soundness and completeness\nproperties. We provide an efficient online monitoring algorithm for both\nsemantics. Finally, we show the applicability of CT-STL in two case studies:\nspecifying and monitoring cumulative temporal requirements for a microgrid and\nan artificial pancreas.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T15:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.10340v1","title":"Forecasting from Clinical Textual Time Series: Adaptations of the\n  Encoder and Decoder Language Model Families","summary":"Clinical case reports encode rich, temporal patient trajectories that are\noften underexploited by traditional machine learning methods relying on\nstructured data. In this work, we introduce the forecasting problem from\ntextual time series, where timestamped clinical findings--extracted via an\nLLM-assisted annotation pipeline--serve as the primary input for prediction. We\nsystematically evaluate a diverse suite of models, including fine-tuned\ndecoder-based large language models and encoder-based transformers, on tasks of\nevent occurrence prediction, temporal ordering, and survival analysis. Our\nexperiments reveal that encoder-based models consistently achieve higher F1\nscores and superior temporal concordance for short- and long-horizon event\nforecasting, while fine-tuned masking approaches enhance ranking performance.\nIn contrast, instruction-tuned decoder models demonstrate a relative advantage\nin survival analysis, especially in early prognosis settings. Our sensitivity\nanalyses further demonstrate the importance of time ordering, which requires\nclinical time series construction, as compared to text ordering, the format of\nthe text inputs that LLMs are classically trained on. This highlights the\nadditional benefit that can be ascertained from time-ordered corpora, with\nimplications for temporal tasks in the era of widespread LLM use.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T15:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.10342v1","title":"VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain\n  Knowledge","summary":"Current multimodal benchmarks often conflate reasoning with domain-specific\nknowledge, making it difficult to isolate and evaluate general reasoning\nabilities in non-expert settings. To address this, we introduce VisualPuzzles,\na benchmark that targets visual reasoning while deliberately minimizing\nreliance on specialized knowledge. VisualPuzzles consists of diverse questions\nspanning five categories: algorithmic, analogical, deductive, inductive, and\nspatial reasoning. One major source of our questions is manually translated\nlogical reasoning questions from the Chinese Civil Service Examination.\nExperiments show that VisualPuzzles requires significantly less intensive\ndomain-specific knowledge and more complex reasoning compared to benchmarks\nlike MMMU, enabling us to better evaluate genuine multimodal reasoning.\nEvaluations show that state-of-the-art multimodal large language models\nconsistently lag behind human performance on VisualPuzzles, and that strong\nperformance on knowledge-intensive benchmarks does not necessarily translate to\nsuccess on reasoning-focused, knowledge-light tasks. Additionally, reasoning\nenhancements such as scaling up inference compute (with \"thinking\" modes) yield\ninconsistent gains across models and task types, and we observe no clear\ncorrelation between model size and performance. We also found that models\nexhibit different reasoning and answering patterns on VisualPuzzles compared to\nbenchmarks with heavier emphasis on knowledge. VisualPuzzles offers a clearer\nlens through which to evaluate reasoning capabilities beyond factual recall and\ndomain knowledge.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T15:50:39Z"}
{"aid":"http://arxiv.org/abs/2504.10348v1","title":"Improving diffusion modeling in all-solid-state lithium batteries: a\n  novel approach for grain boundary effects","summary":"All-solid-state lithium-ion batteries offer promising advantages with respect\nto capacity, safety, and performance. The diffusion behavior of lithium ions in\nthe contained polycrystalline solid-state electrolyte is crucial for battery\nfunction. While atomistic studies indicate that grain boundaries (GBs) and\ngrain size significantly impact diffusivity, the corresponding effects are\neither neglected in simulations on larger scales or considered only under\nstrong assumptions such as isotropy. Our approach considers the fully resolved\ncrystalline structure with a parametrization aligned with the atomistic\nperspective to describe diffusion along and across GBs. The approach is\nembedded into a finite element simulation using a novel collapsed interface\nelement based on an analytical description in thickness direction. Results are\ngoverned by different and potentially anisotropic diffusion coefficients in\nbulk and GB domains. The mesoscale response is derived using linear\ncomputational homogenization to capture large-scale effects. The novel\ncollapsed interface description allows for a reconstruction of the 3D transport\nbehavior within the GB domain without resolving it and is able to capture the\nrelevant transport mechanisms such as channeling effects and concentration\njumps. Grain size and GB volume fraction are expressed in terms of an affine\nparameter dependence and can be altered without any changes to geometry or\nmesh. Together with the observed dependence of the effective material response\non the anisotropic GB parametrization, this leads to the identification of four\ndistinct diffusion regimes, each with implications for the design of battery\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T15:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.10350v1","title":"Benchmarking 3D Human Pose Estimation Models Under Occlusions","summary":"This paper addresses critical challenges in 3D Human Pose Estimation (HPE) by\nanalyzing the robustness and sensitivity of existing models to occlusions,\ncamera position, and action variability. Using a novel synthetic dataset,\nBlendMimic3D, which includes diverse scenarios with multi-camera setups and\nseveral occlusion types, we conduct specific tests on several state-of-the-art\nmodels. Our study focuses on the discrepancy in keypoint formats between common\ndatasets such as Human3.6M, and 2D datasets such as COCO, commonly used for 2D\ndetection models and frequently input of 3D HPE models. Our work explores the\nimpact of occlusions on model performance and the generality of models trained\nexclusively under standard conditions. The findings suggest significant\nsensitivity to occlusions and camera settings, revealing a need for models that\nbetter adapt to real-world variability and occlusion scenarios. This research\ncontributed to ongoing efforts to improve the fidelity and applicability of 3D\nHPE systems in complex environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.10354v1","title":"The diagonal and Hadamard grade of hypergeometric functions","summary":"Diagonals of rational functions are an important class of functions arising\nin number theory, algebraic geometry, combinatorics, and physics. In this paper\nwe study the diagonal grade of a function $f$, which is defined to be the\nsmallest $n$ such that $f$ is the diagonal of a rational function in variables\n$x_0,\\dots, x_n$. We relate the diagonal grade of a function to the nilpotence\nof the associated differential equation. This allows us to determine the\ndiagonal grade of many hypergeometric functions and answer affirmatively the\noutstanding question on the existence of functions with diagonal grade greater\nthan $2$. In particular, we show that\n$\\prescript{}{n}F_{n-1}(\\frac{1}{2},\\dots, \\frac{1}{2};1\\dots,1 \\mid x)$ has\ndiagonal grade $n$ for each $n\\geq 1$. Our method also applies to the\ngenerating function of the Ap\\'ery sequence, which we find to have diagonal\ngrade $3$. We also answer related questions on Hadamard grades posed by\nAllouche and Mend\\`es France. For example, we show that\n$\\prescript{}{n}F_{n-1}(\\frac{1}{2},\\dots, \\frac{1}{2};1\\dots,1 \\mid x)$ has\nHadamard grade $n$ for all $n\\geq 1$.","main_category":"math.CO","categories":"math.CO,math-ph,math.AG,math.MP,math.NT","published":"2025-04-14T16:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.10358v1","title":"FingER: Content Aware Fine-grained Evaluation with Reasoning for\n  AI-Generated Videos","summary":"Recent advances in video generation have posed great challenges in the\nassessment of AI-generated content, particularly with the emergence of\nincreasingly sophisticated models. The various inconsistencies and defects\nobserved in such videos are inherently complex, making overall scoring\nnotoriously difficult. In this paper, we emphasize the critical importance of\nintegrating fine-grained reasoning into video evaluation, and we propose\n$\\textbf{F}$ing$\\textbf{ER}$, a novel entity-level reasoning evaluation\nframework that first automatically generates $\\textbf{F}$ine-grained\n$\\textbf{E}$ntity-level questions, and then answers those questions by a\n$\\textbf{R}$easoning model with scores, which can be subsequently weighted\nsummed to an overall score for different applications. Specifically, we\nleverage LLMs to derive entity-level questions across five distinct\nperspectives, which (i) often focus on some specific entities of the content,\nthereby making answering or scoring much easier by MLLMs, and (ii) are more\ninterpretable. Then we construct a FingER dataset, consisting of approximately\n3.3k videos and corresponding 60k fine-grained QA annotations, each with\ndetailed reasons. Based on that, we further investigate various training\nprotocols to best incentivize the reasoning capability of MLLMs for correct\nanswer prediction. Extensive experiments demonstrate that a reasoning model\ntrained using Group Relative Policy Optimization (GRPO) with a cold-start\nstrategy achieves the best performance. Notably, our model surpasses existing\nmethods by a relative margin of $11.8\\%$ on GenAI-Bench and $5.5\\%$ on\nMonetBench with only 3.3k training videos, which is at most one-tenth of the\ntraining samples utilized by other methods. Our code and dataset will be\nreleased soon.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-14T16:07:16Z"}
{"aid":"http://arxiv.org/abs/2504.10364v1","title":"Widely FSR tunable high Q-factor microresonators formed at the\n  intersection of straight optical fibers","summary":"We present a new class of high-Q tunable microresonators formed at the\nintersection of two straight silica optical fibers, whose free spectral range\n(FSR) can be widely tuned by fiber rotation. The proposed configuration avoids\nthe limitations of traditional monolithic microresonators that lack FSR\ntunability required for a wide range of photonic applications. Using small\nrotation angles (1-15 mrad), we demonstrate a tunability of the FSR from 2 pm\nto 10 pm, enabled by microscale fiber displacements that reshape the resonator\nprofile over millimeter scales. The proposed approach minimizes mechanical\nstress, supports miniaturization, and is suitable for integration with MEMS. It\npaves the way for the fabrication of tunable delay lines, ultralow repetition\nrate broadband frequency comb generators, and nonlocal optofluidic sensors on a\nchip.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-14T16:10:08Z"}
{"aid":"http://arxiv.org/abs/2504.10370v1","title":"Further Comments on Yablo's Construction","summary":"We continue our analysis of Yablo's coding of the liar paradox by infinite\nacyclic graphs. The present notes are based on and continue the author's\nprevious results on the problem. In particular, our approach is often more\nsystematic than before.","main_category":"math.CO","categories":"math.CO,cs.LO","published":"2025-04-14T16:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.10375v1","title":"PG-DPIR: An efficient plug-and-play method for high-count\n  Poisson-Gaussian inverse problems","summary":"Poisson-Gaussian noise describes the noise of various imaging systems thus\nthe need of efficient algorithms for Poisson-Gaussian image restoration. Deep\nlearning methods offer state-of-the-art performance but often require\nsensor-specific training when used in a supervised setting. A promising\nalternative is given by plug-and-play (PnP) methods, which consist in learning\nonly a regularization through a denoiser, allowing to restore images from\nseveral sources with the same network. This paper introduces PG-DPIR, an\nefficient PnP method for high-count Poisson-Gaussian inverse problems, adapted\nfrom DPIR. While DPIR is designed for white Gaussian noise, a naive adaptation\nto Poisson-Gaussian noise leads to prohibitively slow algorithms due to the\nabsence of a closed-form proximal operator. To address this, we adapt DPIR for\nthe specificities of Poisson-Gaussian noise and propose in particular an\nefficient initialization of the gradient descent required for the proximal step\nthat accelerates convergence by several orders of magnitude. Experiments are\nconducted on satellite image restoration and super-resolution problems.\nHigh-resolution realistic Pleiades images are simulated for the experiments,\nwhich demonstrate that PG-DPIR achieves state-of-the-art performance with\nimproved efficiency, which seems promising for on-ground satellite processing\nchains.","main_category":"cs.CV","categories":"cs.CV,cs.LG,eess.IV","published":"2025-04-14T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.10378v1","title":"Cosmogenic Neutrino Point Source and KM3-230213A","summary":"Cosmogenic neutrinos (CNs) are produced by ultra-high energy cosmic rays\n(UHECRs) interacting with cosmic background radiation. We investigated the\nproperties of CN point/extended sources, i.e, the neutrino spectrum, and\nangular profile as functions of time, by assuming that UHECR sources are\ntransient events, such as gamma-ray bursts. The properties depend much on the\nintergalactic magnetic field (IGMF), but the angular extent is in general\nsub-degree, within which the CN flux can overshoot the diffuse CN flux in early\ntime. The nearby CN point sources could be detected for the low IGMF case by\nfuture neutrino telescopes. The recent KM3-230213A event is possible to account\nfor by a nearby transient CN source, rather than diffuse CN emission.\nObservations of CN point sources will provide a chance to search for UHECR\nsources.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-14T16:24:52Z"}
{"aid":"http://arxiv.org/abs/2504.10390v1","title":"Teacher Motion Priors: Enhancing Robot Locomotion over Challenging\n  Terrain","summary":"Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T16:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10394v1","title":"Digits of pi: limits to the seeming randomness II","summary":"According to a popular belief, the decimal digits of mathematical constants\nsuch as {\\pi} behave like statistically independent random variables, each\ntaking the values 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9 with equal probability of\n1/10. If this is the case, then, in particular, the decimal representations of\nthese constants should tend to satisfy the central limit theorem (CLT) and the\nlaw of the iterated logarithm (LIL). The paper presents the results of a direct\nstatistical analysis of the decimal representations of 12 mathematical\nconstants with respect to the central limit theorem (CLT) and the law of the\niterated logarithm (LIL). The first billion digits of each constant were\nanalyzed, with ten billion digits examined in the case of {\\pi}. Within these\nlimits, no evidence was found to suggest that the digits of these constants\nsatisfy CLT or LIL.","main_category":"math.NT","categories":"math.NT","published":"2025-04-14T16:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.10395v1","title":"Better Coherence, Better Height: Fusing Physical Models and Deep\n  Learning for Forest Height Estimation from Interferometric SAR Data","summary":"Estimating forest height from Synthetic Aperture Radar (SAR) images often\nrelies on traditional physical models, which, while interpretable and\ndata-efficient, can struggle with generalization. In contrast, Deep Learning\n(DL) approaches lack physical insight. To address this, we propose CoHNet - an\nend-to-end framework that combines the best of both worlds: DL optimized with\nphysics-informed constraints. We leverage a pre-trained neural surrogate model\nto enforce physical plausibility through a unique training loss. Our\nexperiments show that this approach not only improves forest height estimation\naccuracy but also produces meaningful features that enhance the reliability of\npredictions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.10401v1","title":"Selectivity gain in olfactory receptor neuron at optimal odor\n  concentration","summary":"It has been discovered before (arXiv:2306.07676) that for the selectivity\ngain due to fluctuations in the process of primary odor reception by olfactory\nreceptor neuron (ORN) there exists an optimal concentration of odors at which\nincreased selectivity is mostly manifested. We estimate by means of numerical\nsimulation what could be the gain value at that concentration by modeling ORN\nas a leaky integrate-and-fire neuron with membrane populated by receptor\nproteins R which bind and release odor molecules randomly. Each R is modeled as\na ligand-gated ion channel, and binding-releasing is modeled as a Markov\nstochastic process. Possible values for the selectivity gain are calculated for\nORN parameters suggested by experimental data.\n  Keywords: ORN, selectivity, receptor proteins, fluctuations, stochastic\nprocess, Markov process","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-14T16:51:25Z"}
{"aid":"http://arxiv.org/abs/2504.10402v1","title":"Can spacetime torsion source an extremely red-tilted cosmological GW\n  background?","summary":"In the presence of spacetime torsion, any generic $f(R)$ model of gravity is\nconformally dual to a scalar-tensor theory augmented with a second rank\nantisymmetric massless degree of freedom. We investigate the stochastic\ngravitational wave background (SGWB) that may be sourced directly at the second\norder by such a torsional field, treated perturbatively during an epoch of\ncanonical, single-field, slow-roll inflation. The resulting second-order\ninduced SGWB, which dominates over the primary inflationary GW background at\nall scales, peaks only at ultra-low frequencies, and is found to be extremely\nred-tilted with an effective tensor spectral index $\\alpha_{\\rm T}\\sim-6$ on\nmatter-dominated scales. The signal is potentially within the reach of upcoming\nindirect GW probes on very large scales $k\\lesssim10^{-2}\\:\\textrm{Mpc}^{-1}$,\ni.e., next-generation CMB experiments like the LiteBIRD. In the near future,\nobservation of such a markedly red-tilted SGWB on CMB scales could hence\nprovide a novel and unique clue in favour of torsional gravity during the\ninflationary era.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-14T16:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.10403v1","title":"Satellite Federated Fine-Tuning for Foundation Models in Space Computing\n  Power Networks","summary":"Advancements in artificial intelligence (AI) and low-earth orbit (LEO)\nsatellites have promoted the application of large remote sensing foundation\nmodels for various downstream tasks. However, direct downloading of these\nmodels for fine-tuning on the ground is impeded by privacy concerns and limited\nbandwidth. Satellite federated learning (FL) offers a solution by enabling\nmodel fine-tuning directly on-board satellites and aggregating model updates\nwithout data downloading. Nevertheless, for large foundation models, the\ncomputational capacity of satellites is insufficient to support effective\non-board fine-tuning in traditional satellite FL frameworks. To address these\nchallenges, we propose a satellite-ground collaborative federated fine-tuning\nframework. The key of the framework lies in how to reasonably decompose and\nallocate model components to alleviate insufficient on-board computation\ncapabilities. During fine-tuning, satellites exchange intermediate results with\nground stations or other satellites for forward propagation and back\npropagation, which brings communication challenges due to the special\ncommunication topology of space transmission networks, such as intermittent\nsatellite-ground communication, short duration of satellite-ground\ncommunication windows, and unstable inter-orbit inter-satellite links (ISLs).\nTo reduce transmission delays, we further introduce tailored communication\nstrategies that integrate both communication and computing resources.\nSpecifically, we propose a parallel intra-orbit communication strategy, a\ntopology-aware satellite-ground communication strategy, and a\nlatency-minimalization inter-orbit communication strategy to reduce space\ncommunication costs. Simulation results demonstrate significant reductions in\ntraining time with improvements of approximately 33%.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.NI","published":"2025-04-14T16:52:34Z"}
{"aid":"http://arxiv.org/abs/2504.10404v1","title":"Framing Perception: Exploring Camera Induced Objectification in Cinema","summary":"This study investigates how cinematographic techniques influence viewer\nperception and contribute to the objectification of women, utilizing\neye-tracking data from 91 participants. They watched a sexualized music video\n(SV) known for objectifying portrayals and a non-sexualized music video (TV).\nUsing dynamic Areas of Interests (AOIs) (head, torso, and lower body), gaze\nmetrics such as fixation duration, visit count, and scan paths were recorded to\nassess visual attention patterns. Participants were grouped according to their\naverage fixations on sexualized AOIs. Statistical analyses revealed significant\ndifferences in gaze behavior between the videos and among the groups, with\nincreased attention to sexualized AOIs in SV. Additionally, data-driven group\ndifferences in fixations identified specific segments with heightened\nobjectification that are further analyzed using scan path visualization\ntechniques. These findings provide strong empirical evidence of camera-driven\ngaze objectification, demonstrating how cinematic framing implicitly shapes\nobjectifying gaze patterns, highlighting the critical need for mindful media\nrepresentation.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T16:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.10414v1","title":"HUMOTO: A 4D Dataset of Mocap Human Object Interactions","summary":"We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of\nhuman-object interactions for motion generation, computer vision, and robotics\napplications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO\ncaptures interactions with 63 precisely modeled objects and 72 articulated\nparts. Our innovations include a scene-driven LLM scripting pipeline creating\ncomplete, purposeful tasks with natural progression, and a mocap-and-camera\nrecording setup to effectively handle occlusions. Spanning diverse activities\nfrom cooking to outdoor picnics, HUMOTO preserves both physical accuracy and\nlogical task flow. Professional artists rigorously clean and verify each\nsequence, minimizing foot sliding and object penetrations. We also provide\nbenchmarks compared to other datasets. HUMOTO's comprehensive full-body motion\nand simultaneous multi-object interactions address key data-capturing\nchallenges and provide opportunities to advance realistic human-object\ninteraction modeling across research domains with practical applications in\nanimation, robotics, and embodied AI systems. Project:\nhttps://jiaxin-lu.github.io/humoto/ .","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:59:29Z"}
{"aid":"http://arxiv.org/abs/2504.10428v1","title":"Learning with Positive and Imperfect Unlabeled Data","summary":"We study the problem of learning binary classifiers from positive and\nunlabeled data when the unlabeled data distribution is shifted, which we call\nPositive and Imperfect Unlabeled (PIU) Learning. In the absence of covariate\nshifts, i.e., with perfect unlabeled data, Denis (1998) reduced this problem to\nlearning under Massart noise; however, that reduction fails under even slight\nshifts.\n  Our main results on PIU learning are the characterizations of the sample\ncomplexity of PIU learning and a computationally and sample-efficient algorithm\nachieving a misclassification error $\\varepsilon$. We further show that our\nresults lead to new algorithms for several related problems.\n  1. Learning from smooth distributions: We give algorithms that learn\ninteresting concept classes from only positive samples under smooth feature\ndistributions, bypassing known existing impossibility results and contributing\nto recent advances in smoothened learning (Haghtalab et al, J.ACM'24)\n(Chandrasekaran et al., COLT'24).\n  2. Learning with a list of unlabeled distributions: We design new algorithms\nthat apply to a broad class of concept classes under the assumption that we are\ngiven a list of unlabeled distributions, one of which--unknown to the\nlearner--is $O(1)$-close to the true feature distribution.\n  3. Estimation in the presence of unknown truncation: We give the first\npolynomial sample and time algorithm for estimating the parameters of an\nexponential family distribution from samples truncated to an unknown set\napproximable by polynomials in $L_1$-norm. This improves the algorithm by Lee\net al. (FOCS'24) that requires approximation in $L_2$-norm.\n  4. Detecting truncation: We present new algorithms for detecting whether\ngiven samples have been truncated (or not) for a broad class of non-product\ndistributions, including non-product distributions, improving the algorithm by\nDe et al. (STOC'24).","main_category":"stat.ML","categories":"stat.ML,cs.DS,cs.LG,math.ST,stat.TH","published":"2025-04-14T17:19:29Z"}
{"aid":"http://arxiv.org/abs/2504.10429v1","title":"Out of the box approach to Black hole Information paradox","summary":"Suppose a black hole forms from a pure quantum state $\\ket{\\psi}$. The black\nhole information loss paradox arises from semiclassical arguments suggesting\nthat, even in a closed system, the process of black hole formation and\nevaporation evolves a pure state into a mixed state. Resolution to the paradox\ntypically demands violation of quantum mechanics or relativity in domains where\nthey should hold. Instead, I propose that in a complete theory of quantum\ngravity, any region $\\mathcal{U}$ that could collapse into a black hole should\nalready be described by a mixed state, thus bypassing the paradox entirely. To\nthat end, I present a model in which the universe is in a quantum\nerror-corrected state, such that any local black hole appears mixed and encodes\nno information locally.","main_category":"gr-qc","categories":"gr-qc,hep-th,quant-ph","published":"2025-04-14T17:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.10431v1","title":"Comparison of symplectic capacities","summary":"In this paper, we compare the symplectic (co)homology capacity with the\nspectral capacity in the relative case. This result establishes a chain of\ninequalities of relative symplectic capacities, which is an analogue of the\nnon-relative case. This comparison gives us a criterion for the relative almost\nexistence theorem in terms of heaviness. Also, we investigate a sufficient\ncondition under which the symplectic (co)homology capacity and the first\nGutt-Hutchings capacity are equal in both non-relative and relative cases. This\ncondition is less restrictive than the dynamical convexity.","main_category":"math.SG","categories":"math.SG","published":"2025-04-14T17:20:41Z"}
{"aid":"http://arxiv.org/abs/2504.10432v1","title":"Invariance Matters: Empowering Social Recommendation via Graph Invariant\n  Learning","summary":"Graph-based social recommendation systems have shown significant promise in\nenhancing recommendation performance, particularly in addressing the issue of\ndata sparsity in user behaviors. Typically, these systems leverage Graph Neural\nNetworks (GNNs) to capture user preferences by incorporating high-order social\ninfluences from observed social networks. However, existing graph-based social\nrecommendations often overlook the fact that social networks are inherently\nnoisy, containing task-irrelevant relationships that can hinder accurate user\npreference learning. The removal of these redundant social relations is\ncrucial, yet it remains challenging due to the lack of ground truth. In this\npaper, we approach the social denoising problem from the perspective of graph\ninvariant learning and propose a novel method, Social Graph Invariant\nLearning(SGIL). Specifically,SGIL aims to uncover stable user preferences\nwithin the input social graph, thereby enhancing the robustness of graph-based\nsocial recommendation systems. To achieve this goal, SGIL first simulates\nmultiple noisy social environments through graph generators. It then seeks to\nlearn environment-invariant user preferences by minimizing invariant risk\nacross these environments. To further promote diversity in the generated social\nenvironments, we employ an adversarial training strategy to simulate more\npotential social noisy distributions. Extensive experimental results\ndemonstrate the effectiveness of the proposed SGIL. The code is available at\nhttps://github.com/yimutianyang/SIGIR2025-SGIL.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T17:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.10433v1","title":"MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via\n  Diffusion Model","summary":"Object pose estimation is a core means for robots to understand and interact\nwith their environment. For this task, monocular category-level methods are\nattractive as they require only a single RGB camera. However, current methods\nrely on shape priors or CAD models of the intra-class known objects. We propose\na diffusion-based monocular category-level 9D object pose generation method,\nMonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusion\nmodels to alleviate the need for shape priors, CAD models, or depth sensors for\nintra-class unknown object pose estimation. We first estimate coarse depth via\nDINOv2 from the monocular image in a zero-shot manner and convert it into a\npoint cloud. We then fuse the global features of the point cloud with the input\nimage and use the fused features along with the encoded time step to condition\nMonoDiff9D. Finally, we design a transformer-based denoiser to recover the\nobject pose from Gaussian noise. Extensive experiments on two popular benchmark\ndatasets show that MonoDiff9D achieves state-of-the-art monocular\ncategory-level 9D object pose estimation accuracy without the need for shape\npriors or CAD models at any stage. Our code will be made public at\nhttps://github.com/CNJianLiu/MonoDiff9D.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-14T17:21:10Z"}
{"aid":"http://arxiv.org/abs/2504.10444v1","title":"Maximum entropy modeling of Optimal Transport: the sub-optimality regime\n  and the transition from dense to sparse networks","summary":"We present a bipartite network model that captures intermediate stages of\noptimization by blending the Maximum Entropy approach with Optimal Transport.\nIn this framework, the network's constraints define the total mass each node\ncan supply or receive, while an external cost field favors a minimal set of\nlinks, driving the system toward a sparse, tree-like structure. By tuning the\ncontrol parameter, one transitions from uniformly distributed weights to an\noptimal transport regime in which weights condense onto cost-favorable edges.\nWe quantify this dense-to-sparse transition, showing with numerical analyses\nthat the process does not hinge on specific assumptions about the node-strength\nor cost distributions. Finite-size analysis confirms that the results persist\nin the thermodynamic limit. Because the model offers explicit control over the\ndegree of sub-optimality, this approach lends to practical applications in link\nprediction, network reconstruction, and statistical validation, particularly in\nsystems where partial optimization coexists with other noise-like factors.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-14T17:36:45Z"}
{"aid":"http://arxiv.org/abs/2504.10449v1","title":"M1: Towards Scalable Test-Time Compute with Mamba Reasoning Models","summary":"Effective reasoning is crucial to solving complex mathematical problems.\nRecent large language models (LLMs) have boosted performance by scaling\ntest-time computation through long chain-of-thought reasoning. However,\ntransformer-based models are inherently limited in extending context length due\nto their quadratic computational complexity and linear memory requirements. In\nthis paper, we introduce a novel hybrid linear RNN reasoning model, M1, built\non the Mamba architecture, which allows memory-efficient inference. Our\napproach leverages a distillation process from existing reasoning models and is\nfurther enhanced through RL training. Experimental results on the AIME and MATH\nbenchmarks show that M1 not only outperforms previous linear RNN models but\nalso matches the performance of state-of-the-art Deepseek R1 distilled\nreasoning models at a similar scale. We also compare our generation speed with\na highly performant general purpose inference engine, vLLM, and observe more\nthan a 3x speedup compared to a same size transformer. With throughput speedup,\nwe are able to achieve higher accuracy compared to DeepSeek R1 distilled\ntransformer reasoning models under a fixed generation time budget using\nself-consistency voting. Overall, we introduce a hybrid Mamba reasoning model\nand provide a more effective approach to scaling test-time generation using\nself-consistency or long chain of thought reasoning.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T17:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.10457v1","title":"Holographic Entanglement Entropy in the FLRW Universe","summary":"We compute a holographic entanglement entropy via Ryu--Takayanagi\nprescription in the three-dimensional Friedmann--Lema\\^itre--Robertson--Walker\nuniverse. We consider two types of holographic scenarios analogous to the\nstatic patch holography and the half de Sitter holography, in which the\nholographic boundary is timelike and placed in the bulk. We find in general\nthat the strong subadditivity can be satisfied only in the former type and in\naddition the holographic boundary has to fit inside the apparent horizon. Also,\nfor the universe filled with an ideal fluid of constant equation of state\n$w<-1$, the condition is sharpened as that the holographic boundary has to fit\ninside the event horizon instead. These conditions provide a necessary\ncondition for the dual quantum field theory to be standard and compatible with\nthe strong subadditivity.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc","published":"2025-04-14T17:44:34Z"}
{"aid":"http://arxiv.org/abs/2504.10461v1","title":"Layered Multirate Control of Constrained Linear Systems","summary":"Layered control architectures have been a standard paradigm for efficiently\nmanaging complex constrained systems. A typical architecture consists of: i) a\nhigher layer, where a low-frequency planner controls a simple model of the\nsystem, and ii) a lower layer, where a high-frequency tracking controller\nguides a detailed model of the system toward the output of the higher-layer\nmodel. A fundamental problem in this layered architecture is the design of\nplanners and tracking controllers that guarantee both higher- and lower-layer\nsystem constraints are satisfied. Toward addressing this problem, we introduce\na principled approach for layered multirate control of linear systems subject\nto output and input constraints. Inspired by discrete-time simulation\nfunctions, we propose a streamlined control design that guarantees the\nlower-layer system tracks the output of the higher-layer system with computable\nprecision. Using this design, we derive conditions and present a method for\npropagating the constraints of the lower-layer system to the higher-layer\nsystem. The propagated constraints are integrated into the design of an\narbitrary planner that can handle higher-layer system constraints. Our\nframework ensures that the output constraints of the lower-layer system are\nsatisfied at all high-level time steps, while respecting its input constraints\nat all low-level time steps. We apply our approach in a scenario of motion\nplanning, highlighting its critical role in ensuring collision avoidance.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-14T17:48:34Z"}
{"aid":"http://arxiv.org/abs/2504.10846v1","title":"Mosaic: Client-driven Account Allocation Framework in Sharded\n  Blockchains","summary":"Recent account allocation studies in sharded blockchains are typically\nminer-driven, requiring miners to perform global optimizations for all accounts\nto enhance system-wide performance. This forces each miner to maintain a\ncomplete copy of the entire ledger, resulting in significant storage,\ncommunication, and computation overhead.\n  In this work, we explore an alternative research direction by proposing\nMosaic, the first client-driven framework for distributed, lightweight local\noptimization. Rather than relying on miners to allocate all accounts, Mosaic\nenables clients to independently execute a local algorithm to determine their\nresiding shards. Clients can submit migration requests to a beacon chain when\nrelocation is necessary. Mosaic naturally addresses key limitations of\nminer-driven approaches, including the lack of miner incentives and the\nsignificant overhead. While clients are flexible to adopt any algorithm for\nshard allocation, we design and implement a reference algorithm, Pilot, to\nguide them. Clients execute Pilot to maximize their own benefits, such as\nreduced transaction fees and confirmation latency.\n  On a real-world Ethereum dataset, we implement and evaluate Pilot against\nstate-of-the-art miner-driven global optimization solutions. The results\ndemonstrate that Mosaic significantly enhances computational efficiency,\nachieving a four-order-of-magnitude reduction in computation time, with the\nreduced input data size from 1.44 GB to an average of 228.66 bytes per account.\nDespite these efficiency gains, Pilot introduces only about a 5% increase in\nthe cross-shard ratio and maintains approximately 98% of the system throughput,\ndemonstrating a minimal trade-off in overall effectiveness.","main_category":"cs.DC","categories":"cs.DC,cs.DB,cs.GT","published":"2025-04-15T04:07:09Z"}
{"aid":"http://arxiv.org/abs/2504.10847v1","title":"Cosmic-Ray Constraints on the Flux of Ultra-High-Energy Neutrino Event\n  KM3-230213A","summary":"The detection of a $\\simeq220$~PeV muon neutrino by the KM3NeT neutrino\ntelescope offers an unprecedented opportunity to probe the Universe at extreme\nenergies. We analyze the origin of this event under three scenarios, viz., a\ntransient point source, a diffuse astrophysical emission, and line-of-sight\ninteraction of ultrahigh-energy cosmic rays (UHECR; $E \\gtrsim 0.1$~EeV). Our\nanalysis includes the flux from both a KM3NeT-only fit and a joint fit,\nincorporating data from KM3NeT, IceCube, and Pierre Auger Observatory. If the\nneutrino event originates from transients, it requires a new population of\ntransient that is energetic, gamma-ray dark, and more abundant than known ones.\nIn the framework of diffuse astrophysical emission, we compare the required\nlocal UHECR energy injection rate at $\\gtrsim4$ EeV, assuming a proton primary,\nwith the rate derived from the flux measurements by Auger. This disfavors the\nKM3NeT-only fit at all redshifts, while the joint fit remains viable for\n$z\\gtrsim 1$, based on redshift evolution models of known source populations.\nFor cosmogenic origin from point sources, our results suggest that the\nluminosity obtained at redshifts $z \\lesssim 1$ from the joint fit is\ncompatible with the Eddington luminosity of supermassive black holes in active\ngalactic nuclei.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T04:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.10854v1","title":"LVLM_CSP: Accelerating Large Vision Language Models via Clustering,\n  Scattering, and Pruning for Reasoning Segmentation","summary":"Large Vision Language Models (LVLMs) have been widely adopted to guide vision\nfoundation models in performing reasoning segmentation tasks, achieving\nimpressive performance. However, the substantial computational overhead\nassociated with LVLMs presents a new challenge. The primary source of this\ncomputational cost arises from processing hundreds of image tokens. Therefore,\nan effective strategy to mitigate such overhead is to reduce the number of\nimage tokens, a process known as image token pruning. Previous studies on image\ntoken pruning for LVLMs have primarily focused on high level visual\nunderstanding tasks, such as visual question answering and image captioning. In\ncontrast, guiding vision foundation models to generate accurate visual masks\nbased on textual queries demands precise semantic and spatial reasoning\ncapabilities. Consequently, pruning methods must carefully control individual\nimage tokens throughout the LVLM reasoning process. Our empirical analysis\nreveals that existing methods struggle to adequately balance reductions in\ncomputational overhead with the necessity to maintain high segmentation\naccuracy. In this work, we propose LVLM_CSP, a novel training free visual token\npruning method specifically designed for LVLM based reasoning segmentation\ntasks. LVLM_CSP consists of three stages: clustering, scattering, and pruning.\nInitially, the LVLM performs coarse-grained visual reasoning using a subset of\nselected image tokens. Next, fine grained reasoning is conducted, and finally,\nmost visual tokens are pruned in the last stage. Extensive experiments\ndemonstrate that LVLM_CSP achieves a 65% reduction in image token inference\nFLOPs with virtually no accuracy degradation, and a 70% reduction with only a\nminor 1% drop in accuracy on the 7B LVLM.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T04:27:15Z"}
{"aid":"http://arxiv.org/abs/2504.10859v1","title":"A Sublinear Algorithm for Path Feasibility Among Rectangular Obstacles","summary":"The problem of finding a path between two points while avoiding obstacles is\ncritical in robotic path planning. We focus on the feasibility problem:\ndetermining whether such a path exists. We model the robot as a query-specific\nrectangular object capable of moving parallel to its sides. The obstacles are\naxis-aligned, rectangular, and may overlap. Most previous works only consider\nnondisjoint rectangular objects and point-sized or statically sized robots. Our\napproach introduces a novel technique leveraging generalized Gabriel graphs and\nconstructs a data structure to facilitate online queries regarding path\nfeasibility with varying robot sizes in sublinear time. To efficiently handle\nfeasibility queries, we propose an online algorithm utilizing sweep line to\nconstruct a generalized Gabriel graph under the $L_\\infty$ norm, capturing key\ngap constraints between obstacles. We utilize a persistent disjoint-set union\ndata structure to efficiently determine feasibility queries in\n$\\mathcal{O}(\\log n)$ time and $\\mathcal{O}(n)$ total space.","main_category":"cs.CG","categories":"cs.CG,cs.RO","published":"2025-04-15T04:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.10878v1","title":"Large Language Model-Informed Feature Discovery Improves Prediction and\n  Interpretation of Credibility Perceptions of Visual Content","summary":"In today's visually dominated social media landscape, predicting the\nperceived credibility of visual content and understanding what drives human\njudgment are crucial for countering misinformation. However, these tasks are\nchallenging due to the diversity and richness of visual features. We introduce\na Large Language Model (LLM)-informed feature discovery framework that\nleverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and\nexplain its reasoning. We extract and quantify interpretable features using\ntargeted prompts and integrate them into machine learning models to improve\ncredibility predictions. We tested this approach on 4,191 visual social media\nposts across eight topics in science, health, and politics, using credibility\nratings from 5,355 crowdsourced workers. Our method outperformed zero-shot\nGPT-based predictions by 13 percent in R2, and revealed key features like\ninformation concreteness and image format. We discuss the implications for\nmisinformation mitigation, visual credibility, and the role of LLMs in social\nscience.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-15T05:11:40Z"}
{"aid":"http://arxiv.org/abs/2504.10879v1","title":"Strain effect on optical properties and quantum weight of 2D magnetic\n  topological insulators MnBi$_2$X$_4$ (X = Te, Se, S)","summary":"Manipulating the optical and quantum properties of two-dimensional (2D)\nmaterials through strain engineering is not only fundamentally interesting but\nalso provides significant benefits across various applications. In this work,\nwe employ first-principles calculations to investigate the effects of strain on\nthe magnetic and optical properties of 2D topological insulators MnBi$_2$X$_4$\n(X = Te, Se, S). Our results indicate that biaxial strain enhances the Mn\nmagnetic moment, while uniaxial strains reduce it. Significantly, the\nstrain-dependent behavior, quantified through the quantum weight, can be\nleveraged to control the system's quantum geometry and topological features.\nParticularly, uniaxial strains reduce the quantum weight and introduce\nanisotropy, thus providing an additional degree of freedom to tailor device\nfunctionalities. Finally, by analyzing chemical bonds under various strain\ndirections, we elucidate how the intrinsic ductile or brittle fracture behavior\nof MnBi$_2$X$_4$ could impact fabrication protocols and structural stability.\nThese insights pave the way for strain-based approaches to optimize the quantum\nproperties in 2D magnetic topological insulators in practical device contexts.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-15T05:18:21Z"}
{"aid":"http://arxiv.org/abs/2504.10886v1","title":"Exploring Persona-dependent LLM Alignment for the Moral Machine\n  Experiment","summary":"Deploying large language models (LLMs) with agency in real-world applications\nraises critical questions about how these models will behave. In particular,\nhow will their decisions align with humans when faced with moral dilemmas? This\nstudy examines the alignment between LLM-driven decisions and human judgment in\nvarious contexts of the moral machine experiment, including personas reflecting\ndifferent sociodemographics. We find that the moral decisions of LLMs vary\nsubstantially by persona, showing greater shifts in moral decisions for\ncritical tasks than humans. Our data also indicate an interesting partisan\nsorting phenomenon, where political persona predominates the direction and\ndegree of LLM decisions. We discuss the ethical implications and risks\nassociated with deploying these models in applications that involve moral\ndecisions.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL","published":"2025-04-15T05:29:51Z"}
{"aid":"http://arxiv.org/abs/2504.10895v1","title":"Weighted norm inequalities of higher-order Riesz transforms associated\n  with Laguerre expansions","summary":"Let $\\nu=(\\nu_1,\\ldots,\\nu_n)\\in (-1,\\vc)^n$, $n\\ge 1$, and let\n$\\mathcal{L}_\\nu$ be a self-adjoint extension of the differential operator \\[\nL_\\nu := \\sum_{i=1}^n \\left[-\\frac{\\partial^2}{\\partial x_i^2} + x_i^2 +\n\\frac{1}{x_i^2}(\\nu_i^2 - \\frac{1}{4})\\right] \\] on\n$C_c^\\infty(\\mathbb{R}_+^n)$ as the natural domain. The $j$-th partial\nderivative associated with $L_{\\nu}$ is given by \\[ \\delta_{\\nu_j} =\n\\frac{\\partial}{\\partial x_j} + x_j-\\frac{1}{x_j}\\Big(\\nu_j + \\f{1}{2}\\Big), \\\n\\ \\ \\ j=1,\\ldots, n. \\] In this paper, we investigate the weighted estimates of\nthe higher-order Riesz transforms $\\delta_\\nu^k\\mathcal L^{-|k|/2}_\\nu, k\\in\n\\mathbb N^n$, where $\\delta_\\nu^k=\\delta_{\\nu_n}^{k_n}\\ldots\n\\delta_{\\nu_1}^{k_1}$. This completes the description of the boundedness of the\nhigher-order Riesz transforms with the full range $\\nu \\in (-1,\\vc)^n$.","main_category":"math.CA","categories":"math.CA","published":"2025-04-15T06:12:59Z"}
{"aid":"http://arxiv.org/abs/2504.10911v1","title":"Low-Overhead Channel Estimation Framework for Beyond Diagonal\n  Reconfigurable Intelligent Surface Assisted Multi-User MIMO Communication","summary":"Beyond diagonal reconfigurable intelligent surface (BD-RIS) refers to a\nfamily of RIS architectures characterized by scattering matrices not limited to\nbeing diagonal and enables higher wave manipulation flexibility and large\nperformance gains over conventional (diagonal) RIS. To achieve those promising\ngains, accurate channel state information (CSI) needs to be acquired in BD-RIS\nassisted communication systems. However, the number of coefficients in the\ncascaded channels to be estimated in BD-RIS assisted systems is significantly\nlarger than that in conventional RIS assisted systems, because the channels\nassociated with the off-diagonal elements of the scattering matrix have to be\nestimated as well. Surprisingly, for the first time in the literature, this\npaper rigorously shows that the uplink channel estimation overhead in BD-RIS\nassisted systems is actually of the same order as that in the conventional RIS\nassisted systems. This amazing result stems from a key observation: for each\nuser antenna, its cascaded channel matrix associated with one reference BD-RIS\nelement is a scaled version of that associated with any other BD-RIS element\ndue to the common RIS-base station (BS) channel. In other words, the number of\nindependent unknown variables is far less than it would seem at first glance.\nBuilding upon this property, this paper manages to characterize the minimum\noverhead to perfectly estimate all the channels in the ideal case without noise\nat the BS, and propose a twophase estimation framework for the practical case\nwith noise at the BS. Numerical results demonstrate outstanding channel\nestimation overhead reduction over existing schemes in BD-RIS assisted systems.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-15T06:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.10913v1","title":"douka: A universal platform of data assimilation for materials modeling","summary":"A large-scale, general-purpose data assimilation (DA) platform for materials\nmodeling, douka, was developed and applied to nonlinear materials models. The\nplatform demonstrated its effectiveness in estimating physical properties that\ncannot be directly obtained from observed data. DA was successfully performed\nusing experimental images of oxygen evolution reaction at a water electrolysis\nelectrode, enabling the estimation of oxygen gas injection velocity and bubble\ncontact angle. Furthermore, large-scale ensemble DA was conducted on the\nsupercomputer Fugaku, achieving state estimation with up to 8,192 ensemble\nmembers. The results confirmed that runtime scaling for the prediction step\nfollows the weak scaling law, ensuring computational efficiency even with\nincreased ensemble sizes. These findings highlight the potential of douka as a\nnew approach for data-driven materials science, integrating experimental data\nwith numerical simulation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-15T06:49:24Z"}
{"aid":"http://arxiv.org/abs/2504.10917v1","title":"Towards A Universal Graph Structural Encoder","summary":"Recent advancements in large-scale pre-training have shown the potential to\nlearn generalizable representations for downstream tasks. In the graph domain,\nhowever, capturing and transferring structural information across different\ngraph domains remains challenging, primarily due to the inherent differences in\ntopological patterns across various contexts. Additionally, most existing\nmodels struggle to capture the complexity of rich graph structures, leading to\ninadequate exploration of the embedding space. To address these challenges, we\npropose GFSE, a universal graph structural encoder designed to capture\ntransferable structural patterns across diverse domains such as molecular\ngraphs, social networks, and citation networks. GFSE is the first cross-domain\ngraph structural encoder pre-trained with multiple self-supervised learning\nobjectives. Built on a Graph Transformer, GFSE incorporates attention\nmechanisms informed by graph inductive bias, enabling it to encode intricate\nmulti-level and fine-grained topological features. The pre-trained GFSE\nproduces generic and theoretically expressive positional and structural\nencoding for graphs, which can be seamlessly integrated with various downstream\ngraph feature encoders, including graph neural networks for vectorized features\nand Large Language Models for text-attributed graphs. Comprehensive experiments\non synthetic and real-world datasets demonstrate GFSE's capability to\nsignificantly enhance the model's performance while requiring substantially\nless task-specific fine-tuning. Notably, GFSE achieves state-of-the-art\nperformance in 81.6% evaluated cases, spanning diverse graph models and\ndatasets, highlighting its potential as a powerful and versatile encoder for\ngraph-structured data.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T06:57:26Z"}
{"aid":"http://arxiv.org/abs/2504.10943v1","title":"Drivers and barriers of adopting shared micromobility: a latent class\n  clustering model on the attitudes towards shared micromobility as part of\n  public transport trips in the Netherlands","summary":"Shared micromobility (SMM) is often cited as a solution to the first/last\nmile problem of public transport (train) travel, yet when implemented, they\noften do not get adopted by a broader travelling public. A large part of\nbehavioural adoption is related to peoples' attitudes and perceptions. In this\npaper, we develop an adjusted behavioural framework, based on the UTAUT2\ntechnology acceptance framework. We carry out an exploratory factor analysis\n(EFA) to obtain attitudinal factors which we then use to perform a latent class\ncluster analysis (LCCA), with the goal of studying the potential adoption of\nSMM and to assess the various drivers and barriers as perceived by different\nuser groups. Our findings suggest there are six distinct user groups with\nvarying intention to use shared micromobility: Progressives, Conservatives,\nHesitant participants, Bold innovators, Anxious observers and Skilled sceptics.\nBold innovators and Progressives tend to be the most open to adopting SMM and\nare also able to do so. Hesitant participants would like to, but find it\ndifficult or dangerous to use, while Skilled sceptics are capable and\nconfident, but have limited intention of using it. Conservatives and Anxious\nobservers are most negative about SMM, finding it difficult to use and\ndangerous. In general, factors relating to technological savviness,\nease-of-use, physical safety and societal perception seem to be the biggest\nbarriers to wider adoption. Younger, highly educated males are the group most\nlikely and open to using shared micromobility, while older individuals with\nlower incomes and a lower level of education tend to be the least likely.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-15T07:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.10949v1","title":"A Primer on Orthogonal Delay-Doppler Division Multiplexing (ODDM)","summary":"As a new type of multicarrier (MC) scheme built upon the recently discovered\ndelay-Doppler domain orthogonal pulse (DDOP), orthogonal delay-Doppler division\nmultiplexing (ODDM) aims to address the challenges of waveform design in linear\ntime-varying channels. In this paper, we explore the design principles of ODDM\nand clarify the key ideas underlying the DDOP. We then derive an alternative\nrepresentation of the DDOP and highlight the fundamental differences between\nODDM and conventional MC schemes. Finally, we discuss and compare two\nimplementation methods for ODDM.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-15T07:56:44Z"}
{"aid":"http://arxiv.org/abs/2504.10950v1","title":"Unveiling Challenges for LLMs in Enterprise Data Engineering","summary":"Large Language Models (LLMs) have demonstrated significant potential for\nautomating data engineering tasks on tabular data, giving enterprises a\nvaluable opportunity to reduce the high costs associated with manual data\nhandling. However, the enterprise domain introduces unique challenges that\nexisting LLM-based approaches for data engineering often overlook, such as\nlarge table sizes, more complex tasks, and the need for internal knowledge. To\nbridge these gaps, we identify key enterprise-specific challenges related to\ndata, tasks, and background knowledge and conduct a comprehensive study of\ntheir impact on recent LLMs for data engineering. Our analysis reveals that\nLLMs face substantial limitations in real-world enterprise scenarios, resulting\nin significant accuracy drops. Our findings contribute to a systematic\nunderstanding of LLMs for enterprise data engineering to support their adoption\nin industry.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T07:57:05Z"}
{"aid":"http://arxiv.org/abs/2504.10953v1","title":"Intraoperative perfusion assessment by continuous, low-latency\n  hyperspectral light-field imaging: development, methodology, and clinical\n  application","summary":"Accurate assessment of tissue perfusion is crucial in visceral surgery,\nespecially during anastomosis. Currently, subjective visual judgment is\ncommonly employed in clinical settings. Hyperspectral imaging (HSI) offers a\nnon-invasive, quantitative alternative. However, HSI imaging lacks continuous\nintegration into the clinical workflow. This study presents a hyperspectral\nlight field system for intraoperative tissue oxygen saturation (SO2) analysis\nand visualization. We present a correlation method for determining SO2\nsaturation with low computational demands. We demonstrate clinical application,\nwith our results aligning with the perfusion boundaries determined by the\nsurgeon. We perform and compare continuous perfusion analysis using two\nhyperspectral cameras (Cubert S5, Cubert X20), achieving processing times of <\n170 ms and < 400 ms, respectively. We discuss camera characteristics, system\nparameters, and the suitability for clinical use and real-time applications.","main_category":"eess.IV","categories":"eess.IV,physics.med-ph","published":"2025-04-15T07:59:04Z"}
{"aid":"http://arxiv.org/abs/2504.10957v1","title":"When is Task Vector Provably Effective for Model Editing? A\n  Generalization Analysis of Nonlinear Transformers","summary":"Task arithmetic refers to editing the pre-trained model by adding a weighted\nsum of task vectors, each of which is the weight update from the pre-trained\nmodel to fine-tuned models for certain tasks. This approach recently gained\nattention as a computationally efficient inference method for model editing,\ne.g., multi-task learning, forgetting, and out-of-domain generalization\ncapabilities. However, the theoretical understanding of why task vectors can\nexecute various conceptual operations remains limited, due to the highly\nnon-convexity of training Transformer-based models. To the best of our\nknowledge, this paper provides the first theoretical characterization of the\ngeneralization guarantees of task vector methods on nonlinear Transformers. We\nconsider a conceptual learning setting, where each task is a binary\nclassification problem based on a discriminative pattern. We theoretically\nprove the effectiveness of task addition in simultaneously learning a set of\nirrelevant or aligned tasks, as well as the success of task negation in\nunlearning one task from irrelevant or contradictory tasks. Moreover, we prove\nthe proper selection of linear coefficients for task arithmetic to achieve\nguaranteed generalization to out-of-domain tasks. All of our theoretical\nresults hold for both dense-weight parameters and their low-rank\napproximations. Although established in a conceptual setting, our theoretical\nfindings were validated on a practical machine unlearning task using the large\nlanguage model Phi-1.5 (1.3B).","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T08:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.10963v1","title":"Modeling liquid-mediated interactions for close-to-substrate magnetic\n  microparticle transport in dynamic magnetic field landscapes","summary":"Understanding the on-chip motion of magnetic particles in a microfluidic\nenvironment is key to realizing magnetic particle-based Lab-on-a-chip systems\nfor medical diagnostics. In this work, a simulation model is established to\nquantify the trajectory of a single particle moving close to a polymer surface\nin a quiescent liquid. The simulations include hydrodynamic, magnetostatic, and\nDerjaguin-Landau-Verwey-Overbeek (DLVO) interactions. They are applied to\nparticle motion driven by a dynamically changing magnetic field landscape\ncreated by engineered parallel-stripe magnetic domains superposed by a\nhomogeneous, time-varying external magnetic field. The simulation model is\nadapted to experiments in terms of fluid-particle interactions with the\nmagnetic field landscape approximated by analytic equations under the\nassumption of surface charges. Varying simulation parameters, we especially\nclarify the impact of liquid-mediated DLVO interactions, which are essential\nfor diagnostic applications, on the 3D trajectory of the particle. A comparison\nto experimental results validates our simulation approach.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.app-ph,physics.comp-ph","published":"2025-04-15T08:14:16Z"}
{"aid":"http://arxiv.org/abs/2504.10980v1","title":"Planar Hall effect in ultrathin topological insulator films","summary":"The planar Hall effect (PHE), previously observed in Weyl and Dirac\nsemimetals due to the chiral anomaly, emerges with a different origin in\ntopological insulators (TIs), where in-plane magnetic fields induce resistivity\nanisotropy. In strictly two-dimensional TIs, PHE is generally suppressed due to\nthe inability of the out-of-plane Berry curvature to couple to the in-plane\nband velocity of the charge carriers. Here, we demonstrate that in ultrathin TI\nfilms, a quasi-two-dimensional system, intersurface tunneling coupling with\nin-plane magnetization induces electronic anisotropy, enabling a finite PHE. In\naddition, we reveal that strong in-plane magnetization can stabilize the\nthickness-dependent quantum anomalous Hall effect, typically associated with\nout-of-plane magnetization. These insights advance the understanding of\nmagnetic topological phases, paving the way for next-generation spintronic\ndevices and magnetic sensing technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T08:45:02Z"}
{"aid":"http://arxiv.org/abs/2504.10985v1","title":"DMPT: Decoupled Modality-aware Prompt Tuning for Multi-modal Object\n  Re-identification","summary":"Current multi-modal object re-identification approaches based on large-scale\npre-trained backbones (i.e., ViT) have displayed remarkable progress and\nachieved excellent performance. However, these methods usually adopt the\nstandard full fine-tuning paradigm, which requires the optimization of\nconsiderable backbone parameters, causing extensive computational and storage\nrequirements. In this work, we propose an efficient prompt-tuning framework\ntailored for multi-modal object re-identification, dubbed DMPT, which freezes\nthe main backbone and only optimizes several newly added decoupled\nmodality-aware parameters. Specifically, we explicitly decouple the visual\nprompts into modality-specific prompts which leverage prior modality knowledge\nfrom a powerful text encoder and modality-independent semantic prompts which\nextract semantic information from multi-modal inputs, such as visible,\nnear-infrared, and thermal-infrared. Built upon the extracted features, we\nfurther design a Prompt Inverse Bind (PromptIBind) strategy that employs bind\nprompts as a medium to connect the semantic prompt tokens of different\nmodalities and facilitates the exchange of complementary multi-modal\ninformation, boosting final re-identification results. Experimental results on\nmultiple common benchmarks demonstrate that our DMPT can achieve competitive\nresults to existing state-of-the-art methods while requiring only 6.5%\nfine-tuning of the backbone parameters.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:48:41Z"}
{"aid":"http://arxiv.org/abs/2504.10990v1","title":"Mathematical Analysis of the PDE Model for the Consensus-based\n  Optimization","summary":"In this paper, we develop an analytical framework for the partial\ndifferential equation underlying the consensus-based optimization model. The\nmain challenge arises from the nonlinear, nonlocal nature of the consensus\npoint, coupled with a diffusion term that is both singular and degenerate. By\nemploying a regularization procedure in combination with a compactness\nargument, we establish the global existence and uniqueness of weak solutions in\n$L^\\infty(0,T;L^1\\cap L^\\infty(\\mathbb{R}^d))$. Furthermore, we show that the\nweak solutions exhibit improved $H^2$-regularity when the initial data is\nregular.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-15T09:02:36Z"}
{"aid":"http://arxiv.org/abs/2504.10995v1","title":"TMCIR: Token Merge Benefits Composed Image Retrieval","summary":"Composed Image Retrieval (CIR) retrieves target images using a multi-modal\nquery that combines a reference image with text describing desired\nmodifications. The primary challenge is effectively fusing this visual and\ntextual information. Current cross-modal feature fusion approaches for CIR\nexhibit an inherent bias in intention interpretation. These methods tend to\ndisproportionately emphasize either the reference image features\n(visual-dominant fusion) or the textual modification intent (text-dominant\nfusion through image-to-text conversion). Such an imbalanced representation\noften fails to accurately capture and reflect the actual search intent of the\nuser in the retrieval results. To address this challenge, we propose TMCIR, a\nnovel framework that advances composed image retrieval through two key\ninnovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP\nencoders contrastively using intent-reflecting pseudo-target images,\nsynthesized from reference images and textual descriptions via a diffusion\nmodel. This step enhances the encoder ability of text to capture nuanced\nintents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune\nall encoders contrastively by comparing adaptive token-fusion features with the\ntarget image. This mechanism dynamically balances visual and textual\nrepresentations within the contrastive learning pipeline, optimizing the\ncomposed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR\ndatasets demonstrate that TMCIR significantly outperforms state-of-the-art\nmethods, particularly in capturing nuanced user intent.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T09:14:04Z"}
{"aid":"http://arxiv.org/abs/2504.10996v1","title":"Denoising Application Performance Models with Noise-Resilient Priors","summary":"When scaling parallel codes to larger machines, performance models help\nidentify potential bottlenecks. Since analytically designing these mathematical\nrepresentations is usually challenging, empirical models based on performance\nmeasurements offer a practical alternative. Yet, measurements on HPC systems\nare typically affected by noise, leading to potentially misleading model\npredictions. To reduce the influence of noise, we introduce\napplication-specific dynamic priors into the modeling process, which we derive\nfrom noise-resilient measurements of computational effort and knowledge of\ntypical algorithms used in communication routines. These priors then narrow the\nsearch space for our performance models, excluding complexity classes that\nreflect noise rather than performance. Our approach keeps the models much\ncloser to theoretical expectations and significantly improves their predictive\npower. Finally, it cuts experimental costs in half by minimizing the number of\nrepeated measurements.","main_category":"cs.PF","categories":"cs.PF,cs.DC","published":"2025-04-15T09:14:18Z"}
{"aid":"http://arxiv.org/abs/2504.11013v1","title":"Effective Theory of Ultrafast Skyrmion Nucleation","summary":"Laser-induced ultrafast skyrmion nucleation has been experimentally\ndemonstrated in several materials. So far, atomistic models have been used to\ncorroborate experimental results. However, such simulations do not provide a\nsimple intuitive understanding of the underlying physics. Here, we propose a\ncoarse-grained effective theory where skyrmions can be nucleated or annihilated\nby thermal activation over energy barriers. Evaluating these two processes\nduring a heat pulse shows good agreement with atomistic spin dynamics\nsimulations and experiments while drastically reducing computational\ncomplexity. Furthermore, the effective theory provides a direct guide for\nexperimentally optimizing the number of nucleated skyrmions. Interestingly, the\nmodel also predicts a novel pathway for ultrafast annihilation of skyrmions.\nOur results pave the way for a deeper understanding of ultrafast nanomagnetism\nand the role of non-equilibrium physics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T09:34:15Z"}
{"aid":"http://arxiv.org/abs/2504.11016v1","title":"Heating reduction as collective action: Impact on attitudes, behavior\n  and energy consumption in a Polish field experiment","summary":"Heating and hot water usage account for nearly 80% of household energy\nconsumption in the European Union. In order to reach the EU New Deal goals, new\npolicies to reduce heat energy consumption are indispensable. However, research\ntargeting reductions concentrates either on technical building interventions\nwithout considerations of people's behavior, or psychological interventions\nwith no technical interference. Such interventions can be promising, but their\ntrue potential for scaling up can only be realized by testing approaches that\nintegrate behavioral and technical solutions in tandem rather than in\nisolation. In this research, we study a mix of psychological and technical\ninterventions targeting heating and hot water demand among students in Polish\nuniversity dormitories. We evaluate effects on building energy consumption,\nbehavioral spillovers and on social beliefs and attitudes in a pre-post\nquasi-experimental mixed-method field study in three student dormitories. Our\nfindings reveal that the most effective approaches to yield energy savings were\na direct, collectively framed request to students to reduce thermostat settings\nfor the environment, and an automated technical adjustment of the heating curve\ntemperature. Conversely, interventions targeting domestic hot water had\nunintended effects, including increased energy use and negative spillovers,\nsuch as higher water consumption. Further, we find that informing students\nabout their active, collective participation had a positive impact on perceived\nsocial norms. Our findings highlight the importance of trialing interventions\nin controlled real-world settings to understand the interplay between technical\nsystems, behaviors, and social impacts to enable scalable, evidence-based\npolicies driving an effective and sustainable energy transition.","main_category":"cs.ET","categories":"cs.ET,cs.CY","published":"2025-04-15T09:41:37Z"}
{"aid":"http://arxiv.org/abs/2504.11036v1","title":"Phase-space quantum distorted stability pattern for Aubry-Andr-Harper\n  dynamics","summary":"Instability features associated to topological quantum domains which emerge\nfrom the Weyl-Wigner (WW) quantum phase-space description of Gaussian ensembles\ndriven by Aubry-Andr\\'e-Harper (AAH) Hamiltonians are investigated. Hyperbolic\nequilibrium and stability patterns are then identified and classified according\nto the associated (nonlinear) AAH Hamiltonian parameters. Besides providing the\ntools for quantifying the information content of AAH systems, the Wigner flow\npatterns here discussed suggest a systematic procedure for identifying the role\nof quantum fluctuations over equilibrium and stability, in a framework which\ncan be straightforwardly extended to describe the evolution of similar/modified\nAAH systems.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-15T09:58:20Z"}
{"aid":"http://arxiv.org/abs/2504.11047v1","title":"Hints for a Geon from Causal Dynamic Triangulations","summary":"The existence of geons, physical states of self-bound gravitons, has long\nbeen proposed. In the context of four-dimensional causal dynamical\ntriangulation simulations we investigate this possibility by measuring\ncurvature-curvature correlators of different gravitational operators. We find a\nbehavior consistent with a massive state, independent of the operators\nconsidered, over a certain distance window. While at most a hint, this is\ntantalizing due to its possible implications for dark matter or (primordial)\nblack holes. We also find indications that the phase of rapid expansion of the\nobtained de Sitter universe impacts the mass, and relates to quantum\nfluctuations of space-time.","main_category":"hep-lat","categories":"hep-lat,gr-qc,hep-ph,hep-th","published":"2025-04-15T10:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.11052v1","title":"Weyl-mediated Ruderman-Kittel-Kasuya-Yosida interaction revisited:\n  imaginary-time formalism and finite temperature effects","summary":"Noncentrosymmetric magnetic Weyl semimetals provide a platform for\ninvestigating the interplay among magnetism, inversion symmetry breaking, and\ntopologically nontrivial Weyl fermions. The Weyl-mediated\nRuderman-Kittel-Kasuya-Yosida (RKKY) interaction may be related to the magnetic\norders observed in rare-earth magnetic Weyl semimetals. Previous studies of\nRKKY interaction between magnetic impurities in Weyl semimetals found\nHeisenberg, Ising-like, and Dzyaloshinskii-Moriya (DM) types of interactions.\nHowever, different range functions are obtained in the literature. In this\nwork, we calculate the Weyl-mediated RKKY interaction by using the\ndivergence-free imaginary-time formalism and obtain exact analytical results at\nfinite temperature. The discrepancies among zero temperature range functions in\nthe literature are resolved. At nonzero temperature, the interaction strength\ndecays exponentially in the long distance limit. But in the short distance\nlimit, the DM interaction shows a thermal enhancement, an effect persists up to\nhigher temperature for shorter distance. This provides a mechanism stabilizing\nthe helical order observed in rare-earth magnetic Weyl semimetals.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T10:39:59Z"}
{"aid":"http://arxiv.org/abs/2504.11060v1","title":"Goos-Hnchen Shift and Photonic Spin Hall Effect in Semi-Dirac\n  Material Heterostructures","summary":"We investigate the photonic spin Hall effect (PSHE) and the Goos-H\\\"anchen\nshift (GH shift) in semi-Dirac\n  materials. Through theoretical modeling, we demonstrate that the anisotropic\ndielectric function in semi-Dirac\n  materials play a critical role in determining the magnitude and polarity of\nthese optical displacements. Further more, by utilizing the unidirectional\ndrift of massless Dirac electrons in Semi-Dirac materials, we systematically\n  reveal how the drift velocity and direction modulate the behavior of optical\ndisplacements. The results indicate\n  that semi-Dirac materials provide a versatile platform for controlling\nspin-dependent photonic phenomena with\n  their material anisotropy and carrier transport. This work opens a new avenue\nfor designing advanced photonic\n  devices with tunable optical responses, particularly with significant\napplication potential in quantum information\n  processing and topological photonics.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T10:48:19Z"}
{"aid":"http://arxiv.org/abs/2504.11061v1","title":"Synthesis and characterization of gold-coated nanodiamonds through green\n  chemistry as potential radiosensitizers for proton therapy","summary":"In this work the synthesis and characterization of novel gold-nanodiamond\nnanoparticles was performed. The synthesis was based on the reduction of gold\nonto the different types of nanodiamond (annealed or annealed and oxidized, 50\nor 230 nm) using root extracts of Nympheaea alba as a reducing agent. These\ngold-coated nanodiamonds were characterized by UV-Vis, PXRD, DLS,\nzeta-potential, PIXE, Raman, SEM, and TEM, assessing particle size, stability,\nand gold coating effectiveness. Cellular studies in the A549 and Panc1 cancer\ncell lines assessed uptake, cytotoxicity, and colony formation to evaluate\nNDAu's biological activity. NDAu demonstrated strong cellular uptake and\ncytotoxic effects in A549 and Panc1 cell lines, reducing cell survival in\nclonogenic assay. Futher research in the capabilites of these nanoparticles for\nproton therapy will be performed.","main_category":"hep-ex","categories":"hep-ex,cond-mat.mtrl-sci","published":"2025-04-15T10:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.11070v1","title":"Uncertainty-aware electronic density-functional distributions","summary":"We introduce a method for the estimation of uncertainties in\ndensity-functional-theory (DFT) calculations for atomistic systems. The method\nis based on the construction of an uncertainty-aware functional distribution\n(UAFD) in a space spanned by a few different exchange-correlation functionals\nand is illustrated at the level of generalized-gradient-approximation\nfunctionals. The UAFD provides reliable estimates of errors -- compared to\nexperiments or higher-quality calculations -- in calculations performed\nself-consistently with the Perdew-Burke-Ernzerhof functional. The scheme\nfurthermore allows for a decomposition of the error into a systematic bias and\na reduced error. The approach is applied to four different properties:\nmolecular atomization energies, cohesive energies, lattice constants, and bulk\nmoduli of solids. The probability distribution can be tailored to optimize the\nprediction of a single property or for several properties simultaneously.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.data-an","published":"2025-04-15T11:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.11085v1","title":"TD-Suite: All Batteries Included Framework for Technical Debt\n  Classification","summary":"Recognizing that technical debt is a persistent and significant challenge\nrequiring sophisticated management tools, TD-Suite offers a comprehensive\nsoftware framework specifically engineered to automate the complex task of its\nclassification within software projects. It leverages the advanced natural\nlanguage understanding of state-of-the-art transformer models to analyze\ntextual artifacts, such as developer discussions in issue reports, where subtle\nindicators of debt often lie hidden.\n  TD-Suite provides a seamless end-to-end pipeline, managing everything from\ninitial data ingestion and rigorous preprocessing to model training, thorough\nevaluation, and final inference. This allows it to support both straightforward\nbinary classification (debt or no debt) and more valuable, identifying specific\ncategories like code, design, or documentation debt, thus enabling more\ntargeted management strategies.\n  To ensure the generated models are robust and perform reliably on real-world,\noften imbalanced, datasets, TD-Suite incorporates critical training\nmethodologies: k-fold cross-validation assesses generalization capability,\nearly stopping mechanisms prevent overfitting to the training data, and class\nweighting strategies effectively address skewed data distributions. Beyond core\nfunctionality, and acknowledging the growing importance of sustainability, the\nframework integrates tracking and reporting of carbon emissions associated with\nthe computationally intensive model training process.\n  It also features a user-friendly Gradio web interface in a Docker container\nsetup, simplifying model interaction, evaluation, and inference.","main_category":"cs.SE","categories":"cs.SE,cs.LG","published":"2025-04-15T11:31:17Z"}
{"aid":"http://arxiv.org/abs/2504.11087v1","title":"Quantum walk on a square lattice with identical particles","summary":"We investigate quantum superposition effects in two-dimensional quantum walks\nof identical particles with different statistics under particle exchange,\nstarting from various different initial configurations. To characterize\ninter-particle correlation dynamics, we focus on joint properties such as\ntwo-particle coincidence probabilities and the spread velocity of the\ninter-particle distance. Regarding spatial modes as an environment for the\nparticles internal degrees of freedom, we study the role played by the particle\nstatistics using standard entanglement witnesses, showing that particles\npossessing fermionic statistics are more resistant to thermalize with their\nenvironment. We analyze the presence of multipartite entanglement in the\nsystem's degrees of freedom through the Quantum Fisher Information, revealing\nthat fermionic states generated during the walk are better suited to perform\nquantum metrology tasks. Finally, we discuss the potential for implementing\nthis model using integrated photonic circuits by exploiting $N$-partite\nentanglement between individual photons.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T11:33:08Z"}
{"aid":"http://arxiv.org/abs/2504.11090v1","title":"Towards global equity in political polarization research","summary":"With a folk understanding that political polarization refers to\nsocio-political divisions within a society, many have proclaimed that we are\nmore divided than ever. In this account, polarization has been blamed for\npopulism, the erosion of social cohesion, the loss of trust in the institutions\nof democracy, legislative dysfunction, and the collective failure to address\nexistential risks such as Covid-19 or climate change. However, at a global\nscale there is surprisingly little academic literature which conclusively\nsupports these claims, with half of all studies being U.S.-focused. Here, we\nprovide an overview of the global state of research on polarization,\nhighlighting insights that are robust across countries, those unique to\nspecific contexts, and key gaps in the literature. We argue that addressing\nthese gaps is urgent, but has been hindered thus far by systemic and cultural\nbarriers, such as regionally stratified restrictions on data access and\nmisaligned research incentives. If continued cross-disciplinary inertia means\nthat these disparities are left unaddressed, we see a substantial risk that\ncountries will adopt policies to tackle polarization based on inappropriate\nevidence, risking flawed decision-making and the weakening of democratic\ninstitutions.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-15T11:34:12Z"}
{"aid":"http://arxiv.org/abs/2504.11092v1","title":"Vivid4D: Improving 4D Reconstruction from Monocular Video by Video\n  Inpainting","summary":"Reconstructing 4D dynamic scenes from casually captured monocular videos is\nvaluable but highly challenging, as each timestamp is observed from a single\nviewpoint. We introduce Vivid4D, a novel approach that enhances 4D monocular\nvideo synthesis by augmenting observation views - synthesizing multi-view\nvideos from a monocular input. Unlike existing methods that either solely\nleverage geometric priors for supervision or use generative priors while\noverlooking geometry, we integrate both. This reformulates view augmentation as\na video inpainting task, where observed views are warped into new viewpoints\nbased on monocular depth priors. To achieve this, we train a video inpainting\nmodel on unposed web videos with synthetically generated masks that mimic\nwarping occlusions, ensuring spatially and temporally consistent completion of\nmissing regions. To further mitigate inaccuracies in monocular depth priors, we\nintroduce an iterative view augmentation strategy and a robust reconstruction\nloss. Experiments demonstrate that our method effectively improves monocular 4D\nscene reconstruction and completion.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:38:14Z"}
{"aid":"http://arxiv.org/abs/2504.11095v1","title":"Magnetotransport and activation energy of the surface states in Cd3As2\n  thin films","summary":"Recent experiments performed the magnetotransport measurements in\n(001)-oriented Cd$_3$As$_2$ thin films and attributed the magnetotransport\nproperties to the surface states. In this paper, by using an effective model to\ndescribe the surface states, we analyze the Landau bands and then calculate the\nmagnetoconductivities and magnetoresistivities. From these results, the\nfeatures of two-dimensional quantum Hall effect of the surface states can be\ncaptured. More importantly, we reveal that the activation energy is determined\nby the Hall plateau width, which can explain the experimental observations that\nthe activation energies at odd plateaus are larger than those at even plateaus.\nWe also analyze the roles played by the structural inversion symmetry breaking\nand impurity scatterings in the magnetotransport, and suggest that their\ncombined effects would lead to the absence of some Hall plateaus.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T11:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.11099v1","title":"Double categories of profunctors","summary":"We characterize virtual double categories of enriched categories, functors,\nand profunctors by introducing a new notion of double-categorical colimits. Our\ncharacterization is strict in the sense that it is up to equivalence between\nvirtual double categories and, at the level of objects, up to isomorphism of\nenriched categories. Throughout the paper, we treat enrichment in a unital\nvirtual double category rather than in a bicategory or a monoidal category,\nand, for consistency and better visualization of pasting diagrams, we adopt\naugmented virtual double categories as a fundamental language for\ndouble-categorical concepts.","main_category":"math.CT","categories":"math.CT","published":"2025-04-15T11:45:59Z"}
{"aid":"http://arxiv.org/abs/2504.11111v1","title":"S$^2$Teacher: Step-by-step Teacher for Sparsely Annotated Oriented\n  Object Detection","summary":"Although fully-supervised oriented object detection has made significant\nprogress in multimodal remote sensing image understanding, it comes at the cost\nof labor-intensive annotation. Recent studies have explored weakly and\nsemi-supervised learning to alleviate this burden. However, these methods\noverlook the difficulties posed by dense annotations in complex remote sensing\nscenes. In this paper, we introduce a novel setting called sparsely annotated\noriented object detection (SAOOD), which only labels partial instances, and\npropose a solution to address its challenges. Specifically, we focus on two key\nissues in the setting: (1) sparse labeling leading to overfitting on limited\nforeground representations, and (2) unlabeled objects (false negatives)\nconfusing feature learning. To this end, we propose the S$^2$Teacher, a novel\nmethod that progressively mines pseudo-labels for unlabeled objects, from easy\nto hard, to enhance foreground representations. Additionally, it reweights the\nloss of unlabeled objects to mitigate their impact during training. Extensive\nexperiments demonstrate that S$^2$Teacher not only significantly improves\ndetector performance across different sparse annotation levels but also\nachieves near-fully-supervised performance on the DOTA dataset with only 10%\nannotation instances, effectively balancing detection accuracy with annotation\nefficiency. The code will be public.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:57:00Z"}
{"aid":"http://arxiv.org/abs/2504.11118v1","title":"Revealing Covert Attention by Analyzing Human and Reinforcement Learning\n  Agent Gameplay","summary":"This study introduces a novel method for revealing human covert attention\npatterns using gameplay data alone, utilizing offline attention techniques from\nreinforcement learning (RL). We propose the contextualized, task-relevant (CTR)\nattention network, which generates attention maps from both human and RL agent\ngameplay in Atari environments. These maps are sparse yet retain the necessary\ninformation for the current player's decision making. We compare the\nCTR-derived attention maps with a temporally integrated overt attention (TIOA)\nmodel based on eye-tracking data, serving as a point of comparison and\ndiscussion. Visual inspection reveals distinct attention patterns: human CTR\nmaps focus on the player and rather nearby opponents, occasionally shifting\nbetween stronger focus and broader views - sometimes even attending to empty\nspace ahead. In contrast, agent maps maintain a consistent broad focus on most\nobjects, including distant ones and the player. Quantitative analysis further\ndemonstrates that human CTR maps align more closely with TIOA than agent maps\ndo. Our findings indicate that the CTR attention network can effectively reveal\nhuman covert attention patterns from gameplay alone, without the need for\nadditional data like brain activity recordings. This work contributes to\nunderstanding human-agent attention differences and enables the development of\nRL agents augmented with human covert attention.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T12:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.11125v1","title":"A mixed-integer framework for analyzing neural network-based controllers\n  for piecewise affine systems with bounded disturbances","summary":"We present a method for representing the closed-loop dynamics of piecewise\naffine (PWA) systems with bounded additive disturbances and neural\nnetwork-based controllers as mixed-integer (MI) linear constraints. We show\nthat such representations enable the computation of robustly positively\ninvariant (RPI) sets for the specified system class by solving MI linear\nprograms. These RPI sets can subsequently be used to certify stability and\nconstraint satisfaction. Furthermore, the approach allows to handle non-linear\nsystems based on suitable PWA approximations and corresponding error bounds,\nwhich can be interpreted as the bounded disturbances from above.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T12:14:20Z"}
{"aid":"http://arxiv.org/abs/2504.11133v1","title":"Hessian stability and convergence rates for entropic and Sinkhorn\n  potentials via semiconcavity","summary":"In this paper we determine quantitative stability bounds for the Hessian of\nentropic potentials, i.e., the dual solution to the entropic optimal transport\nproblem. Up to authors' knowledge this is the first work addressing this\nsecond-order quantitative stability estimate in general unbounded settings. Our\nproof strategy relies on semiconcavity properties of entropic potentials and on\nthe representation of entropic transport plans as laws of forward and backward\ndiffusion processes, known as Schr\\\"odinger bridges. Moreover, our approach\nallows to deduce a stochastic proof of quantitative stability entropic\nestimates and integrated gradient estimates as well. Finally, as a direct\nconsequence of these stability bounds, we deduce exponential convergence rates\nfor gradient and Hessian of Sinkhorn iterates along Sinkhorn's algorithm, a\nproblem that was still open in unbounded settings. Our rates have a polynomial\ndependence on the regularization parameter.","main_category":"math.PR","categories":"math.PR,math.AP,math.OC,stat.ML","published":"2025-04-15T12:34:09Z"}
{"aid":"http://arxiv.org/abs/2504.11135v1","title":"The baryonic Tully-Fisher relation and Fundamental Plane in the light of\n  $f(R)$ gravity","summary":"Here we use the samples of spiral and elliptical galaxies, in order to\ninvestigate theoretically some of their properties and to test the empirical\nrelations, in the light of modified gravities. We show that the baryonic\nTully-Fisher relation can be described in the light of $f(R)$ gravity, without\nintroducing the dark matter. Also, it is possible to explain the features of\nfundamental plane of elliptical galaxies without the dark matter hypothesis.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T12:38:55Z"}
{"aid":"http://arxiv.org/abs/2504.11156v1","title":"A preliminary cosmological analysis of stellar population synthesis of\n  galaxies released by LAMOST LRS DR11","summary":"The evolution of the universe together with the galaxies is one of the\nfundamental issues that we humans are most interested in. Both the observations\nof tidal streams from SDSS and the theory of $\\Lambda$CDM support the\nhierarchical merging theory. The study of high redshift celestial bodies\ncontributes to a more in-depth study of cosmology. The LAMOST low resolution\nsearch catalog DR11 v1.0 has released 11,939,296 spectra, including 11,581,542\nstars, 275,302 galaxies, and 82,452 quasars, and so on. The data of 28,780\nstellar population synthesis of galaxies and some high redshift quasars are\nused to do a preliminary statistical research. We selected the data with small\nerrors for analysis and obtained some basic statistical conclusions. Older\ngalaxies have relatively larger stellar velocity dispersions. The larger the\nmetallicity, the greater the stellar velocity dispersion. These statistical\nresults are reasonable and consistent with previous work. Because the stellar\nvelocity dispersion is driven by the total mass of a galaxy at the first order\nand more massive galaxies have older ages and greater metallicities. The\nspectra of high redshift quasars show clear Gunn-Peterson trough and\nLyman-$\\alpha$ forest. The identified emission lines and high redshift\ncelestial spectra released by LAMOST can be used for cosmological research.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T13:01:48Z"}
{"aid":"http://arxiv.org/abs/2504.11162v1","title":"Scalable Transceiver Design for Multi-User Communication in FDD Massive\n  MIMO Systems via Deep Learning","summary":"This paper addresses the joint transceiver design, including pilot\ntransmission, channel feature extraction and feedback, as well as precoding,\nfor low-overhead downlink massive multiple-input multiple-output (MIMO)\ncommunication in frequency-division duplex (FDD) systems. Although deep\nlearning (DL) has shown great potential in tackling this problem, existing\nmethods often suffer from poor scalability in practical systems, as the\nsolution obtained in the training phase merely works for a fixed feedback\ncapacity and a fixed number of users in the deployment phase. To address this\nlimitation, we propose a novel DL-based framework comprised of choreographed\nneural networks, which can utilize one training phase to generate all the\ntransceiver solutions used in the deployment phase with varying sizes of\nfeedback codebooks and numbers of users. The proposed framework includes a\nresidual vector-quantized variational autoencoder (RVQ-VAE) for efficient\nchannel feedback and an edge graph attention network (EGAT) for robust\nmultiuser precoding. It can adapt to different feedback capacities by flexibly\nadjusting the RVQ codebook sizes using the hierarchical codebook structure, and\nscale with the number of users through a feedback module sharing scheme and the\ninherent scalability of EGAT. Moreover, a progressive training strategy is\nproposed to further enhance data transmission performance and generalization\ncapability. Numerical results on a real-world dataset demonstrate the superior\nscalability and performance of our approach over existing methods.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-15T13:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.11165v1","title":"YOLO-RS: Remote Sensing Enhanced Crop Detection Methods","summary":"With the rapid development of remote sensing technology, crop classification\nand health detection based on deep learning have gradually become a research\nhotspot. However, the existing target detection methods show poor performance\nwhen dealing with small targets in remote sensing images, especially in the\ncase of complex background and image mixing, which is difficult to meet the\npractical application requirementsite. To address this problem, a novel target\ndetection model YOLO-RS is proposed in this paper. The model is based on the\nlatest Yolov11 which significantly enhances the detection of small targets by\nintroducing the Context Anchor Attention (CAA) mechanism and an efficient\nmulti-field multi-scale feature fusion network. YOLO-RS adopts a bidirectional\nfeature fusion strategy in the feature fusion process, which effectively\nenhances the model's performance in the detection of small targets. Small\ntarget detection. Meanwhile, the ACmix module at the end of the model backbone\nnetwork solves the category imbalance problem by adaptively adjusting the\ncontrast and sample mixing, thus enhancing the detection accuracy in complex\nscenes. In the experiments on the PDT remote sensing crop health detection\ndataset and the CWC crop classification dataset, YOLO-RS improves both the\nrecall and the mean average precision (mAP) by about 2-3\\% or so compared with\nthe existing state-of-the-art methods, while the F1-score is also significantly\nimproved. Moreover, the computational complexity of the model only increases by\nabout 5.2 GFLOPs, indicating its significant advantages in both performance and\nefficiency. The experimental results validate the effectiveness and application\npotential of YOLO-RS in the task of detecting small targets in remote sensing\nimages.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:13:22Z"}
{"aid":"http://arxiv.org/abs/2504.11175v1","title":"Systoles on punctured spheres","summary":"We determine the maximal number of systoles among all spheres with $n$\npunctures endowed with a complete Riemannian metric of finite area.","main_category":"math.GT","categories":"math.GT,math.DG","published":"2025-04-15T13:30:45Z"}
{"aid":"http://arxiv.org/abs/2504.11195v1","title":"R-TPT: Improving Adversarial Robustness of Vision-Language Models\n  through Test-Time Prompt Tuning","summary":"Vision-language models (VLMs), such as CLIP, have gained significant\npopularity as foundation models, with numerous fine-tuning methods developed to\nenhance performance on downstream tasks. However, due to their inherent\nvulnerability and the common practice of selecting from a limited set of\nopen-source models, VLMs suffer from a higher risk of adversarial attacks than\ntraditional vision models. Existing defense techniques typically rely on\nadversarial fine-tuning during training, which requires labeled data and lacks\nof flexibility for downstream tasks. To address these limitations, we propose\nrobust test-time prompt tuning (R-TPT), which mitigates the impact of\nadversarial attacks during the inference stage. We first reformulate the\nclassic marginal entropy objective by eliminating the term that introduces\nconflicts under adversarial conditions, retaining only the pointwise entropy\nminimization. Furthermore, we introduce a plug-and-play reliability-based\nweighted ensembling strategy, which aggregates useful information from reliable\naugmented views to strengthen the defense. R-TPT enhances defense against\nadversarial attacks without requiring labeled training data while offering high\nflexibility for inference tasks. Extensive experiments on widely used\nbenchmarks with various attacks demonstrate the effectiveness of R-TPT. The\ncode is available in https://github.com/TomSheng21/R-TPT.","main_category":"cs.LG","categories":"cs.LG,cs.CR,cs.CV","published":"2025-04-15T13:49:31Z"}
{"aid":"http://arxiv.org/abs/2504.11202v1","title":"Focal Split: Untethered Snapshot Depth from Differential Defocus","summary":"We introduce Focal Split, a handheld, snapshot depth camera with fully\nonboard power and computing based on depth-from-differential-defocus (DfDD).\nFocal Split is passive, avoiding power consumption of light sources. Its\nachromatic optical system simultaneously forms two differentially defocused\nimages of the scene, which can be independently captured using two photosensors\nin a snapshot. The data processing is based on the DfDD theory, which\nefficiently computes a depth and a confidence value for each pixel with only\n500 floating point operations (FLOPs) per pixel from the camera measurements.\nWe demonstrate a Focal Split prototype, which comprises a handheld custom\ncamera system connected to a Raspberry Pi 5 for real-time data processing. The\nsystem consumes 4.9 W and is powered on a 5 V, 10,000 mAh battery. The\nprototype can measure objects with distances from 0.4 m to 1.2 m, outputting\n480$\\times$360 sparse depth maps at 2.1 frames per second (FPS) using\nunoptimized Python scripts. Focal Split is DIY friendly. A comprehensive guide\nto building your own Focal Split depth camera, code, and additional data can be\nfound at https://focal-split.qiguo.org.","main_category":"cs.CV","categories":"cs.CV,eess.IV,eess.SP,I.4.8","published":"2025-04-15T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.11210v1","title":"Differentiating Formation Models with New Dynamical Masses for the PDS\n  70 Protoplanets","summary":"Hot- and cold-start planet formation models predict differing luminosities\nfor the young, bright planets that direct imaging surveys are most sensitive\nto. However, precise mass estimates are required to distinguish between these\nmodels observationally. The presence of two directly imaged planets, PDS 70 b\nand c, in the PDS 70 protoplanetary disk provides us a unique opportunity for\ndynamical mass measurements, since the masses for these planets are currently\npoorly constrained. Fitting orbital parameters to new astrometry of these\nplanets, taken with VLTI/GRAVITY in the $K$~band, we find $2\\sigma$ dynamical\nupper mass limits of 4.9 $M_{\\rm Jup}$ for b and 13.6 $M_{\\rm Jup}$ for c.\nAdding astrometry from the newly proposed planet candidate PDS 70 d into our\nmodel, we determine $2\\sigma$ dynamical upper mass limits of 5.3 $M_{\\rm Jup}$,\n7.5 $M_{\\rm Jup}$ and 2.2 $M_{\\rm Jup}$ for b, c, and the candidate d\nrespectively. However, $N$-body analysis of the orbits fit in this case suggest\nthat the inclusion of $d$ makes the system unstable. Using the upper mass\nlimits for b and c we rule out the coldest-start formation models for both\nplanets, calculating minimum post-formation entropies ($S_i$) of 9.5 $k_{\\rm\nB}/{\\rm baryon}$ and 8.4 $k_{\\rm B}/{\\rm baryon}$ respectively. This places PDS\n70 b and c on the growing list of directly-imaged planets inconsistent with\ncold-start formation.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-15T14:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.11212v1","title":"SDFs from Unoriented Point Clouds using Neural Variational Heat\n  Distances","summary":"We propose a novel variational approach for computing neural Signed Distance\nFields (SDF) from unoriented point clouds. To this end, we replace the commonly\nused eikonal equation with the heat method, carrying over to the neural domain\nwhat has long been standard practice for computing distances on discrete\nsurfaces. This yields two convex optimization problems for whose solution we\nemploy neural networks: We first compute a neural approximation of the\ngradients of the unsigned distance field through a small time step of heat flow\nwith weighted point cloud densities as initial data. Then we use it to compute\na neural approximation of the SDF. We prove that the underlying variational\nproblems are well-posed. Through numerical experiments, we demonstrate that our\nmethod provides state-of-the-art surface reconstruction and consistent SDF\ngradients. Furthermore, we show in a proof-of-concept that it is accurate\nenough for solving a PDE on the zero-level set.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-04-15T14:13:54Z"}
{"aid":"http://arxiv.org/abs/2504.11218v1","title":"3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians","summary":"3D affordance reasoning is essential in associating human instructions with\nthe functional regions of 3D objects, facilitating precise, task-oriented\nmanipulations in embodied AI. However, current methods, which predominantly\ndepend on sparse 3D point clouds, exhibit limited generalizability and\nrobustness due to their sensitivity to coordinate variations and the inherent\nsparsity of the data. By contrast, 3D Gaussian Splatting (3DGS) delivers\nhigh-fidelity, real-time rendering with minimal computational overhead by\nrepresenting scenes as dense, continuous distributions. This positions 3DGS as\na highly effective approach for capturing fine-grained affordance details and\nimproving recognition accuracy. Nevertheless, its full potential remains\nlargely untapped due to the absence of large-scale, 3DGS-specific affordance\ndatasets. To overcome these limitations, we present 3DAffordSplat, the first\nlarge-scale, multi-modal dataset tailored for 3DGS-based affordance reasoning.\nThis dataset includes 23,677 Gaussian instances, 8,354 point cloud instances,\nand 6,631 manually annotated affordance labels, encompassing 21 object\ncategories and 18 affordance types. Building upon this dataset, we introduce\nAffordSplatNet, a novel model specifically designed for affordance reasoning\nusing 3DGS representations. AffordSplatNet features an innovative cross-modal\nstructure alignment module that exploits structural consistency priors to align\n3D point cloud and 3DGS representations, resulting in enhanced affordance\nrecognition accuracy. Extensive experiments demonstrate that the 3DAffordSplat\ndataset significantly advances affordance learning within the 3DGS domain,\nwhile AffordSplatNet consistently outperforms existing methods across both seen\nand unseen settings, highlighting its robust generalization capabilities.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T14:21:47Z"}
{"aid":"http://arxiv.org/abs/2504.11224v1","title":"Accurate Machine Learning Interatomic Potentials for Polyacene Molecular\n  Crystals: Application to Single Molecule Host-Guest Systems","summary":"Emerging machine learning interatomic potentials (MLIPs) offer a promising\nsolution for large-scale accurate material simulations, but stringent tests\nrelated to the description of vibrational dynamics in molecular crystals remain\nscarce. Here, we develop a general MLIP by leveraging the graph neural\nnetwork-based MACE architecture and active-learning strategies to accurately\ncapture vibrational dynamics across a range of polyacene-based molecular\ncrystals, namely naphthalene, anthracene, tetracene and pentacene. Through\ncareful error propagation, we show that these potentials are accurate and\nenable the study of anharmonic vibrational features, vibrational lifetimes, and\nvibrational coupling. In particular, we investigate large-scale host-guest\nsystems based on these molecular crystals, showing the capacity of\nmolecular-dynamics-based techniques to explain and quantify vibrational\ncoupling between host and guest nuclear motion. Our results establish a\nframework for understanding vibrational signatures in large-scale complex\nmolecular systems and thus represent an important step for engineering\nvibrational interactions in molecular environments.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-15T14:27:21Z"}
{"aid":"http://arxiv.org/abs/2504.11226v1","title":"Ab initio Maxwell-Bloch Approach for X-Ray Excitations in\n  Two-Dimensional Materials","summary":"The combination of Maxwell and X-ray Bloch equations forms an appropriate\nframework to describe ultrafast time-resolved X-ray experiments on attosecond\ntime scale in crystalline solids. However, broadband experiments such as X-ray\nabsorption near edge spectroscopy or resonant inelastic X-ray scattering\nrequire a detailed knowledge of the electronic structure and transition matrix\nelements. Here, we show how to fill this gap by combining the Maxwell-X-ray\nBloch formalism with first-principles calculations treating explicitly the core\nstates. The resulting X-ray absorption spectrum recovers key spectral\nsignatures which were missing in our previous work relying on a semi-empirical\ntight-binding approach.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-15T14:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.11235v1","title":"Guided Wave-Based Structural Awareness Under Varying Operating States\n  via Manifold Representations","summary":"Guided wave-based structural health monitoring (SHM) remains a powerful\nstrategy for identifying early-stage defects and safeguarding vital aerospace\nstructures. Yet, its practical use is often hindered by the enormous,\nhigh-dimensional data streams produced by sensor arrays operating at megahertz\nsampling rates, coupled with the added complexity of shifts in environmental\nand operational conditions (EOCs). Studies have explored various\ndata-compression approaches that retain critical diagnostic details in a\nlower-dimensional latent space. While conventional techniques can streamline\ndimensionality to some extent, they do not always capture the nonlinear\ninteractions typical of guided waves. Manifold learning, as illustrated by\nDiffusion Maps, tackles these nonlinearities by deriving low-dimensional\nembeddings directly from wave signals, minimizing the need for manual feature\nextraction. In parallel, developments in deep learning -- particularly\nautoencoders -- provide an encoder-decoder model for both data compression and\nreconstruction. Convolutional autoencoders (CAEs) and variational autoencoders\n(VAEs) have been particularly effective for guided wave applications. However,\ncurrent methods can still struggle to maintain accurate state estimation under\nchanging EOCs, and they are often limited to a single task. In response, the\nproposed framework adopts a two-fold strategy: it compresses high-dimensional\nsignals into lower-dimensional representations and then leverages those\nrepresentations to both estimate structural states and reconstruct the original\ndata, even as conditions vary. Applied to two real-world SHM use-cases, this\nintegrated method has proven its ability to preserve and retrieve key damage\nsignatures under noise, shifting operational parameters, and other complicating\nfactors.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T14:38:30Z"}
{"aid":"http://arxiv.org/abs/2504.11249v1","title":"Cryo-em images are intrinsically low dimensional","summary":"Simulation-based inference provides a powerful framework for cryo-electron\nmicroscopy, employing neural networks in methods like CryoSBI to infer\nbiomolecular conformations via learned latent representations. This latent\nspace represents a rich opportunity, encoding valuable information about the\nphysical system and the inference process. Harnessing this potential hinges on\nunderstanding the underlying geometric structure of these representations. We\ninvestigate this structure by applying manifold learning techniques to CryoSBI\nrepresentations of hemagglutinin (simulated and experimental). We reveal that\nthese high-dimensional data inherently populate low-dimensional, smooth\nmanifolds, with simulated data effectively covering the experimental\ncounterpart. By characterizing the manifold's geometry using Diffusion Maps and\nidentifying its principal axes of variation via coordinate interpretation\nmethods, we establish a direct link between the latent structure and key\nphysical parameters. Discovering this intrinsic low-dimensionality and\ninterpretable geometric organization not only validates the CryoSBI approach\nbut enables us to learn more from the data structure and provides opportunities\nfor improving future inference strategies by exploiting this revealed manifold\ngeometry.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.CV,cs.LG,q-bio.BM,stat.ML","published":"2025-04-15T14:46:25Z"}
{"aid":"http://arxiv.org/abs/2504.11250v1","title":"A Rollout-Based Algorithm and Reward Function for Efficient Resource\n  Allocation in Business Processes","summary":"Resource allocation plays a critical role in minimizing cycle time and\nimproving the efficiency of business processes. Recently, Deep Reinforcement\nLearning (DRL) has emerged as a powerful tool to optimize resource allocation\npolicies in business processes. In the DRL framework, an agent learns a policy\nthrough interaction with the environment, guided solely by reward signals that\nindicate the quality of its decisions. However, existing algorithms are not\nsuitable for dynamic environments such as business processes. Furthermore,\nexisting DRL-based methods rely on engineered reward functions that approximate\nthe desired objective, but a misalignment between reward and objective can lead\nto undesired decisions or suboptimal policies. To address these issues, we\npropose a rollout-based DRL algorithm and a reward function to optimize the\nobjective directly. Our algorithm iteratively improves the policy by evaluating\nexecution trajectories following different actions. Our reward function\ndirectly decomposes the objective function of minimizing the mean cycle time.\nMaximizing our reward function guarantees that the objective function is\nminimized without requiring extensive reward engineering. The results show that\nour method consistently learns the optimal policy in all six evaluated business\nprocesses, outperforming the state-of-the-art algorithm that can only learn the\noptimal policy in two of the evaluated processes.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T14:46:58Z"}
{"aid":"http://arxiv.org/abs/2504.11254v1","title":"Model Consistency of Iterative Regularization for Low-Complexity\n  Regularization","summary":"Regularization is a core component of modern inverse problems as it allows to\nestablish well-posedness to the solution of interests. Popular regularization\napproaches include variational regularization and iterative regularization. The\nformer one can be tackled by solving a variational optimization problem, which\nis the sum of a regularization term and a data-fidelity term balanced by a\nproper weight, while the latter one chooses a proper stopping time to avoid\noverfitting to the noise. In the study of regularization, an important topic is\nthe relation between the solution obtained by regularization and the original\nground truth. When the ground truth has low-complexity structure which is\nencoded as the \"model\", a sensitivity property shows that the solution obtained\nfrom proper regularization that promotes the same structure is robust to small\nperturbations, this is called \"model consistency\". For variational\nregularization, model consistency of linear inverse problem is studied in [1].\nWhile, for iterative regularization, the existence of model consistency is an\nopen problem. In this paper, based on a recent development of partial\nsmoothness which is also considered in [1], we show that if the noise level is\nsufficiently small and a proper stopping time is chosen, the solution by\niterative regularization also achieves model consistency and more exhibit local\nlinear convergence behavior. Numerical simulations are provided to verify our\ntheoretical findings.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T14:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.11260v1","title":"$QQ$-systems and tropical geometry","summary":"We investigate the system of polynomial equations, known as $QQ$-systems,\nwhich are closely related to the so-called Bethe ansatz equations of the XXZ\nspin chain, using the methods of tropical geometry.","main_category":"math.AG","categories":"math.AG,hep-th,math-ph,math.MP,math.QA,math.RT","published":"2025-04-15T14:59:26Z"}
{"aid":"http://arxiv.org/abs/2504.11269v1","title":"Minimax asymptotics","summary":"In this paper, we consider asymptotics of the optimal value and the optimal\nsolutions of parametric minimax estimation problems. Specifically, we consider\nestimators of the optimal value and the optimal solutions in a sample minimax\nproblem that approximates the true population problem and study the limiting\ndistributions of these estimators as the sample size tends to infinity. The\nmain technical tool we employ in our analysis is the theory of sensitivity\nanalysis of parameterized mathematical optimization problems. Our results go\nwell beyond the existing literature and show that these limiting distributions\nare highly non-Gaussian in general and normal in simple specific cases. These\nresults open up the way for the development of statistical inference methods in\nparametric minimax problems.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-15T15:10:59Z"}
{"aid":"http://arxiv.org/abs/2504.11270v1","title":"Rank-based transfer learning for high-dimensional survival data with\n  application to sepsis data","summary":"Sepsis remains a critical challenge due to its high mortality and complex\nprognosis. To address data limitations in studying MSSA sepsis, we extend\nexisting transfer learning frameworks to accommodate transformation models for\nhigh-dimensional survival data. Specifically, we construct a measurement index\nbased on C-index for intelligently identifying the helpful source datasets, and\nthe target model performance is improved by leveraging information from the\nidentified source datasets via performing the transfer step and debiasing step.\nWe further provide an algorithm to construct confidence intervals for each\ncoefficient component. Another significant development is that statistical\nproperties are rigorously established, including $\\ell_1/\\ell_2$-estimation\nerror bounds of the transfer learning algorithm, detection consistency property\nof the transferable source detection algorithm and asymptotic theories for the\nconfidence interval construction. Extensive simulations and analysis of\nMIMIC-IV sepsis data demonstrate the estimation and prediction accuracy, and\npractical advantages of our approach, providing significant improvements in\nsurvival estimates for MSSA sepsis patients.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-15T15:12:25Z"}
{"aid":"http://arxiv.org/abs/2504.11276v1","title":"Invention, Innovation, and Commercialisation in British Biophysics","summary":"British biophysics has a rich tradition of scientific invention and\ninnovation, on several occasions resulting in new technologies which have\ntransformed biological insight, such as rapid DNA sequencing, high-precision\nsuper-resolution and label-free microscopy hardware, new approaches for\nhigh-throughput and single-molecule bio-sensing, and the development of a range\nof de novo bio-inspired synthetic materials. Some of these advances have been\nestablished through democratised, open-source platforms and many have\nbiomedical success, a key example involving the SARS-CoV-2 spike protein during\nthe COVID-19 pandemic. Here, three UK labs made crucial contributions in\nrevealing how the spike protein targets human cells, and how therapies such as\nvaccines and neutralizing nanobodies likely work, enabled in large part through\nthe biophysical technological innovations of cryo-electron microscopy. In this\nreview, we discuss leading-edge technological and methodological innovations\nwhich resulted from initial outcomes of discovery-led 'Physics of Life' (PoL)\nresearch (capturing biophysics, biological physics and multiple blends of\nphysical-life sciences interdisciplinary research in the UK) and which have\nmatured into wider-reaching sustainable commercial ventures enabling\nsignificant translational impact. We describe the fundamental biophysical\nscience which led to a diverse range of academic spinouts, presenting the\nscientific questions that were first asked and addressed through innovating new\ntechniques and approaches, and highlighting the key publications which\nultimately led to commercialisation. We consider these example companies\nthrough the lens of opportunities and challenges for academic biophysics\nresearch in partnership with British industry. Finally, we propose\nrecommendations concerning future resourcing and structuring of UK biophysics\nresearch and the training and support of...","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-15T15:16:42Z"}
{"aid":"http://arxiv.org/abs/2504.11287v1","title":"On kinetic energy localization in fluid flow","summary":"This works focuses on participation number -- a parameter that allows to\nquantitatively asses the level of kinetic energy localization. The author\npresents a clear way of deriving participation number in a continuous case\nwithout making any assumptions about the system, fluid or flow regime.\nMoreover, a method of computing participation number in discretized cases is\ndiscussed and verified against well known analytical solutions using three\nmethods, in which one was used previously in research on fluid flow through\nporous media. A robust formula, that works for both uniform and nonuniform\ndiscretization grids is presented.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph","published":"2025-04-15T15:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.11298v1","title":"Giant Magnetocaloric Effect in Spin Supersolid Candidate\n  Na$_2$BaCo(PO$_4$)$_2$","summary":"Supersolid, an exotic quantum state of matter that consists of particles\nforming an incompressible solid structure while simultaneously showing\nsuperfluidity of zero viscosity [1], is one of the long-standing pursuits in\nfundamental research [2, 3]. Although the initial report of $^4$He supersolid\nturned out to be an artifact [4], this intriguing quantum matter has inspired\nenthusiastic investigations into ultracold quantum gases [5-8]. Nevertheless,\nthe realization of supersolidity in condensed matter remains elusive. Here we\nfind evidence for a quantum magnetic analogue of supersolid -- the spin\nsupersolid -- in the recently synthesized triangular-lattice antiferromagnet\nNa$_2$BaCo(PO$_4$)$_2$ [9]. Notably, a giant magnetocaloric effect related to\nthe spin supersolidity is observed in the demagnetization cooling process,\nmanifesting itself as two prominent valley-like regimes, with the lowest\ntemperature attaining below 100 mK. Not only is there an experimentally\ndetermined series of critical fields but the demagnetization cooling profile\nalso shows excellent agreement with the theoretical simulations with an\neasy-axis Heisenberg model. Neutron diffractions also successfully locate the\nproposed spin supersolid phases by revealing the coexistence of\nthree-sublattice spin solid order and interlayer incommensurability indicative\nof the spin superfluidity. Thus, our results indicate a strong entropic effect\nof the spin supersolid phase in a frustrated quantum magnet and open up a\nviable and promising avenue for applications in sub-Kelvin refrigeration,\nespecially in the context of persistent concerns about helium shortages [10,\n11].","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T15:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.11311v1","title":"From Symmetry to Supersymmetry to Supergravity","summary":"The theoretical developments that led to supersymmetry, first global and then\nlocal, over roughly six years (1970-1976) arose from a convergence of physical\ninsights and mathematical methods stemming from diverse, and sometimes\nindependent, research directions. This contribution aims to illustrate the\ninterplay of ideas, methods, and motivations that informed the entire process\nand concludes with a reflection on the scientific modality of these\ndevelopments.","main_category":"physics.hist-ph","categories":"physics.hist-ph,hep-th","published":"2025-04-15T15:51:54Z"}
{"aid":"http://arxiv.org/abs/2504.11322v1","title":"Fast detection and reconstruction of merging Massive Black Hole Binary\n  signals","summary":"The Laser Interferometer Space Antenna (LISA) will detect gravitational waves\nfrom the population of merging massive black holes binaries (MBHBs) throughout\nthe Universe. The LISA data stream will feature many superposed signals from\ndifferent astrophysical sources, requiring a global fit procedure. Most of the\nMBHB signals will be loud enough to be detected days or even weeks before the\nmerger; and for those sources LISA will be able to predict the time of the\nmerger well in advance of the coalescence, as well as an approximate position\nin the sky. In this paper, we present a fast detection and signal\nreconstruction scheme for massive black hole binaries in the LISA observation\nband. We propose: (i) a detection scheme for MBHB mergers allowing a first\nsubtraction of these signals for the purpose of a global fit, and (ii) an\nefficient early detection scheme providing a time-of-merger estimate for a\npre-merger signal, that will allow to trigger a protection period, placing LISA\nin ``do not disturb'' mode and enabling more detailed analysis that will\nfacilitate multi-messenger observations. We highlight the effect of confusion\nof several overlapping in time MBHB signals in the pre-merger detection.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,astro-ph.IM","published":"2025-04-15T16:01:55Z"}
{"aid":"http://arxiv.org/abs/2504.11343v1","title":"A Minimalist Approach to LLM Reasoning: from Rejection Sampling to\n  Reinforce","summary":"Reinforcement learning (RL) has become a prevailing approach for fine-tuning\nlarge language models (LLMs) on complex reasoning tasks. Among recent methods,\nGRPO stands out for its empirical success in training models such as\nDeepSeek-R1, yet the sources of its effectiveness remain poorly understood. In\nthis work, we revisit GRPO from a reinforce-like algorithm perspective and\nanalyze its core components. Surprisingly, we find that a simple rejection\nsampling baseline, RAFT, which trains only on positively rewarded samples,\nyields competitive performance than GRPO and PPO. Our ablation studies reveal\nthat GRPO's main advantage arises from discarding prompts with entirely\nincorrect responses, rather than from its reward normalization. Motivated by\nthis insight, we propose Reinforce-Rej, a minimal extension of policy gradient\nthat filters both entirely incorrect and entirely correct samples.\nReinforce-Rej improves KL efficiency and stability, serving as a lightweight\nyet effective alternative to more complex RL algorithms. We advocate RAFT as a\nrobust and interpretable baseline, and suggest that future advances should\nfocus on more principled designs for incorporating negative samples, rather\nthan relying on them indiscriminately. Our findings provide guidance for future\nwork in reward-based LLM post-training.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,stat.ML","published":"2025-04-15T16:15:02Z"}
{"aid":"http://arxiv.org/abs/2504.11344v1","title":"Interpretable Hybrid-Rule Temporal Point Processes","summary":"Temporal Point Processes (TPPs) are widely used for modeling event sequences\nin various medical domains, such as disease onset prediction, progression\nanalysis, and clinical decision support. Although TPPs effectively capture\ntemporal dynamics, their lack of interpretability remains a critical challenge.\nRecent advancements have introduced interpretable TPPs. However, these methods\nfail to incorporate numerical features, thereby limiting their ability to\ngenerate precise predictions. To address this issue, we propose Hybrid-Rule\nTemporal Point Processes (HRTPP), a novel framework that integrates temporal\nlogic rules with numerical features, improving both interpretability and\npredictive accuracy in event modeling. HRTPP comprises three key components:\nbasic intensity for intrinsic event likelihood, rule-based intensity for\nstructured temporal dependencies, and numerical feature intensity for dynamic\nprobability modulation. To effectively discover valid rules, we introduce a\ntwo-phase rule mining strategy with Bayesian optimization. To evaluate our\nmethod, we establish a multi-criteria assessment framework, incorporating rule\nvalidity, model fitting, and temporal predictive accuracy. Experimental results\non real-world medical datasets demonstrate that HRTPP outperforms\nstate-of-the-art interpretable TPPs in terms of predictive performance and\nclinical interpretability. In case studies, the rules extracted by HRTPP\nexplain the disease progression, offering valuable contributions to medical\ndiagnosis.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-15T16:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.11348v1","title":"Circuit metaconstruction in logspace for Rice-like complexity lower\n  bounds in ANs and SGRs","summary":"A new proof technique combining finite model theory and dynamical systems has\nrecently been introduced to obtain general complexity lower bounds on any\nquestion one may formulate on the dynamics (seen as a graph) of a given\nautomata network (AN). ANs are abstract finite dynamical systems of interacting\nentities whose evolution rules are encoded as circuits, hence the study also\napplies to succinct graph representations (SGRs). In this article, we detail\nthe construction of circuits to obtain general complexity lower bounds\n(metareduction) and show that the reduction is feasible in logarithmic space.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-15T16:20:22Z"}
{"aid":"http://arxiv.org/abs/2504.11355v1","title":"Neural Networks for on-chip Model Predictive Control: a Method to Build\n  Optimized Training Datasets and its application to Type-1 Diabetes","summary":"Training Neural Networks (NNs) to behave as Model Predictive Control (MPC)\nalgorithms is an effective way to implement them in constrained embedded\ndevices. By collecting large amounts of input-output data, where inputs\nrepresent system states and outputs are MPC-generated control actions, NNs can\nbe trained to replicate MPC behavior at a fraction of the computational cost.\nHowever, although the composition of the training data critically influences\nthe final NN accuracy, methods for systematically optimizing it remain\nunderexplored. In this paper, we introduce the concept of Optimally-Sampled\nDatasets (OSDs) as ideal training sets and present an efficient algorithm for\ngenerating them. An OSD is a parametrized subset of all the available data that\n(i) preserves existing MPC information up to a certain numerical resolution,\n(ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or\ncomplete. We demonstrate the effectiveness of OSDs by training NNs to replicate\nthe University of Virginia's MPC algorithm for automated insulin delivery in\nType-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably,\ntwo OSD-trained NNs received regulatory clearance for clinical testing as the\nfirst NN-based control algorithm for direct human insulin dosing. This\nmethodology opens new pathways for implementing advanced optimizations on\nresource-constrained embedded platforms, potentially revolutionizing how\ncomplex algorithms are deployed.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-15T16:25:06Z"}
{"aid":"http://arxiv.org/abs/2504.11381v1","title":"RankAlign: A Ranking View of the Generator-Validator Gap in Large\n  Language Models","summary":"Although large language models (LLMs) have become generally more capable and\naccurate across many tasks, some fundamental sources of unreliability remain in\ntheir behavior. One key limitation is their inconsistency at reporting the the\nsame information when prompts are changed. In this paper, we consider the\ndiscrepancy between a model's generated answer and their own verification of\nthat answer, the generator-validator gap. We define this gap in a more\nstringent way than prior work: we expect correlation of scores from a generator\nand a validator over the entire set of candidate answers. We show that\naccording to this measure, a large gap exists in various settings, including\nquestion answering, lexical semantics tasks, and next-word prediction. We then\npropose RankAlign, a ranking-based training method, and show that it\nsignificantly closes the gap by 31.8% on average, surpassing all baseline\nmethods. Moreover, this approach generalizes well to out-of-domain tasks and\nlexical items.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-15T16:53:31Z"}
{"aid":"http://arxiv.org/abs/2504.11397v1","title":"MLPs and KANs for data-driven learning in physical problems: A\n  performance comparison","summary":"There is increasing interest in solving partial differential equations (PDEs)\nby casting them as machine learning problems. Recently, there has been a spike\nin exploring Kolmogorov-Arnold Networks (KANs) as an alternative to traditional\nneural networks represented by Multi-Layer Perceptrons (MLPs). While showing\npromise, their performance advantages in physics-based problems remain largely\nunexplored. Several critical questions persist: Can KANs capture complex\nphysical dynamics and under what conditions might they outperform traditional\narchitectures? In this work, we present a comparative study of KANs and MLPs\nfor learning physical systems governed by PDEs. We assess their performance\nwhen applied in deep operator networks (DeepONet) and graph network-based\nsimulators (GNS), and test them on physical problems that vary significantly in\nscale and complexity. Drawing inspiration from the Kolmogorov Representation\nTheorem, we examine the behavior of KANs and MLPs across shallow and deep\nnetwork architectures. Our results reveal that although KANs do not\nconsistently outperform MLPs when configured as deep neural networks, they\ndemonstrate superior expressiveness in shallow network settings, significantly\noutpacing MLPs in accuracy over our test cases. This suggests that KANs are a\npromising choice, offering a balance of efficiency and accuracy in applications\ninvolving physical systems.","main_category":"cs.LG","categories":"cs.LG,physics.comp-ph","published":"2025-04-15T17:13:42Z"}
{"aid":"http://arxiv.org/abs/2504.11407v1","title":"The Higman-M\\lowercase{c}Laughlin Theorem for the flag-transitive\n  $2$-designs with $$ prime","summary":"A famous result of Higman and McLaughlin \\cite{HM} in 1961 asserts that any\nflag-transitive automorphism group $G$ of a $2$-design $\\mathcal{D}$ with\n$\\lambda=1$ acts point-primitively on $\\mathcal{D}$. In this paper, we show\nthat the Higman and McLaughlin theorem is still true when $\\lambda$ is a prime\nand $\\mathcal{D}$ is not isomorphic to one of the two $2$-$(16,6,2)$ designs as\nin [42, Section 1.2], or the $2$-$(45,12,3)$ design as in [44, Construction\n4.2], or, when $2^{2^{j}}+1$ is a Fermat prime, a possible\n$2$-$(2^{2^{j+1}}(2^{2^{j}}+2),2^{2^{j}}(2^{2^{j}}+1),2^{2^{j}}+1)$ design\nhaving very specific features.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-15T17:23:58Z"}
{"aid":"http://arxiv.org/abs/2504.11408v1","title":"Five dimensional rotating and Quintessence black hole and their shadows","summary":"We present a new five-dimensional rotating quintessence black hole solution.\nTo obtain this, we employ the $5D$ version of the Janis Newman algorithm, which\nincorporates the Hopf bifurcation. The variation of the quintessence parameter\n$w_q$ causes the geometry to transition from a regular rotating universe\nsurrounded by a cosmological horizon to a singular rotating geometry, which can\nrepresent a naked singularity, a singular extremal black hole, or a singular\nblack hole with both an inner and an outer (event) horizon. We have also\ndetermined the properties of the ergosphere. For the study of the shadow, we\nfollowed a novel approach in which the $2D$ shadow observed by humans\ncorresponds to cross-sections of the $3D$ shadow. We analyzed how quintessence\naffects both the size and shape of the black hole shadow, showing that\nincreasing the quintessence strength reduces the shadow radius, contrary to the\nknown results in $4D$. We also propose a speculative methodology to test the\nshadow behavior in five-dimensional scenarios, in light of the constraints\nprovided by the Event Horizon Telescope (EHT) concerning the shadow of the\nfour-dimensional supermassive black hole M87. We identify scenarios in which\nthe theoretical $5D$ results could be consistent with these observational\nconstraints. Finally, we determine the energy conditions required to support\nthe solution.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-15T17:26:18Z"}
{"aid":"http://arxiv.org/abs/2504.11425v1","title":"MINDS: The very low-mass star and brown dwarf sample -- Hidden water in\n  carbon-dominated protoplanetary disks","summary":"Infrared observations of the inner disks around very low-mass stars (VLMS,\n$<$0.3$\\,M_{\\odot}$) have revealed a carbon-rich gas composition in the\nterrestrial planet-forming regions. Contrary to the typically water-rich T\nTauri disk spectra, only two disks around VLMS have been observed to be\nwater-rich among more than ten VLMS disks observed so far with JWST/MIRI. In\nthis letter, we systematically search for the presence of water and other\noxygen-bearing molecules in the JWST/MIRI spectra of ten VLMS disks from the\nMIRI mid-INfrared Disk Survey (MINDS). In addition to the two previously\nreported detections of water emission in this VLMS sample, we detect water\nemission in the spectra of three other sources and tentatively in one source,\nand we provide strong evidence for water emission in the remaining disks in the\nMINDS sample, most of which have bright emission from carbon-bearing molecules.\nWe show that the $\\rm C_2H_2$ emission is much stronger than that of water for\nsources with low luminosities, and the hydrocarbons outshine the water emission\nin such conditions. We propose that the appearance of water-rich vs.\nhydrocarbon-rich spectra is related to the location of the water reservoir in\nthe disk relative to the main hydrocarbon reservoir. Our findings indicate that\nthe terrestrial planet forming regions in VLMS disks have high carbon-to-oxygen\nratios (C/O$>$1), but can still harbor ample water similar to those in the T\nTauri disks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-15T17:38:14Z"}
{"aid":"http://arxiv.org/abs/2504.11426v1","title":"A Dual-Space Framework for General Knowledge Distillation of Large\n  Language Models","summary":"Knowledge distillation (KD) is a promising solution to compress large\nlanguage models (LLMs) by transferring their knowledge to smaller models.\nDuring this process, white-box KD methods usually minimize the distance between\nthe output distributions of the teacher model and the student model to transfer\nmore information. However, we reveal that the current white-box KD framework\nexhibits two limitations: a) bridging probability distributions from different\noutput spaces will limit the similarity between the teacher model and the\nstudent model; b) this framework cannot be applied to LLMs with different\nvocabularies. One of the root causes for these limitations is that the\ndistributions from the teacher and the student for KD are output by different\nprediction heads, which yield distributions in different output spaces and\ndimensions. Therefore, in this paper, we propose a dual-space knowledge\ndistillation (DSKD) framework that unifies the prediction heads of the teacher\nand the student models for KD. Specifically, we first introduce two projectors\nwith ideal initialization to project the teacher/student hidden states into the\nstudent/teacher representation spaces. After this, the hidden states from\ndifferent models can share the same head and unify the output spaces of the\ndistributions. Furthermore, we develop an exact token alignment (ETA) algorithm\nto align the same tokens in two differently-tokenized sequences. Based on the\nabove, our DSKD framework is a general KD framework that supports both\noff-policy and on-policy KD, and KD between any two LLMs regardless of their\nvocabularies. Extensive experiments on instruction-following, mathematical\nreasoning, and code generation benchmarks show that DSKD significantly\noutperforms existing methods based on the current white-box KD framework and\nsurpasses other cross-tokenizer KD methods for LLMs with different\nvocabularies.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-15T17:38:47Z"}
{"aid":"http://arxiv.org/abs/2504.11427v1","title":"NormalCrafter: Learning Temporally Consistent Normals from Video\n  Diffusion Priors","summary":"Surface normal estimation serves as a cornerstone for a spectrum of computer\nvision applications. While numerous efforts have been devoted to static image\nscenarios, ensuring temporal coherence in video-based normal estimation remains\na formidable challenge. Instead of merely augmenting existing methods with\ntemporal components, we present NormalCrafter to leverage the inherent temporal\npriors of video diffusion models. To secure high-fidelity normal estimation\nacross sequences, we propose Semantic Feature Regularization (SFR), which\naligns diffusion features with semantic cues, encouraging the model to\nconcentrate on the intrinsic semantics of the scene. Moreover, we introduce a\ntwo-stage training protocol that leverages both latent and pixel space learning\nto preserve spatial accuracy while maintaining long temporal context. Extensive\nevaluations demonstrate the efficacy of our method, showcasing a superior\nperformance in generating temporally consistent normal sequences with intricate\ndetails from diverse videos.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:39:07Z"}
{"aid":"http://arxiv.org/abs/2504.11431v1","title":"Masculine Defaults via Gendered Discourse in Podcasts and Large Language\n  Models","summary":"Masculine defaults are widely recognized as a significant type of gender\nbias, but they are often unseen as they are under-researched. Masculine\ndefaults involve three key parts: (i) the cultural context, (ii) the masculine\ncharacteristics or behaviors, and (iii) the reward for, or simply acceptance\nof, those masculine characteristics or behaviors. In this work, we study\ndiscourse-based masculine defaults, and propose a twofold framework for (i) the\nlarge-scale discovery and analysis of gendered discourse words in spoken\ncontent via our Gendered Discourse Correlation Framework (GDCF); and (ii) the\nmeasurement of the gender bias associated with these gendered discourse words\nin LLMs via our Discourse Word-Embedding Association Test (D-WEAT). We focus\nour study on podcasts, a popular and growing form of social media, analyzing\n15,117 podcast episodes. We analyze correlations between gender and discourse\nwords -- discovered via LDA and BERTopic -- to automatically form gendered\ndiscourse word lists. We then study the prevalence of these gendered discourse\nwords in domain-specific contexts, and find that gendered discourse-based\nmasculine defaults exist in the domains of business, technology/politics, and\nvideo games. Next, we study the representation of these gendered discourse\nwords from a state-of-the-art LLM embedding model from OpenAI, and find that\nthe masculine discourse words have a more stable and robust representation than\nthe feminine discourse words, which may result in better system performance on\ndownstream tasks for men. Hence, men are rewarded for their discourse patterns\nwith better system performance by one of the state-of-the-art language models\n-- and this embedding disparity is a representational harm and a masculine\ndefault.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG,cs.SI","published":"2025-04-15T17:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.11438v1","title":"Mamba-Based Ensemble learning for White Blood Cell Classification","summary":"White blood cell (WBC) classification assists in assessing immune health and\ndiagnosing various diseases, yet manual classification is labor-intensive and\nprone to inconsistencies. Recent advancements in deep learning have shown\npromise over traditional methods; however, challenges such as data imbalance\nand the computational demands of modern technologies, such as Transformer-based\nmodels which do not scale well with input size, limit their practical\napplication. This paper introduces a novel framework that leverages Mamba\nmodels integrated with ensemble learning to improve WBC classification. Mamba\nmodels, known for their linear complexity, provide a scalable alternative to\nTransformer-based approaches, making them suitable for deployment in\nresource-constrained environments. Additionally, we introduce a new WBC\ndataset, Chula-WBC-8, for benchmarking. Our approach not only validates the\neffectiveness of Mamba models in this domain but also demonstrates their\npotential to significantly enhance classification efficiency without\ncompromising accuracy. The source code can be found at\nhttps://github.com/LewisClifton/Mamba-WBC-Classification.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T17:53:18Z"}
{"aid":"http://arxiv.org/abs/2504.11442v1","title":"TextArena","summary":"TextArena is an open-source collection of competitive text-based games for\ntraining and evaluation of agentic behavior in Large Language Models (LLMs). It\nspans 57+ unique environments (including single-player, two-player, and\nmulti-player setups) and allows for easy evaluation of model capabilities via\nan online-play system (against humans and other submitted models) with\nreal-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social\nskills such as negotiation, theory of mind, and deception, creating a gap that\nTextArena addresses. Designed with research, community and extensibility in\nmind, TextArena emphasizes ease of adding new games, adapting the framework,\ntesting models, playing against the models, and training models. Detailed\ndocumentation of environments, games, leaderboard, and examples are available\non https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG,cs.MA","published":"2025-04-15T17:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.11446v1","title":"eXplainable AI for data driven control: an inverse optimal control\n  approach","summary":"Understanding the behavior of black-box data-driven controllers is a key\nchallenge in modern control design. In this work, we propose an eXplainable AI\n(XAI) methodology based on Inverse Optimal Control (IOC) to obtain local\nexplanations for the behavior of a controller operating around a given region.\nSpecifically, we extract the weights assigned to tracking errors and control\neffort in the implicit cost function that a black-box controller is optimizing,\noffering a more transparent and interpretable representation of the\ncontroller's underlying objectives. This approach presents connections with\nwell-established XAI techniques, such as Local Interpretable Model-agnostic\nExplanations (LIME) since it is still based on a local approximation of the\ncontrol policy. However, rather being limited to a standard sensitivity\nanalysis, the explanation provided by our method relies on the solution of an\ninverse Linear Quadratic (LQ) problem, offering a structured and more\ncontrol-relevant perspective. Numerical examples demonstrate that the inferred\ncost function consistently provides a deeper understanding of the controller's\ndecision-making process, shedding light on otherwise counterintuitive or\nunexpected phenomena.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T17:56:24Z"}
{"aid":"http://arxiv.org/abs/2504.11447v1","title":"Diffusion Distillation With Direct Preference Optimization For Efficient\n  3D LiDAR Scene Completion","summary":"The application of diffusion models in 3D LiDAR scene completion is limited\ndue to diffusion's slow sampling speed. Score distillation accelerates\ndiffusion sampling but with performance degradation, while post-training with\ndirect policy optimization (DPO) boosts performance using preference data. This\npaper proposes Distillation-DPO, a novel diffusion distillation framework for\nLiDAR scene completion with preference aligment. First, the student model\ngenerates paired completion scenes with different initial noises. Second, using\nLiDAR scene evaluation metrics as preference, we construct winning and losing\nsample pairs. Such construction is reasonable, since most LiDAR scene metrics\nare informative but non-differentiable to be optimized directly. Third,\nDistillation-DPO optimizes the student model by exploiting the difference in\nscore functions between the teacher and student models on the paired completion\nscenes. Such procedure is repeated until convergence. Extensive experiments\ndemonstrate that, compared to state-of-the-art LiDAR scene completion diffusion\nmodels, Distillation-DPO achieves higher-quality scene completion while\naccelerating the completion speed by more than 5-fold. Our method is the first\nto explore adopting preference learning in distillation to the best of our\nknowledge and provide insights into preference-aligned distillation. Our code\nis public available on https://github.com/happyw1nd/DistillationDPO.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:57:13Z"}
{"aid":"http://arxiv.org/abs/2504.12628v1","title":"Enhancing NDAR with Delay-Gate-Induced Amplitude Damping","summary":"The Noise-Directed Adaptive Remapping (NDAR) method utilizes amplitude\ndamping noise to enhance the performance of quantum optimization algorithms.\nNDAR alternates between exploration by sampling solutions from the quantum\ncircuit and exploitation by transforming the cost Hamiltonian by changing the\nsigns of its terms. Both exploration and exploitation are important components\nin classical heuristic algorithm design. In this study, we examine how NDAR\nperformance improves by adjusting the balance between these components. We\ncontrol the degree of exploitation by varying the delay time to 0, 50, and\n$100~\\mu\\text{s}$, and investigate exploration strategies using two quantum\ncircuits, QAOA and a random circuit, on IBM's Heron processor. Our results show\nthat increasing delay time in NDAR improves the best objective value found in\neach iteration. In single-layer QAOA and random circuits applied to unweighted\nMax-Cut problem with low edge density, both exploration strategies yield\nsimilar objective value trajectories and provide competitive solution quality\nto simulated annealing for the 80-node problem. Their similar performance\nindicates that, in most cases, increasing amplitude damping noise via\nadditional delay time results in information loss. On the other hand, QAOA\noutperforms random circuits in specific cases, such as positive-negative\nweighted Max-Cut on a fully connected graph. This suggests potential advantages\nof QAOA in more complex settings. We further develop a classical NDAR to better\nunderstand exploration strategies, demonstrating that controlling the Hamming\nweight distribution of sampled bitstrings yields higher quality solutions. This\nsuggests that identifying suitable quantum circuits for exploration could\nenhance NDAR performance.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T04:09:11Z"}
{"aid":"http://arxiv.org/abs/2504.12642v1","title":"Accelerated Collapse Kinetics of Charged Polymers in Good Solvent: Role\n  of Counterion Condensation","summary":"We investigate the collapse kinetics of charged polymers (polyelectrolytes)\ninduced by counterion condensation using coarse-grained molecular dynamics\nsimulations. Under good solvent conditions, polyelectrolytes above the critical\ncharge density ($A > A_c$) exhibit significantly faster collapse dynamics\ncompared to neutral polymers, with dynamic scaling exponents ($\\nu_c \\approx\n0.76-0.84$) distinctly smaller than those observed for neutral polymers ($\\nu_c\n\\approx 1.44$) . This accelerated collapse is driven primarily by three\nmechanisms: (1) local charge neutralization due to counterion condensation,\nwhich facilitates immediate local compaction, (2) screening of long-range\nelectrostatic repulsions, reducing the conformational search space, and (3)\nbridging interactions mediated by multivalent counterions, enhancing efficient\nformation of intra-chain contacts. We systematically explore the effects of\npolymer length, charge density, and counterion valency (monovalent, divalent,\nand trivalent) on collapse dynamics, demonstrating that increased counterion\nvalency significantly lowers the critical charge density required for collapse\nand accelerates the collapse process. Our findings highlight the limitations of\nmodeling charged biopolymers using purely neutral coarse-grained models,\nunderscoring the importance of electrostatic interactions and counterion\ndynamics in determining their kinetic pathways. These insights may aid in\nbetter understanding the folding, organization, and dynamics of inherently\ncharged biomolecules, such as proteins and nucleic acids.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-17T05:03:14Z"}
{"aid":"http://arxiv.org/abs/2504.12646v1","title":"Replication Packages in Software Engineering Secondary Studies: A\n  Systematic Mapping","summary":"Context: Systematic reviews (SRs) summarize state-of-the-art evidence in\nscience, including software engineering (SE). Objective: Our objective is to\nevaluate how SRs report replication packages and to provide a comprehensive\nlist of these packages. Method: We examined 528 secondary studies published\nbetween 2013 and 2023 to analyze the availability and reporting of replication\npackages. Results: Our findings indicate that only 25.4% of the reviewed\nstudies include replication packages. Encouragingly, the situation is gradually\nimproving, as our regression analysis shows significant increase in the\navailability of replication packages over time. However, in 2023, just 50.6% of\nsecondary studies provided a replication package while an even lower\npercentage, 29.1% had used a permanent repository with a digital object\nidentifier (DOI) for storage. Conclusion: To enhance transparency and\nreproducibility in SE research, we advocate for the mandatory publication of\nreplication packages in secondary studies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T05:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.12651v1","title":"Feature selection based on cluster assumption in PU learning","summary":"Feature selection is essential for efficient data mining and sometimes\nencounters the positive-unlabeled (PU) learning scenario, where only a few\npositive labels are available, while most data remains unlabeled. In certain\nreal-world PU learning tasks, data subjected to adequate feature selection\noften form clusters with concentrated positive labels. Conventional feature\nselection methods that treat unlabeled data as negative may fail to capture the\nstatistical characteristics of positive data in such scenarios, leading to\nsuboptimal performance. To address this, we propose a novel feature selection\nmethod based on the cluster assumption in PU learning, called FSCPU. FSCPU\nformulates the feature selection problem as a binary optimization task, with an\nobjective function explicitly designed to incorporate the cluster assumption in\nthe PU learning setting. Experiments on synthetic datasets demonstrate the\neffectiveness of FSCPU across various data conditions. Moreover, comparisons\nwith 10 conventional algorithms on three open datasets show that FSCPU achieves\ncompetitive performance in downstream classification tasks, even when the\ncluster assumption does not strictly hold.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-17T05:22:17Z"}
{"aid":"http://arxiv.org/abs/2504.12664v1","title":"Autonomous Drone for Dynamic Smoke Plume Tracking","summary":"This paper presents a novel autonomous drone-based smoke plume tracking\nsystem capable of navigating and tracking plumes in highly unsteady atmospheric\nconditions. The system integrates advanced hardware and software and a\ncomprehensive simulation environment to ensure robust performance in controlled\nand real-world settings. The quadrotor, equipped with a high-resolution imaging\nsystem and an advanced onboard computing unit, performs precise maneuvers while\naccurately detecting and tracking dynamic smoke plumes under fluctuating\nconditions. Our software implements a two-phase flight operation, i.e.,\ndescending into the smoke plume upon detection and continuously monitoring the\nsmoke movement during in-plume tracking. Leveraging Proportional\nIntegral-Derivative (PID) control and a Proximal Policy Optimization based Deep\nReinforcement Learning (DRL) controller enables adaptation to plume dynamics.\nUnreal Engine simulation evaluates performance under various smoke-wind\nscenarios, from steady flow to complex, unsteady fluctuations, showing that\nwhile the PID controller performs adequately in simpler scenarios, the\nDRL-based controller excels in more challenging environments. Field tests\ncorroborate these findings. This system opens new possibilities for drone-based\nmonitoring in areas like wildfire management and air quality assessment. The\nsuccessful integration of DRL for real-time decision-making advances autonomous\ndrone control for dynamic environments.","main_category":"cs.RO","categories":"cs.RO,physics.flu-dyn","published":"2025-04-17T05:50:15Z"}
{"aid":"http://arxiv.org/abs/2504.12665v1","title":"Predicting Driver's Perceived Risk: a Model Based on Semi-Supervised\n  Learning Strategy","summary":"Drivers' perception of risk determines their acceptance, trust, and use of\nthe Automated Driving Systems (ADSs). However, perceived risk is subjective and\ndifficult to evaluate using existing methods. To address this issue, a driver's\nsubjective perceived risk (DSPR) model is proposed, regarding perceived risk as\na dynamically triggered mechanism with anisotropy and attenuation. 20\nparticipants are recruited for a driver-in-the-loop experiment to report their\nreal-time subjective risk ratings (SRRs) when experiencing various automatic\ndriving scenarios. A convolutional neural network and bidirectional long\nshort-term memory network with temporal pattern attention (CNN-Bi-LSTM-TPA) is\nembedded into a semi-supervised learning strategy to predict SRRs, aiming to\nreduce data noise caused by subjective randomness of participants. The results\nillustrate that DSPR achieves the highest prediction accuracy of 87.91% in\npredicting SRRs, compared to three state-of-the-art risk models. The\nsemi-supervised strategy improves accuracy by 20.12%. Besides, CNN-Bi-LSTM-TPA\nnetwork presents the highest accuracy among four different LSTM structures.\nThis study offers an effective method for assessing driver's perceived risk,\nproviding support for the safety enhancement of ADS and driver's trust\nimprovement.","main_category":"cs.LG","categories":"cs.LG,cs.HC","published":"2025-04-17T05:50:33Z"}
{"aid":"http://arxiv.org/abs/2504.12666v1","title":"Sublinear lower bounds of eigenvalues for twisted Laplacian on compact\n  hyperbolic surfaces","summary":"We investigate the asymptotic spectral distribution of the twisted Laplacian\nassociated with a real harmonic 1-form on a compact hyperbolic surface. In\nparticular, we establish a sublinear lower bound on the number of eigenvalues\nin a sufficiently large strip determined by the pressure of the harmonic\n1-form. Furthermore, following an observation by Anantharaman\n\\cite{nalinideviation}, we show that quantum unique ergodicity fails to hold\nfor certain twisted Laplacians.","main_category":"math.SP","categories":"math.SP,math.AP","published":"2025-04-17T05:50:43Z"}
{"aid":"http://arxiv.org/abs/2504.12676v1","title":"Accurate Tracking of Arabidopsis Root Cortex Cell Nuclei in 3D\n  Time-Lapse Microscopy Images Based on Genetic Algorithm","summary":"Arabidopsis is a widely used model plant to gain basic knowledge on plant\nphysiology and development. Live imaging is an important technique to visualize\nand quantify elemental processes in plant development. To uncover novel\ntheories underlying plant growth and cell division, accurate cell tracking on\nlive imaging is of utmost importance. The commonly used cell tracking software,\nTrackMate, adopts tracking-by-detection fashion, which applies Laplacian of\nGaussian (LoG) for blob detection, and Linear Assignment Problem (LAP) tracker\nfor tracking. However, they do not perform sufficiently when cells are densely\narranged. To alleviate the problems mentioned above, we propose an accurate\ntracking method based on Genetic algorithm (GA) using knowledge of Arabidopsis\nroot cellular patterns and spatial relationship among volumes. Our method can\nbe described as a coarse-to-fine method, in which we first conducted relatively\neasy line-level tracking of cell nuclei, then performed complicated nuclear\ntracking based on known linear arrangement of cell files and their spatial\nrelationship between nuclei. Our method has been evaluated on a long-time live\nimaging dataset of Arabidopsis root tips, and with minor manual rectification,\nit accurately tracks nuclei. To the best of our knowledge, this research\nrepresents the first successful attempt to address a long-standing problem in\nthe field of time-lapse microscopy in the root meristem by proposing an\naccurate tracking method for Arabidopsis root nuclei.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:07:17Z"}
{"aid":"http://arxiv.org/abs/2504.12698v1","title":"High-Resolution Multipath Angle Estimation Based on Power-Angle-Delay\n  Profile for Directional Scanning Sounding","summary":"Directional scanning sounding (DSS) has become widely adopted for\nhigh-frequency channel measurements because it effectively compensates for\nsevere path loss. However, the resolution of existing multipath component (MPC)\nangle estimation methods is constrained by the DSS angle sampling interval.\nTherefore, this communication proposes a high-resolution MPC angle estimation\nmethod based on power-angle-delay profile (PADP) for DSS. By exploiting the\nmapping relationship between the power difference of adjacent angles in the\nPADP and MPC offset angle, the resolution of MPC angle estimation is refined,\nsignificantly enhancing the accuracy of MPC angle and amplitude estimation\nwithout increasing measurement complexity. Numerical simulation results\ndemonstrate that the proposed method reduces the mean squared estimation errors\nof angle and amplitude by one order of magnitude compared to traditional\nomnidirectional synthesis methods. Furthermore, the estimation errors approach\nthe Cram\\'er-Rao Lower Bounds (CRLBs) derived for wideband DSS, thereby\nvalidating its superior performance in MPC angle and amplitude estimation.\nFinally, experiments conducted in an indoor scenario at 37.5 GHz validate the\nexcellent performance of the proposed method in practical applications.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T06:56:34Z"}
{"aid":"http://arxiv.org/abs/2504.12699v1","title":"Unsupervised Cross-Domain 3D Human Pose Estimation via\n  Pseudo-Label-Guided Global Transforms","summary":"Existing 3D human pose estimation methods often suffer in performance, when\napplied to cross-scenario inference, due to domain shifts in characteristics\nsuch as camera viewpoint, position, posture, and body size. Among these\nfactors, camera viewpoints and locations {have been shown} to contribute\nsignificantly to the domain gap by influencing the global positions of human\nposes. To address this, we propose a novel framework that explicitly conducts\nglobal transformations between pose positions in the camera coordinate systems\nof source and target domains. We start with a Pseudo-Label Generation Module\nthat is applied to the 2D poses of the target dataset to generate pseudo-3D\nposes. Then, a Global Transformation Module leverages a human-centered\ncoordinate system as a novel bridging mechanism to seamlessly align the\npositional orientations of poses across disparate domains, ensuring consistent\nspatial referencing. To further enhance generalization, a Pose Augmentor is\nincorporated to address variations in human posture and body size. This process\nis iterative, allowing refined pseudo-labels to progressively improve guidance\nfor domain adaptation. Our method is evaluated on various cross-dataset\nbenchmarks, including Human3.6M, MPI-INF-3DHP, and 3DPW. The proposed method\noutperforms state-of-the-art approaches and even outperforms the target-trained\nmodel.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.12722v1","title":"SimUSER: Simulating User Behavior with Large Language Models for\n  Recommender System Evaluation","summary":"Recommender systems play a central role in numerous real-life applications,\nyet evaluating their performance remains a significant challenge due to the gap\nbetween offline metrics and online behaviors. Given the scarcity and limits\n(e.g., privacy issues) of real user data, we introduce SimUSER, an agent\nframework that serves as believable and cost-effective human proxies. SimUSER\nfirst identifies self-consistent personas from historical data, enriching user\nprofiles with unique backgrounds and personalities. Then, central to this\nevaluation are users equipped with persona, memory, perception, and brain\nmodules, engaging in interactions with the recommender system. SimUSER exhibits\ncloser alignment with genuine humans than prior work, both at micro and macro\nlevels. Additionally, we conduct insightful experiments to explore the effects\nof thumbnails on click rates, the exposure effect, and the impact of reviews on\nuser engagement. Finally, we refine recommender system parameters based on\noffline A/B test results, resulting in improved user engagement in the real\nworld.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-17T07:57:23Z"}
{"aid":"http://arxiv.org/abs/2504.12761v1","title":"Temporal Variation of Flare Occurrence Rates via the Spot Evolution on\n  the Sun and Solar-type Stars","summary":"The spot evolution on the Sun and solar-type stars is important for\nunderstanding the nature of consequential flaring activity. This study\nstatistically investigates the variance of flare occurrence rate through the\ntime evolution of spots on the Sun and solar-type stars. We have compiled the\n28-year catalogs of solar flares and their source sunspots obtained from solar\nsurface observations by NOAA and GOES for the Sun. Also, we combined the\ncataloged stellar flares with the time evolution of starspots estimated by\nlight curves obtained by the 4-year Kepler mission for solar-type stars. For\nthe obtained 24124 solar flares and 180 stellar flares, we calculate the flare\noccurrence distribution with respect to $t_\\mathrm{flare}-t_\\mathrm{max}$,\nwhich represents the timing of flare through the spot evolution, where\n$t_\\mathrm{flare}$ is the flare occurrence time, and $t_\\mathrm{max}$ is the\ntime when the source spot takes its maximum area. When normalized by the spot\nlifetime, we found that the flare occurrence distribution for\n$t_\\mathrm{flare}-t_\\mathrm{max}$ shows a similar distribution regardless of\nspot size or flare energy, suggesting that the Sun and the solar-type star\nshare the same physical process in the spot-to-flare activity. On this basis,\nwe propose a formula for the time variation of the flare occurrence rate per\nspot. Also, the correlation between the temporal variation of flare occurrence\nrate and the time evolution of spot area and the lack of difference in flare\noccurrence rate between the emergence and decaying phases provide a milestone\nfor the nature of flare-productive spots.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-17T08:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.12764v1","title":"GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large\n  Language Models on Graph-theoretic Tasks","summary":"In this paper, we presented GraphOmni, a comprehensive benchmark framework\nfor systematically evaluating the graph reasoning capabilities of LLMs. By\nanalyzing critical dimensions, including graph types, serialization formats,\nand prompt schemes, we provided extensive insights into the strengths and\nlimitations of current LLMs. Our empirical findings emphasize that no single\nserialization or prompting strategy consistently outperforms others. Motivated\nby these insights, we propose a reinforcement learning-based approach that\ndynamically selects the best serialization-prompt pairings, resulting in\nsignificant accuracy improvements. GraphOmni's modular and extensible design\nestablishes a robust foundation for future research, facilitating advancements\ntoward general-purpose graph reasoning models.","main_category":"cs.LG","categories":"cs.LG,cs.DM","published":"2025-04-17T09:01:16Z"}
{"aid":"http://arxiv.org/abs/2504.12776v1","title":"StorySets: Ordering Curves and Dimensions for Visualizing Uncertain Sets\n  and Multi-Dimensional Discrete Data","summary":"We propose a method for visualizing uncertain set systems, which differs from\nprevious set visualization approaches that are based on certainty (an element\neither belongs to a set or not). Our method is inspired by storyline\nvisualizations and parallel coordinate plots: (a) each element is represented\nby a vertical glyph, subdivided into bins that represent different levels of\nuncertainty; (b) each set is represented by an x-monotone curve that traverses\nelement glyphs through the bins representing the level of uncertainty of their\nmembership. Our implementation also includes optimizations to reduce visual\ncomplexity captured by the number of turns for the set curves and the number of\ncrossings. Although several of the natural underlying optimization problems are\nNP-hard in theory (e.g., optimal element order, optimal set order), in\npractice, we can compute near-optimal solutions with respect to curve crossings\nwith the help of a new exact algorithm for optimally ordering set curves within\neach element's bins. With these optimizations, the proposed method makes it\neasy to see set containment (the smaller set's curve is strictly below the\nlarger set's curve). A brief design-space exploration using uncertain\nset-membership data, as well as multi-dimensional discrete data, shows the\nflexibility of the proposed approach.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-17T09:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.12784v1","title":"Accessing quasi-flat $\\textit{f}$-bands to harvest large Berry curvature\n  in NdGaSi","summary":"Bands away from the Fermi energy do not influence the electrical conduction.\nIn typical rare-earth lanthanide compounds, the localized\n4$\\textit{f}$-electrons have a weak effect on the electrical conduction,\nlimiting their influence on the Berry curvature and, hence, the intrinsic\nanomalous Hall effect. However, a comprehensive study of the magnetic,\nthermodynamic, and transport properties of single-crystalline NdGaSi, guided by\nfirst-principles calculations, reveals a ferromagnetic ground state that\ninduces a splitting of quasi-flat 4$\\textit{f}$-electronic bands and positions\nthem near the Fermi energy. The observation of an extraordinarily large\nintrinsic anomalous Hall conductivity of 1165 $\\Omega^{-1}$cm$^{-1}$ implies\nthe direct involvement of localized states in the generation of non-trivial\nband crossings around the Fermi energy. These results are remarkable when\ncompared to ferrimagnetic NdAlSi, which differs only in a non-magnetic atom (a\nchange in the principal quantum number $\\textit{n}$ of the outer $\\textit{p}$\norbital) with the same number of valence electrons and does not exhibit any\nmeasurable anomalous Hall conductivity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-17T09:30:23Z"}
{"aid":"http://arxiv.org/abs/2504.12785v1","title":"New developments in MatCont: delay equation importer and Lyapunov\n  exponents","summary":"MatCont is a powerful toolbox for numerical bifurcation analysis focussing on\nsmooth ODEs. A user can study equilibria, periodic and connecting orbits, and\ntheir stability and bifurcations. Here, we report on additional features in\nversion 7p6. The first is a delay equation importer enabling MatCont users to\nstudy a much larger class of models, namely delay equations with finite delay\n(including delay differential and renewal equations). This importer translates\nthe delay equation into a system of ODEs using a pseudospectral approximation\nwith an order specified by the user. We also implemented Lyapunov exponent\ncomputations, event functions for Poincar\\'e maps, and enhanced homoclinic\ncontinuation. We demonstrate these features with test cases, such as the\nMackey-Glass equation and a renewal equation, and provide additional examples\nin online tutorials.","main_category":"math.DS","categories":"math.DS","published":"2025-04-17T09:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.12786v1","title":"Magnetized black holes in Kaluza-Klein theory and the Kerr/CFT\n  correspondence","summary":"In this work, we examine the Kerr/CFT correspondence for magnetized black\nholes arising from Kaluza--Klein theory, demonstrating that Kerr/CFT holography\npersists beyond the traditional Einstein--Maxwell framework. Notably, unlike in\nthe Einstein--Maxwell case, the massless neutral scalar field equation here is\nfully separable into radial and angular parts. This separability reveals a\nhidden conformal symmetry in the near--horizon, low--frequency regime,\nproviding further support for the robustness of Kerr/CFT dualities in extended\ngravitational theories.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-17T09:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.12791v1","title":"Probing the topological protection of edge states in multilayer tungsten\n  ditelluride with the superconducting proximity effect","summary":"The topology of WTe2, a transition metal dichalcogenide with large spin-orbit\ninteractions, is thought to combine type II Weyl semimetal and second-order\ntopological insulator (SOTI) character. The SOTI character should endow WTe2\nmultilayer crystals with topologically protected helical states at its hinges,\nand, indeed, 1D states have been detected thanks to Josephson interferometry.\nHowever, the immunity to backscattering conferred to those states by their\nhelical nature has so far not been tested. To probe the topological protection\nof WTe2 edge states, we have fabricated Superconducting Quantum Interference\nDevices (SQUIDs) in which the supercurrent through a junction on the crystal\nedge interferes with the supercurrent through a junction in the bulk of the\ncrystal. We find behaviors ranging from a Symmetric SQUID pattern to asymmetric\nSQUID patterns, including one in which the modulation by magnetic field reveals\na sawtooth-like supercurrent versus phase relation for the edge junction,\ndemonstrating that the supercurrent at the edge is carried by ballistic\nchannels over 600 nm, a tell-tale sign of the SOTI character of WTe2.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T09:43:04Z"}
{"aid":"http://arxiv.org/abs/2504.12802v1","title":"First insight into transverse-momentum-dependent fragmentation physics\n  at photon-photon colliders","summary":"Future planned lepton colliders, both in the circular and linear\nconfigurations, can effectively work as virtual and quasi-real photon-photon\ncolliders and are expected to stimulate an intense physics program in the next\nfew years. In this paper, we suggest to consider photon-photon scattering as a\nuseful source of information on transverse momentum dependent fragmentation\nfunctions (TMD FFs), complementing semi-inclusive deep inelastic scattering and\n$e^+e^-$ annihilation processes, which provide most of the present\nphenomenological information on TMD FFs. As a first illustrative example, we\nstudy two-hadron azimuthal asymmetries around the jet thrust-axis in the\nprocess $\\ell^+\\ell^-\\to\\gamma^* \\gamma\\to q\\bar q\\to h_1 h_2 + X$, in which in\na circular lepton collider one tagged, deeply-virtual photon scatters off an\nuntagged quasi-real photon, both originating from the initial lepton beams,\nproducing inclusively an almost back-to-back light-hadron pair with large\ntransverse momentum, in the $\\gamma^*\\gamma$ center of mass frame. Similar\nprocesses, in a more complicated environment due to the presence of initial\nhadronic states, can also be studied in ultraperipheral collisions at the LHC\nand the planned future hadron colliders.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T10:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.12817v1","title":"Explainable Scene Understanding with Qualitative Representations and\n  Graph Neural Networks","summary":"This paper investigates the integration of graph neural networks (GNNs) with\nQualitative Explainable Graphs (QXGs) for scene understanding in automated\ndriving. Scene understanding is the basis for any further reactive or proactive\ndecision-making. Scene understanding and related reasoning is inherently an\nexplanation task: why is another traffic participant doing something, what or\nwho caused their actions? While previous work demonstrated QXGs' effectiveness\nusing shallow machine learning models, these approaches were limited to\nanalysing single relation chains between object pairs, disregarding the broader\nscene context. We propose a novel GNN architecture that processes entire graph\nstructures to identify relevant objects in traffic scenes. We evaluate our\nmethod on the nuScenes dataset enriched with DriveLM's human-annotated\nrelevance labels. Experimental results show that our GNN-based approach\nachieves superior performance compared to baseline methods. The model\neffectively handles the inherent class imbalance in relevant object\nidentification tasks while considering the complete spatial-temporal\nrelationships between all objects in the scene. Our work demonstrates the\npotential of combining qualitative representations with deep learning\napproaches for explainable scene understanding in autonomous driving systems.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-04-17T10:21:30Z"}
{"aid":"http://arxiv.org/abs/2504.12822v1","title":"Miura transformation in bidifferential calculus and a vectorial Darboux\n  transformation for the Fokas-Lenells equation","summary":"Using a general result of bidifferential calculus and recent results of other\nauthors, a vectorial binary Darboux transformation is derived for the first\nmember of the \"negative\" part of the potential Kaup-Newell hierarchy, which is\na system of two coupled Fokas-Lenells equations. Miura transformations are\nfound from the latter to the first member of the negative part of the AKNS\nhierarchy and also to its \"pseudodual\". The reduction to the Fokas-Lenells\nequation is implemented and exact solutions with a plane wave seed generated.","main_category":"nlin.SI","categories":"nlin.SI,math-ph,math.MP","published":"2025-04-17T10:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.12832v1","title":"Physics of an AMOC Overshoot in a Box Model","summary":"Recently the global average temperature has temporarily exceeded the\n1.5{\\deg}C goal of the Paris Agreement, and so an overshoot of various climate\ntipping elements becomes increasingly likely. In this study we analyze the\nphysical processes of an overshoot of the Atlantic Meridional Overturning\nCirculation (AMOC), one of the major tipping elements, using a conceptual box\nmodel. Here either the atmospheric temperature above the North Atlantic, or the\nfreshwater forcing into the North Atlantic overshoot their respective critical\nboundaries. In both cases a higher forcing rate can prevent a collapse of the\nAMOC, since a higher rate of forcing causes initially a fresher North Atlantic,\nwhich in turn results in a higher northward transport by the subtropical gyre\nsupplementing the salinity loss in time. For small exceedance amplitudes the\nAMOC is still resilient as the forcing rates can be low and so other state\nvariables outside of the North Atlantic can adjust. Contrarily, for larger\novershoots the trajectories are dynamically similar and we find a lower limit\nin volume and exceedance time for respectively freshwater and temperature\nforcing in order to prevent a collapse. Moreover, for a large overshoot an\nincreased air-sea temperature coupling has a destabilizing effect, while the\nreverse holds for an overshoot close to the tipping point. The understanding of\nthe physics of the AMOC overshoot behavior is important for interpreting\nresults of Earth System Models and for evaluating the effects of mitigation and\nintervention strategies.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-17T10:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.12834v1","title":"Hunting for newborn magnetars: a multi-messenger approach","summary":"We carry out a numerical calculation of magnetar-powered shock break-outs\n(SBOs) and supernova (SN) light-curves. In particular, we investigate the\nimpact of gravitational wave (GW) emission by the magnetar central engine on\nits electromagnetic (EM) counterparts in the ULTRASAT band. Our results show\nthat GW emission by the magnetar has only a minor effect on the SBO\nlight-curve. However, we find that SN light-curves can carry a direct signature\nof GW emission, which becomes more evident at late times (> 20-30 days).~Our\nresults demonstrate that future ULTRASAT observations will provide crucial\ninsights into the magnetar formation process, and unique information for direct\nsearches of long-transient signals with current and future generation GW\ndetectors. In particular, we estimate a rate of multi-messenger (UV+GW)\ndetections of newly formed magnetars $>$ 1 every two years with ULTRASAT and\nthe Einstein Telescope.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-17T10:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.12835v1","title":"Kinetic simulated annealing optimization with entropy-based cooling rate","summary":"We present a modified simulated annealing method with a dynamical choice of\nthe cooling temperature. The latter is determined via a closed-loop control and\nis proven to yield exponential decay of the entropy of the particle system. The\nanalysis is carried out through kinetic equations for interacting particle\nsystems describing the simulated annealing method in an extended phase space.\nDecay estimates are derived under the quasi-invariant scaling of the resulting\nsystem of Boltzmann-type equations to assess the consistency with their\nmean-field limit. Numerical results are provided to illustrate and support the\ntheoretical findings.","main_category":"math.OC","categories":"math.OC,nlin.AO","published":"2025-04-17T10:50:24Z"}
{"aid":"http://arxiv.org/abs/2504.12841v1","title":"ALT: A Python Package for Lightweight Feature Representation in Time\n  Series Classification","summary":"We introduce ALT, an open-source Python package created for efficient and\naccurate time series classification (TSC). The package implements the adaptive\nlaw-based transformation (ALT) algorithm, which transforms raw time series data\ninto a linearly separable feature space using variable-length shifted time\nwindows. This adaptive approach enhances its predecessor, the linear law-based\ntransformation (LLT), by effectively capturing patterns of varying temporal\nscales. The software is implemented for scalability, interpretability, and ease\nof use, achieving state-of-the-art performance with minimal computational\noverhead. Extensive benchmarking on real-world datasets demonstrates the\nutility of ALT for diverse TSC tasks in physics and related domains.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,cs.MS,stat.ML","published":"2025-04-17T10:57:29Z"}
{"aid":"http://arxiv.org/abs/2504.12843v1","title":"Quadratic subproduct systems, free products, and their C*-algebras","summary":"Motivated by the interplay between quadratic algebras, noncommutative\ngeometry, and operator theory, we introduce the notion of quadratic subproduct\nsystems of Hilbert spaces. Specifically, we study the subproduct systems\ninduced by a finite number of complex quadratic polynomials in noncommuting\nvariables, and describe their Toeplitz and Cuntz--Pimsner algebras. Inspired by\nthe theory of graded associative algebras, we define a free product operation\nin the category of subproduct systems and show that this corresponds to the\nreduced free product of the Toeplitz algebras. Finally, we obtain results about\nthe K-theory of the Toeplitz and Cuntz--Pimsner algebras of a large class of\nquadratic subproduct systems.","main_category":"math.OA","categories":"math.OA","published":"2025-04-17T10:57:58Z"}
{"aid":"http://arxiv.org/abs/2504.12846v1","title":"Timing via Pinwheel Double Categories","summary":"We discuss string diagrams for timed process theories -- represented by\nduoidally-graded symmetric strict monoidal categories -- built upon the string\ndiagrams of pinwheel double categories.","main_category":"math.CT","categories":"math.CT,cs.LO","published":"2025-04-17T11:02:52Z"}
{"aid":"http://arxiv.org/abs/2504.12849v1","title":"FedX: Adaptive Model Decomposition and Quantization for IoT Federated\n  Learning","summary":"Federated Learning (FL) allows collaborative training among multiple devices\nwithout data sharing, thus enabling privacy-sensitive applications on mobile or\nInternet of Things (IoT) devices, such as mobile health and asset tracking.\nHowever, designing an FL system with good model utility that works with low\ncomputation/communication overhead on heterogeneous, resource-constrained\nmobile/IoT devices is challenging. To address this problem, this paper proposes\nFedX, a novel adaptive model decomposition and quantization FL system for IoT.\nTo balance utility with resource constraints on IoT devices, FedX decomposes a\nglobal FL model into different sub-networks with adaptive numbers of quantized\nbits for different devices. The key idea is that a device with fewer resources\nreceives a smaller sub-network for lower overhead but utilizes a larger number\nof quantized bits for higher model utility, and vice versa. The quantization\noperations in FedX are done at the server to reduce the computational load on\ndevices. FedX iteratively minimizes the losses in the devices' local data and\nin the server's public data using quantized sub-networks under a regularization\nterm, and thus it maximizes the benefits of combining FL with model\nquantization through knowledge sharing among the server and devices in a\ncost-effective training process. Extensive experiments show that FedX\nsignificantly improves quantization times by up to 8.43X, on-device computation\ntime by 1.5X, and total end-to-end training time by 1.36X, compared with\nbaseline FL systems. We guarantee the global model convergence theoretically\nand validate local model convergence empirically, highlighting FedX's\noptimization efficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T11:08:51Z"}
{"aid":"http://arxiv.org/abs/2504.12852v1","title":"Why $w \\ne -1$? Anthropic Selection in a $$ + Axion Dark Energy\n  Model","summary":"We study a dark energy model composed of a bare negative cosmological\nconstant and a single ultra-light axion, motivated by the string axiverse.\nAssuming that intelligent observers can exist and observe an accelerating\nuniverse, we derive nontrivial constraints on both the axion mass and the bare\ncosmological constant. The axion mass is bounded from above to avoid\nfine-tuning of the initial misalignment angle near the hilltop, and from below\nbecause extremely light axions would require the bare cosmological constant to\nbe unnaturally close to zero to achieve accelerated expansion. As a result, the\nanthropically allowed axion mass range typically lies around $m =\n\\mathcal{O}(10)\\, H_0$ for a decay constant close to the Planck scale, where\n$H_0$ is the observed value of the Hubble constant. In this framework, the dark\nenergy equation of state parameter $w_0$ generically deviates from $-1$ by\n$\\mathcal{O}(0.1)$, providing a natural explanation for why $w \\ne -1$ may be\nexpected. This outcome is intriguingly consistent with recent DESI hints of\ntime-varying dark energy, and offers a compelling anthropic explanation within\nthe $\\Lambda$ + axion framework.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-17T11:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.12854v1","title":"Versatile, Robust, and Explosive Locomotion with Rigid and Articulated\n  Compliant Quadrupeds","summary":"Achieving versatile and explosive motion with robustness against dynamic\nuncertainties is a challenging task. Introducing parallel compliance in\nquadrupedal design is deemed to enhance locomotion performance, which, however,\nmakes the control task even harder. This work aims to address this challenge by\nproposing a general template model and establishing an efficient motion\nplanning and control pipeline. To start, we propose a reduced-order template\nmodel-the dual-legged actuated spring-loaded inverted pendulum with trunk\nrotation-which explicitly models parallel compliance by decoupling spring\neffects from active motor actuation. With this template model, versatile\nacrobatic motions, such as pronking, froggy jumping, and hop-turn, are\ngenerated by a dual-layer trajectory optimization, where the singularity-free\nbody rotation representation is taken into consideration. Integrated with a\nlinear singularity-free tracking controller, enhanced quadrupedal locomotion is\nachieved. Comparisons with the existing template model reveal the improved\naccuracy and generalization of our model. Hardware experiments with a rigid\nquadruped and a newly designed compliant quadruped demonstrate that i) the\ntemplate model enables generating versatile dynamic motion; ii) parallel\nelasticity enhances explosive motion. For example, the maximal pronking\ndistance, hop-turn yaw angle, and froggy jumping distance increase at least by\n25%, 15% and 25%, respectively; iii) parallel elasticity improves the\nrobustness against dynamic uncertainties, including modelling errors and\nexternal disturbances. For example, the allowable support surface height\nvariation increases by 100% for robust froggy jumping.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T11:20:29Z"}
{"aid":"http://arxiv.org/abs/2504.12858v1","title":"A particle-based approach for the prediction of grain microstructures in\n  solidification processes","summary":"Grain microstructures are crucial to the mechanical properties, performance,\nand often lifetime of metallic components. Hence, the prediction of grain\nmicrostructures emerging from solidification processes at relevant macroscopic\nscale is essential to the design or optimization of new alloys and processing\nconditions. Yet, despite the broad range of multi-scale models proposed so far,\nall of them suffer from computational limitations, such that advances from\ncomputational and algorithm perspectives remain needed. Here, we present a\nnovel approach for tracking crystallographic solidification grain envelopes\ncapable of predicting competitive growth scenarios and columnar-to-equiaxed\ntransitions for stationary grains. The model relies on classical assumptions\nand equations in use in several broadly used and thoroughly validated\napproaches (e.g. cellular automata). Yet, our approach defines the grain\nenvelope using Lagrangian particles and tracks their evolution using an\nalgorithm and an implementation relying on scalable libraries and using modern\nCPU/GPU architectures. The model is used to simulate several benchmarks of\nincreasing complexity, and the results are compared to analytical,\nexperimental, and numerical results from literature for the purpose of model\nvalidation. To highlight the applicability to real-world processes and the\npossibility of coupling the model with existing physics-based simulation tools,\nthe model is also (one-way) coupled with a multiphysics\nlaser-material-interaction model to simulate competitive grain growth during\nlaser beam welding of steel.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T11:34:08Z"}
{"aid":"http://arxiv.org/abs/2504.12861v1","title":"Hardware Implementation of Tunable Fractional-Order Capacitors by\n  Morphogenesis of Conducting Polymer Dendrites","summary":"Conventional electronics is founded on a paradigm where shaping perfect\nelectrical elements is done at the fabrication plant, so as to make devices and\nsystems identical, \"eternally immutable\". In nature, morphogenic evolutions are\nobserved in most living organisms and exploit topological plasticity as a\nlow-resource mechanism for in operando manufacturing and computation. Often\nfractal, the resulting topologies feature inherent disorder: a property which\nis never exploited in conventional electronics manufacturing, while necessary\nfor data generation and security in software. In this study, we present how\nsuch properties can be exploited to implement long-term and evolvable synaptic\nplasticity in an electronic hardware. The rich topology of conducting polymer\ndendrites (CPDs) is exploited to program the non-ideality of their\nelectrochemical capacitances containing constant-phase-elements. Their\nevolution through structural changes alters the characteristic time constants\nfor them to charge and discharge with the applied voltage stimuli. Under a\ntrain of voltage spikes, the evolvable current relaxation of the\nelectrochemical systems promotes short-term plasticity with timescales ranging\nfrom milliseconds to seconds. This large window depends on the temporality of\nthe voltage pulses used for reading, but also on the structure of a pair of\nCPDs on two electrodes, grown by voltage pulses. This study demonstrates how\nrelevant physically transient and non-ideal electrochemical components can be\nexploited for unconventional electronics, with the aim to mimic a universal\nproperty of living organisms which could barely be replicated in a silicon\nmonocrystal.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-17T11:38:43Z"}
{"aid":"http://arxiv.org/abs/2504.12862v1","title":"A Holomorphic perspective of Strict Deformation Quantization","summary":"We provide and discuss complex analytic methods for overcoming the formal\ncharacter of formal deformation quantization. This is a necessity for returning\nto physically meaningful statements, and accounts for the fact that the formal\nparameter $\\hbar$ carries the interpretation of Planck's constant. As formal\nstar products are given by a formal power series, this naturally leads into the\nrealm of holomorphic functions and analytic continuation, both in finite and\ninfinite dimensions. We propose a general notion of strict deformation\nquantization and investigate how one can use established results from complex\nanalysis to think about the resulting objects. Within the main body of the\ntext, the outlined program is then put into practice for strict deformation\nquantizations of constant Poisson structures on locally convex vector spaces\nand the strict deformation quantization of canonical mechanics on the cotangent\nbundle of a Lie group. Numerous auxiliary results, many of which are well-known\nyet remarkable in their own right, are provided throughout.","main_category":"math.CV","categories":"math.CV,math-ph,math.MP,math.QA","published":"2025-04-17T11:40:43Z"}
{"aid":"http://arxiv.org/abs/2504.12867v1","title":"EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text\n  Prompting","summary":"Human speech goes beyond the mere transfer of information; it is a profound\nexchange of emotions and a connection between individuals. While Text-to-Speech\n(TTS) models have made huge progress, they still face challenges in controlling\nthe emotional expression in the generated speech. In this work, we propose\nEmoVoice, a novel emotion-controllable TTS model that exploits large language\nmodels (LLMs) to enable fine-grained freestyle natural language emotion\ncontrol, and a phoneme boost variant design that makes the model output phoneme\ntokens and audio tokens in parallel to enhance content consistency, inspired by\nchain-of-thought (CoT) and modality-of-thought (CoM) techniques. Besides, we\nintroduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring\nexpressive speech and fine-grained emotion labels with natural language\ndescriptions. EmoVoice achieves state-of-the-art performance on the English\nEmoVoice-DB test set using only synthetic training data, and on the Chinese\nSecap test set using our in-house data. We further investigate the reliability\nof existing emotion evaluation metrics and their alignment with human\nperceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and\nGemini to assess emotional speech. Demo samples are available at\nhttps://anonymous.4open.science/r/EmoVoice-DF55. Dataset, code, and checkpoints\nwill be released.","main_category":"eess.AS","categories":"eess.AS,cs.AI,cs.CL","published":"2025-04-17T11:50:04Z"}
{"aid":"http://arxiv.org/abs/2504.12870v1","title":"CST-former: Multidimensional Attention-based Transformer for Sound Event\n  Localization and Detection in Real Scenes","summary":"Sound event localization and detection (SELD) is a task for the\nclassification of sound events and the identification of direction of arrival\n(DoA) utilizing multichannel acoustic signals. For effective classification and\nlocalization, a channel-spectro-temporal transformer (CST-former) was\nsuggested. CST-former employs multidimensional attention mechanisms across the\nspatial, spectral, and temporal domains to enlarge the model's capacity to\nlearn the domain information essential for event detection and DoA estimation\nover time. In this work, we present an enhanced version of CST-former with\nmultiscale unfolded local embedding (MSULE) developed to capture and aggregate\ndomain information over multiple time-frequency scales. Also, we propose\nfinetuning and post-processing techniques beneficial for conducting the SELD\ntask over limited training datasets. In-depth ablation studies of the proposed\narchitecture and detailed analysis on the proposed modules are carried out to\nvalidate the efficacy of multidimensional attentions on the SELD task.\nEmpirical validation through experimentation on STARSS22 and STARSS23 datasets\ndemonstrates the remarkable performance of CST-former and post-processing\ntechniques without using external data.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-17T11:56:13Z"}
{"aid":"http://arxiv.org/abs/2504.12876v1","title":"A two-component dark matter model with $Z_2 \\times Z_4$ symmetry","summary":"We consider a two-component dark matter model with $Z_2 \\times Z_4$ symmetry,\nwhere a singlet scalar $S$ and a Majorana fermion $\\chi$ are introduced as dark\nmatter candidates. We also introduce another singlet scalar $S_0$ with a\nnon-zero vacuum expectation value to the SM so that the fermion dark matter can\nobtain mass after spontaneous symmetry breaking. We have a new Higgs boson in\nthe model and in the case of the decoupling limit, the fermion dark matter\nproduction is only determined by $S$ and the new Higgs boson. The mass\nhierarchy of these new particles can make a difference in the reaction rate of\ndark matter annihilation processes, contributing to different viable parameter\nspaces for different mass orderings. We randomly scanned the parameter space\nwith six various cases under relic density constraint and found that when\n$\\chi$ is the lightest among the dark sector, $\\chi$ production is generated\nvia the so-called forbidden channels. Moreover, we consider the combined limits\narising from Higgs invisible decay, dark matter relic density and direct\ndetection constraints. Within the chosen parameter space, direct detection\nresults put the most stringent constraint, and we have a more flexible value\nfor the scalar dark matter mass when the mass of $\\chi$ is not smaller than the\nnew Higgs boson mass.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T12:04:13Z"}
{"aid":"http://arxiv.org/abs/2504.12880v1","title":"Can Masked Autoencoders Also Listen to Birds?","summary":"Masked Autoencoders (MAEs) pretrained on AudioSet fail to capture the\nfine-grained acoustic characteristics of specialized domains such as\nbioacoustic monitoring. Bird sound classification is critical for assessing\nenvironmental health, yet general-purpose models inadequately address its\nunique acoustic challenges. To address this, we introduce Bird-MAE, a\ndomain-specialized MAE pretrained on the large-scale BirdSet dataset. We\nexplore adjustments to pretraining, fine-tuning and utilizing frozen\nrepresentations. Bird-MAE achieves state-of-the-art results across all BirdSet\ndownstream tasks, substantially improving multi-label classification\nperformance compared to the general-purpose Audio-MAE baseline. Additionally,\nwe propose prototypical probing, a parameter-efficient method for leveraging\nMAEs' frozen representations. Bird-MAE's prototypical probes outperform linear\nprobing by up to 37\\% in MAP and narrow the gap to fine-tuning to approximately\n3\\% on average on BirdSet.","main_category":"cs.LG","categories":"cs.LG,cs.SD,eess.AS","published":"2025-04-17T12:13:25Z"}
{"aid":"http://arxiv.org/abs/2504.12893v1","title":"Hardness of classically sampling quantum chemistry circuits","summary":"Significant advances have been made in the study of quantum advantage both in\ntheory and experiment, although these have mostly been limited to artificial\nsetups. In this work, we extend the scope to address quantum advantage in tasks\nrelevant to chemistry and physics. Specifically, we consider the unitary\ncluster Jastrow (UCJ) ansatz-a variant of the unitary coupled cluster ansatz,\nwhich is widely used to solve the electronic structure problem on quantum\ncomputers-to show that sampling from the output distributions of quantum\ncircuits implementing the UCJ ansatz is likely to be classically hard. More\nspecifically, we show that there exist UCJ circuits for which classical\nsimulation of sampling cannot be performed in polynomial time, under a\nreasonable complexity-theoretical assumption that the polynomial hierarchy does\nnot collapse. Our main contribution is to show that a class of UCJ circuits can\nbe used to perform arbitrary instantaneous quantum polynomial-time (IQP)\ncomputations, which are already known to be classically hard to simulate under\nthe same complexity assumption. As a side result, we also show that UCJ\nequipped with post-selection can generate the class post-BQP. Our\ndemonstration, worst-case nonsimulatability of UCJ, would potentially imply\nquantum advantage in quantum algorithms for chemistry and physics using unitary\ncoupled cluster type ansatzes, such as the variational quantum eigensolver and\nquantum-selected configuration interaction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T12:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.12895v1","title":"Optimum Contribution Selection for Honeybees","summary":"In 1997, T. H. E. Meuwissen published a groundbreaking article titled\n'Maximizing the response of selection with a predefined rate of inbreeding', in\nwhich he provided an optimized solution for the trade-off between genetic\nresponse and inbreeding avoidance in animal breeding. Evidently, this issue is\nhighly relevant for the honeybee with its small breeding population sizes.\nHowever, the genetic peculiarities of bees have thus far prevented an\napplication of the theory to this species. The present manuscript intends to\nfill this desideratum. It develops the necessary bee-specific theory and\nintroduces a small R script that implements Optimum Contribution Selection\n(OCS) for honeybees. While researching for this manuscript, we found it rather\ncumbersome that even though Meuwissen's theory is 28 years old and has sparked\nresearch in many new directions, to our knowledge, there is still no\ncomprehensive textbook on the topic. Instead, all relevant information had to\nbe extracted from several articles, leading to a steep learning curve. We\nanticipate that many honeybee breeding scientists with a putative interest in\nOCS for honeybees have little to no experience with classical OCS. Thus, we\ndecided to embed our new derivations into a general introduction to OCS that\nthen specializes more and more to the honeybee case. The result are these 121\npages, of which we hope that at least the first sections can also be of use for\nbreeding theorists concerned with other species than honeybees.","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-17T12:37:58Z"}
{"aid":"http://arxiv.org/abs/2504.12904v1","title":"Complexity of del Pezzo surfaces with du Val singularities","summary":"We compute the complexity of del Pezzo surfaces with du Val singularities.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T12:50:59Z"}
{"aid":"http://arxiv.org/abs/2504.12906v1","title":"Properties and applications of $\\rm{Ar-H_2}$ atmospheric pressure plasma\n  jets","summary":"Whether for materials processing or medical applications, the use of\natmospheric pressure plasma jets (APPJs) has emerged as a relevant alternative\nto conventional methods. Within the APPJs research field, the search for\ninnovation aims not only to solve existing problems, but also to explore novel\noptions for generating plasma jets and find new possible applications. In this\nwork, the properties of $\\rm{Ar-H_2}$ APPJs generated using two plasma sources,\nwhich differ basically in the generated voltage frequency, amplitude and\nwaveform, were studied through electrical, thermal and optical\ncharacterization. Discharge and plasma parameters were analyzed as a function\nof the $\\rm{H_2}$ content in the gas mixture, with this parameter varying from\n$0\\%$ to $3.5\\%$. In all cases, the discharge power, electron density as well\nas the rotational, vibrational and gas temperatures presented a trend of\ngrowing when the proportion of $\\rm{H_2}$ in the gas composition was increased.\nOptical emission spectroscopy revealed that the same reactive species were\nproduced for both plasma sources, except for nitric oxide (NO), which was\nobserved only for the one operated at higher frequency (PS #1). Applications on\npolymer (polypropylene, PP) and water treatment were performed using PS #1\nwithout $\\rm{H_2}$ and with $3.5\\%$ of $\\rm{H_2}$ in the gas mixture. NH\nfunctional groups were detected on the PP surface in the presence of $\\rm{H_2}$\nin the gas composition. This indicates a possible way to increase the nitrogen\ncontent on polymer surfaces. The results of water treatment revealed that\nammonia ($\\rm{NH_3}$) is also produced when there is $\\rm{H_2}$ in the working\ngas. This opens an alternative for the use of plasma treated water in\nagriculture.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-17T12:52:45Z"}
{"aid":"http://arxiv.org/abs/2504.12913v1","title":"MAIN: Mutual Alignment Is Necessary for instruction tuning","summary":"Instruction tuning has enabled large language models (LLMs) to achieve\nremarkable performance, but its success heavily depends on the availability of\nlarge-scale, high-quality instruction-response pairs. However, current methods\nfor scaling up data generation often overlook a crucial aspect: the alignment\nbetween instructions and responses. We hypothesize that high-quality\ninstruction-response pairs are not defined by the individual quality of each\ncomponent, but by the extent of their alignment with each other. To address\nthis, we propose a Mutual Alignment Framework (MAIN) that ensures coherence\nbetween the instruction and response through mutual constraints. Experiments\ndemonstrate that models such as LLaMA and Mistral, fine-tuned within this\nframework, outperform traditional methods across multiple benchmarks. This\napproach underscores the critical role of instruction-response alignment in\nenabling scalable and high-quality instruction tuning for LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T13:02:44Z"}
{"aid":"http://arxiv.org/abs/2504.12917v1","title":"Arrayed waveguide gratings in lithium tantalate integrated photonics","summary":"Arrayed Waveguide Gratings (AWGs) are widely used photonic components for\nsplitting and combining different wavelengths of light. They play a key role in\nwavelength division multiplexing (WDM) systems by enabling efficient routing of\nmultiple data channels over a single optical fiber and as a building block for\nvarious optical signal processing, computing, imaging, and spectroscopic\napplications. Recently, there has been growing interest in integrating AWGs in\nferroelectric material platforms, as the platform simultaneously provide\nefficient electro-optic modulation capability and thus hold the promise for\nfully integrated WDM transmitters. To date, several demonstrations have been\nmade in the X-cut thin-film lithium niobate ($\\mathrm{LiNbO}_3$) platform, yet,\nthe large anisotropy of $\\mathrm{LiNbO}_3$ complicates the design and degrades\nthe performance of the AWGs. To address this limitation, we use the recently\ndeveloped photonic integrated circuits (PICs) based on thin-film lithium\ntantalate ($\\mathrm{LiTaO}_3$), a material with a similar Pockels coefficient\nas $\\mathrm{LiNbO}_3$ but significantly reduced optical anisotropy, as an\nalternative viable platform. In this work, we manufacture $\\mathrm{LiTaO}_3$\nAWGs using deep ultraviolet lithography on a wafer-scale. The fabricated AWGs\nfeature a channel spacing of 100 GHz, an insertion loss of < 4 dB and crosstalk\nof < -14 dB. In addition, we demonstrate a cyclic AWG, as well as a\nmultiplexing and demultiplexing AWG pair for the first time on\n$\\mathrm{LiTaO}_3$ platform. The wafer-scale fabrication of these AWGs not only\nensures uniformity and reproducibility, but also paves the way for realizing\nvolume-manufactured integrated WDM transmitters in ferroelectric photonic\nintegrated platforms.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-17T13:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.12918v1","title":"Sliced-Wasserstein Distance-based Data Selection","summary":"We propose a new unsupervised anomaly detection method based on the\nsliced-Wasserstein distance for training data selection in machine learning\napproaches. Our filtering technique is interesting for decision-making\npipelines deploying machine learning models in critical sectors, e.g., power\nsystems, as it offers a conservative data selection and an optimal transport\ninterpretation. To ensure the scalability of our method, we provide two\nefficient approximations. The first approximation processes reduced-cardinality\nrepresentations of the datasets concurrently. The second makes use of a\ncomputationally light Euclidian distance approximation. Additionally, we open\nthe first dataset showcasing localized critical peak rebate demand response in\na northern climate. We present the filtering patterns of our method on\nsynthetic datasets and numerically benchmark our method for training data\nselection. Finally, we employ our method as part of a first forecasting\nbenchmark for our open-source dataset.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T13:07:26Z"}
{"aid":"http://arxiv.org/abs/2504.12922v1","title":"On the asymptotic behaviour of stochastic processes, with applications\n  to supermartingale convergence, Dvoretzky's approximation theorem, and\n  stochastic quasi-Fejr monotonicity","summary":"We prove a novel and general result on the asymptotic behavior of stochastic\nprocesses which conform to a certain relaxed supermartingale condition. Our\nresult provides quantitative information in the form of an explicit and\neffective construction of a rate of convergence for this process, both in mean\nand almost surely, that is moreover highly uniform in the sense that it only\ndepends on very few data of the surrounding objects involved in the iteration.\nWe then apply this result to derive new quantitative versions of well-known\nconcepts and theorems from stochastic approximation, in particular providing\neffective rates for a variant of the Robbins-Siegmund theorem, Dvoretzky's\nconvergence theorem, as well as the convergence of stochastic quasi-Fej\\'er\nmonotone sequences, the latter of which formulated in a novel and highly\ngeneral metric context. We utilize the classic and widely studied Robbins-Monro\nprocedure as a template to evaluate our quantitative results and their\napplicability in greater detail. We conclude by illustrating the breadth of\npotential further applications with a brief discussion on a variety of other\nwell-known iterative procedures from stochastic approximation, covering a range\nof different applied scenarios to which our methods can be immediately applied.\nThroughout, we isolate and discuss special cases of our results which even\nallow for the construction of fast, and in particular linear, rates.","main_category":"math.OC","categories":"math.OC,cs.LG,math.LO,math.PR","published":"2025-04-17T13:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.12946v1","title":"Prospects for Detecting Signs of Life on Exoplanets in the JWST Era","summary":"The search for signs of life in the Universe has entered a new phase with the\nadvent of the James Webb Space Telescope (JWST). Detecting biosignature gases\nvia exoplanet atmosphere transmission spectroscopy is in principle within\nJWST's reach. We reflect on JWST's early results in the context of the\npotential search for biological activity on exoplanets. The results confront us\nwith a complex reality. Established inverse methods to interpret observed\nspectra-already known to be highly averaged representations of intricate 3D\natmospheric processes-can lead to disparate interpretations even with JWST's\nquality of data. Characterizing rocky or sub-Neptune-size exoplanets with JWST\nis an intricate task, and moves us away from the notion of finding a definitive\n\"silver bullet\" biosignature gas. Indeed, JWST results necessitate us to allow\n\"parallel interpretations\" that will perhaps not be resolved until the next\ngeneration of observatories. Nonetheless, with a handful of habitable-zone\nplanet atmospheres accessible given the anticipated noise floor, JWST may\ncontinue to contribute to this journey by designating a planet as biosignature\ngas candidate. To do this we will need to sufficiently refine our inverse\nmethods and physical models for confidently quantifying specific gas abundances\nand constraining the atmosphere context. Looking ahead, future telescopes and\ninnovative observational strategies will be essential for the reliable\ndetection of biosignature gases.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-17T13:48:43Z"}
{"aid":"http://arxiv.org/abs/2504.12951v1","title":"Are Retrials All You Need? Enhancing Large Language Model Reasoning\n  Without Verbalized Feedback","summary":"Recent advancements in large language models (LLMs) have catalyzed the\ndevelopment of general-purpose autonomous agents, demonstrating remarkable\nperformance in complex reasoning tasks across various domains. This surge has\nspurred the evolution of a plethora of prompt-based reasoning frameworks. A\nrecent focus has been on iterative reasoning strategies that refine outputs\nthrough self-evaluation and verbalized feedback. However, these strategies\nrequire additional computational complexity to enable models to recognize and\ncorrect their mistakes, leading to a significant increase in their cost. In\nthis work, we introduce the concept of ``retrials without feedback'', an\nembarrassingly simple yet powerful mechanism for enhancing reasoning frameworks\nby allowing LLMs to retry problem-solving attempts upon identifying incorrect\nanswers. Unlike conventional iterative refinement methods, our method does not\nrequire explicit self-reflection or verbalized feedback, simplifying the\nrefinement process. Our findings indicate that simpler retrial-based approaches\noften outperform more sophisticated reasoning frameworks, suggesting that the\nbenefits of complex methods may not always justify their computational costs.\nBy challenging the prevailing assumption that more intricate reasoning\nstrategies inherently lead to better performance, our work offers new insights\ninto how simpler, more efficient approaches can achieve optimal results. So,\nare retrials all you need?","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-17T13:52:48Z"}
{"aid":"http://arxiv.org/abs/2504.12953v1","title":"How to get Rid of SQL, Relational Algebra, the Relational Model, ERM,\n  and ORMs in a Single Paper -- A Thought Experiment","summary":"Without any doubt, the relational paradigm has been a huge success. At the\nsame time, we believe that the time is ripe to rethink how database systems\ncould look like if we designed them from scratch. Would we really end up with\nthe same abstractions and techniques that are prevalent today? This paper\nexplores that space. We discuss the various issues with both the relational\nmodel(RM) and the entity-relationship model (ERM). We provide a unified data\nmodel: the relational map type model (RMTM) which can represent both RM and ERM\nas special cases and overcomes all of their problems. We proceed to identify\nseven rules that an RMTM query language (QL) must fulfill and provide a\nfoundation of a language fulfilling all seven rules. Our QL operates on maps\nwhich may represent tuples, relations, databases or sets of databases. Like\nthat we dramatically expand the existing operational abstractions found in SQL\nand relational algebra (RA) which only operate on relations/tables. In fact, RA\nis just a special case of our much more generic approach. This work has\nfar-reaching consequences: we show a path how to come up with a modern QL that\nsolves (almost if not) all problems of SQL. Our QL is much more expressive than\nSQL and integrates smoothly into existing programming languages (PL). We also\nshow results of an initial experiment showcasing that just by switching to our\ndata model, and without changing the underlying query processing algorithms, we\ncan achieve speed-ups of up to a factor 3. We will conclude that, if we build a\ndatabase system from scratch, we could and should do this without SQL, RA, RM,\nERM, and ORMs.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-17T13:55:41Z"}
{"aid":"http://arxiv.org/abs/2504.12963v1","title":"ALMAGAL IV. Morphological comparison of molecular and thermal dust\n  emission using the histogram of oriented gradients (HOG) method","summary":"The study of molecular line emission is crucial to unveil the kinematics and\nthe physical conditions of gas in star-forming regions. Our aim is to quantify\nthe reliability of using individual molecular transitions to derive physical\nproperties of the bulk of the H2 gas, looking at morphological correlations in\ntheir overall integrated molecular line emission with the cold dust. For this\nstudy we selected transitions of H2CO, CH$_3$OH, DCN, HC$_3$N, CH$_3$CN,\nCH$_3$OCHO, SO, and SiO and compared them with the 1.38 mm dust continuum\nemission at different spatial scales in the ALMAGAL sample, that observed a\ntotal of 1013 targets covering all evolutionary stages of the high-mass\nstar-formation process and different conditions of clump fragmentation. We used\nthe method of the histogram of oriented gradients (HOG) implemented in the tool\nastroHOG to compare the morphology of integrated line emission with maps of the\n1.38 mm dust continuum emission. Moreover, we calculated the Spearman's\ncorrelation coefficient, and compared it with our astroHOG results. Only\nH$_2$CO, CH$_3$OH, and SO show emission on spatial scales comparable with the\ndiffuse continuum emission. However, from the HOG method, the median\ncorrelation of the emission of each of these species with the continuum is only\n$\\sim$24-29%. In comparison with the dense fragments these molecular species\nstill have low values of correlation. On the other hand DCN, HC$_3$N, CH$_3$CN,\nand CH$_3$OCHO show a good correlation with the dense dust fragments, above\n60%. The worst correlation is seen with SiO, both with the extended continuum\nemission and with compact sources. From the comparison of the results of the\nHOG method and the Spearman's correlation coefficient, the HOG method gives\nmuch more reliable results than the intensity-based coefficient in estimating\nthe level of similarity of the emission morphology.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T14:17:28Z"}
{"aid":"http://arxiv.org/abs/2504.12964v1","title":"Lee Yang edge singularities of QCD in association with Roberge-Weiss\n  phase transition and chiral phase transition","summary":"We study the Quantum Chromodynamics (QCD) phase transitions in the complex\nchemical potential plane in the framework of Dyson-Schwinger equation approach,\nin the presence of a constant gluonic background field that represents\nconfining dynamics. We solve the quark gap equation and the background field\nequation self consistently, which allows us to directly explore the confinement\nphase transition and furthermore, evaluate the impact of the back-coupling of\nconfinement on chiral symmetry breaking. Moreover, within such a coupled\nframework towards the complex chemical potential region, we demonstrate the\nemergence of Roberge-Weiss (RW) symmetry and investigate the trajectory of\nLee-Yang edge singularities (LYES). Our analysis reveals that the LYES scaling\nbehavior is similar to our previous findings without the background field\ncondensate. However, a significant difference from our earlier work is that the\ntrajectory of LYES terminates when the imaginary part of the singularity\nbecomes $1/3 \\, \\pi T$. We elaborate that this cut-off behavior is caused by\nthe RW symmetry that is symmetric to the imaginary chemical potential\n$\\mu_i=1/3 \\, \\pi T$.","main_category":"hep-ph","categories":"hep-ph,hep-th,nucl-th","published":"2025-04-17T14:18:14Z"}
{"aid":"http://arxiv.org/abs/2504.12967v1","title":"Krysalis Hand: A Lightweight, High-Payload, 18-DoF Anthropomorphic\n  End-Effector for Robotic Learning and Dexterous Manipulation","summary":"This paper presents the Krysalis Hand, a five-finger robotic end-effector\nthat combines a lightweight design, high payload capacity, and a high number of\ndegrees of freedom (DoF) to enable dexterous manipulation in both industrial\nand research settings. This design integrates the actuators within the hand\nwhile maintaining an anthropomorphic form. Each finger joint features a\nself-locking mechanism that allows the hand to sustain large external forces\nwithout active motor engagement. This approach shifts the payload limitation\nfrom the motor strength to the mechanical strength of the hand, allowing the\nuse of smaller, more cost-effective motors. With 18 DoF and weighing only 790\ngrams, the Krysalis Hand delivers an active squeezing force of 10 N per finger\nand supports a passive payload capacity exceeding 10 lbs. These characteristics\nmake Krysalis Hand one of the lightest, strongest, and most dexterous robotic\nend-effectors of its kind. Experimental evaluations validate its ability to\nperform intricate manipulation tasks and handle heavy payloads, underscoring\nits potential for industrial applications as well as academic research. All\ncode related to the Krysalis Hand, including control and teleoperation, is\navailable on the project GitHub repository:\nhttps://github.com/Soltanilara/Krysalis_Hand","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-17T14:19:26Z"}
{"aid":"http://arxiv.org/abs/2504.12974v1","title":"L-systems with Multiplication Operator and c-Entropy","summary":"In this note, we utilize the concepts of c-entropy and the dissipation\ncoefficient in connection with canonical L-systems based on the multiplication\n(by a scalar) operator. Additionally, we examine the coupling of such L-systems\nand derive explicit formulas for the associated c-entropy and dissipation\ncoefficient. In this context, we also introduce the concept of a skew-adjoint\nL-system and analyze its coupling with the original L-system.","main_category":"math.SP","categories":"math.SP","published":"2025-04-17T14:27:10Z"}
{"aid":"http://arxiv.org/abs/2504.12977v1","title":"A Phenomenological Approach to Analyzing User Queries in IT Systems\n  Using Heidegger's Fundamental Ontology","summary":"This paper presents a novel research analytical IT system grounded in Martin\nHeidegger's Fundamental Ontology, distinguishing between beings (das Seiende)\nand Being (das Sein). The system employs two modally distinct, descriptively\ncomplete languages: a categorical language of beings for processing user inputs\nand an existential language of Being for internal analysis. These languages are\nbridged via a phenomenological reduction module, enabling the system to analyze\nuser queries (including questions, answers, and dialogues among IT\nspecialists), identify recursive and self-referential structures, and provide\nactionable insights in categorical terms. Unlike contemporary systems limited\nto categorical analysis, this approach leverages Heidegger's phenomenological\nexistential analysis to uncover deeper ontological patterns in query\nprocessing, aiding in resolving logical traps in complex interactions, such as\nmetaphor usage in IT contexts. The path to full realization involves\nformalizing the language of Being by a research team based on Heidegger's\nFundamental Ontology; given the existing completeness of the language of\nbeings, this reduces the system's computability to completeness, paving the way\nfor a universal query analysis tool. The paper presents the system's\narchitecture, operational principles, technical implementation, use\ncases--including a case based on real IT specialist dialogues--comparative\nevaluation with existing tools, and its advantages and limitations.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL,cs.HC","published":"2025-04-17T14:29:25Z"}
{"aid":"http://arxiv.org/abs/2504.12978v1","title":"X-ray linear dichroic orientation tomography: reconstruction of\n  nanoscale three-dimensional orientation fields","summary":"Properties in crystalline and ordered materials tend to be anisotropic, with\ntheir orientation affecting the macroscopic behavior and functionality of\nmaterials. The ability to image the orientation of anisotropic material\nproperties in three dimensions (3D) is fundamental for the understanding and\nfunctionality-driven development of novel materials. With the development of X\nray linear dichroic orientation tomography (XL DOT), it is now possible to\nnon-destructively map three-dimensional (3D) orientation fields in\nmicrometer-sized samples. In this work, we present the iterative,\ngradient-based reconstruction algorithm behind XL DOT that can be used to map\norientations based on linear dichroism in 3D. As linear dichroism can be\nexhibited by a broad spectrum of materials, XL DOT can be used to map, for\nexample, crystal orientations as well as ferroic alignment, such as\nferroelectric and antiferromagnetic order. We demonstrate the robustness of\nthis technique for orientation fields that exhibit smoothly varying and\ngranular configurations, and subsequently identify and discuss optimal\ngeometries for experimental data acquisition and optimal conditions for the\nreconstruction. We anticipate that this technique will be instrumental in\nenabling a deeper understanding of the relationship between material structures\nand their functionality, quantifying, for example, the orientation of charge\ndistributions and magnetic anisotropies at the nanoscale in a wide variety of\nsystems - from functional to energy materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-17T14:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.12994v1","title":"Characterization of the $W_{1+\\infty}$-n-algebra and applications","summary":"In this paper, we construct the $W_{1+\\infty}$-n-algebras in the framework of\nthe generalized quantum algebra. We characterize the\n$\\mathcal{R}(p,q)$-multi-variable $W_{1+\\infty}$-algebra and derive its\n$n$-algebra which is the generalized Lie algebra for $n$ even. Furthermore, we\ninvestigate the $\\mathcal{R}(p,q)$-elliptic hermitian matrix model and\ndetermine a toy model for the generalized quantum $W_{\\infty}$ constraints.\nAlso, we deduce particular cases of our results.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-17T15:02:43Z"}
{"aid":"http://arxiv.org/abs/2504.12998v1","title":"Automated Generation of Commit Messages in Software Repositories","summary":"Commit messages are crucial for documenting software changes, aiding in\nprogram comprehension and maintenance. However, creating effective commit\nmessages is often overlooked by developers due to time constraints and varying\nlevels of documentation skills. Our research presents an automated approach to\ngenerate commit messages using Machine Learning (ML) and Natural Language\nProcessing (NLP) by developing models that use techniques such as Logistic\nRegression with TF-IDF and Word2Vec, as well as more sophisticated methods like\nLSTM. We used the dataset of code changes and corresponding commit messages\nthat was used by Liu et al., which we used to train and evaluate ML/NLP models\nand was chosen because it is extensively used in previous research, also for\ncomparability in our study. The objective was to explore which ML/NLP\ntechniques generate the most effective, clear, and concise commit messages that\naccurately reflect the code changes. We split the dataset into training,\nvalidation, and testing sets and used these sets to evaluate the performance of\neach model using qualitative and quantitative evaluation methods. Our results\nreveal a spectrum of effectiveness among these models, with the highest BLEU\nscore achieved being 16.82, showcasing the models' capability in automating a\nclear and concise commit message generation. Our paper offers insights into the\ncomparative effectiveness of different machine learning models for automating\ncommit message generation in software development, aiming to enhance the\noverall practice of code documentation. The source code is available at\nhttps://doi.org/10.5281/zenodo.10888106.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T15:08:05Z"}
{"aid":"http://arxiv.org/abs/2504.13004v1","title":"Calibrating the SIDM Gravothermal Catastrophe with N-body Simulations","summary":"Self-interacting dark matter (SIDM) theories predict that dark matter halos\nexperience core-collapse in late-stage evolution, a process where the halo's\ninner region rapidly increases in density and decreases in size. This process\ncan be modeled by treating the dark matter as a gravothermal fluid, and solving\nthe fluid equations to predict the density profile evolution. This model is\nincomplete without calibration to N-body simulations, through a constant factor\n$\\beta$ included in the thermal conductivity for the long-mean-free-path limit.\nThe value of $\\beta$ employed in the gravothermal fluid formalism has varied\nbetween studies, with no clear universal value in the literature. In this work,\nwe use the N-body code Arepo to conduct a series of isolated core-collapse\nsimulations across a range of scattering cross-sections, halo concentrations,\nand halo masses to calibrate the heat transfer parameter $\\beta$. We find that\n$\\beta$ is independent of cross-section, halo concentration, and halo mass for\nvelocity independent elastic scattering cross-sections. We present a model for\nan effective $\\beta$ as a function of a dimensionless cross-section, to\ndescribe halo evolution in the long mean free path limit, and show that it\naccurately captures halo evolution as long as the cross section is not too\nlarge. This effective model facilitates comparisons between simulations and the\ngravothermal model, and enables fast predictions of the dark matter density\nprofile at any given time without running N-body simulations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T15:14:35Z"}
{"aid":"http://arxiv.org/abs/2504.13005v1","title":"Knot Floer homology of positive braids","summary":"We compute the next-to-top term of knot Floer homology for positive braid\nlinks. The rank is 1 for any prime positive braid knot. We give some examples\nof fibered positive links that are not positive braids.","main_category":"math.GT","categories":"math.GT","published":"2025-04-17T15:15:06Z"}
{"aid":"http://arxiv.org/abs/2504.13012v1","title":"Hopf Exceptional Points","summary":"Exceptional points at which eigenvalues and eigenvectors of non-Hermitian\nmatrices coalesce are ubiquitous in the description of a wide range of\nplatforms from photonic or mechanical metamaterials to open quantum systems.\nHere, we introduce a class of Hopf exceptional points (HEPs) that are protected\nby the Hopf invariants (including the higher-dimensional generalizations) and\nwhich exhibit phenomenology sharply distinct from conventional exceptional\npoints. Saliently, owing to their $\\mathbb{Z}_2$ topological invariant related\nto the Witten anomaly, three-fold HEPs and symmetry-protected five-fold HEPs\nact as their own ``antiparticles\". Furthermore, based on higher homotopy groups\nof spheres, we predict the existence of multifold HEPs and symmetry-protected\nHEPs with non-Hermitian topology captured by a range of finite groups (such as\n$\\mathbb{Z}_3$, $\\mathbb{Z}_{12}$, or $\\mathbb{Z}_{24}$) beyond the periodic\ntable of Bernard-LeClair symmetry classes.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.optics,quant-ph","published":"2025-04-17T15:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.13016v1","title":"ORIS allocation to minimize the outage probability in a multi-user VLC\n  scenario","summary":"Visible Light Communication (VLC) is a promising solution to address the\ngrowing demand for wireless data, leveraging the widespread use of\nlight-emitting diodes (LEDs) as transmitters. However, its deployment is\nchallenged by link blockages that cause connectivity outages. Optical\nreconfigurable intelligent surfaces (ORISs) have recently emerged as a solution\nto mitigate these disruptions. This work considers a multi-user VLC system and\ninvestigates the optimal association of ORISs to LEDs and users to minimize the\noutage probability while limiting the number of ORISs used. Numerical results\nfrom our proposed optimization algorithm demonstrate that using ORISs can\nreduce the outage probability by up to 85% compared to a no-ORIS scenario.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T15:24:25Z"}
{"aid":"http://arxiv.org/abs/2504.13017v1","title":"A characterization of $C^*$-simplicity of countable groups via Poisson\n  boundaries","summary":"We characterize $C^*$-simplicity for countable groups by means of the\nfollowing dichotomy. If a group is $C^*$-simple, then the action on the Poisson\nboundary is essentially free for a generic measure on the group. If a group is\nnot $C^*$-simple, then the action on the Poisson boundary is not essentially\nfree for a generic measure on the group.","main_category":"math.DS","categories":"math.DS,math.OA,math.PR","published":"2025-04-17T15:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.13022v1","title":"CompGS++: Compressed Gaussian Splatting for Static and Dynamic Scene\n  Representation","summary":"Gaussian splatting demonstrates proficiency for 3D scene modeling but suffers\nfrom substantial data volume due to inherent primitive redundancy. To enable\nfuture photorealistic 3D immersive visual communication applications,\nsignificant compression is essential for transmission over the existing\nInternet infrastructure. Hence, we propose Compressed Gaussian Splatting\n(CompGS++), a novel framework that leverages compact Gaussian primitives to\nachieve accurate 3D modeling with substantial size reduction for both static\nand dynamic scenes. Our design is based on the principle of eliminating\nredundancy both between and within primitives. Specifically, we develop a\ncomprehensive prediction paradigm to address inter-primitive redundancy through\nspatial and temporal primitive prediction modules. The spatial primitive\nprediction module establishes predictive relationships for scene primitives and\nenables most primitives to be encoded as compact residuals, substantially\nreducing the spatial redundancy. We further devise a temporal primitive\nprediction module to handle dynamic scenes, which exploits primitive\ncorrelations across timestamps to effectively reduce temporal redundancy.\nMoreover, we devise a rate-constrained optimization module that jointly\nminimizes reconstruction error and rate consumption. This module effectively\neliminates parameter redundancy within primitives and enhances the overall\ncompactness of scene representations. Comprehensive evaluations across multiple\nbenchmark datasets demonstrate that CompGS++ significantly outperforms existing\nmethods, achieving superior compression performance while preserving accurate\nscene modeling. Our implementation will be made publicly available on GitHub to\nfacilitate further research.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T15:33:01Z"}
{"aid":"http://arxiv.org/abs/2504.13029v1","title":"Three-dimensional canonical quantum plasmonics for finite media: exact\n  solution in terms of the classical Green tensor","summary":"This article presents a comprehensive three-dimensional canonical\nquantization to treat quantum plasmonics for finite metallic or dielectric\nmedia of arbitrary shape. We use a microscopic model for the dissipative and\ndispersive medium coupled with the electromagnetic field, which is justified by\nthe fact that if one integrates the degrees of freedom of the medium, one\nobtains the macroscopic Maxwell equations. Its quantization features a\nHamiltonian formulation having the form of two infinite harmonic oscillators\ncharacterized by a double continuum. The diagonalized Hamiltonian is quantized\nby the correspondence principle, introducing creation-annihilation operators in\na bosonic Fock space. The diagonal quantum Hamiltonian is the sum of two terms\ncorresponding to the two continua. The physical observables, like, e.g., the\nelectric field, are also the sum of two terms corresponding to the two\ncontinua, one of which had been omitted in the literature geared for an\ninfinite bulk medium. In a second step, we show that the electric field\noperator can by written as linear combinations of the creation-annihilation\noperators with coefficients that satisfy integral equations of Fredholm type.\nWe show that the solution of these equations can be expressed in terms of the\nclassical Green tensor of the medium satisfying the Sommerfeld radiation\ncondition. Finally, we consider the Purcell effect for the spontaneous emission\nof an atom close to the medium. We show that through an exact compensation of\nsome terms, the Purcell factor for the system with the double continuum is\nproportional to the imaginary part of the Green tensor, which defines the local\ndensity of states. This result has the same form as the one obtained in the\nliterature for bulk systems that involve a single continuum and a small\ndissipative background extending to infinity, and can be seen as a\njustification of this approach.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T15:39:29Z"}
{"aid":"http://arxiv.org/abs/2504.13032v1","title":"InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction\n  Graphs for LLM-Based Task Planning","summary":"Recent advancements in large language models (LLMs) have enabled their use as\nagents for planning complex tasks. Existing methods typically rely on a\nthought-action-observation (TAO) process to enhance LLM performance, but these\napproaches are often constrained by the LLMs' limited knowledge of complex\ntasks. Retrieval-augmented generation (RAG) offers new opportunities by\nleveraging external databases to ground generation in retrieved information. In\nthis paper, we identify two key challenges (enlargability and transferability)\nin applying RAG to task planning. We propose InstructRAG, a novel solution\nwithin a multi-agent meta-reinforcement learning framework, to address these\nchallenges. InstructRAG includes a graph to organize past instruction paths\n(sequences of correct actions), an RL-Agent with Reinforcement Learning to\nexpand graph coverage for enlargability, and an ML-Agent with Meta-Learning to\nimprove task generalization for transferability. The two agents are trained\nend-to-end to optimize overall planning performance. Our experiments on four\nwidely used task planning datasets demonstrate that InstructRAG significantly\nenhances performance and adapts efficiently to new tasks, achieving up to a\n19.2% improvement over the best existing approach.","main_category":"cs.AI","categories":"cs.AI,cs.IR","published":"2025-04-17T15:41:39Z"}
{"aid":"http://arxiv.org/abs/2504.13034v1","title":"Inference-friendly Graph Compression for Graph Neural Networks","summary":"Graph Neural Networks (GNNs) have demonstrated promising performance in graph\nanalysis. Nevertheless, the inference process of GNNs remains costly, hindering\ntheir applications for large graphs. This paper proposes inference-friendly\ngraph compression (IFGC), a graph compression scheme to accelerate GNNs\ninference. Given a graph $G$ and a GNN $M$, an IFGC computes a small compressed\ngraph $G_c$, to best preserve the inference results of $M$ over $G$, such that\nthe result can be directly inferred by accessing $G_c$ with no or little\ndecompression cost. (1) We characterize IFGC with a class of inference\nequivalence relation. The relation captures the node pairs in $G$ that are not\ndistinguishable for GNN inference. (2) We introduce three practical\nspecifications of IFGC for representative GNNs: structural preserving\ncompression (SPGC), which computes $G_c$ that can be directly processed by GNN\ninference without decompression; ($\\alpha$, $r$)-compression, that allows for a\nconfigurable trade-off between compression ratio and inference quality, and\nanchored compression that preserves inference results for specific nodes of\ninterest. For each scheme, we introduce compression and inference algorithms\nwith guarantees of efficiency and quality of the inferred results. We conduct\nextensive experiments on diverse sets of large-scale graphs, which verifies the\neffectiveness and efficiency of our graph compression approaches.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T15:42:13Z"}
{"aid":"http://arxiv.org/abs/2504.13041v1","title":"QI-MPC: A Hybrid Quantum-Inspired Model Predictive Control for Learning\n  Optimal Policies","summary":"In this paper, we present Quantum-Inspired Model Predictive Control (QIMPC),\nan approach that uses Variational Quantum Circuits (VQCs) to learn control\npolices in MPC problems. The viability of the approach is tested in five\nexperiments: A target-tracking control strategy, energy-efficient building\nclimate control, autonomous vehicular dynamics, the simple pendulum, and the\ncompound pendulum. Three safety guarantees were established for the approach,\nand the experiments gave the motivation for two important theoretical results\nthat, in essence, identify systems for which the approach works best.","main_category":"quant-ph","categories":"quant-ph,math.OC","published":"2025-04-17T15:55:37Z"}
{"aid":"http://arxiv.org/abs/2504.13043v1","title":"Machine Learning Decoding of Circuit-Level Noise for Bivariate Bicycle\n  Codes","summary":"Fault-tolerant quantum computers will depend crucially on the performance of\nthe classical decoding algorithm which takes in the results of measurements and\noutputs corrections to the errors inferred to have occurred. Machine learning\nmodels have shown great promise as decoders for the surface code; however, this\npromise has not yet been substantiated for the more challenging task of\ndecoding quantum low-density parity-check (QLDPC) codes. In this paper, we\npresent a recurrent, transformer-based neural network designed to decode\ncircuit-level noise on Bivariate Bicycle (BB) codes, introduced recently by\nBravyi et al (Nature 627, 778-782, 2024). For the $[[72,12,6]]$ BB code, at a\nphysical error rate of $p=0.1\\%$, our model achieves a logical error rate\nalmost $5$ times lower than belief propagation with ordered statistics decoding\n(BP-OSD). Moreover, while BP-OSD has a wide distribution of runtimes with\nsignificant outliers, our model has a consistent runtime and is an\norder-of-magnitude faster than the worst-case times from a benchmark BP-OSD\nimplementation. On the $[[144,12,12]]$ BB code, our model obtains worse logical\nerror rates but maintains the speed advantage. These results demonstrate that\nmachine learning decoders can out-perform conventional decoders on QLDPC codes,\nin regimes of current interest.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T15:57:16Z"}
{"aid":"http://arxiv.org/abs/2504.13050v1","title":"Radiative properties of a nonsingular black hole: Hawking radiation and\n  gray-body factor","summary":"We study the radiative properties of a spherical and singularity-free\nblack-hole geometry recently proposed in the literature. Contrary to the\nSchwarzschild spacetime, this geometry is geodesically complete and regular,\nand, instead of the singularity, it presents a minimal surface that connects a\ntrapped (black-hole) with an antitrapped (white-hole) region. The geometry is\ncharacterized by two parameters: the Schwarzschild radius and another parameter\nthat measures the area of the minimal surface. This parameter is related to\ncertain corrections expected in the context of loop quantum gravity to the\nclassical general-relativistic dynamics. We explicitly compute the spectrum of\nthe Hawking radiation and the gray-body factor. Since the gravitational\npotential is shallower than in Schwarzschild, the emission spectrum turns out\nbe colder and purer (less gray). From this, we sketch the evaporation history\nof this geometry and conclude that, instead of completely evaporating, it\nnaturally leads to a remnant, which provides a possible resolution of the\ninformation loss issue.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T16:07:11Z"}
{"aid":"http://arxiv.org/abs/2504.13056v1","title":"Adaptive Task Space Non-Singular Terminal Super-Twisting Sliding Mode\n  Control of a 7-DOF Robotic Manipulator","summary":"This paper presents a new task-space Non-singular Terminal Super-Twisting\nSliding Mode (NT-STSM) controller with adaptive gains for robust trajectory\ntracking of a 7-DOF robotic manipulator. The proposed approach addresses the\nchallenges of chattering, unknown disturbances, and rotational motion tracking,\nmaking it suited for high-DOF manipulators in dexterous manipulation tasks. A\nrigorous boundedness proof is provided, offering gain selection guidelines for\npractical implementation. Simulations and hardware experiments with external\ndisturbances demonstrate the proposed controller's robust, accurate tracking\nwith reduced control effort under unknown disturbances compared to other\nNT-STSM and conventional controllers. The results demonstrated that the\nproposed NT-STSM controller mitigates chattering and instability in complex\nmotions, making it a viable solution for dexterous robotic manipulations and\nvarious industrial applications.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-17T16:11:33Z"}
{"aid":"http://arxiv.org/abs/2504.13057v1","title":"Covariate balancing estimation and model selection for\n  difference-in-differences approach","summary":"In causal inference, remarkable progress has been made in\ndifference-in-differences (DID) approaches to estimate the average effect of\ntreatment on the treated (ATT). Of these, the semiparametric DID (SDID)\napproach incorporates a propensity score analysis into the DID setup. Supposing\nthat the ATT is a function of covariates, we estimate it by weighting the\ninverse of the propensity score. As one method to make the estimation robust to\nthe propensity score modeling, we incorporate covariate balancing. Then, by\nattentively constructing the moment conditions used in the covariate balancing,\nwe show that the proposed estimator has doubly robustness. In addition to the\nestimation, model selection is also addressed. In practice, covariate selection\nis an essential task in statistical analysis, but even in the basic setting of\nthe SDID approach, there are no reasonable information criteria. Therefore, we\nderive a model selection criterion as an asymptotically bias-corrected\nestimator of risk based on the loss function used in the SDID estimation. As a\nresult, we show that a penalty term is derived that is considerably different\nfrom almost twice the number of parameters that often appears in AIC-type\ninformation criteria. Numerical experiments show that the proposed method\nestimates the ATT robustly compared to the method using propensity scores given\nby the maximum likelihood estimation (MLE), and that the proposed criterion\nclearly reduces the risk targeted in the SDID approach compared to the\nintuitive generalization of the existing information criterion. In addition,\nreal data analysis confirms that there is a large difference between the\nresults of the proposed method and the existing method.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T16:11:42Z"}
{"aid":"http://arxiv.org/abs/2504.13070v1","title":"A quadratic estimator view of the transfer function correction in\n  intensity mapping surveys","summary":"In single dish neutral hydrogen (HI) intensity mapping, signal separation\nmethods such as Principal Component Analysis (PCA) are used to clean the\nastrophysical foregrounds. PCA induces a signal loss in the estimated power\nspectrum, which can be corrected by a transfer function (TF). By injecting mock\nsignals of HI into the data and performing the PCA cleaning, we can use the\ncleaned mock HI signal to cross-correlate with the original mock, and estimate\nthe signal loss as a TF, $T(\\vec{k})$. As expected, a correction of\n${T}(\\vec{k})^{-1}$ restores the cross-power between the HI and optical\ngalaxies. However, contrary to intuition, the HI auto-power also requires a\n${T}(\\vec{k})^{-1}$ correction, not ${T}(\\vec{k})^{-2}$. The\n${T}(\\vec{k})^{-1}$ correction is only known empirically through simulations.\nIn this Letter, we show that the ${T}(\\vec{k})^{-1}$ correction in auto-power\nis universal, and can be analytically proven using the quadratic estimator\nformalism through window function normalisation. The normalisation can also be\nused to determine the TF correction for any type of linear process. Using the\nwindow function, we demonstrate that PCA induces mode-mixing in the power\nspectrum estimation, which may lead to biases in the model inference.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-17T16:31:14Z"}
{"aid":"http://arxiv.org/abs/2504.13075v1","title":"An All-Atom Generative Model for Designing Protein Complexes","summary":"Proteins typically exist in complexes, interacting with other proteins or\nbiomolecules to perform their specific biological roles. Research on\nsingle-chain protein modeling has been extensively and deeply explored, with\nadvancements seen in models like the series of ESM and AlphaFold. Despite these\ndevelopments, the study and modeling of multi-chain proteins remain largely\nuncharted, though they are vital for understanding biological functions.\nRecognizing the importance of these interactions, we introduce APM (All-Atom\nProtein Generative Model), a model specifically designed for modeling\nmulti-chain proteins. By integrating atom-level information and leveraging data\non multi-chain proteins, APM is capable of precisely modeling inter-chain\ninteractions and designing protein complexes with binding capabilities from\nscratch. It also performs folding and inverse-folding tasks for multi-chain\nproteins. Moreover, APM demonstrates versatility in downstream applications: it\nachieves enhanced performance through supervised fine-tuning (SFT) while also\nsupporting zero-shot sampling in certain tasks, achieving state-of-the-art\nresults. Code will be released at https://github.com/bytedance/apm.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T16:37:41Z"}
{"aid":"http://arxiv.org/abs/2504.13084v1","title":"Proca theory of four-dimensional regularized Gauss-Bonnet gravity and\n  black holes with primary hair","summary":"We introduce a novel, well-defined four-dimensional regularized Gauss-Bonnet\ntheory of gravity by applying a dimensional regularization procedure. The\nresulting theory is a vector-tensor theory within the generalized Proca class.\nWe then consider the static spherically symmetric solutions of this theory and\nfind black hole solutions that acquire primary hair. Notably, one of the\nintegration constants associated with the Proca field is not manifest in the\noriginal metric, but under a disformal transformation of the seed solution, it\nemerges as a second, independent primary hair. This additional hair acts as an\neffective cosmological constant in the disformed geometry, even in the absence\nof a bare cosmological constant term. We further generalize these black hole\nsolutions to include electromagnetic charges and effects related to the\nscalar-tensor counterparts of the regularized Gauss-Bonnet theory. We discuss\nthe implications of our findings to observations.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T16:51:57Z"}
{"aid":"http://arxiv.org/abs/2504.13091v1","title":"Perturbed symmetric-product orbifold: first-order mixing and puzzles for\n  integrability","summary":"We study the marginal deformation of the symmetric-product orbifold theory\nSym$_N(T^4)$ which corresponds to introducing a small amount of Ramond-Ramond\nflux into the dual $AdS_3\\times S^3\\times T^4$ background. Already at first\norder in perturbation theory, the dimension of certain single-cycle operators\nis corrected, indicating that wrapping corrections from integrability must come\ninto play earlier than expected. We also discuss a flaw in the original\nderivation of the integrable structure of the perturbed orbifold. Together,\nthese observations suggest that more needs to be done to correctly identify and\nexploit the integrable structure of the perturbed orbifold CFT.","main_category":"hep-th","categories":"hep-th","published":"2025-04-17T16:58:34Z"}
{"aid":"http://arxiv.org/abs/2504.13093v1","title":"A lattice point counting approach for the study of the number of\n  self-avoiding walks on $\\mathbb{Z}^{d}$","summary":"We reduce the problem of counting self-avoiding walks in the square lattice\nto a problem of counting the number of integral points in multidimensional\ndomains. We obtain an asymptotic estimate of the number of self-avoiding walks\nof length $n$ in the square lattice. This new formalism gives a natural and\nunified setting in order to study the properties the number of self-avoidings\nwalks in the lattice $\\mathbb{Z}^{d}$ of any dimension $d\\geq 2$.","main_category":"math.PR","categories":"math.PR,math.CO,math.NT","published":"2025-04-17T16:59:16Z"}
{"aid":"http://arxiv.org/abs/2504.13100v1","title":"Kato-Kuzumaki's properties for function fields over higher local fields","summary":"Let $k$ be a $d$-local field such that the corresponding $1$-local field\n$k^{(d-1)}$ is a $p$-adic field and $C$ a curve over $k$. Let $K$ be the\nfunction field of $C$. We prove that for each $n,m \\in \\mathbf{N}$, and\nhypersurface $Z$ of $\\mathbf{P}^n_K$ with degree $m$ such that $m^{d+1} \\leq\nn$, the $(d+1)$-th Milnor $\\mathrm{K}$-theory group is generated by the images\nnorms of finite extension $L$ of $K$ such that $Z$ admits an $L$-point. Let $j\n\\in \\{1,\\cdots , d\\}$. When $C$ admits a point in an extension $l/k$ that is\nnot $i$-ramified for every $i \\in \\{1, \\cdots, d-j\\}$ we generalise this result\nto hypersurfaces $Z$ of $\\mathbf{P}_K^n$ with degree $m$ such that $m^{j+1}\n\\leq n$. \\par\n  In order to prove these results we give a description of the Tate-Shafarevich\ngroup $\\Sha^{d+2}(K,\\mathbf{Q}/\\mathbf{Z}(d+1))$ in terms of the combinatorics\nof the special fibre of certain models of the curve $C$.","main_category":"math.AG","categories":"math.AG,math.KT,math.NT","published":"2025-04-17T17:08:54Z"}
{"aid":"http://arxiv.org/abs/2504.13106v1","title":"Intersection of non-degenerate Hermitian variety and cubic hypersurface","summary":"Edoukou, Ling and Xing in 2010, conjectured that in\n\\mathbb{P}^n(\\mathbb{F}_{q^2}), n \\geq 3, the maximum number of common points\nof a non-degenerate Hermitian variety \\mathcal{U}_n and a hypersurface of\ndegree d is achieved only when the hypersurface is a union of d distinct\nhyperplanes meeting in a common linear space \\Pi_{n-2} of codimension 2 such\nthat \\Pi_{n-2} \\cap \\mathcal{U}_n is a non-degenerate Hermitian variety.\nFurthermore, these d hyperplanes are tangent to \\mathcal{U}_n if n is odd and\nnon-tangent if n is even. In this paper, we show that the conjecture is true\nfor d = 3 and q \\geq 7.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T17:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.13118v1","title":"CEERS: Forging the First Dust Grains in the Universe? A Population of\n  Galaxies with spectroscopically-derived Extremely Low Dust Attenuation\n  (GELDA) at 4.0<z<11.4","summary":"Aims: This paper investigates the coevolution of metals and dust for 173\ngalaxies at $4.0<z<11.4$ observed with JWST/NIRSpec in the CEERS project. We\nfocus on galaxies with extremely low dust attenuation to understand the\nphysical mechanisms at play. Methods: We developed a new version of the\n\\texttt{CIGALE} code that integrates spectroscopic and photometric data. By\nstatistically comparing observations with modeled spectra, we derive physical\nparameters to constrain these mechanisms. Results: Our analysis reveals a\npopulation of 49 extremely low dust attenuation galaxies (GELDAs), consistent\nwith $A_{FUV} = 0.0$ within $2\\sigma$ and $M_{\\star} < 10^9 M_\\odot$. The\nstacked spectrum of GELDAs shows a very blue UV slope $\\beta_{FUV} = -2.451 \\pm\n0.066$ and a Balmer decrement H$\\alpha$/H$\\beta = 2.932 \\pm 0.660$, consistent\nwith no dust and Case B recombination with minimal underlying absorption.\nNotably, GELDAs are more prevalent at $z > 8.8$ (83.3\\%) than at lower\nredshifts (26.3\\%), suggesting they could dominate in the early Universe.\n  Using a far-infrared dust spectrum from the ALPINE sample, we study\n$M_{dust}$ vs. $M_{\\star}$ trends. These exhibit upper and lower sequences\nconnected by transitional galaxies. Our comparison with models indicates a\ncritical transition around $M_{\\star} \\approx 10^{8.5}\\,M_\\odot$, from dust\ndominated by stellar sources (SNe and AGB stars) to dust growth via gas\naccretion. This corresponds to a metallicity of $12 + \\log_{10}(O/H) = 7.60$\n($Z/Z_\\odot \\approx 0.1$), aligning with the point where ISM dust growth\nmatches stellar dust production.\n  The sample has a high gas fraction ($f_{\\mathrm{gas}} \\gtrsim 0.9$), with no\nsignificant gas expulsion, and high surface gas densities. This leads to low\nstar formation efficiencies compared to sub-millimeter galaxies. GELDAs may\nhelp explain the observed excess of bright galaxies at $z \\gtrsim 9$.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T17:37:14Z"}
{"aid":"http://arxiv.org/abs/2504.13120v1","title":"Probing and Inducing Combinational Creativity in Vision-Language Models","summary":"The ability to combine existing concepts into novel ideas stands as a\nfundamental hallmark of human intelligence. Recent advances in Vision-Language\nModels (VLMs) like GPT-4V and DALLE-3 have sparked debate about whether their\noutputs reflect combinational creativity--defined by M. A. Boden (1998) as\nsynthesizing novel ideas through combining existing concepts--or sophisticated\npattern matching of training data. Drawing inspiration from cognitive science,\nwe investigate the combinational creativity of VLMs from the lens of concept\nblending. We propose the Identification-Explanation-Implication (IEI)\nframework, which decomposes creative processes into three levels: identifying\ninput spaces, extracting shared attributes, and deriving novel semantic\nimplications. To validate this framework, we curate CreativeMashup, a\nhigh-quality dataset of 666 artist-generated visual mashups annotated according\nto the IEI framework. Through extensive experiments, we demonstrate that in\ncomprehension tasks, best VLMs have surpassed average human performance while\nfalling short of expert-level understanding; in generation tasks, incorporating\nour IEI framework into the generation pipeline significantly enhances the\ncreative quality of VLMs outputs. Our findings establish both a theoretical\nfoundation for evaluating artificial creativity and practical guidelines for\nimproving creative generation in VLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-17T17:38:18Z"}
{"aid":"http://arxiv.org/abs/2504.13124v1","title":"Spatial Confidence Regions for Excursion Sets with False Discovery Rate\n  Control","summary":"Identifying areas where the signal is prominent is an important task in image\nanalysis, with particular applications in brain mapping. In this work, we\ndevelop confidence regions for spatial excursion sets above and below a given\nlevel. We achieve this by treating the confidence procedure as a testing\nproblem at the given level, allowing control of the False Discovery Rate (FDR).\nMethods are developed to control the FDR, separately for positive and negative\nexcursions, as well as jointly over both. Furthermore, power is increased by\nincorporating a two-stage adaptive procedure. Simulation results with various\nsignals show that our confidence regions successfully control the FDR under the\nnominal level. We showcase our methods with an application to functional\nmagnetic resonance imaging (fMRI) data from the Human Connectome Project\nillustrating the improvement in statistical power over existing approaches.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-17T17:41:05Z"}
{"aid":"http://arxiv.org/abs/2504.13137v1","title":"Integral formulas for hypersurfaces in cones and related questions","summary":"We discuss the validity of Minkowski integral identities for hypersurfaces\ninside a cone, intersecting the boundary of the cone orthogonally. In doing so\nwe correct a formula provided in [3]. Then we study rigidity results for\nconstant mean curvature graphs proving the precise statement of a result given\nin [9] and [10]. Finally we provide an integral estimate for stable constant\nmean curvature hypersurfaces in cones.","main_category":"math.AP","categories":"math.AP","published":"2025-04-17T17:48:27Z"}
{"aid":"http://arxiv.org/abs/2504.13139v1","title":"Syntactic and Semantic Control of Large Language Models via Sequential\n  Monte Carlo","summary":"A wide range of LM applications require generating text that conforms to\nsyntactic or semantic constraints. Imposing such constraints can be naturally\nframed as probabilistic conditioning, but exact generation from the resulting\ndistribution -- which can differ substantially from the LM's base distribution\n-- is generally intractable. In this work, we develop an architecture for\ncontrolled LM generation based on sequential Monte Carlo (SMC). Our SMC\nframework allows us to flexibly incorporate domain- and problem-specific\nconstraints at inference time, and efficiently reallocate computational\nresources in light of new information during the course of generation. By\ncomparing to a number of alternatives and ablations on four challenging domains\n-- Python code generation for data science, text-to-SQL, goal inference, and\nmolecule synthesis -- we demonstrate that, with little overhead, our approach\nallows small open-source language models to outperform models over 8x larger,\nas well as closed-source, fine-tuned ones. In support of the probabilistic\nperspective, we show that these performance improvements are driven by better\napproximation to the posterior distribution. Our system builds on the framework\nof Lew et al. (2023) and integrates with its language model probabilistic\nprogramming language, giving users a simple, programmable way to apply SMC to a\nbroad variety of controlled generation problems.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-17T17:49:40Z"}
{"aid":"http://arxiv.org/abs/2504.13151v1","title":"MIB: A Mechanistic Interpretability Benchmark","summary":"How can we know whether new mechanistic interpretability methods achieve real\nimprovements? In pursuit of meaningful and lasting evaluation standards, we\npropose MIB, a benchmark with two tracks spanning four tasks and five models.\nMIB favors methods that precisely and concisely recover relevant causal\npathways or specific causal variables in neural language models. The circuit\nlocalization track compares methods that locate the model components - and\nconnections between them - most important for performing a task (e.g.,\nattribution patching or information flow routes). The causal variable\nlocalization track compares methods that featurize a hidden vector, e.g.,\nsparse autoencoders (SAEs) or distributed alignment search (DAS), and locate\nmodel features for a causal variable relevant to the task. Using MIB, we find\nthat attribution and mask optimization methods perform best on circuit\nlocalization. For causal variable localization, we find that the supervised DAS\nmethod performs best, while SAE features are not better than neurons, i.e.,\nstandard dimensions of hidden vectors. These findings illustrate that MIB\nenables meaningful comparisons of methods, and increases our confidence that\nthere has been real progress in the field.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-17T17:55:45Z"}
{"aid":"http://arxiv.org/abs/2504.13156v1","title":"Gravitational wave anisotropies from axion inflation","summary":"An important prediction of inflation is the production of a primordial\nstochastic gravitational wave background. Observing this background is\nchallenging due to the weakness of the signal and the simultaneous presence of\nan astrophysical background generated by many unresolved late-time sources. One\npossible way to distinguish between the two is to examine their anisotropies.\nIn this paper we calculate the primordial correlation function of gravitational\nwave anisotropies in the cosmological background generated by axion inflation,\nwhere the inflaton is a pseudo-Nambu-Goldstone boson coupled to gauge fields.\nIn this scenario, tensor modes arise not only from the standard amplification\nof vacuum fluctuations present in any inflationary model, but also from the\ninverse decay process of the produced gauge fields. The correlator of\ngravitational wave anisotropies consists therefore of two main components: the\ncontribution from vacuum tensor modes and the contribution from tensor modes\nsourced by the gauge fields. Our analysis shows that, while the former,\npreviously studied in the literature, is negligible, the one arising from the\nsourced tensor modes, normalized by the fractional energy density at\ninterferometer frequencies, can reach values as large as\n$\\mathcal{O}(10^{-1})$. This result shows that axion inflation can generate\nlarge anisotropies with the potential to be observed by gravitational wave\ndetectors within a reasonable time frame.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-17T17:56:58Z"}
{"aid":"http://arxiv.org/abs/2504.13160v1","title":"Discovery and Dynamics of the Nontransiting Planet Kepler-139f","summary":"Among the ways that an outer giant planet can alter the architecture of an\ninner planetary system is by tilting the orbits of the inner planets and\nreducing their mutual transit probabilities. Here, we report on an example of\nthis phenomenon: we show that the Kepler-139 system contains a nontransiting\nplanet just exterior to three transiting planets, and interior to a giant\nplanet. This newly discovered planet, Kepler-139f, has an orbital period of\n$355 \\pm 2$ days and a mass of $36 \\pm 10 M_\\oplus$ based on transit-timing and\nradial-velocity data. Through dynamical simulations, we show that gravitational\nperturbations on planet f's orbit from the outer giant planet reduce the\nprobability for a randomly located observer to see transits of all four inner\nplanets. Thus, Kepler-139 illustrates the role that outer giant planets can\nplay in the apparent truncation of compact systems of multiple transiting\nplanets.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-17T17:57:59Z"}
{"aid":"http://arxiv.org/abs/2504.13161v1","title":"CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for\n  Language Model Pre-training","summary":"Pre-training datasets are typically collected from web content and lack\ninherent domain divisions. For instance, widely used datasets like Common Crawl\ndo not include explicit domain labels, while manually curating labeled datasets\nsuch as The Pile is labor-intensive. Consequently, identifying an optimal\npre-training data mixture remains a challenging problem, despite its\nsignificant benefits for pre-training performance. To address these challenges,\nwe propose CLustering-based Iterative Data Mixture Bootstrapping (CLIMB), an\nautomated framework that discovers, evaluates, and refines data mixtures in a\npre-training setting. Specifically, CLIMB embeds and clusters large-scale\ndatasets in a semantic space and then iteratively searches for optimal mixtures\nusing a smaller proxy model and a predictor. When continuously trained on 400B\ntokens with this mixture, our 1B model exceeds the state-of-the-art\nLlama-3.2-1B by 2.0%. Moreover, we observe that optimizing for a specific\ndomain (e.g., Social Sciences) yields a 5% improvement over random sampling.\nFinally, we introduce ClimbLab, a filtered 1.2-trillion-token corpus with 20\nclusters as a research playground, and ClimbMix, a compact yet powerful\n400-billion-token dataset designed for efficient pre-training that delivers\nsuperior performance under an equal token budget. We analyze the final data\nmixture, elucidating the characteristics of an optimal data mixture. Our data\nis available at: https://research.nvidia.com/labs/lpr/climb/","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T17:58:13Z"}
{"aid":"http://arxiv.org/abs/2504.13179v1","title":"ViTa-Zero: Zero-shot Visuotactile Object 6D Pose Estimation","summary":"Object 6D pose estimation is a critical challenge in robotics, particularly\nfor manipulation tasks. While prior research combining visual and tactile\n(visuotactile) information has shown promise, these approaches often struggle\nwith generalization due to the limited availability of visuotactile data. In\nthis paper, we introduce ViTa-Zero, a zero-shot visuotactile pose estimation\nframework. Our key innovation lies in leveraging a visual model as its backbone\nand performing feasibility checking and test-time optimization based on\nphysical constraints derived from tactile and proprioceptive observations.\nSpecifically, we model the gripper-object interaction as a spring-mass system,\nwhere tactile sensors induce attractive forces, and proprioception generates\nrepulsive forces. We validate our framework through experiments on a real-world\nrobot setup, demonstrating its effectiveness across representative visual\nbackbones and manipulation scenarios, including grasping, object picking, and\nbimanual handover. Compared to the visual models, our approach overcomes some\ndrastic failure modes while tracking the in-hand object pose. In our\nexperiments, our approach shows an average increase of 55% in AUC of ADD-S and\n60% in ADD, along with an 80% lower position error compared to FoundationPose.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-17T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.14825v1","title":"ECViT: Efficient Convolutional Vision Transformer with Local-Attention\n  and Multi-scale Stages","summary":"Vision Transformers (ViTs) have revolutionized computer vision by leveraging\nself-attention to model long-range dependencies. However, ViTs face challenges\nsuch as high computational costs due to the quadratic scaling of self-attention\nand the requirement of a large amount of training data. To address these\nlimitations, we propose the Efficient Convolutional Vision Transformer (ECViT),\na hybrid architecture that effectively combines the strengths of CNNs and\nTransformers. ECViT introduces inductive biases such as locality and\ntranslation invariance, inherent to Convolutional Neural Networks (CNNs) into\nthe Transformer framework by extracting patches from low-level features and\nenhancing the encoder with convolutional operations. Additionally, it\nincorporates local-attention and a pyramid structure to enable efficient\nmulti-scale feature extraction and representation. Experimental results\ndemonstrate that ECViT achieves an optimal balance between performance and\nefficiency, outperforming state-of-the-art models on various image\nclassification tasks while maintaining low computational and storage\nrequirements. ECViT offers an ideal solution for applications that prioritize\nhigh efficiency without compromising performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T03:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.14830v1","title":"Solving All Seismic Tomographic Problems using Deep Learning","summary":"In a variety of geoscientific applications scientists often need to image\nproperties of the Earth's interior in order to understand the heterogeneity and\nprocesses taking place within the Earth. Seismic tomography is one such method\nwhich has been used widely to study properties of the subsurface. In order to\nsolve tomographic problems efficiently, neural network-based methods have been\nintroduced to geophysics. However, these methods can only be applied to certain\ntypes of problems with fixed acquisition geometry at a specific site. In this\nstudy we extend neural network-based methods to problems with various scales\nand acquisition geometries by using graph mixture density networks (MDNs). We\ntrain a graph MDN for 2D tomographic problems using simulated velocity models\nand travel time data, and apply the trained network to both synthetic and real\ndata problems that have various scales and station distributions at different\nsites. The results demonstrate that graph MDNs can provide comparable solutions\nto those obtained using traditional Bayesian methods in seconds, and therefore\nprovide the possibility to use graph MDNs to produce rapid solutions for all\nkinds of seismic tomographic problems over the world.","main_category":"physics.geo-ph","categories":"physics.geo-ph,physics.data-an","published":"2025-04-21T03:14:57Z"}
{"aid":"http://arxiv.org/abs/2504.14843v1","title":"Quantitative Measures for Passive Sonar Texture Analysis","summary":"Passive sonar signals contain complex characteristics often arising from\nenvironmental noise, vessel machinery, and propagation effects. While\nconvolutional neural networks (CNNs) perform well on passive sonar\nclassification tasks, they can struggle with statistical variations that occur\nin the data. To investigate this limitation, synthetic underwater acoustic\ndatasets are generated that centered on amplitude and period variations. Two\nmetrics are proposed to quantify and validate these characteristics in the\ncontext of statistical and structural texture for passive sonar. These measures\nare applied to real-world passive sonar datasets to assess texture information\nin the signals and correlate the performances of the models. Results show that\nCNNs underperform on statistically textured signals, but incorporating explicit\nstatistical texture modeling yields consistent improvements. These findings\nhighlight the importance of quantifying texture information for passive sonar\nclassification.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-21T03:55:49Z"}
{"aid":"http://arxiv.org/abs/2504.14845v1","title":"Enhancing the Patent Matching Capability of Large Language Models via\n  the Memory Graph","summary":"Intellectual Property (IP) management involves strategically protecting and\nutilizing intellectual assets to enhance organizational innovation,\ncompetitiveness, and value creation. Patent matching is a crucial task in\nintellectual property management, which facilitates the organization and\nutilization of patents. Existing models often rely on the emergent capabilities\nof Large Language Models (LLMs) and leverage them to identify related patents\ndirectly. However, these methods usually depend on matching keywords and\noverlook the hierarchical classification and categorical relationships of\npatents. In this paper, we propose MemGraph, a method that augments the patent\nmatching capabilities of LLMs by incorporating a memory graph derived from\ntheir parametric memory. Specifically, MemGraph prompts LLMs to traverse their\nmemory to identify relevant entities within patents, followed by attributing\nthese entities to corresponding ontologies. After traversing the memory graph,\nwe utilize extracted entities and ontologies to improve the capability of LLM\nin comprehending the semantics of patents. Experimental results on the\nPatentMatch dataset demonstrate the effectiveness of MemGraph, achieving a\n17.68% performance improvement over baseline LLMs. The further analysis\nhighlights the generalization ability of MemGraph across various LLMs, both\nin-domain and out-of-domain, and its capacity to enhance the internal reasoning\nprocesses of LLMs during patent matching. All data and codes are available at\nhttps://github.com/NEUIR/MemGraph.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-21T03:56:56Z"}
{"aid":"http://arxiv.org/abs/2504.14850v1","title":"Charmonium pair production in ultraperipheral collision","summary":"We study the exclusive double charmonium ($J/\\psi \\mbox{-} J/\\psi$ and\n$\\eta_c \\mbox{-} \\eta_c$) production through photon-photon fusion via\nultraperipheral collision (UPC) at the HL-LHC and FCC with next-to-leading\norder (NLO) QCD predictions in the framework of non-relativistic QCD (NRQCD).\nNumerical results indicate that the NLO corrections for $J/\\psi$ pair are large\nand negative, while positive for $\\eta_c$ pair. The total cross section of\n$J/\\psi \\mbox{-} J/\\psi$ ($\\eta_c \\mbox{-} \\eta_c$) in Pb-Pb UPC is 28.0 (65.1)\nnb at nucleon-nucleon c.m. energy $\\sqrt{s_{NN}} = 5.52$ TeV. Due to the\nbackgrounds from various QCD interactions at UPC are highly suppressed and the\nevent topologies for charmonium pair are easy to tag, the phenomenological\nstudies at the LHC and FCC are feasible. The detailed transverse momentum\n$p_T$, diphoton invariant mass $m_{\\gamma\\gamma}$ and the rapidity difference\n$\\Delta y$ distributions are given. The production for X(6900) is also\ndiscussed.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T04:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.14852v1","title":"APIRAT: Integrating Multi-source API Knowledge for Enhanced Code\n  Translation with LLMs","summary":"Code translation is an essential task in software migration, multilingual\ndevelopment, and system refactoring. Recent advancements in large language\nmodels (LLMs) have demonstrated significant potential in this task. However,\nprior studies have highlighted that LLMs often struggle with domain-specific\ncode, particularly in resolving cross-lingual API mappings. To tackle this\nchallenge, we propose APIRAT, a novel code translation method that integrates\nmulti-source API knowledge. APIRAT employs three API knowledge augmentation\ntechniques, including API sequence retrieval, API sequence back-translation,\nand API mapping, to guide LLMs to translating code, ensuring both the correct\nstructure of API sequences and the accurate usage of individual APIs. Extensive\nexperiments on two public datasets, CodeNet and AVATAR, indicate that APIRAT\nsignificantly surpasses existing LLM-based methods, achieving improvements in\ncomputational accuracy ranging from 4% to 15.1%. Additionally, our evaluation\nacross different LLMs showcases the generalizability of APIRAT. An ablation\nstudy further confirms the individual contributions of each API knowledge\ncomponent, underscoring the effectiveness of our approach.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-21T04:24:49Z"}
{"aid":"http://arxiv.org/abs/2504.14857v1","title":"SuFIA-BC: Generating High Quality Demonstration Data for Visuomotor\n  Policy Learning in Surgical Subtasks","summary":"Behavior cloning facilitates the learning of dexterous manipulation skills,\nyet the complexity of surgical environments, the difficulty and expense of\nobtaining patient data, and robot calibration errors present unique challenges\nfor surgical robot learning. We provide an enhanced surgical digital twin with\nphotorealistic human anatomical organs, integrated into a comprehensive\nsimulator designed to generate high-quality synthetic data to solve fundamental\ntasks in surgical autonomy. We present SuFIA-BC: visual Behavior Cloning\npolicies for Surgical First Interactive Autonomy Assistants. We investigate\nvisual observation spaces including multi-view cameras and 3D visual\nrepresentations extracted from a single endoscopic camera view. Through\nsystematic evaluation, we find that the diverse set of photorealistic surgical\ntasks introduced in this work enables a comprehensive evaluation of prospective\nbehavior cloning models for the unique challenges posed by surgical\nenvironments. We observe that current state-of-the-art behavior cloning\ntechniques struggle to solve the contact-rich and complex tasks evaluated in\nthis work, regardless of their underlying perception or control architectures.\nThese findings highlight the importance of customizing perception pipelines and\ncontrol architectures, as well as curating larger-scale synthetic datasets that\nmeet the specific demands of surgical tasks. Project website:\nhttps://orbit-surgical.github.io/sufia-bc/","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T04:50:24Z"}
{"aid":"http://arxiv.org/abs/2504.14860v1","title":"Bridge the Gap: From Weak to Full Supervision for Temporal Action\n  Localization with PseudoFormer","summary":"Weakly-supervised Temporal Action Localization (WTAL) has achieved notable\nsuccess but still suffers from a lack of temporal annotations, leading to a\nperformance and framework gap compared with fully-supervised methods. While\nrecent approaches employ pseudo labels for training, three key challenges:\ngenerating high-quality pseudo labels, making full use of different priors, and\noptimizing training methods with noisy labels remain unresolved. Due to these\nperspectives, we propose PseudoFormer, a novel two-branch framework that\nbridges the gap between weakly and fully-supervised Temporal Action\nLocalization (TAL). We first introduce RickerFusion, which maps all predicted\naction proposals to a global shared space to generate pseudo labels with better\nquality. Subsequently, we leverage both snippet-level and proposal-level labels\nwith different priors from the weak branch to train the regression-based model\nin the full branch. Finally, the uncertainty mask and iterative refinement\nmechanism are applied for training with noisy pseudo labels. PseudoFormer\nachieves state-of-the-art WTAL results on the two commonly used benchmarks,\nTHUMOS14 and ActivityNet1.3. Besides, extensive ablation studies demonstrate\nthe contribution of each component of our method.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T05:00:07Z"}
{"aid":"http://arxiv.org/abs/2504.14864v1","title":"Radiative Transitions for the Ground and Excited Charmonia States","summary":"In this work, we have investigated the physical properties like decay\nconstants, radiative transitions, decay widths, and branching ratios for the\nground and radially excited charmonia states. For the numerical calculations,\nwe have adopted the light-front quark model (LFQM). We have studied\n$\\chi_{c0}\\rightarrow J{/}\\psi+\\gamma $ and\n$\\psi(2S)\\rightarrow\\chi_{c0}+\\gamma$, $h_c(1P)\\rightarrow\\eta_c(1S)+\\gamma $,\nand $\\eta_c(2S)\\rightarrow h_c(1P)+\\gamma $ transitions in this work. We have\nalso demonstrated the behavior of the transition form factors (TFFs) for the\n$h_c(1P)\\rightarrow\\eta_c(1S)+\\gamma $ and\n$\\psi(2S)\\rightarrow\\chi_{c0}+\\gamma$ decays in this model. Using the TFFs\nresults, we have calculated the decay widths and branching ratios for these\ntransitions. Our numerical results of decay constants, decay widths, and\nbranching ratios are overall in good agreement with available experimental,\ntheoretical and lattice simulation data.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T05:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.14866v1","title":"GainSight: Application-Guided Profiling for Composing Heterogeneous\n  On-Chip Memories in AI Hardware Accelerators","summary":"As AI workloads drive soaring memory requirements, there is a need for\nhigher-density on-chip memory for domain-specific accelerators that goes beyond\nwhat current SRAM technology can provide. We motivate that algorithms and\napplication behavior should guide the composition of heterogeneous on-chip\nmemories. However, there has been little work in factoring dynamic application\nprofiles into such design decisions. We present GainSight, a profiling\nframework that analyzes fine-grained memory access patterns and computes data\nlifetimes in domain-specific accelerators. By combining instrumentation and\nsimulation across retargetable hardware backends, GainSight aligns\nheterogeneous memory designs with workload-specific traffic and lifetime\nmetrics. Case studies on MLPerf Inference and PolyBench workloads using NVIDIA\nH100 GPUs and systolic arrays reveal key insights: (1) 40% of L1 and 18% of L2\nGPU cache accesses, and 79% of systolic array scratchpad accesses across\nprofiled workloads are short-lived and suitable for silicon-based gain cell RAM\n(Si-GCRAM); (2) Si-GCRAM reduces active energy by 11-28% compared to SRAM; (3)\nUp to 90% of GPU cache fetches are never reused, highlighting inefficiencies in\nterms of cache pollution. These insights that GainSight provides can be used to\nbetter understand the design spaces of both emerging on-chip memories and\nsoftware algorithmic optimizations for the next generation of AI accelerators.","main_category":"cs.AR","categories":"cs.AR,cs.ET","published":"2025-04-21T05:27:33Z"}
{"aid":"http://arxiv.org/abs/2504.14867v1","title":"On tensor invariants of the Clebsch system","summary":"We present some new Poisson bivectors that are invariants by the Clebsch\nsystem flow. Symplectic integrators on their symplectic leaves exactly preserve\nthe corresponding Casimir functions, which have different physical meanings.\nThe Kahan discretization of the Clebsch system is discussed briefly.","main_category":"nlin.SI","categories":"nlin.SI,math-ph,math.MP","published":"2025-04-21T05:36:19Z"}
{"aid":"http://arxiv.org/abs/2504.14877v1","title":"Collaborative Enhancement Network for Low-quality Multi-spectral Vehicle\n  Re-identification","summary":"The performance of multi-spectral vehicle Re-identification (ReID) is\nsignificantly degraded when some important discriminative cues in visible, near\ninfrared and thermal infrared spectra are lost. Existing methods generate or\nenhance missing details in low-quality spectra data using the high-quality one,\ngenerally called the primary spectrum, but how to justify the primary spectrum\nis a challenging problem. In addition, when the quality of the primary spectrum\nis low, the enhancement effect would be greatly degraded, thus limiting the\nperformance of multi-spectral vehicle ReID. To address these problems, we\npropose the Collaborative Enhancement Network (CoEN), which generates a\nhigh-quality proxy from all spectra data and leverages it to supervise the\nselection of primary spectrum and enhance all spectra features in a\ncollaborative manner, for robust multi-spectral vehicle ReID. First, to\nintegrate the rich cues from all spectra data, we design the Proxy Generator\n(PG) to progressively aggregate multi-spectral features. Second, we design the\nDynamic Quality Sort Module (DQSM), which sorts all spectra data by measuring\ntheir correlations with the proxy, to accurately select the primary spectra\nwith the highest correlation. Finally, we design the Collaborative Enhancement\nModule (CEM) to effectively compensate for missing contents of all spectra by\ncollaborating the primary spectra and the proxy, thereby mitigating the impact\nof low-quality primary spectra. Extensive experiments on three benchmark\ndatasets are conducted to validate the efficacy of the proposed approach\nagainst other multi-spectral vehicle ReID methods. The codes will be released\nat https://github.com/yongqisun/CoEN.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T06:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.14879v1","title":"Impact of Latent Space Dimension on IoT Botnet Detection Performance:\n  VAE-Encoder Versus ViT-Encoder","summary":"The rapid evolution of Internet of Things (IoT) technology has led to a\nsignificant increase in the number of IoT devices, applications, and services.\nThis surge in IoT devices, along with their widespread presence, has made them\na prime target for various cyber-attacks, particularly through IoT botnets. As\na result, security has become a major concern within the IoT ecosystem. This\nstudy focuses on investigating how the latent dimension impacts the performance\nof different deep learning classifiers when trained on latent vector\nrepresentations of the train dataset. The primary objective is to compare the\noutcomes of these models when encoder components from two cutting-edge\narchitectures: the Vision Transformer (ViT) and the Variational Auto-Encoder\n(VAE) are utilized to project the high dimensional train dataset to the learned\nlow dimensional latent space. The encoder components are employed to project\nhigh-dimensional structured .csv IoT botnet traffic datasets to various latent\nsizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that\nVAE-encoder based dimension reduction outperforms ViT-encoder based dimension\nreduction for both datasets in terms of four performance metrics including\naccuracy, precision, recall, and F1-score for all models which can be\nattributed to absence of spatial patterns in the datasets the ViT model\nattempts to learn and extract from image instances.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T06:15:07Z"}
{"aid":"http://arxiv.org/abs/2504.14893v1","title":"Hardware-based Heterogeneous Memory Management for Large Language Model\n  Inference","summary":"A large language model (LLM) is one of the most important emerging machine\nlearning applications nowadays. However, due to its huge model size and runtime\nincrease of the memory footprint, LLM inferences suffer from the lack of memory\ncapacity in conventional systems consisting of multiple GPUs with a modest\namount of high bandwidth memory. Moreover, since LLM contains many\nbandwidthintensive kernels, only focusing on the memory capacity without\nconsidering the bandwidth incurs a serious performance degradation. To handle\nsuch conflicting memory capacity and bandwidth demands in a cost-effective way,\nthis study investigates the potential of heterogeneous memory systems,\nproposing H2M2. It uses an asymmetric memory architecture consisting of\ncapacity-centric and bandwidthcentric memory with computation units attached to\neach memory device. With the asymmetric memory, we first analyze the effect of\nkernel-memory mapping for the asymmetric memory. Second, we propose a dynamic\nruntime algorithm that finds a mapping solution considering the characteristics\nof LLM operations and the change of footprint during LLM inference. Third, we\nadvocate the need for memory abstraction for the efficient management of the\nasymmetric memory. H2M2 outperforms the conventional homogeneous memory system\nwith LPDDR by 1.46x, 1.55x, and 2.94x speedup in GPT3-175B, Chinchilla-70B, and\nLlama2-70B, respectively.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-21T06:45:41Z"}
{"aid":"http://arxiv.org/abs/2504.14896v1","title":"Vector pulse magnet","summary":"The underlying symmetry of the crystal, electronic structure, and magnetic\nstructure manifests itself in the anisotropy of materials' properties, which is\na central topic of the present condensed matter research. However, it demands\nsuch a considerable effort to fill the explorable space that only a small part\nhas been conquered. We report a vector pulse magnet (VPM) as an alternative\nexperimental technique to control the direction of applied magnetic fields,\nwhich may complement the conventional methods with its characteristic features.\nThe VPM combines a conventional pulse magnet and a vector magnet. The VPM can\ncreate vector pulsed magnetic fields and swiftly rotating pulsed magnetic\nfields. As a demonstration, the three-dimensional magnetoresistance measurement\nof a highly oriented pyrolytic graphite is carried out using the AC four-probe\nmethod at 4.5 K and 6 T. The two-dimensional electronic structure of graphite\nis visualized in the three-dimensional magnetoresistance data. One can uncover\nthe rotational and time-reversal symmetry of materials using a VPM and a\nvariety of measurement techniques.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T07:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.14899v1","title":"Uni3C: Unifying Precisely 3D-Enhanced Camera and Human Motion Controls\n  for Video Generation","summary":"Camera and human motion controls have been extensively studied for video\ngeneration, but existing approaches typically address them separately,\nsuffering from limited data with high-quality annotations for both aspects. To\novercome this, we present Uni3C, a unified 3D-enhanced framework for precise\ncontrol of both camera and human motion in video generation. Uni3C includes two\nkey contributions. First, we propose a plug-and-play control module trained\nwith a frozen video generative backbone, PCDController, which utilizes\nunprojected point clouds from monocular depth to achieve accurate camera\ncontrol. By leveraging the strong 3D priors of point clouds and the powerful\ncapacities of video foundational models, PCDController shows impressive\ngeneralization, performing well regardless of whether the inference backbone is\nfrozen or fine-tuned. This flexibility enables different modules of Uni3C to be\ntrained in specific domains, i.e., either camera control or human motion\ncontrol, reducing the dependency on jointly annotated data. Second, we propose\na jointly aligned 3D world guidance for the inference phase that seamlessly\nintegrates both scenic point clouds and SMPL-X characters to unify the control\nsignals for camera and human motion, respectively. Extensive experiments\nconfirm that PCDController enjoys strong robustness in driving camera motion\nfor fine-tuned backbones of video generation. Uni3C substantially outperforms\ncompetitors in both camera controllability and human motion quality.\nAdditionally, we collect tailored validation sets featuring challenging camera\nmovements and human actions to validate the effectiveness of our method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T07:10:41Z"}
{"aid":"http://arxiv.org/abs/2504.14910v1","title":"Erratic non-Hermitian skin localization","summary":"A novel localization phenomenon, termed erratic non-Hermitian skin\nlocalization, has been identified in disordered globally-reciprocal\nnon-Hermitian lattices. Unlike conventional non-Hermitian skin effect and\nAnderson localization, it features macroscopic eigenstate localization at\nirregular, disorder-dependent positions with sub-exponential decay. Using the\nHatano-Nelson model with disordered imaginary gauge fields as a case study,\nthis effect is linked to stochastic interfaces governed by the universal order\nstatistics of random walks. Finite-size scaling analysis confirms the localized\nnature of the eigenstates. This discovery challenges conventional wave\nlocalization paradigms, offering new avenues for understanding and controlling\nlocalization phenomena in non-Hermitian physics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,physics.optics,quant-ph","published":"2025-04-21T07:27:59Z"}
{"aid":"http://arxiv.org/abs/2504.14913v1","title":"Guidelines for External Disturbance Factors in the Use of OCR in\n  Real-World Environments","summary":"The performance of OCR has improved with the evolution of AI technology. As\nOCR continues to broaden its range of applications, the increased likelihood of\ninterference introduced by various usage environments can prevent it from\nachieving its inherent performance. This results in reduced recognition\naccuracy under certain conditions, and makes the quality control of recognition\ndevices more challenging. Therefore, to ensure that users can properly utilize\nOCR, we compiled the real-world external disturbance factors that cause\nperformance degradation, along with the resulting image degradation phenomena,\ninto an external disturbance factor table and, by also indicating how to make\nuse of it, organized them into guidelines.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T07:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.14918v1","title":"Monopoles at Future Neutrino Detectors","summary":"We investigate the potential of future neutrino experiments, DUNE and\nHyper-Kamiokande, to probe magnetic monopoles via Callan-Rubakov (CR)\nprocesses. We consider both relativistic and non-relativistic monopoles and\nfocus on two primary detection signatures: high-energy antiproton production\nand proton decay catalysis. For relativistic monopoles, our analysis of the CR\nprocess indicates antiproton production with energies near 900 GeV and we find\nthat both experiments can provide limits on the fluxes an order of magnitude\nbelow the Parker bound (approximately $\\Phi \\lesssim\n10^{-16}\\,\\mathrm{cm^{-2}\\,s^{-1}\\,sr^{-1}}$). For non-relativistic monopoles,\nwe recast the experimental sensitivity to proton decay catalysis and obtain\nupper limits on the monopole flux of $\\Phi \\lesssim 2.3 \\times\n10^{-23}\\,\\mathrm{cm^{-2}\\,s^{-1}\\,sr^{-1}}$ for Hyper-Kamiokande and $\\Phi\n\\lesssim 1.1 \\times 10^{-22}\\,\\mathrm{cm^{-2}\\,s^{-1}\\,sr^{-1}}$ for DUNE.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T07:35:35Z"}
{"aid":"http://arxiv.org/abs/2504.14921v1","title":"Fast Adversarial Training with Weak-to-Strong Spatial-Temporal\n  Consistency in the Frequency Domain on Videos","summary":"Adversarial Training (AT) has been shown to significantly enhance adversarial\nrobustness via a min-max optimization approach. However, its effectiveness in\nvideo recognition tasks is hampered by two main challenges. First, fast\nadversarial training for video models remains largely unexplored, which\nseverely impedes its practical applications. Specifically, most video\nadversarial training methods are computationally costly, with long training\ntimes and high expenses. Second, existing methods struggle with the trade-off\nbetween clean accuracy and adversarial robustness. To address these challenges,\nwe introduce Video Fast Adversarial Training with Weak-to-Strong consistency\n(VFAT-WS), the first fast adversarial training method for video data.\nSpecifically, VFAT-WS incorporates the following key designs: First, it\nintegrates a straightforward yet effective temporal frequency augmentation\n(TF-AUG), and its spatial-temporal enhanced form STF-AUG, along with a\nsingle-step PGD attack to boost training efficiency and robustness. Second, it\ndevises a weak-to-strong spatial-temporal consistency regularization, which\nseamlessly integrates the simpler TF-AUG and the more complex STF-AUG.\nLeveraging the consistency regularization, it steers the learning process from\nsimple to complex augmentations. Both of them work together to achieve a better\ntrade-off between clean accuracy and robustness. Extensive experiments on\nUCF-101 and HMDB-51 with both CNN and Transformer-based models demonstrate that\nVFAT-WS achieves great improvements in adversarial robustness and corruption\nrobustness, while accelerating training by nearly 490%.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T07:40:35Z"}
{"aid":"http://arxiv.org/abs/2504.14935v1","title":"An elementary definition of opetopic sets","summary":"We propose elementary definitions of opetopes and opetopic sets. We directly\ndefine opetopic sets by a simple structure and several axioms. Opetopes are\nthen opetopic sets satisfying one more axiom. We show that our definition is\nequivalent to the polynomial monad definition given by Kock, Joyal, Batanin,\nand Mascari. We also show that our category of opetopes is equivalent to the\none given by Ho Thanh.","main_category":"math.CT","categories":"math.CT","published":"2025-04-21T07:56:23Z"}
{"aid":"http://arxiv.org/abs/2504.14950v1","title":"Thin-film periodically poled lithium niobate waveguides fabricated by\n  femtosecond laser photolithography","summary":"Periodically poled lithium niobate on insulator (PPLNOI) ridge waveguides are\ncritical photonic components for both classical and quantum information\nprocessing. However, dry etching of PPLNOI waveguides often generates rough\nsidewalls and variations in the etching rates of oppositely poled lithium\nniobate ferroelectric domains, leading a relatively high propagation losses\n(0.25 - 1 dB/cm), which significantly limits net conversion efficiency and\nhinders scalable photonic integration. In this work, a low-loss PPLNOI ridge\nwaveguide with a length of 7 mm was fabricated using ultra-smooth sidewalls\nthrough photolithography-assisted chemo-mechanical etching followed by\nhigh-voltage pulse poling. The average surface roughness was measured at just\n0.27 nm, resulting in significantly lower propagation loss compared to\ndry-etched counterparts. Highly efficient second-harmonic generation was\ndemonstrated with a normalized efficiency of 1742%/(W*cm^2) and an overall\nefficiency of 750.1%/W (without accounting for propagation loss). The absolute\nconversion efficiency reached 15.8%, representing a six-fold improvement over\nthe best previously reported values in single-period PPLNOI waveguides without\nmagnesium oxide doping.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-21T08:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.14954v1","title":"Transition temperature of a two-component Bose-Einstein condensates in\n  improved Hartree-Fock approximation","summary":"In this study, we investigate the transition temperature of a two-component\nBose-Einstein condensates by means of Cornwall-Jackiw-Tomboulis effective\naction formalism within the framework of the improved Hartree-Fock\napproximation. Influence of intra- and interspecies interactions as well as of\nthe thermal fluctuations to the transition temperature are considered up to\nleading order of the gas parameters and scattering lengths.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-21T08:26:45Z"}
{"aid":"http://arxiv.org/abs/2504.14956v1","title":"Considerations on the Design of Transceivers for Ambient Internet of\n  Things","summary":"The Ambient IoT (A-IoT) will introduce trillions of connections and enable\nlow-cost battery-less devices. The A-IoT nodes can achieve low cost ($\\sim \\$\n0.1$ like RFID tag), sub-1mW average power consumption, $\\leq 10$ kbps data\nrates, maintenance-free working for decades, cm-scale size, cm-scale size, and\nsupporting applications like supply chain and smart agriculture. The\ntransceiver challenges in A-IoT focus on sub-mW receivers and crystal-less\nclock generation. The paper proposes an \"approximate low-IF\" receiver and\n\"carrier-auxiliary IF feedback\" LO synthesizer architecture for Type-B/C A-IoT\ndevices, which tracks the RF carrier frequency and eliminates external\ncrystals. The proposed receiver and LO generator are implemented using 55nm\nCMOS technology. After locking the LO calibration loop, the receiver\nsensitivity is better than -88 dBm. The proposed receiver architecture will\npromote \"zero power\" devices for ubiquitous IoT connectivity, bridging digital\nand physical worlds.","main_category":"eess.SY","categories":"eess.SY,cs.AR,cs.SY","published":"2025-04-21T08:31:41Z"}
{"aid":"http://arxiv.org/abs/2504.14959v1","title":"ScaleGuard: Rational and Scalable Configuration Privacy Protection with\n  Topology Expansion","summary":"As networks grow in size and complexity, safeguarding sensitive data while\nsharing configuration files is critical for network management and research.\nExisting anonymization tools primarily hide fields like IP addresses or AS\nnumbers to mitigate direct data exposure. However, they often lack mechanisms\nto preserve privacy around network scale, an increasingly sensitive aspect that\ncan reveal organizational size or resource distribution. We propose ScaleGuard,\nwhich preserves network functional equivalence while adding fake routers and\nhosts to conceal network scale, and generating complete router configurations\nthat resemble the originals. Our system introduces a graph embedding-based\nexpansion method and k-degree mapping anonymity, reducing unnecessary topology\nmodifications when adversaries only know the original degree sequence. For\nrouting repair, ScaleGuard designs a network repair framework combining SMT and\niterative methods, delivering stable performance under randomized link costs\nand complex cross-protocol routing. Experiment results show that ScaleGuard\nexpands network scale effectively, providing consistent anonymization of\ntopology, scale, and routing, while achieving strong topological rationality,\nconfiguration fidelity, and repairing efficiency.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-21T08:38:52Z"}
{"aid":"http://arxiv.org/abs/2504.14966v1","title":"SLO-Aware Scheduling for Large Language Model Inferences","summary":"Large language models (LLMs) have revolutionized applications such as code\ncompletion, chatbots, and online classification. To elevate user experiences,\nservice level objectives (SLOs) serve as crucial benchmarks for assessing\ninference services capabilities. In practice, an inference service processes\nmultiple types of tasks, each with its own distinct SLO. To ensure satisfactory\nuser experiences, each request's distinct SLOs should be considered in\nscheduling. However, existing designs lack this consideration, leading to\ninsufficient hardware utility and suboptimal performance.\n  This paper analyzes scenarios to process tasks with varying SLOs, and\nintroduces a simulated annealing-based scheduler to decide request priority\nsequence based on a request's SLO, input lengths, and possible output lengths.\nAs the first specialized scheduler for multi-SLO scenarios, this work improves\nSLO attainment by up to 5x and reduces average latency by 31.6% on\nPython-Code-23k-ShareGPT and ShareGPT_Vicuna_unfiltered datasets, compared to\ncurrent state-of-the-art framework vLLM and a new framework LMDeploy.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-21T08:48:48Z"}
{"aid":"http://arxiv.org/abs/2504.14967v1","title":"3D Gaussian Head Avatars with Expressive Dynamic Appearances by Compact\n  Tensorial Representations","summary":"Recent studies have combined 3D Gaussian and 3D Morphable Models (3DMM) to\nconstruct high-quality 3D head avatars. In this line of research, existing\nmethods either fail to capture the dynamic textures or incur significant\noverhead in terms of runtime speed or storage space. To this end, we propose a\nnovel method that addresses all the aforementioned demands. In specific, we\nintroduce an expressive and compact representation that encodes texture-related\nattributes of the 3D Gaussians in the tensorial format. We store appearance of\nneutral expression in static tri-planes, and represents dynamic texture details\nfor different expressions using lightweight 1D feature lines, which are then\ndecoded into opacity offset relative to the neutral face. We further propose\nadaptive truncated opacity penalty and class-balanced sampling to improve\ngeneralization across different expressions. Experiments show this design\nenables accurate face dynamic details capturing while maintains real-time\nrendering and significantly reduces storage costs, thus broadening the\napplicability to more scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T08:50:12Z"}
{"aid":"http://arxiv.org/abs/2504.14969v1","title":"Evaluating LLMs on Chinese Topic Constructions: A Research Proposal\n  Inspired by Tian et al. (2024)","summary":"This paper proposes a framework for evaluating large language models (LLMs)\non Chinese topic constructions, focusing on their sensitivity to island\nconstraints. Drawing inspiration from Tian et al. (2024), we outline an\nexperimental design for testing LLMs' grammatical knowledge of Mandarin syntax.\nWhile no experiments have been conducted yet, this proposal aims to provide a\nfoundation for future studies and invites feedback on the methodology.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T08:56:23Z"}
{"aid":"http://arxiv.org/abs/2504.14982v1","title":"Understanding the Valence Quark Structure of the Pion through GTMDs","summary":"We investigate the internal structure of the pion using generalized\ntransverse momentum-dependent parton distributions (GTMDs) within the\nlight-cone quark model. By solving the quark-quark correlator, we derive the\ntwist-$2$, $3$, and $4$ quark GTMDs in terms of light-front wave functions\n(LFWFs). Out of the $16$ possible GTMDs, $12$ are found to be nonzero.\nFurthermore, we extract the valence quark transverse momentum-dependent parton\ndistributions (TMDs) and generalized parton distributions (GPDs) from their\ncorresponding GTMDs. Additionally, we compute the valence quark electromagnetic\nform factors (FFs) and parton distribution functions (PDFs) up to twist-$4$.\nThe elastic charge radius of the pion is determined to be $0.558$ fm. Our\nresults exhibit a qualitative agreement with predictions from other theoretical\nmodel like Nambu-Jona-Lasinio model, Light-front holographic model, and\nspectator model at the leading twist. This study provides a comprehensive\ninsight into the internal structure of the pion.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T09:19:15Z"}
{"aid":"http://arxiv.org/abs/2504.14984v1","title":"A New Formation Mechanism of Counterstreaming Mass Flows in Filaments\n  and the Doppler Bullseye Pattern in Prominences","summary":"The eruption of solar prominences can eject substantial mass and magnetic\nfield into interplanetary space and cause geomagnetic storms. However, various\nquestions about prominences and their eruption mechanism remain unclear. In\nparticular, what causes the intriguing Doppler bullseye pattern in prominences\nhas not yet been solved, despite some preliminary studies proposing that they\nare probably associated with counterstreaming mass flows. Previous studies are\nmainly based on single-angle and short timescale observations, making it\ndifficult to determine the physical origin of Doppler bullseye patterns in\nprominences. Here, taking advantage of stereoscopic observations taken by the\nSolar Dynamics Observatory and the Solar Terrestrial Relations Observatory and\na three-dimensional numerical simulation, we investigate the origin of\nprominence Doppler bullseye pattern by tracing a long-lived transequatorial\nfilament/prominence from July 23 to August 4, 2012. We find that repeated\ncoronal jets at one end of the prominence can launch the Doppler bullseye\npattern. It is evidenced in our observations and simulation that during the\nforward traveling of jet plasma along the helical magnetic field structure of\nthe prominence, part of the ejecting plasma can not pass through the apex of\nthe prominence due to the insufficient kinetic energy and therefore forms a\nbackward-moving mass flow along the same or neighboring magnetic field lines.\nThis process finally forms counterstreaming mass flows in on-disk filaments.\nWhen the on-disk filament rotates to the solar limb to be a prominence, the\ncounterstreaming mass flows are naturally observed as a Doppler bullseye\npattern.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T09:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.14994v1","title":"Learning Compositional Transferability of Time Series for Source-Free\n  Domain Adaptation","summary":"Domain adaptation is challenging for time series classification due to the\nhighly dynamic nature. This study tackles the most difficult subtask when both\ntarget labels and source data are inaccessible, namely, source-free domain\nadaptation. To reuse the classification backbone pre-trained on source data,\ntime series reconstruction is a sound solution that aligns target and source\ntime series by minimizing the reconstruction errors of both. However, simply\nfine-tuning the source pre-trained reconstruction model on target data may lose\nthe learnt priori, and it struggles to accommodate domain varying temporal\npatterns in a single encoder-decoder. Therefore, this paper tries to\ndisentangle the composition of domain transferability by using a compositional\narchitecture for time series reconstruction. Here, the preceding component is a\nU-net frozen since pre-trained, the output of which during adaptation is the\ninitial reconstruction of a given target time series, acting as a coarse step\nto prompt the subsequent finer adaptation. The following pipeline for finer\nadaptation includes two parallel branches: The source replay branch using a\nresidual link to preserve the output of U-net, and the offset compensation\nbranch that applies an additional autoencoder (AE) to further warp U-net's\noutput. By deploying a learnable factor on either branch to scale their\ncomposition in the final output of reconstruction, the data transferability is\ndisentangled and the learnt reconstructive capability from source data is\nretained. During inference, aside from the batch-level optimization in the\ntraining, we search at test time stability-aware rescaling of source replay\nbranch to tolerate instance-wise variation. The experimental results show that\nsuch compositional architecture of time series reconstruction leads to SOTA\nperformance on 3 widely used benchmarks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T09:51:24Z"}
{"aid":"http://arxiv.org/abs/2504.14995v1","title":"Trainable Quantum Neural Network for Multiclass Image Classification\n  with the Power of Pre-trained Tree Tensor Networks","summary":"Tree tensor networks (TTNs) offer powerful models for image classification.\nWhile these TTN image classifiers already show excellent performance on\nclassical hardware, embedding them into quantum neural networks (QNNs) may\nfurther improve the performance by leveraging quantum resources. However,\nembedding TTN classifiers into QNNs for multiclass classification remains\nchallenging. Key obstacles are the highorder gate operations required for large\nbond dimensions and the mid-circuit postselection with exponentially low\nsuccess rates necessary for the exact embedding. In this work, to address these\nchallenges, we propose forest tensor network (FTN)-classifiers, which aggregate\nmultiple small-bond-dimension TTNs. This allows us to handle multiclass\nclassification without requiring large gates in the embedded circuits. We then\nremove the overhead of mid-circuit postselection by extending the adiabatic\nencoding framework to our setting and smoothly encode the FTN-classifiers into\na quantum forest tensor network (qFTN)- classifiers. Numerical experiments on\nMNIST and CIFAR-10 demonstrate that we can successfully train FTN-classifiers\nand encode them into qFTN-classifiers, while maintaining or even improving the\nperformance of the pre-trained FTN-classifiers. These results suggest that\nsynergy between TTN classification models and QNNs can provide a robust and\nscalable framework for multiclass quantum-enhanced image classification.","main_category":"quant-ph","categories":"quant-ph,cs.AI,cs.LG","published":"2025-04-21T09:51:39Z"}
{"aid":"http://arxiv.org/abs/2504.15007v1","title":"Shifts in Doctors' Eye Movements Between Real and AI-Generated Medical\n  Images","summary":"Eye-tracking analysis plays a vital role in medical imaging, providing key\ninsights into how radiologists visually interpret and diagnose clinical cases.\nIn this work, we first analyze radiologists' attention and agreement by\nmeasuring the distribution of various eye-movement patterns, including saccades\ndirection, amplitude, and their joint distribution. These metrics help uncover\npatterns in attention allocation and diagnostic strategies. Furthermore, we\ninvestigate whether and how doctors' gaze behavior shifts when viewing\nauthentic (Real) versus deep-learning-generated (Fake) images. To achieve this,\nwe examine fixation bias maps, focusing on first, last, short, and longest\nfixations independently, along with detailed saccades patterns, to quantify\ndifferences in gaze distribution and visual saliency between authentic and\nsynthetic images.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-21T10:13:59Z"}
{"aid":"http://arxiv.org/abs/2504.15019v1","title":"Feedback Stackelberg-Nash equilibria in difference games with\n  quasi-hierarchical interactions and inequality constraints","summary":"In this paper, we study a class of two-player deterministic finite-horizon\ndifference games with coupled inequality constraints, where each player has two\ntypes of decision variables: one involving sequential interactions and the\nother simultaneous interactions. We refer to these as quasi-hierarchical\ndynamic games and define a solution concept called the feedback\nStackelberg-Nash (FSN) equilibrium. Under a separability assumption on cost\nfunctions, we formulate FSN solutions recursively using a dynamic\nprogramming-like approach. We further show that the FSN solution for these\nconstrained games can be derived from the parametric feedback Stackelberg\nsolution of an associated unconstrained game with only sequential interactions,\ngiven parameter choices that satisfy implicit complementarity conditions. For\nthe linear-quadratic case, we show that the FSN solutions are obtained by\nreformulating these complementarity conditions as a single large-scale linear\ncomplementarity problem. Finally, we illustrate our results with a dynamic\nduopoly game with production constraints.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-21T11:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.15025v1","title":"Quantum pseudoresources imply cryptography","summary":"While one-way functions (OWFs) serve as the minimal assumption for\ncomputational cryptography in the classical setting, in quantum cryptography,\nwe have even weaker cryptographic assumptions such as pseudo-random states, and\nEFI pairs, among others. Moreover, the minimal assumption for computational\nquantum cryptography remains an open question. Recently, it has been shown that\npseudoentanglement is necessary for the existence of quantum cryptography\n(Goul\\~ao and Elkouss 2024), but no cryptographic construction has been built\nfrom it.\n  In this work, we study the cryptographic usefulness of quantum\npseudoresources -- a pair of families of quantum states that exhibit a gap in\ntheir resource content yet remain computationally indistinguishable. We show\nthat quantum pseudoresources imply a variant of EFI pairs, which we call EPFI\npairs, and that these are equivalent to quantum commitments and thus EFI pairs.\nOur results suggest that, just as randomness is fundamental to classical\ncryptography, quantum resources may play a similarly crucial role in the\nquantum setting.\n  Finally, we focus on the specific case of entanglement, analyzing different\ndefinitions of pseudoentanglement and their implications for constructing EPFI\npairs. Moreover, we propose a new cryptographic functionality that is\nintrinsically dependent on entanglement as a resource.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-21T11:17:30Z"}
{"aid":"http://arxiv.org/abs/2504.15029v1","title":"Story of an architecturally suggestive polyhedron: from medieval trade\n  to Renaissance art and modern design","summary":"We describe a balance weight dated to the Early Islamic Period from the Hecht\nMuseum at the University of Haifa (Israel) Its polyhedral shape was attributed\nto a truncated elongated octagonal bipyramid. To our knowledge, the earliest\nRenaissance book containing the image of this polyhedron is \"La Pratica di\nProspettiva\" published in 1596 by Florentine architect and perspective artist\nLorenzo Sirigatti. We described an outline of Sirigatti life and the importance\nof his book for scientists and artists, Galileo Galilei among them. We depict\nexamples of lamps and lanterns in European cities shaped as the truncated\nelongated octagonal bipyramid, as well as a drawing by Raphael with a lantern\nof a similar form. Finally, we discussed why the artist chose this particular\npolyhedron for his drawing.","main_category":"math.HO","categories":"math.HO","published":"2025-04-21T11:33:41Z"}
{"aid":"http://arxiv.org/abs/2504.15032v1","title":"DyST-XL: Dynamic Layout Planning and Content Control for Compositional\n  Text-to-Video Generation","summary":"Compositional text-to-video generation, which requires synthesizing dynamic\nscenes with multiple interacting entities and precise spatial-temporal\nrelationships, remains a critical challenge for diffusion-based models.\nExisting methods struggle with layout discontinuity, entity identity drift, and\nimplausible interaction dynamics due to unconstrained cross-attention\nmechanisms and inadequate physics-aware reasoning. To address these\nlimitations, we propose DyST-XL, a \\textbf{training-free} framework that\nenhances off-the-shelf text-to-video models (e.g., CogVideoX-5B) through\nframe-aware control. DyST-XL integrates three key innovations: (1) A Dynamic\nLayout Planner that leverages large language models (LLMs) to parse input\nprompts into entity-attribute graphs and generates physics-aware keyframe\nlayouts, with intermediate frames interpolated via trajectory optimization; (2)\nA Dual-Prompt Controlled Attention Mechanism that enforces localized text-video\nalignment through frame-aware attention masking, achieving the precise control\nover individual entities; and (3) An Entity-Consistency Constraint strategy\nthat propagates first-frame feature embeddings to subsequent frames during\ndenoising, preserving object identity without manual annotation. Experiments\ndemonstrate that DyST-XL excels in compositional text-to-video generation,\nsignificantly improving performance on complex prompts and bridging a crucial\ngap in training-free video synthesis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T11:41:22Z"}
{"aid":"http://arxiv.org/abs/2504.15037v1","title":"A Call for New Recipes to Enhance Spatial Reasoning in MLLMs","summary":"Multimodal Large Language Models (MLLMs) have demonstrated impressive\nperformance in general vision-language tasks. However, recent studies have\nexposed critical limitations in their spatial reasoning capabilities. This\ndeficiency in spatial reasoning significantly constrains MLLMs' ability to\ninteract effectively with the physical world, thereby limiting their broader\napplications. We argue that spatial reasoning capabilities will not naturally\nemerge from merely scaling existing architectures and training methodologies.\nInstead, this challenge demands dedicated attention to fundamental\nmodifications in the current MLLM development approach. In this position paper,\nwe first establish a comprehensive framework for spatial reasoning within the\ncontext of MLLMs. We then elaborate on its pivotal role in real-world\napplications. Through systematic analysis, we examine how individual components\nof the current methodology-from training data to reasoning mechanisms-influence\nspatial reasoning capabilities. This examination reveals critical limitations\nwhile simultaneously identifying promising avenues for advancement. Our work\naims to direct the AI research community's attention toward these crucial yet\nunderexplored aspects. By highlighting these challenges and opportunities, we\nseek to catalyze progress toward achieving human-like spatial reasoning\ncapabilities in MLLMs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T11:48:39Z"}
{"aid":"http://arxiv.org/abs/2504.15054v1","title":"Structure-guided Diffusion Transformer for Low-Light Image Enhancement","summary":"While the diffusion transformer (DiT) has become a focal point of interest in\nrecent years, its application in low-light image enhancement remains a blank\narea for exploration. Current methods recover the details from low-light images\nwhile inevitably amplifying the noise in images, resulting in poor visual\nquality. In this paper, we firstly introduce DiT into the low-light enhancement\ntask and design a novel Structure-guided Diffusion Transformer based Low-light\nimage enhancement (SDTL) framework. We compress the feature through wavelet\ntransform to improve the inference efficiency of the model and capture the\nmulti-directional frequency band. Then we propose a Structure Enhancement\nModule (SEM) that uses structural prior to enhance the texture and leverages an\nadaptive fusion strategy to achieve more accurate enhancement effect. In\nAddition, we propose a Structure-guided Attention Block (SAB) to pay more\nattention to texture-riched tokens and avoid interference from noisy areas in\nnoise prediction. Extensive qualitative and quantitative experiments\ndemonstrate that our method achieves SOTA performance on several popular\ndatasets, validating the effectiveness of SDTL in improving image quality and\nthe potential of DiT in low-light enhancement tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T12:30:01Z"}
{"aid":"http://arxiv.org/abs/2504.15058v1","title":"One Dimensional Asymptotic Plateau Problem in $n$-Dimensional\n  Asymptotically Conical Manifolds","summary":"Let $(M,g)$ be an asymptotically conical Riemannian manifold having dimension\n$n\\ge 2$, opening angle $\\alpha \\in (0,\\pi/2) \\setminus \\{\\arcsin\n\\frac{1}{2k+1}\\}_{k \\in \\mathbb{N}}$ and positive asymptotic rate. Under the\nassumption that the exponential map is proper at each point, we give a solution\nto the one dimensional asymptotic Plateau problem on $M$. Precisely, for any\npair of antipodal points in the ideal boundary $\\partial_\\infty M = \\mathbb\nS^{n-1}$, we prove the existence of a geodesic line with asymptotic prescribed\nboundaries and the Morse index $\\le n-1$.","main_category":"math.DG","categories":"math.DG","published":"2025-04-21T12:36:07Z"}
{"aid":"http://arxiv.org/abs/2504.15062v1","title":"OPO: Making Decision-Focused Data Acquisition Decisions","summary":"We propose a model for making data acquisition decisions for variables in\ncontextual stochastic optimisation problems. Data acquisition decisions are\ntypically treated as separate and fixed. We explore problem settings in which\nthe acquisition of contextual variables is costly and consequently constrained.\nThe data acquisition problem is often solved heuristically for proxy objectives\nsuch as coverage. The more intuitive objective is the downstream decision\nquality as a result of data acquisition decisions. The whole pipeline can be\ncharacterised as an optimise-then-predict-then-optimise (OPO) problem.\nAnalogously, much recent research has focused on how to integrate prediction\nand optimisation (PO) in the form of decision-focused learning. We propose\nleveraging differentiable optimisation to extend the integration to data\nacquisition. We solve the data acquisition problem with well-defined\nconstraints by learning a surrogate linear objective function. We demonstrate\nan application of this model on a shortest path problem for which we first have\nto set a drone reconnaissance strategy to capture image segments serving as\ninputs to a model that predicts travel costs. We ablate the problem with a\nnumber of training modalities and demonstrate that the differentiable\noptimisation approach outperforms random search strategies.","main_category":"math.OC","categories":"math.OC,cs.AI","published":"2025-04-21T12:41:35Z"}
{"aid":"http://arxiv.org/abs/2504.15071v1","title":"Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling","summary":"We introduce an extensive new dataset of MIDI files, created by transcribing\naudio recordings of piano performances into their constituent notes. The data\npipeline we use is multi-stage, employing a language model to autonomously\ncrawl and score audio recordings from the internet based on their metadata,\nfollowed by a stage of pruning and segmentation using an audio classifier. The\nresulting dataset contains over one million distinct MIDI files, comprising\nroughly 100,000 hours of transcribed audio. We provide an in-depth analysis of\nour techniques, offering statistical insights, and investigate the content by\nextracting metadata tags, which we also provide. Dataset available at\nhttps://github.com/loubbrad/aria-midi.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-21T12:59:40Z"}
{"aid":"http://arxiv.org/abs/2504.15076v1","title":"Note on Type $III_1$ Algebras in $ c= 1$ String Theory and Bulk Causal\n  Diamonds","summary":"We argue that the Leutheusser-Liu procedure of isolating a von Neumann\nalgebra in the $N = \\infty$ limit of string theories, leads to the algebra of\nrelativistic fermion fields on a half line for the $c = 1$ string theory. This\nis a Type $I$ von Neumann algebra, since it is the algebra of the Rindler wedge\nin the Rindler vacuum state. Subalgebras of finite regions are Type $III_1$.\nThe argument uses the elegant results of Moore and of Alexandrov, Kazakov and\nKostov. This model is well known to be integrable and have no black hole\nexcitations. We have speculated that adding an interaction invisible in\nperturbation theory to a large finite number, $M$, of copies of the model,\nproduces a non-integrable model with meta-stable excitations having all of the\nproperties of linear dilaton black holes. The algebra of fields is the tensor\nproduct of $M$ copies of the $c = 1$ model's algebra, whether or not we add the\nnon-integrable interaction. We argue that the infinite dimensional $c = 1$\nalgebras are analogous to those of the boundary field theory in AdS/CFT, even\nthough they appear to encode bulk causal structure. An IR cutoff on the\nboundary renders them finite and causal structure must be formulated in terms\nof an analog of the Tensor Network Renormalization Group. This is a time\ndependent Hamiltonian flow, embedding smaller Hilbert spaces into larger ones.\nIt is the analog of one sided modular inclusion in quantum field theory.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-21T13:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.15080v1","title":"Empowering AI to Generate Better AI Code: Guided Generation of Deep\n  Learning Projects with LLMs","summary":"While large language models (LLMs) have been widely applied to code\ngeneration, they struggle with generating entire deep learning projects, which\nare characterized by complex structures, longer functions, and stronger\nreliance on domain knowledge than general-purpose code. An open-domain LLM\noften lacks coherent contextual guidance and domain expertise for specific\nprojects, making it challenging to produce complete code that fully meets user\nrequirements.\n  In this paper, we propose a novel planning-guided code generation method,\nDLCodeGen, tailored for generating deep learning projects. DLCodeGen predicts a\nstructured solution plan, offering global guidance for LLMs to generate the\nproject. The generated plan is then leveraged to retrieve semantically\nanalogous code samples and subsequently abstract a code template. To\neffectively integrate these multiple retrieval-augmented techniques, a\ncomparative learning mechanism is designed to generate the final code. We\nvalidate the effectiveness of our approach on a dataset we build for deep\nlearning code generation. Experimental results demonstrate that DLCodeGen\noutperforms other baselines, achieving improvements of 9.7% in CodeBLEU and\n3.6% in human evaluation metrics.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-21T13:09:25Z"}
{"aid":"http://arxiv.org/abs/2504.15098v1","title":"Optimal Behavior Planning for Implicit Communication using a\n  Probabilistic Vehicle-Pedestrian Interaction Model","summary":"In interactions between automated vehicles (AVs) and crossing pedestrians,\nmodeling implicit vehicle communication is crucial. In this work, we present a\ncombined prediction and planning approach that allows to consider the influence\nof the planned vehicle behavior on a pedestrian and predict a pedestrian's\nreaction. We plan the behavior by solving two consecutive optimal control\nproblems (OCPs) analytically, using variational calculus. We perform a\nvalidation step that assesses whether the planned vehicle behavior is adequate\nto trigger a certain pedestrian reaction, which accounts for the closed-loop\ncharacteristics of prediction and planning influencing each other. In this\nstep, we model the influence of the planned vehicle behavior on the pedestrian\nusing a probabilistic behavior acceptance model that returns an estimate for\nthe crossing probability. The probabilistic modeling of the pedestrian reaction\nfacilitates considering the pedestrian's costs, thereby improving cooperative\nbehavior planning. We demonstrate the performance of the proposed approach in\nsimulated vehicle-pedestrian interactions with varying initial settings and\nhighlight the decision making capabilities of the planning approach.","main_category":"cs.HC","categories":"cs.HC,cs.SY,eess.SY","published":"2025-04-21T13:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.15109v1","title":"New Heintze-Karcher type inequalities in sub-static warped product\n  manifolds","summary":"In this paper, we prove Heintze-Karcher type inequalities involving the\nshifted mean curvature for smooth bounded domains in certain sub-static warped\nproduct manifolds. In particular, we prove a Heintze-Karcher-type inequality\nfor non mean-convex domains in the hyperbolic space. As applications, we obtain\nuniqueness results for hypersurfaces satisfying a class of curvature equations.","main_category":"math.DG","categories":"math.DG","published":"2025-04-21T14:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.15112v1","title":"The phase diagram of CeRh$_{2}$As$_{2}$ for out-of-plane magnetic field","summary":"The heavy-fermion superconductor CeRh$_{2}$As$_{2}$ ($T_{\\textrm{c}} = 0.35\\,\n\\textrm{K}$) shows two superconducting (SC) phases, SC1 and SC2, when a\nmagnetic field is applied parallel to the $c$ axis of the tetragonal unit cell.\nAll experiments to date indicate that the change in SC order parameter detected\nat $\\mu_{\\textrm{0}}H^{*} \\approx 4\\, \\textrm{T}$ is due to strong Rashba\nspin-orbit coupling at the Ce sites caused by the locally non-centrosymmetric\nenvironments of the otherwise globally centrosymmetric crystalline structure.\nAnother phase (phase I) exists in this material below $T_{\\textrm{0}} = 0.54\\,\n\\textrm{K}$. In a previous specific heat study [K. Semeniuk et al. Phys. Rev.\nB, $107$, L220504 (2023)] we have shown that phase I persists up to a field\n$\\mu_{\\textrm{0}}H_{0} \\approx 6\\, \\textrm{T}$, larger than $H^{*}$. From\nthermodynamic arguments we expected the phase-I boundary line to cross phase\nSC2 at a tetracritical point. However, we could not find any signature of the\nphase-I line inside the SC2 phase and speculated that this was due to the fact\nthat the $T_{0}(H)$ line is almost perpendicular to the $H$ axis and,\ntherefore, invisible to $T$-dependent measurements. This would imply a weak\ncompetition between the two order parameters. Here, we report magnetic field\ndependent measurements of the magnetostriction and ac-susceptibility on\nhigh-quality single crystals. We see clear evidence of the singularity at\n$H_{0}$ inside the SC2 phase and confirm our previous prediction. Furthermore,\nwe observe the transition across the $T^{*}(H)$ line in $T$-dependent specific\nheat measurements, which show that the $T^{*}(H)$ line is not perpendicular to\nthe field axis, but has a positive slope. Our work supports recent $\\mu$SR\nresults which suggest coexistence of phase I with superconductivity.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-21T14:05:57Z"}
{"aid":"http://arxiv.org/abs/2504.15123v1","title":"Squeezing Effect in the Gouy Phase of Matter Waves","summary":"We investigate the Gouy phase emerging from the time evolution of confined\nmatter waves in a harmonic potential. Specifically, we analyze the quantum\ndynamics of a Gaussian wavepacket that exhibits position--momentum\ncorrelations. By tuning the parameters governing its evolution, we reveal\nintriguing effects, with a particular focus on squeezing. Notably, during the\nwavepacket evolution quantum spreading and squeezing processes emerge, giving\nrise to Gouy phase contributions of $\\pi/4$ rad, establishing a clear link\nbetween the Gouy phase and a purely quantum phenomenon. Furthermore, the\ninterplay between wavepacket squeezing and one-dimensional spreading leads to a\ntotal Gouy phase accumulation of $\\pi/2$ rad in an oscillation period. Both\nsqueezing and Gouy phase have individually proven valuable in state engineering\nand quantum metrology. By demonstrating a direct, controllable relationship\nbetween these two fundamental processes, our findings expand the realm of\nquantum-enhanced technologies, including quantum sensing and precision\nmeasurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T14:19:36Z"}
{"aid":"http://arxiv.org/abs/2504.15124v1","title":"Bubble-assisted micromixing via thermally excited intrinsic air within\n  microfluidic systems","summary":"The micromixing process in microfluidic devices is of central importance in\nquite a few applications, with microfluidic studies on carbon capture and\nenvironmental monitoring being two examples. High surface area to volume ratio\nin microscale flows outweighs the role of interfacial tension manipulation by\nmeans of introducing a secondary phase to the main flow in order to augment the\ntypically diffusion-dominant mass transfer operation. In this paper, we\nintroduce an easily integrable continuous flow micromixing scheme implemented\non a simple Y-type microchannel based on thermally excited intrinsic air within\nmicrochannel. Thanks to the direct contact between the sputtered thin platinum\nmicroheater and the co-flowing streams, trapped air in the liquid and/or tiny\ncrevices is employed to generate elongated bubbles with a millisecond lifespan,\nconsuming less than 0.4 W of power and thereby enabling homogeneous mixing. The\nperformance of the micromixer is characterized in terms of the mixing index\n(MI), and it is shown that immediately ahead of the microheater, the MI exceeds\n95% for side-by-side flowing of water at different overall flowrates, namely 4,\n10, and 20 uL/min. Interpreting the experimental results, supplemented by\nscaling arguments, we quantitatively describe the ephemeral role of emerging\nelongated bubbles in the micromixing process in which the Marangoni as well as\nWeber numbers are recognized as the characteristic local non-dimensional groups\nwhile the enhancing role of tiny daughter microbubbles on the micromixing\ndownstream of the microchannel can be reflected in the Peclet and the Capillary\nnumbers.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.soft","published":"2025-04-21T14:20:17Z"}
{"aid":"http://arxiv.org/abs/2504.15132v1","title":"Investigating Youth's Technical and Ethical Understanding of Generative\n  Language Models When Engaging in Construction and Deconstruction Activities","summary":"The widespread adoption of generative artificial intelligence/machine\nlearning (AI/ML) technologies has increased the need to support youth in\ndeveloping AI/ML literacies. However, most work has centered on preparing young\npeople to use these systems, with less attention to how they can participate in\ndesigning and evaluating them. This study investigates how engaging young\npeople in the design and auditing of generative language models (GLMs) may\nfoster the development of their understanding of how these systems work from\nboth technical and ethical perspectives. The study takes an in-pieces approach\nto investigate novices' conceptions of GLMs. Such an approach supports the\nanalysis of how technical and ethical conceptions evolve and relate to each\nother. I am currently conducting a series of participatory design workshops\nwith sixteen ninth graders (ages 14-15) in which they will (a) build GLMs from\na data-driven perspective that glassboxes how data shapes model performance and\n(b) audit commercial GLMs by repeatedly and systematically querying them to\ndraw inferences about their behaviors. I will analyze participants'\ninteractions to identify ethical and technical conceptions they may exhibit\nwhile designing and auditing GLMs. I will also conduct clinical interviews and\nuse microgenetic knowledge analysis and ordered network analysis to investigate\nhow participants' ethical and technical conceptions of GLMs relate to each\nother and change after the workshop. The study will contribute (a) evidence of\nhow engaging youth in design and auditing activities may support the\ndevelopment of ethical and technical understanding of GLMs and (b) an inventory\nof novice design and auditing practices that may support youth's technical and\nethical understanding of GLMs.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-21T14:30:16Z"}
{"aid":"http://arxiv.org/abs/2504.15140v1","title":"Evidence of Donor Bias in Chicago Police Stops","summary":"This study provides the first empirical evidence that private donations to\npolice departments can influence officer behavior. Drawing on the psychology of\nreciprocity bias, we theorize that public donations create social debts that\nshape discretionary enforcement. Using quasi-experimental data from Chicago, we\nfind that after 7-Eleven sponsored a police foundation gala, investigatory\nstops, particularly of Black pedestrians, increased around its stores. These\nfindings reveal a racialized pattern of donor bias in policing and call into\nquestion the consequences of private donations to public law enforcement.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC,stat.AP","published":"2025-04-21T14:44:44Z"}
{"aid":"http://arxiv.org/abs/2504.15146v1","title":"Behavioral Universe Network (BUN): A Behavioral Information-Based\n  Framework for Complex Systems","summary":"Modern digital ecosystems feature complex, dynamic interactions among\nautonomous entities across diverse domains. Traditional models often separate\nagents and objects, lacking a unified foundation to capture their interactive\nbehaviors. This paper introduces the Behavioral Universe Network (BUN), a\ntheoretical framework grounded in the Agent-Interaction-Behavior (AIB)\nformalism. BUN treats subjects (active agents), objects (resources), and\nbehaviors (operations) as first-class entities, all governed by a shared\nBehavioral Information Base (BIB). We detail the AIB core concepts and\ndemonstrate how BUN leverages information-driven triggers, semantic enrichment,\nand adaptive rules to coordinate multi-agent systems. We highlight key\nbenefits: enhanced behavior analysis, strong adaptability, and cross-domain\ninteroperability. We conclude by positioning BUN as a promising foundation for\nnext-generation digital governance and intelligent applications.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T14:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.15152v1","title":"Landmark-Free Preoperative-to-Intraoperative Registration in\n  Laparoscopic Liver Resection","summary":"Liver registration by overlaying preoperative 3D models onto intraoperative\n2D frames can assist surgeons in perceiving the spatial anatomy of the liver\nclearly for a higher surgical success rate. Existing registration methods rely\nheavily on anatomical landmark-based workflows, which encounter two major\nlimitations: 1) ambiguous landmark definitions fail to provide efficient\nmarkers for registration; 2) insufficient integration of intraoperative liver\nvisual information in shape deformation modeling. To address these challenges,\nin this paper, we propose a landmark-free preoperative-to-intraoperative\nregistration framework utilizing effective self-supervised learning, termed\n\\ourmodel. This framework transforms the conventional 3D-2D workflow into a\n3D-3D registration pipeline, which is then decoupled into rigid and non-rigid\nregistration subtasks. \\ourmodel~first introduces a feature-disentangled\ntransformer to learn robust correspondences for recovering rigid\ntransformations. Further, a structure-regularized deformation network is\ndesigned to adjust the preoperative model to align with the intraoperative\nliver surface. This network captures structural correlations through geometry\nsimilarity modeling in a low-rank transformer network. To facilitate the\nvalidation of the registration performance, we also construct an in-vivo\nregistration dataset containing liver resection videos of 21 patients, called\n\\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the\nliver together with liver mask annotations and calibrated camera intrinsic\nparameters. Extensive experiments and user studies on both synthetic and\nin-vivo datasets demonstrate the superiority and potential clinical\napplicability of our method.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T14:55:57Z"}
{"aid":"http://arxiv.org/abs/2504.15157v1","title":"Reconfiguring Proportional Committees","summary":"An important desideratum in approval-based multiwinner voting is\nproportionality. We study the problem of reconfiguring proportional committees:\ngiven two proportional committees, is there a transition path that consists\nonly of proportional committees, where each transition involves replacing one\ncandidate with another candidate? We show that the set of committees satisfying\nthe proportionality axiom of justified representation (JR) is not always\nconnected, and it is PSPACE-complete to decide whether two such committees are\nconnected. On the other hand, we prove that any two JR committees can be\nconnected by committees satisfying a $2$-approximation of JR. We also obtain\nsimilar results for the stronger axiom of extended justified representation\n(EJR). In addition, we demonstrate that the committees produced by several\nwell-known voting rules are connected or at least not isolated, and investigate\nthe reconfiguration problem in restricted preference domains.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-21T15:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.15158v1","title":"Interacting Copies of Random Constraint Satisfaction Problems","summary":"We study a system of $y=2$ coupled copies of a well-known constraint\nsatisfaction problem (random hypergraph bicoloring) to examine how the\nferromagnetic coupling between the copies affects the properties of the\nsolution space. We solve the replicated model by applying the cavity method to\nthe supervariables taking $2^y$ values. Our results show that a coupling of\nstrength $\\gamma$ between the copies decreases the clustering threshold\n$\\alpha_d(\\gamma)$, at which typical solutions shatters into disconnected\ncomponents, therefore preventing numerical methods such as Monte Carlo Markov\nChains from reaching equilibrium in polynomial time. This result needs to be\nreconciled with the observation that, in models with coupled copies, denser\nregions of the solution space should be more accessible. Additionally, we\nobserve a change in the nature of the clustering phase transition, from\ndiscontinuous to continuous, in a wide $\\gamma$ range. We investigate how the\ncoupling affects the behavior of the Belief Propagation (BP) algorithm on\nfinite-size instances and find that BP convergence is significantly impacted by\nthe continuous transition. These results highlight the importance of better\nunderstanding algorithmic performance at the clustering transition, and call\nfor a further exploration into the optimal use of re-weighting strategies\ndesigned to enhance algorithmic performances.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-21T15:05:18Z"}
{"aid":"http://arxiv.org/abs/2504.15167v1","title":"Almost-perfect colorful matchings in three-edge-colored bipartite graphs","summary":"We prove that, for positive integers $n,a_1, a_2, a_3$ satisfying\n$a_1+a_2+a_3 = n-1$, it holds that any bipartite graph $G$ which is the union\nof three perfect matchings $M_1$, $M_2$, and $M_3$ on $2n$ vertices contains a\nmatching $M$ such that $|M\\cap M_i| =a_i$ for $i= 1,2,$ and $3$. The bound\n$n-1$ on the sum is best possible in general. Our result verifies the\nmultiplicity extension of the Ryser-Brualdi-Stein Conjecture, proposed recently\nby Anastos, Fabian, M\\\"uyesser, and Szab\\'o, for three colors.","main_category":"math.CO","categories":"math.CO","published":"2025-04-21T15:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.15168v1","title":"On true empty category","summary":"According to Chomsky (1981, 1986), empty categories consist of PRO, pro,\ntrace, and variable. However, some empty object positions seem to be\nincompatible with extant empty categories. Given this, Li (2007a, 2007b, 2014)\nand Li & Wei (2014) raise the true empty category hypothesis, which holds that\ntrue empty category is only an empty position with category and Case features.\nAs a last resort option, it is used mainly to meet the subcatgorization of a\nverb. This assumption is ingenious, and if proved to be true, it will exert a\ngreat impact on the study of UG. In this paper, we evaluate their evidence from\ntopicalization and demonstrate that it can be accounted for without invoking\ntrue empty category.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T15:22:21Z"}
{"aid":"http://arxiv.org/abs/2504.15191v1","title":"Aerodynamic Control of Laminar Separation on a Wall-Bounded Airfoil at\n  Transitional Reynolds Numbers","summary":"Experiments were conducted in a low-turbulence wind tunnel to investigate the\nefficacy of localised acoustic forcing upon the dynamics and stability of the\nflow on a cambered, wall-bounded airfoil over a range of Reynolds numbers (Re)\nwhere the flow state can switch between two limits -- a low-lift state (SI)\nwhere separation continues beyond the trailing edge and a high-lift state (SII)\nwhere the separated flow is closed off to form a laminar separation bubble. The\nswitching between SI and SII can occur close to a critical angle of attack\n($\\alpha_{\\textrm{crit}}$) which varies with $\\textrm{Re}$. The most effective\nforcing frequencies are found at a constant value of a rescaled Strouhal\nnumber, $\\textrm{St}^* = \\textrm{St}/\\textrm{Re}^{1/2}= 0.027$, which indicates\nthat though the primary unstable modes of the separated shear layer are of the\ninviscid, Kelvin-Helmholtz type, these modes are seeded by length scales that\noriginate in the laminar (viscous) boundary layer. The most effective chordwise\nforcing location varies with $\\textrm{St}/\\textrm{Re}^{1/2}$ and incidence\nangle, $\\alpha$, and is always upstream of the separation point. Although the\nboundary layer flows are far from two-dimensional, forcing at a fixed chord\nlocation across all spanwise locations is effective in controlling the SI --\nSII transition. Strategies for active and passive feedback control are\nsuggested.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-21T16:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.15195v1","title":"Arc K-semistability is a very general property","summary":"We prove that arc K-semistability is a very general property in flat families\nof polarised varieties, and prove a similar result for uniform arc K-stability.\nThis can be used to produce the only current examples of smooth uniformly arc\nK-stable varieties which are not known to admit a constant scalar curvature\nK\\\"ahler metric. Our technique is to prove a general result stating that\nsemistability of a pair in the sense of Paul is a Zariski open property, and to\nemploy prior work with Reboulet relating arc K-semistability to semistability\nof an associated pair.","main_category":"math.AG","categories":"math.AG,math.DG","published":"2025-04-21T16:07:21Z"}
{"aid":"http://arxiv.org/abs/2504.15206v1","title":"How Global Calibration Strengthens Multiaccuracy","summary":"Multiaccuracy and multicalibration are multigroup fairness notions for\nprediction that have found numerous applications in learning and computational\ncomplexity. They can be achieved from a single learning primitive: weak\nagnostic learning. Here we investigate the power of multiaccuracy as a learning\nprimitive, both with and without the additional assumption of calibration. We\nfind that multiaccuracy in itself is rather weak, but that the addition of\nglobal calibration (this notion is called calibrated multiaccuracy) boosts its\npower substantially, enough to recover implications that were previously known\nonly assuming the stronger notion of multicalibration.\n  We give evidence that multiaccuracy might not be as powerful as standard weak\nagnostic learning, by showing that there is no way to post-process a\nmultiaccurate predictor to get a weak learner, even assuming the best\nhypothesis has correlation $1/2$. Rather, we show that it yields a restricted\nform of weak agnostic learning, which requires some concept in the class to\nhave correlation greater than $1/2$ with the labels. However, by also requiring\nthe predictor to be calibrated, we recover not just weak, but strong agnostic\nlearning.\n  A similar picture emerges when we consider the derivation of hardcore\nmeasures from predictors satisfying multigroup fairness notions. On the one\nhand, while multiaccuracy only yields hardcore measures of density half the\noptimal, we show that (a weighted version of) calibrated multiaccuracy achieves\noptimal density.\n  Our results yield new insights into the complementary roles played by\nmultiaccuracy and calibration in each setting. They shed light on why\nmultiaccuracy and global calibration, although not particularly powerful by\nthemselves, together yield considerably stronger notions.","main_category":"cs.LG","categories":"cs.LG,cs.CC","published":"2025-04-21T16:22:44Z"}
{"aid":"http://arxiv.org/abs/2504.15211v1","title":"Position: Bayesian Statistics Facilitates Stakeholder Participation in\n  Evaluation of Generative AI","summary":"The evaluation of Generative AI (GenAI) systems plays a critical role in\npublic policy and decision-making, yet existing methods are often limited by\nreliance on benchmark-driven, point-estimate comparisons that fail to capture\nuncertainty and broader societal impacts. This paper argues for the use of\nBayesian statistics as a principled framework to address these challenges.\nBayesian methods enable the integration of domain expertise through prior\nelicitation, allow for continuous learning from new data, and provide robust\nuncertainty quantification via posterior inference. We demonstrate how Bayesian\ninference can be applied to GenAI evaluation, particularly in incorporating\nstakeholder perspectives to enhance fairness, transparency, and reliability.\nFurthermore, we discuss Bayesian workflows as an iterative process for model\nvalidation and refinement, ensuring robust assessments of GenAI systems in\ndynamic, real-world contexts.","main_category":"cs.AI","categories":"cs.AI,stat.AP","published":"2025-04-21T16:31:15Z"}
{"aid":"http://arxiv.org/abs/2504.15212v1","title":"A universal threshold for geometric embeddings of trees","summary":"A graph $G=(V,E)$ is geometrically embeddable into a normed space $X$ when\nthere is a mapping $\\zeta: V\\to X$ such that $\\|\\zeta(v)-\\zeta(w)\\|_X\\leqslant\n1$ if and only if $\\{v,w\\}\\in E$, for all distinct $v,w\\in V$. Our result is\nthe following universal threshold for the embeddability of trees. Let $\\Delta\n\\geqslant 3$, and let $N$ be sufficiently large in terms of $\\Delta$. Every\n$N$--vertex tree of maximal degree at most $\\Delta$ is embeddable into any\nnormed space of dimension at least $64\\,\\frac{\\log N}{\\log\\log N}$, and\ncomplete trees are non-embeddable into any normed space of dimension less than\n$\\frac{1}{2}\\,\\frac{\\log N}{\\log\\log N}$. In striking contrast, spectral\nexpanders and random graphs are known to be non-embeddable in sublogarithmic\ndimension. Our result is based on a randomized embedding whose analysis\nutilizes the recent breakthroughs on Bourgain's slicing problem.","main_category":"math.CO","categories":"math.CO,math.FA,math.MG,math.PR","published":"2025-04-21T16:33:18Z"}
{"aid":"http://arxiv.org/abs/2504.15213v1","title":"Community detection in hypergraphs through hyperedge percolation","summary":"Complex networks, representing the connections between the constituents of\nlarge complex systems, are often characterised by a community structure, with\ncommunities corresponding to denser sub-graphs in which nodes are closely\nlinked. When modelling systems where interactions extend beyond node pairs to\ninvolve arbitrary numbers of nodes, hypergraphs become necessary, creating a\nneed for specialised community detection methods. Here, we adapt the classical\n$k$-clique percolation method to hypergraphs, building communities from\nhyperedges containing at least $k$ nodes, defining hyperedge adjacency\nsimilarly to clique adjacency in the original algorithm. Although the analogy\nbetween the proposed hyperedge percolation method and the classical clique\npercolation algorithm is evident, we show that communities obtained directly\nfrom the hyperedges can differ from those identified by the clique percolation\nmethod in the pairwise projection of the hypergraph. We also propose an\nalternative way for uniting hyperedges into communities, where instead of\nlimiting the cardinality of the considered hyperedges from below, we restrict\nthe size of the largest hyperedges that can be added to a community. This\nalternative algorithm is better suited to hypergraphs where larger edges\nrealise weaker linkages between the nodes. After comparing the suggested two\napproaches on simple synthetic hypergraphs constructed to highlight their\ndifferences, we test them on hypergraphs generated with a newly proposed\ngeometric process on the hyperbolic plane, as well as on some real-world\nexamples.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-21T16:35:24Z"}
{"aid":"http://arxiv.org/abs/2504.15234v1","title":"Equivariant quasisymmetry and noncrossing partitions","summary":"We introduce a definition of ``equivariant quasisymmetry'' for polynomials in\ntwo sets of variables. Using this definition we define quasisymmetric\ngeneralizations of the theory of double Schur and double Schubert polynomials\nthat we call double fundamental polynomials and double forest polynomials,\nwhere the subset of ``noncrossing partitions'' plays the role of $S_n$. In\nsubsequent work we will show this combinatorics is governed by a new geometric\nconstruction we call the ``quasisymmetric flag variety'' which plays the same\nrole for equivariant quasisymmetry as the usual flag variety plays in the\nclassical story.","main_category":"math.CO","categories":"math.CO,math.AG","published":"2025-04-21T17:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.15242v1","title":"Modified Kantorovich-type Sampling Series in Orlicz Space Frameworks","summary":"This study examines a modified Kantorovich approach applied to generalized\nsampling series. The paper establishes that the approximation order to a\nfunction using these modified operators is atleast as good as that achieved by\nclassical methods by using some graphs. The analysis focuses on these series\nwithin the context of Orlicz space \\( L^{\\eta}(\\mathbb{R}) \\), specifically\nlooking at irregularly spaced samples. This is crucial for real-world\napplications, especially in fields like signal processing and computational\nmathematics, where samples are often not uniformly spaced. The paper also\nestablishes a result on modular convergence for functions \\( g \\in\nL^{\\eta}(\\mathbb{R}) \\), which includes specific cases like convergence in \\(\nL^{p}(\\mathbb{R}) \\)-spaces, \\( L \\log L \\)-spaces, and exponential spaces. The\nstudy then explores practical applications of the modified sampling series,\nnotably for discontinuous functions and provides graphs to illustrate the\nresults.","main_category":"math.FA","categories":"math.FA","published":"2025-04-21T17:15:44Z"}
{"aid":"http://arxiv.org/abs/2504.15243v1","title":"Single-loop Algorithms for Stochastic Non-convex Optimization with\n  Weakly-Convex Constraints","summary":"Constrained optimization with multiple functional inequality constraints has\nsignificant applications in machine learning. This paper examines a crucial\nsubset of such problems where both the objective and constraint functions are\nweakly convex. Existing methods often face limitations, including slow\nconvergence rates or reliance on double-loop algorithmic designs. To overcome\nthese challenges, we introduce a novel single-loop penalty-based stochastic\nalgorithm. Following the classical exact penalty method, our approach employs a\n{\\bf hinge-based penalty}, which permits the use of a constant penalty\nparameter, enabling us to achieve a {\\bf state-of-the-art complexity} for\nfinding an approximate Karush-Kuhn-Tucker (KKT) solution. We further extend our\nalgorithm to address finite-sum coupled compositional objectives, which are\nprevalent in artificial intelligence applications, establishing improved\ncomplexity over existing approaches. Finally, we validate our method through\nexperiments on fair learning with receiver operating characteristic (ROC)\nfairness constraints and continual learning with non-forgetting constraints.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-21T17:15:48Z"}
{"aid":"http://arxiv.org/abs/2504.15264v1","title":"Sunflowers and Ramsey problems for restricted intersections","summary":"Extremal problems on set systems with restricted intersections have been an\nimportant part of combinatorics in the last 70 year. In this paper, we study\nthe following Ramsey version of these problems. Given a set $L\\subseteq\n\\{0,\\dots,k-1\\}$ and a family $\\mathcal{F}$ of $k$-element sets which does not\ncontain a sunflower with $m$ petals whose kernel size is in $L$, how large a\nsubfamily of $\\mathcal{F}$ can we find in which no pair has intersection size\nin $L$? We give matching upper and lower bounds, determining the dependence on\n$m$ for all $k$ and $L$. This problem also finds applications in quantum\ncomputing.\n  As an application of our techniques, we also obtain a variant of F\\\"uredi's\ncelebrated semilattice lemma, which is a key tool in the powerful delta-system\nmethod. We prove that one cannot remove the double-exponential dependency on\nthe uniformity in F\\\"uredi's result, however, we provide an alternative with\nsignificantly better, single-exponential dependency on the parameters, which is\nstill strong enough for most applications of the delta-system method.","main_category":"math.CO","categories":"math.CO,cs.DM,quant-ph","published":"2025-04-21T17:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.15274v1","title":"Is Dynamical Dark Energy Necessary? DESI BAO and Modified Recombination","summary":"Recent measurements of baryon acoustic oscillations (BAO) by the Dark Energy\nSpectroscopic Instrument (DESI) exhibit a mild-to-moderate tension with cosmic\nmicrowave background (CMB) and Type Ia supernova (SN) observations when\ninterpreted within a flat $\\Lambda$CDM framework. This discrepancy has been\ncited as evidence for dynamical dark energy (DDE). Given the profound\nimplications of DDE for fundamental physics, we explore whether the tension can\ninstead be resolved by modifying the physics of recombination. We find that a\nphenomenological model of modified recombination can effectively reconcile the\nBAO and CMB datasets and, unlike DDE, also predicts a higher Hubble constant\n$H_0$, thereby partially alleviating the Hubble tension. A global fit to BAO,\nCMB, and calibrated SN data clearly favors modified recombination over DDE,\nsuggesting that current claims of a DDE detection may be premature.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T17:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.15275v1","title":"Stop Summation: Min-Form Credit Assignment Is All Process Reward Model\n  Needs for Reasoning","summary":"Process reward models (PRMs) have proven effective for test-time scaling of\nLarge Language Models (LLMs) on challenging reasoning tasks. However, reward\nhacking issues with PRMs limit their successful application in reinforcement\nfine-tuning. In this paper, we identify the main cause of PRM-induced reward\nhacking: the canonical summation-form credit assignment in reinforcement\nlearning (RL), which defines the value as cumulative gamma-decayed future\nrewards, easily induces LLMs to hack steps with high rewards. To address this,\nwe propose PURE: Process sUpervised Reinforcement lEarning. The key innovation\nof PURE is a min-form credit assignment that formulates the value function as\nthe minimum of future rewards. This method significantly alleviates reward\nhacking by limiting the value function range and distributing advantages more\nreasonably. Through extensive experiments on 3 base models, we show that\nPRM-based approaches enabling min-form credit assignment achieve comparable\nreasoning performance to verifiable reward-based methods within only 30% steps.\nIn contrast, the canonical sum-form credit assignment collapses training even\nat the beginning! Additionally, when we supplement PRM-based fine-tuning with\njust 10% verifiable rewards, we further alleviate reward hacking and produce\nthe best fine-tuned model based on Qwen2.5-Math-7B in our experiments,\nachieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5\nbenchmarks. Moreover, we summarize the observed reward hacking cases and\nanalyze the causes of training collapse. Code and models are available at\nhttps://github.com/CJReinforce/PURE.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-21T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.15569v1","title":"Centers of perfectoid purity","summary":"We introduce a mixed characteristic analog of log canonical centers in\ncharacteristic $0$ and centers of $F$-purity in positive characteristic, which\nwe call centers of perfectoid purity. We show that their existence detects (the\nfailure of) normality of the ring. We also show the existence of a special\ncenter of perfectoid purity that detects the perfectoid purity of $R$,\nanalogously to the splitting prime of Aberbach and Enescu, and investigate its\nbehavior under \\'etale morphisms.","main_category":"math.AG","categories":"math.AG,math.AC","published":"2025-04-22T03:55:38Z"}
{"aid":"http://arxiv.org/abs/2504.15570v1","title":"Hypertrees and their host trees: a survey","summary":"A hypergraph $\\mathcal{H}=(V,\\mathcal{E})$ is a hypertree if it admits a tree\n$T$ with vertex set $V$ such that every edge of $\\mathcal{H}$ induces a subtree\nof $T$. A tree like that is called a host tree. Several characterizations and\nproperties of hypertrees have been discovered over the years. However, the\ninterest in the structure of their host trees was weaker and restricted to\nparticular scenarios where they arise, like the clique tree of chordal graphs.\nIn that special case, the proofs of most characteristics of clique trees that\nexist in the literature rely significantly on the structural properties of\nchordal graphs. The purpose of this work is the study of the properties of the\nhost trees of hypertrees in a more general context and have them described in a\nsingle place, giving simpler proofs for known facts, generalizing others and\nintroducing some new concepts that the author considers that are relevant for\nthe study of the topic. Particularly, we will determine what edges can be found\nin some host tree of a hypertree, and how these edges must be combined to form\na host tree, with an emphasis in tools like the basis and the completion of a\nhypergraph, and the concept of equivalent hypergraphs.","main_category":"math.CO","categories":"math.CO,G.2.2","published":"2025-04-22T03:56:15Z"}
{"aid":"http://arxiv.org/abs/2504.15579v1","title":"A characterization of closed subfunctors through $3\\times 3$-lemma\n  property in extriangulated categories","summary":"Given an extriangulated category $(\\mathcal{C},\\mathbb{E},\\mathfrak{s})$, we\nintroduce the $3 \\times 3$-lemma property for subfunctors of $\\mathbb{E}$ and\nprove that an additive subfunctor $\\mathbb{F}$ of $\\mathbb{E}$ is closed if,\nand only if, it satisfies this condition. This characterization extends a well\nknown result by A. Buan (for abelian categories) to extriangulated categories.\nAs an application of this result, we get a new equivalent condition to describe\nsaturated proper classes $\\xi$ in $\\mathcal{C}$.","main_category":"math.CT","categories":"math.CT,math.RT","published":"2025-04-22T04:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.15589v1","title":"Validation of 3GPP TR 38.901 Indoor Hotspot Path Loss Model Based on\n  Measurements Conducted at 6.75, 16.95, 28, and 73 GHz for 6G and Beyond","summary":"This paper presents a thorough validation of the Third Generation Partnership\nProject (3GPP) Technical Report (TR) 38.901 indoor hotspot (InH) path loss\nmodel, as part of the 3GPP Release 19 study on \"Channel model validation of TR\n38.901 for 7-24 GHz,\" for 6G standardization. Specifically, we validate the\n3GPP TR 38.901 path loss model for the InH scenario in both line of sight (LOS)\nand non line of sight (NLOS) channel conditions, using the floating intercept\n(FI) and alpha-beta-gamma (ABG) path loss models. The validation focuses on\nspecific frequencies, including 6.75 GHz and 16.95 GHz, as well as the broader\n7-24 GHz and 0.5-100 GHz frequency ranges. The validation is based on\nreal-world measurements conducted at 6.75 GHz, 16.95 GHz, 28 GHz, and 73 GHz by\nNYU WIRELESS using a 1 GHz wideband time domain based sliding correlation\nchannel sounder in the InH scenario for both LOS and NLOS channel conditions.\nOur results confirm that the 3GPP TR 38.901 path loss model for the InH\nscenario remains valid for the 7-24 GHz range in both LOS and NLOS conditions\nand provide valuable input for 6G standardization efforts.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-22T05:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.15598v1","title":"Charge dependent nucleon-nucleon potentials in covariant chiral\n  effective field theory","summary":"The charge-dependent nucleon-nucleon ($NN$) interactions are crucial in\nunderstanding the nuclear structure and reaction problems. This work explores\nthe charge-dependent $NN$ interaction in covariant chiral effective field\ntheory. By incorporating the isospin-breaking contributions, we derive the\ncharge-dependent covariant chiral $NN$ potential up to the\nnext-to-next-to-leading order (NNLO). The calculated $np$ and $pp$ phase shifts\nare in satisfactory agreement with the PWA93 partial wave analysis. Our results\ncontribute to a deeper understanding of the isospin-breaking effects in nuclear\nforces and provide a solid foundation for future studies of nuclear structure\nand reactions in the context of a covariant framework.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-22T05:29:45Z"}
{"aid":"http://arxiv.org/abs/2504.15609v1","title":"SonarT165: A Large-scale Benchmark and STFTrack Framework for Acoustic\n  Object Tracking","summary":"Underwater observation systems typically integrate optical cameras and\nimaging sonar systems. When underwater visibility is insufficient, only sonar\nsystems can provide stable data, which necessitates exploration of the\nunderwater acoustic object tracking (UAOT) task. Previous studies have explored\ntraditional methods and Siamese networks for UAOT. However, the absence of a\nunified evaluation benchmark has significantly constrained the value of these\nmethods. To alleviate this limitation, we propose the first large-scale UAOT\nbenchmark, SonarT165, comprising 165 square sequences, 165 fan sequences, and\n205K high-quality annotations. Experimental results demonstrate that SonarT165\nreveals limitations in current state-of-the-art SOT trackers. To address these\nlimitations, we propose STFTrack, an efficient framework for acoustic object\ntracking. It includes two novel modules, a multi-view template fusion module\n(MTFM) and an optimal trajectory correction module (OTCM). The MTFM module\nintegrates multi-view feature of both the original image and the binary image\nof the dynamic template, and introduces a cross-attention-like layer to fuse\nthe spatio-temporal target representations. The OTCM module introduces the\nacoustic-response-equivalent pixel property and proposes normalized pixel\nbrightness response scores, thereby suppressing suboptimal matches caused by\ninaccurate Kalman filter prediction boxes. To further improve the model\nfeature, STFTrack introduces a acoustic image enhancement method and a\nFrequency Enhancement Module (FEM) into its tracking pipeline. Comprehensive\nexperiments show the proposed STFTrack achieves state-of-the-art performance on\nthe proposed benchmark. The code is available at\nhttps://github.com/LiYunfengLYF/SonarT165.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T06:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.15614v1","title":"Spin-dependent electronic transport in NiMnSb/MoS2(001)/NiMnSb magnetic\n  tunnel junction","summary":"Half-metallic Heusler alloy compounds with Curie temperatures above room\ntemperature are suitable candidate electrode materials for injecting large\nspin-polarised charge carriers into the semiconducting barriers at the\nferromagnet semiconductor junction to obtain highly spin-polarised current.\nCombining the density functional theory and non-equilibrium Green's function\nmethod, the electronic structure, spin dependent electron transport in\nNiMnSb/MoS2(001)/NiMnSb is studied. The possibilities of injecting 100%\nspin-polarised electron into MoS2 using half metallic NiMnSb as an electrode,\nthe layer dependent, and the effect of the type of interface on electronic\nstructure and spin-transport properties in magnetic tunnel junction devices are\nstudied. We show that the half-metallicity of NiMnSb(111) is preserved at the\ninterface between the half-Heusler alloy NiMnSb and MoS2. NiMnSb keeps a fully\nspin-polarised state in the majority spin channel at the interface between\nNiMnSb and MoS2, injecting fully spin-polarised electrons into the\nsemiconductor. The device based on NiMnSb/MoS2(single layer)/NiMnSb has a\nmetallic interface. Metal-induced states in the spin-majority channel of MoS2\nare seen after making an interface with half metallic NiMnSb. In contrast, the\nNiMnSb/MoS2(three layers)/NiMnSb interface with a multilayer of MoS2 has a band\ngap region, and electrons can tunnel through the junction. The Mn-S interface\nis more conducting than the Sb-S interface due to the strong bonding of Mn and\nS atoms at the Mn-S interface.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-22T06:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.15617v1","title":"Spatiotemporal Assessment of Aircraft Noise Exposure Using Mobile\n  Phone-Derived Population Estimates and High-Resolution Noise Measurements","summary":"Aircraft noise exposure has traditionally been assessed using static\nresidential population data and long-term average noise metrics, often\noverlooking the dynamic nature of human mobility and temporal variations in\noperational conditions. This study proposes a data-driven framework that\nintegrates high-resolution noise measurements from airport monitoring terminals\nwith mobile phone-derived de facto population estimates to evaluate noise\nexposure with fine spatio-temporal resolution. We develop hourly noise exposure\nprofiles and quantify the number of individuals affected across regions and\ntime windows, using both absolute counts and inequality metrics such as Gini\ncoefficients. This enables a nuanced examination of not only who is exposed,\nbut when and where the burden is concentrated. At our case study airport,\noperational runway patterns resulted in recurring spatial shifts in noise\nexposure. By incorporating de facto population data, we demonstrate that\nidentical noise operations can yield unequal impacts depending on the time and\nlocation of population presence, highlighting the importance of accounting for\npopulation dynamics in exposure assessment. Our approach offers a scalable\nbasis for designing population-sensitive noise abatement strategies,\ncontributing to more equitable and transparent aviation noise management.","main_category":"stat.AP","categories":"stat.AP,stat.OT","published":"2025-04-22T06:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.15626v1","title":"Realized Local Volatility Surface","summary":"For quantitative trading risk management purposes, we present a novel idea:\nthe realized local volatility surface. Concisely, it stands for the conditional\nexpected volatility when sudden market behaviors of the underlying occur. One\nis able to explore risk management usages by following the orthotical\nDelta-Gamma dynamic hedging framework. The realized local volatility surface\nis, mathematically, a generalized Wiener measure from historical prices. It is\nreconstructed via employing high-frequency trading market data. A\nStick-Breaking Gaussian Mixture Model is fitted via Hamiltonian Monte Carlo,\nproducing a local volatility surface with 95% credible intervals. A practically\nvalidated Bayesian nonparametric estimation workflow. Empirical results on TSLA\nhigh-frequency data illustrate its ability to capture counterfactual\nvolatility. We also discuss its application in improving volatility-based risk\nmanagement.","main_category":"q-fin.RM","categories":"q-fin.RM,math.OC,q-fin.CP,q-fin.TR","published":"2025-04-22T06:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.15627v1","title":"ZeroSlide: Is Zero-Shot Classification Adequate for Lifelong Learning in\n  Whole-Slide Image Analysis in the Era of Pathology Vision-Language Foundation\n  Models?","summary":"Lifelong learning for whole slide images (WSIs) poses the challenge of\ntraining a unified model to perform multiple WSI-related tasks, such as cancer\nsubtyping and tumor classification, in a distributed, continual fashion. This\nis a practical and applicable problem in clinics and hospitals, as WSIs are\nlarge, require storage, processing, and transfer time. Training new models\nwhenever new tasks are defined is time-consuming. Recent work has applied\nregularization- and rehearsal-based methods to this setting. However, the rise\nof vision-language foundation models that align diagnostic text with pathology\nimages raises the question: are these models alone sufficient for lifelong WSI\nlearning using zero-shot classification, or is further investigation into\ncontinual learning strategies needed to improve performance? To our knowledge,\nthis is the first study to compare conventional continual-learning approaches\nwith vision-language zero-shot classification for WSIs. Our source code and\nexperimental results will be available soon.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T06:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.15633v1","title":"An analytic redshift-independent formulation of baryonic effects on the\n  matter power spectrum","summary":"Baryonic effects created by feedback processes associated with galaxy\nformation are an important, poorly constrained systematic effect for models of\nlarge-scale structure as probed by weak gravitational lensing. Upcoming surveys\nrequire fast methods to predict and marginalize over the potential impact of\nbaryons on the total matter power spectrum. Here we use the FLAMINGO\ncosmological hydrodynamical simulations to test a recent proposal to\napproximate the matter power spectrum as the sum of the linear matter power\nspectrum and a constant multiple, $A_{\\rm mod}$, of the difference between the\nlinear and non-linear gravity-only power spectra. We show that replacing this\nconstant multiple with a one-parameter family of sigmoid functions of the\nwavenumber $k$ allows to us match the predictions of simulations with different\nfeedback strengths for $z \\leq 1, k < 3~h\\cdot{\\rm Mpc}^{-1}$, and the\ndifferent cosmological models in the FLAMINGO suite. The baryonic response\npredicted by FLAMINGO models that use jet-like AGN feedback instead of the\nfiducial thermally-driven AGN feedback can also be reproduced, but at the cost\nof increasing the number of parameters in the sigmoid function from one to\nthree. The assumption that $A_{\\rm mod}$ depends only on $k$ breaks down for\ndecaying dark matter models, highlighting the need for more advanced baryon\nresponse models when studying cosmological models that deviate strongly from\n$\\Lambda$CDM.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-22T06:48:25Z"}
{"aid":"http://arxiv.org/abs/2504.15639v1","title":"A remark for characterizing blowup introduced by Giga and Kohn","summary":"Giga and Kohn studied the blowup solutions for the equation $v_{t} - \\Delta v\n- |v|^{p - 1} v = 0 $ and characterized the asymptotic behavior of $v$ near a\nsingularity. In the proof, they reduced the problem to a Liouville theorem for\nthe equation $\\Delta u - \\frac{1}{2} x \\cdot \\nabla u + |u|^{p - 1} u - \\beta u\n= 0$ where $\\beta = \\frac{1}{p - 1}$ and $|u|$ is bounded. This article is a\nremark for their work and we will show when $u \\geq 0$, the boundedness\ncondition for $|u|$ can be removed.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T06:57:02Z"}
{"aid":"http://arxiv.org/abs/2504.15644v1","title":"On the Klein-Gordon bosonic fields in the Bonnor-Melvin spacetime with a\n  cosmological constant in rainbow gravity: Bonnor-Melvin Domain Walls","summary":"We investigate the effect of rainbow gravity on Klein-Gordon (KG) bosons in\nthe background of the magnetized Bonnor-Melvin (BM) spacetime with a\ncosmological constant. We first show that the very existence of the sinusoidal\nterm \\(\\sin^2(\\sqrt{2\\Lambda}r)\\), in the BM space-time metric, suggests that\n\\(\\sin^2(\\sqrt{2\\Lambda}r) \\in [0,1],\\) which consequently restricts the range\nof the radial coordinate \\(r\\) to \\(r \\in [0,\\pi/\\sqrt{2\\Lambda}]\\). Moreover,\nwe show that at \\(r = 0\\) and \\(r = \\pi/\\sqrt{2\\Lambda}\\), the magnetized\nBM-spacetime introduces domain walls (infinitely impenetrable hard walls)\nwithin which the KG bosonic fields are allowed to move. Interestingly, the\nmagnetized BM-spacetime introduces not only two domain walls but a series of\ndomain walls. However, we focus on the range \\(r \\in [0,\\pi/\\sqrt{2\\Lambda}]\\).\nA quantum particle remains indefinitely confined within this range and cannot\nbe found elsewhere. Based on these findings, we report the effects of rainbow\ngravity on KG bosonic fields in BM-spacetime. We use three pairs of rainbow\nfunctions: \\( f(\\chi) = \\frac{1}{1 - \\tilde{\\beta} |E|}, \\, h(\\chi) = 1 \\); \\(\nf(\\chi) = (1 - \\tilde{\\beta} |E|)^{-1}, \\, h(\\chi) = 1 \\); and \\( f(\\chi) = 1,\n\\, h(\\chi) = \\sqrt{1 - \\tilde{\\beta} |E|^\\upsilon} \\), with \\(\\upsilon = 1,2\\).\nHere, \\(\\chi = |E| / E_p\\), \\(\\tilde{\\beta} = \\beta / E_p\\), and \\(\\beta\\) is\nthe rainbow parameter. We found that while the pairs \\((f,h)\\) in the first and\nthird cases fully comply with the theory of rainbow gravity and ensure that\n\\(E_p\\) is the maximum possible energy for particles and antiparticles, the\nsecond pair does not show any response to the effects of rainbow gravity. We\nshow that the corresponding bosonic states can form magnetized, spinning\nvortices in monolayer materials, and these vortices can be driven by adjusting\nan out-of-plane aligned magnetic field.","main_category":"gr-qc","categories":"gr-qc,nucl-th","published":"2025-04-22T07:03:05Z"}
{"aid":"http://arxiv.org/abs/2504.15657v1","title":"Neural Kinematic Bases for Fluids","summary":"We propose mesh-free fluid simulations that exploit a kinematic neural basis\nfor velocity fields represented by an MLP. We design a set of losses that\nensures that these neural bases satisfy fundamental physical properties such as\northogonality, divergence-free, boundary alignment, and smoothness. Our neural\nbases can then be used to fit an input sketch of a flow, which will inherit the\nsame fundamental properties from the bases. We then can animate such flow in\nreal-time using standard time integrators. Our neural bases can accommodate\ndifferent domains and naturally extend to three dimensions.","main_category":"cs.GR","categories":"cs.GR,cs.LG,physics.flu-dyn","published":"2025-04-22T07:28:28Z"}
{"aid":"http://arxiv.org/abs/2504.15660v1","title":"Electroweak form factors of baryons in dense nuclear matter","summary":"There are evidences that the properties of the hadrons are modified in a\nnuclear medium. Information about the medium modifications of the internal\nstructure of the hadrons are fundamental for the study of dense nuclear matter\nand high energy processes including heavy-ion and nucleus-nucleus collisions.\nAt the moment, however, the empirical information about the medium\nmodifications of the hadrons is limited, therefore, theoretical studies are\nessential for the progress in the field. In the present work we review\ntheoretical studies of the electromagnetic and axial form factors of octet\nbaryons in symmetric nuclear matter. The calculations are based on a model that\ntakes into account the degrees of freedom revealed on experimental studies of\nthe low and intermediate square transfer momentum $q^2=-Q^2$: valence quarks\nand meson cloud excitations of the baryon cores. The formalism combines a\ncovariant constituent quark model, developed for the free space (vacuum) with\nthe quark-meson coupling model for the extension to the nuclear medium. We\nconclude that the nuclear medium modifies the baryon properties differently\naccording to the flavor content of the baryons and the medium density. The\neffects of the medium increase with the density, and are stronger (quenched or\nenhanced) for light baryons than for heavy baryons. In particular, the\nin-medium neutrino-nucleon and antineutrino-nucleon cross sections are reduced\ncompared to the values in free space. The proposed formalism can be extended to\ndensities above the normal nuclear density and applied to neutrino-hyperon and\nantineutrino-hyperon scattering in dense nuclear matter.","main_category":"nucl-th","categories":"nucl-th,hep-ex,hep-lat,hep-ph,nucl-ex","published":"2025-04-22T07:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.15665v1","title":"Motion-Enhanced Nonlocal Similarity Implicit Neural Representation for\n  Infrared Dim and Small Target Detection","summary":"Infrared dim and small target detection presents a significant challenge due\nto dynamic multi-frame scenarios and weak target signatures in the infrared\nmodality. Traditional low-rank plus sparse models often fail to capture dynamic\nbackgrounds and global spatial-temporal correlations, which results in\nbackground leakage or target loss. In this paper, we propose a novel\nmotion-enhanced nonlocal similarity implicit neural representation (INR)\nframework to address these challenges. We first integrate motion estimation via\noptical flow to capture subtle target movements, and propose multi-frame fusion\nto enhance motion saliency. Second, we leverage nonlocal similarity to\nconstruct patch tensors with strong low-rank properties, and propose an\ninnovative tensor decomposition-based INR model to represent the nonlocal patch\ntensor, effectively encoding both the nonlocal low-rankness and\nspatial-temporal correlations of background through continuous neural\nrepresentations. An alternating direction method of multipliers is developed\nfor the nonlocal INR model, which enjoys theoretical fixed-point convergence.\nExperimental results show that our approach robustly separates dim targets from\ncomplex infrared backgrounds, outperforming state-of-the-art methods in\ndetection accuracy and robustness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T07:42:00Z"}
{"aid":"http://arxiv.org/abs/2504.15667v1","title":"Performance Estimation for Supervised Medical Image Segmentation Models\n  on Unlabeled Data Using UniverSeg","summary":"The performance of medical image segmentation models is usually evaluated\nusing metrics like the Dice score and Hausdorff distance, which compare\npredicted masks to ground truth annotations. However, when applying the model\nto unseen data, such as in clinical settings, it is often impractical to\nannotate all the data, making the model's performance uncertain. To address\nthis challenge, we propose the Segmentation Performance Evaluator (SPE), a\nframework for estimating segmentation models' performance on unlabeled data.\nThis framework is adaptable to various evaluation metrics and model\narchitectures. Experiments on six publicly available datasets across six\nevaluation metrics including pixel-based metrics such as Dice score and\ndistance-based metrics like HD95, demonstrated the versatility and\neffectiveness of our approach, achieving a high correlation (0.956$\\pm$0.046)\nand low MAE (0.025$\\pm$0.019) compare with real Dice score on the independent\ntest set. These results highlight its ability to reliably estimate model\nperformance without requiring annotations. The SPE framework integrates\nseamlessly into any model training process without adding training overhead,\nenabling performance estimation and facilitating the real-world application of\nmedical image segmentation algorithms. The source code is publicly available","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-22T07:42:48Z"}
{"aid":"http://arxiv.org/abs/2504.15670v1","title":"Applicability Evaluation of Selected xAI Methods for Machine Learning\n  Algorithms for Signal Parameters Extraction","summary":"Machine learning methods find growing application in the reconstruction and\nanalysis of data in high energy physics experiments. A modified convolutional\nautoencoder model was employed to identify and reconstruct the pulses from\nscintillating crystals. The model was further investigated using four xAI\nmethods for deeper understanding of the underlying reconstruction mechanism.\nThe results are discussed in detail, underlining the importance of xAI for\nknowledge gain and further improvement of the algorithms.","main_category":"physics.comp-ph","categories":"physics.comp-ph,hep-ex,physics.ins-det","published":"2025-04-22T07:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.15695v1","title":"A Time Series Analysis of Malware Uploads to Programming Language\n  Ecosystems","summary":"Software ecosystems built around programming languages have greatly\nfacilitated software development. At the same time, their security has\nincreasingly been acknowledged as a problem. To this end, the paper examines\nthe previously overlooked longitudinal aspects of software ecosystem security,\nfocusing on malware uploaded to six popular programming language ecosystems.\nThe dataset examined is based on the new Open Source Vulnerabilities (OSV)\ndatabase. According to the results, records about detected malware uploads in\nthe database have recently surpassed those addressing vulnerabilities in\npackages distributed in the ecosystems. In the early 2025 even up to 80% of all\nentries in the OSV have been about malware. Regarding time series analysis of\nmalware frequencies and their shares to all database entries, good predictions\nare available already by relatively simple autoregressive models using the\nnumbers of ecosystems, security advisories, and media and other articles as\npredictors. With these results and the accompanying discussion, the paper\nimproves and advances the understanding of the thus far overlooked longitudinal\naspects of ecosystems and malware.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-04-22T08:27:22Z"}
{"aid":"http://arxiv.org/abs/2504.15700v1","title":"Towards True Work-Efficiency in Parallel Derandomization: MIS, Maximal\n  Matching, and Hitting Set","summary":"Derandomization is one of the classic topics studied in the theory of\nparallel computations, dating back to the early 1980s. Despite much work, all\nknown techniques lead to deterministic algorithms that are not work-efficient.\nFor instance, for the well-studied problem of maximal independent set -- e.g.,\n[Karp, Wigderson STOC'84; Luby STOC' 85; Luby FOCS'88] -- state-of-the-art\ndeterministic algorithms require at least $m \\cdot poly(\\log n)$ work, where\n$m$ and $n$ denote the number of edges and vertices. Hence, these deterministic\nalgorithms will remain slower than their trivial sequential counterparts unless\nwe have at least $poly(\\log n)$ processors.\n  In this paper, we present a generic parallel derandomization technique that\nmoves exponentially closer to work-efficiency. The method iteratively rounds\nfractional solutions representing the randomized assignments to integral\nsolutions that provide deterministic assignments, while maintaining certain\nlinear or quadratic objective functions, and in an \\textit{essentially\nwork-efficient} manner. As example end-results, we use this technique to obtain\ndeterministic algorithms with $m \\cdot poly(\\log \\log n)$ work and $poly(\\log\nn)$ depth for problems such as maximal independent set, maximal matching, and\nhitting set.","main_category":"cs.DS","categories":"cs.DS,cs.DC","published":"2025-04-22T08:41:25Z"}
{"aid":"http://arxiv.org/abs/2504.15707v1","title":"RePOPE: Impact of Annotation Errors on the POPE Benchmark","summary":"Since data annotation is costly, benchmark datasets often incorporate labels\nfrom established image datasets. In this work, we assess the impact of label\nerrors in MSCOCO on the frequently used object hallucination benchmark POPE. We\nre-annotate the benchmark images and identify an imbalance in annotation errors\nacross different subsets. Evaluating multiple models on the revised labels,\nwhich we denote as RePOPE, we observe notable shifts in model rankings,\nhighlighting the impact of label quality. Code and data are available at\nhttps://github.com/YanNeu/RePOPE .","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-22T08:47:59Z"}
{"aid":"http://arxiv.org/abs/2504.15715v1","title":"Assessing FAIRness of the Digital Shadow Reference Model","summary":"Models play a critical role in managing the vast amounts of data and\nincreasing complexity found in the IoT, IIoT, and IoP domains. The Digital\nShadow Reference Model, which serves as a foundational metadata schema for\nlinking data and metadata in these environments, is an example of such a model.\nEnsuring FAIRness (adherence to the FAIR Principles) is critical because it\nimproves data findability, accessibility, interoperability, and reusability,\nfacilitating efficient data management and integration across systems.\n  This paper presents an evaluation of the FAIRness of the Digital Shadow\nReference Model using a structured evaluation framework based on the FAIR Data\nPrinciples. Using the concept of FAIR Implementation Profiles (FIPs),\nsupplemented by a mini-questionnaire, we systematically evaluate the model's\nadherence to these principles. Our analysis identifies key strengths, including\nthe model's metadata schema that supports rich descriptions and authentication\ntechniques, and highlights areas for improvement, such as the need for globally\nunique identifiers and consequent support for different Web standards. The\nresults provide actionable insights for improving the FAIRness of the model and\npromoting better data management and reuse. This research contributes to the\nfield by providing a detailed assessment of the Digital Shadow Reference Model\nand recommending next steps to improve its FAIRness and usability.","main_category":"cs.DB","categories":"cs.DB,cs.CY,cs.IR","published":"2025-04-22T08:58:48Z"}
{"aid":"http://arxiv.org/abs/2504.15723v1","title":"Structure-Preserving Zero-Shot Image Editing via Stage-Wise Latent\n  Injection in Diffusion Models","summary":"We propose a diffusion-based framework for zero-shot image editing that\nunifies text-guided and reference-guided approaches without requiring\nfine-tuning. Our method leverages diffusion inversion and timestep-specific\nnull-text embeddings to preserve the structural integrity of the source image.\nBy introducing a stage-wise latent injection strategy-shape injection in early\nsteps and attribute injection in later steps-we enable precise, fine-grained\nmodifications while maintaining global consistency. Cross-attention with\nreference latents facilitates semantic alignment between the source and\nreference. Extensive experiments across expression transfer, texture\ntransformation, and style infusion demonstrate state-of-the-art performance,\nconfirming the method's scalability and adaptability to diverse image editing\nscenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T09:18:16Z"}
{"aid":"http://arxiv.org/abs/2504.15732v1","title":"Integral Artin motives II: Perverse motives and Artin Vanishing Theorem","summary":"In this text, we are mainly interested in the existence of the perverse\nmotivic t-structures on the category of Artin \\'etale motives with integral\ncoefficients. We construct the perverse homotopy t-structure which is the best\npossible approximation to a perverse t-structure on Artin motives with rational\ncoefficients. The heart of this t-structure has properties similar to those of\nthe category of perverse sheaves and contains the Ayoub-Zucker motive. With\nintegral coefficients, we construct the perverse motivic t-structure on Artin\nmotives when the base scheme is of dimension at most $2$ and show that it\ncannot exist in dimension $4$. This construction relies notably on a an\nanalogue for Artin motives of the Artin Vanishing Theorem.","main_category":"math.AG","categories":"math.AG","published":"2025-04-22T09:25:27Z"}
{"aid":"http://arxiv.org/abs/2504.15737v1","title":"Energy-Efficient SIM-assisted Communications: How Many Layers Do We\n  Need?","summary":"The stacked intelligent metasurface (SIM), comprising multiple layers of\nreconfigurable transmissive metasurfaces, is becoming an increasingly viable\nsolution for future wireless communication systems. In this paper, we explore\nthe integration of SIM in a multi-antenna base station for application to\ndownlink multi-user communications, and a realistic power consumption model for\nSIM-assisted systems is presented. Specifically, we focus on maximizing the\nenergy efficiency (EE) for hybrid precoding design, i.e., the base station\ndigital precoding and SIM wave-based beamforming. Due to the non-convexity and\nhigh complexity of the formulated problem, we employ the quadratic\ntransformation method to reformulate the optimization problem and propose an\nalternating optimization (AO)-based joint precoding framework. Specifically, a\nsuccessive convex approximation (SCA) algorithm is adopted for the base station\nprecoding design. For the SIM wave-based beamforming, two algorithms are\nemployed: the high-performance semidefinite programming (SDP) method and the\nlow-complexity projected gradient ascent (PGA) algorithm. In particular, the\nresults indicate that while the optimal number of SIM layers for maximizing the\nEE and spectral efficiency differs, a design of 2 to 5 layers can achieve\nsatisfactory performance for both. Finally, numerical results are illustrated\nto evaluate the effectiveness of the proposed hybrid precoding framework and to\nshowcase the performance enhancement achieved by the algorithm in comparison to\nbenchmark schemes.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-22T09:31:55Z"}
{"aid":"http://arxiv.org/abs/2504.15740v1","title":"CaRoSaC: A Reinforcement Learning-Based Kinematic Control of\n  Cable-Driven Parallel Robots by Addressing Cable Sag through Simulation","summary":"This paper introduces the Cable Robot Simulation and Control (CaRoSaC)\nFramework, which integrates a simulation environment with a model-free\nreinforcement learning control methodology for suspended Cable-Driven Parallel\nRobots (CDPRs), accounting for cable sag. Our approach seeks to bridge the\nknowledge gap of the intricacies of CDPRs due to aspects such as cable sag and\nprecision control necessities by establishing a simulation platform that\ncaptures the real-world behaviors of CDPRs, including the impacts of cable sag.\nThe framework offers researchers and developers a tool to further develop\nestimation and control strategies within the simulation for understanding and\npredicting the performance nuances, especially in complex operations where\ncable sag can be significant. Using this simulation framework, we train a\nmodel-free control policy in Reinforcement Learning (RL). This approach is\nchosen for its capability to adaptively learn from the complex dynamics of\nCDPRs. The policy is trained to discern optimal cable control inputs, ensuring\nprecise end-effector positioning. Unlike traditional feedback-based control\nmethods, our RL control policy focuses on kinematic control and addresses the\ncable sag issues without being tethered to predefined mathematical models. We\nalso demonstrate that our RL-based controller, coupled with the flexible cable\nsimulation, significantly outperforms the classical kinematics approach,\nparticularly in dynamic conditions and near the boundary regions of the\nworkspace. The combined strength of the described simulation and control\napproach offers an effective solution in manipulating suspended CDPRs even at\nworkspace boundary conditions where traditional approach fails, as proven from\nour experiments, ensuring that CDPRs function optimally in various applications\nwhile accounting for the often neglected but critical factor of cable sag.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T09:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.15742v1","title":"Proving Cypher Query Equivalence","summary":"Graph database systems store graph data as nodes and relationships, and\nutilize graph query languages (e.g., Cypher) for efficiently querying graph\ndata. Proving the equivalence of graph queries is an important foundation for\noptimizing graph query performance, ensuring graph query reliability, etc.\nAlthough researchers have proposed many SQL query equivalence provers for\nrelational database systems, these provers cannot be directly applied to prove\nthe equivalence of graph queries. The difficulty lies in the fact that graph\nquery languages (e.g., Cypher) adopt significantly different data models\n(property graph model vs. relational model) and query patterns (graph pattern\nmatching vs. tabular tuple calculus) from SQL.\n  In this paper, we propose GraphQE, an automated prover to determine whether\ntwo Cypher queries are semantically equivalent. We design a U-semiring based\nCypher algebraic representation to model the semantics of Cypher queries. Our\nCypher algebraic representation is built on the algebraic structure of\nunbounded semirings, and can sufficiently express nodes and relationships in\nproperty graphs and complex Cypher queries. Then, determining the equivalence\nof two Cypher queries is transformed into determining the equivalence of the\ncorresponding Cypher algebraic representations, which can be verified by SMT\nsolvers. To evaluate the effectiveness of GraphQE, we construct a dataset\nconsisting of 148 pairs of equivalent Cypher queries. Among them, we have\nsuccessfully proven 138 pairs of equivalent Cypher queries, demonstrating the\neffectiveness of GraphQE.","main_category":"cs.DB","categories":"cs.DB,cs.SE","published":"2025-04-22T09:45:37Z"}
{"aid":"http://arxiv.org/abs/2504.15752v1","title":"On the complexity of proximal gradient and proximal Newton-CG methods\n  for \\(\\ell_1\\)-regularized Optimization","summary":"In this paper, we propose two second-order methods for solving the\n\\(\\ell_1\\)-regularized composite optimization problem, which are developed\nbased on two distinct definitions of approximate second-order stationary\npoints. We introduce a hybrid proximal gradient and negative curvature method,\nas well as a proximal Newton-CG method, to find a strong* approximate\nsecond-order stationary point and a weak approximate second-order stationary\npoint for \\(\\ell_1\\)-regularized optimization problems, respectively.\nComprehensive analyses are provided regarding the iteration complexity,\ncomputational complexity, and the local superlinear convergence rates of the\nfirst phases of these two methods under specific error bound conditions.\nSpecifically, we demonstrate that the proximal Newton-CG method achieves the\nbest-known iteration complexity for attaining the proposed weak approximate\nsecond-order stationary point, which is consistent with the results for finding\nan approximate second-order stationary point in unconstrained optimization.\nThrough a toy example, we show that our proposed methods can effectively escape\nthe first-order approximate solution. Numerical experiments implemented on the\n\\(\\ell_1\\)-regularized Student's t-regression problem validate the\neffectiveness of both methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-22T09:56:28Z"}
{"aid":"http://arxiv.org/abs/2504.15753v1","title":"Markov Kernels, Distances and Optimal Control: A Parable of Linear\n  Quadratic Non-Gaussian Distribution Steering","summary":"For a controllable linear time-varying (LTV) pair\n$(\\boldsymbol{A}_t,\\boldsymbol{B}_t)$ and $\\boldsymbol{Q}_{t}$ positive\nsemidefinite, we derive the Markov kernel for the It\\^{o} diffusion\n${\\mathrm{d}}\\boldsymbol{x}_{t}=\\boldsymbol{A}_{t}\\boldsymbol{x}_t {\\mathrm{d}}\nt + \\sqrt{2}\\boldsymbol{B}_{t}{\\mathrm{d}}\\boldsymbol{w}_{t}$ with an\naccompanying killing of probability mass at rate\n$\\frac{1}{2}\\boldsymbol{x}^{\\top}\\boldsymbol{Q}_{t}\\boldsymbol{x}$. This Markov\nkernel is the Green's function for an associated linear\nreaction-advection-diffusion partial differential equation. Our result\ngeneralizes the recently derived kernel for the special case\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t\\right)=\\left(\\boldsymbol{0},\\boldsymbol{I}\\right)$,\nand depends on the solution of an associated Riccati matrix ODE. A consequence\nof this result is that the linear quadratic non-Gaussian Schr\\\"{o}dinger bridge\nis exactly solvable. This means that the problem of steering a controlled LTV\ndiffusion from a given non-Gaussian distribution to another over a fixed\ndeadline while minimizing an expected quadratic cost can be solved using\ndynamic Sinkhorn recursions performed with the derived kernel. Our derivation\nfor the\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t,\\boldsymbol{Q}_t\\right)$-parametrized\nkernel pursues a new idea that relies on finding a state-time dependent\ndistance-like functional given by the solution of a deterministic optimal\ncontrol problem. This technique breaks away from existing methods, such as\ngeneralizing Hermite polynomials or Weyl calculus, which have seen limited\nsuccess in the reaction-diffusion context. Our technique uncovers a new\nconnection between Markov kernels, distances, and optimal control. This\nconnection is of interest beyond its immediate application in solving the\nlinear quadratic Schr\\\"{o}dinger bridge problem.","main_category":"math.OC","categories":"math.OC,cs.LG,cs.SY,eess.SY,math.PR,math.ST,stat.TH","published":"2025-04-22T10:07:43Z"}
{"aid":"http://arxiv.org/abs/2504.15778v1","title":"A Stochastic Lattice Model for Convective Self-aggregation Incorporating\n  Longwave Radiative Effect","summary":"Self-aggregation of tropical convection is a universal feature observed in a\ndiverse range of atmospheric environments. Several preceding models\nconceptualized the self-aggregation of convection as a phase transition driven\nby collisions between cold pool gust fronts. However, self-aggregation may also\nbe influenced by various physical processes, such as surface fluxes, radiation,\nand moisture perturbations in the planetary boundary layer, and it remains\nunclear which process plays a dominant role. In this study, we develop a simple\nstochastic lattice model for the pattern formation of deep convection, inspired\nby the two-dimensional Ising model. Here, in addition to the process of cold\npool collisions, which have an effect of triggering new convection, we\nincorporate the process of clear-sky radiative cooling that has an effect of\nsuppressing deep convection as an interaction between clouds. Our results show\nthat by amplifying the intensity of the clear-sky radiative cooling effect, the\ntransition from a quasi-uniform to an inhomogeneous cloud field can be\nreproduced. The model also successfully explains the dependence of\nself-aggregation on several model parameters, such as the experimental domain\nsize and the characteristic size of cold pools. Furthermore, by varying the\ndistance over which the subsidence induced by radiative cooling extends, we\nsucceed in capturing a pattern formation that closely resembles the convective\nclusters observed in the real atmosphere and three-dimensional numerical model\nsimulations.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-22T10:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.15779v1","title":"Shannon invariants: A scalable approach to information decomposition","summary":"Distributed systems, such as biological and artificial neural networks,\nprocess information via complex interactions engaging multiple subsystems,\nresulting in high-order patterns with distinct properties across scales.\nInvestigating how these systems process information remains challenging due to\ndifficulties in defining appropriate multivariate metrics and ensuring their\nscalability to large systems. To address these challenges, we introduce a novel\nframework based on what we call \"Shannon invariants\" -- quantities that capture\nessential properties of high-order information processing in a way that depends\nonly on the definition of entropy and can be efficiently calculated for large\nsystems. Our theoretical results demonstrate how Shannon invariants can be used\nto resolve long-standing ambiguities regarding the interpretation of widely\nused multivariate information-theoretic measures. Moreover, our practical\nresults reveal distinctive information-processing signatures of various deep\nlearning architectures across layers, which lead to new insights into how these\nsystems process information and how this evolves during training. Overall, our\nframework resolves fundamental limitations in analyzing high-order phenomena\nand offers broad opportunities for theoretical developments and empirical\nanalyses.","main_category":"cs.IT","categories":"cs.IT,cs.AI,cs.LG,math.IT,nlin.AO,physics.data-an","published":"2025-04-22T10:41:38Z"}
{"aid":"http://arxiv.org/abs/2504.15782v1","title":"Model-based Metric 3D Shape and Motion Reconstruction of Wild Bottlenose\n  Dolphins in Drone-Shot Videos","summary":"We address the problem of estimating the metric 3D shape and motion of wild\ndolphins from monocular video, with the aim of assessing their body condition.\nWhile considerable progress has been made in reconstructing 3D models of\nterrestrial quadrupeds, aquatic animals remain unexplored due to the difficulty\nof observing them in their natural underwater environment. To address this, we\npropose a model-based approach that incorporates a transmission model to\naccount for water-induced occlusion. We apply our method to video captured\nunder different sea conditions. We estimate mass and volume, and compare our\nresults to a manual 2D measurements-based method.","main_category":"cs.CV","categories":"cs.CV,cs.GR","published":"2025-04-22T10:47:29Z"}
{"aid":"http://arxiv.org/abs/2504.15786v1","title":"Satellite to GroundScape -- Large-scale Consistent Ground View\n  Generation from Satellite Views","summary":"Generating consistent ground-view images from satellite imagery is\nchallenging, primarily due to the large discrepancies in viewing angles and\nresolution between satellite and ground-level domains. Previous efforts mainly\nconcentrated on single-view generation, often resulting in inconsistencies\nacross neighboring ground views. In this work, we propose a novel cross-view\nsynthesis approach designed to overcome these challenges by ensuring\nconsistency across ground-view images generated from satellite views. Our\nmethod, based on a fixed latent diffusion model, introduces two conditioning\nmodules: satellite-guided denoising, which extracts high-level scene layout to\nguide the denoising process, and satellite-temporal denoising, which captures\ncamera motion to maintain consistency across multiple generated views. We\nfurther contribute a large-scale satellite-ground dataset containing over\n100,000 perspective pairs to facilitate extensive ground scene or video\ngeneration. Experimental results demonstrate that our approach outperforms\nexisting methods on perceptual and temporal metrics, achieving high\nphotorealism and consistency in multi-view outputs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T10:58:42Z"}
{"aid":"http://arxiv.org/abs/2504.15788v1","title":"A primer on Kitaev Model: Basic aspects, material realization, and\n  recent experiments","summary":"This elementary review article is aimed to the beginning graduate students\ninterested to know basic aspects of Kitaev model. We begin with a very lucid\nintroduction of Kitaev model and present its exact solution, Hilbert space\nstructure, fractionalisation, spin-spin correlation function and topological\ndegeneracy in an elementary way. We then discuss the recent proposal of\nrealizing Kitaev interaction in certain materials. Finally we present some\nrecent experiments done on these materials, mainly magnetization,\nsusceptibility, specific heat and thermal Hall effect to elucidate the recent\nstatus of material realization of coveted Kitaev spin-liquid phase. We end with\na brief discussion on other theoretical works on Kitaev model from different\nmany-body aspects.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-22T11:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.15789v1","title":"Doubly-charmed pentaquark states in a mass splitting model","summary":"Concentrating on the mass differences relative to $P_{\\psi}^{N}(4312)^+$, we\nsystematically investigate the spectra of doubly-charmed pentaquark states in\nthe compact $ccqq\\bar{q}$ ($q=u, d, s$) configuration. The assumption that the\nobserved $P_{\\psi}^{N}(4312)^+$ is a compact hidden-charm pentaquark with\n$I(J^P)=\\frac12(\\frac32^-)$ is adopted. We also study the properties of strong\ndecays within a simple rearrangement scheme. The results indicate that the\n$I(J^P)=\\frac12(\\frac12^-)$ $ccnn\\bar{n}$ with $I_{nn}=0$ where $n$ denotes $u$\nor $d$ quark, $I(J^P)=0(\\frac12^-)$ $ccnn\\bar{s}$, and $I(J^P)=0(\\frac12^-)$\n$ccns\\bar{n}$ ground states should be stable.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-22T11:03:34Z"}
{"aid":"http://arxiv.org/abs/2504.15799v1","title":"Gradient higher integrability for degenerate parabolic double phase\n  systems with two modulating coefficients","summary":"We establish an interior gradient higher integrability result for weak\nsolutions to degenerate parabolic double phase systems involving two modulating\ncoefficients. To be more precise, we study systems of the form \\begin{align*}\n  u_t-\\operatorname{div} \\left(a(z)|Du|^{p-2}Du+\nb(z)|Du|^{q-2}Du\\right)=-\\operatorname{div} \\left(a(z)|F|^{p-2}F+\nb(z)|F|^{q-2}F\\right), \\end{align*} where $2\\leq p\\leq q < \\infty$ and the\nmodulating coefficients $a(z)$ and $b(z)$ are non-negative, with $a(z)$ being\nuniformly continuous and $b(z)$ being H\\\"{o}lder continuous. We further assume\nthat the sum of two modulating coefficients is bounded from below by some\npositive constant. To establish the gradient higher integrability result, we\nintroduce a suitable intrinsic geometry and develop a delicate comparison\nscheme to separate and analyze the different phases--namely, the $p$-phase,\n$q$-phase and $(p,q)$-phase. To the best of our knowledge, this is the first\nregularity result in the parabolic setting that addresses general double phase\nsystems.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T11:27:55Z"}
{"aid":"http://arxiv.org/abs/2504.15802v1","title":"Cosmic ray neutrons in magnetized astrophysical structures","summary":"Cosmic rays are often modeled as charged particles. This allows their\nnon-ballistic propagation in magnetized structures to be captured. In certain\nsituations, a neutral cosmic ray component can arise. For example, cosmic ray\nneutrons are produced in considerable numbers through hadronic pp and p$\\gamma$\ninteractions. At ultrahigh energies, the decay timescales of these neutrons is\ndilated, allowing them to traverse distances on the scale of galactic and\ncosmological structures. Unlike charged cosmic rays, neutrons are not deflected\nby magnetic fields. They propagate ballistically at the speed of light in\nstraight lines. The presence of a neutral baryonic cosmic ray component formed\nin galaxies, clusters and cosmological filaments can facilitate the escape and\nleakage of cosmic rays from magnetic structures that would otherwise confine\nthem. We show that, by allowing confinement breaking, the formation of\ncosmic-ray neutrons by high-energy hadronic interactions in large scale\nastrophysical structures can modify the exchange of ultra high-energy particles\nacross magnetic interfaces between galaxies, clusters, cosmological filaments\nand voids.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.CO,astro-ph.GA","published":"2025-04-22T11:33:57Z"}
{"aid":"http://arxiv.org/abs/2504.15807v1","title":"Evaluating the potential of HIV self-testing to reduce HIV incidence in\n  EHE districts: a modeling study","summary":"Background: High HIV transmission persists in many U.S. jurisdictions despite\nprevention efforts. HIV self-testing offers a means to overcome barriers\nassociated with routine laboratory-based testing but carries a risk of\nincreasing incidence if replacement effects reduce overall test sensitivity.\nMethods: A linearized four-compartment HIV transmission model was applied to 38\nEnding the HIV Epidemic (EHE) priority jurisdictions. A threshold testing level\nwas defined to counterbalance potential negative effects from reduced self-test\nsensitivity. Both the percentage of self-tests and the overall testing rate\nwere varied to quantify 10-year changes in HIV incidence. Results: Substantial\nheterogeneity emerged across districts. Incidence reductions exceeded 5 percent\nin some areas, while others saw only minor effects. Jurisdictions with higher\nbaseline testing displayed an elevated risk of increased incidence from\nsubstitution of laboratory-based testing with self-tests. In contrast, a\nderived Awareness Reproduction Number, capturing transmissions attributable to\nundiagnosed infection, strongly correlated with the magnitude of possible\nincidence declines. Conclusions: Local epidemiological context is pivotal in\ndetermining the risks and benefits of HIV self-testing. Jurisdictions with\nrobust testing systems may face a greater likelihood of inadvertently raising\nincidence, whereas those with a high number of individuals stand to achieve\nnotable transmission reductions. Tailoring self-testing strategies based on\njurisdiction-specific conditions can maximize public health benefits while\nminimizing unintended consequences.","main_category":"math.DS","categories":"math.DS","published":"2025-04-22T11:43:28Z"}
{"aid":"http://arxiv.org/abs/2504.15818v1","title":"Uniqueness of Parisi measures for enriched convex vector spin glass","summary":"In the PDE approach to mean-field spin glasses, it has been observed that the\nfree energy of convex spin glass models could be enriched by adding an extra\nparameter in its definition, and that the thermodynamic limit of the enriched\nfree energy satisfies a partial differential equation. This parameter can be\nthought of as a matrix-valued path, and the usual free energy is recovered by\nsetting this parameter to be the constant path taking only the value $0$.\nFurthermore, the enriched free energy can be expressed using a variational\nformula, which is a natural extension of the Parisi formula for the usual free\nenergy. For models with scalar spins the Parisi formula can be expressed as an\noptimization problem over a convex set, and it was shown in [arXiv:1402.5132]\nthat this problem has a unique optimizer thanks to a strict convexity property.\nFor models with vector spins, the Parisi formula cannot easily be written as a\nconvex optimization problem. In this paper, we generalize the uniqueness of\nParisi measures proven in [arXiv:1402.5132] to the enriched free energy of\nmodels with vector spins when the extra parameter is a strictly increasing\npath. Our approach relies on a Gateaux differentiability property of the free\nenergy and the envelope theorem.","main_category":"math.PR","categories":"math.PR,math.AP","published":"2025-04-22T12:03:46Z"}
{"aid":"http://arxiv.org/abs/2504.15823v1","title":"Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition\n  Models","summary":"Near-infrared (NIR) face recognition systems, which can operate effectively\nin low-light conditions or in the presence of makeup, exhibit vulnerabilities\nwhen subjected to physical adversarial attacks. To further demonstrate the\npotential risks in real-world applications, we design a novel, stealthy, and\npractical adversarial patch to attack NIR face recognition systems in a\nblack-box setting. We achieved this by utilizing human-imperceptible\ninfrared-absorbing ink to generate multiple patches with digitally optimized\nshapes and positions for infrared images. To address the optimization mismatch\nbetween digital and real-world NIR imaging, we develop a light reflection model\nfor human skin to minimize pixel-level discrepancies by simulating NIR light\nreflection.\n  Compared to state-of-the-art (SOTA) physical attacks on NIR face recognition\nsystems, the experimental results show that our method improves the attack\nsuccess rate in both digital and physical domains, particularly maintaining\neffectiveness across various face postures. Notably, the proposed approach\noutperforms SOTA methods, achieving an average attack success rate of 82.46% in\nthe physical domain across different models, compared to 64.18% for existing\nmethods. The artifact is available at\nhttps://anonymous.4open.science/r/Human-imperceptible-adversarial-patch-0703/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T12:10:25Z"}
{"aid":"http://arxiv.org/abs/2504.15827v1","title":"DualOptim: Enhancing Efficacy and Stability in Machine Unlearning with\n  Dual Optimizers","summary":"Existing machine unlearning (MU) approaches exhibit significant sensitivity\nto hyperparameters, requiring meticulous tuning that limits practical\ndeployment. In this work, we first empirically demonstrate the instability and\nsuboptimal performance of existing popular MU methods when deployed in\ndifferent scenarios. To address this issue, we propose Dual Optimizer\n(DualOptim), which incorporates adaptive learning rate and decoupled momentum\nfactors. Empirical and theoretical evidence demonstrates that DualOptim\ncontributes to effective and stable unlearning. Through extensive experiments,\nwe show that DualOptim can significantly boost MU efficacy and stability across\ndiverse tasks, including image classification, image generation, and large\nlanguage models, making it a versatile approach to empower existing MU\nalgorithms.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T12:18:26Z"}
{"aid":"http://arxiv.org/abs/2504.15830v1","title":"Predictive Synthesis of Control Barrier Functions and its Application to\n  Time-Varying Constraints","summary":"This paper presents a systematic method for synthesizing a Control Barrier\nFunction (CBF) that encodes predictive information into a CBF. Unlike other\nmethods, the synthesized CBF can account for changes and time-variations in the\nconstraints even when constructed for time-invariant constraints. This avoids\nrecomputing the CBF when the constraint specifications change. The method\nprovides an explicit characterization of the extended class K function {\\alpha}\nthat determines the dynamic properties of the CBF, and {\\alpha} can even be\nexplicitly chosen as a design parameter in the controller synthesis. The\nresulting CBF further accounts for input constraints, and its values can be\ndetermined at any point without having to compute the CBF over the entire\ndomain. The synthesis method is based on a finite horizon optimal control\nproblem inspired by Hamilton-Jacobi reachability analysis and does not rely on\na nominal control law. The synthesized CBF is time-invariant if the constraints\nare. The method poses mild assumptions on the controllability of the dynamic\nsystem and assumes the knowledge of at least a subset of some control invariant\nset. The paper provides a detailed analysis of the properties of the\nsynthesized CBF, including its application to time-varying constraints. A\nsimulation study applies the proposed approach to various dynamic systems in\nthe presence of time-varying constraints. The paper is accompanied by an online\navailable parallelized implementation of the proposed synthesis method.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-22T12:21:16Z"}
{"aid":"http://arxiv.org/abs/2504.15831v1","title":"Detecting genuine non-Gaussian entanglement","summary":"Efficiently certifying non-Gaussian entanglement in continuous-variable\nquantum systems is a central challenge for advancing quantum information\nprocessing, photonic quantum computing, and metrology. Here, we put forward\ncontinuous-variable counterparts of the recently introduced entanglement\ncriteria based on moments of the partially transposed state, together with\nsimple readout schemes that require only a few replicas of the state, passive\nlinear optics, and particle-number measurements. Our multicopy method enables\nthe detection of genuine non-Gaussian entanglement for various relevant state\nfamilies overlooked by standard approaches, which includes the entire class of\nNOON states. Further, it is robust against realistic experimental constraints\n(losses, noise, and finite statistics), which we demonstrate by extensive\nnumerical simulations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T12:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.15839v1","title":"On commuting integer matrices","summary":"Given $d, N \\in \\mathbb{N}$, we define $\\mathfrak{C}_d(N)$ to be the number\nof pairs of $d\\times d$ matrices $A,B$ with entries in $[-N,N] \\cap \\mathbb{Z}$\nsuch that $AB = BA$. We prove that $$ N^{10} \\ll \\mathfrak{C}_3(N) \\ll\nN^{10},$$ thus confirming a speculation of Browning-Sawin-Wang. We further\nestablish that $$ \\mathfrak{C}_2(N) = K(2N+1)^5 (1 + o(1)),$$ where $K>0$ is an\nexplicit constant. Our methods are completely elementary and rely on upper\nbounds of the correct order for restricted divisor correlations with high\nuniformity.","main_category":"math.NT","categories":"math.NT,math.CO","published":"2025-04-22T12:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.15840v1","title":"Attractive and repulsive angulons in superfluid environments","summary":"We investigate the in- and out-of-equilibrium phenomena of a rotational\nimpurity -- specifically, a linear molecule -- coupled to a nonconventional\nenvironment, a helium nanodroplet. By employing a Lee-Low-Pines-like\ntransformation combined with a multireference configuration approach, we\nself-consistently account for the molecule's backaction on the superfluid bath\nand accurately capture the complex entanglement between the molecule's\nrotational degrees of freedom and the bath excitations. Our findings reveal\nthat, in the ground state, the impurity induces a density defect in the\nsuperfluid bath, giving rise to two novel types of excited states: (a)\nattractive angulon states, analogous to bound states in photonic crystals and\nYu-Shiba-Rusinov bound states in superconductors, localized within the density\ndefect region; and (b) long-lived repulsive angulon states in dilute\nenvironments. Rotational spectroscopy demonstrates a crossover from repulsive\nto attractive angulon states as the bath density increases. This work paves the\nway for exploring novel nonequilibrium phenomena of quantum impurities in\ninteracting environments.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,physics.chem-ph,quant-ph","published":"2025-04-22T12:34:55Z"}
{"aid":"http://arxiv.org/abs/2504.15841v1","title":"Quantum Discrete Variable Representations","summary":"We present a fault-tolerant quantum algorithm for implementing the Discrete\nVariable Representation (DVR) transformation, a technique widely used in\nsimulations of quantum-mechanical Hamiltonians. DVR provides a diagonal\nrepresentation of local operators and enables sparse Hamiltonian structures,\nmaking it a powerful alternative to the finite basis representation (FBR),\nparticularly in high-dimensional problems. While DVR has been extensively used\nin classical simulations, its quantum implementation, particularly using\nGaussian quadrature grids, remains underexplored. We develop a quantum circuit\nthat efficiently transforms FBR into DVR by following a recursive construction\nbased on quantum arithmetic operations, and we compare this approach with\nmethods that directly load DVR matrix elements using quantum read-only memory\n(QROM). We analyze the quantum resources, including T-gate and qubit counts,\nrequired for implementing the DVR unitary and discuss preferable choices of\nQROM-based and recursive-based methods for a given matrix size and precision.\nThis study lays the groundwork for utilizing DVR Hamiltonians in quantum\nalgorithms such as quantum phase estimation with block encoding.","main_category":"quant-ph","categories":"quant-ph,physics.chem-ph,physics.comp-ph","published":"2025-04-22T12:35:25Z"}
{"aid":"http://arxiv.org/abs/2504.15844v1","title":"Sound and Complete Invariant-Based Heap Encodings (Technical Report)","summary":"Verification of programs operating on mutable, heap-allocated data structures\nposes significant challenges due to potentially unbounded structures like\nlinked lists and trees. In this paper, we present a novel relational heap\nencoding leveraging uninterpreted predicates and prophecy variables, reducing\nheap verification tasks to satisfiability checks over integers in constrained\nHorn clauses (CHCs). To the best of our knowledge, our approach is the first\ninvariant-based method that achieves both soundness and completeness for\nheap-manipulating programs. We provide formal proofs establishing the\ncorrectness of our encodings. Through an experimental evaluation we demonstrate\nthat our method significantly extends the capability of existing CHC-based\nverification tools, allowing automatic verification of programs with heap\npreviously unreachable by state-of-the-art tools.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-22T12:40:21Z"}
{"aid":"http://arxiv.org/abs/2504.15848v1","title":"Exploring Cognitive and Aesthetic Causality for Multimodal Aspect-Based\n  Sentiment Analysis","summary":"Multimodal aspect-based sentiment classification (MASC) is an emerging task\ndue to an increase in user-generated multimodal content on social platforms,\naimed at predicting sentiment polarity toward specific aspect targets (i.e.,\nentities or attributes explicitly mentioned in text-image pairs). Despite\nextensive efforts and significant achievements in existing MASC, substantial\ngaps remain in understanding fine-grained visual content and the cognitive\nrationales derived from semantic content and impressions (cognitive\ninterpretations of emotions evoked by image content). In this study, we present\nChimera: a cognitive and aesthetic sentiment causality understanding framework\nto derive fine-grained holistic features of aspects and infer the fundamental\ndrivers of sentiment expression from both semantic perspectives and\naffective-cognitive resonance (the synergistic effect between emotional\nresponses and cognitive interpretations). Specifically, this framework first\nincorporates visual patch features for patch-word alignment. Meanwhile, it\nextracts coarse-grained visual features (e.g., overall image representation)\nand fine-grained visual regions (e.g., aspect-related regions) and translates\nthem into corresponding textual descriptions (e.g., facial, aesthetic).\nFinally, we leverage the sentimental causes and impressions generated by a\nlarge language model (LLM) to enhance the model's awareness of sentimental cues\nevoked by semantic content and affective-cognitive resonance. Experimental\nresults on standard MASC datasets demonstrate the effectiveness of the proposed\nmodel, which also exhibits greater flexibility to MASC compared to LLMs such as\nGPT-4o. We have publicly released the complete implementation and dataset at\nhttps://github.com/Xillv/Chimera","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T12:43:37Z"}
{"aid":"http://arxiv.org/abs/2504.15850v1","title":"Embedded Safe Reactive Navigation for Multirotors Systems using Control\n  Barrier Functions","summary":"Aiming to promote the wide adoption of safety filters for autonomous aerial\nrobots, this paper presents a safe control architecture designed for seamless\nintegration into widely used open-source autopilots. Departing from methods\nthat require consistent localization and mapping, we formalize the obstacle\navoidance problem as a composite control barrier function constructed only from\nthe online onboard range measurements. The proposed framework acts as a safety\nfilter, modifying the acceleration references derived by the nominal\nposition/velocity control loops, and is integrated into the PX4 autopilot\nstack. Experimental studies using a small multirotor aerial robot demonstrate\nthe effectiveness and performance of the solution within dynamic maneuvering\nand unknown environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T12:45:11Z"}
{"aid":"http://arxiv.org/abs/2504.15851v1","title":"Sensitivity analysis for parametric nonlinear programming: A tutorial","summary":"This tutorial provides an overview of the current state-of-the-art in the\nsensitivity analysis for nonlinear programming. Building upon the fundamental\nwork of Fiacco, it derives the sensitivity of primal-dual solutions for regular\nnonlinear programs and explores the extent to which Fiacco's framework can be\nextended to degenerate nonlinear programs with non-unique dual solutions. The\nsurvey ends with a discussion on how to adapt the sensitivity analysis for\nconic programs and approximate solutions obtained from interior-point\nalgorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-22T12:45:36Z"}
{"aid":"http://arxiv.org/abs/2504.15853v1","title":"DFT exploration of pressure dependent physical properties of the\n  recently discovered La3Ni2O7 superconductor","summary":"The recent discovery of superconductivity in Ruddlesden-Popper bilayer\nnickelate La3Ni2O7 under pressure has drawn a lot of interest. La3Ni2O7 is\nisostructural with cuprates in some respect. Investigation of its properties\nwill undoubtedly provide new insights into high-Tc superconductivity. In the\npresent work, we study structural, mechanical, elastic, optoelectronic,\nthermophysical properties, and Fermi surface topology of La3Ni2O7 under\npressure within the range of 30-40 GPa employing the density functional theory\n(DFT). The calculated structural parameters agree well with the earlier\nexperimental findings. The structural, mechanical, and thermodynamical\nstability is justified across the entire pressure range. The computed elastic\nmoduli classify the compound as ductile, and the material's ductility is\nlargely unaffected by pressure. The compound has a high level of machinability\nindex and dry lubricity. The electronic band structure reveals metallic feature\nof La3Ni2O7. The Debye temperature, thermal conductivity, and melting\ntemperature increase with increasing pressure, but in an anomalous manner. The\ncharacteristic peaks in refractive index, reflectivity, and photoconductivity\nexhibit a small shift towards higher energy for all polarizations of the\nelectric field vector with increasing pressure. The investigated material might\nbe a good ultraviolet radiation absorber and can be used as an anti-reflection\nsystem. Moreover, the pressure dependent electronic density of states at the\nFermi level, pressure induced negligible variations in the repulsive Coulomb\npseudopotential, and the changes in the Debye temperature have been used to\nexplore the effect of pressure on the superconducting transition temperature in\nthis study.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-22T12:49:03Z"}
{"aid":"http://arxiv.org/abs/2504.15858v1","title":"Positive-tone Nanolithography of Antimony Trisulfide with Femtosecond\n  Laser Wet-etching","summary":"Antimony trisulfide ($Sb_{2}S_{3}$), as an emerging material for integrated\nphotonic devices, has attracted significant attention due to its high index,\nlow loss, and phase-changing property in the optical regime. However,\nconventional lithography-based fabrication methods involve complex,\ntime-consuming, multistep processes, rendering the photonic application of\n$Sb_{2}S_{3}$ challenging. Here, we demonstrate that positive-tone fabrication\nof $Sb_{2}S_{3}$ nanostructures using wet-etch femtosecond laser processing, a\nstraightforward technique for the engraving of micro- and nanoscale structures,\ncan address major fabrication challenges. The patterning mechanism and factors\ninfluencing resolution of $Sb_{2}S_{3}$ thin film structures deposited on\nquartz (transmissive) and gold (reflective) substrates are experimentally\ninvestigated and supported by theoretical modelling. Using this approach, the\nsmallest linewidth fabricated is measured at 178 nm. Consequently, multiple\ntest patterns are demonstrated showing versatile functionalities. Functional\nFresnel Zone Plates (FZPs) with varying focal length are fabricated and\ncharacterized. This study provides a significantly simplified approach for\nrealizing $Sb_{2}S_{3}$ based integrated photonic devices.","main_category":"physics.optics","categories":"physics.optics,cond-mat.mtrl-sci,physics.ins-det","published":"2025-04-22T12:53:43Z"}
{"aid":"http://arxiv.org/abs/2504.15899v1","title":"RaSCL: Radar to Satellite Crossview Localization","summary":"GNSS is unreliable, inaccurate, and insufficient in many real-time autonomous\nfield applications. In this work, we present a GNSS-free global localization\nsolution that contains a method of registering imaging radar on the ground with\noverhead RGB imagery, with joint optimization of relative poses from odometry\nand global poses from our overhead registration. Previous works have used\nvarious combinations of ground sensors and overhead imagery, and different\nfeature extraction and matching methods. These include various handcrafted and\ndeep-learning-based methods for extracting features from overhead imagery. Our\nwork presents insights on extracting essential features from RGB overhead\nimages for effective global localization against overhead imagery using only\nground radar and a single georeferenced initial guess. We motivate our method\nby evaluating it on datasets in diverse geographic conditions and robotic\nplatforms, including on an Unmanned Surface Vessel (USV) as well as urban and\nsuburban driving datasets.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-22T13:41:04Z"}
{"aid":"http://arxiv.org/abs/2504.15905v1","title":"GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs\n  Computing in Edge Network","summary":"With the exponential growth of Internet of Things (IoT) devices, edge\ncomputing (EC) is gradually playing an important role in providing\ncost-effective services. However, existing approaches struggle to perform well\nin graph-structured scenarios where user data is correlated, such as traffic\nflow prediction and social relationship recommender systems. In particular,\ngraph neural network (GNN)-based approaches lead to expensive server\ncommunication cost. To address this problem, we propose GraphEdge, an efficient\nGNN-based EC architecture. It considers the EC system of GNN tasks, where there\nare associations between users and it needs to take into account the task data\nof its neighbors when processing the tasks of a user. Specifically, the\narchitecture first perceives the user topology and represents their data\nassociations as a graph layout at each time step. Then the graph layout is\noptimized by calling our proposed hierarchical traversal graph cut algorithm\n(HiCut), which cuts the graph layout into multiple weakly associated subgraphs\nbased on the aggregation characteristics of GNN, and the communication cost\nbetween different subgraphs during GNN inference is minimized. Finally, based\non the optimized graph layout, our proposed deep reinforcement learning (DRL)\nbased graph offloading algorithm (DRLGO) is executed to obtain the optimal\noffloading strategy for the tasks of users, the offloading strategy is\nsubgraph-based, it tries to offload user tasks in a subgraph to the same edge\nserver as possible while minimizing the task processing time and energy\nconsumption of the EC system. Experimental results show the good effectiveness\nand dynamic adaptation of our proposed architecture and it also performs well\neven in dynamic scenarios.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T13:45:13Z"}
{"aid":"http://arxiv.org/abs/2504.15908v1","title":"Learning the Spoofability of Limit Order Books With Interpretable\n  Probabilistic Neural Networks","summary":"This paper investigates real-time detection of spoofing activity in limit\norder books, focusing on cryptocurrency centralized exchanges. We first\nintroduce novel order flow variables based on multi-scale Hawkes processes that\naccount both for the size and placement distance from current best prices of\nnew limit orders. Using a Level-3 data set, we train a neural network model to\npredict the conditional probability distribution of mid price movements based\non these features. Our empirical analysis highlights the critical role of the\nposting distance of limit orders in the price formation process, showing that\nspoofing detection models that do not take the posting distance into account\nare inadequate to describe the data. Next, we propose a spoofing detection\nframework based on the probabilistic market manipulation gain of a spoofing\nagent and use the previously trained neural network to compute the expected\ngain. Running this algorithm on all submitted limit orders in the period\n2024-12-04 to 2024-12-07, we find that 31% of large orders could spoof the\nmarket. Because of its simple neuronal architecture, our model can be run in\nreal time. This work contributes to enhancing market integrity by providing a\nrobust tool for monitoring and mitigating spoofing in both cryptocurrency\nexchanges and traditional financial markets.","main_category":"q-fin.TR","categories":"q-fin.TR,q-fin.ST","published":"2025-04-22T13:52:55Z"}
{"aid":"http://arxiv.org/abs/2504.15925v1","title":"Improving robustness and training efficiency of machine-learned\n  potentials by incorporating short-range empirical potentials","summary":"Machine learning force fields (MLFFs) are powerful tools for materials\nmodeling, but their performance is often limited by training dataset quality,\nparticularly the lack of rare event configurations. This limitation undermines\ntheir accuracy and robustness in long-time and large-scale molecular dynamics\nsimulations. In this work, we present a hybrid MLFF framework that integrates\nan empirical short-range repulsive potential and demonstrates improved\nrobustness and training efficiency. Using solid electrolyte\nLi$_7$La$_3$Zr$_2$O$_{12}$ (LLZO) as a model system, we show that purely\ndata-driven MLFFs fail to prevent unphysical atomistic clustering in extended\nsimulations due to inadequate short-range repulsion. In contrast, the hybrid\nforce field eliminates these artifacts, enabling stable long-time simulations,\nwhich are critical for studying various properties of LLZO. The hybrid\nframework also reduces the need for extensive active learning and performs well\nwith just 25 training configurations. By combining physics-driven constraints\nwith data-driven flexibility, this approach is compatible with most existing\nMLFF architectures and establishes a universal paradigm for developing robust,\ntraining-efficient force fields for complex material systems.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-22T14:12:45Z"}
{"aid":"http://arxiv.org/abs/2504.15927v1","title":"New Recipe for Semi-supervised Community Detection: Clique Annealing\n  under Crystallization Kinetics","summary":"Semi-supervised community detection methods are widely used for identifying\nspecific communities due to the label scarcity. Existing semi-supervised\ncommunity detection methods typically involve two learning stages learning in\nboth initial identification and subsequent adjustment, which often starts from\nan unreasonable community core candidate. Moreover, these methods encounter\nscalability issues because they depend on reinforcement learning and generative\nadversarial networks, leading to higher computational costs and restricting the\nselection of candidates. To address these limitations, we draw a parallel\nbetween crystallization kinetics and community detection to integrate the\nspontaneity of the annealing process into community detection. Specifically, we\nliken community detection to identifying a crystal subgrain (core) that expands\ninto a complete grain (community) through a process similar to annealing. Based\non this finding, we propose CLique ANNealing (CLANN), which applies kinetics\nconcepts to community detection by integrating these principles into the\noptimization process to strengthen the consistency of the community core.\nSubsequently, a learning-free Transitive Annealer was employed to refine the\nfirst-stage candidates by merging neighboring cliques and repositioning the\ncommunity core, enabling a spontaneous growth process that enhances\nscalability. Extensive experiments on \\textbf{43} different network settings\ndemonstrate that CLANN outperforms state-of-the-art methods across multiple\nreal-world datasets, showcasing its exceptional efficacy and efficiency in\ncommunity detection.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-04-22T14:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.15933v1","title":"Low-Rank Adaptation of Neural Fields","summary":"Processing visual data often involves small adjustments or sequences of\nchanges, such as in image filtering, surface smoothing, and video storage.\nWhile established graphics techniques like normal mapping and video compression\nexploit redundancy to encode such small changes efficiently, the problem of\nencoding small changes to neural fields (NF) -- neural network\nparameterizations of visual or physical functions -- has received less\nattention.\n  We propose a parameter-efficient strategy for updating neural fields using\nlow-rank adaptations (LoRA). LoRA, a method from the parameter-efficient\nfine-tuning LLM community, encodes small updates to pre-trained models with\nminimal computational overhead. We adapt LoRA to instance-specific neural\nfields, avoiding the need for large pre-trained models yielding a pipeline\nsuitable for low-compute hardware.\n  We validate our approach with experiments in image filtering, video\ncompression, and geometry editing, demonstrating its effectiveness and\nversatility for representing neural field updates.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-22T14:21:34Z"}
{"aid":"http://arxiv.org/abs/2504.15972v1","title":"Bug Destiny Prediction in Large Open-Source Software Repositories\n  through Sentiment Analysis and BERT Topic Modeling","summary":"This study explores a novel approach to predicting key bug-related outcomes,\nincluding the time to resolution, time to fix, and ultimate status of a bug,\nusing data from the Bugzilla Eclipse Project. Specifically, we leverage\nfeatures available before a bug is resolved to enhance predictive accuracy. Our\nmethodology incorporates sentiment analysis to derive both an emotionality\nscore and a sentiment classification (positive or negative). Additionally, we\nintegrate the bug's priority level and its topic, extracted using a BERTopic\nmodel, as features for a Convolutional Neural Network (CNN) and a Multilayer\nPerceptron (MLP). Our findings indicate that the combination of BERTopic and\nsentiment analysis can improve certain model performance metrics. Furthermore,\nwe observe that balancing model inputs enhances practical applicability, albeit\nat the cost of a significant reduction in accuracy in most cases. To address\nour primary objectives, predicting time-to-resolution, time-to-fix, and bug\ndestiny, we employ both binary classification and exact time value predictions,\nallowing for a comparative evaluation of their predictive effectiveness.\nResults demonstrate that sentiment analysis serves as a valuable predictor of a\nbug's eventual outcome, particularly in determining whether it will be fixed.\nHowever, its utility is less pronounced when classifying bugs into more complex\nor unconventional outcome categories.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-22T15:18:14Z"}
{"aid":"http://arxiv.org/abs/2504.15973v1","title":"Duality Anomalies in Linearized Gravity","summary":"Classical linearized gravity admits a dual formulation in terms of a\nhigher-rank tensor field. Proposing a prescription for the instanton sectors of\nlinearized gravity and its dual, we show that they may be quantum inequivalent\nin even dimensions. The duality anomaly is obtained by resolving the dual\ngraviton theories into vector-valued $p$-form electrodynamics and is controlled\nby the Reidemeister torsion, Ray-Singer torsion and Euler characteristic of the\ncotangent bundle. Under the proposed instanton prescription the duality anomaly\nvanishes for an odd number of spacetime dimensions as a consequence of the\ncelebrated Cheeger-M\\\"uller theorem. In the presence of a gravitational\n$\\theta$-term, the partition function is a modular form in direct analogy to\nAbelian S-duality for Maxwell theory.","main_category":"hep-th","categories":"hep-th,gr-qc,math-ph,math.MP","published":"2025-04-22T15:18:47Z"}
{"aid":"http://arxiv.org/abs/2504.15978v1","title":"Unveiling the electrodynamic nature of spacetime collisions","summary":"Gravitational waves from merging binary black holes present exciting\nopportunities for understanding fundamental aspects of gravity, including\nnonlinearities in the strong-field regime. One challenge in studying and\ninterpreting the dynamics of binary black hole collisions is the intrinsically\ngeometrical nature of spacetime, which in many ways is unlike that of other\nclassical field theories. By exactly recasting Einstein's equations into a set\nof coupled nonlinear Maxwell equations closely resembling classical\nelectrodynamics, we visualize the intricate dynamics of gravitational electric\nand magnetic fields during inspiral, merger and ring-down of a binary black\nhole collision.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th,physics.plasm-ph","published":"2025-04-22T15:27:20Z"}
{"aid":"http://arxiv.org/abs/2504.15985v1","title":"Modeling and Forecasting Realized Volatility with Multivariate\n  Fractional Brownian Motion","summary":"A multivariate fractional Brownian motion (mfBm) with component-wise Hurst\nexponents is used to model and forecast realized volatility. We investigate the\ninterplay between correlation coefficients and Hurst exponents and propose a\nnovel estimation method for all model parameters, establishing consistency and\nasymptotic normality of the estimators. Additionally, we develop a\ntime-reversibility test, which is typically not rejected by real volatility\ndata. When the data-generating process is a time-reversible mfBm, we derive\noptimal forecasting formulae and analyze their properties. A key insight is\nthat an mfBm with different Hurst exponents and non-zero correlations can\nreduce forecasting errors compared to a one-dimensional model. Consistent with\noptimal forecasting theory, out-of-sample forecasts using the time-reversible\nmfBm show improvements over univariate fBm, particularly when the estimated\nHurst exponents differ significantly. Empirical results demonstrate that\nmfBm-based forecasts outperform the (vector) HAR model.","main_category":"q-fin.ST","categories":"q-fin.ST","published":"2025-04-22T15:38:31Z"}
{"aid":"http://arxiv.org/abs/2504.15991v1","title":"Efficient Adaptation of Deep Neural Networks for Semantic Segmentation\n  in Space Applications","summary":"In recent years, the application of Deep Learning techniques has shown\nremarkable success in various computer vision tasks, paving the way for their\ndeployment in extraterrestrial exploration. Transfer learning has emerged as a\npowerful strategy for addressing the scarcity of labeled data in these novel\nenvironments. This paper represents one of the first efforts in evaluating the\nfeasibility of employing adapters toward efficient transfer learning for rock\nsegmentation in extraterrestrial landscapes, mainly focusing on lunar and\nmartian terrains. Our work suggests that the use of adapters, strategically\nintegrated into a pre-trained backbone model, can be successful in reducing\nboth bandwidth and memory requirements for the target extraterrestrial device.\nIn this study, we considered two memory-saving strategies: layer fusion (to\nreduce to zero the inference overhead) and an ``adapter ranking'' (to also\nreduce the transmission cost). Finally, we evaluate these results in terms of\ntask performance, memory, and computation on embedded devices, evidencing\ntrade-offs that open the road to more research in the field.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-22T15:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.15996v1","title":"Small-scale dynamic phenomena associated with interacting fan-spine\n  topologies: quiet-Sun Ellerman bombs, UV brightenings, and chromospheric\n  inverted-Y-shaped jets","summary":"QSEBs are small-scale magnetic reconnection events in lower solar atmosphere.\nSometimes, they exhibit transition region counterparts, known as UV\nbrightenings. Magnetic field extrapolations suggest that QSEBs can occur at\nvarious locations of a fan-spine topology, with UV brightening occurring at\nnull point through a common reconnection process. We aim to understand how\ncomplex magnetic configurations like interacting fan-spine topologies can cause\nsmall-scale dynamic phenomena in lower atmosphere. QSEBs were detected using\nk-means clustering on Hbeta observations from Swedish 1-m Solar Telescope\n(SST). Further, chromospheric inverted-Y-shaped jets were identified in the\nHbeta blue wing. Magnetic field topologies were determined through potential\nfield extrapolations from photospheric magnetograms using the Fe I 6173 A line.\nUV brightenings were detected in IRIS 1400 A SJI. We identify two distinct\nmagnetic configurations associated with QSEBs, UV brightenings, and\nchromospheric inverted-Y-shaped jets. The first involves a nested fan-spine\nstructure where, due to flux emergence, an inner 3D null forms inside fan\nsurface of an outer 3D null with some overlap. QSEBs occur at two footpoints\nalong the shared fan surface, with UV brightening located near the outer 3D\nnull point. The jet originates close to the two QSEBs and follows the path of\nhigh squashing factor Q. We discuss a comparable scenario using a numerical\nsimulation. In second case, two adjacent fan-spine topologies share fan\nfootpoints at a common positive polarity patch, with the QSEB, along with a\nchromospheric inverted-Y-shaped jet, occurring at the intersection having high\nQ values. This study demonstrates through observational and modelling support\nthat associated QSEBs, UV brightenings, and chromospheric inverted-Y-shaped\njets share a common origin driven by magnetic reconnection between interacting\nfan-spine topologies.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-22T16:01:37Z"}
{"aid":"http://arxiv.org/abs/2504.16000v1","title":"How Private is Your Attention? Bridging Privacy with In-Context Learning","summary":"In-context learning (ICL)-the ability of transformer-based models to perform\nnew tasks from examples provided at inference time-has emerged as a hallmark of\nmodern language models. While recent works have investigated the mechanisms\nunderlying ICL, its feasibility under formal privacy constraints remains\nlargely unexplored. In this paper, we propose a differentially private\npretraining algorithm for linear attention heads and present the first\ntheoretical analysis of the privacy-accuracy trade-off for ICL in linear\nregression. Our results characterize the fundamental tension between\noptimization and privacy-induced noise, formally capturing behaviors observed\nin private training via iterative methods. Additionally, we show that our\nmethod is robust to adversarial perturbations of training prompts, unlike\nstandard ridge regression. All theoretical findings are supported by extensive\nsimulations across diverse settings.","main_category":"stat.ML","categories":"stat.ML,cs.AI,cs.CL,cs.CR,cs.LG","published":"2025-04-22T16:05:26Z"}
{"aid":"http://arxiv.org/abs/2504.16027v1","title":"Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs\n  DeepSeek-V3","summary":"Determining the most effective Large Language Model for code smell detection\npresents a complex challenge. This study introduces a structured methodology\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\ncode samples consistently annotated with known smells. The dataset spans four\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\nmetrics. Our analysis covers three levels of detail: overall performance,\ncategory level performance, and individual code smell type performance.\nAdditionally, we explore cost effectiveness by comparing the token based\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\nDeepSeek V3. The study also includes a cost analysis relative to traditional\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\nfor practitioners in selecting an efficient, cost effective solution for\nautomated code smell detection","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.LG,cs.PL","published":"2025-04-22T16:44:39Z"}
{"aid":"http://arxiv.org/abs/2504.16028v1","title":"Hessian Riemannian Flow For Multi-Population Wardrop Equilibrium","summary":"In this paper, we address the problem of optimizing flows on generalized\ngraphs that feature multiple entry points and multiple populations, each with\nvarying cost structures. We tackle this problem by considering the\nmulti-population Wardrop equilibrium, defined through variational inequalities.\nWe rigorously analyze the existence and uniqueness of the Wardrop equilibrium.\nFurthermore, we introduce an efficient numerical method to find the solution.\nIn particular, we reformulate the equilibrium problem as a distributed\noptimization problem over subgraphs and introduce a novel Hessian Riemannian\nflow method, a Riemannian-manifold-projected Hessian flow, to efficiently\ncompute a solution. Finally, we demonstrate the effectiveness of our approach\nthrough examples in urban traffic management, including routing for diverse\nvehicle types and strategies for minimizing emissions in congested\nenvironments.","main_category":"eess.SY","categories":"eess.SY,cs.MA,cs.SY,math.OC","published":"2025-04-22T16:45:29Z"}
{"aid":"http://arxiv.org/abs/2504.16036v1","title":"Rotational ultrasound and photoacoustic tomography of the human body","summary":"Imaging the human body's morphological and angiographic information is\nessential for diagnosing, monitoring, and treating medical conditions.\nUltrasonography performs the morphological assessment of the soft tissue based\non acoustic impedance variations, whereas photoacoustic tomography (PAT) can\nvisualize blood vessels based on intrinsic hemoglobin absorption.\nThree-dimensional (3D) panoramic imaging of the vasculature is generally not\npractical in conventional ultrasonography with limited field-of-view (FOV)\nprobes, and PAT does not provide sufficient scattering-based soft tissue\nmorphological contrast. Complementing each other, fast panoramic rotational\nultrasound tomography (RUST) and PAT are integrated for hybrid rotational\nultrasound and photoacoustic tomography (RUS-PAT), which obtains 3D ultrasound\nstructural and PAT angiographic images of the human body quasi-simultaneously.\nThe RUST functionality is achieved in a cost-effective manner using a\nsingle-element ultrasonic transducer for ultrasound transmission and rotating\narc-shaped arrays for 3D panoramic detection. RUST is superior to conventional\nultrasonography, which either has a limited FOV with a linear array or is\nhigh-cost with a hemispherical array that requires both transmission and\nreceiving. By switching the acoustic source to a light source, the system is\nconveniently converted to PAT mode to acquire angiographic images in the same\nregion. Using RUS-PAT, we have successfully imaged the human head, breast,\nhand, and foot with a 10 cm diameter FOV, submillimeter isotropic resolution,\nand 10 s imaging time for each modality. The 3D RUS-PAT is a powerful tool for\nhigh-speed, 3D, dual-contrast imaging of the human body with potential for\nrapid clinical translation.","main_category":"physics.med-ph","categories":"physics.med-ph,eess.SP,physics.app-ph","published":"2025-04-22T17:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.16044v1","title":"Search for Axionlike Dark Matter Using Liquid-State Nuclear Magnetic\n  Resonance","summary":"We search for dark matter in the form of axionlike particles (ALPs) in the\nmass range $5.576741 \\,\\mathrm{neV/c^2}$ - $5.577733\\,\\mathrm{neV/c^2}$ by\nprobing their possible coupling to fermion spins through the ALP field\ngradient. This is achieved by performing proton nuclear magnetic resonance\nspectroscopy on a sample of methanol as a technical demonstration of the Cosmic\nAxion Spin Precession Experiment Gradient (CASPEr-Gradient) Low-Field\napparatus. Searching for spin-coupled ALP dark matter in this mass range with\nassociated Compton frequencies in a 240 Hz window centered at 1.348570 MHz\nresulted in a sensitivity to the ALP-proton coupling constant of\n$g_{\\mathrm{ap}} \\approx 3 \\times 10^{-2}\\,\\mathrm{GeV}^{-1}$. This\nnarrow-bandwidth search serves as a proof-of-principle and a commissioning\nmeasurement, validating our methodology and demonstrating the experiment's\ncapabilities. It opens the door to probing large swaths of hitherto unexplored\nmass-coupling parameter space in the future by using hyperpolarized samples.","main_category":"hep-ex","categories":"hep-ex,physics.atom-ph","published":"2025-04-22T17:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.16080v1","title":"From Reflection to Perfection: Scaling Inference-Time Optimization for\n  Text-to-Image Diffusion Models via Reflection Tuning","summary":"Recent text-to-image diffusion models achieve impressive visual quality\nthrough extensive scaling of training data and model parameters, yet they often\nstruggle with complex scenes and fine-grained details. Inspired by the\nself-reflection capabilities emergent in large language models, we propose\nReflectionFlow, an inference-time framework enabling diffusion models to\niteratively reflect upon and refine their outputs. ReflectionFlow introduces\nthree complementary inference-time scaling axes: (1) noise-level scaling to\noptimize latent initialization; (2) prompt-level scaling for precise semantic\nguidance; and most notably, (3) reflection-level scaling, which explicitly\nprovides actionable reflections to iteratively assess and correct previous\ngenerations. To facilitate reflection-level scaling, we construct GenRef, a\nlarge-scale dataset comprising 1 million triplets, each containing a\nreflection, a flawed image, and an enhanced image. Leveraging this dataset, we\nefficiently perform reflection tuning on state-of-the-art diffusion\ntransformer, FLUX.1-dev, by jointly modeling multimodal inputs within a unified\nframework. Experimental results show that ReflectionFlow significantly\noutperforms naive noise-level scaling methods, offering a scalable and\ncompute-efficient solution toward higher-quality image synthesis on challenging\ntasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.16381v1","title":"PINN-MEP: Continuous Neural Representations for Minimum-Energy Path\n  Discovery in Molecular Systems","summary":"Characterizing conformational transitions in physical systems remains a\nfundamental challenge in the computational sciences. Traditional sampling\nmethods like molecular dynamics (MD) or MCMC often struggle with the\nhigh-dimensional nature of molecular systems and the high energy barriers of\ntransitions between stable states. While these transitions are rare events in\nsimulation timescales, they often represent the most biologically significant\nprocesses - for example, the conformational change of an ion channel protein\nfrom its closed to open state, which controls cellular ion flow and is crucial\nfor neural signaling. Such transitions in real systems may take milliseconds to\nseconds but could require months or years of continuous simulation to observe\neven once. We present a method that reformulates transition path generation as\na continuous optimization problem solved through physics-informed neural\nnetworks (PINNs) inspired by string methods for minimum-energy path (MEP)\ngeneration. By representing transition paths as implicit neural functions and\nleveraging automatic differentiation with differentiable molecular dynamics\nforce fields, our method enables the efficient discovery of physically\nrealistic transition pathways without requiring expensive path sampling. We\ndemonstrate our method's effectiveness on two proteins, including an explicitly\nhydrated bovine pancreatic trypsin inhibitor (BPTI) system with over 8,300\natoms.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cs.AI,physics.comp-ph","published":"2025-04-23T03:02:29Z"}
{"aid":"http://arxiv.org/abs/2504.16394v1","title":"ConTextual: Improving Clinical Text Summarization in LLMs with\n  Context-preserving Token Filtering and Knowledge Graphs","summary":"Unstructured clinical data can serve as a unique and rich source of\ninformation that can meaningfully inform clinical practice. Extracting the most\npertinent context from such data is critical for exploiting its true potential\ntoward optimal and timely decision-making in patient care. While prior research\nhas explored various methods for clinical text summarization, most prior\nstudies either process all input tokens uniformly or rely on heuristic-based\nfilters, which can overlook nuanced clinical cues and fail to prioritize\ninformation critical for decision-making. In this study, we propose Contextual,\na novel framework that integrates a Context-Preserving Token Filtering method\nwith a Domain-Specific Knowledge Graph (KG) for contextual augmentation. By\npreserving context-specific important tokens and enriching them with structured\nknowledge, ConTextual improves both linguistic coherence and clinical fidelity.\nOur extensive empirical evaluations on two public benchmark datasets\ndemonstrate that ConTextual consistently outperforms other baselines. Our\nproposed approach highlights the complementary role of token-level filtering\nand structured retrieval in enhancing both linguistic and clinical integrity,\nas well as offering a scalable solution for improving precision in clinical\ntext generation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T03:42:46Z"}
{"aid":"http://arxiv.org/abs/2504.16395v1","title":"A Nonlocal Biharmonic Model with $$-Convergence to Local Model","summary":"Nonlocal models and their associated theories have been extensively\ninvestigated in recent years. Among these, nonlocal versions of the classical\nLaplace operator have attracted the most attention, while higher-order nonlocal\noperators have been studied far less. In this work, we focus on the nonlocal\ncounterpart of the classical biharmonic operator together with clamped boundary\ncondition ($u$ and $\\frac{\\partial u}{\\partial n}$ are given on boundary). We\ndevelop the variational formulation of a nonlocal biharmonic model, establish\nthe existence and uniqueness of its solution, and analyze its convergence as\nthe nonlocal horizon approaches zero. In addition, numerical experiments are\npresented to further illustrate the analytical properties of the model and its\nsolution.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T03:45:47Z"}
{"aid":"http://arxiv.org/abs/2504.16409v1","title":"A Molecular Dynamics Study of Size Effects for Critical Resolved Shear\n  Stress in Nickel Superalloys","summary":"We present in this work a molecular dynamics study of a size effect relating\nto the volume fraction of gamma-prime precipitate of edge dislocation motion in\na simple model of Nickel superalloys. We model the superalloy as periodically\nspaced cubic gamma-prime precipitates inside a uniform gamma matrix. We then\nanalyze the motion of paired edge dislocations in the gamma phase when subject\nto an external shear stress for various volume fractions of the gamma-prime\nprecipitate for a wide range of temperatures, from 300 K to 700 K. While the\nvariation of dislocation velocity is not significant, the critical resolved\nshear stress is found to exhibit a power law dependence on the volume fraction\nof the gamma-prime precipitate with two distinct regimes which have similar\nexponent but markedly different prefactors; we also observe that this\ntwo-regime behavior remains true across a wide range of temperatures. We\npresent a detailed analysis of this behavior and reduce it to a linear\ndependence of the critical resolved shear stress on the length of the\ngamma-prime precipitate along the direction of dislocation motion. We further\nidentify the critical length scale underlying the transition between the two\nobserved regimes as the total core width of the paired dislocations in a pure\ngamma-prime system, which includes in addition to the complex stacking fault\nseparating the partials of the paired dislocations the width of the anti-phase\nboundary that is formed between the super-dislocations. The results presented\nin this work provides new details on the strengthening effect of gamma-prime\nprecipitates in nickel superalloys and also has important implications for\nlarger scale dislocation dynamics studies for nickel superalloys.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T04:24:03Z"}
{"aid":"http://arxiv.org/abs/2504.16418v1","title":"Scalable Data-Driven Basis Selection for Linear Machine Learning\n  Interatomic Potentials","summary":"Machine learning interatomic potentials (MLIPs) provide an effective approach\nfor accurately and efficiently modeling atomic interactions, expanding the\ncapabilities of atomistic simulations to complex systems. However, a priori\nfeature selection leads to high complexity, which can be detrimental to both\ncomputational cost and generalization, resulting in a need for hyperparameter\ntuning. We demonstrate the benefits of active set algorithms for automated\ndata-driven feature selection. The proposed methods are implemented within the\nAtomic Cluster Expansion (ACE) framework. Computational tests conducted on a\nvariety of benchmark datasets indicate that sparse ACE models consistently\nenhance computational efficiency, generalization accuracy and interpretability\nover dense ACE models. An added benefit of the proposed algorithms is that they\nproduce entire paths of models with varying cost/accuracy ratio.","main_category":"physics.comp-ph","categories":"physics.comp-ph,math.OC","published":"2025-04-23T04:53:29Z"}
{"aid":"http://arxiv.org/abs/2504.16428v1","title":"Energy Rates Due to Weak Decay Rates of Vanadium Isotopes in Stellar\n  Environment","summary":"The neutrino cooling and gamma heating rates are considered as an important\ninput needed to study the final phases of the evolution of high-mass stars. The\nweak-interaction mediated processes, namely the $\\beta$-decay and electron\ncapture, significantly change the lepton to baryon ratio and accelerate the\ncontraction of the core. The emission of resulting neutrinos/antineutrinos\ntends to cool the stellar core. On the other hand, gamma rays are produced\nbecause of electron capture and $\\beta$-decay to excited states in daughter\nnuclei. These gamma rays heat the core and contribute to an increase of entropy\nwhich may cause convection to occur.\n  In the present work, the weak-interaction heating and cooling rates on a\nchain of twenty-two isotopes of vanadium having mass in the range $43-64$ have\nbeen estimated using the proton-neutron quasiparticle random phase\napproximation theory. The rates have been computed for the temperature ranging\nfrom ($10^{7} - 3 \\times 10^{10}$)\\;K and for the density range\n($10-10^{11}$)\\;g/cm$^{3}$. Our calculated neutrino energy loss rates have also\nbeen compared with the previously reported rates calculated using other\ntheoretical models. At high stellar temperatures, our rates are larger by 1-2\norders of magnitude as compared to previous results.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-23T05:25:42Z"}
{"aid":"http://arxiv.org/abs/2504.16438v1","title":"Private Federated Learning using Preference-Optimized Synthetic Data","summary":"In practical settings, differentially private Federated learning (DP-FL) is\nthe dominant method for training models from private, on-device client data.\nRecent work has suggested that DP-FL may be enhanced or outperformed by methods\nthat use DP synthetic data (Wu et al., 2024; Hou et al., 2024). The primary\nalgorithms for generating DP synthetic data for FL applications require careful\nprompt engineering based on public information and/or iterative private client\nfeedback. Our key insight is that the private client feedback collected by\nprior DP synthetic data methods (Hou et al., 2024; Xie et al., 2024) can be\nviewed as a preference ranking. Our algorithm, Preference Optimization for\nPrivate Client Data (POPri) harnesses client feedback using preference\noptimization algorithms such as Direct Preference Optimization (DPO) to\nfine-tune LLMs to generate high-quality DP synthetic data. To evaluate POPri,\nwe release LargeFedBench, a new federated text benchmark for uncontaminated LLM\nevaluations on federated client data. POPri substantially improves the utility\nof DP synthetic data relative to prior work on LargeFedBench datasets and an\nexisting benchmark from Xie et al. (2024). POPri closes the gap between\nnext-token prediction accuracy in the fully-private and non-private settings by\nup to 68%, compared to 52% for prior synthetic data methods, and 10% for\nstate-of-the-art DP federated learning methods. The code and data are available\nat https://github.com/meiyuw/POPri.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CR,cs.DC","published":"2025-04-23T05:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.16453v1","title":"Foliation de Rham cohomology of generic Reeb foliations","summary":"In this paper, we prove that there exists a residual subset of contact forms\n$\\lambda$ (if any) on a compact orientable manifold $M$ for which the foliation\nde Rham cohomology of the associated Reeb foliation\n  $F_\\lambda$ is trivial in that both $H^0(F_\\lambda,{\\mathbb R})$ and\n$H^1(F_\\lambda,{\\mathbb R})$ are isomorphic to $\\mathbb R$. For any choice of\n$\\lambda$ from the aforementioned residual subset, this cohomological result\ncan be restated as any of the following two equivalent statements: (1) The\nfunctional equation $R_{\\lambda}[f] = u$ is \\emph{uniquely} solvable (modulo\nthe addition by constant)\n  for any $u$ satisfying $\\int_M u\\, d\\mu_\\lambda =0$, or (2) The Lie algebra\nof the group of strict contactomorphisms is isomorphic to the span of Reeb\nvector fields, and so isomorphic to the 1 dimensional abelian Lie algebra\n$\\mathbb R$.\n  This result is also a key ingredient for the proof of the generic scarcity\nresult of strict contactomorphisms by Savelyev and the author.","main_category":"math.SG","categories":"math.SG","published":"2025-04-23T06:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.16468v1","title":"HAQA: A Hardware-Guided and Fidelity-Aware Strategy for Efficient Qubit\n  Mapping Optimization","summary":"Quantum algorithms rely on quantum computers for implementation, but the\nphysical connectivity constraints of modern quantum processors impede the\nefficient realization of quantum algorithms. Qubit mapping, a critical\ntechnology for practical quantum computing applications, directly determines\nthe execution efficiency and feasibility of algorithms on superconducting\nquantum processors. Existing mapping methods overlook intractable quantum\nhardware fidelity characteristics, reducing circuit execution quality. They\nalso exhibit prolonged solving times or even failure to complete when handling\nlarge-scale quantum architectures, compromising efficiency. To address these\nchallenges, we propose a novel qubit mapping method HAQA. HAQA first introduces\na community-based iterative region identification strategy leveraging hardware\nconnection topology, achieving effective dimensionality reduction of mapping\nspace. This strategy avoids global search procedures, with complexity analysis\ndemonstrating quadratic polynomial-level acceleration. Furthermore, HAQA\nimplements a hardware-characteristic-based region evaluation mechanism,\nenabling quantitative selection of mapping regions based on fidelity metrics.\nThis approach effectively integrates hardware fidelity information into the\nmapping process, enabling fidelity-aware qubit allocation. Experimental results\ndemonstrate that HAQA significantly improves solving speed and fidelity while\nensuring solution quality. When applied to state-of-the-art quantum mapping\ntechniques Qsynth-v2 and TB-OLSQ2, HAQA achieves acceleration ratios of 632.76\nand 286.87 respectively, while improving fidelity by up to 52.69% and 238.28%","main_category":"quant-ph","categories":"quant-ph,cs.ET","published":"2025-04-23T07:27:27Z"}
{"aid":"http://arxiv.org/abs/2504.16473v1","title":"ERASER: Efficient RTL FAult Simulation Framework with Trimmed Execution\n  Redundancy","summary":"As intelligent computing devices increasingly integrate into human life,\nensuring the functional safety of the corresponding electronic chips becomes\nmore critical. A key metric for functional safety is achieving a sufficient\nfault coverage. To meet this requirement, extensive time-consuming fault\nsimulation of the RTL code is necessary during the chip design phase.The main\noverhead in RTL fault simulation comes from simulating behavioral nodes (always\nblocks). Due to the limited fault propagation capacity, fault simulation\nresults often match the good simulation results for many behavioral nodes. A\nkey strategy for accelerating RTL fault simulation is the identification and\nelimination of redundant simulations. Existing methods detect redundant\nexecutions by examining whether the fault inputs to each RTL node are\nconsistent with the good inputs. However, we observe that this input comparison\nmechanism overlooks a significant amount of implicit redundant execution:\nalthough the fault inputs differ from the good inputs, the node's execution\nresults remain unchanged. Our experiments reveal that this overlooked redundant\nexecution constitutes nearly half of the total execution overhead of behavioral\nnodes, becoming a significant bottleneck in current RTL fault simulation. The\nunderlying reason for this overlooked redundancy is that, in these cases, the\ntrue execution paths within the behavioral nodes are not affected by the\nchanges in input values. In this work, we propose a behavior-level redundancy\ndetection algorithm that focuses on the true execution paths. Building on the\nelimination of redundant executions, we further developed an efficient RTL\nfault simulation framework, Eraser.Experimental results show that compared to\ncommercial tools, under the same fault coverage, our framework achieves a 3.9\n$\\times$ improvement in simulation performance on average.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-23T07:33:44Z"}
{"aid":"http://arxiv.org/abs/2504.16474v1","title":"Seeking Flat Minima over Diverse Surrogates for Improved Adversarial\n  Transferability: A Theoretical Framework and Algorithmic Instantiation","summary":"The transfer-based black-box adversarial attack setting poses the challenge\nof crafting an adversarial example (AE) on known surrogate models that remain\neffective against unseen target models. Due to the practical importance of this\ntask, numerous methods have been proposed to address this challenge. However,\nmost previous methods are heuristically designed and intuitively justified,\nlacking a theoretical foundation. To bridge this gap, we derive a novel\ntransferability bound that offers provable guarantees for adversarial\ntransferability. Our theoretical analysis has the advantages of \\textit{(i)}\ndeepening our understanding of previous methods by building a general attack\nframework and \\textit{(ii)} providing guidance for designing an effective\nattack algorithm. Our theoretical results demonstrate that optimizing AEs\ntoward flat minima over the surrogate model set, while controlling the\nsurrogate-target model shift measured by the adversarial model discrepancy,\nyields a comprehensive guarantee for AE transferability. The results further\nlead to a general transfer-based attack framework, within which we observe that\nprevious methods consider only partial factors contributing to the\ntransferability. Algorithmically, inspired by our theoretical results, we first\nelaborately construct the surrogate model set in which models exhibit diverse\nadversarial vulnerabilities with respect to AEs to narrow an instantiated\nadversarial model discrepancy. Then, a \\textit{model-Diversity-compatible\nReverse Adversarial Perturbation} (DRAP) is generated to effectively promote\nthe flatness of AEs over diverse surrogate models to improve transferability.\nExtensive experiments on NIPS2017 and CIFAR-10 datasets against various target\nmodels demonstrate the effectiveness of our proposed attack.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-23T07:33:45Z"}
{"aid":"http://arxiv.org/abs/2504.16479v1","title":"The Dance of Atoms-De Novo Protein Design with Diffusion Model","summary":"The de novo design of proteins refers to creating proteins with specific\nstructures and functions that do not naturally exist. In recent years, the\naccumulation of high-quality protein structure and sequence data and\ntechnological advancements have paved the way for the successful application of\ngenerative artificial intelligence (AI) models in protein design. These models\nhave surpassed traditional approaches that rely on fragments and\nbioinformatics. They have significantly enhanced the success rate of de novo\nprotein design, and reduced experimental costs, leading to breakthroughs in the\nfield. Among various generative AI models, diffusion models have yielded the\nmost promising results in protein design. In the past two to three years, more\nthan ten protein design models based on diffusion models have emerged. Among\nthem, the representative model, RFDiffusion, has demonstrated success rates in\n25 protein design tasks that far exceed those of traditional methods, and other\nAI-based approaches like RFjoint and hallucination. This review will\nsystematically examine the application of diffusion models in generating\nprotein backbones and sequences. We will explore the strengths and limitations\nof different models, summarize successful cases of protein design using\ndiffusion models, and discuss future development directions.","main_category":"q-bio.BM","categories":"q-bio.BM,cs.AI","published":"2025-04-23T07:45:00Z"}
{"aid":"http://arxiv.org/abs/2504.16491v1","title":"Novel approach to use the Kelvin Probe method ex-situ for measuring the\n  electron emission yield of insulator materials subjected to electron\n  irradiation","summary":"Measuring the total electron emission yield of dielectric materials remains a\nchallenging task. Indeed, the charge induced by irradiation and electron\nemission disturbs the measurement. It is therefore important to quantify this\ncharge during the measurement. Using a Kelvin probe allows both the emission\nyield and the induced charge to be measured. However, this method requires the\nprobe to be placed inside the vacuum chamber, which is often complicated or\neven impossible. We propose a complete redesign of this method to overcome this\nissue. A capacitive coupling now allows the potential probe to be placed\noutside the chamber, in ambient atmosphere. Beyond this major simplification in\nimplementation, we have also introduced several improvements that simplify the\nmeasurement protocol and reduce the overall measurement time. The new method\nwas first validated on a metallic sample (Cu), and subsequently applied to a\npolymer (Kapton).","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-23T08:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.16521v1","title":"Performance Assessment of Hybrid and Digital Irregular Array\n  Configurations for Beyond 100-GHz Multi-User MIMO Systems","summary":"The performance of irregular phased array architectures is assessed in the\ncontext of multi-user multiple-input multiple-output (MU-MIMO) communications\noperating beyond 100 GHz. Realizing half-wavelength spaced planar phased arrays\nis challenging due to wavelength-integrated circuit (IC) size conflict at those\nfrequencies where the antenna dimensions are comparable to IC size. Therefore,\nirregular array architectures such as thinned and clustered arrays are\ndeveloped to mitigate the wavelength-IC size conflict. In the thinned arrays,\nradiating elements are permanently deactivated, while in clustered arrays,\nneighboring elements are grouped into subarrays. Furthermore, irregular arrays\nare integrated with hybrid beamforming architectures to manage the complexity\nintroduced by full digital beamforming, where a single radio frequency chain is\nconnected per power amplifier. An optimization problem is formulated to\ndetermine the optimal arrangement of antenna elements where the trade-off\nbetween spectral efficiency (SE) and sidelobe levels (SLL) can be tuned.\nClustered array configurations are optimized by genetic algorithm and\nAlgorithm-X based methodologies, where the former relies on a randomized search\nand the latter exploits brute-force search, respectively. Furthermore, a\nprototype array is designed on a printed circuit board (PCB) to verify the\nproposed methodologies through full-wave simulations. To have a fair\ncomparison, clustered arrays with a grouping of two and four elements are\ncompared with thinned arrays with half and quarter thinning ratios,\nrespectively. The combination of hybrid and irregular array architectures leads\nto minimal or no performance degradation in the case of hybrid fully connected\narchitectures but severe SE and SLL degradation in the case of hybrid partially\nconnected architectures, respectively.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T08:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.16528v1","title":"Quantitative Strategy Templates","summary":"This paper presents (permissive) \\emph{Quantitative Strategy Templates}\n(QaSTels) to succinctly represent infinitely many winning strategies in\ntwo-player energy and mean-payoff games. This transfers the recently introduced\nconcept of \\emph{Permissive (qualitative) Strategy Templates} (PeSTels) for\n$\\omega$-regular games to games with quantitative objectives. We provide the\ntheoretical and algorithmic foundations of (i) QaSTel synthesis, and (ii) their\n(incremental) combination with PeSTels for games with mixed quantitative and\nqualitative objectives. Using a prototype implementation of our synthesis\nalgorithms, we demonstrate empirically that QaSTels extend the advantageous\nproperties of strategy templates over single winning strategies -- known from\nPeSTels -- to games with (additional) quantitative objectives. This includes\n(i) the enhanced robustness of strategies due to their runtime-adaptability,\nand (ii) the compositionality of templates w.r.t. incrementally arriving\nobjectives. We use control-inspired examples to illustrate these superior\nproperties of QaSTels for CPS design.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T08:53:10Z"}
{"aid":"http://arxiv.org/abs/2504.16544v1","title":"On the zoology of 2d $\\mathcal{N}=(0,2)$ dualities gauge theories with\n  antisymmetric matter","summary":"In this paper we investigate and propose new dualities involving 2d gauge\ntheories with $\\mathcal{N}=(0,2)$ supersymmetry. In the first part of the paper\nwe focus on $\\mathrm{SU}(n)$ gauge theories with two antisymmetric chirals. The\ngauge theories are non-anomalous if we consider, in addition to such matter\ncontent, $n_f$ fundamental and $n_a$ antifundamental chirals, provided the\nconstraint $n_f+n_a=4$. By exploring the five possibile scenarios arising from\nthis constraint we provide in each case evidences of a dual LG description, by\nmatching the 't Hooft anomalies and deriving the relation between the elliptic\ngenera in terms of other more fundamental dualities. In the second part of the\npaper we provide a 4d origin for a gauge/LG duality already stated in the\nliterature, that does not descend from any known s-confining duality. In the\nlast part of the paper we focus on dualities for $\\mathrm{SU}(n)$ and\n$\\mathrm{USp}(2n)$ models with antisymmetric Fermi multiplets, obtained from\ndimensional reduction of 4d parent dualities.","main_category":"hep-th","categories":"hep-th","published":"2025-04-23T09:19:30Z"}
{"aid":"http://arxiv.org/abs/2504.16547v1","title":"Generation of Phonons with Angular Momentum During Ultrafast\n  Demagnetization","summary":"A major question in the field of femtosecond laser-induced demagnetization is\nwhereto the angular momentum lost by the electrons is transferred. Recent\nultrafast electron diffraction measurements [Tauchert \\textit{et al.}, Nature\n{\\bf 602}, 73 (2022)] suggest that this angular momentum is transferred to the\nrotational motion of atoms on a sub-picosecond timescale, but a theory\nconfirmation of this proposition has yet to be given. Here we investigate the\ncoupled electron-nuclear dynamics during ultrafast demagnetization of L1$_0$\nFePt, using Ehrenfest nuclear dynamics simulations combined with the\ntime-dependent density functional theory (TDDFT) framework. We demonstrate that\natomic rotations appear, i.e., the generation of phonons carrying finite\nangular momentum following ultrafast demagnetization. We further show that both\nultrafast demagnetization and the generation of phonons with angular momentum\narise from symmetry constraints imposed by the spin-orbit coupling, thus\nproviding insight in spin-phonon interaction at ultrafast timescales.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.atom-ph","published":"2025-04-23T09:23:31Z"}
{"aid":"http://arxiv.org/abs/2504.16554v1","title":"Temperature switchable self-propulsion activity of liquid crystalline\n  microdroplets","summary":"We report on a switchable emulsion droplet microswimmer by utilizing a\ntemperature-dependent transition of the droplet phase. The droplets, made from\na liquid crystalline (LC) smectic phase material ($T =$ 25 $^{\\circ}$C),\nself-propel only in their nematic and isotropic phases at elevated temperatures\n($T\\ge$ 33.5 $^{\\circ}$C). This transition between motile and non-motile states\nis fully reversible - in the motile state, the droplets exhibit persistent\nmotion and directional memory over multiple heating-cooling cycles. Further, we\ndistinguish the state of rest from the state of motion by characterizing the\nchemical and hydrodynamic fields of the droplets. Next, we map the motility\nbehaviour of the droplets across varying surfactant concentrations and\ntemperatures, observing that swimming occurs only at sufficiently high\nsurfactant concentrations above and temperatures above the smectic-nematic\nphase transition temperature $\\textit{i.e.}$ $T\\ge$ 33.5 $^{\\circ}$C. Our work\nenvisions the potential of LC emulsion droplets as switchable microswimmers.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-23T09:32:19Z"}
{"aid":"http://arxiv.org/abs/2504.16561v1","title":"Performance Analysis of MDI-QKD in Thermal-Loss and Phase Noise Channels","summary":"Measurement-device-independent quantum key distribution (MDI-QKD), enhances\nquantum cryptography by mitigating detector-side vulnerabilities. This study\nanalyzes MDI-QKD performance in thermal-loss and phase noise channels, modeled\nas depolarizing and dephasing channels to capture thermal and phase noise\neffects. Based on this channel framework, we derive analytical expressions for\nBell state measurement probabilities, quantum bit error rates (QBER), and\nsecret key rates (SKR) of MDI-QKD. Our simulations reveal that SKR decreases\nexponentially with transmission distance, with performance further degraded by\nincreasing thermal noise and phase noise, particularly under high thermal noise\nconditions. These findings offer insights into enhancing MDI-QKD's noise\nresilience, supporting secure key generation in practical, noisy environments.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T09:39:34Z"}
{"aid":"http://arxiv.org/abs/2504.16566v1","title":"Optically detected and radio wave-controlled spin chemistry in\n  cryptochrome","summary":"Optically addressable spin systems, such as nitrogen-vacancy (NV) centers in\ndiamond, have been widely studied for quantum sensing applications. In this\nwork, we demonstrate that flavin-based cryptochrome proteins, which generate\nradical pairs upon optical excitation, also exhibit optically detected magnetic\nresonance. We further show that this optical spin interface is tunable by the\nprotein structure. These findings establish radical pairs in proteins as a\nnovel platform for optically addressable spin systems and magnetic field\nsensors. Additionally, the ability to control spin transitions introduces a new\nclass of biophysical tools that hold promise for enabling multiplexed\nfluorescence microscopy. Importantly, due to the spin-selective nature of\nradical pair chemistry, the results lay the groundwork for radiofrequency-based\nmanipulation of biological systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T09:45:30Z"}
{"aid":"http://arxiv.org/abs/2504.16580v1","title":"Hyper-Transforming Latent Diffusion Models","summary":"We introduce a novel generative framework for functions by integrating\nImplicit Neural Representations (INRs) and Transformer-based hypernetworks into\nlatent variable models. Unlike prior approaches that rely on MLP-based\nhypernetworks with scalability limitations, our method employs a\nTransformer-based decoder to generate INR parameters from latent variables,\naddressing both representation capacity and computational efficiency. Our\nframework extends latent diffusion models (LDMs) to INR generation by replacing\nstandard decoders with a Transformer-based hypernetwork, which can be trained\neither from scratch or via hyper-transforming-a strategy that fine-tunes only\nthe decoder while freezing the pre-trained latent space. This enables efficient\nadaptation of existing generative models to INR-based representations without\nrequiring full retraining.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-23T10:01:18Z"}
{"aid":"http://arxiv.org/abs/2504.16585v1","title":"Enhancing Variable Selection in Large-scale Logistic Regression:\n  Leveraging Manual Labeling with Beneficial Noise","summary":"In large-scale supervised learning, penalized logistic regression (PLR)\neffectively addresses the overfitting problem by introducing regularization\nterms yet its performance still depends on efficient variable selection\nstrategies. This paper theoretically demonstrates that label noise stemming\nfrom manual labeling, which is solely related to classification difficulty,\nrepresents a type of beneficial noise for variable selection in PLR. This\nbenefit is reflected in a more accurate estimation of the selected non-zero\ncoefficients when compared with the case where only truth labels are used.\nUnder large-scale settings, the sample size for PLR can become very large,\nmaking it infeasible to store on a single machine. In such cases, distributed\ncomputing methods are required to handle PLR model with manual labeling. This\npaper presents a partition-insensitive parallel algorithm founded on the ADMM\n(alternating direction method of multipliers) algorithm to address PLR by\nincorporating manual labeling. The partition insensitivity of the proposed\nalgorithm refers to the fact that the solutions obtained by the algorithm will\nnot change with the distributed storage of data. In addition, the algorithm has\nglobal convergence and a sublinear convergence rate. Experimental results\nindicate that, as compared with traditional variable selection classification\ntechniques, the PLR with manually-labeled noisy data achieves higher estimation\nand classification accuracy across multiple large-scale datasets.","main_category":"cs.LG","categories":"cs.LG,stat.CO,stat.ML","published":"2025-04-23T10:05:54Z"}
{"aid":"http://arxiv.org/abs/2504.16599v1","title":"A two-dimensional swarmalator model with higher-order interactions","summary":"We study a simple two-dimensional swarmalator model that incorporates\nhigher-order phase interactions, uncovering a diverse range of collective\nstates. The latter include spatially coherent and gas-like configurations,\nneither of which appear in models with only pairwise interactions.\nAdditionally, we discover bistability between various states, a phenomenon that\narises directly from the inclusion of higher-order interactions. By analyzing\nseveral of these emergent states analytically, both for identical and\nnonidentical populations of swarmalators, we gain deeper insights into their\nunderlying mechanisms and stability conditions. Our findings broaden the\nunderstanding of swarmalator dynamics and open new avenues for exploring\ncomplex collective behaviors in systems governed by higher-order interactions.","main_category":"nlin.AO","categories":"nlin.AO,math-ph,math.MP","published":"2025-04-23T10:28:13Z"}
{"aid":"http://arxiv.org/abs/2504.16605v1","title":"Phase stabilization of In2Se3 by disordered Ni intercalation and its\n  enhanced thermoelectrical performance","summary":"Van der Waals (vdW) layered materials have gained significant attention owing\nto their distinctive structure and unique properties. The weak interlayer\nbonding in vdW layered materials enables guest atom intercalation, allowing\nprecise tuning of their physical and chemical properties. In this work, a\nternary compound, NixIn2Se3 (x = 0-0.3), with Ni randomly occupying the\ninterlayers of In2Se3, was synthesized via an intercalation route driven by\nelectron injection. The intercalated Ni atoms act as anchor points within the\ninterlayer of In2Se3, which effectively suppresses the phase transition of\nIn2Se3 at elevated temperatures. Furthermore, the disordered Ni intercalation\nsignificantly enhanced the electrical conductivity of In2Se3 through electron\ninjection, while reducing the thermal conductivity due to the interlayer phonon\nscattering, leading to an improved thermoelectric performance. For instance,\nthe thermoelectric figure of merit (ZT) of Ni0.3In2Se3 increased by 86%\n(in-plane) and 222% (out-of-plane) compared to In2Se3 at 500 oC. These findings\nnot only provide an effective strategy to enhance the performance of layered\nthermoelectric materials, but also demonstrate the potential of intercalation\nchemistry for expanding the application scope of van der Waals (vdW) layered\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T10:34:23Z"}
{"aid":"http://arxiv.org/abs/2504.16617v1","title":"Security Science (SecSci), Basic Concepts and Mathematical Foundations","summary":"This textbook compiles the lecture notes from security courses taught at\nOxford in the 2000s, at Royal Holloway in the 2010s, and currently in Hawaii.\nThe early chapters are suitable for a first course in security. The middle\nchapters have been used in advanced courses. Towards the end there are also\nsome research problems.","main_category":"cs.CR","categories":"cs.CR,cs.CY,cs.IT,cs.SI,math.IT,math.LO","published":"2025-04-23T11:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.16618v1","title":"The quantum spin Brauer category","summary":"We introduce a diagrammatic braided monoidal category, the quantum spin\nBrauer category, together with a full functor to the category of\nfinite-dimensional, type $1$ modules for $U_q(\\mathfrak{so}(N))$ or\n$U_q(\\mathfrak{o}(N))$. This functor becomes essentially surjective after\npassing to the idempotent completion. The quantum spin Brauer category can be\nthought of as a quantum version of the spin Brauer category introduced\npreviously by the authors. Alternatively, it is an enlargement of the Kauffman\ncategory, obtained by adding a generating object corresponding to the quantum\nspin module.","main_category":"math.QA","categories":"math.QA,math.RT","published":"2025-04-23T11:06:25Z"}
{"aid":"http://arxiv.org/abs/2504.16621v1","title":"Ultra-high dose rate 6 MeV electron irradiation generates stable\n  [1-$^{13}$C]alanine radicals suitable for medical imaging with dissolution\n  Dynamic Nuclear Polarisation","summary":"Dissolution Dynamic Nuclear Polarisation (dDNP) is an experimental technique\nthat increases the sensitivity of magnetic resonance experiments by more than a\nfactor of $10^5$, permitting isotopically-labelled molecules to be transiently\nvisible in MRI scans with their biochemical fates spatially resolvable over\ntime following injection into a patient. dDNP requires a source of unpaired\nelectrons to be in contact with the isotope-labelled nuclei, cooled to\ntemperatures close to absolute zero, and spin-pumped into a given state by\nmicrowave irradiation. At present, these electrons are typically provided by\nchemical radicals which require removal by filtration prior to injection into\nhumans. Alternative sources include UV irradiation, requiring storing samples\nin liquid nitrogen, or cobalt-60 gamma irradiation, which requires days and\ngenerates polarisation two to three orders of magnitude lower than chemical\nradicals. In this study, we present ultra-high dose rate electron beam\nirradiation as a novel alternative for generating non-persistent radicals in\nglycerol/alanine mixtures. These radicals are stable for months at room\ntemperature, are present at concentrations dependent on irradiation dose, and\ngenerate comparable nuclear polarisation to the typically used trityl radicals\n(20%) through a novel mechanism. The process of their generation inherently\nsterilises samples, and they enable the imaging of alanine metabolism in vivo\nusing dDNP. This new method of generating radicals for dDNP offers the\npotential to report on relevant biological processes while being translatable\nto the clinic.","main_category":"physics.med-ph","categories":"physics.med-ph,q-bio.BM","published":"2025-04-23T11:23:23Z"}
{"aid":"http://arxiv.org/abs/2504.16622v1","title":"Cognitive Silicon: An Architectural Blueprint for Post-Industrial\n  Computing Systems","summary":"Autonomous AI systems reveal foundational limitations in deterministic,\nhuman-authored computing architectures. This paper presents Cognitive Silicon:\na hypothetical full-stack architectural framework projected toward 2035,\nexploring a possible trajectory for cognitive computing system design. The\nproposed architecture would integrate symbolic scaffolding, governed memory,\nruntime moral coherence, and alignment-aware execution across\nsilicon-to-semantics layers. Our design grammar has emerged from dialectical\nco-design with LLMs under asymmetric epistemic conditions--creating structured\nfriction to expose blind spots and trade-offs. The envisioned framework would\nestablish mortality as a natural consequence of physical constraints,\nnon-copyable tacit knowledge, and non-cloneable identity keys as\ncognitive-embodiment primitives. Core tensions (trust/agency,\nscaffolding/emergence, execution/governance) would function as central\narchitectural pressures rather than edge cases. The architecture theoretically\nconverges with the Free Energy Principle, potentially offering a formal account\nof how cognitive systems could maintain identity through prediction error\nminimization across physical and computational boundaries. The resulting\nframework aims to deliver a morally tractable cognitive infrastructure that\ncould maintain human-alignment through irreversible hardware constraints and\nidentity-bound epistemic mechanisms resistant to replication or subversion.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-04-23T11:24:30Z"}
{"aid":"http://arxiv.org/abs/2504.16626v1","title":"Solvability of elliptic homogeneous linear equations with measure data\n  in weighted Lebesgue spaces","summary":"Let $A(D)$ be an elliptic homogeneous linear differential operator with\ncomplex constant coefficients, $ \\mu $ be a vector-valued Borel measure and $w$\nbe a positive locally integrable function on $\\mathbb{R}^N$. In this work, we\npresent sufficient conditions on $\\mu$ and $w$ for the existence of solutions\nin the weighted Lebesgue spaces $L^p_w$ for the equation $A^{*}(D)f=\\mu$, for $\n1\\leq p<\\infty $. Those conditions are related to a certain control of the\nRiesz potential of the measure $\\mu$. We also present sufficient conditions for\nthe solvability when $p=\\infty$ adding a canceling condition on the operator.\nOur method is based on a new weighted $L^1$ Stein-Weiss type inequality on\nmeasures for a special class of vector fields.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T11:33:46Z"}
{"aid":"http://arxiv.org/abs/2504.16628v1","title":"ParetoHqD: Fast Offline Multiobjective Alignment of Large Language\n  Models using Pareto High-quality Data","summary":"Aligning large language models with multiple human expectations and values is\ncrucial for ensuring that they adequately serve a variety of user needs. To\nthis end, offline multiobjective alignment algorithms such as the\nRewards-in-Context algorithm have shown strong performance and efficiency.\nHowever, inappropriate preference representations and training with imbalanced\nreward scores limit the performance of such algorithms. In this work, we\nintroduce ParetoHqD that addresses the above issues by representing human\npreferences as preference directions in the objective space and regarding data\nnear the Pareto front as ''high-quality'' data. For each preference, ParetoHqD\nfollows a two-stage supervised fine-tuning process, where each stage uses an\nindividual Pareto high-quality training set that best matches its preference\ndirection. The experimental results have demonstrated the superiority of\nParetoHqD over five baselines on two multiobjective alignment tasks.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-23T11:35:57Z"}
{"aid":"http://arxiv.org/abs/2504.16648v1","title":"FAST Observation and Results for Core Collapse Globular Cluster M15 and\n  NGC 6517","summary":"Radio astronomy is part of radio science that developed rapidly in recent\ndecades. In the research of radio astronomy, pulsars have always been an\nenduring popular research target. To find and observe more pulsars, large radio\ntelescopes have been built all over the world. In this paper, we present our\nstudies on pulsars in M15 and NGC 6517 with FAST, including monitoring pulsars\nin M15 and new pulsar discoveries in NGC 6517. All the previously known pulsars\nin M15 were detected without no new discoveries. Among them, M15C was still\ndetectable by FAST, while it is assumed to fade out due to precession [1]. In\nNGC 6517, new pulsars were continues to be discovered and all of them are tend\nto be isolated pulsars. Currently, the number of pulsars in NGC 6517 is 17,\nmuch more than the predicted before [2].","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T12:10:04Z"}
{"aid":"http://arxiv.org/abs/2504.16650v1","title":"Small Alfvn Number Limit for the Global-in-time Solutions of\n  Incompressible MHD Equations with General Initial Data","summary":"The small Alfv\\'en number (denoted by $\\varepsilon$) limit (one type of large\nparameter limits, i.e. singular limits) in magnetohydrodynamic (abbr. MHD)\nequations was first proposed by Klainerman--Majda in (Comm. Pure Appl. Math.\n34: 481--524, 1981). Recently Ju--Wang--Xu mathematically verified that the\n\\emph{local-in-time} solutions of three-dimensional (abbr. 3D) ideal (i.e. the\nabsence of the dissipative terms) incompressible MHD equations with general\ninitial data in $\\mathbb{T}^3$ (i.e. a spatially periodic domain) tend to a\nsolution of 2D ideal MHD equations in the distribution sense as $\\varepsilon\\to\n0$ by Schochet's fast averaging method in (J. Differential Equations, 114:\n476--512, 1994). In this paper, we revisit the small Alfv\\'en number limit in\n$\\mathbb{R}^n$ with $n=2$, $3$, and develop another approach, motivated by\nCai--Lei's energy method in (Arch. Ration. Mech. Anal. 228: 969--993, 2018), to\nestablish a new conclusion that the \\emph{global-in-time} solutions of\nincompressible MHD equations (including the viscous resistive case) with\ngeneral initial data converge to zero as $\\varepsilon\\to 0$ for any given\ntime-space variable $(x,t)$ with $t>0$. In addition, we find that the large\nperturbation solutions and vanishing phenomenon of the nonlinear interactions\nalso exist in the \\emph{viscous resistive} MHD equations for small Alfv\\'en\nnumbers, and thus extend Bardos et al.'s results of the \\emph{ideal} MHD\nequations in (Trans Am Math Soc 305: 175--191, 1988).","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T12:10:45Z"}
{"aid":"http://arxiv.org/abs/2504.16661v1","title":"Impact of unidirectional magnetoresistance on spin-orbit torque analysis","summary":"The second-harmonic Hall technique is a widely used, sensitive method for\nstudying the spin-orbit torques generated by charge current. It exploits the\ndependence of the Hall resistance on the magnetization direction, although\nthermal phenomena also contribute. Historically, deviations from the expected\nmagnetic field dependence have usually been neglected. Based on our studies on\npermalloy/platinum bilayers, we show that a unidirectional magnetoresistance -\nknown to appear in the second-harmonic longitudinal resistance - also appears\nin the Hall data, and that describing the results in a wide field range with\nthese contributions is essential to accurately estimate the torques.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-23T12:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.16662v1","title":"MHD Simulations Preliminarily Predict The Habitability and Radio\n  Emission of TRAPPIST-1e","summary":"As the closest Earth-like exoplanet within the habitable zone of the M-dwarf\nstar TRAPPIST-1, TRAPPIST-1e exhibits a magnetic field topology that is\ndependent on space weather conditions. Variations in these conditions influence\nits habitability and contribute to its radio emissions. Our objective is to\nanalyze the response of different terrestrial magnetosphere structures of\nTRAPPIST-1e to various space weather conditions, including events analogous to\ncoronal mass ejections (CMEs). We assess its habitability by computing the\nmagnetopause standoff distance and predict the resulting radio emissions using\nscaling laws. This study provides some priors for future radio observations. We\nperform three-dimensional magnetohydrodynamic (MHD) simulations of the\nTRAPPIST-1e system using the PLUTO code in spherical coordinates. Our analysis\nindicates that the predicted habitability and radio emission of TRAPPIST-1e\nstrongly depend on the planet's magnetic field intensity and magnetic axis\ninclination. Within sub-Alfvenic, super-Alfvenic, and transitional stellar wind\nregimes, the radio emission intensity positively correlates with both planetary\nmagnetic field strength and axial tilt, while planetary habitability,\nquantified by the magnetopause standoff distance, shows a positive correlation\nwith magnetic field strength and a negative correlation with magnetic axis\ntilt...","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA","published":"2025-04-23T12:28:26Z"}
{"aid":"http://arxiv.org/abs/2504.16668v1","title":"Efficient Data Valuation Approximation in Federated Learning: A\n  Sampling-based Approach","summary":"Federated learning paradigm to utilize datasets across multiple data\nproviders. In FL, cross-silo data providers often hesitate to share their\nhigh-quality dataset unless their data value can be fairly assessed. Shapley\nvalue (SV) has been advocated as the standard metric for data valuation in FL\ndue to its desirable properties. However, the computational overhead of SV is\nprohibitive in practice, as it inherently requires training and evaluating an\nFL model across an exponential number of dataset combinations. Furthermore,\nexisting solutions fail to achieve high accuracy and efficiency, making\npractical use of SV still out of reach, because they ignore choosing suitable\ncomputation scheme for approximation framework and overlook the property of\nutility function in FL. We first propose a unified stratified-sampling\nframework for two widely-used schemes. Then, we analyze and choose the more\npromising scheme under the FL linear regression assumption. After that, we\nidentify a phenomenon termed key combinations, where only limited dataset\ncombinations have a high-impact on final data value. Building on these\ninsights, we propose a practical approximation algorithm, IPSS, which\nstrategically selects high-impact dataset combinations rather than evaluating\nall possible combinations, thus substantially reducing time cost with minor\napproximation error. Furthermore, we conduct extensive evaluations on the FL\nbenchmark datasets to demonstrate that our proposed algorithm outperforms a\nseries of representative baselines in terms of efficiency and effectiveness.","main_category":"cs.LG","categories":"cs.LG,cs.DB","published":"2025-04-23T12:36:20Z"}
{"aid":"http://arxiv.org/abs/2504.16674v1","title":"Emergent topological phases and coexistence of gapless and\n  spectral-localized Floquet quantum spin Hall states via electron-phonon\n  interaction","summary":"In this work, a thorough exploration has been carried out to unravel the role\nof electron-phonon interaction (EPI) in a Bernevig-Hughes-Zhang (BHZ) quantum\nspin Hall (QSH) insulator subjected to a time-periodic step drive. It is\nobserved that upon inclusion of the EPI, the system demonstrates emergent\nFloquet QSH (FQSH) phases and several topological phase transitions therein,\nmediated solely by the interaction strength. Quite intriguingly, the emergence\nof topological zero ($\\pi$) modes in the bulk that remains otherwise gapless in\nthe vicinity of the $\\pi$ (zero) energy sector is observed, thus serving as a\nprime candidate of robust topology in gapless systems. With other invariants\nbeing found to be deficient in characterizing such coexistent phases, a\nspectral localizer (SL) is employed, which distinctly ascertains the nature of\nthe (zero or $\\pi$) edge modes. Following the SL prescription, a real-space\nChern marker computed by us further provides support to such \\textit{gapless}\nFloquet topological scenario. Our results can be realized in advanced optical\nsetups that may underscore the importance of EPI-induced Floquet features.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-23T12:42:27Z"}
{"aid":"http://arxiv.org/abs/2504.16675v1","title":"A Novel Sparse Sum and Difference Co-Array With Low Redundancy and\n  Enhanced DOF for Non-Circular Signals","summary":"Array structures based on the sum and difference co-arrays provide more\ndegrees of freedom (DOF). However, since the growth of DOF is limited by a\nsingle case of sum and difference co-arrays, the paper aims to design a sparse\nlinear array (SLA) with higher DOF via exploring different cases of\nsecond-order cumulants. We present a mathematical framework based on\nsecond-order cumulant to devise a second-order extended co-array (SO-ECA) and\ndefine the redundancy of SO-ECA. Based on SO-ECA, a novel array is proposed,\nnamely low redundancy sum and difference array (LR-SDA), which can provide\nclosed-form expressions for the sensor positions and enhance DOF in order to\nresolve more signal sources in the direction of arrival (DOA) estimation of\nnon-circular (NC) signals. For LR-SDA, the maximum DOF under the given number\nof total physical sensors can be derived and the SO-ECA of LR-SDA is hole-free.\nFurther, the corresponding necessary and sufficient conditions of signal\nreconstruction for LR-SDA are derived. Additionally, the redundancy and weight\nfunction of LR-SDA are defined, and the lower band of the redundancy for LR-SDA\nis derived. The proposed LR-SDA achieves higher DOF and lower redundancy than\nthose of existing DCAs designed based on sum and difference co-arrays.\nNumerical simulations are conducted to verify the superiority of LR-SDA on DOA\nestimation performance and enhanced DOF over other existing DCAs.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-23T12:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.16679v1","title":"Transition mechanisms in hypersonic wind-tunnel nozzles: a\n  methodological approach using global linear stability analysis","summary":"Base-flow computations and stability analyses are performed for a hypersonic\nwind tunnel nozzle at a Mach number of 6. Isothermal and adiabatic wall\nboundary conditions are investigated, and moderate stagnation conditions are\nused to provide representative scenarios to study the transition in quiet\nhypersonic wind tunnel facilities. Under these conditions, the studied nozzle\nshows a small flow separation at the convergent inlet. Global stability\nanalysis reveals that this recirculation bubble may trigger a classical\nthree-dimensional stationary unstable global mode. Resolvent analysis reveals\nG\\\"ortler, first and second Mack modes affecting the divergent part of the\nnozzle, along with a Kelvin-Helmholtz instability induced by the bubble. The\npresent study also highlights the key impact of perturbations located in the\nconvergent inlet on the development of instabilities further downstream in the\ndivergent outlet, helping understand the need and efficacy of a suction lip\nupstream of the nozzle throat to mitigate instabilities in the divergent\nnozzle. Detailed knowledge of all these mechanisms is essential for\nunderstanding flows in quiet hypersonic wind tunnel nozzles and, consequently,\nrepresents a key step toward the optimisation of such nozzles.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T12:56:20Z"}
{"aid":"http://arxiv.org/abs/2504.16691v1","title":"Rethinking Vision Transformer for Large-Scale Fine-Grained Image\n  Retrieval","summary":"Large-scale fine-grained image retrieval (FGIR) aims to retrieve images\nbelonging to the same subcategory as a given query by capturing subtle\ndifferences in a large-scale setting. Recently, Vision Transformers (ViT) have\nbeen employed in FGIR due to their powerful self-attention mechanism for\nmodeling long-range dependencies. However, most Transformer-based methods focus\nprimarily on leveraging self-attention to distinguish fine-grained details,\nwhile overlooking the high computational complexity and redundant dependencies\ninherent to these models, limiting their scalability and effectiveness in\nlarge-scale FGIR. In this paper, we propose an Efficient and Effective\nViT-based framework, termed \\textbf{EET}, which integrates token pruning module\nwith a discriminative transfer strategy to address these limitations.\nSpecifically, we introduce a content-based token pruning scheme to enhance the\nefficiency of the vanilla ViT, progressively removing background or\nlow-discriminative tokens at different stages by exploiting feature responses\nand self-attention mechanism. To ensure the resulting efficient ViT retains\nstrong discriminative power, we further present a discriminative transfer\nstrategy comprising both \\textit{discriminative knowledge transfer} and\n\\textit{discriminative region guidance}. Using a distillation paradigm, these\ncomponents transfer knowledge from a larger ``teacher'' ViT to a more efficient\n``student'' model, guiding the latter to focus on subtle yet crucial regions in\na cost-free manner. Extensive experiments on two widely-used fine-grained\ndatasets and four large-scale fine-grained datasets demonstrate the\neffectiveness of our method. Specifically, EET reduces the inference latency of\nViT-Small by 42.7\\% and boosts the retrieval performance of 16-bit hash codes\nby 5.15\\% on the challenging NABirds dataset.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-23T13:23:56Z"}
{"aid":"http://arxiv.org/abs/2504.16698v1","title":"Effect of pressure on the transport properties and thermoelectric\n  performance of Dirac semimetal ZrTe5","summary":"In this study, we have investigated and compared the effect of hydrostatic\npressure up to ~20 kbar on the transport properties of ZrTe5 single crystals\ngrown by chemical vapor transport (CVT) and flux methods. With the application\nof pressure, the electrical resistivity Rho(T) and thermopower S(T) of both\ncrystals were found to increase in the whole temperature range unlike the other\nknown thermoelectric materials, such as Bi2Te3, SnSe etc. This observation is\nsupported by the complementary first-principles band structure calculation as\nthe application of pressure widens the direct bandgap at {\\Gamma} point.\nMoreover, the analysis of the pressure dependent magneto-transport and\nShubnikov de-Hass oscillation results revealed an increase in carrier\nconcentration and effective mass along with the reduction of mobility as\npressure rises. Furthermore, with the application of pressure, the flux-grown\nZrTe5 crystals display a transition from unipolar to bipolar charge transport\nas evidenced by the emergence of resistivity peak at T* under high pressure,\nunlike the CVT-grown ZrTe5 crystals where the bipolar charge transport near its\ncharacteristic resistivity peak (Tp) remains unaffected.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T13:28:58Z"}
{"aid":"http://arxiv.org/abs/2504.16700v1","title":"The Electric Dipole Moment of the electron in the decoupling limit of\n  the aligned Two-Higgs Doublet Model","summary":"We present a discussion of model-independent contributions to the EDM of the\nelectron. We focus on those contributions that emerge from a heavy scalar\nsector that is linearly realized. In particular, we explore the decoupling\nlimit of the aligned 2HDM. In this model, Barr-Zee diagrams with a fermion loop\nproduce logarithmically-enhanced contributions that are proportional to\npotentially large new sources of CP violation. In the decoupling limit these\ncontributions are generated by effective dimension-6 operators via the mixing\nof four-fermion operators into electroweak dipole operators. These logarithmic\ncontributions are not present in more constrained versions of the 2HDM where a\n$\\mathcal Z_2$ symmetry is imposed, which then controls the basis of effective\noperators needed to describe the new physics contributions to the electron EDM.\nThus, the $\\mathcal Z_2$ symmetry provides a suppression mechanism. We then\nstudy how the experimental bounds on the electron EDM constrain the set of\nparameters of the aligned 2HDM.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T13:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.16708v1","title":"Density of rational languages under shift invariant measures","summary":"We study density of rational languages under shift invariant probability\nmeasures on spaces of two-sided infinite words, which generalizes the classical\nnotion of density studied in formal languages and automata theory. The density\nfor a language is defined as the limit in average (if it exists) of the\nprobability that a word of a given length belongs to the language. We establish\nthe existence of densities for all rational languages under all shift invariant\nmeasures. We also give explicit formulas under certain conditions, in\nparticular when the language is aperiodic. Our approach combines tools and\nideas from semigroup theory and ergodic theory.","main_category":"cs.FL","categories":"cs.FL","published":"2025-04-23T13:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.16721v1","title":"Spectrum of cones of non-reduced plane curves with ordinary\n  singularities","summary":"We give a simple proof of the assertion claiming that the spectrum of the\ncone of a non-reduced plane curve can be determined only by its multiplicities\nalong local irreducible components at each singular point as well as those\nalong global ones together with the degrees of the latter (where the relation\nbetween global components and singular points is not needed) if the associated\nreduced plane curve have only ordinary singularities (for instance a line\narrangement). Note that the last condition is strictly weaker than local\nhomogeneity. As a corollary we can also get a simple proof of a formula which\nis equivalent to the one obtained earlier by the second-named author.","main_category":"math.AG","categories":"math.AG","published":"2025-04-23T13:51:18Z"}
{"aid":"http://arxiv.org/abs/2504.16722v1","title":"PMG: Progressive Motion Generation via Sparse Anchor Postures Curriculum\n  Learning","summary":"In computer animation, game design, and human-computer interaction,\nsynthesizing human motion that aligns with user intent remains a significant\nchallenge. Existing methods have notable limitations: textual approaches offer\nhigh-level semantic guidance but struggle to describe complex actions\naccurately; trajectory-based techniques provide intuitive global motion\ndirection yet often fall short in generating precise or customized character\nmovements; and anchor poses-guided methods are typically confined to synthesize\nonly simple motion patterns. To generate more controllable and precise human\nmotions, we propose \\textbf{ProMoGen (Progressive Motion Generation)}, a novel\nframework that integrates trajectory guidance with sparse anchor motion\ncontrol. Global trajectories ensure consistency in spatial direction and\ndisplacement, while sparse anchor motions only deliver precise action guidance\nwithout displacement. This decoupling enables independent refinement of both\naspects, resulting in a more controllable, high-fidelity, and sophisticated\nmotion synthesis. ProMoGen supports both dual and single control paradigms\nwithin a unified training process. Moreover, we recognize that direct learning\nfrom sparse motions is inherently unstable, we introduce \\textbf{SAP-CL (Sparse\nAnchor Posture Curriculum Learning)}, a curriculum learning strategy that\nprogressively adjusts the number of anchors used for guidance, thereby enabling\nmore precise and stable convergence. Extensive experiments demonstrate that\nProMoGen excels in synthesizing vivid and diverse motions guided by predefined\ntrajectory and arbitrary anchor frames. Our approach seamlessly integrates\npersonalized motion with structured guidance, significantly outperforming\nstate-of-the-art methods across multiple control scenarios.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T13:51:42Z"}
{"aid":"http://arxiv.org/abs/2504.16732v1","title":"Simplified Swarm Learning Framework for Robust and Scalable Diagnostic\n  Services in Cancer Histopathology","summary":"The complexities of healthcare data, including privacy concerns, imbalanced\ndatasets, and interoperability issues, necessitate innovative machine learning\nsolutions. Swarm Learning (SL), a decentralized alternative to Federated\nLearning, offers privacy-preserving distributed training, but its reliance on\nblockchain technology hinders accessibility and scalability. This paper\nintroduces a \\textit{Simplified Peer-to-Peer Swarm Learning (P2P-SL) Framework}\ntailored for resource-constrained environments. By eliminating blockchain\ndependencies and adopting lightweight peer-to-peer communication, the proposed\nframework ensures robust model synchronization while maintaining data privacy.\nApplied to cancer histopathology, the framework integrates optimized\npre-trained models, such as TorchXRayVision, enhanced with DenseNet decoders,\nto improve diagnostic accuracy. Extensive experiments demonstrate the\nframework's efficacy in handling imbalanced and biased datasets, achieving\ncomparable performance to centralized models while preserving privacy. This\nstudy paves the way for democratizing advanced machine learning in healthcare,\noffering a scalable, accessible, and efficient solution for privacy-sensitive\ndiagnostic applications.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-23T14:04:15Z"}
{"aid":"http://arxiv.org/abs/2504.16737v1","title":"Scaling limints for supercritical nearly unstable Hawkes processes with\n  hheavy tail","summary":"In this paper, we establish the asymptotic behavior of {\\it supercritical}\nnearly unstable Hawkes processes with a power law kernel. We find that, the\nHawkes process in our context admits a similar equation to that in\n\\cite{MR3563196} for {\\it subcritical} case. In particular, the rescaled Hawkes\nprocess $(Z^n_{nt}/n^{2\\alpha})_{t\\in[0,1]}$ converges in law to a kind of\nintegrated fractional Cox Ingersoll Ross process with different coefficients\nfrom that in \\cite{MR3563196}, as $n$ tends to infinity.","main_category":"math.PR","categories":"math.PR","published":"2025-04-23T14:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.16745v1","title":"Frequency-Compensated Network for Daily Arctic Sea Ice Concentration\n  Prediction","summary":"Accurately forecasting sea ice concentration (SIC) in the Arctic is critical\nto global ecosystem health and navigation safety. However, current methods\nstill is confronted with two challenges: 1) these methods rarely explore the\nlong-term feature dependencies in the frequency domain. 2) they can hardly\npreserve the high-frequency details, and the changes in the marginal area of\nthe sea ice cannot be accurately captured. To this end, we present a\nFrequency-Compensated Network (FCNet) for Arctic SIC prediction on a daily\nbasis. In particular, we design a dual-branch network, including branches for\nfrequency feature extraction and convolutional feature extraction. For\nfrequency feature extraction, we design an adaptive frequency filter block,\nwhich integrates trainable layers with Fourier-based filters. By adding\nfrequency features, the FCNet can achieve refined prediction of edges and\ndetails. For convolutional feature extraction, we propose a high-frequency\nenhancement block to separate high and low-frequency information. Moreover,\nhigh-frequency features are enhanced via channel-wise attention, and temporal\nattention unit is employed for low-frequency feature extraction to capture\nlong-range sea ice changes. Extensive experiments are conducted on a\nsatellite-derived daily SIC dataset, and the results verify the effectiveness\nof the proposed FCNet. Our codes and data will be made public available at:\nhttps://github.com/oucailab/FCNet .","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-23T14:15:48Z"}
{"aid":"http://arxiv.org/abs/2504.16763v1","title":"Noise-Tolerant Coreset-Based Class Incremental Continual Learning","summary":"Many applications of computer vision require the ability to adapt to novel\ndata distributions after deployment. Adaptation requires algorithms capable of\ncontinual learning (CL). Continual learners must be plastic to adapt to novel\ntasks while minimizing forgetting of previous tasks.However, CL opens up\navenues for noise to enter the training pipeline and disrupt the CL. This work\nfocuses on label noise and instance noise in the context of class-incremental\nlearning (CIL), where new classes are added to a classifier over time, and\nthere is no access to external data from past classes. We aim to understand the\nsensitivity of CL methods that work by replaying items from a memory\nconstructed using the idea of Coresets. We derive a new bound for the\nrobustness of such a method to uncorrelated instance noise under a general\nadditive noise threat model, revealing several insights. Putting the theory\ninto practice, we create two continual learning algorithms to construct\nnoise-tolerant replay buffers. We empirically compare the effectiveness of\nprior memory-based continual learners and the proposed algorithms under label\nand uncorrelated instance noise on five diverse datasets. We show that existing\nmemory-based CL are not robust whereas the proposed methods exhibit significant\nimprovements in maximizing classification accuracy and minimizing forgetting in\nthe noisy CIL setting.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,cs.NE","published":"2025-04-23T14:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.16785v1","title":"Non collapse of the Sinha spectral sequence for knots in R^3","summary":"We give an explicit description up to the third page of the Sinha homology\nmod 2 spectral sequence for the space of long knots in $\\mathbb{R}^3$, that is\nconjecturally equivalent to the Vassiliev spectral sequence. The description\narises from a multicomplex structure on the Fox Neuwirth chain complexes for\neuclidean configuration spaces. A computer assisted calculation reveals a non\ntrivial third page differential from a 2-dimensional class, in contrast to the\nrational case.","main_category":"math.AT","categories":"math.AT,math.GT","published":"2025-04-23T15:02:19Z"}
{"aid":"http://arxiv.org/abs/2504.16793v1","title":"A self-avoiding curve associated with sums of digits","summary":"For each $n\\in N ^{\\ast }$, we write $s_{n}=\\left( 1,\\ldots ,1,0\\right) $\nwith $n$ times $1$. For each $a \\in N$, we consider the binary representation\n$\\left( a_{i}\\right) _{i\\in -N }$ of $a$ with $a_{i}=0$ for nearly each $i$; we\ndenote by $\\alpha _{n}(a)$ the number of integers $i$ such that $\\left( a_{i},\n\\ldots ,a_{i+n} \\right) =s_{n}$. We consider the curve $C_{n}=\\left(\nS_{n,k}\\right) _{k\\in N ^{\\ast }}$ which consists of consecutive segments of\nlength $1$ such that, for each $k$, $S_{n,k+1}$ is obtained from $S_{n,k}$ by\nturning right if $k+\\alpha _{n}(k)-\\alpha _{n}(k-1)$ is even and left\notherwise. $C_{1}$ is self-avoiding since it is the curve associated to the\nalternating folding sequence. In [1], M. Mend\\`es France and J. Shallit\nconjectured that the curves $C_{n}$ for $n\\geq 2$ are also self-avoiding. In\nthe present paper, we show that this property is true for $n=2$. We also prove\nthat $C_{2}$ has some properties similar to those which were shown in [2], [3]\nand [4] for folding curves.","main_category":"math.CO","categories":"math.CO","published":"2025-04-23T15:13:11Z"}
{"aid":"http://arxiv.org/abs/2504.16799v1","title":"Coalescence delay mediated by the gas layer during the impact of hot\n  droplets","summary":"Coalescence may not occur immediately when droplets impact a liquid film.\nDespite the prevalence of the high-temperature condition during the impact\nprocess in many applications, the effect of droplet temperature on droplet\ncoalescence is rarely considered. In this study, we experimentally investigate\nthe droplet coalescence during the impact of hot droplets on a liquid film by\nusing color interferometry, high-speed imaging, and infrared imaging. We find\nthat the coalescence of the hot droplet with the liquid film can be delayed\nwhich is mediated by the intervening gas layer between the droplet and the\nfilm. Compared with droplets at room temperature, the residence time of hot\ndroplets can increase by more than two orders of magnitude. We find that the\nthickness of the gas layer increases with the droplet temperature, explaining\nthat the thermal delay of coalescence is due to the thicker gas layer. During\nthe hot droplet impact, the temperature gradient at the bottom of the droplet\ninduces Maranogni flow, which can delay the drainage of the intervening gas\nlayer. The results also show that as the Weber number increases, the residence\ntime of the droplet decreases because of the thinner thickness of the gas\nlayer.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T15:20:19Z"}
{"aid":"http://arxiv.org/abs/2504.16805v1","title":"Evaluating the Impact of CT-to-RED Calibration Curves on Dosimetric\n  Accuracy in Brain Radiotherapy Dose Distribution","summary":"Accurate dose calculation is crucial in radiotherapy, as tissue relative\nelectron densities (RED) derived from CT scans play a vital role. This study\ninvestigated the impact of different CT-to-RED calibration curves on brain\ncancer treatment plans. Three calibration curves were compared: CIRS\nphantom-derived, Catphan phantom-derived, and the default curve in the Monaco\nTreatment Planning System. Ten volumetric modulated arc therapy (VMAT) plans\nwere generated and recalculated using each curve. Dosimetric parameters for\nPlanning Target Volume (PTV) and Organs at Risk (OARs) were analyzed. Results\nshowed significant differences in PTV dose distribution between the\nCIRS-derived and default curves, while no significant differences were found\nbetween Catphan-derived and default curves. The CIRS-derived curve demonstrated\nsuperior performance in representing brain tissue electron densities. These\nfindings emphasize the importance of using site-specific CT-to-RED calibration\ncurves for accurate dose calculations in brain radiotherapy, potentially\nimproving treatment safety and efficacy","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-23T15:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.16818v1","title":"Rediscussion of eclipsing binaries. Paper XXIV. The delta Scuti pulsator\n  V596 Pup (formerly known as VV Pyx)","summary":"V596 Pup is a detached eclipsing binary containing two A1 V stars in a 4.596\nd period orbit with a small eccentricity and apsidal motion, previously\ndesignated as VV Pyxidis. We use new light curves from the Transiting Exoplanet\nSurvey Satellite (TESS) and published radial velocities to determine the\nphysical properties of the component stars. We find masses of 2.098 +/- 0.021\nMsun and 2.091 +/- 0.018 Msun, and radii of 2.179 +/- 0.008 Rsun and 2.139 +/-\n0.007 Rsun. The measured distance to the system is affected by the light from a\nnearby companion star; we obtain 178.4 +/- 2.5 pc. The properties of the system\nare best matched by theoretical predictions for a subsolar metallicity of Z =\n0.010 and an age of 570 Myr. We measure seven significant pulsation frequencies\nfrom the light curve, six of which are consistent with delta Scuti pulsations\nand one of which is likely of slowly-pulsating B-star type.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:37:29Z"}
{"aid":"http://arxiv.org/abs/2504.16824v1","title":"Nurturing Language Proficiency in Spanish.speaking children Through\n  digital competence","summary":"This article explores into the intricate design and meticulous construction\nof a digital platform aimed at revolutionizing early-age English education,\nparticularly for Spanish-speaking children. The focus of this work used an\ninnovative methodologies, vibrant and engaging visuals, and a comprehensive\napproach to phonics. The principles of usability, accessibility, and\nuser-centered design are intricately woven into every facet of the platform's\narchitecture.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T15:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.16826v1","title":"Modeling a Non-Singular Universe with Late-Time Acceleration through a\n  Novel Inhomogeneous Barotropic Equation of State","summary":"In this study, we investigated the effects of incorporating barotropic fluids\non cosmological solutions within the general relativity (GR) framework. We\nproposed a modified version of the barotropic fluid with the EoS, $p=\\zeta _0\n\\rho +\\zeta _1 \\rho \\left(t-t_0\\right){}^{-2 n}$, where $\\zeta_0$, $\\zeta_1$,\n$t_0$ and $n$ are some constants. Our goal is to explore if this type of EoS\nmight help explain the universe's development, concentrating on the scenario\nwhere the universe bounces instead of singularities. Interestingly the generic\nsolutions derived from our model are sufficiently adaptable to illustrate the\nbounce scenario, cosmic inflation and late-time dark-energy behaviour. The\nparameters $\\zeta_0$, $\\zeta_1$, $t_0$, and $n$ define the universe's phase in\nthis non-singular solution. We investigated several elements of cosmic\ndevelopment, including as the energy density, deceleration parameter, and\nenergy conditions, in order to validate our model. Stability analysis showed\nthat the perturbations approach to zero as the time evolves, indicating the\nmodel is stable under scalar perturbation. Additionally, we looked at the\nstatefinder diagnostics and Hubble flow dynamics to get more understanding of\nthe model's dark energy and inflationary behaviour, respectively. Additionally,\nwe conducted a study of the models' relevance to the observational datasets\nfrom BAO, DESI and Pantheon+SH0ES.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T15:43:02Z"}
{"aid":"http://arxiv.org/abs/2504.16832v1","title":"GreenMind: A Next-Generation Vietnamese Large Language Model for\n  Structured and Logical Reasoning","summary":"Chain-of-Thought (CoT) is a robust approach for tackling LLM tasks that\nrequire intermediate reasoning steps prior to generating a final answer. In\nthis paper, we present GreenMind-Medium-14B-R1, the Vietnamese reasoning model\ninspired by the finetuning strategy based on Group Relative Policy\nOptimization. We also leverage a high-quality Vietnamese synthesized reasoning\ndataset and design two reward functions to tackle the main limitations of this\ntechnique: (i) language mixing, where we explicitly detect the presence of\nbiased language characters during the process of sampling tokens, and (ii) we\nleverage Sentence Transformer-based models to ensure that the generated\nreasoning content maintains factual correctness and does not distort the final\noutput. Experimental results on the Vietnamese dataset from the VLSP 2023\nChallenge demonstrate that our model outperforms prior works and enhances\nlinguistic consistency in its responses. Furthermore, we extend our evaluation\nto SeaExam-a multilingual multiple-choice dataset, showing the effectiveness of\nour reasoning method compared to few-shot prompting techniques.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T15:48:55Z"}
{"aid":"http://arxiv.org/abs/2504.16842v1","title":"Bertrand Menu Competition","summary":"We study a variation of the price competition model a la Bertrand, in which\nfirms must offer menus of contracts that obey monotonicity constraints, e.g.,\nwages that rise with worker productivity to comport with equal pay legislation.\nWhile such constraints limit firms' ability to undercut their competitors, we\nshow that Bertrand's classic result still holds: competition drives firm\nprofits to zero and leads to efficient allocations without rationing. Our\nfindings suggest that Bertrand's logic extends to a broader variety of markets,\nincluding labor and product markets that are subject to real-world constraints\non pricing across workers and products.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-23T16:06:09Z"}
{"aid":"http://arxiv.org/abs/2504.16843v1","title":"Physically Consistent Humanoid Loco-Manipulation using Latent Diffusion\n  Models","summary":"This paper uses the capabilities of latent diffusion models (LDMs) to\ngenerate realistic RGB human-object interaction scenes to guide humanoid\nloco-manipulation planning. To do so, we extract from the generated images both\nthe contact locations and robot configurations that are then used inside a\nwhole-body trajectory optimization (TO) formulation to generate physically\nconsistent trajectories for humanoids. We validate our full pipeline in\nsimulation for different long-horizon loco-manipulation scenarios and perform\nan extensive analysis of the proposed contact and robot configuration\nextraction pipeline. Our results show that using the information extracted from\nLDMs, we can generate physically consistent trajectories that require\nlong-horizon reasoning.","main_category":"cs.RO","categories":"cs.RO,cs.GR","published":"2025-04-23T16:07:02Z"}
{"aid":"http://arxiv.org/abs/2504.16852v1","title":"Fair division of the replacement-units without an appraiser in urban\n  renewal processes","summary":"Rebuild and Divide is an urban renewal process that involves the demolition\nof old buildings and the construction of new ones. Original homeowners are\ncompensated with upgraded apartments, while surplus units are sold for profit,\nso theoretically it is a win-win project for all parties involved. However,\nmany rebuild-and-divide projects withheld or delayed due to disagreements over\nthe assignment of new units, claiming they are not \"fair\". The goal of this\nresearch is to develop algorithms for envy-free allocation of the new units.\nThe main challenge is that, in contrast to previous work on envy-free\nallocation, the envy depends also on the value of the old units, as people with\nmore valuable old units are entitled to more valuable new units. We introduce\nthree models that capture different notions of fairness: (1) the Difference\nModel, where agents evaluate their gains relative to others; (2) the Envy Sum\nModel, which permits some envy as long as the total envy does not exceed that\nof the original allocation; and (3) the Ratio Model, where fairness is assessed\nbased on the proportional value of old apartments. For each model, we establish\nan envy criterion and seek a payment vector and allocation that ensure\nenvy-freeness. These models present both theoretical challenges and intriguing\ninsights. Additionally, within the Envy Sum Model, we present a mechanism that\ncomputes an allocation and payment scheme that minimizes total envy. We also\nanalyze the mechanism's vulnerability to manipulation and identify conditions\nunder which it is obviously manipulable.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T16:19:55Z"}
{"aid":"http://arxiv.org/abs/2504.16853v1","title":"Formal Verification of Blockchain Nonforking in DAG-Based BFT Consensus\n  with Dynamic Stake","summary":"Blockchain consensus protocols enable participants to agree on consistent\nviews of the blockchain that may be ahead or behind relative to each other but\ndo not fork into different chains. A number of recently popular\nByzantine-fault-tolerant (BFT) protocols first construct a directed acyclic\ngraph (DAG) that partially orders transactions, then linearize the DAG into a\nblockchain that totally orders transactions. The definitions and correctness\nproofs of these DAG-based protocols typically assume that the set of\nparticipants is fixed, which is impractical in long-lived blockchains.\nAdditionally, only a few of those proofs have been machine-checked, uncovering\nerrors in some published proofs. We developed a formal model of a DAG-based BFT\nprotocol with dynamic stake, where participants can join and leave at every\nblock, with stake used to weigh decisions in the protocol. We formally proved\nthat blockchains never fork in the model, also clarifying how BFT bounds on\nfaulty participants generalize to these highly dynamic sets of participants.\nOur model and proofs are formalized in the ACL2 theorem prover, apply to\narbitrarily long executions and arbitrarily large system states, and are\nverified in 1 minute by ACL2.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-23T16:22:55Z"}
{"aid":"http://arxiv.org/abs/2504.16855v1","title":"Monte Carlo Planning with Large Language Model for Text-Based Game\n  Agents","summary":"Text-based games provide valuable environments for language-based autonomous\nagents. However, planning-then-learning paradigms, such as those combining\nMonte Carlo Tree Search (MCTS) and reinforcement learning (RL), are notably\ntime-consuming due to extensive iterations. Additionally, these algorithms\nperform uncertainty-driven exploration but lack language understanding and\nreasoning abilities. In this paper, we introduce the Monte Carlo planning with\nDynamic Memory-guided Large language model (MC-DML) algorithm. MC-DML leverages\nthe language understanding and reasoning capabilities of Large Language Models\n(LLMs) alongside the exploratory advantages of tree search algorithms.\nSpecifically, we enhance LLMs with in-trial and cross-trial memory mechanisms,\nenabling them to learn from past experiences and dynamically adjust action\nevaluations during planning. We conduct experiments on a series of text-based\ngames from the Jericho benchmark. Our results demonstrate that the MC-DML\nalgorithm significantly enhances performance across various games at the\ninitial planning phase, outperforming strong contemporary methods that require\nmultiple iterations. This demonstrates the effectiveness of our algorithm,\npaving the way for more efficient language-grounded planning in complex\nenvironments.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T16:23:15Z"}
{"aid":"http://arxiv.org/abs/2504.16868v1","title":"Hint towards inconsistency between BAO and Supernovae Dataset: The\n  Evidence of Redshift Evolving Dark Energy from DESI DR2 is Absent","summary":"The combination of independent cosmological datasets is a route towards\nprecision and accurate inference of the cosmological parameters if these\nobservations are not contaminated by systematic effects. However, the presence\nof unknown systematics present in differrent datasets can lead to a biased\ninference of the cosmological parameters. In this work, we test the consistency\nof the two independent tracers of the low-redshift cosmic expansion, namely the\nsupernovae dataset from Pantheon$+$ and the BAO dataset from DESI DR2 using the\ndistance duality relation which is a cornerstone relation in cosmology under\nthe framework of General Relativity. We find that these datasets violate the\ndistance duality relation and show a signature of redshift evolution, hinting\ntoward unaccounted physical effects or observational artifacts. Coincidentally\nthis effect mimics a redshift evolving dark energy scenario when supernovae\ndataset and DESI datasets are combined without accounting for this\ninconsistency. Accounting for this effect in the likelihood refutes the\nprevious claim of evidence of non-cosmological constant as dark energy model\nfrom DESI DR2, and shows a result consistent with cosmological constant with\n$w_0= -0.92\\pm 0.08$ and $w_a= -0.49^{+0.33}_{-0.36}$. This indicates that the\ncurrent conclusion from DESI DR2 in combination with Pantheon$+$ is likely due\nto the combination of two inconsistent datasets resulting in precise but\ninaccurate inference of cosmological parameters. In the future, tests of this\nkind for the consistency between different cosmological datasets will be\nessential for robust inference of cosmological parameters and for deciphering\nunaccounted physical effects or observational artifacts from supernovae and BAO\ndatasets.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-23T16:44:24Z"}
{"aid":"http://arxiv.org/abs/2504.16869v1","title":"Geometry of Cells Sensible to Curvature and Their Receptive Profiles","summary":"We propose a model of the functional architecture of curvature sensible cells\nin the visual cortex that associates curvature with scale. The feature space of\norientation and position is naturally enhanced via its oriented prolongation,\nyielding a 4-dimensional manifold endowed with a canonical Engel structure.\nThis structure encodes position, orientation, signed curvature, and scale. We\nassociate an open submanifold of the prolongation with the quasi-regular\nrepresentation of the similitude group SIM (2), and find left-invariant\ngenerators for the Engel structure. Finally, we use the generators of the Engel\nstructure to characterize curvature-sensitive receptive profiles .","main_category":"q-bio.NC","categories":"q-bio.NC,math.DG","published":"2025-04-23T16:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.16881v1","title":"Fermi-LAT and FAST observation of the gamma-ray binary HESS J0632+057","summary":"Using 15 years of data from the Fermi Large Area Telescope (Fermi-LAT), we\nperformed a comprehensive analysis on the gamma-ray binary HESS J0632+057. Its\nspectrum in 0.1-300 GeV band is well described by a power law model with an\nindex of $2.40\\pm0.16$, leading to an energy flux of (5.5$\\pm$1.6$)\\times$\n10$^{-12}$ erg cm$^{-2}$ s$^{-1}$. The GeV Spectral Energy Distribution (SED)\nof HESS J0632+057 hints for a spectral turn-over between $\\sim$10-100 GeV.\nOrbital analysis reveals a flux enhancement during the phase range of 0.2-0.4,\nconsistent with the X-ray and TeV light curves, indicating an origin of a\ncommon particle population. We carried out six deep radio observations on HESS\nJ0632+057 with the Five-hundred-meter Aperture Spherical Telescope (FAST),\nevenly distributed across its orbit, reaching a detection sensitivity of\n2$\\mu$Jy. However, no radio pulsation was detected within these observations.\nThe absence of radio pulsation may be attributed to the dense stellar wind\nenvironment of HESS J0632+057.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T16:57:27Z"}
{"aid":"http://arxiv.org/abs/2504.16893v1","title":"Practical approaches for crystal structure predictions with inpainting\n  generation and universal interatomic potentials","summary":"We present Crystal Host-Guided Generation (CHGGen), a diffusion-based\nframework for crystal structure prediction. Unconditional generation with\ndiffusion models demonstrates limited efficacy in identifying symmetric\ncrystals as the unit cell size increases. CHGGen addresses this limitation\nthrough conditional generation with the inpainting method, which optimizes a\nfraction of atomic positions within a predefined and symmetrized host\nstructure. We demonstrate the method on the ZnS-P$_2$S$_5$ and Li-Si chemical\nsystems, where the inpainting method generates a higher fraction of symmetric\nstructures than unconditional generation. The practical significance of CHGGen\nextends to enabling the structural modification of crystal structures,\nparticularly for systems with partial occupancy, surface absorption and\ndefects. The inpainting method also allows for seamless integration with other\ngenerative models, providing a versatile framework for accelerating materials\ndiscovery.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-23T17:21:03Z"}
{"aid":"http://arxiv.org/abs/2504.16901v1","title":"Characterizing fragments of collection principle in set theory with\n  model theoretic properties","summary":"We prove some model theoretic equivalent forms of variants of collection\nprinciple in set theory on models of a very weak set theory.","main_category":"math.LO","categories":"math.LO","published":"2025-04-23T17:27:17Z"}
{"aid":"http://arxiv.org/abs/2504.16904v1","title":"Observation of Double Hysteresis in CoFe$_2$O$_4$/MnFe$_2$O$_4$\n  Core/Shell Nanoparticles and Its Contribution to AC Heat Induction","summary":"Magnetic core/shell nanoparticles are promising candidates for magnetic\nhyperthermia due to its high AC magnetic heat induction (specific loss power\n(SLP)). It's widely accepted that magnetic exchange-coupling between core and\nshell plays the crucial role in enhancing SLP of magnetic core/shell\nnanoparticles. However, the physical contribution of exchange coupling to SLP\nhas not been systematically investigated, and the underlying mechanism remains\nunclear. In this study, magnetic hard/soft CoFe$_2$O$_4$/MnFe$_2$O$_4 and\ninverted soft/hard MnFe$_2$O$_4$/CoFe$_2$O$_4$ core/shell nanoparticles were\nsynthesized, systematically varying the number of shell layers, to investigate\nthe physical contribution of internal bias coupling at the core/shell interface\nto AC heat induction (SLP). Our results show that a unique magnetic property,\ndouble-hysteresis loop, was present and clearly observed, which was never\nreported in previous core/shell research literature. According to the\nexperimentally and theoretically analyzed results, the double-hysteresis\nbehavior in core/shell nanoparticles was caused by the difference in magnetic\nanisotropy between core and shell materials, separated by a non-magnetic\ninterface. The enhanced SLP and maximum temperature rise (TAC,max) of\ncore/shell nanoparticles are attributed to the optimized magnetic anisotropy,\nAC magnetic softness and double hysteresis behavior due to the internal bias\ncoupling. These results demonstrate that the rational design capabilities to\nseparately control the magnetic anisotropy, AC/DC magnetic properties by\nvarying the volume ration between core and shell and by switching hard or soft\nphase materials between core and shell are effective modalities to enhance the\nAC heat induction of core/shell nanoparticles for magnetic nanoparticle\nhyperthermia.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-23T17:28:28Z"}
{"aid":"http://arxiv.org/abs/2504.16907v1","title":"BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation","summary":"Text-to-video (T2V) generative models have rapidly advanced and found\nwidespread applications across fields like entertainment, education, and\nmarketing. However, the adversarial vulnerabilities of these models remain\nrarely explored. We observe that in T2V generation tasks, the generated videos\noften contain substantial redundant information not explicitly specified in the\ntext prompts, such as environmental elements, secondary objects, and additional\ndetails, providing opportunities for malicious attackers to embed hidden\nharmful content. Exploiting this inherent redundancy, we introduce BadVideo,\nthe first backdoor attack framework tailored for T2V generation. Our attack\nfocuses on designing target adversarial outputs through two key strategies: (1)\nSpatio-Temporal Composition, which combines different spatiotemporal features\nto encode malicious information; (2) Dynamic Element Transformation, which\nintroduces transformations in redundant elements over time to convey malicious\ninformation. Based on these strategies, the attacker's malicious target\nseamlessly integrates with the user's textual instructions, providing high\nstealthiness. Moreover, by exploiting the temporal dimension of videos, our\nattack successfully evades traditional content moderation systems that\nprimarily analyze spatial information within individual frames. Extensive\nexperiments demonstrate that BadVideo achieves high attack success rates while\npreserving original semantics and maintaining excellent performance on clean\ninputs. Overall, our work reveals the adversarial vulnerability of T2V models,\ncalling attention to potential risks and misuse. Our project page is at\nhttps://wrt2000.github.io/BadVideo2025/.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T17:34:48Z"}
{"aid":"http://arxiv.org/abs/2504.16925v1","title":"Latent Diffusion Planning for Imitation Learning","summary":"Recent progress in imitation learning has been enabled by policy\narchitectures that scale to complex visuomotor tasks, multimodal distributions,\nand large datasets. However, these methods often rely on learning from large\namount of expert demonstrations. To address these shortcomings, we propose\nLatent Diffusion Planning (LDP), a modular approach consisting of a planner\nwhich can leverage action-free demonstrations, and an inverse dynamics model\nwhich can leverage suboptimal data, that both operate over a learned latent\nspace. First, we learn a compact latent space through a variational\nautoencoder, enabling effective forecasting of future states in image-based\ndomains. Then, we train a planner and an inverse dynamics model with diffusion\nobjectives. By separating planning from action prediction, LDP can benefit from\nthe denser supervision signals of suboptimal and action-free data. On simulated\nvisual robotic manipulation tasks, LDP outperforms state-of-the-art imitation\nlearning approaches, as they cannot leverage such additional data.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-23T17:53:34Z"}
{"aid":"http://arxiv.org/abs/2504.17585v1","title":"The tidal heating of the exoplanet 55 Cnc e. The role of the orbital\n  eccentricity","summary":"Context. Observations with warm Spitzer and JWST revealed high and variable\nbrightness in the planet 55 Cnc e.\n  Aims. Inventory of the tidal effects on the rotational and orbital evolution\nof the planet 55 Cnc e enhanced by the nonzero orbital eccentricity.\n  Methods. The creep-tide theory is used in simulations and dynamical analyses\nthat explore the difficult trapping of the planet rotation in a 3:2 spin-orbit\nresonance and the most probable synchronization of the rotation.\n  Results. The strong tidal dissipation of energy, enhanced by the non-zero\norbital eccentricity, may explain the observed brightness anomalies. However,\nthe strong dissipation should also circularize the orbit. The observed non-zero\neccentricity, if true, would indicate that an unknown planet in a close orbital\nresonance with 55 Cnc e perturbing the motion of this planet should exist.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-24T14:17:21Z"}
{"aid":"http://arxiv.org/abs/2504.17587v1","title":"Enhancing gravitational-wave detection: a machine learning pipeline\n  combination approach with robust uncertainty quantification","summary":"Gravitational-wave data from advanced-era interferometric detectors consists\nof background Gaussian noise, frequent transient artefacts, and rare\nastrophysical signals. Multiple search algorithms exist to detect the signals\nfrom compact binary coalescences, but their varying performance complicates\ninterpretation. We present a machine learning-driven approach that combines\nresults from individual pipelines and utilises conformal prediction to provide\nrobust, calibrated uncertainty quantification. Using simulations, we\ndemonstrate improved detection efficiency and apply our model to GWTC-3,\nenhancing confidence in multi-pipeline detections, such as the sub-threshold\nbinary neutron star candidate GW200311_103121.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-24T14:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.17613v1","title":"TarDiff: Target-Oriented Diffusion Guidance for Synthetic Electronic\n  Health Record Time Series Generation","summary":"Synthetic Electronic Health Record (EHR) time-series generation is crucial\nfor advancing clinical machine learning models, as it helps address data\nscarcity by providing more training data. However, most existing approaches\nfocus primarily on replicating statistical distributions and temporal\ndependencies of real-world data. We argue that fidelity to observed data alone\ndoes not guarantee better model performance, as common patterns may dominate,\nlimiting the representation of rare but important conditions. This highlights\nthe need for generate synthetic samples to improve performance of specific\nclinical models to fulfill their target outcomes. To address this, we propose\nTarDiff, a novel target-oriented diffusion framework that integrates\ntask-specific influence guidance into the synthetic data generation process.\nUnlike conventional approaches that mimic training data distributions, TarDiff\noptimizes synthetic samples by quantifying their expected contribution to\nimproving downstream model performance through influence functions.\nSpecifically, we measure the reduction in task-specific loss induced by\nsynthetic samples and embed this influence gradient into the reverse diffusion\nprocess, thereby steering the generation towards utility-optimized data.\nEvaluated on six publicly available EHR datasets, TarDiff achieves\nstate-of-the-art performance, outperforming existing methods by up to 20.4% in\nAUPRC and 18.4% in AUROC. Our results demonstrate that TarDiff not only\npreserves temporal fidelity but also enhances downstream model performance,\noffering a robust solution to data scarcity and class imbalance in healthcare\nanalytics.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T14:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.17618v1","title":"The effects of Hessian eigenvalue spectral density type on the\n  applicability of Hessian analysis to generalization capability assessment of\n  neural networks","summary":"Hessians of neural network (NN) contain essential information about the\ncurvature of NN loss landscapes which can be used to estimate NN generalization\ncapabilities. We have previously proposed generalization criteria that rely on\nthe observation that Hessian eigenvalue spectral density (HESD) behaves\nsimilarly for a wide class of NNs. This paper further studies their\napplicability by investigating factors that can result in different types of\nHESD. We conduct a wide range of experiments showing that HESD mainly has\npositive eigenvalues (MP-HESD) for NN training and fine-tuning with various\noptimizers on different datasets with different preprocessing and augmentation\nprocedures. We also show that mainly negative HESD (MN-HESD) is a consequence\nof external gradient manipulation, indicating that the previously proposed\nHessian analysis methodology cannot be applied in such cases. We also propose\ncriteria and corresponding conditions to determine HESD type and estimate NN\ngeneralization potential. These HESD types and previously proposed\ngeneralization criteria are combined into a unified HESD analysis methodology.\nFinally, we discuss how HESD changes during training, and show the occurrence\nof quasi-singular (QS) HESD and its influence on the proposed methodology and\non the conventional assumptions about the relation between Hessian eigenvalues\nand NN loss landscape curvature.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-24T14:43:07Z"}
{"aid":"http://arxiv.org/abs/2504.17620v1","title":"Reverse energy flows: the physical mechanism underling dramatic drop of\n  loss in hollow-core fibers","summary":"Hollow-core fibers (HCFs) with claddings composed of silica glass capillaries\nhave recently attracted a great deal of attention following the demonstration\nof optical loss levels lower than those of conventional telecommunication\nfibers. It is well established already that optical losses in HCFs are highly\nsensitive to both the wavelength and the geometry of the cladding capillaries.\nThe underlying physical mechanisms behind reducing loss with the change of HCF\ndesign parameters while keeping the same fiber structure are not yet fully\nunderstood. In this work, we investigate the relationship between light\nlocalization and corresponding decrease of losses in HCFs and the distribution\nof reverse energy fluxes in air-core modes. We show here that the shape of the\ncapillaries plays a crucial role in controlling radial energy backflows that\ninfluence light confinement and the energy leakage from air-core modes of HCFs.\nThrough numerical modeling, we demonstrate that optimizing the capillary\ngeometry to tailor the distribution of reverse radial energy fluxes leads to a\nsubstantial reduction in transmission losses even in fibers with relatively\nsimple cladding structures. Consideration of the energy flows and observed\noccurrences of vortex of the Poynting vector allows us to a draw an interesting\ninterdisciplinary analogy with the hydrodynamical system with suppressed\nbackward flow - Tesla valve. We believe that combination of singular optics and\nenergy fluxes analysis provides valuable physical insight into the mechanisms\ngoverning waveguiding in HCFs offering a pathway toward novel designs with\nminimized leakage loss.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-24T14:44:23Z"}
{"aid":"http://arxiv.org/abs/2504.17630v1","title":"Geometry-induced asymmetric level coupling","summary":"Tailoring energy levels in quantum systems via Hamiltonian control parameters\nis essential for designing quantum thermodynamic devices and materials.\nHowever, conventional methods for manipulating finite-size systems, such as\ntuning external fields or system size, typically lead to uniform spectral\nshifts, limiting precise control. A recently introduced technique, called the\nsize-invariant shape transformation, overcomes this by introducing a new\ncontrol parameter that deforms the potential landscape without altering system\nsize, enabling nonuniform level scaling. This shape parameter gives rise to\nquantum shape effects in confined systems, conceptually distinct from quantum\nsize effects. We explore the limits of this phenomenon by asking: what is the\nminimal system in which such spectral behavior can emerge? We show that even a\ntwo-level system can exhibit thermodynamic consequences of quantum shape\neffects, including spontaneous transitions into lower-entropy states, a feature\nabsent in classical thermodynamics for non-interacting systems. We identify the\norigin as geometry-induced asymmetric level coupling, where the ground-state\nenergy and level spacing respond oppositely to shape changes. This extends to\nmany-level systems, where the thermally averaged level spacing and ground-state\nenergy evolve in opposite directions. We construct spontaneity maps revealing\nenergy- and entropy-driven spontaneous processes. These behaviors emerge under\nquasistatic, isothermal deformations and show how geometry alone can induce\nthermodynamic effects typically exclusive to interacting or open systems. Our\nresults offer a broadly applicable route to spectral gap control in quantum\ntechnologies.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.stat-mech","published":"2025-04-24T14:58:44Z"}
{"aid":"http://arxiv.org/abs/2504.17635v1","title":"Quantifying jet-interstellar medium interactions in Cyg X-1: Insights\n  from dual-frequency bow shock detection with MeerKAT","summary":"Accretion and outflows are astrophysical phenomena observed across a wide\nrange of objects, from white dwarfs to supermassive black holes. Developing a\ncomplete picture of these processes requires complementary studies across this\nfull spectrum of jet-launching sources. Jet-interstellar medium (ISM)\ninteraction sites near black hole X-ray binaries provide unique laboratories to\nstudy jet energetics. This work aims to detect and characterise the bow shock\nnear one black hole X-ray binary, Cyg X-1, and then use this bow shock\nstructure to parametrise the properties of the jet launched by Cyg X-1 over its\nlifetime. We used the MeerKAT radio telescope to investigate the bow shock\nstructure formed by the interaction between the jets of Cyg X-1 and the ISM. We\nsuccessfully detect the bow shock north of Cyg X-1 in the L and S bands and\nreport its size and brightness. We present the spectral index distribution\nacross the bow shock, which is in the range -0.9 to 0.4, with an error\ndistribution (0.6 to 1.5) that peaks at unity. We determine that the unshocked\nISM density is 6-7 cm^-3 for a temperature range of 10^4 to 3*10^6 K. This\ntemperature range suggests that the velocity of the bow shock is 21 km/s to 364\nkm/s. The age of the Cyg X-1 jet responsible for the bow shock is 0.04 to 0.3\nMyr, and the power of the jet is constrained to 2*10^31 ergs/s to 10^35 ergs/s.\nWe also detect new morphological features of the bow shock in the S-band image.\nThe comparison of archival H_alpha maps with the new radio observations hints\nat different regions of emission, different temperature ranges, and different\nISM densities. The spectral index suggests a consistent emission origin across\nthe structure. The ISM density around Cyg X-1 is on the higher end for Galactic\nenvironments, and our results indicate a lower jet energy transport rate than\nprior estimates.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-24T15:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.17655v1","title":"Aerial Image Classification in Scarce and Unconstrained Environments via\n  Conformal Prediction","summary":"This paper presents a comprehensive empirical analysis of conformal\nprediction methods on a challenging aerial image dataset featuring diverse\nevents in unconstrained environments. Conformal prediction is a powerful\npost-hoc technique that takes the output of any classifier and transforms it\ninto a set of likely labels, providing a statistical guarantee on the coverage\nof the true label. Unlike evaluations on standard benchmarks, our study\naddresses the complexities of data-scarce and highly variable real-world\nsettings. We investigate the effectiveness of leveraging pretrained models\n(MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to\ngenerate informative prediction sets. To further evaluate the impact of\ncalibration, we consider two parallel pipelines (with and without temperature\nscaling) and assess performance using two key metrics: empirical coverage and\naverage prediction set size. This setup allows us to systematically examine how\ncalibration choices influence the trade-off between reliability and efficiency.\nOur findings demonstrate that even with relatively small labeled samples and\nsimple nonconformity scores, conformal prediction can yield valuable\nuncertainty estimates for complex tasks. Moreover, our analysis reveals that\nwhile temperature scaling is often employed for calibration, it does not\nconsistently lead to smaller prediction sets, underscoring the importance of\ncareful consideration in its application. Furthermore, our results highlight\nthe significant potential of model compression techniques within the conformal\nprediction pipeline for deployment in resource-constrained environments. Based\non our observations, we advocate for future research to delve into the impact\nof noisy or ambiguous labels on conformal prediction performance and to explore\neffective model reduction strategies.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,stat.ML","published":"2025-04-24T15:25:37Z"}
{"aid":"http://arxiv.org/abs/2504.17658v1","title":"Insights from Analytical Theory of Eccentric Circumbinary Disks","summary":"Eccentric cavities in circumbinary disks precess on timescales much longer\nthan the binary orbital period. These long-lived steady states can be\nunderstood as trapped modes in an effective potential primarily determined by\nthe binary quadrupole and the inner-disk pressure support, with associated\nfrequencies $\\omega_Q$ and $\\omega_P$. Within this framework, we show that the\nratio $\\omega_P/\\omega_Q$ is the main parameter determining the mode spectrum,\nand obtain a thorough understanding of it by systematically solving this\nproblem with various degrees of sophistication. We first find analytical\nsolutions for truncated power-law disks and use this insight in disks with\nsmooth central cavities. Our main findings are: (i) The number of modes\nincreases for thinner disks and more-equal-mass binaries. (ii) For 2D disks,\nthe normalized ground-mode frequency, $\\omega_0/(\\omega_Q+\\omega_P)$, decreases\nmonotonically with the ratio $\\omega_P/\\omega_Q$. (iii) For thin disks,\n$\\omega_P\\ll\\omega_Q$, the ground-mode frequency coincides with the maximum of\nthe effective potential, which tracks the gravitational quadrupole frequency\ninside the inner-disk cavity, and is thus rather sensitive to the density\nprofile of the cavity, where these modes are localized. (iv) For thick disks,\n$\\omega_P\\gg\\omega_Q$, increasing pressure support anchors the peak of the\neffective potential at the inner cavity radius as the ground-mode extends\nfarther out and its frequency decreases. (v) In agreement with numerical\nsimulations, with $\\omega_P/\\omega_Q \\simeq 0.1$, we find that disk precession\nis rather insensitive to the density profile and ground-mode frequencies for 3D\ndisks are about half the value for 2D disks.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-24T15:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.17661v1","title":"Sharp Material Interface Limit of the Darcy-Boussinesq System","summary":"We investigate the sharp material interface limit of the Darcy-Boussinesq\nmodel for convection in layered porous media with diffused material interfaces,\nwhich allow a gradual transition of material parameters between different\nlayers. We demonstrate that as the thickness of these transition layers\napproaches zero, the conventional sharp interface model with interfacial\nboundary conditions, commonly adopted by the fluids community, is recovered\nunder the assumption of constant porosity. Our results validate the widely used\nsharp interface model by bridging it with the more physically realistic case of\ndiffused material interfaces. This limiting process is singular and involves a\nboundary layer in the velocity field. Our analysis requires del","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T15:30:18Z"}
{"aid":"http://arxiv.org/abs/2504.17664v1","title":"On Multivariate Financial Time Series Classification","summary":"This article investigates the use of Machine Learning and Deep Learning\nmodels in multivariate time series analysis within financial markets. It\ncompares small and big data approaches, focusing on their distinct challenges\nand the benefits of scaling. Traditional methods such as SVMs are contrasted\nwith modern architectures like ConvTimeNet. The results show the importance of\nusing and understanding Big Data in depth in the analysis and prediction of\nfinancial time series.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T15:33:00Z"}
{"aid":"http://arxiv.org/abs/2504.17668v1","title":"FRG analysis for relativistic BEC in arbitrary spatial dimensions","summary":"A relativistic Bose-Einstein condensate (BEC) is studied within the complex\nscalar field theory using the functional renormalization group (FRG) under the\nlocal potential approximation. We investigate fluctuation effects on the\nrelativistic BEC through numerical analyses for various spatial dimensions and\nchemical potentials. Our numerical results are consistent with the\nMermin-Wagner theorem, and this consistency is also analytically confirmed from\nthe flow equation. We also discuss a numerical instability of the FRG in lower\nspatial dimensions, which is evadable for certain parameter choices.","main_category":"hep-ph","categories":"hep-ph,cond-mat.quant-gas,hep-th,G.1.8","published":"2025-04-24T15:37:35Z"}
{"aid":"http://arxiv.org/abs/2504.17673v1","title":"DTECM: Digital Twin Enabled Channel Measurement and Modeling in\n  Terahertz Urban Macrocell","summary":"In this work, in the THz UMa, extensive channel measurements are conducted\nand an accurate channel model is developed by combining ray-tracing, computer\nvision (CV), and statistical methods. Specifically, substantial channel\nmeasurement campaigns with distances up to 410~m are conducted at 220~GHz, with\nnanosecond-level absolute time synchronization. Based on the measurement\nresults, the propagation phenomena are analyzed in detail and the channel\ncharacteristics are calculated and statistically modeled. Furthermore, a\ndigital twin enabled channel model (DTECM) is proposed, which generates THz\nchannel responses in a hybrid manner. Specifically, the dominant paths are\ngenerated deterministically by using the ray-tracing technique and CV methods.\nApart from the path gains determined by ray-tracing, the additional foliage\nloss is accurately modeled based on foliage information extracted from\npanoramic pictures. To maintain a low computational complexity for the DTECM,\nnon-dominant paths are then generated statistically. Numeric results reveal\nthat compared to the traditional statistical channel models, the DTECM reduces\nthe path loss modeling error from 14~dB to 4~dB, showing its great superiority.\nFurthermore, a preliminary link performance evaluation using the DTECM\nindicates that THz UMa is feasible, though requiring high antenna gains and\ncoverage extension techniques to achieve high spectral efficiencies and wide\ncoverage.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T15:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.17684v1","title":"Evaluating the Vulnerability of ML-Based Ethereum Phishing Detectors to\n  Single-Feature Adversarial Perturbations","summary":"This paper explores the vulnerability of machine learning models to simple\nsingle-feature adversarial attacks in the context of Ethereum fraudulent\ntransaction detection. Through comprehensive experimentation, we investigate\nthe impact of various adversarial attack strategies on model performance\nmetrics. Our findings, highlighting how prone those techniques are to simple\nattacks, are alarming, and the inconsistency in the attacks' effect on\ndifferent algorithms promises ways for attack mitigation. We examine the\neffectiveness of different mitigation strategies, including adversarial\ntraining and enhanced feature selection, in enhancing model robustness and show\ntheir effectiveness.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T15:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.17695v1","title":"PICO: Reconstructing 3D People In Contact with Objects","summary":"Recovering 3D Human-Object Interaction (HOI) from single color images is\nchallenging due to depth ambiguities, occlusions, and the huge variation in\nobject shape and appearance. Thus, past work requires controlled settings such\nas known object shapes and contacts, and tackles only limited object classes.\nInstead, we need methods that generalize to natural images and novel object\nclasses. We tackle this in two main ways: (1) We collect PICO-db, a new dataset\nof natural images uniquely paired with dense 3D contact on both body and object\nmeshes. To this end, we use images from the recent DAMON dataset that are\npaired with contacts, but these contacts are only annotated on a canonical 3D\nbody. In contrast, we seek contact labels on both the body and the object. To\ninfer these given an image, we retrieve an appropriate 3D object mesh from a\ndatabase by leveraging vision foundation models. Then, we project DAMON's body\ncontact patches onto the object via a novel method needing only 2 clicks per\npatch. This minimal human input establishes rich contact correspondences\nbetween bodies and objects. (2) We exploit our new dataset of contact\ncorrespondences in a novel render-and-compare fitting method, called PICO-fit,\nto recover 3D body and object meshes in interaction. PICO-fit infers contact\nfor the SMPL-X body, retrieves a likely 3D object mesh and contact from PICO-db\nfor that object, and uses the contact to iteratively fit the 3D body and object\nmeshes to image evidence via optimization. Uniquely, PICO-fit works well for\nmany object categories that no existing method can tackle. This is crucial to\nenable HOI understanding to scale in the wild. Our data and code are available\nat https://pico.is.tue.mpg.de.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T16:03:11Z"}
{"aid":"http://arxiv.org/abs/2504.17697v1","title":"'The Boring and the Tedious': Invisible Labour in India's Gig-Economy","summary":"India's gig-based food delivery platforms, such as Swiggy and Zomato, provide\ncrucial income to marginalised communities but also entrench workers in cycles\nof invisible labour. Through 14 semi-structured interviews, we analyse waiting\ntime and repetitive UI itneractions as key burdens that contribute to 'digital\ndiscomfort' for gig based food delivery agents. We find that workers employ\ncreative strategies to navigate algorithmic management, yet remain constrained\nby platform-side 'gamification' and system opacity. We propose worker-centered\nGUI automation as a potential intervention to reduce friction while preserving\nagency. In conclusion, this position paper argues for rethinking HCI approaches\nin the Global South to prioritise worker autonomy over efficiency-driven design\noptimisations.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-24T16:06:26Z"}
{"aid":"http://arxiv.org/abs/2504.17712v1","title":"Generative Fields: Uncovering Hierarchical Feature Control for StyleGAN\n  via Inverted Receptive Fields","summary":"StyleGAN has demonstrated the ability of GANs to synthesize highly-realistic\nfaces of imaginary people from random noise. One limitation of GAN-based image\ngeneration is the difficulty of controlling the features of the generated\nimage, due to the strong entanglement of the low-dimensional latent space.\nPrevious work that aimed to control StyleGAN with image or text prompts\nmodulated sampling in W latent space, which is more expressive than Z latent\nspace. However, W space still has restricted expressivity since it does not\ncontrol the feature synthesis directly; also the feature embedding in W space\nrequires a pre-training process to reconstruct the style signal, limiting its\napplication. This paper introduces the concept of \"generative fields\" to\nexplain the hierarchical feature synthesis in StyleGAN, inspired by the\nreceptive fields of convolution neural networks (CNNs). Additionally, we\npropose a new image editing pipeline for StyleGAN using generative field theory\nand the channel-wise style latent space S, utilizing the intrinsic structural\nfeature of CNNs to achieve disentangled control of feature synthesis at\nsynthesis time.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T16:15:02Z"}
{"aid":"http://arxiv.org/abs/2504.17718v1","title":"Recursive feasibility for stochastic MPC and the rationale behind fixing\n  flat tires","summary":"In this paper, we address the problem of designing stochastic model\npredictive control (SMPC) schemes for linear systems affected by unbounded\ndisturbances. The contribution of the paper is rooted in a measured-state\ninitialization strategy. First, due to the nonzero probability of violating\nchance-constraints in the case of unbounded noise, we introduce\nellipsoidal-based probabilistic reachable sets and we include constraint\nrelaxations to recover recursive feasibility conditioned to the measured state.\nSecond, we prove that the solution of this novel SMPC scheme guarantees\nclosed-loop chance constraints satisfaction under minimum relaxation. Last, we\ndemonstrate that, in expectation, the need of relaxing the constraints vanishes\nover time, which leads the closed-loop trajectories steered towards the\nunconstrained LQR invariant region. This novel SMPC scheme is proven to satisfy\nthe recursive feasibility conditioned to the state realization, and its\nsuperiority with respect to open-loop initialization schemes is shown through\nnumerical examples.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-24T16:26:22Z"}
{"aid":"http://arxiv.org/abs/2504.17720v1","title":"Multilingual Performance Biases of Large Language Models in Education","summary":"Large language models (LLMs) are increasingly being adopted in educational\nsettings. These applications expand beyond English, though current LLMs remain\nprimarily English-centric. In this work, we ascertain if their use in education\nsettings in non-English languages is warranted. We evaluated the performance of\npopular LLMs on four educational tasks: identifying student misconceptions,\nproviding targeted feedback, interactive tutoring, and grading translations in\nsix languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to\nEnglish. We find that the performance on these tasks somewhat corresponds to\nthe amount of language represented in training data, with lower-resource\nlanguages having poorer task performance. Although the models perform\nreasonably well in most languages, the frequent performance drop from English\nis significant. Thus, we recommend that practitioners first verify that the LLM\nworks well in the target language for their educational task before deployment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T16:32:31Z"}
{"aid":"http://arxiv.org/abs/2504.17734v1","title":"Signed puzzles for Schubert coefficients","summary":"We give a signed puzzle rule to compute Schubert coefficients. The rule is\nbased on a careful analysis of Knutson's recurrence arXiv:math/0306304. We use\nthe rule to prove polynomiality of the sums of Schubert coefficients with\nbounded number of inversions.","main_category":"math.CO","categories":"math.CO","published":"2025-04-24T16:47:38Z"}
{"aid":"http://arxiv.org/abs/2504.17742v1","title":"Novel Heusler Materials for Spintronic Applications: Growth,\n  Characterizations and Applications","summary":"Spintronics is a rapidly evolving technology that utilizes the spin of\nelectrons along with their charge to enable high speed, low power and non\nvolatile electronic devices. The development of novel materials with tailored\nmagnetic and electronic properties is critical to exploit the full potential of\nspintronic applications. Among these, Heusler alloys stand out due to their\ntunable multifunctional properties. This review presents a comprehensive\noverview of various Heusler based materials including half metallic\nferromagnets, spin gapless semiconductors, magnetic semiconductors, spin\nsemimetals, and nearly zero moment materials focusing on their synthesis,\nstructural and magnetic characterizations, and transport behavior. The role of\ncrystal structure, and structural disorder in governing their magnetic and\nelectronic properties is discussed in detail. Emphasis is placed on\nexperimental results and their implications for spintronic devices. By bringing\ntogether recent advancements, the review highlights the critical role of\nHeusler alloys in advancing the next-generation spintronic technologies and\noutlines future directions for their integration in practical applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T16:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.17747v1","title":"Fourier Acceleration in a Linear Sigma Model with Spontaneous Symmetry\n  Breaking","summary":"Fourier acceleration is a technique used in Hybrid Monte Carlo simulations to\ndecrease the autocorrelation between subsequent field configurations in the\ngenerated ensemble. It has been shown, in the perturbative limit, to eliminate\nthe problem of critical slowing down in a $\\phi^4$ theory (arXiv:1812.05281\n[hep-lat]). As a result, there are several techniques that are being explored\nto generalize Fourier acceleration to work with non-Abelian gauge theories like\nQCD (arXiv:2112.04556 [hep-lat], arXiv:2108.05486 [hep-lat]). It is hoped that\nthese methods will prove effective at overcoming the problem of critical\nslowing down, even in the non-perturbative limit. In our work, we show that\nFourier acceleration can be applied effectively to a linear sigma model in the\nsymmetry broken phase, leading to reduced autocorrelation and faster\nthermalization. We present an algorithm for estimating the optimal Fourier\nacceleration masses dynamically, based on the lattice data. In the future, we\nhope to explore the effectiveness of these techniques in the\nstrongly-interacting case. Since our $\\phi^4$ theory is a linear chiral\neffective theory for QCD, this could be interesting for those who are seeking\nto generalize Fourier acceleration to QCD.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-24T17:07:44Z"}
{"aid":"http://arxiv.org/abs/2504.17753v1","title":"Conversational Assistants to support Heart Failure Patients: comparing a\n  Neurosymbolic Architecture with ChatGPT","summary":"Conversational assistants are becoming more and more popular, including in\nhealthcare, partly because of the availability and capabilities of Large\nLanguage Models. There is a need for controlled, probing evaluations with real\nstakeholders which can highlight advantages and disadvantages of more\ntraditional architectures and those based on generative AI. We present a\nwithin-group user study to compare two versions of a conversational assistant\nthat allows heart failure patients to ask about salt content in food. One\nversion of the system was developed in-house with a neurosymbolic architecture,\nand one is based on ChatGPT. The evaluation shows that the in-house system is\nmore accurate, completes more tasks and is less verbose than the one based on\nChatGPT; on the other hand, the one based on ChatGPT makes fewer speech errors\nand requires fewer clarifications to complete the task. Patients show no\npreference for one over the other.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T17:16:24Z"}
{"aid":"http://arxiv.org/abs/2504.17757v1","title":"On canonical differential equations for Calabi-Yau multi-scale Feynman\n  integrals","summary":"We generalise a method recently introduced in the literature, that derives\ncanonical differential equations, to multi-scale Feynman integrals with an\nunderlying Calabi-Yau geometry. We start by recomputing a canonical form for\nthe sunrise integral with all unequal masses. Additionally, we compute for the\nfirst time a canonical form for the three-loop banana integral with two unequal\nmasses and for a four-loop banana integral with two unequal masses. For the\nintegrals we compute, we find an $\\epsilon$-form whose connection has at most\nsimple poles. We motivate our construction by studying the Picard-Fuchs\noperators acting on the integrals considered. In the appendices, we give a\nconstructive explanation for why our generalisation works.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-24T17:20:12Z"}
{"aid":"http://arxiv.org/abs/2504.17758v1","title":"First study of neutrino angle reconstruction using quasielastic-like\n  interactions in MicroBooNE","summary":"We investigate the expected precision of the reconstructed neutrino direction\nusing a {\\nu}{\\mu}-argon quasielastic-like event topology with one muon and one\nproton in the final state and the reconstruction capabilities of the MicroBooNE\nliquid argon time projection chamber. This direction is of importance in the\ncontext of DUNE sub-GeV atmospheric oscillation studies. MicroBooNE allows for\na data-driven quantification of this resolution by investigating the deviation\nof the reconstructed muon-proton system orientation with respect to the\nwell-known direction of neutrinos originating from the Booster Neutrino Beam\nwith an exposure of 1.3 x 1021 protons on target. Using simulation studies, we\nderive the expected sub-GeV DUNE atmospheric-neutrino reconstructed simulated\nspectrum by developing a reweighting scheme as a function of the true neutrino\nenergy. We further report flux-integrated single- and double-differential cross\nsection measurements of charged-current {\\nu}{\\mu} quasielastic-like scattering\non argon as a function of the muon-proton system angle using the full\nMicroBooNE data sets. We also demonstrate the sensitivity of these results to\nnuclear effects and final state hadronic reinteraction modeling.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-24T17:20:49Z"}
{"aid":"http://arxiv.org/abs/2504.17768v1","title":"The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs","summary":"Sparse attention offers a promising strategy to extend long-context\ncapabilities in Transformer LLMs, yet its viability, its efficiency-accuracy\ntrade-offs, and systematic scaling studies remain unexplored. To address this\ngap, we perform a careful comparison of training-free sparse attention methods\nat varying model scales, sequence lengths, and sparsity levels on a diverse\ncollection of long-sequence tasks-including novel ones that rely on natural\nlanguage while remaining controllable and easy to evaluate. Based on our\nexperiments, we report a series of key findings: 1) an isoFLOPS analysis\nreveals that for very long sequences, larger and highly sparse models are\npreferable to smaller and dense ones. 2) The level of sparsity attainable while\nstatistically guaranteeing accuracy preservation is higher during decoding than\nprefilling, and correlates with model size in the former. 3) There is no clear\nstrategy that performs best across tasks and phases, with different units of\nsparsification or budget adaptivity needed for different scenarios. Even\nmoderate sparsity levels often result in significant performance degradation on\nat least one task, highlighting that sparse attention is not a universal\nsolution. 4) We introduce and validate novel scaling laws specifically tailored\nfor sparse attention, providing evidence that our findings are likely to hold\ntrue beyond our range of experiments. Through these insights, we demonstrate\nthat sparse attention is a key tool to enhance the capabilities of Transformer\nLLMs for processing longer sequences, but requires careful evaluation of\ntrade-offs for performance-sensitive applications.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-24T17:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.17778v1","title":"Flexoelectric polarization in chiral liquid crystals: electrostatic\n  self-interactions of topological defects","summary":"The presence of topological defects in apolar chiral liquid crystals cause\norientational distortions, leading to non-uniform strain. This non-uniform\nstrain generates an electric polarization response due to the flexoelectric\neffect, which induces an internal electric field. Associated to this electric\nfield is an electrostatic self-energy, which has a back-reaction on the\ndirector field. Calculation of this internal electric field and its resulting\nback-reaction on the director field is complicated. We propose a method to do\nsuch, adapting a method recently developed to study the magnetostatic\nself-interaction effect on skyrmions in chiral ferromagnets. Bloch skyrmions in\nchiral magnets are solenoidal and are unaffected by the magnetostatic\nself-interaction. However, Bloch skyrmions in liquid crystals yield\nnon-solenoidal flexoelectric polarization and, thus, are affected by the\nelectrostatic self-interaction. Additionally, as the flexoelectric coefficients\nare increased in strength, a transition from a hopfion to a skyrmion is\nobserved in three-dimensional confined systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-24T17:55:09Z"}
{"aid":"http://arxiv.org/abs/2504.17779v1","title":"Josephson anomalous vortices","summary":"We show that vortices with circulating current, related with odd-frequency\ntriplet pairing, appear in Josephson junctions where the barrier is a weak\nferromagnet with strong spin-orbit coupling. By both symmetry analysis and\nmicroscopic methods we show that there is an additional term - a rotary\ninvariant - in the superconducting free energy which allows for magnetoelectric\neffects even when the previously considered Lifshitz invariant vanishes. We\nshow that the size, shape, and position of these vortices can be controlled by\nmanipulating Rashba spin-orbit coupling in the weak link, via gates, and we\nsuggest that these vortices could be detected via scanning magnetometry\ntechniques. We also show that the transverse triplet components of the\nsuperconducting correlations can form a texture.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-24T17:56:00Z"}
{"aid":"http://arxiv.org/abs/2504.17782v1","title":"Unleashing the Power of Natural Audio Featuring Multiple Sound Sources","summary":"Universal sound separation aims to extract clean audio tracks corresponding\nto distinct events from mixed audio, which is critical for artificial auditory\nperception. However, current methods heavily rely on artificially mixed audio\nfor training, which limits their ability to generalize to naturally mixed audio\ncollected in real-world environments. To overcome this limitation, we propose\nClearSep, an innovative framework that employs a data engine to decompose\ncomplex naturally mixed audio into multiple independent tracks, thereby\nallowing effective sound separation in real-world scenarios. We introduce two\nremix-based evaluation metrics to quantitatively assess separation quality and\nuse these metrics as thresholds to iteratively apply the data engine alongside\nmodel training, progressively optimizing separation performance. In addition,\nwe propose a series of training strategies tailored to these separated\nindependent tracks to make the best use of them. Extensive experiments\ndemonstrate that ClearSep achieves state-of-the-art performance across multiple\nsound separation tasks, highlighting its potential for advancing sound\nseparation in natural audio scenarios. For more examples and detailed results,\nplease visit our demo page at https://clearsep.github.io.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-24T17:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.19947v1","title":"Nonlinear states of the conservative complex Swift-Hohenberg equation","summary":"We consider the conservative complex Swift-Hohenberg equation, which belongs\nto the family of nonlinear fourth-order dispersive Schr\\\"odinger equations. In\ncontrast to the well-studied one-dimensional dissipative Swift-Hohenberg\nequation, the complex variant introduces a wide array of largely unexplored\nsolutions. Our study provides a fundamental step in understanding the complex\ncharacteristics of this equation, particularly for typical classes of\nsolutions-uniform, periodic, and localized states-and their relationship with\nthe original dissipative model. Our findings reveal significant differences\nbetween the two models. For instance, uniform solutions in the conservative\nmodel are inherently unstable, and periodic solutions are generally unstable\nexcept within a narrow parameter interval that supports multiple localized\nstates. Furthermore, we establish a generalized Vakhitov-Kolokolov criterion to\ndetermine the stability of localized states in the conservative equation and\nrelate it to the stability properties of the dissipative counterpart.","main_category":"nlin.PS","categories":"nlin.PS","published":"2025-04-28T16:19:21Z"}
{"aid":"http://arxiv.org/abs/2504.19950v1","title":"Data-Driven Stabilization of Unknown Linear-Threshold Network Dynamics","summary":"This paper studies the data-driven control of unknown linear-threshold\nnetwork dynamics to stabilize the state to a reference value. We consider two\ntypes of controllers: (i) a state feedback controller with feed-forward\nreference input and (ii) an augmented feedback controller with error\nintegration. The first controller features a simpler structure and is easier to\ndesign, while the second offers improved performance in the presence of system\nparameter changes and disturbances. Our design strategy employs state-input\ndatasets to construct data-based representations of the closed-loop dynamics.\nSince these representations involve linear threshold functions, we rewrite them\nas switched linear systems, and formulate the design problem as that of finding\na common controller for all the resulting modes. This gives rise to a set of\nlinear matrix inequalities (LMIs) whose solutions corresponds to the controller\ngain matrices. We analyze the computational complexity of solving the LMIs and\npropose a simplified, sufficient set of conditions that scales linearly with\nthe system state. Simulations on two case studies involving regulation of\nfiring rate dynamics in rodent brains and of arousal level dynamics in humans\ndemonstrate the effectiveness of the controller designs.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-28T16:21:47Z"}
{"aid":"http://arxiv.org/abs/2504.19953v1","title":"Marginal expected shortfall: Systemic risk measurement under dependence\n  uncertainty","summary":"Measuring the contribution of a bank or an insurance company to the overall\nsystemic risk of the market is an important issue, especially in the aftermath\nof the 2007-2009 financial crisis and the financial downturn of 2020. In this\npaper, we derive the worst-case and best-case bounds for marginal expected\nshortfall (MES) -- a key measure of systemic risk contribution -- under the\nassumption of known marginal distributions for individual companies' risks but\nan unknown dependence structure. We further derive improved bounds for the MES\nrisk measure when partial information on companies' risk exposures -- and hence\ntheir dependence -- is available. To capture this partial information, we\nutilize three commonly used background risk models: the additive,\nminimum-based, and multiplicative factor models. Finally, we present an\nalternative set of improved MES bounds based on a linear regression\nrelationship between individual companies' risks and overall market risk,\nconsistent with the assumptions of the Capital Asset Pricing Model in finance\nand the Weighted Insurance Pricing Model in insurance.","main_category":"q-fin.RM","categories":"q-fin.RM,math.ST,stat.AP,stat.TH","published":"2025-04-28T16:23:53Z"}
{"aid":"http://arxiv.org/abs/2504.19954v1","title":"Type-Based Unsourced Multiple Access over Fading Channels with Cell-Free\n  Massive MIMO","summary":"Type-based unsourced multiple access (TUMA) is a recently proposed framework\nfor type-based estimation in massive uncoordinated access networks. We extend\nthe existing design of TUMA, developed for an additive white Gaussian channel,\nto a more realistic environment with fading and multiple antennas.\nSpecifically, we consider a cell-free massive multiple-input multiple-output\nsystem and exploit spatial diversity to estimate the set of transmitted\nmessages and the number of users transmitting each message. Our solution relies\non a location-based codeword partition and on the use at the receiver of a\nmultisource approximate message passing algorithm in both centralized and\ndistributed implementations. The proposed TUMA framework results in a robust\nand scalable architecture for massive machine-type communications.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T16:24:46Z"}
{"aid":"http://arxiv.org/abs/2504.19959v1","title":"From Concept to Practice: an Automated LLM-aided UVM Machine for RTL\n  Verification","summary":"Verification presents a major bottleneck in Integrated Circuit (IC)\ndevelopment, consuming nearly 70% of the total development effort. While the\nUniversal Verification Methodology (UVM) is widely used in industry to improve\nverification efficiency through structured and reusable testbenches,\nconstructing these testbenches and generating sufficient stimuli remain\nchallenging. These challenges arise from the considerable manual coding effort\nrequired, repetitive manual execution of multiple EDA tools, and the need for\nin-depth domain expertise to navigate complex designs.Here, we present UVM^2,\nan automated verification framework that leverages Large Language Models (LLMs)\nto generate UVM testbenches and iteratively refine them using coverage\nfeedback, significantly reducing manual effort while maintaining rigorous\nverification standards.To evaluate UVM^2, we introduce a benchmark suite\ncomprising Register Transfer Level (RTL) designs of up to 1.6K lines of\ncode.The results show that UVM^2 reduces testbench setup time by up to UVM^2\ncompared to experienced engineers, and achieve average code and function\ncoverage of 87.44% and 89.58%, outperforming state-of-the-art solutions by\n20.96% and 23.51%, respectively.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-28T16:33:08Z"}
{"aid":"http://arxiv.org/abs/2504.19966v1","title":"Quantum circuit lower bounds in the magic hierarchy","summary":"We introduce the magic hierarchy, a quantum circuit model that alternates\nbetween arbitrary-sized Clifford circuits and constant-depth circuits with\ntwo-qubit gates ($\\textsf{QNC}^0$). This model unifies existing circuit models,\nsuch as $\\textsf{QAC}^0_f$ and models with adaptive intermediate measurements.\nDespite its generality, we are able to prove nontrivial lower bounds.\n  We prove new lower bounds in the first level of the hierarchy, showing that\ncertain explicit quantum states cannot be approximately prepared by circuits\nconsisting of a Clifford circuit followed by $\\textsf{QNC}^0$. These states\ninclude ground states of some topologically ordered Hamiltonians and\nnonstabilizer quantum codes. Our techniques exploit the rigid structure of\nstabilizer codes and introduce an infectiousness property: if even a single\nstate in a high distance code can be approximately prepared by one of these\ncircuits, then the entire subspace must lie close to a perturbed stabilizer\ncode. We also show that proving state preparation lower bounds beyond a certain\nlevel of the hierarchy would imply classical circuit lower bounds beyond the\nreach of current techniques in complexity theory.\n  More broadly, our techniques go beyond lightcone-based methods and highlight\nhow the magic hierarchy provides a natural framework for connecting circuit\ncomplexity, condensed matter, and Hamiltonian complexity.","main_category":"quant-ph","categories":"quant-ph,cs.CC","published":"2025-04-28T16:38:20Z"}
{"aid":"http://arxiv.org/abs/2504.19969v1","title":"Holographic Consequences of Heterotic String Theory beyond its\n  Supergravity Approximation","summary":"In this work, we study the effects of stringy corrections on the low energy\neffective action derived from heterotic string theory beyond its supergravity\napproximation. Compactifying the ten dimensional theory with these stringy\ncorrections produces an effective action for a scalar field whose higher\nderivative term is governed by a single coefficient that depends on the\ninternal volume, average curvature, and flux of the compactification manifold.\nThe higher derivative coupling imported from compactification shifts the\nBreitenlohner Freedman stability bound by an amount set by the relative\nstrengths of internal flux and curvature, relaxing it in flux dominated vacua\nand tightening it in curvature dominated ones. Furthermore, we analyze how the\nstringy corrections shift the scaling dimensions of the dual operators, track\nthe resulting renormalization group flow, and investigate the higher derivative\nterm using a holographic Lee Wick regulator. In holographic superconductors,\nstringy corrections lower the effective bulk mass and raise the critical\ntemperature when flux dominates, but have the opposite effect when curvature\ndominates.","main_category":"hep-th","categories":"hep-th","published":"2025-04-28T16:40:25Z"}
{"aid":"http://arxiv.org/abs/2504.19970v1","title":"Shopformer: Transformer-Based Framework for Detecting Shoplifting via\n  Human Pose","summary":"Shoplifting remains a costly issue for the retail sector, but traditional\nsurveillance systems, which are mostly based on human monitoring, are still\nlargely ineffective, with only about 2% of shoplifters being arrested. Existing\nAI-based approaches rely on pixel-level video analysis which raises privacy\nconcerns, is sensitive to environmental variations, and demands significant\ncomputational resources. To address these limitations, we introduce Shopformer,\na novel transformer-based model that detects shoplifting by analyzing pose\nsequences rather than raw video. We propose a custom tokenization strategy that\nconverts pose sequences into compact embeddings for efficient transformer\nprocessing. To the best of our knowledge, this is the first pose-sequence-based\ntransformer model for shoplifting detection. Evaluated on real-world pose data,\nour method outperforms state-of-the-art anomaly detection models, offering a\nprivacy-preserving, and scalable solution for real-time retail surveillance.\nThe code base for this work is available at\nhttps://github.com/TeCSAR-UNCC/Shopformer.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T16:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.19987v1","title":"Graph Neural Network Prediction of Nonlinear Optical Properties","summary":"Nonlinear optical (NLO) materials for generating lasers via second harmonic\ngeneration (SHG) are highly sought in today's technology. However, discovering\nnovel materials with considerable SHG is challenging due to the time-consuming\nand costly nature of both experimental methods and first-principles\ncalculations. In this study, we present a deep learning approach using the\nAtomistic Line Graph Neural Network (ALIGNN) to predict NLO properties.\nSourcing data from the Novel Opto-Electronic Materials Discovery (NOEMD)\ndatabase and using the Kurtz-Perry (KP) coefficient as the key target, we\ndeveloped a robust model capable of accurately estimating nonlinear optical\nresponses. Our results demonstrate that the model achieves 82.5% accuracy at a\ntolerated absolute error up to 1 pm/V and relative error not exceeding 0.5.\nThis work highlights the potential of deep learning in accelerating the\ndiscovery and design of advanced optical materials with desired properties.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.optics","published":"2025-04-28T17:03:22Z"}
{"aid":"http://arxiv.org/abs/2504.20000v1","title":"Knowledge Distillation of Domain-adapted LLMs for Question-Answering in\n  Telecom","summary":"Knowledge Distillation (KD) is one of the approaches to reduce the size of\nLarge Language Models (LLMs). A LLM with smaller number of model parameters\n(student) is trained to mimic the performance of a LLM of a larger size\n(teacher model) on a specific task. For domain-specific tasks, it is not clear\nif teacher or student model, or both, must be considered for domain adaptation.\nIn this work, we study this problem from perspective of telecom domain\nQuestion-Answering (QA) task. We systematically experiment with Supervised\nFine-tuning (SFT) of teacher only, SFT of student only and SFT of both prior to\nKD. We design experiments to study the impact of vocabulary (same and\ndifferent) and KD algorithms (vanilla KD and Dual Space KD, DSKD) on the\ndistilled model. Multi-faceted evaluation of the distillation using 14\ndifferent metrics (N-gram, embedding and LLM-based metrics) is considered.\nExperimental results show that SFT of teacher improves performance of distilled\nmodel when both models have same vocabulary, irrespective of algorithm and\nmetrics. Overall, SFT of both teacher and student results in better performance\nacross all metrics, although the statistical significance of the same depends\non the vocabulary of the teacher models.","main_category":"cs.CL","categories":"cs.CL,cs.IR,cs.LG,I.2.7","published":"2025-04-28T17:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.20006v1","title":"Chatbot Arena Meets Nuggets: Towards Explanations and Diagnostics in the\n  Evaluation of LLM Responses","summary":"Battles, or side-by-side comparisons in so called arenas that elicit human\npreferences, have emerged as a popular approach to assessing the output quality\nof LLMs. Recently, this idea has been extended to retrieval-augmented\ngeneration (RAG) systems. While undoubtedly representing an advance in\nevaluation, battles have at least two drawbacks, particularly in the context of\ncomplex information-seeking queries: they are neither explanatory nor\ndiagnostic. Recently, the nugget evaluation methodology has emerged as a\npromising approach to evaluate the quality of RAG answers. Nuggets decompose\nlong-form LLM-generated answers into atomic facts, highlighting important\npieces of information necessary in a \"good\" response. In this work, we apply\nour AutoNuggetizer framework to analyze data from roughly 7K Search Arena\nbattles provided by LMArena in a fully automatic manner. Our results show a\nsignificant correlation between nugget scores and human preferences, showcasing\npromise in our approach to explainable and diagnostic system evaluations.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-28T17:24:36Z"}
{"aid":"http://arxiv.org/abs/2504.20011v1","title":"Curiosity Driven Exploration to Optimize Structure-Property Learning in\n  Microscopy","summary":"Rapidly determining structure-property correlations in materials is an\nimportant challenge in better understanding fundamental mechanisms and greatly\nassists in materials design. In microscopy, imaging data provides a direct\nmeasurement of the local structure, while spectroscopic measurements provide\nrelevant functional property information. Deep kernel active learning\napproaches have been utilized to rapidly map local structure to functional\nproperties in microscopy experiments, but are computationally expensive for\nmulti-dimensional and correlated output spaces. Here, we present an alternative\nlightweight curiosity algorithm which actively samples regions with unexplored\nstructure-property relations, utilizing a deep-learning based surrogate model\nfor error prediction. We show that the algorithm outperforms random sampling\nfor predicting properties from structures, and provides a convenient tool for\nefficient mapping of structure-property relationships in materials science.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG","published":"2025-04-28T17:31:29Z"}
{"aid":"http://arxiv.org/abs/2504.20016v1","title":"Applying LLM-Powered Virtual Humans to Child Interviews in\n  Child-Centered Design","summary":"In child-centered design, directly engaging children is crucial for deeply\nunderstanding their experiences. However, current research often prioritizes\nadult perspectives, as interviewing children involves unique challenges such as\nenvironmental sensitivities and the need for trust-building. AI-powered virtual\nhumans (VHs) offer a promising approach to facilitate engaging and multimodal\ninteractions with children. This study establishes key design guidelines for\nLLM-powered virtual humans tailored to child interviews, standardizing\nmultimodal elements including color schemes, voice characteristics, facial\nfeatures, expressions, head movements, and gestures. Using ChatGPT-based prompt\nengineering, we developed three distinct Human-AI workflows (LLM-Auto,\nLLM-Interview, and LLM-Analyze) and conducted a user study involving 15\nchildren aged 6 to 12. The results indicated that the LLM-Analyze workflow\noutperformed the others by eliciting longer responses, achieving higher user\nexperience ratings, and promoting more effective child engagement.","main_category":"cs.HC","categories":"cs.HC,cs.CY,cs.MM","published":"2025-04-28T17:35:46Z"}
{"aid":"http://arxiv.org/abs/2504.20022v1","title":"Better To Ask in English? Evaluating Factual Accuracy of Multilingual\n  LLMs in English and Low-Resource Languages","summary":"Multilingual Large Language Models (LLMs) have demonstrated significant\neffectiveness across various languages, particularly in high-resource languages\nsuch as English. However, their performance in terms of factual accuracy across\nother low-resource languages, especially Indic languages, remains an area of\ninvestigation. In this study, we assess the factual accuracy of LLMs - GPT-4o,\nGemma-2-9B, Gemma-2-2B, and Llama-3.1-8B - by comparing their performance in\nEnglish and Indic languages using the IndicQuest dataset, which contains\nquestion-answer pairs in English and 19 Indic languages. By asking the same\nquestions in English and their respective Indic translations, we analyze\nwhether the models are more reliable for regional context questions in Indic\nlanguages or when operating in English. Our findings reveal that LLMs often\nperform better in English, even for questions rooted in Indic contexts.\nNotably, we observe a higher tendency for hallucination in responses generated\nin low-resource Indic languages, highlighting challenges in the multilingual\nunderstanding capabilities of current LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-28T17:48:13Z"}
{"aid":"http://arxiv.org/abs/2504.20035v1","title":"Cam-2-Cam: Exploring the Design Space of Dual-Camera Interactions for\n  Smartphone-based Augmented Reality","summary":"Off-the-shelf smartphone-based AR systems typically use a single front-facing\nor rear-facing camera, which restricts user interactions to a narrow field of\nview and small screen size, thus reducing their practicality. We present\n\\textit{Cam-2-Cam}, an interaction concept implemented in three\nsmartphone-based AR applications with interactions that span both cameras.\nResults from our qualitative analysis conducted on 30 participants presented\ntwo major design lessons that explore the interaction space of smartphone AR\nwhile maintaining critical AR interface attributes like embodiment and\nimmersion: (1) \\textit{Balancing Contextual Relevance and Feedback Quality}\nserves to outline a delicate balance between implementing familiar interactions\npeople do in the real world and the quality of multimodal AR responses and (2)\n\\textit{Preventing Disorientation using Simultaneous Capture and Alternating\nCameras} which details how to prevent disorientation during AR interactions\nusing the two distinct camera techniques we implemented in the paper.\nAdditionally, we consider observed user assumptions or natural tendencies to\ninform future implementations of dual-camera setups for smartphone-based AR. We\nenvision our design lessons as an initial pioneering step toward expanding the\ninteraction space of smartphone-based AR, potentially driving broader adoption\nand overcoming limitations of single-camera AR.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-28T17:56:40Z"}
{"aid":"http://arxiv.org/abs/2504.20043v1","title":"Starlight from JWST: Implications for star formation and dark matter\n  models","summary":"We confront the star formation rate in different dark matter (DM) models with\nUV luminosity data from JWST up to $z\\simeq25$ and legacy data from HST. We\nfind that a transition from a Salpeter population to top-heavy Pop-III stars is\nlikely at $z\\simeq10$ and that beyond $z=10-15$ the feedback from supernovae\nand active galactic nuclei is progressively reduced, so that at $z\\simeq25$ the\nproduction of stars is almost free from any feedback. We compare fuzzy and warm\nDM models that suppress small-scale structures with the CDM paradigm, finding\nthat the fuzzy DM mass $> 4.5 \\times 10^{-22}{\\rm eV}$ and the warm DM mass $>\n1.5\\, {\\rm keV}$ at the 95\\% CL. The fits of the star formation rate\nparametrization do not depend strongly on the DM properties within the allowed\nrange. We find no preference over CDM for enhanced matter perturbations\nassociated with axion miniclusters or primordial black holes. The scale of the\nenhancement of the power spectrum should be $> 27\\,{\\rm Mpc}^{-1}$ at the 95\\%\nCL, excluding axion miniclusters produced for $m_a < 7.5 \\times 10^{-17}\\,{\\rm\neV}$ or heavy primordial black holes that constitute a fraction $f_{\\rm PBH}$\nof DM in the range $10^{-4} (m_{\\rm PBH}/10^4 \\,M_{\\odot})^{-0.09} < f_{\\rm\nPBH} < 8.7\\times 10^{-3} (m_{\\rm PBH}/10^4\\, M_{\\odot})^{-1}$.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,hep-ph","published":"2025-04-28T17:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.20390v1","title":"Manifold Clustering with Schatten p-norm Maximization","summary":"Manifold clustering, with its exceptional ability to capture complex data\nstructures, holds a pivotal position in cluster analysis. However, existing\nmethods often focus only on finding the optimal combination between K-means and\nmanifold learning, and overlooking the consistency between the data structure\nand labels. To address this issue, we deeply explore the relationship between\nK-means and manifold learning, and on this basis, fuse them to develop a new\nclustering framework. Specifically, the algorithm uses labels to guide the\nmanifold structure and perform clustering on it, which ensures the consistency\nbetween the data structure and labels. Furthermore, in order to naturally\nmaintain the class balance in the clustering process, we maximize the Schatten\np-norm of labels, and provide a theoretical proof to support this.\nAdditionally, our clustering framework is designed to be flexible and\ncompatible with many types of distance functions, which facilitates efficient\nprocessing of nonlinear separable data. The experimental results of several\ndatabases confirm the superiority of our proposed model.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T03:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.20392v1","title":"Pair-Instability Gap Black Holes in Population III Star Clusters:\n  Pathways, Dynamics, and Gravitational Wave Implications","summary":"The detection of the gravitational wave (GW) event GW190521 raises questions\nabout the formation of black holes within the pair-instability mass gap\n(PIBHs). We propose that Population III (Pop III) star clusters significantly\ncontribute to events similar to GW190521. We perform $N$-body simulations and\nfind that PIBHs can form from stellar collisions or binary black hole (BBH)\nmergers, with the latter accounting for 90\\% of the contributions. Due to GW\nrecoil during BBH mergers, approximately 10-50% of PIBHs formed via BBH mergers\nescape from clusters, depending on black hole spins and cluster escape\nvelocities. The remaining PIBHs can participate in secondary and multiple BBH\nformation events, contributing to GW events. Assuming Pop III stars form in\nmassive clusters (initially 100,000 $M_\\odot$) with a top-heavy initial mass\nfunction, the average merger rates for GW events involving PIBHs with 0% and\n100% primordial binaries are $0.005$ and $0.017$ $\\text{yr}^{-1}\n\\text{Gpc}^{-3}$, respectively, with maximum values of $0.030$ and $0.106$\n$\\text{yr}^{-1} \\text{Gpc}^{-3}$. If Pop III stars form in low-mass clusters\n(initial mass of $1000M_\\odot$ and $10000 M_\\odot$), the merger rate is\ncomparable with a 100% primordial binary fraction but significantly lower\nwithout primordial binaries. We also calculate the characteristic strains of\nthe GW events in our simulations and find that about 43.4% (LISA) 97.8% (Taiji)\nand 66.4% (Tianqin) of these events could potentially be detected by\nspace-borne detectors, including LISA, Taiji, and TianQin. The next-generation\nGW detectors such as DECIGO, ET, and CE can nearly cover all these signals.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.GA","published":"2025-04-29T03:26:25Z"}
{"aid":"http://arxiv.org/abs/2504.20393v1","title":"Emergent superconductivity and non-reciprocal transport in a van der\n  Waals Dirac semimetal/antiferromagnet heterostructure","summary":"We investigate emergent superconductivity and non-reciprocal transport\n(magnetochiral anisotropy, superconducting diode effect) at the heterointerface\nof two non-superconducting van der Waals (vdW) materials, the Dirac semimetal\nZrTe$_2$ and the antiferromagnetic iron chalcogenide FeTe, grown using\nmolecular beam epitaxy. We show from electrical transport measurements that two\ndimensional (2D) superconductivity arises at the heterointerface below\ntemperature $T \\sim 12$~K. When capped with a 2D ferromagnet (CrTe$_2$), these\nheterostructures show a superconducting diode effect with efficiency of about\n30\\%. With strong spin-orbit coupling in ZrTe$_2$, these epitaxial\nheterostructures provide an attractive epitaxial vdW platform for exploring\nunconventional superconductivity in Dirac semimetals and for developing\nnon-reciprocal devices for superconducting electronics.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-29T03:32:54Z"}
{"aid":"http://arxiv.org/abs/2504.20400v1","title":"Evolution of Gaussians in the Hellinger-Kantorovich-Boltzmann gradient\n  flow","summary":"This study leverages the basic insight that the gradient-flow equation\nassociated with the relative Boltzmann entropy, in relation to a Gaussian\nreference measure within the Hellinger-Kantorovich (HK) geometry, preserves the\nclass of Gaussian measures. This invariance serves as the foundation for\nconstructing a reduced gradient structure on the parameter space characterizing\nGaussian densities. We derive explicit ordinary differential equations that\ngovern the evolution of mean, covariance, and mass under the HK-Boltzmann\ngradient flow. The reduced structure retains the additive form of the HK\nmetric, facilitating a comprehensive analysis of the dynamics involved.\n  We explore the geodesic convexity of the reduced system, revealing that\nglobal convexity is confined to the pure transport scenario, while a variant of\nsublevel semi-convexity is observed in the general case. Furthermore, we\ndemonstrate exponential convergence to equilibrium through\nPolyak-Lojasiewicz-type inequalities, applicable both globally and on sublevel\nsets. By monitoring the evolution of covariance eigenvalues, we refine the\ndecay rates associated with convergence. Additionally, we extend our analysis\nto non-Gaussian targets exhibiting strong log-lambda-concavity, corroborating\nour theoretical results with numerical experiments that encompass a\nGaussian-target gradient flow and a Bayesian logistic regression application.","main_category":"math.AP","categories":"math.AP,math.PR,stat.ML","published":"2025-04-29T03:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.20409v1","title":"GarmentX: Autoregressive Parametric Representations for High-Fidelity 3D\n  Garment Generation","summary":"This work presents GarmentX, a novel framework for generating diverse,\nhigh-fidelity, and wearable 3D garments from a single input image. Traditional\ngarment reconstruction methods directly predict 2D pattern edges and their\nconnectivity, an overly unconstrained approach that often leads to severe\nself-intersections and physically implausible garment structures. In contrast,\nGarmentX introduces a structured and editable parametric representation\ncompatible with GarmentCode, ensuring that the decoded sewing patterns always\nform valid, simulation-ready 3D garments while allowing for intuitive\nmodifications of garment shape and style. To achieve this, we employ a masked\nautoregressive model that sequentially predicts garment parameters, leveraging\nautoregressive modeling for structured generation while mitigating\ninconsistencies in direct pattern prediction. Additionally, we introduce\nGarmentX dataset, a large-scale dataset of 378,682 garment parameter-image\npairs, constructed through an automatic data generation pipeline that\nsynthesizes diverse and high-quality garment images conditioned on parametric\ngarment representations. Through integrating our method with GarmentX dataset,\nwe achieve state-of-the-art performance in geometric fidelity and input image\nalignment, significantly outperforming prior approaches. We will release\nGarmentX dataset upon publication.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T04:15:33Z"}
{"aid":"http://arxiv.org/abs/2504.20416v1","title":"Large-scale artificial intelligence with 41 million nanophotonic neurons\n  on a metasurface","summary":"Conventional integrated circuits (ICs) struggle to meet the escalating\ndemands of artificial intelligence (AI). This has sparked a renewed interest in\nan unconventional computing paradigm: neuromorphic (brain-inspired) computing.\nHowever, current neuromorphic systems face significant challenges in delivering\na large number of parameters (i.e., weights) required for large-scale AI\nmodels. As a result, most neuromorphic hardware is limited to basic benchmark\ndemonstrations, hindering its application to real-world AI challenges. Here, we\npresent a large-scale optical neural network (ONN) for machine learning\nacceleration, featuring over 41 million photonic neurons. This system not only\nsurpasses digital electronics in speed and energy efficiency but more\nimportantly, closes the performance gap with large-scale AI models. Our ONN\nleverages an innovative optical metasurface device featuring numerous spatial\nmodes. This device integrates over 41 million meta-atoms on a 10 mm$^2$\nmetasurface chip, enabling the processing of tens of millions of weights in a\nsingle operation. For the first time, we demonstrate that an ONN, utilizing a\nsingle-layer metasurface, can match the performance of deep and large-scale\ndeep learning models, such as ResNet and Vision Transformer, across various\nbenchmark tasks. Additionally, we show that our system can deliver\nhigh-performance solutions to real-world AI challenges through its\nunprecedented scale, such as accelerating the analysis of multi-gigapixel whole\nslide images (WSIs) for cancer detection by processing the million-pixel\nsub-image in a single shot. Our system reduces computing time and energy\nconsumption by over 1,000 times compared to state-of-the-art graphic processing\nunits (GPUs). This work presents a large-scale, low-power, and high-performance\nneuromorphic computing system, paving the way for future disruptive AI\ntechnologies.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T04:27:35Z"}
{"aid":"http://arxiv.org/abs/2504.20417v1","title":"Protocol-level description and self-contained security proof of\n  decoy-state BB84 QKD protocol","summary":"In this paper, we present a flowchart-based description of the decoy-state\nBB84 quantum key distribution (QKD) protocol and provide a step-by-step,\nself-contained information-theoretic security proof for this protocol within\nthe universal composable security framework. As a result, our proof yields a\nkey rate consistent with previous findings. Importantly, unlike all the prior\nsecurity proofs, our approach offers a fully rigorous and mathematical\njustification for achieving the key rate with the claimed correctness and\nsecrecy parameters, thereby representing a significant step toward the formal\ncertification of QKD systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T04:28:15Z"}
{"aid":"http://arxiv.org/abs/2504.20423v1","title":"Redox chemistry meets semiconductor defect physics","summary":"Understanding how the electronic structure of electrodes influences\nelectrocatalytic reactions has been a longstanding topic in the\nelectrochemistry community, with predominant attention paid to metallic\nelectrodes. In this work, we present a defect physics perspective on the effect\nof semiconductor band structure on electrochemical redox reactions.\nSpecifically, the Haldane-Anderson model, originally developed to study\nmultiple charge states of transition-metal defects in semiconductors, is\nextended to describe electrochemical redox reactions by incorporating the\nsolvent effect, inspired by the Holstein model. The solvent coordinate and the\nactual charge on the redox species in reduced and oxidized states are assumed\nto be instant equilibrium, and the transitions between these states are defined\nby the framework of Green's function. With these treatments, we treat the\ncharge state transition in a self-consistent manner. We first confirm that this\nself-consistent approach is essential to accurately depict the hybridization\neffect of band structure by comparing the model-calculated ionization potential\n(IP), electron affinity (EA), and redox potential of the species with those\nobtained from density functional theory (DFT) calculations. Next, we illustrate\nhow this self-consistent treatment enhances our understanding of the catalytic\nactivities of semiconductor electrodes and the source of asymmetry in\nreorganization energies, which is often observed in prior ab initio molecular\ndynamics (AIMD) simulations. Additionally, we discuss how band structure\nimpacts redox reactions in the strong coupling limit. Finally, we compare our\nwork with other relevant studies in the literature.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-29T04:38:55Z"}
{"aid":"http://arxiv.org/abs/2504.20430v1","title":"Learning Laplacian Positional Encodings for Heterophilous Graphs","summary":"In this work, we theoretically demonstrate that current graph positional\nencodings (PEs) are not beneficial and could potentially hurt performance in\ntasks involving heterophilous graphs, where nodes that are close tend to have\ndifferent labels. This limitation is critical as many real-world networks\nexhibit heterophily, and even highly homophilous graphs can contain local\nregions of strong heterophily. To address this limitation, we propose Learnable\nLaplacian Positional Encodings (LLPE), a new PE that leverages the full\nspectrum of the graph Laplacian, enabling them to capture graph structure on\nboth homophilous and heterophilous graphs. Theoretically, we prove LLPE's\nability to approximate a general class of graph distances and demonstrate its\ngeneralization properties. Empirically, our evaluation on 12 benchmarks\ndemonstrates that LLPE improves accuracy across a variety of GNNs, including\ngraph transformers, by up to 35% and 14% on synthetic and real-world graphs,\nrespectively. Going forward, our work represents a significant step towards\ndeveloping PEs that effectively capture complex structures in heterophilous\ngraphs.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T04:58:13Z"}
{"aid":"http://arxiv.org/abs/2504.20441v1","title":"Task-Oriented Semantic Communication with Importance-Aware Rate Control","summary":"Semantic communication is recognized for its high compression efficiency and\nrobust resistance to noise. However, utilizing a fixed transmission rate in\nenvironments with dynamic signal-to-noise ratios (SNR) often results in\ninefficient use of communication resources. To address this challenge, this\nletter proposes an importance-aware rate control semantic communication (IRCSC)\nscheme, which dynamically adjusts transmission rates in response to both\nchannel conditions and semantic importance. The scheme employs a\ncontribution-based importance analyzer to rank semantic importance.\nAdditionaly, a novel metric, the semantic transmission integrity index (STII),\nis proposed to quantify the amount of correctly transmitted information and to\ncorrelate it with inference performance. Simulations indicate that, with low\ncomputational complexity, IRCSC guarantees a controllable trade-off between\nperformance and rate, delivering higher compression efficiency and improved\ntask performance in high-SNR scenarios.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T05:32:18Z"}
{"aid":"http://arxiv.org/abs/2504.20456v1","title":"Reviving Any-Subset Autoregressive Models with Principled Parallel\n  Sampling and Speculative Decoding","summary":"In arbitrary-order language models, it is an open question how to sample\ntokens in parallel from the correct joint distribution. With discrete diffusion\nmodels, the more tokens they generate in parallel, the less their predicted\ndistributions adhere to the originally learned data distribution, as they rely\non a conditional independence assumption that only works with infinitesimally\nsmall timesteps. We find that a different class of models, any-subset\nautoregressive models (AS-ARMs), holds the solution. As implied by the name,\nAS-ARMs can generate tokens in any order, and in parallel. Moreover, AS-ARMs\nsupport parallelized joint probability density estimation, allowing them to\ncorrect their own parallel-generated token distributions, via our Any-Subset\nSpeculative Decoding (ASSD) algorithm. ASSD provably enables generation of\ntokens from the correct joint distribution, with the number of neural network\ncalls upper bounded by the number of tokens predicted. We empirically verify\nthat ASSD speeds up language generation, without sacrificing quality.\nFurthermore, we provide a mathematically justified scheme for training AS-ARMs\nfor generation, and show that AS-ARMs achieve state-of-the-art performance\namong sub-200M parameter models on infilling benchmark tasks, and nearly match\nthe performance of models 50X larger on code generation. Our theoretical and\nempirical results indicate that the once-forgotten AS-ARMs are a promising\ndirection of language modeling.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-29T06:33:13Z"}
{"aid":"http://arxiv.org/abs/2504.20467v1","title":"Switching, Multiple Time-Scales and Geometric Blow-Up in a\n  Low-Dimensional Gene Regulatory Network","summary":"ODE-based models for gene regulatory networks (GRNs) can often be formulated\nas smooth singular perturbation problems with multiple small parameters, some\nof which are related to time-scale separation, whereas others are related to\n'switching' (proximity to a non-smooth singular limit). This motivates the\nstudy of reduced models obtained after (i) quasi-steady state reduction (QSSR),\nwhich utilises the time-scale separation, and (ii) piecewise-smooth\napproximations, which reduce the nonlinearity of the model by viewing highly\nnonlinear sigmoidal terms as singular perturbations of step functions. We\ninvestigate the interplay between the reduction methods (i)-(ii), in the\ncontext of a 4-dimensional GRN which has been used as a low-dimensional\nrepresentative of an important class of (generally high-dimensional) GRN models\nin the literature. We begin by identifying a region in the small parameter\nplane for which this problem can be formulated as a smooth singularly perturbed\nsystem on a blown-up space, uniformly in the switching parameter. This allows\nus to apply Fenichel's coordinate-free theorems and obtain a rigorous reduction\nto a 2-dimensional system, that is a perturbation of the QSSR. Finally, we show\nthat the reduced system features a Hopf bifurcation which does not appear in\nthe QSSR system, due to the influence of higher order terms. Taken together,\nour findings suggest that the relative size of the small parameters is\nimportant for the validity of QSS reductions and the determination of\nqualitative dynamics in GRN models more generally. Although the focus is on the\n4-dimensional GRN, our approach is applicable to higher dimensions.","main_category":"math.DS","categories":"math.DS","published":"2025-04-29T07:05:05Z"}
{"aid":"http://arxiv.org/abs/2504.20471v1","title":"The Estimation of Continual Causal Effect for Dataset Shifting Streams","summary":"Causal effect estimation has been widely used in marketing optimization. The\nframework of an uplift model followed by a constrained optimization algorithm\nis popular in practice. To enhance performance in the online environment, the\nframework needs to be improved to address the complexities caused by temporal\ndataset shift. This paper focuses on capturing the dataset shift from user\nbehavior and domain distribution changing over time. We propose an Incremental\nCausal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle\nthis challenge. The ICE-PKD framework includes two components: (i) a\nmulti-treatment uplift network that eliminates confounding bias using\ncounterfactual regression; (ii) an incremental training strategy that adapts to\nthe temporal dataset shift by updating with the latest data and protects\ngeneralization via replay-based knowledge distillation. We also revisit the\nuplift modeling metrics and introduce a novel metric for more precise online\nevaluation in multiple treatment scenarios. Extensive experiments on both\nsimulated and online datasets show that the proposed framework achieves better\nperformance. The ICE-PKD framework has been deployed in the marketing system of\nHuaxiaozhu, a ride-hailing platform in China.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ME","published":"2025-04-29T07:13:28Z"}
{"aid":"http://arxiv.org/abs/2504.20473v1","title":"Large-data regular solutions in a one-dimensional thermoviscoelastic\n  evolution problem involving temperature-dependent viscosities","summary":"The model \\[\n  \\left\\{ \\begin{array}{l}\n  u_{tt} = \\big(\\gamma(\\Theta) u_{xt}\\big)_x + au_{xx} - \\big(f(\\Theta)\\big)_x,\n\\\\[1mm]\n  \\Theta_t = \\Theta_{xx} + \\gamma(\\Theta) u_{xt}^2 - f(\\Theta) u_{xt},\n  \\end{array} \\right. \\] for thermoviscoelastic evolution in one-dimensional\nKelvin-Voigt materials is considered.\n  By means of an approach based on maximal Sobolev regularity theory of scalar\nparabolic equations, it is shown that if $\\gamma_0>0$ is fixed, then there\nexists $\\delta=\\delta(\\gamma_0)>0$ with the property that for suitably regular\ninitial data of arbitrary size an associated initial-boundary value problem\nposed in an open bounded interval admits a global classical solution whenever\n$\\gamma\\in C^2([0,\\infty))$ and $f\\in C^2([0,\\infty))$ are such that $f(0)=0$\nand $|f(\\xi)| \\le K_f \\cdot (\\xi+1)^\\alpha$ for all $\\xi\\ge 0$ and some $K_f>0$\nand $\\alpha<\\frac{3}{2}$, and that \\[\n  \\gamma_0 \\le \\gamma(\\xi) \\le \\gamma_0 + \\delta\n  \\qquad \\mbox{for all } \\xi\\ge 0. \\] This is supplemented by a statement on\nglobal existence of certain strong solutions, particularly continuous in both\ncomponents, under weaker conditions on the initial data.","main_category":"math.AP","categories":"math.AP","published":"2025-04-29T07:14:22Z"}
{"aid":"http://arxiv.org/abs/2504.20479v1","title":"Full-field surrogate modeling of cardiac function encoding geometric\n  variability","summary":"Combining physics-based modeling with data-driven methods is critical to\nenabling the translation of computational methods to clinical use in\ncardiology. The use of rigorous differential equations combined with machine\nlearning tools allows for model personalization with uncertainty quantification\nin time frames compatible with clinical practice. However, accurate and\nefficient surrogate models of cardiac function, built from physics-based\nnumerical simulation, are still mostly geometry-specific and require retraining\nfor different patients and pathological conditions. We propose a novel\ncomputational pipeline to embed cardiac anatomies into full-field surrogate\nmodels. We generate a dataset of electrophysiology simulations using a complex\nmulti-scale mathematical model coupling partial and ordinary differential\nequations. We adopt Branched Latent Neural Maps (BLNMs) as an effective\nscientific machine learning method to encode activation maps extracted from\nphysics-based numerical simulations into a neural network. Leveraging large\ndeformation diffeomorphic metric mappings, we build a biventricular anatomical\natlas and parametrize the anatomical variability of a small and challenging\ncohort of 13 pediatric patients affected by Tetralogy of Fallot. We propose a\nnovel statistical shape modeling based z-score sampling approach to generate a\nnew synthetic cohort of 52 biventricular geometries that are compatible with\nthe original geometrical variability. This synthetic cohort acts as the\ntraining set for BLNMs. Our surrogate model demonstrates robustness and great\ngeneralization across the complex original patient cohort, achieving an average\nadimensional mean squared error of 0.0034. The Python implementation of our\nBLNM model is publicly available under MIT License at\nhttps://github.com/StanfordCBCL/BLNM.","main_category":"eess.IV","categories":"eess.IV,cs.LG","published":"2025-04-29T07:22:06Z"}
{"aid":"http://arxiv.org/abs/2504.20481v1","title":"Self-consistency error correction for accurate machine learning\n  potentials from variational Monte Carlo","summary":"Variational Monte Carlo (VMC) can be used to train accurate machine learning\ninteratomic potentials (MLIPs), enabling molecular dynamics (MD) simulations of\ncomplex materials on time scales and for system sizes previously unattainable.\nVMC training sets are often based on partially optimized wave functions (WFs)\nto circumvent expensive energy optimizations of the whole set of WF parameters.\nHowever, frozen variational parameters lead to VMC forces and pressures not\nconsistent with the underlying potential energy surface, a bias called the\nself-consistency error (SCE). Here, we demonstrate how the SCE can spoil the\naccuracy of MLIPs trained on these data, taking high-pressure hydrogen as test\ncase. We then apply a recently introduced SCE correction [ Phys. Rev. B 109,\n205151 (2024)] to generate unbiased VMC training sets based on a\nJastrow-correlated single determinant WF with frozen Kohn-Sham orbitals. The\nMLIPs generated within this framework are significantly improved and can\napproach in quality those trained on datasets built with fully optimized WFs.\nOur conclusions are further supported by MD simulations, which show how MLIPs\ntrained on SCE-corrected datasets systematically yield more reliable physical\nobservables. Our framework opens the possibility of constructing extended\nhigh-quality training sets with VMC.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.dis-nn,cond-mat.mtrl-sci","published":"2025-04-29T07:22:31Z"}
{"aid":"http://arxiv.org/abs/2504.20483v1","title":"Merger-Driven Turbulence and Coherent Transport in the Intracluster\n  Medium","summary":"The distribution of metals and temperature in the intracluster medium (ICM)\nprovides key insights into galaxy cluster evolution, revealing information\nabout chemical enrichment and heating and cooling processes, respectively. To\naccess this information, it is crucial to understand the transport processes in\nthe ICM. Here, we systematically study the transport mechanisms in the ICM with\ntracer particle resimulations of the Omega500 cosmological hydrosimulation,\nusing a sample of four galaxy clusters of comparable masses but different mass\nassembly histories. Through the analysis of particle pair dispersion\nstatistics, we find a time-dependent scaling index linked to the cluster's\ndynamical state. It reaches or exceeds Richardson scaling briefly during major\nmergers but remains much lower in relaxed clusters. We identify a coherent\ntransport mode during major mergers that causes directional flow in the ICM.\nAlthough coherent transport can move particles to outer regions, the particles\ntransported to the cluster outskirts compose only a small fraction of the\ndensity there; thus the anisotropy it creates in the overall density\ndistribution is limited. Moreover, strong turbulence generated by mergers\nquickly disperses these particles, further limiting this effect. We also\nprovide useful statistics on the radial evolution of the ICM and the fraction\nof particles that ever reached the inner regions as a function of radius. Our\nresults show that major mergers primarily drive particle transport, linking ICM\ntransport to merger-driven dynamics, and highlighting the interplay between\ncoherent and turbulent transport.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.CO","published":"2025-04-29T07:23:29Z"}
{"aid":"http://arxiv.org/abs/2504.20488v1","title":"Scaling and shape of financial returns distributions modeled as\n  conditionally independent random variables","summary":"We show that assuming that the returns are independent when conditioned on\nthe value of their variance (volatility), which itself varies in time randomly,\nthen the distribution of returns is well described by the statistics of the sum\nof conditionally independent random variables. In particular, we show that the\ndistribution of returns can be cast in a simple scaling form, and that its\nfunctional form is directly related to the distribution of the volatilities.\nThis approach explains the presence of power-law tails in the returns as a\ndirect consequence of the presence of a power law tail in the distribution of\nvolatilities. It also provides the form of the distribution of Bitcoin returns,\nwhich behaves as a stretched exponential, as a consequence of the fact that the\nBitcoin volatilities distribution is also closely described by a stretched\nexponential. We test our predictions with data from the S\\&P 500 index, Apple\nand Paramount stocks; and Bitcoin.","main_category":"q-fin.ST","categories":"q-fin.ST,stat.AP","published":"2025-04-29T07:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.20498v1","title":"Style-Adaptive Detection Transformer for Single-Source Domain\n  Generalized Object Detection","summary":"Single-source Domain Generalization (SDG) in object detection aims to develop\na detector using only data from a source domain that can exhibit strong\ngeneralization capability when applied to unseen target domains. Existing\nmethods are built upon CNN-based detectors and primarily improve robustness by\nemploying carefully designed data augmentation strategies integrated with\nfeature alignment techniques. However, data augmentation methods have inherent\ndrawbacks; they are only effective when the augmented sample distribution\napproximates or covers the unseen scenarios, thus failing to enhance\ngeneralization across all unseen domains. Furthermore, while the recent\nDetection Transformer (DETR) has demonstrated superior generalization\ncapability in domain adaptation tasks due to its efficient global information\nextraction, its potential in SDG tasks remains unexplored. To this end, we\nintroduce a strong DETR-based detector named the Style-Adaptive Detection\nTransformer (SA-DETR) for SDG in object detection. Specifically, we present a\ndomain style adapter that projects the style representation of the unseen\ntarget domain into the training domain, enabling dynamic style adaptation.\nThen, we propose an object-aware contrastive learning module to guide the\ndetector in extracting domain-invariant features through contrastive learning.\nBy using object-aware gating masks to constrain feature aggregation in both\nspatial and semantic dimensions, this module achieves cross-domain contrast of\ninstance-level features, thereby enhancing generalization. Extensive\nexperiments demonstrate the superior performance and generalization capability\nof SA-DETR across five different weather scenarios. Code is released at\nhttps://github.com/h751410234/SA-DETR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T07:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.20514v1","title":"Distributed U6G ELAA Communication Systems: Channel Measurement and\n  Small-Scale Fading Characterization","summary":"The distributed upper 6 GHz (U6G) extra-large scale antenna array (ELAA) is a\nkey enabler for future wireless communication systems, offering higher\nthroughput and wider coverage, similar to existing ELAA systems, while\neffectively mitigating unaffordable complexity and hardware overhead. Uncertain\nchannel characteristics, however, present significant bottleneck problems that\nhinder the hardware structure and algorithm design of the distributed U6G ELAA\nsystem. In response, we construct a U6G channel sounder and carry out extensive\nmeasurement campaigns across various typical scenarios. Initially, U6G channel\ncharacteristics, particularly small-scale fading characteristics, are unveiled\nand compared across different scenarios. Subsequently, the U6G ELAA channel\ncharacteristics are analyzed using a virtual array comprising 64 elements.\nFurthermore, inspired by the potential for distributed processing, we\ninvestigate U6G ELAA channel characteristics from the perspectives of subarrays\nand sub-bands, including subarray-wise nonstationarities, consistencies,\nfar-field approximations, and sub-band characteristics. Through a combination\nof analysis and measurement validation, several insights and benefits,\nparticularly suitable for distributed processing in U6G ELAA systems, are\nrevealed, which provides practical validation for the deployment of U6G ELAA\nsystems.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T07:57:08Z"}
{"aid":"http://arxiv.org/abs/2504.20518v1","title":"Dynamic Attention Analysis for Backdoor Detection in Text-to-Image\n  Diffusion Models","summary":"Recent studies have revealed that text-to-image diffusion models are\nvulnerable to backdoor attacks, where attackers implant stealthy textual\ntriggers to manipulate model outputs. Previous backdoor detection methods\nprimarily focus on the static features of backdoor samples. However, a vital\nproperty of diffusion models is their inherent dynamism. This study introduces\na novel backdoor detection perspective named Dynamic Attention Analysis (DAA),\nshowing that these dynamic characteristics serve as better indicators for\nbackdoor detection. Specifically, by examining the dynamic evolution of\ncross-attention maps, we observe that backdoor samples exhibit distinct feature\nevolution patterns at the $<$EOS$>$ token compared to benign samples. To\nquantify these dynamic anomalies, we first introduce DAA-I, which treats the\ntokens' attention maps as spatially independent and measures dynamic feature\nusing the Frobenius norm. Furthermore, to better capture the interactions\nbetween attention maps and refine the feature, we propose a dynamical\nsystem-based approach, referred to as DAA-S. This model formulates the spatial\ncorrelations among attention maps using a graph-based state equation and we\ntheoretically analyze the global asymptotic stability of this method. Extensive\nexperiments across five representative backdoor attack scenarios demonstrate\nthat our approach significantly surpasses existing detection methods, achieving\nan average F1 Score of 79.49% and an AUC of 87.67%. The code is available at\nhttps://github.com/Robin-WZQ/DAA.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-29T07:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.20529v1","title":"Safe Bottom-Up Flexibility Provision from Distributed Energy Resources","summary":"Modern renewables-based power systems need to tap on the flexibility of\nDistributed Energy Resources (DERs) connected to distribution networks. It is\nimportant, however, that DER owners/users remain in control of their assets,\ndecisions, and objectives. At the same time, the dynamic landscape of\nDER-penetrated distribution networks calls for agile, data-driven flexibility\nmanagement frameworks. In the face of these developments, the Multi-Agent\nReinforcement Learning (MARL) paradigm is gaining significant attention, as a\ndistributed and data-driven decision-making policy. This paper addresses the\nneed for bottom-up DER management decisions to account for the distribution\nnetwork's safety-related constraints. While the related literature on safe MARL\ntypically assumes that network characteristics are available and incorporated\ninto the policy's safety layer, which implies active DSO engagement, this paper\nensures that self-organized DER communities are enabled to provide\ndistribution-network-safe flexibility services without relying on the\naspirational and problematic requirement of bringing the DSO in the\ndecision-making loop.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-29T08:16:15Z"}
{"aid":"http://arxiv.org/abs/2504.20531v1","title":"Addressing Data Scarcity in UBEM Validation: Application of Survey\n  Sampling Techniques","summary":"Urban Building Energy Models (UBEM) are vital for enhancing energy efficiency\nand sustainability in urban planning. However, data scarcity often challenges\ntheir validation, particularly the lack of hourly measured data and the variety\nof building samples. This study addresses this issue by applying bias\nadjustment techniques from survey research to improve UBEM validation\nrobustness with incomplete measured data. Error estimation tests are conducted\nusing various levels of missingness, and three bias adjustment methods are\nemployed: multivariate imputation, cell weighting and raking weighting. Key\nfindings indicate that using incomplete data in UBEM validation without\nadjustment is not advisable, while bias adjustment techniques significantly\nenhance the robustness of validation, providing more reliable model validity\nestimates. Cell weighting is preferable in this study due to its reliance on\njoint distributions of auxiliary variables.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-29T08:23:04Z"}
{"aid":"http://arxiv.org/abs/2504.20544v1","title":"Efficient patient-centric EMR sharing block tree","summary":"Flexible sharing of electronic medical records (EMRs) is an urgent need in\nhealthcare, as fragmented storage creates EMR management complexity for both\npractitioners and patients. Blockchain has emerged as a promising solution to\naddress the limitations of centralized EMR systems regarding interoperability,\ndata ownership, and trust concerns. Whilst its healthcare implementation\ncontinues to face scalability challenges, particularly in uploading lag time as\nEMR volumes increase. In this paper, we describe the design of a novel\nblockchain-based data structure, MedBlockTree, which aims to solve the\nscalability issue in blockchain-based EMR systems, particularly low block\nthroughput and patient awareness. MedBlockTree leverages a chameleon hash\nfunction to generate collision blocks for existing patients and expand a single\nchain into a growing block tree with $n$ branches that are capable of\nprocessing $n$ new blocks in a single consensus round. We also introduce the\nEnhancedPro consensus algorithm to manage multiple branches and maintain\nnetwork consistency. Our comprehensive simulation evaluates performance across\nfour dimensions: branch number, worker number, collision rate, and network\nlatency. Comparative analysis against a traditional blockchain-based EMR system\ndemonstrates outstanding throughput improvements across all dimensions,\nachieving processing speeds $\\nu\\cdot n$ times faster than conventional\napproaches.","main_category":"cs.DC","categories":"cs.DC,cs.CR","published":"2025-04-29T08:42:01Z"}
{"aid":"http://arxiv.org/abs/2504.20545v1","title":"WakeLoc: An Ultra-Low Power, Accurate and Scalable On-Demand RTLS using\n  Wake-Up Radios","summary":"For future large scale robotic moon missions, the availability of\ninfrastructure-less, cheap and low power real-time locating systems (RTLSs) is\ncritical. Traditional RTLS face significant trade-offs between power\nconsumption and localization latency, often requiring anchors to be connected\nto the power grid or sacrificing speed for energy efficiency. This paper\nproposes WakeLoc, an on-demand RTLS based on ultra-wideband (UWB), enabling\nboth low-latency and ultra-low power consumption by leveraging UWB wake-up\nradios (WuRs). In WakeLoc, tags independently start a localization procedure by\nsending a wake-up call (WuC) to anchors, before performing the actual\nlocalization. Distributed tags equipped with WuRs listen to the WuC and use\npassive listening of the UWB messages to determine their own position.\nExperimental measurements demonstrate that the localization accuracy in a 2D\nsetup achieves less than 12.9cm error, both for the active and the passive tag.\nAdditional power simulations based on real-world measurements were performed in\na realistic environment, showing that anchors can achieve a power consumption\nas low as 15.53{\\mu}W while the RTLS performs one on-demand localization per\nminute for 5 tags, thus operate up to 5.01 years on a single coin cell battery\n(690mWh).","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-29T08:42:41Z"}
{"aid":"http://arxiv.org/abs/2504.20582v1","title":"Thin accretion disk around a Kerr black hole immersed in swirling\n  universes","summary":"We have studied the properties of the thin accretion disk around a\nswirling-Kerr black hole, which owns an extra swirling parameter described the\nrotation of the immersed universe. Our results show that the swirling parameter\nimprints in the energy flux, temperature distribution and emission spectra of\nthe disk and gives rise to some new effects differed from those arising from\nthe black hole spin. With the increasing of the swirling parameter, the energy\nflux and the radiated temperature in the disk increase in the near region with\nthe smaller circular orbital radius and decrease in the far region with the\nlarger circular orbital radius. However, they always increase with the black\nhole spin. Although the swirling parameter and the black hole spin parameter\nlead to the higher cut-off frequencies, the background swirling decreases the\nobserved luminosity of the disk at the lower frequencies and enhances the\nhigher observed luminosity only at the higher frequencies, which differs from\nthat of the black hole spin. Moreover, the conversion efficiency increases with\nthe black hole spin parameter, but decreases with on the swirling parameters.\nFurthermore, effects of the swirling parameter are found to be suppressed by\nthe black hole spin parameter. These results could help us to further\nunderstand the properties of thin accretion disks and the swirling of the\nuniverse background.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-29T09:36:49Z"}
{"aid":"http://arxiv.org/abs/2504.20597v1","title":"How to be an orthodox quantum mechanic","summary":"This work sets out to answer a single question: what is the orthodox\ninterpretation of quantum mechanics? However, we adopt a different approach to\nthat normally used. Rather than carefully surveying the precise details of the\nthoughts of Bohr and Heisenberg, we extract an orthodoxy empirically. To do\nthis we review a collection of 33 textbooks on quantum mechanics, encompassing\nthe most popular and prominent works of this nature. We then gauge their\nresponse to 12 propositions to build up a picture of exactly what is believed\nby an orthodox quantum mechanic. We demonstrate that this orthodoxy is largely\nunchanged over the past century, with some interesting emerging deviations, and\nhas many aspects of Copenhagen-like viewpoints. However, it is more nuanced\nthan some reductive characterisations that condense it down to the ontological\nprimacy of the quantum state. The revealed orthodoxy has two main pillars:\nmeasurement inherently disturbs quantum states and these states refer to\nindividual instances, not ensembles. More fully it entails that individual\nparticles exist in wave-like super-positions and present particle behaviours\nonly when forced to by outside influences. The act of measuring such a system\ninherently changes its state in a random fashion, manifesting in a form of\nmeasurement error that corresponds to the uncertainty principle. This implies\nthat measurement does not reveal underlying values of quantum properties.","main_category":"quant-ph","categories":"quant-ph,physics.hist-ph","published":"2025-04-29T09:50:54Z"}
{"aid":"http://arxiv.org/abs/2504.20600v1","title":"A citation index bridging Hirsch's h and Egghe's g","summary":"We propose a citation index $\\nu$ (``nu'') and show that it lies between the\nclassical $h$-index and $g$-index. This idea is then generalized to a monotone\nparametric family $(\\nu_\\alpha)$ ($\\alpha\\ge 0$), whereby $h=\\nu_0$ and\n$\\nu=\\nu_1$, while the limiting value $\\nu_\\infty$ is expressed in terms of the\nmaximum citation.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-29T10:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.20623v1","title":"Cell-free Fluid Antenna Multiple Access Networks","summary":"Fluid antenna enables position reconfigurability that gives transceiver\naccess to a high-resolution spatial signal and the ability to avoid\ninterference through the ups and downs of fading channels. Previous studies\ninvestigated this fluid antenna multiple access (FAMA) approach in a\nsingle-cell setup only. In this paper, we consider a cell-free network\narchitecture in which users are associated with the nearest base stations (BSs)\nand all users share the same physical channel. Each BS has multiple fixed\nantennas that employ maximum ratio transmission (MRT) to beam to its associated\nusers while each user relies on its fluid antenna system (FAS) on one radio\nfrequency (RF) chain to overcome the inter-user interference. Our aim is to\nanalyze the outage probability performance of such cell-free FAMA network when\nboth large- and small-scale fading effects are considered. To do so, we derive\nthe distribution of the received \\textcolor{black}{magnitude} for a typical\nuser and then the interference distribution under both fast and slow port\nswitching techniques. The outage probability is finally obtained in integral\nform in each case. Numerical results demonstrate that in an\ninterference-limited situation, although fast port switching is typically\nunderstood as the superior method for FAMA, slow port switching emerges as a\nmore effective solution when there is a large antenna array at the BS.\nMoreover, it is revealed that FAS at each user can serve to greatly reduce the\nburden of BS in terms of both antenna costs and CSI estimation overhead,\nthereby enhancing the scalability of cell-free networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T10:50:10Z"}
{"aid":"http://arxiv.org/abs/2504.20628v1","title":"Cognitive maps are generative programs","summary":"Making sense of the world and acting in it relies on building simplified\nmental representations that abstract away aspects of reality. This principle of\ncognitive mapping is universal to agents with limited resources. Living\norganisms, people, and algorithms all face the problem of forming functional\nrepresentations of their world under various computing constraints. In this\nwork, we explore the hypothesis that human resource-efficient planning may\narise from representing the world as predictably structured. Building on the\nmetaphor of concepts as programs, we propose that cognitive maps can take the\nform of generative programs that exploit predictability and redundancy, in\ncontrast to directly encoding spatial layouts. We use a behavioral experiment\nto show that people who navigate in structured spaces rely on modular planning\nstrategies that align with programmatic map representations. We describe a\ncomputational model that predicts human behavior in a variety of structured\nscenarios. This model infers a small distribution over possible programmatic\ncognitive maps conditioned on human prior knowledge of the world, and uses this\ndistribution to generate resource-efficient plans. Our models leverages a Large\nLanguage Model as an embedding of human priors, implicitly learned through\ntraining on a vast corpus of human data. Our model demonstrates improved\ncomputational efficiency, requires drastically less memory, and outperforms\nunstructured planning algorithms with cognitive constraints at predicting human\nbehavior, suggesting that human planning strategies rely on programmatic\ncognitive maps.","main_category":"cs.AI","categories":"cs.AI,cs.ET","published":"2025-04-29T10:55:40Z"}
{"aid":"http://arxiv.org/abs/2504.20633v1","title":"Collapse of molecular orbital by ultrahigh magnetic fields in\n  V$_6$O$_{13}$","summary":"V$_6$O$_{13}$ exhibits the metal-insulator transition (MIT) with\nvanadium-vanadium (V-V) dimer formation. The magnetostriction of V$_6$O$_{13}$\nalong the crystallographic $b$-axis has been measured in ultrahigh magnetic\nfields up to 186 T at several temperatures in this work. The large negative\nmagnetostriction as large as $\\Delta L / L \\sim10^{-3}$ was observed above 110\nT below the transition temperature. Discussion based on experimental results\nand the physical property of V$_6$O$_{13}$ suggests that the observed large\nnegative magnetostriction corresponds to the collapse of V-V dimer molecular\norbital (MO). This is the first case for direct observation of lattice change\noriginating from the magnetic field-induced collapse of V-V dimer MO in\nvanadium oxides. In addition, the $B$-$T$ phase diagram and the magnitude of\nmagnetostriction indicate that the collapse of V-V dimer MO probably\naccompanies the insulator-to-metal transition. A large hysteresis that is\nlarger than 50 T was observed, which probably arises from the non-equilibrated\ncross-correlation of such degrees of freedom as the charge, spin, and lattice.\nComparison with the VO$_2$ case suggests the magnetic entropy of the remanent\nparamagnetic spins in the insulating phase may play an important role for the\nMIT in V$_6$O$_{13}$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-29T11:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.20635v1","title":"Bridging the Generalisation Gap: Synthetic Data Generation for\n  Multi-Site Clinical Model Validation","summary":"Ensuring the generalisability of clinical machine learning (ML) models across\ndiverse healthcare settings remains a significant challenge due to variability\nin patient demographics, disease prevalence, and institutional practices.\nExisting model evaluation approaches often rely on real-world datasets, which\nare limited in availability, embed confounding biases, and lack the flexibility\nneeded for systematic experimentation. Furthermore, while generative models aim\nfor statistical realism, they often lack transparency and explicit control over\nfactors driving distributional shifts. In this work, we propose a novel\nstructured synthetic data framework designed for the controlled benchmarking of\nmodel robustness, fairness, and generalisability. Unlike approaches focused\nsolely on mimicking observed data, our framework provides explicit control over\nthe data generating process, including site-specific prevalence variations,\nhierarchical subgroup effects, and structured feature interactions. This\nenables targeted investigation into how models respond to specific\ndistributional shifts and potential biases. Through controlled experiments, we\ndemonstrate the framework's ability to isolate the impact of site variations,\nsupport fairness-aware audits, and reveal generalisation failures, particularly\nhighlighting how model complexity interacts with site-specific effects. This\nwork contributes a reproducible, interpretable, and configurable tool designed\nto advance the reliable deployment of ML in clinical settings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T11:04:28Z"}
{"aid":"http://arxiv.org/abs/2504.20649v1","title":"Short-time quantum Fourier transform processing","summary":"Algorithms for processing data in short-time batches are critical for both\nonline and offline processing of streamed and large data respectively due to\nthe quadratic relation between signal length and computational cost of\nconvolution-based processing schemes. Whilst quantum analogs to some digital\nsignal processing algorithms have been discovered, including the quantum\nFourier transform (QFT), there has been no development of short-time processing\ntechniques in the quantum domain. In this manuscript, we introduce the\nshort-time QFT (STQFT) processing technique to bridge this gap in research. We\ndevelop a novel overlap-add reconstruction technique in the quantum domain\nusing a permutation gate to combine subsequent windows. With this in mind, we\ndiscuss convolution under our novel STQFT processing scheme. We demonstrate\nfiltering in the quantum Fourier domain with a filter stored in a quantum\nregister as well as in a block encoded unitary gate. Throughout the paper, we\nelaborate upon implementation details such as applying DC offsets to input\nsignals, skipping input data frames whenever necessary, the use of overlap-save\nas a reconstruction technique and mitigating time-varying scaling due to\nnormalization of the windowed input data and filters.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T11:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.20666v1","title":"SFi-Former: Sparse Flow Induced Attention for Graph Transformer","summary":"Graph Transformers (GTs) have demonstrated superior performance compared to\ntraditional message-passing graph neural networks in many studies, especially\nin processing graph data with long-range dependencies. However, GTs tend to\nsuffer from weak inductive bias, overfitting and over-globalizing problems due\nto the dense attention. In this paper, we introduce SFi-attention, a novel\nattention mechanism designed to learn sparse pattern by minimizing an energy\nfunction based on network flows with l1-norm regularization, to relieve those\nissues caused by dense attention. Furthermore, SFi-Former is accordingly\ndevised which can leverage the sparse attention pattern of SFi-attention to\ngenerate sparse network flows beyond adjacency matrix of graph data.\nSpecifically, SFi-Former aggregates features selectively from other nodes\nthrough flexible adaptation of the sparse attention, leading to a more robust\nmodel. We validate our SFi-Former on various graph datasets, especially those\ngraph data exhibiting long-range dependencies. Experimental results show that\nour SFi-Former obtains competitive performance on GNN Benchmark datasets and\nSOTA performance on LongRange Graph Benchmark (LRGB) datasets. Additionally,\nour model gives rise to smaller generalization gaps, which indicates that it is\nless prone to over-fitting. Click here for codes.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T11:45:24Z"}
{"aid":"http://arxiv.org/abs/2504.20673v1","title":"CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language\n  Model Evaluation","summary":"Large language models (LLMs) play a crucial role in software engineering,\nexcelling in tasks like code generation and maintenance. However, existing\nbenchmarks are often narrow in scope, focusing on a specific task and lack a\ncomprehensive evaluation framework that reflects real-world applications. To\naddress these gaps, we introduce CoCo-Bench (Comprehensive Code Benchmark),\ndesigned to evaluate LLMs across four critical dimensions: code understanding,\ncode generation, code modification, and code review. These dimensions capture\nessential developer needs, ensuring a more systematic and representative\nevaluation. CoCo-Bench includes multiple programming languages and varying task\ndifficulties, with rigorous manual review to ensure data quality and accuracy.\nEmpirical results show that CoCo-Bench aligns with existing benchmarks while\nuncovering significant variations in model performance, effectively\nhighlighting strengths and weaknesses. By offering a holistic and objective\nevaluation, CoCo-Bench provides valuable insights to guide future research and\ntechnological advancements in code-oriented LLMs, establishing a reliable\nbenchmark for the field.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-29T11:57:23Z"}
{"aid":"http://arxiv.org/abs/2504.20674v1","title":"DiffLiB: High-fidelity differentiable modeling of lithium-ion batteries\n  and efficient gradient-based parameter identification","summary":"The physics-based Doyle-Fuller-Newman (DFN) model, widely adopted for its\nprecise electrochemical modeling, stands out among various simulation models of\nlithium-ion batteries (LIBs). Although the DFN model is powerful in forward\npredictive analysis, the inverse identification of its model parameters has\nremained a long-standing challenge. The numerous unknown parameters associated\nwith the nonlinear, time-dependent, and multi-scale DFN model are extremely\ndifficult to be determined accurately and efficiently, hindering the practical\nuse of such battery simulation models in industrial applications. To tackle\nthis challenge, we introduce DiffLiB, a high-fidelity finite-element-based LIB\nsimulation framework, equipped with advanced differentiable programming\ntechniques so that efficient gradient-based inverse parameter identification is\nenabled. Customized automatic differentiation rules are defined by identifying\nthe VJP (vector-Jacobian product) structure in the chain rule and implemented\nusing adjoint-based implicit differentiation methods. Four numerical examples,\nincluding both 2D and 3D forward predictions and inverse parameter\nidentification, are presented to validate the accuracy and computational\nefficiency of DiffLiB. Benchmarking against COMSOL demonstrates excellent\nagreement in forward predictions, with terminal voltage discrepancies\nmaintaining a root-mean-square error (RMSE) below 2 mV across all test\nconditions. In parameter identification tasks using experimentally measured\nvoltage data, the proposed gradient-based optimization scheme achieves superior\ncomputational performance, with 96% fewer forward predictions and 72% less\ncomputational time compared with gradient-free approaches. These results\ndemonstrate that DiffLiB is a versatile and powerful computational framework\nfor the development of advanced LIBs.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-29T11:57:51Z"}
{"aid":"http://arxiv.org/abs/2504.20684v1","title":"Identifying Uncertainty in Self-Adaptive Robotics with Large Language\n  Models","summary":"Future self-adaptive robots are expected to operate in highly dynamic\nenvironments while effectively managing uncertainties. However, identifying the\nsources and impacts of uncertainties in such robotic systems and defining\nappropriate mitigation strategies is challenging due to the inherent complexity\nof self-adaptive robots and the lack of comprehensive knowledge about the\nvarious factors influencing uncertainty. Hence, practitioners often rely on\nintuition and past experiences from similar systems to address uncertainties.\nIn this article, we evaluate the potential of large language models (LLMs) in\nenabling a systematic and automated approach to identify uncertainties in\nself-adaptive robotics throughout the software engineering lifecycle. For this\nevaluation, we analyzed 10 advanced LLMs with varying capabilities across four\nindustrial-sized robotics case studies, gathering the practitioners'\nperspectives on the LLM-generated responses related to uncertainties. Results\nshowed that practitioners agreed with 63-88% of the LLM responses and expressed\nstrong interest in the practicality of LLMs for this purpose.","main_category":"cs.RO","categories":"cs.RO,cs.SE","published":"2025-04-29T12:07:39Z"}
{"aid":"http://arxiv.org/abs/2504.20688v1","title":"Young Diagram Decompositions for Almost Symmetric Numerical Semigroups","summary":"This paper introduces new structural decompositions for almost symmetric\nnumerical semigroups through the combinatorial lens of Young diagrams. To do\nthat, we use the foundational correspondence between numerical sets and Young\ndiagrams, which enables a visual and algorithmic approach to studying\nproperties of numerical semigroups. Central to the paper, a decomposition\ntheorem for almost symmetric numerical semigroups is proved, which reveals that\nsuch semigroups can be uniquely expressed as a combination of a numerical\nsemigroup, its dual and an ordinary numerical semigroup.","main_category":"math.GR","categories":"math.GR,math.CO","published":"2025-04-29T12:11:17Z"}
{"aid":"http://arxiv.org/abs/2504.20707v1","title":"Cavity Field-Driven Symmetry Breaking and Modulation of Vibrational\n  Properties: Insights from the Analytical QED-HF Hessian","summary":"In this work, we present the analytical derivation and implementation of the\nquantum electrodynamics Hartree-Fock Hessian. We investigate how electronic\nstrong coupling influences molecular vibrational properties, applying this\nframework to formaldehyde, p-nitroaniline, and adamantane. Our analysis reveals\ncavity-induced changes in vibrational frequencies and intensities.\nAdditionally, we show how the quantum electromagnetic field breaks molecular\nsymmetry, activating previously forbidden infrared transitions. Our findings\nhighlight the potential of strong coupling as a method for controlling and\nmodulating molecular vibrational properties.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-29T12:38:21Z"}
{"aid":"http://arxiv.org/abs/2504.20711v1","title":"Hamiltonian learning of triplon excitations in an artificial nanoscale\n  molecular quantum magnet","summary":"Extracting the Hamiltonian of nanoscale quantum magnets from experimental\nmeasurements is a significant challenge in correlated quantum matter. Here we\nput forward a machine learning strategy to extract the spin Hamiltonian from\ninelastic spectroscopy with scanning tunneling microscopy, and we demonstrate\nthis methodology experimentally with an artificial nanoscale molecular magnet\nbased on cobalt phthalocyanine (CoPC) molecules on NbSe$_2$. We show that this\ntechnique allows to directly extract the Hamiltonian parameters of a quantum\nmagnet from the differential conductance, including the substrate-induced\nspatial variation of the different exchange couplings. Our methodology\nleverages a machine learning algorithm trained on exact quantum many-body\nsimulations with tensor networks of finite quantum magnets, leading to a\nmethodology that can be used to predict the Hamiltonian of CoPC quantum magnets\nof arbitrary size. Our results demonstrate how quantum many-body methods and\nmachine learning enable learning a microscopic description of nanoscale quantum\nmany-body systems with scanning tunneling spectroscopy.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-29T12:43:35Z"}
{"aid":"http://arxiv.org/abs/2504.20713v1","title":"AIM: A User-friendly GUI Workflow program for Isotherm Fitting, Mixture\n  Prediction, Isosteric Heat of Adsorption Estimation, and Breakthrough\n  Simulation","summary":"Adsorption breakthrough modeling often requires complex software environments\nand scripting, limiting accessibility for many practitioners. We present AIM, a\nMATLAB-based graphical user interface (GUI) application that streamlines\nfixed-bed adsorption analysis through an integrated workflow for isotherm\nfitting, heat of adsorption estimation, mixture prediction, and multicomponent\nbreakthrough simulations. AIM's intuitive GUI requires no coding and supports a\nbroad isotherm library (e.g., Langmuir, Toth, Dubinin-Astakhov,\nStructural-Transition-Adsorption). It also enables non-isothermal breakthrough\nsimulations with axial dispersion. Case studies, such as Xe/Kr breakthrough\ncurves in SBMOF-1, closely match the results from other software applications,\nsuch as RUPTURA. Mixture predictions can be done using the Ideal Adsorbed\nSolution Theory (IAST) and Extended Langmuir models, while isosteric heats are\nderived from Clausius-Clapeyron or Virial equations. Users can export detailed\ncolumn and outlet profiles (e.g., composition, temperature) in multiple\nformats, enhancing reproducibility and data sharing among practitioners.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.stat-mech","published":"2025-04-29T12:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.20719v1","title":"Particle-Hole Asymmetry and Pinball Liquid in a Triangular-Lattice\n  Extended Hubbard Model within Mean-Field Approximation","summary":"Recently, triangular lattice models have received a lot of attention since\nthey can describe a number of strongly-correlated materials that exhibit\nsuperconductivity and various magnetic and charge orders. In this research we\npresent an extensive analysis of the charge-ordering phenomenon of the\ntriangular-lattice extended Hubbard model with repulsive onsite and\nnearest-neighbor interaction, arbitrary charge concentration, and\n$\\sqrt{3}\\times\\sqrt{3}$ supercell (3-sublattice assumption). The model is\nsolved in the ground state with the mean-field approximation which allowed to\nidentify $8$ charge-ordered phases and a large variety of phase transitions. An\nexotic pinball-liquid phase was found and described. Moreover, strong\nparticle-hole asymmetry of the phase diagram is found to play an important role\nfor triangular lattices. The analysis of band structures, unavailable for more\nadvanced methods that take into account correlation effects, provided a great\ninsight in the nature of triangular-lattice phases and phase transitions. The\ncomplexity of the mean-field phase diagram showed the importance and usefulness\nof the results for the further research with correlation effects included.\nTogether with atomic-limit approximation it can serve them as both a starting\npoint, and a tool to interpret results.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.other,cond-mat.quant-gas,cond-mat.stat-mech,physics.comp-ph","published":"2025-04-29T12:58:57Z"}
{"aid":"http://arxiv.org/abs/2504.20725v1","title":"Quasinormal Modes and Shadows of Black Holes in Infinite Derivative\n  Theory of Gravity","summary":"In this work, we study the quasinormal modes (QNMs) and shadow of a\nSchwarzschild black hole (BH) with higher-order metric corrections, in the\nframework of the Infinite Derivative theory of Gravity (IDG). We study the\neffects of corrections to the BH's metric, which arises from the IDG's\ncorrections, on the QNMs and shadow of the BH. We used the 6th-order Pad\\'{e}\naveraged WKB approximation method to study the QNMs of the BH perturbed by a\nscalar field. The dependence of the amplitude and damping of QNMs with respect\nto the free parameters has been analysed. It is found that the BH system\nbecomes unstable for some values of the free parameters. We also studied the\ntime evolution of a scalar field around the BH spacetime. The QNMs have also\nbeen calculated from the time profile of the evolution, which show good\nagreement with the values obtained from the WKB method. The variation of the\nshadow radius of the BH due to the inclusion of higher-order corrections has\nbeen studied. Finally, we constrain the free parameters associated with the\ncorrection terms using the data from the Keck and VLTI observation, and we\nobtain some bounds on the parameters.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-29T13:06:42Z"}
{"aid":"http://arxiv.org/abs/2504.20729v1","title":"Handling Large-Scale Network Flow Records: A Comparative Study on Lossy\n  Compression","summary":"Flow records, that summarize the characteristics of traffic flows, represent\na practical and powerful way to monitor a network. While they already offer\nsignificant compression compared to full packet captures, their sheer volume\nremains daunting, especially for large Internet Service Providers (ISPs). In\nthis paper, we investigate several lossy compression techniques to further\nreduce storage requirements while preserving the utility of flow records for\nkey tasks, such as predicting the domain name of contacted servers. Our study\nevaluates scalar quantization, Principal Component Analysis (PCA), and vector\nquantization, applied to a real-world dataset from an operational campus\nnetwork. Results reveal that scalar quantization provides the best tradeoff\nbetween compression and accuracy. PCA can preserve predictive accuracy but\nhampers subsequent entropic compression, and while vector quantization shows\npromise, it struggles with scalability due to the high-dimensional nature of\nthe data. These findings result in practical strategies for optimizing flow\nrecord storage in large-scale monitoring scenarios.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-29T13:11:59Z"}
{"aid":"http://arxiv.org/abs/2504.20748v1","title":"On the estimation of the $q$-numerical radius via Orlicz functions","summary":"This study utilizes Orlicz functions to provide refined lower and upper\nbounds on the q-numerical radius of an operator acting on a Hilbert space.\nAdditionally, the concept of q-sectorial matrices is introduced and further\nbounds for the q-numerical radius are established. Our results unify several\nexisting bounds for the q-numerical radius. Suitable examples are provided to\nsupplement the estimations.","main_category":"math.FA","categories":"math.FA","published":"2025-04-29T13:28:38Z"}
{"aid":"http://arxiv.org/abs/2504.20754v1","title":"DDPS: Discrete Diffusion Posterior Sampling for Paths in Layered Graphs","summary":"Diffusion models form an important class of generative models today,\naccounting for much of the state of the art in cutting edge AI research. While\nnumerous extensions beyond image and video generation exist, few of such\napproaches address the issue of explicit constraints in the samples generated.\nIn this paper, we study the problem of generating paths in a layered graph (a\nvariant of a directed acyclic graph) using discrete diffusion models, while\nguaranteeing that our generated samples are indeed paths. Our approach utilizes\na simple yet effective representation for paths which we call the padded\nadjacency-list matrix (PALM). In addition, we show how to effectively perform\nclassifier guidance, which helps steer the sampled paths to specific preferred\nedges without any retraining of the diffusion model. Our preliminary results\nshow that empirically, our method outperforms alternatives which do not\nexplicitly account for path constraints.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-29T13:34:17Z"}
{"aid":"http://arxiv.org/abs/2504.20771v1","title":"Turing Machine Evaluation for Large Language Model","summary":"With the rapid development and widespread application of Large Language\nModels (LLMs), rigorous evaluation has become particularly crucial. This\nresearch adopts a novel perspective, focusing on evaluating the core\ncomputational reasoning ability of LLMs, defined as the capacity of model to\naccurately understand rules, and execute logically computing operations. This\ncapability assesses the reliability of LLMs as precise executors, and is\ncritical to advanced tasks such as complex code generation and multi-step\nproblem-solving. We propose an evaluation framework based on Universal Turing\nMachine (UTM) simulation. This framework requires LLMs to strictly follow\ninstructions and track dynamic states, such as tape content and read/write head\nposition, during multi-step computations. To enable standardized evaluation, we\ndeveloped TMBench, a benchmark for systematically studying the computational\nreasoning capabilities of LLMs. TMBench provides several key advantages,\nincluding knowledge-agnostic evaluation, adjustable difficulty, foundational\ncoverage through Turing machine encoding, and unlimited capacity for instance\ngeneration, ensuring scalability as models continue to evolve. We find that\nmodel performance on TMBench correlates strongly with performance on other\nrecognized reasoning benchmarks (Pearson correlation coefficient is 0.73),\nclearly demonstrating that computational reasoning is a significant dimension\nfor measuring the deep capabilities of LLMs. Code and data are available at\nhttps://github.com/HaitaoWuTJU/Turing-Machine-Bench.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T13:52:47Z"}
{"aid":"http://arxiv.org/abs/2504.20781v1","title":"Using LLMs in Generating Design Rationale for Software Architecture\n  Decisions","summary":"Design Rationale (DR) for software architecture decisions refers to the\nreasoning underlying architectural choices, which provides valuable insights\ninto the different phases of the architecting process throughout software\ndevelopment. However, in practice, DR is often inadequately documented due to a\nlack of motivation and effort from developers. With the recent advancements in\nLarge Language Models (LLMs), their capabilities in text comprehension,\nreasoning, and generation may enable the generation and recovery of DR for\narchitecture decisions. In this study, we evaluated the performance of LLMs in\ngenerating DR for architecture decisions. First, we collected 50 Stack Overflow\n(SO) posts, 25 GitHub issues, and 25 GitHub discussions related to architecture\ndecisions to construct a dataset of 100 architecture-related problems. Then, we\nselected five LLMs to generate DR for the architecture decisions with three\nprompting strategies, including zero-shot, chain of thought (CoT), and\nLLM-based agents. With the DR provided by human experts as ground truth, the\nPrecision of LLM-generated DR with the three prompting strategies ranges from\n0.267 to 0.278, Recall from 0.627 to 0.715, and F1-score from 0.351 to 0.389.\nAdditionally, 64.45% to 69.42% of the arguments of DR not mentioned by human\nexperts are also helpful, 4.12% to 4.87% of the arguments have uncertain\ncorrectness, and 1.59% to 3.24% of the arguments are potentially misleading.\nBased on the results, we further discussed the pros and cons of the three\nprompting strategies and the strengths and limitations of the DR generated by\nLLMs.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-29T14:00:18Z"}
{"aid":"http://arxiv.org/abs/2504.20790v1","title":"Charge Schedule Optimization and Infrastructure Planning for\n  Solar-Integrated Electric Bus Transit Systems","summary":"As urban transit systems transition towards electrification, using renewable\nenergy sources (RES), such as solar, is essential to make them efficient and\nsustainable. However, the intermittent nature of renewables poses a challenge\nin deciding the solar panel requirements and battery energy storage system\n(BESS) capacity at charging locations. To address these challenges, we propose\na two-stage stochastic programming model that considers seasonality in solar\nenergy generation while incorporating temperature-based variations in bus\nenergy consumption and dynamic time-of-use electricity prices. Specifically, we\nformulate the problem as a multi-scenario linear program (LP) where the\nfirst-stage long-term variables determine the charging station power capacity,\nBESS capacity, and the solar panel area at each charging location. The\nsecond-stage scenario-specific variables prescribe the energy transferred to\nbuses directly from the grid or the BESS during layovers. We demonstrate the\neffectiveness of this framework using data from Durham Transit Network\n(Ontario) and Action Buses (Canberra), where bus schedules and charging\nlocations are determined using a concurrent scheduler-based heuristic. Solar\nenergy data is collected from the National Renewable Energy Laboratory (NREL)\ndatabase. We solved the multi-scenario LP using Benders' decomposition, which\nperformed better than the dual simplex method, especially when the number of\nscenarios was high. With solar energy production at the depots, our model\nestimated a cost savings of 16.48% and 32.00% for the Durham and Canberra\nnetworks, respectively. Our results also show that the scenario-based schedule\nadapts better to seasonal variations than a schedule estimated from average\ninput parameters.","main_category":"math.OC","categories":"math.OC","published":"2025-04-29T14:04:32Z"}
{"aid":"http://arxiv.org/abs/2504.20792v1","title":"RecGaze: The First Eye Tracking and User Interaction Dataset for\n  Carousel Interfaces","summary":"Carousel interfaces are widely used in e-commerce and streaming services, but\nlittle research has been devoted to them. Previous studies of interfaces for\npresenting search and recommendation results have focused on single ranked\nlists, but it appears their results cannot be extrapolated to carousels due to\nthe added complexity. Eye tracking is a highly informative approach to\nunderstanding how users click, yet there are no eye tracking studies concerning\ncarousels. There are very few interaction datasets on recommenders with\ncarousel interfaces and none that contain gaze data.\n  We introduce the RecGaze dataset: the first comprehensive feedback dataset on\ncarousels that includes eye tracking results, clicks, cursor movements, and\nselection explanations. The dataset comprises of interactions from 3 movie\nselection tasks with 40 different carousel interfaces per user. In total, 87\nusers and 3,477 interactions are logged. In addition to the dataset, its\ndescription and possible use cases, we provide results of a survey on carousel\ndesign and the first analysis of gaze data on carousels, which reveals a golden\ntriangle or F-pattern browsing behavior.\n  Our work seeks to advance the field of carousel interfaces by providing the\nfirst dataset with eye tracking results on carousels. In this manner, we\nprovide and encourage an empirical understanding of interactions with carousel\ninterfaces, for building better recommender systems through gaze information,\nand also encourage the development of gaze-based recommenders.","main_category":"cs.IR","categories":"cs.IR,cs.HC","published":"2025-04-29T14:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.20797v1","title":"Partitioned Memory Storage Inspired Few-Shot Class-Incremental learning","summary":"Current mainstream deep learning techniques exhibit an over-reliance on\nextensive training data and a lack of adaptability to the dynamic world,\nmarking a considerable disparity from human intelligence. To bridge this gap,\nFew-Shot Class-Incremental Learning (FSCIL) has emerged, focusing on continuous\nlearning of new categories with limited samples without forgetting old\nknowledge. Existing FSCIL studies typically use a single model to learn\nknowledge across all sessions, inevitably leading to the stability-plasticity\ndilemma. Unlike machines, humans store varied knowledge in different cerebral\ncortices. Inspired by this characteristic, our paper aims to develop a method\nthat learns independent models for each session. It can inherently prevent\ncatastrophic forgetting. During the testing stage, our method integrates\nUncertainty Quantification (UQ) for model deployment. Our method provides a\nfresh viewpoint for FSCIL and demonstrates the state-of-the-art performance on\nCIFAR-100 and mini-ImageNet datasets.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T14:11:06Z"}
{"aid":"http://arxiv.org/abs/2504.20803v1","title":"Continuation maps for the Morse fundamental group","summary":"We study properties of the continuation map for the Morse fundamental group\n$\\pi_1^\\text{Morse}(f,\\ast)$ associated to a Morse-Smale pair $(f,g)$ on a\nmanifold $M$. We get a morphism between $\\pi_1^\\text{Morse}(f_1,\\ast_1)$ and\n$\\pi_1^\\text{Morse}(f_2,\\ast_2)$ and show that it is functorial. We also define\nthe morphism in the case of Morse data over different manifolds, thanks to the\nuse of grafted trajectories. Finally, given an interpolation function on\n$M\\times\\mathbb{R}$ between two Morse functions (used for example to define the\ncontinuation map), we study the Morse fundamental group associated to that\nfunction and show that it is isomorphic to a relative fundamental group on\n$M\\times\\mathbb{R}$.","main_category":"math.GT","categories":"math.GT,math.DG,math.SG","published":"2025-04-29T14:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.20811v1","title":"A Quantum Range-Doppler Algorithm for Synthetic Aperture Radar Image\n  Formation","summary":"Synthetic aperture radar (SAR) is a well established technology in the field\nof Earth remote sensing. Over the years, the resolution of SAR images has been\nsteadily improving and the pixel count increasing as a result of advances in\nthe sensor technology, and so have the computational resources required to\nprocess the raw data to a focused image. Because they are a necessary step in\nthe study of the retrieved data, new high-resolution and low-complexity\nfocusing algorithms are constantly explored in the SAR literature. The theory\nof quantum computing proposes a new computational framework that might allow to\nprocess a vast amount of data in a more efficient way. Relevant to our case is\nthe advantage proven for the quantum Fourier transform (QFT), the quantum\ncounterpart of a fundamental element of many SAR focusing algorithms. Motivated\nby this, in this work we propose a quantum version of the range-Doppler\nalgorithm. We show how in general reference functions, a key element in many\nSAR focusing algorithms, can be mapped to quantum gates; we present the quantum\ncircuit performing the SAR raw data focusing and we discuss in detail its\ncomputational complexity. We find that the core of the quantum range-Doppler\nalgorithm has a computational complexity, namely the number of single- and\ntwo-qubit gates, of $O(N)$, less than its classical counterpart with\ncomputational complexity $O(N \\log N)$.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T14:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.20836v1","title":"Non-Linear Modeling and Analysis of Amplifier-Less Potentiostat\n  Architectures","summary":"In this article, a previously published amplifier-less potentiostat\narchitecture is further examined. Starting with a linearized model, the impact\nof the most important parameters is studied taking in account the\nelectrodes-solution electrochemical interface. A detailed model is obtained and\nthoroughly verified, and recommended operating conditions are given for certain\nlimit load conditions. Then, a more complete non-linear model is developed to\ntake in account the measurement uncertainty introduced by the circuit\nnon-linear components. This non-linear model is compared to a time domain\ndescription of the circuit and it is verified that it can predict the\nnon-linear behavior with a precision better than 20%. This result enables the\ncircuit designers to compensate for these effects and ultimately reduce the\noverall measurement uncertainty.","main_category":"eess.SY","categories":"eess.SY,cs.SY,94-06","published":"2025-04-29T14:59:50Z"}
{"aid":"http://arxiv.org/abs/2504.20840v1","title":"Thermal Resilience of Suspended Thin-Film Lithium Niobate Acoustic\n  Resonators up to 550 C","summary":"This paper reports a suspended thin-film lithium niobate (LN) piezoelectric\nresonator platform surviving high annealing temperatures of 550 {\\deg}C, among\nthe highest temperature at which the thermal resilience of suspended LN\nresonators is studied. Acoustic resonators are built on 600 nm thick\ntransferred stoichiometric LN on silicon wafers with 40 nm thick platinum (Pt)\nelectrodes, selected for high temperature operation. The fabricated resonators\nare first annealed at 250 {\\deg}C, and the anneal temperature is incrementally\nincreased to 550 {\\deg}C after 7 rounds of annealing. The annealing is shown to\nupshift resonant frequencies and can increase the quality factor (Q), within a\ntemperature range, before it gradually damages the device performance. This\nwork presents promising results for using the suspended thin-film LN platform\nfor resonators, sensors, and transducers in harsh thermal environments.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-29T15:05:21Z"}
{"aid":"http://arxiv.org/abs/2504.20842v1","title":"Language Model for Large-Text Transmission in Noisy Quantum\n  Communications","summary":"Quantum communication has the potential to revolutionize information\nprocessing, providing unparalleled security and increased capacity compared to\nits classical counterpart by using the principles of quantum mechanics.\nHowever, the presence of noise remains a major barrier to realizing these\nadvantages. While strategies like quantum error correction and mitigation have\nbeen developed to address this challenge, they often come with substantial\noverhead in physical qubits or sample complexity, limiting their practicality\nfor large-scale information transfer. Here, we present an alternative approach:\napplying machine learning frameworks from natural language processing to\nenhance the performance of noisy quantum communications, focusing on superdense\ncoding. By employing bidirectional encoder representations from transformers\n(BERT), a model known for its capabilities in natural language processing, we\ndemonstrate improvements in information transfer efficiency without resorting\nto conventional error correction or mitigation techniques. These results mark a\nstep toward the practical realization of a scalable and resilient quantum\ninternet.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T15:11:35Z"}
{"aid":"http://arxiv.org/abs/2504.20843v1","title":"A nuclear mass model rooted in chiral effective field theory","summary":"We develop a nuclear mass model that is based on chiral effective field\ntheory at next-to-next-to leading order. Nuclear binding energies are computed\nvia the Hartree-Fock method using a Hamiltonian from delta-full chiral\neffective field theory. We employ Hartree-Fock emulators to adjust $11$\nlow-energy constants in the chiral interaction to binding energies of $18$\neven-even nuclei. When applied to $107$ even-even nuclei with mass numbers\n$16\\leq A\\leq 56$ the chiral mass model exhibits an overall root-mean-square\ndeviation of $3.5$ MeV.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-29T15:13:19Z"}
{"aid":"http://arxiv.org/abs/2504.20845v1","title":"Conformal Einstein equation and symplectic flux with a positive\n  cosmological constant","summary":"We analyze the conformal Einstein equation with a positive cosmological\nconstant to extract fall-off conditions of the gravitational fields. The\nfall-off conditions are consistent with a finite, non-trivial presymplectic\ncurrent on the future boundary of de Sitter. Hence our result allows a non-zero\ngravitational flux across the boundary of the de Sitter. We present an explicit\ngauge-free computation to show that the Gibbons-Hawking boundary term,\ncounterterm in the action, and fall-off condition of gravitational field in\nconformal Einstein equation are crucial to reproduce the finite symplectic\nflux.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-29T15:17:33Z"}
{"aid":"http://arxiv.org/abs/2504.20846v1","title":"Disjunctive and Conjunctive Normal Form Explanations of Clusters Using\n  Auxiliary Information","summary":"We consider generating post-hoc explanations of clusters generated from\nvarious datasets using auxiliary information which was not used by clustering\nalgorithms. Following terminology used in previous work, we refer to the\nauxiliary information as tags. Our focus is on two forms of explanations,\nnamely disjunctive form (where the explanation for a cluster consists of a set\nof tags) and a two-clause conjunctive normal form (CNF) explanation (where the\nexplanation consists of two sets of tags, combined through the AND operator).\nWe use integer linear programming (ILP) as well as heuristic methods to\ngenerate these explanations. We experiment with a variety of datasets and\ndiscuss the insights obtained from our explanations. We also present\nexperimental results regarding the scalability of our explanation methods.","main_category":"cs.AI","categories":"cs.AI,I.2","published":"2025-04-29T15:18:18Z"}
{"aid":"http://arxiv.org/abs/2504.20850v1","title":"Nuclear Dimension for Virtually Abelian Groups","summary":"Let $G$ be a finitely generated virtually abelian group. We show that the\nHirsch length, $h(G)$, is equal to the nuclear dimension of its group\n$C^*$-algebra, $\\dim_{nuc}(C^*(G))$. We then specialize our attention to a\ngeneralization of crystallographic groups dubbed $\\textit{crystal-like}$. We\ndemonstrate that in this scenario a $\\textit{point group}$ is well defined and\nthe order of this point group is preserved by $C^*$-isomorphism. In addition,\nwe provide a counter-example to $C^*$-superrigidity within this crystal-like\nsetting.","main_category":"math.OA","categories":"math.OA,math.GR,math.RT","published":"2025-04-29T15:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.20864v1","title":"($0,6$) AdS$_3$/CFT$_2$ and surface defects","summary":"We explore a new class of AdS$_3$ solutions in massive type IIA supergravity\npreserving $\\mathcal{N} = (0,6)$ supersymmetry and realising an\n$\\mathfrak{osp}(6|2)$ superconformal algebra. These solutions exhibit an\nSO(6)-symmetric internal space constructed from a $\\mathbb{CP}^3$, and are\nfully specified by a single cubic function controlling the fluxes and warping.\nWe propose a brane box configuration underlying the solutions from which we\nconstruct a two-dimensional quiver gauge theory whose anomaly structure and\ncentral charge we analyse, and from which we can realise Seiberg-like dualities\nas large gauge transformations. The brane box configuration suggests an\ninterpretation of the solutions as dual to surface defects within the ABJ(M)\ntheory. Our findings provide a concrete setting for exploring holography beyond\nthe ABJM vacuum. Remarkably, no explicit field theories are currently known to\nrealise $\\mathcal{N} = (0,6)$ supersymmetry in two dimensions, making our setup\na promising and largely unexplored direction for field-theoretic\ninvestigations.","main_category":"hep-th","categories":"hep-th","published":"2025-04-29T15:39:27Z"}
{"aid":"http://arxiv.org/abs/2504.20868v1","title":"Two-dimensional non-van der Waals niobium nitride nanosheets with\n  high-temperature two-gap superconductivity","summary":"The exploration of the superconductivity in two-dimensional materials has\ngarnered significant attention due to their promising low-power applications\nand fundamental scientific interest. Here, we report some novel stable non-van\nder Waals Nb$_x$N$_{x+1}$ ($x$ = 1-4) monolayers derived from the NbN bulk\nexfoliated along the (001) plane, as identified through first-principles\ncalculations. Among these monolayers, Nb$_2$N$_3$, which crystallizes in the $P\n\\overline{6} m2$ symmetry, stands out with an exceptional superconducting\ntransition temperature of 77.8 K, setting a new high-$T_c$ benchmark for\ntwo-dimensional transition metal nitrides and binary compounds. Our detailed\nanalysis reveals that the strong superconductivity in Nb$_2$N$_3$ is driven by\nphonon modes dominated by N vibrations, with significant electron-phonon\ncoupling contributions from N-$p$ and Nb-$d$ electronic states. Using the\nanisotropic Migdal-Eliashberg framework, we further determine the two-gap\nnature of the superconductivity in the Nb$_2$N$_3$ monolayer, characterized by\npronounced electron-phonon coupling and anisotropic energy gaps. These results\nadvance our understanding of superconductivity in 2D transition metal nitride\nand highlight their potential for nanoscale superconducting applications.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-29T15:42:51Z"}
{"aid":"http://arxiv.org/abs/2504.20871v1","title":"Fluctuating magnetism in Zn-doped averievite with well-separated kagome\n  layers","summary":"Kagome lattice decorated with S=1/2 spins is one of the most discussed ways\nto realize a quantum spin liquid. However, all previous material realizations\nof this model have suffered from additional complications, ranging from\nadditional interactions to impurity effects. Recently, a new quantum kagome\nsystem has been identified in the form of averievite Cu(5-x)ZnxV2O10(CsCl),\nfeaturing a unique double-layer spacing between the kagome planes. Using muon\nspin spectroscopy we show that only a complete substitution (i.e. $x=2$) of\ninterplanar copper ions leads to a quantum-disordered ground state. In\ncontrast, the parent compound ($x=0$) exhibits long-range magnetic order, with\na phase transition around 24 K. Experiments performed on the partially\nsubstituted material ($x=1$) show that the transformation proceeds through an\nintermediate disordered, partially frozen ground state, unaffected by pressures\nup to 23 kbar. Our study provides a microscopic view of the magnetism of the\ndecoupling of the kagome layers and establishes the averievite as a new\nmaterial platform for the experimental study of the fully-decoupled kagome\nlayers.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-29T15:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.20882v1","title":"Barotropic Equation of State and Nonlinear Electrodynamics in Dynamical\n  Black Hole Spacetimes","summary":"Models of black holes that differ from idealized vacuum and electrovacuum\nsolutions of Einstein's equations often contain parameters whose physical\ninterpretation is unclear. However, to propose a black hole model for\nexperimental verification, we must clearly understand which parameters describe\nthe black hole and what physical constraints can be imposed on each parameter.\nWhen considering dynamical black holes with a barotropic equation of state, an\nadditional integration constant arises, the nature of which remains unclear\nexcept for a few specific values of the equation of state coefficient.\nNevertheless, when examining solutions such as Husain or Kiselev, we can\nobserve remarkable effects related to black hole evaporation, which are\nassociated with the violation of null energy conditions. However, the main\nissue lies in the fact that while violations of energy conditions may occur in\nnature, the ambiguity in the values of parameters describing black holes makes\nit difficult to determine whether such violations result from natural physical\nprocesses or are purely mathematical artifacts that should be excluded from\nconsideration. Moreover, energy conditions play a crucial role in the evolution\nof a black hole shadow - a characteristic that can potentially be observed\nexperimentally. In this article, we elucidate the parameter arising in Husain's\nand Kiselev's solutions using nonlinear electrodynamics. We demonstrate that\nfor physically relevant equations of state, the additional parameter represents\na combination of electric and magnetic charges.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-29T15:53:44Z"}
{"aid":"http://arxiv.org/abs/2504.20886v1","title":"Mapping a Movement: Exploring a Proposed Police Training Facility in\n  Atlanta and the Stop Cop City Movement through Online Maps","summary":"In 2021, the City of Atlanta and Atlanta Police Foundation launched plans to\nbuild a large police training facility in the South River Forest in\nunincorporated DeKalb County, GA. Residents of Atlanta and DeKalb County,\nenvironmental activists, police and prison abolitionists, and other activists\nand concerned individuals formed the movement in opposition to the facility,\nknown as the Stop Cop City / Defend the Atlanta Forest movement. Social media\nand digital maps became common tools for communicating information about the\nfacility and the movement. Here, we examine online maps about the facility and\nthe opposition movement, originating from grassroots organizations, the City of\nAtlanta, news media outlets, the Atlanta Police Foundation, and individuals. We\ngather and examine 32 publicly available maps collected through the Google\nSearch API, Twitter (now X), Instagram and reddit. Using a framework of\ncritical cartography, we conduct a content analysis of these maps to identify\nthe mapping technologies and techniques (data, cartographic elements, styles)\nused by different stakeholders and roles that maps and mapping technologies can\nplay in social movements. We examine the extent to which these maps provide\ndata to confirm or contradict concerns raised by grassroots organizations and\nlocal residents about the facility. We find that stakeholders and mapmakers use\ngeospatial tools in different ways and likely have varied access to mapping\ntechnologies. We argue that documenting the use of maps to communicate\ninformation about a contentious project can help enumerate community positions\nand perspectives, and we advocate for accessible mapmaking tools. We conclude\nby discussing the implications of accessibility of mapping technology and\nposting maps to social media, and share example map images that extend the\ngeographic information systems (GIS) techniques seen in the retrieved maps.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-29T16:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.20888v1","title":"New Capacity Bounds for PIR on Graph and Multigraph-Based Replicated\n  Storage","summary":"In this paper, we study the problem of private information retrieval (PIR) in\nboth graph-based and multigraph-based replication systems, where each file is\nstored on exactly two servers, and any pair of servers shares at most $r$\nfiles. We derive upper bounds on the PIR capacity for such systems and\nconstruct PIR schemes that approach these bounds. For graph-based systems, we\ndetermine the exact PIR capacity for path graphs and improve upon existing\nresults for complete bipartite graphs and complete graphs. For multigraph-based\nsystems, we propose a PIR scheme that leverages the symmetry of the underlying\ngraph-based construction, yielding a capacity lower bound for such multigraphs.\nFurthermore, we establish several general upper and lower bounds on the PIR\ncapacity of multigraphs, which are tight in certain cases.","main_category":"cs.IT","categories":"cs.IT,cs.CR,math.CO,math.IT,H.3.3","published":"2025-04-29T16:05:42Z"}
{"aid":"http://arxiv.org/abs/2504.20889v1","title":"A Decision Diagram Approach for the Parallel Machine Scheduling Problem\n  with Chance Constraints","summary":"The Chance-Constrained Parallel Machine Scheduling Problem (CC-PMSP) assigns\njobs with uncertain processing times to machines, ensuring that each machine's\navailability constraints are met with a certain probability. We present a\ndecomposition approach where the master problem assigns jobs to machines, and\nthe subproblems schedule the jobs on each machine while verifying the\nsolution's feasibility under the chance constraint. We propose two different\nDecision Diagram (DD) formulations to solve the subproblems and generate cuts.\nThe first formulation employs DDs with a linear cost function, while the second\nuses a non-linear cost function to reduce the diagram's size. We show how to\ngenerate no-good and irreducible infeasible subsystem (IIS) cuts based on our\nDDs. Additionally, we extend the cuts proposed by Lozano & Smith (2018) to\nsolve two-stage stochastic programming models. Our DD-based methodology\noutperforms traditional integer programming (IP) models designed to solve the\nCC-PMSP in several instances. Specifically, our best DD-based approach solves\n55 more instances than the best IP alternative (from a total of 405) and\ntypically achieves smaller gaps (50% vs. 120% gap on average).","main_category":"math.OC","categories":"math.OC","published":"2025-04-29T16:07:01Z"}
{"aid":"http://arxiv.org/abs/2504.20890v1","title":"Thermodynamic interpretation to Stochastic Fisher Information and\n  Single-Trajectory Speed Limits","summary":"The Fisher information (FI) metric is a Riemannian metric that allows a\ngeometric treatment of stochastic thermodynamics, introducing the possibility\nof computing thermodynamic lengths and deviations from equilibrium. At the\ntrajectory level, a related quantity can be introduced, the stochastic Fisher\ninformation (SFI), which on average, is equivalent to the FI. In this work, we\ndiscuss two fundamental questions regarding the SFI; namely, (i) what is the\nthermodynamic interpretation of the SFI is and (ii) whether there are any\ntrajectory-level thermodynamic bounds due to the SFI. We find that, contrary to\nprevious results in the literature for the FI, the thermodynamic interpretation\nof the SFI depends only on the entropy produced by the system and on the\nthermodynamic force. Moreover, we find that the SFI allows one to derive\nsingle-trajectory speed limits, which we demonstrate to hold for a Brownian\nparticle under a saturating drive force and a Brownian particle under a\ndecreasing drive force. From the ensemble of single-trajectory bounds one can\nderive a hierarchy of average speed limits that are always less tight than the\none derived from the FI. We test our results for speed limits on the adopted\nmodels and find that the hierarchy of average speed limits is respected and\nthat the single-trajectory speed limits behave qualitatively similarly to the\naverage and stochastic speed limits, with some trajectories achieving\nvelocities higher than the tightest average bound whenever it does not\nsaturate. Our results open avenues for the exploration of uncertainty relations\nat the trajectory level.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-29T16:07:31Z"}
{"aid":"http://arxiv.org/abs/2504.20892v1","title":"Imaging on the Edge: Mapping Object Corners and Edges with Stereo X-ray\n  Tomography","summary":"X-ray computed tomography is a powerful tool for volumetric imaging, where\nthree-dimensional (3D) images are generated from a large number of individual\nX-ray projection images. Collecting the required number of low noise projection\nimages is however time-consuming and so the technique is not currently\napplicable when spatial information needs to be collected with high temporal\nresolution, such as in the study of dynamic processes. In our previous work,\ninspired by stereo vision, we developed stereo X-ray imaging methods that\noperate with only two X-ray projection images. Previously we have shown how\nthis allowed us to map point and line fiducial markers into 3D space at\nsignificantly faster temporal resolutions. In this paper, we make two further\ncontributions. Firstly, instead of utilising internal fiducial markers, we\ndemonstrate the applicability of the method to the 3D mapping of sharp object\ncorners, a problem of interest in measuring the deformation of manufactured\ncomponents under different loads. Furthermore, we demonstrate how the approach\ncan be applied to real stereo X-ray data, even in settings where we do not have\nthe annotated real training data that was required for the training of our\nprevious Machine Learning approach. This is achieved by substituting the real\ndata with a relatively simple synthetic training dataset designed to mimic key\naspects of the real data.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-29T16:08:00Z"}
{"aid":"http://arxiv.org/abs/2504.20901v1","title":"High-temperature partition functions and classical simulability of\n  long-range quantum systems","summary":"Long-range quantum systems, in which the interactions decay as\n$1/r^{\\alpha}$, are of increasing interest due to the variety of experimental\nset-ups in which they naturally appear. Motivated by this, we study fundamental\nproperties of long-range spin systems in thermal equilibrium, focusing on the\nweak regime of $ \\alpha>D$. Our main result is a proof of analiticity of their\npartition functions at high temperatures, which allows us to construct a\nclassical algorithm with sub-exponential runtime\n$\\exp(\\mathcal{O}(\\log^2(N/\\epsilon)))$ that approximates the log-partition\nfunction to small additive error $\\epsilon$. As by-products, we establish the\nequivalence of ensembles and the Gaussianity of the density of states, which we\nverify numerically in both the weak and strong long-range regimes. This also\nyields constraints on the appearance of various classes of phase transitions,\nincluding thermal, dynamical and excited-state ones. Our main technical\ncontribution is the extension to the quantum long-range regime of the\nconvergence criterion for cluster expansions of Koteck\\'y and Preiss.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-29T16:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.20906v1","title":"GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In\n  Industrial Control Systems","summary":"The continuous monitoring of the interactions between cyber-physical\ncomponents of any industrial control system (ICS) is required to secure\nautomation of the system controls, and to guarantee plant processes are\nfail-safe and remain in an acceptably safe state. Safety is achieved by\nmanaging actuation (where electric signals are used to trigger physical\nmovement), dependent on corresponding sensor readings; used as ground truth in\ndecision making. Timely detection of anomalies (attacks, faults and\nunascertained states) in ICSs is crucial for the safe running of a plant, the\nsafety of its personnel, and for the safe provision of any services provided.\nWe propose an anomaly detection method that involves accurate linearization of\nthe non-linear forms arising from sensor-actuator(s) relationships, primarily\nbecause solving linear models is easier and well understood. Further, the time\ncomplexity of the anomaly detection scenario/problem at hand is lowered using\ndimensionality reduction of the actuator(s) in relationship with a sensor. We\naccomplish this by using a well-known water treatment testbed as a use case.\nOur experiments show millisecond time response to detect anomalies and provide\nexplainability; that are not simultaneously achieved by other state of the art\nAI/ML models with eXplainable AI (XAI) used for the same purpose. Further, we\npin-point the sensor(s) and its actuation state for which anomaly was detected.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-29T16:24:11Z"}
{"aid":"http://arxiv.org/abs/2504.20912v1","title":"On the Secrecy-Sensing Optimization of RIS-assisted Full-Duplex\n  Integrated Sensing and Communication Network","summary":"Integrated sensing and communication (ISAC) has recently emerged as a viable\ntechnique for establishing sensing and communication using the same resources.\nNonetheless, the operation of ISAC networks is often challenged by the absence\nof a direct link between the sensing node and the targets, and by the risk of\ndisclosing confidential data to malicious targets when using the same signal\nfor both tasks. In this paper, a robust reconfigurable intelligent surface\n(RIS)-aided scheme for securing a full-duplex (FD) ISAC network is proposed.\nThe considered network consists of uplink and downlink users served in FD\nthrough a multi-antenna dual-functional radar communication base station (BS),\nwhich employs co-located multi-antenna communication-radar arrays to detect\nmultiple malicious targets while preserving communication secrecy in their\npresence. Additionally, the BS utilizes an optimized artificial noise (AN) that\nserves to disrupt the malicious targets' reception and increase the sensing\npower. By optimally designing the RIS phase shifts, transmit beamforming, AN\ncovariance, and uplink users' transmit power and combining vectors using an\nalternating optimization-based algorithm, the network's sensing performance is\nmaximized under secrecy and total power constraints. Numerical results present\nthe proposed scheme's efficacy, particularly when a direct link between the BS\nand the various nodes/targets is absent.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-29T16:32:22Z"}
{"aid":"http://arxiv.org/abs/2504.20924v1","title":"A Domain-Agnostic Scalable AI Safety Ensuring Framework","summary":"Ensuring the safety of AI systems has recently emerged as a critical priority\nfor real-world deployment, particularly in physical AI applications. Current\napproaches to AI safety typically address predefined domain-specific safety\nconditions, limiting their ability to generalize across contexts.\n  We propose a novel AI safety framework that ensures AI systems comply with\n\\textbf{any user-defined constraint}, with \\textbf{any desired probability},\nand across \\textbf{various domains}.\n  In this framework, we combine an AI component (e.g., neural network) with an\noptimization problem to produce responses that minimize objectives while\nsatisfying user-defined constraints with probabilities exceeding user-defined\nthresholds. For credibility assessment of the AI component, we propose\n\\textit{internal test data}, a supplementary set of safety-labeled data, and a\n\\textit{conservative testing} methodology that provides statistical validity of\nusing internal test data. We also present an approximation method of a loss\nfunction and how to compute its gradient for training.\n  We mathematically prove that probabilistic constraint satisfaction is\nguaranteed under specific, mild conditions and prove a scaling law between\nsafety and the number of internal test data. We demonstrate our framework's\neffectiveness through experiments in diverse domains: demand prediction for\nproduction decision, safe reinforcement learning within the SafetyGym\nsimulator, and guarding AI chatbot outputs. Through these experiments, we\ndemonstrate that our method guarantees safety for user-specified constraints,\noutperforms {for \\textbf{up to several order of magnitudes}} existing methods\nin low safety threshold regions, and scales effectively with respect to the\nsize of internal test data.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T16:38:35Z"}
{"aid":"http://arxiv.org/abs/2504.20939v1","title":"Flexible Semantic-Aware Resource Allocation: Serving More Users Through\n  Similarity Range Constraints","summary":"Semantic communication (SemCom) aims to enhance the resource efficiency of\nnext-generation networks by transmitting the underlying meaning of messages,\nfocusing on information relevant to the end user. Existing literature on SemCom\nprimarily emphasizes learning the encoder and decoder through end-to-end deep\nlearning frameworks, with the objective of minimizing a task-specific semantic\nloss function. Beyond its influence on the physical and application layer\ndesign, semantic variability across users in multi-user systems enables the\ndesign of resource allocation schemes that incorporate user-specific semantic\nrequirements. To this end, \\emph{a semantic-aware resource allocation} scheme\nis proposed with the objective of maximizing transmission and semantic\nreliability, ultimately increasing the number of users whose semantic\nrequirements are met. The resulting resource allocation problem is a non-convex\nmixed-integer nonlinear program (MINLP), which is known to be NP-hard. To make\nthe problem tractable, it is decomposed into a set of sub-problems, each of\nwhich is efficiently solved via geometric programming techniques. Finally,\nsimulations demonstrate that the proposed method improves user satisfaction by\nup to $17.1\\%$ compared to state of the art methods based on quality of\nexperience-aware SemCom methods.","main_category":"cs.NI","categories":"cs.NI,eess.SP","published":"2025-04-29T17:04:48Z"}
{"aid":"http://arxiv.org/abs/2504.20954v1","title":"21 years of Astronomy at Warwick: celebrating the legacy of Prof. Tom\n  Marsh","summary":"Between the 4th and 6th of September 2024, the Astronomy & Astrophysics group\nat the University of Warwick held a meeting to celebrate 21 years of astronomy\nat Warwick and the scientific legacy of the late Prof. Tom Marsh, the group\nfounder. More than a hundred people attended the meeting, with about half of\nthe attendees being external delegates and coming from as far afield as the USA\nand South Africa. Tom Marsh moved to the University of Warwick from Southampton\nin 2003, after the Department of Physics decided to expand the scope of its\nresearch. From its humble beginnings with only two staff members, Tom himself\nand Boris G\\\"ansicke, one postdoc and a couple of PhD students, the group has\nnow grown to more than 95 members, including 25 staff. Tom pioneered the\ndevelopment of Doppler tomography, led key discoveries in the field of\ndouble-degenerate binary systems and made extensive contributions to\ninstrumentation, primarily to developing the high-speed imaging photometers\nULTRACAM, ULTRASPEC and HiPERCAM. This article provides a summary of Tom's\nlegacy and Warwick's history as presented in the 21 years of Astronomy at\nWarwick meeting.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,astro-ph.IM","published":"2025-04-29T17:25:07Z"}
{"aid":"http://arxiv.org/abs/2504.20961v1","title":"Simple Finite-Length Achievability and Converse Bounds for the Deletion\n  Channel and the Insertion Channel","summary":"We develop upper bounds on code size for independent and identically\ndistributed deletion (insertion) channel for given code length and target frame\nerror probability. The bounds are obtained as a variation of a general converse\nbound, which, though available for any channel, is inefficient and not easily\ncomputable without a good reference distribution over the output alphabet. We\nobtain a reference output distribution for a general finite-input finite-output\nchannel and provide a simple formula for the converse bound on the capacity\nemploying this distribution. We then evaluate the bound for the deletion\nchannel with a finite block length and show that the resulting upper bound on\nthe code side is tighter than that for a binary erasure channel, which is the\nonly alternative converse bound for this finite-length setting. Also, we\nprovide the similar results for the insertion channel.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-29T17:32:27Z"}
{"aid":"http://arxiv.org/abs/2504.20969v1","title":"XPG-RL: Reinforcement Learning with Explainable Priority Guidance for\n  Efficiency-Boosted Mechanical Search","summary":"Mechanical search (MS) in cluttered environments remains a significant\nchallenge for autonomous manipulators, requiring long-horizon planning and\nrobust state estimation under occlusions and partial observability. In this\nwork, we introduce XPG-RL, a reinforcement learning framework that enables\nagents to efficiently perform MS tasks through explainable, priority-guided\ndecision-making based on raw sensory inputs. XPG-RL integrates a task-driven\naction prioritization mechanism with a learned context-aware switching strategy\nthat dynamically selects from a discrete set of action primitives such as\ntarget grasping, occlusion removal, and viewpoint adjustment. Within this\nstrategy, a policy is optimized to output adaptive threshold values that govern\nthe discrete selection among action primitives. The perception module fuses\nRGB-D inputs with semantic and geometric features to produce a structured scene\nrepresentation for downstream decision-making. Extensive experiments in both\nsimulation and real-world settings demonstrate that XPG-RL consistently\noutperforms baseline methods in task success rates and motion efficiency,\nachieving up to 4.5$\\times$ higher efficiency in long-horizon tasks. These\nresults underscore the benefits of integrating domain knowledge with learnable\ndecision-making policies for robust and efficient robotic manipulation.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-29T17:37:45Z"}
{"aid":"http://arxiv.org/abs/2504.20970v1","title":"SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep\n  Features","summary":"Accurate and early diagnosis of pneumonia through X-ray imaging is essential\nfor effective treatment and improved patient outcomes. Recent advancements in\nmachine learning have enabled automated diagnostic tools that assist\nradiologists in making more reliable and efficient decisions. In this work, we\npropose a Singular Value Decomposition-based Least Squares (SVD-LS) framework\nfor multi-class pneumonia classification, leveraging powerful feature\nrepresentations from state-of-the-art self-supervised and transfer learning\nmodels. Rather than relying on computationally expensive gradient based\nfine-tuning, we employ a closed-form, non-iterative classification approach\nthat ensures efficiency without compromising accuracy. Experimental results\ndemonstrate that SVD-LS achieves competitive performance while offering\nsignificantly reduced computational costs, making it a viable alternative for\nreal-time medical imaging applications.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-29T17:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.20987v1","title":"Localized Fock Space Cages in Kinetically Constrained Models","summary":"We investigate a mechanism for non-ergodic behavior in many-body quantum\nsystems arising from destructive interference, leading to localization in Fock\nspace. Drawing parallels with single-particle flat-band localization and\nAharonov-Bohm cages, we identify conditions under which similar interference\neffects in the many-body domain produce Fock space cages (FSCs)-highly\nlocalized many-body eigenstates. By interpreting Fock space as a graph where\nnodes represent bitstring basis states and edges denote non-zero transition\namplitudes of the Hamiltonian, we analyze different kinetically constrained\nmodels. The FSCs cause non-ergodic dynamics when the system is initialized\nwithin their support, highlighting a universal interference-driven localization\nmechanism in many-body systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.str-el","published":"2025-04-29T17:56:25Z"}
{"aid":"http://arxiv.org/abs/2504.20989v1","title":"Photonic Quantum Convolutional Neural Networks with Adaptive State\n  Injection","summary":"Linear optical architectures have been extensively investigated for quantum\ncomputing and quantum machine learning applications. Recently, proposals for\nphotonic quantum machine learning have combined linear optics with resource\nadaptivity, such as adaptive circuit reconfiguration, which promises to enhance\nexpressivity and improve algorithm performances and scalability. Moreover,\nlinear optical platforms preserve some subspaces due to the fixed number of\nparticles during the computation, a property recently exploited to design a\nnovel quantum convolutional neural networks. This last architecture has shown\nan advantage in terms of running time complexity and of the number of\nparameters needed with respect to other quantum neural network proposals. In\nthis work, we design and experimentally implement the first photonic quantum\nconvolutional neural network (PQCNN) architecture based on particle-number\npreserving circuits equipped with state injection, an approach recently\nproposed to increase the controllability of linear optical circuits.\nSubsequently, we experimentally validate the PQCNN for a binary image\nclassification on a photonic platform utilizing a semiconductor quantum\ndot-based single-photon source and programmable integrated photonic\ninterferometers comprising 8 and 12 modes. In order to investigate the\nscalability of the PQCNN design, we have performed numerical simulations on\ndatasets of different sizes. We highlight the potential utility of a simple\nadaptive technique for a nonlinear Boson Sampling task, compatible with\nnear-term quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-29T17:57:01Z"}
{"aid":"http://arxiv.org/abs/2504.20995v1","title":"TesserAct: Learning 4D Embodied World Models","summary":"This paper presents an effective approach for learning novel 4D embodied\nworld models, which predict the dynamic evolution of 3D scenes over time in\nresponse to an embodied agent's actions, providing both spatial and temporal\nconsistency. We propose to learn a 4D world model by training on RGB-DN (RGB,\nDepth, and Normal) videos. This not only surpasses traditional 2D models by\nincorporating detailed shape, configuration, and temporal changes into their\npredictions, but also allows us to effectively learn accurate inverse dynamic\nmodels for an embodied agent. Specifically, we first extend existing robotic\nmanipulation video datasets with depth and normal information leveraging\noff-the-shelf models. Next, we fine-tune a video generation model on this\nannotated dataset, which jointly predicts RGB-DN (RGB, Depth, and Normal) for\neach frame. We then present an algorithm to directly convert generated RGB,\nDepth, and Normal videos into a high-quality 4D scene of the world. Our method\nensures temporal and spatial coherence in 4D scene predictions from embodied\nscenarios, enables novel view synthesis for embodied environments, and\nfacilitates policy learning that significantly outperforms those derived from\nprior video-based world models.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-29T17:59:30Z"}
{"aid":"http://arxiv.org/abs/2504.21269v1","title":"Observation of the decay $B^0_{s}\\to K^0 p \\bar{p}$ and measurement of\n  the $B^0_{(s)} \\to K^0 p \\bar{p}$ branching fractions","summary":"A study of the charmless baryonic decays $B^0_{(s)} \\to K^0 p \\bar{p}$ is\npresented, where $B^0_{(s)}$ denotes either a $B^0$ or a $B^0_s$ meson. The\nanalysis is based on proton-proton collision data collected by the LHCb\nexperiment at centre-of-mass energies of 7, 8, and $13~\\mathrm{Tev}$,\ncorresponding to an integrated luminosity of $9~\\mathrm{fb}^{-1}$. The decay\n$B^0_s \\to K^0 p \\bar{p}$ is observed for the first time, with a measured\nbranching fraction of $(9.14 \\pm 1.69 \\pm 0.90 \\pm 0.33 \\pm 0.20) \\times\n10^{-7}$ and a significance of $5.6\\sigma$. The uncertainties respectively\naccount for statistical and systematic contributions, the precision of the\nbranching fraction of the normalisation channel $B^0 \\to K^0 \\pi^{+} \\pi^{-}$\nand the fragmentation fraction ratio ${f_s}/{f_d}$. The branching fraction\ndetermined for $B^0 \\to K^0 p \\bar{p}$ is $(2.82 \\pm 0.08 \\pm 0.12 \\pm 0.10)\n\\times 10^{-6}$, which is the most precise measurement to date.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-30T02:53:23Z"}
{"aid":"http://arxiv.org/abs/2504.21274v1","title":"Selmer ranks in twists of CM abelian varieties","summary":"We prove the distribution of Selmer ranks in the certain family of $p$-th\ntwists of CM abelian varieties obeys the symplectic distribution $\\sD_p^\\sym$\nor the unitary distribution $\\sD_{p^2}^\\uni$. As an application, for a prime\n$p\\geq 3$, we obtain that the twisted Fermat curve $X^p+Y^p=\\delta$ over a\nnumber field containing a primitive $p$-th root of unity is ``largely\"\nunsolvable as $\\delta$ varies.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T03:06:56Z"}
{"aid":"http://arxiv.org/abs/2504.21275v1","title":"Hurdle Network Model With Latent Dynamic Shrinkage For Enhanced Edge\n  Prediction in Zero-Inflated Directed Network Time Series","summary":"This article aims to model international trade relationships among 29\ncountries in the apparel industry between 1994 and 2013. Bilateral trade flows\ncan be represented as a directed network, where nodes correspond to countries\nand directed edges indicate trade flows (i.e., whether one country exported to\nanother in a given year). Additionally, node (e.g., GDP) and edge-specific\n(e.g., labor provision) covariates are also available. The study focuses on two\nkey challenges: (1) capturing multiple forms of temporal and network\ndependence, and dependence on covariates; and (2) accounting for potential\ntrade volume as an important but partially observed edge-specific covariate,\nwhich is only available for country pairs that engaged in trade.\n  To address these challenges, we introduce the dynamic hurdle network model\n(Hurdle-Net) for zero-inflated directed network time series that incorporates\nseveral novel features. First, it represents the time series as a paired binary\nand continuous time series and utilizes a hurdle model that effectively handles\nsparsity in edge occurrence. Second, the model captures evolving network\ndependencies using node-specific latent variables governed by a dynamic\nshrinkage process. Third, it leverages a shared latent structure across the\nbinary and continuous components, reflecting the fact that both networks\ninvolve the same nodes. Finally, the model employs a generalized logistic link\nfunction to relate edge occurrence to edge weight, allowing for a parsimonious\nand coherent hierarchical Bayesian framework that jointly models both network\ncomponents. Compared to static or independent models, Hurdle-Net provides\nimproved model selection, estimation, and prediction performance for analyzing\ninternational trade patterns. Its effectiveness is demonstrated through\nsimulation studies and an application to bilateral trade flow data.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-30T03:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.21290v1","title":"High-Fidelity Single-Pixel Imaging at Ultra-Low Sampling Ratios via\n  Physically Enhanced Laguerre Gaussian Encoding","summary":"Single-pixel imaging (SPI) has offered an unprecedented technique for\ncapturing a targeted scenes without requiring either raster-scanned systems or\nmuti-pixel detectors. However, in the current research, there are rare study\nreports about achieving both high spatial quality and low sampling ratio below\n5% without additional algorithms in the existing SPI architectures. To\ncircumvent these challenges, here we demonstrate a novel Laguerre Gaussian\nsingle-pixel imaging (LGSI) technique achieving ultra-low sampling ratio (3%)\nand super-high spatial imaging quality (Structural Similarity (SSIM) of 0.739\nand a peak signal-to-noise ratio (PSNR) of 20.762 dB). The fundamental\nmethodology relies on the enhancement of the encoded patterns by the\ndifferential modulation of discrete orthogonal physical LG moments, enabling\nthe reconstruction of illuminated target object via a linear weighting of the\nstructured light intensity. Leveraging this orthogonal mechanism, LGSI\ndemonstrates superior imaging quality and computational efficiency, surpassing\nthe capabilities of non-orthogonal moments. Comparative analyses of the power\nspectra from reconstructed images highlight the enhanced efficacy of LGSI over\nHadamard SPI (HSI) and Fourier SPI (FSI). Our results suggest the possibility\nof encoding multi-dimensional structured light fields as a promising pathway\nfor realizing low sampling ratio, universal, and physical-endow SPI.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-30T03:54:13Z"}
{"aid":"http://arxiv.org/abs/2504.21305v1","title":"Virtual Element Method Applied to Two Dimensional Axisymmetric Elastic\n  Problems","summary":"This work presents a Virtual Element Method (VEM) formulation tailored for\ntwo-dimensional axisymmetric problems in linear elasticity. By exploiting the\nrotational symmetry of the geometry and loading conditions, the problem is\nreduced to a meridional cross-section, where all fields depend only on the\nradial and axial coordinates. The method incorporates the radial weight $r$ in\nboth the weak formulation and the interpolation estimates to remain consistent\nwith the physical volume measure of cylindrical coordinates. A projection\noperator onto constant strain fields is constructed via boundary integrals, and\na volumetric correction term is introduced to account for the divergence of the\nstress field arising from axisymmetry. The stabilization term is designed to\nact only on the kernel of the projection and is implemented using a\nboundary-based formulation that guarantees stability without affecting\npolynomial consistency. Furthermore, an a priori interpolation error estimate\nis established in a weighted Sobolev space, showing optimal convergence rates.\nThe implementation is validated through patch tests that demonstrate the\naccuracy, consistency, and robustness of the proposed approach.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T04:26:50Z"}
{"aid":"http://arxiv.org/abs/2504.21308v1","title":"AGHI-QA: A Subjective-Aligned Dataset and Metric for AI-Generated Human\n  Images","summary":"The rapid development of text-to-image (T2I) generation approaches has\nattracted extensive interest in evaluating the quality of generated images,\nleading to the development of various quality assessment methods for\ngeneral-purpose T2I outputs. However, existing image quality assessment (IQA)\nmethods are limited to providing global quality scores, failing to deliver\nfine-grained perceptual evaluations for structurally complex subjects like\nhumans, which is a critical challenge considering the frequent anatomical and\ntextural distortions in AI-generated human images (AGHIs). To address this gap,\nwe introduce AGHI-QA, the first large-scale benchmark specifically designed for\nquality assessment of AGHIs. The dataset comprises 4,000 images generated from\n400 carefully crafted text prompts using 10 state of-the-art T2I models. We\nconduct a systematic subjective study to collect multidimensional annotations,\nincluding perceptual quality scores, text-image correspondence scores, visible\nand distorted body part labels. Based on AGHI-QA, we evaluate the strengths and\nweaknesses of current T2I methods in generating human images from multiple\ndimensions. Furthermore, we propose AGHI-Assessor, a novel quality metric that\nintegrates the large multimodal model (LMM) with domain-specific human features\nfor precise quality prediction and identification of visible and distorted body\nparts in AGHIs. Extensive experimental results demonstrate that AGHI-Assessor\nshowcases state-of-the-art performance, significantly outperforming existing\nIQA methods in multidimensional quality assessment and surpassing leading LMMs\nin detecting structural distortions in AGHIs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T04:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.21309v1","title":"An Evaluation of a Visual Question Answering Strategy for Zero-shot\n  Facial Expression Recognition in Still Images","summary":"Facial expression recognition (FER) is a key research area in computer vision\nand human-computer interaction. Despite recent advances in deep learning,\nchallenges persist, especially in generalizing to new scenarios. In fact,\nzero-shot FER significantly reduces the performance of state-of-the-art FER\nmodels. To address this problem, the community has recently started to explore\nthe integration of knowledge from Large Language Models for visual tasks. In\nthis work, we evaluate a broad collection of locally executed Visual Language\nModels (VLMs), avoiding the lack of task-specific knowledge by adopting a\nVisual Question Answering strategy. We compare the proposed pipeline with\nstate-of-the-art FER models, both integrating and excluding VLMs, evaluating\nwell-known FER benchmarks: AffectNet, FERPlus, and RAF-DB. The results show\nexcellent performance for some VLMs in zero-shot FER scenarios, indicating the\nneed for further exploration to improve FER generalization.","main_category":"cs.CV","categories":"cs.CV,I.2.10","published":"2025-04-30T04:38:05Z"}
{"aid":"http://arxiv.org/abs/2504.21317v1","title":"Redundancy Analysis and Mitigation for Machine Learning-Based Process\n  Monitoring of Additive Manufacturing","summary":"The deployment of machine learning (ML)-based process monitoring systems has\nsignificantly advanced additive manufacturing (AM) by enabling real-time defect\ndetection, quality assessment, and process optimization. However, redundancy is\na critical yet often overlooked challenge in the deployment and operation of\nML-based AM process monitoring systems. Excessive redundancy leads to increased\nequipment costs, compromised model performance, and high computational\nrequirements, posing barriers to industrial adoption. However, existing\nresearch lacks a unified definition of redundancy and a systematic framework\nfor its evaluation and mitigation. This paper defines redundancy in ML-based AM\nprocess monitoring and categorizes it into sample-level, feature-level, and\nmodel-level redundancy. A comprehensive multi-level redundancy mitigation\n(MLRM) framework is proposed, incorporating advanced methods such as data\nregistration, downscaling, cross-modality knowledge transfer, and model pruning\nto systematically reduce redundancy while improving model performance. The\nframework is validated through an ML-based in-situ defect detection case study\nfor directed energy deposition (DED), demonstrating a 91% reduction in latency,\na 47% decrease in error rate, and a 99.4% reduction in storage requirements.\nAdditionally, the proposed approach lowers sensor costs and energy consumption,\nenabling a lightweight, cost-effective, and scalable monitoring system. By\ndefining redundancy and introducing a structured mitigation framework, this\nstudy establishes redundancy analysis and mitigation as a key enabler of\nefficient ML-based process monitoring in production environments.","main_category":"cs.CE","categories":"cs.CE,cs.LG,eess.SP","published":"2025-04-30T05:04:53Z"}
{"aid":"http://arxiv.org/abs/2504.21329v1","title":"Drawing Reeb Graphs","summary":"Reeb graphs are simple topological descriptors which find applications in\nmany areas like topological data analysis and computational geometry. Despite\ntheir prevalence, visualization of Reeb graphs has received less attention. In\nthis paper, we bridge an essential gap in the literature by exploring the\ncomplexity of drawing Reeb graphs. Specifically, we demonstrate that Reeb graph\ncrossing number minimization is NP-hard, both for straight-line and curve\nrepresentations of edges. On the other hand, we identify specific classes of\nReeb graphs, namely paths and caterpillars, for which crossing-free drawings\nexist. We also give an optimal algorithm for drawing cycle-shaped Reeb graphs\nwith the least number of crossings and provide initial observations on the\ncomplexities of drawing multi-cycle Reeb graphs. We hope that this work\nestablishes the foundation for an understanding of the graph drawing challenges\ninherent in Reeb graph visualization and paves the way for future work in this\narea.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-30T05:35:04Z"}
{"aid":"http://arxiv.org/abs/2504.21336v1","title":"UniBiomed: A Universal Foundation Model for Grounded Biomedical Image\n  Interpretation","summary":"Multi-modal interpretation of biomedical images opens up novel opportunities\nin biomedical image analysis. Conventional AI approaches typically rely on\ndisjointed training, i.e., Large Language Models (LLMs) for clinical text\ngeneration and segmentation models for target extraction, which results in\ninflexible real-world deployment and a failure to leverage holistic biomedical\ninformation. To this end, we introduce UniBiomed, the first universal\nfoundation model for grounded biomedical image interpretation. UniBiomed is\nbased on a novel integration of Multi-modal Large Language Model (MLLM) and\nSegment Anything Model (SAM), which effectively unifies the generation of\nclinical texts and the segmentation of corresponding biomedical objects for\ngrounded interpretation. In this way, UniBiomed is capable of tackling a wide\nrange of biomedical tasks across ten diverse biomedical imaging modalities. To\ndevelop UniBiomed, we curate a large-scale dataset comprising over 27 million\ntriplets of images, annotations, and text descriptions across ten imaging\nmodalities. Extensive validation on 84 internal and external datasets\ndemonstrated that UniBiomed achieves state-of-the-art performance in\nsegmentation, disease recognition, region-aware diagnosis, visual question\nanswering, and report generation. Moreover, unlike previous models that rely on\nclinical experts to pre-diagnose images and manually craft precise textual or\nvisual prompts, UniBiomed can provide automated and end-to-end grounded\ninterpretation for biomedical image analysis. This represents a novel paradigm\nshift in clinical workflows, which will significantly improve diagnostic\nefficiency. In summary, UniBiomed represents a novel breakthrough in biomedical\nAI, unlocking powerful grounded interpretation capabilities for more accurate\nand efficient biomedical image analysis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T05:51:48Z"}
{"aid":"http://arxiv.org/abs/2504.21342v1","title":"Low latency FPGA implementation of twisted Edward curve cryptography\n  hardware accelerator over prime field","summary":"The performance of any elliptic curve cryptography hardware accelerator\nsignificantly relies on the efficiency of the underlying point multiplication\n(PM) architecture. This article presents a hardware implementation of\nfield-programmable gate array (FPGA) based modular arithmetic, group operation,\nand point multiplication unit on the twisted Edwards curve (Edwards25519) over\nthe 256-bit prime field. An original hardware architecture of a unified point\noperation module in projective coordinates that executes point addition and\npoint doubling within a single module has been developed, taking only 646 clock\ncycles and ensuring a better security level than conventional approaches. The\nproposed point multiplication module consumes 1.4 ms time, operating at a\nmaximal clock frequency of 117.8 MHz utilising 164,730 clock cycles having\n183.38 kbps throughput on the Xilinx Virtex-5 FPGA platform for 256-bit length\nof key. The comparative assessment of latency and throughput across various\nrelated recent works indicates the effectiveness of our proposed PM\narchitecture. Finally, this high throughput and low latency PM architecture\nwill be a good candidate for rapid data encryption in high-speed wireless\ncommunication networks.","main_category":"cs.CR","categories":"cs.CR,cs.NI","published":"2025-04-30T06:03:36Z"}
{"aid":"http://arxiv.org/abs/2504.21346v1","title":"A microwave-activated high-fidelity three-qubit gate scheme for\n  fixed-frequency superconducting qubits","summary":"Scalable superconducting quantum processors require balancing critical\nconstraints in coherence, control complexity, and spectral crowding.\nFixed-frequency architectures suppress flux noise and simplify control via\nall-microwave operations but remain limited by residual ZZ crosstalk. Here we\npropose a microwave-activated three-qubit gate protocol for fixed-frequency\ntransmon qubits in the large-detuning regime ($|\\Delta| \\gg g$), leveraging the\nthird-order nonlinear interaction to coherently exchange $|001\\rangle\n\\leftrightarrow |110\\rangle$ states. By incorporating a phase-compensated\noptimization protocol, numerical simulations demonstrate a high average gate\nfidelity exceeding $99.9\\%$. Systematic error analysis identifies static\nlong-range ZZ coupling as the dominant error source in multi-qubit systems,\nwhich can be suppressed via operations in the large-detuning regime ($\\sim 1$\nGHz). This approach simultaneously enhances gate fidelity while preserving\nspectral isolation, ensuring compatibility with existing all-microwave\ncontrolled-Z gate frameworks. The protocol exhibits intrinsic robustness to\nfabrication-induced qubit parameter variations. This hardware-efficient\nstrategy advances scalable quantum computing systems by improving coherence\nproperties, reducing spectral congestion, and expanding the experimental\ntoolkit for error-resilient quantum operations in the noisy intermediate-scale\nquantum era.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T06:16:16Z"}
{"aid":"http://arxiv.org/abs/2504.21347v1","title":"IRL Dittos: Embodied Multimodal AI Agent Interactions in Open Spaces","summary":"We introduce the In Real Life (IRL) Ditto, an AI-driven embodied agent\ndesigned to represent remote colleagues in shared office spaces, creating\nopportunities for real-time exchanges even in their absence. IRL Ditto offers a\nunique hybrid experience by allowing in-person colleagues to encounter a\ndigital version of their remote teammates, initiating greetings, updates, or\nsmall talk as they might in person. Our research question examines: How can the\nIRL Ditto influence interactions and relationships among colleagues in a shared\noffice space? Through a four-day study, we assessed IRL Ditto's ability to\nstrengthen social ties by simulating presence and enabling meaningful\ninteractions across different levels of social familiarity. We find that\nenhancing social relationships depended deeply on the foundation of the\nrelationship participants had with the source of the IRL Ditto. This study\nprovides insights into the role of embodied agents in enriching workplace\ndynamics for distributed teams.","main_category":"cs.AI","categories":"cs.AI,cs.HC","published":"2025-04-30T06:16:32Z"}
{"aid":"http://arxiv.org/abs/2504.21363v1","title":"The differential structure shared by probability and moment matching\n  priors on non-regular statistical models via the Lie derivative","summary":"In Bayesian statistics, the selection of noninformative priors is a crucial\nissue. There have been various discussions on theoretical justification,\nproblems with the Jeffreys prior, and alternative objective priors. Among them,\nwe focus on two types of matching priors consistent with frequentist theory:\nthe probability matching priors and the moment matching priors. In particular,\nno clear relationship has been established between these two types of priors on\nnon-regular statistical models, even though they share similar objectives.\n  Considering information geometry on a one-sided truncated exponential family,\na typical example of non-regular statistical models, we find that the Lie\nderivative along a particular vector field provides the conditions for both the\nprobability and moment matching priors. Notably, this Lie derivative does not\nappear in regular models. These conditions require the invariance of a\ngeneralized volume element with respect to differentiation along the\nnon-regular parameter. This invariance leads to a suitable decomposition of the\none-sided truncated exponential family into one-dimensional submodels. This\nresult promotes a unified understanding of probability and moment matching\npriors on non-regular models.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-30T06:51:13Z"}
{"aid":"http://arxiv.org/abs/2504.21365v1","title":"Self-sustaining traveling fronts for a model related to bushfires","summary":"This article investigates a mathematical model for bushfire propagation,\nfocusing on the existence and properties of translating solutions. We obtain\nquantitative bounds on the environmental diffusion coefficient and ignition\nkernels, identifying conditions under which fires either propagate across the\nentire region or naturally extinguish.\n  Our analysis also reveals that vertically translating solutions do not exist,\nwhereas traveling wave solutions with a front moving at any prescribed velocity\nalways exist for kernels that are either of mild intensity or short range.\nThese traveling waves exhibit unbounded profiles.\n  Although evolutionary unstable, these traveling waves demonstrate stability\nunder perturbations localized in a small region.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T06:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.21398v1","title":"In a Few Words: Comparing Weak Supervision and LLMs for Short Query\n  Intent Classification","summary":"User intent classification is an important task in information retrieval.\nPreviously, user intents were classified manually and automatically; the latter\nhelped to avoid hand labelling of large datasets. Recent studies explored\nwhether LLMs can reliably determine user intent. However, researchers have\nrecognized the limitations of using generative LLMs for classification tasks.\nIn this study, we empirically compare user intent classification into\ninformational, navigational, and transactional categories, using weak\nsupervision and LLMs. Specifically, we evaluate LLaMA-3.1-8B-Instruct and\nLLaMA-3.1-70B-Instruct for in-context learning and LLaMA-3.1-8B-Instruct for\nfine-tuning, comparing their performance to an established baseline classifier\ntrained using weak supervision (ORCAS-I). Our results indicate that while LLMs\noutperform weak supervision in recall, they continue to struggle with\nprecision, which shows the need for improved methods to balance both metrics\neffectively.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-30T07:54:04Z"}
{"aid":"http://arxiv.org/abs/2504.21404v1","title":"A radiative neutrino mass model with leptoquarks under non-holomorphic\n  modular $A_4$ symmetry","summary":"We investigate a radiative seesaw model with two leptoquarks under\nnon-holomorphic modular $A_4$ symmetry. The leptons and quarks belong to\nnon-trivial representations of the modular $A_4$ and the structures of their\nmass matrices are restricted. Neutrino masses are generated at one-loop level\nvia leptoquark inside loop diagram where structures of relevant Yukawa\ninteractions are determined by the modular $A_4$ symmetry. We scan the free\nparameters in the model and try to fit all the observed data for both lepton\nand quark sectors. For allowed parameters, we show some predictions regarding\nneutrino observables such as sum of neutrino mass and neutrinoless double beta\ndecay.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-30T08:04:16Z"}
{"aid":"http://arxiv.org/abs/2504.21412v1","title":"On the Encapsulation of Medical Imaging AI Algorithms","summary":"In the context of collaborative AI research and development projects, it\nwould be ideal to have self-contained encapsulated algorithms that can be\neasily shared between different parties, executed and validated on data at\ndifferent sites, or trained in a federated manner. In practice, all of this is\npossible but greatly complicated, because human supervision and expert\nknowledge is needed to set up the execution of algorithms based on their\ndocumentation, possibly implicit assumptions, and knowledge about the execution\nenvironment and data involved.\n  We derive and formulate a range of detailed requirements from the above goal\nand from specific use cases, focusing on medical imaging AI algorithms.\nFurthermore, we refer to a number of existing APIs and implementations and\nreview which aspects each of them addresses, which problems are still open, and\nwhich public standards and ontologies may be relevant. Our contribution is a\ncomprehensive collection of aspects that have not yet been addressed in their\nentirety by any single solution.\n  Working towards the formulated goals should lead to more sustainable\nalgorithm ecosystems and relates to the FAIR principles for research data,\nwhere this paper focuses on interoperability and (re)usability of medical\nimaging AI algorithms.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-30T08:12:09Z"}
{"aid":"http://arxiv.org/abs/2504.21433v1","title":"NGENT: Next-Generation AI Agents Must Integrate Multi-Domain Abilities\n  to Achieve Artificial General Intelligence","summary":"This paper argues that the next generation of AI agent (NGENT) should\nintegrate across-domain abilities to advance toward Artificial General\nIntelligence (AGI). Although current AI agents are effective in specialized\ntasks such as robotics, role-playing, and tool-using, they remain confined to\nnarrow domains. We propose that future AI agents should synthesize the\nstrengths of these specialized systems into a unified framework capable of\noperating across text, vision, robotics, reinforcement learning, emotional\nintelligence, and beyond. This integration is not only feasible but also\nessential for achieving the versatility and adaptability that characterize\nhuman intelligence. The convergence of technologies across AI domains, coupled\nwith increasing user demand for cross-domain capabilities, suggests that such\nintegration is within reach. Ultimately, the development of these versatile\nagents is a critical step toward realizing AGI. This paper explores the\nrationale for this shift, potential pathways for achieving it.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-30T08:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.21447v1","title":"Rethinking Visual Layer Selection in Multimodal LLMs","summary":"Multimodal large language models (MLLMs) have achieved impressive performance\nacross a wide range of tasks, typically using CLIP-ViT as their visual encoder\ndue to its strong text-image alignment capabilities. While prior studies\nsuggest that different CLIP-ViT layers capture different types of information,\nwith shallower layers focusing on fine visual details and deeper layers\naligning more closely with textual semantics, most MLLMs still select visual\nfeatures based on empirical heuristics rather than systematic analysis. In this\nwork, we propose a Layer-wise Representation Similarity approach to group\nCLIP-ViT layers with similar behaviors into {shallow, middle, and deep}\ncategories and assess their impact on MLLM performance. Building on this\nfoundation, we revisit the visual layer selection problem in MLLMs at scale,\ntraining LLaVA-style models ranging from 1.4B to 7B parameters. Through\nextensive experiments across 10 datasets and 4 tasks, we find that: (1) deep\nlayers are essential for OCR tasks; (2) shallow and middle layers substantially\noutperform deep layers on reasoning tasks involving counting, positioning, and\nobject localization; (3) a lightweight fusion of features across shallow,\nmiddle, and deep layers consistently outperforms specialized fusion baselines\nand single-layer selections, achieving gains on 9 out of 10 datasets. Our work\noffers the first principled study of visual layer selection in MLLMs, laying\nthe groundwork for deeper investigations into visual representation learning\nfor MLLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-30T09:07:10Z"}
{"aid":"http://arxiv.org/abs/2504.21462v1","title":"High-Quality Ultra-Fast Total Scattering and Pair Distribution Function\n  Data using an X-ray Free Electron Laser","summary":"High-quality total scattering data, a key tool for understanding atomic-scale\nstructure in disordered materials, require stable instrumentation and access to\nhigh momentum transfers. This is now routine at dedicated synchrotron\ninstrumentation using high-energy X-ray beams, but it is very challenging to\nmeasure a total scattering dataset in less than a few microseconds. This limits\ntheir effectiveness for capturing structural changes that occur at the much\nfaster timescales of atomic motion. Current X-ray free-electron lasers (XFELs)\nprovide femtosecond-pulsed X-ray beams with maximum energies of approximately\n24 keV, giving the potential to measure total scattering and the attendant pair\ndistribution functions (PDFs) on femtosecond timescales. Here, we show that\nthis potential has been realised using the HED scientific instrument at the\nEuropean XFEL and present normalised total scattering data for 0.35 \\r{A}-1 < Q\n< 16.6 \\r{A}-1 and their PDFs from a broad spectrum of materials, including\ncrystalline, nanocrystalline and amorphous solids, liquids, and clusters in\nsolution. We analyse the data using a variety of methods, including Rietveld\nrefinement, small-box PDF refinement, joint reciprocal-real space refinement,\ncluster refinement, and Debye scattering analysis. The resolution function of\nthe setup is also thoroughly characterised. We conclusively show that\nhigh-quality data can be obtained from a single approximately 30 fs XFEL pulse.\nOur efforts not only significantly increase the existing maximum reported\nQ-range for an S(Q) measured at an XFEL but also mean that XFELs are now a\nviable X-ray source for the broad community of people using reciprocal space\ntotal scattering and PDF methods in their research.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-30T09:31:22Z"}
{"aid":"http://arxiv.org/abs/2504.21468v1","title":"Quaternion Nuclear Norms Over Frobenius Norms Minimization for Robust\n  Matrix Completion","summary":"Recovering hidden structures from incomplete or noisy data remains a\npervasive challenge across many fields, particularly where multi-dimensional\ndata representation is essential. Quaternion matrices, with their ability to\nnaturally model multi-dimensional data, offer a promising framework for this\nproblem. This paper introduces the quaternion nuclear norm over the Frobenius\nnorm (QNOF) as a novel nonconvex approximation for the rank of quaternion\nmatrices. QNOF is parameter-free and scale-invariant. Utilizing quaternion\nsingular value decomposition, we prove that solving the QNOF can be simplified\nto solving the singular value $L_1/L_2$ problem. Additionally, we extend the\nQNOF to robust quaternion matrix completion, employing the alternating\ndirection multiplier method to derive solutions that guarantee weak convergence\nunder mild conditions. Extensive numerical experiments validate the proposed\nmodel's superiority, consistently outperforming state-of-the-art quaternion\nmethods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T09:44:09Z"}
{"aid":"http://arxiv.org/abs/2504.21481v1","title":"Evidence for Dynamical Dark Matter","summary":"The nature of dark matter is one of the most fundamental questions in\ncosmology. Using the cosmic microwave background (CMB), type Ia supernova (SN)\nand DESI's new measurements of baryon acoustic oscillations (BAO), we find the\nrobust $\\sim2\\,\\sigma$ evidences of the evolution of dark matter in the\ndynamical dark matter (DDM) model,\n$\\omega_{dm}(a)=\\omega_{dm0}+\\omega_{dma}(1-a)$. Based on CMB data, we find a\nvery strong linear relation $\\omega_{dma}=-\\omega_{dm0}$, inducing the\nsingle-parameter DDM model, $\\omega_{dm}(a)=\\omega_{dm}a$, where the\n$\\sim2\\,\\sigma$ DDM evidences is well captured and even strengthened. We\ndemonstrate that there are beyond $2\\,\\sigma$ evidences of the coexistence of\nDDM and dynamical dark energy using the combinations of CMB, DESI BAO and\nPantheon+ SN data. In such models, at a beyond $5\\,\\sigma$ confidence level, we\nverify that the universe remains in a matter-dominated state for a substantial\nperiod in the past, accelerate in the distant future and finally becomes\ncompletely dominated by dark matter. We propose that the ultimate fate of the\nuniverse is the ``Super Rip'' induced by dark matter with an extremely negative\npressure. Our findings fundamentally challenge the prevailing understanding of\ncosmic acceleration and deepen our insight into the universe's evolution.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-30T10:05:45Z"}
{"aid":"http://arxiv.org/abs/2504.21488v1","title":"New Constructions of Distance-Biregular Graphs","summary":"We construct a new family of distance-biregular graphs related to hyperovals\nand a new sporadic example of a distance-biregular graph related to Mathon's\nperp system. The infinite family can be explained using 2-Y- homogeneity, while\nthe sporadic example belongs to a generalization of a construction by Delorme.\nAdditionally, we give a new non-existence criteria for distance-biregular\ngraphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-30T10:13:55Z"}
{"aid":"http://arxiv.org/abs/2504.21495v1","title":"Consistency-aware Fake Videos Detection on Short Video Platforms","summary":"This paper focuses to detect the fake news on the short video platforms.\nWhile significant research efforts have been devoted to this task with notable\nprogress in recent years, current detection accuracy remains suboptimal due to\nthe rapid evolution of content manipulation and generation technologies.\nExisting approaches typically employ a cross-modal fusion strategy that\ndirectly combines raw video data with metadata inputs before applying a\nclassification layer. However, our empirical observations reveal a critical\noversight: manipulated content frequently exhibits inter-modal inconsistencies\nthat could serve as valuable discriminative features, yet remain underutilized\nin contemporary detection frameworks. Motivated by this insight, we propose a\nnovel detection paradigm that explicitly identifies and leverages cross-modal\ncontradictions as discriminative cues. Our approach consists of two core\nmodules: Cross-modal Consistency Learning (CMCL) and Multi-modal Collaborative\nDiagnosis (MMCD). CMCL includes Pseudo-label Generation (PLG) and Cross-modal\nConsistency Diagnosis (CMCD). In PLG, a Multimodal Large Language Model is used\nto generate pseudo-labels for evaluating cross-modal semantic consistency.\nThen, CMCD extracts [CLS] tokens and computes cosine loss to quantify\ncross-modal inconsistencies. MMCD further integrates multimodal features\nthrough Multimodal Feature Fusion (MFF) and Probability Scores Fusion (PSF).\nMFF employs a co-attention mechanism to enhance semantic interactions across\ndifferent modalities, while a Transformer is utilized for comprehensive feature\nfusion. Meanwhile, PSF further integrates the fake news probability scores\nobtained in the previous step. Extensive experiments on established benchmarks\n(FakeSV and FakeTT) demonstrate our model exhibits outstanding performance in\nFake videos detection.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-30T10:26:04Z"}
{"aid":"http://arxiv.org/abs/2504.21508v1","title":"On type IIB AdS$_{3}$ flux vacua with scale separation and integer\n  conformal dimensions","summary":"We review recent progress in constructing type IIB AdS$_{3}$ flux vacua that\nexhibit parametrically-controlled scale separation and come along with\ninteger-valued conformal dimensions for the would-be dual CFT$_{2}$ operators.\nWe comment on the anisotropic nature of the associated internal spaces, as well\nas on the existence of polynomial shift symmetries underlying the mass spectra.\nWe conclude by outlining open questions and potential directions for future\nresearch, partially inspired by the Swampland program.","main_category":"hep-th","categories":"hep-th","published":"2025-04-30T10:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.21515v1","title":"Double nuclear modification factor in relativistic heavy ion collisions","summary":"The hypothesis of the factorization of the double nuclear modification factor\nin relativistic heavy ion collisions is tested for different types of\nfinal-state hadrons within the HYDJET++ model. The results demonstrate that\nthis factorization holds reasonably well at moderately high transverse momenta,\nprovided that the effects of double parton scattering can be small or\nneglected.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex","published":"2025-04-30T11:09:15Z"}
{"aid":"http://arxiv.org/abs/2504.21527v1","title":"Low-rank computation of the posterior mean in Multi-Output Gaussian\n  Processes","summary":"Gaussian processes (GP) are a versatile tool in machine learning and\ncomputational science. We here consider the case of multi-output Gaussian\nprocesses (MOGP) and present low-rank approaches for efficiently computing the\nposterior mean of a MOGP. Starting from low-rank spatio-temporal data we\nconsider a structured covariance function, assuming separability across space\nand time. This separability, in turn, gives a decomposition of the covariance\nmatrix into a Kronecker product of individual covariance matrices.\nIncorporating the typical noise term to the model then requires the solution of\na large-scale Stein equation for computing the posterior mean. For this, we\npropose efficient low-rank methods based on a combination of a LRPCG method\nwith the Sylvester equation solver KPIK adjusted for solving Stein equations.\nWe test the developed method on real world street network graphs by using graph\nfilters as covariance matrices. Moreover, we propose a degree-weighted average\ncovariance matrix, which can be employed under specific assumptions to achieve\nmore efficient convergence.","main_category":"math.NA","categories":"math.NA,cs.LG,cs.NA","published":"2025-04-30T11:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.21537v1","title":"The role of dendritic spines in water exchange measurements with\n  diffusion MRI: Double Diffusion Encoding and free-waveform MRI","summary":"Time-dependent diffusion MRI enables the estimation of water exchange rates\nin vivo, yet reported values in grey matter remain inconsistent. While most\nstudies attribute these estimates to membrane permeability, non-permeative\ngeometric exchange has also been proposed. The present study investigates the\ncontribution of geometric exchange between dendritic spines and shafts to\ndiffusion MRI-derived exchange estimates. Monte Carlo simulations were\nperformed in synthetic dendrites with varying spine morphology, density, and\nmembrane permeability. Diffusion-weighted signals were generated using multiple\nprotocols - including single diffusion encoding, double diffusion encoding, and\nfree waveforms - and were analysed using four frameworks: the K\\\"arger model\n(via kurtosis time-dependence), correlation tensor imaging,\nRestriction-Exchange, and Multi-Gaussian Exchange with transient kurtosis\n(tMGE). Dendritic spines were found to impart similar time-dependence\nsignatures on the diffusion-weighted signal as permeative exchange (signal\ndecrease with diffusion time). The effect was modulated by both spine\nmorphology and density. Both the exchange rate and microscopic kurtosis\nincreased with spine density. The tMGE method demonstrated the ability to\ndisentangle geometric from permeative exchange. Non-permeative exchange in\ndendritic spines has a non-negligible impact on exchange estimates obtained\nwith diffusion MRI and should be considered in future studies. Diffusion MRI\nexchange estimates may provide a non-invasive proxy for dendritic spine\ndensity, with potential applications in studies of neurological disorders.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-30T11:34:44Z"}
{"aid":"http://arxiv.org/abs/2504.21548v1","title":"Leveraging Systems and Control Theory for Social Robotics: A Model-Based\n  Behavioral Control Approach to Human-Robot Interaction","summary":"Social robots (SRs) should autonomously interact with humans, while\nexhibiting proper social behaviors associated to their role. By contributing to\nhealth-care, education, and companionship, SRs will enhance life quality.\nHowever, personalization and sustaining user engagement remain a challenge for\nSRs, due to their limited understanding of human mental states. Accordingly, we\nleverage a recently introduced mathematical dynamic model of human perception,\ncognition, and decision-making for SRs. Identifying the parameters of this\nmodel and deploying it in behavioral steering system of SRs allows to\neffectively personalize the responses of SRs to evolving mental states of their\nusers, enhancing long-term engagement and personalization. Our approach\nuniquely enables autonomous adaptability of SRs by modeling the dynamics of\ninvisible mental states, significantly contributing to the transparency and\nawareness of SRs. We validated our model-based control system in experiments\nwith 10 participants who interacted with a Nao robot over three chess puzzle\nsessions, 45 - 90 minutes each. The identified model achieved a mean squared\nerror (MSE) of 0.067 (i.e., 1.675% of the maximum possible MSE) in tracking\nbeliefs, goals, and emotions of participants. Compared to a model-free\ncontroller that did not track mental states of participants, our approach\nincreased engagement by 16% on average. Post-interaction feedback of\nparticipants (provided via dedicated questionnaires) further confirmed the\nperceived engagement and awareness of the model-driven robot. These results\nhighlight the unique potential of model-based approaches and control theory in\nadvancing human-SR interactions.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-30T11:48:26Z"}
{"aid":"http://arxiv.org/abs/2504.21549v1","title":"Online Experimental Design for Network Tomography","summary":"How to efficiently perform network tomography is a fundamental problem in\nnetwork management and monitoring. A network tomography task usually consists\nof applying multiple probing experiments, e.g., across different paths or via\ndifferent casts (including unicast and multicast). We study how to optimize the\nnetwork tomography process through online sequential decision-making. From the\nmethodology perspective, we introduce an online probe allocation algorithm that\ndynamically performs network tomography based on the principles of optimal\nexperimental design and the maximum likelihood estimation. We rigorously\nanalyze the regret of the algorithm under the conditions that i) the optimal\nallocation is Lipschitz continuous in the parameters being estimated and ii)\nthe parameter estimators satisfy a concentration property. From the application\nperspective, we present two case studies: a) the classical lossy\npacket-switched network and b) the quantum bit-flip network. We show that both\ncases fulfill the two theoretical conditions and provide their corresponding\nregrets when deploying our proposed online probe allocation algorithm. Besides\nthese two case studies with theoretical guarantees, we also conduct simulations\nto compare our proposed algorithm with existing methods and demonstrate our\nalgorithm's effectiveness in a broader range of scenarios.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-30T11:48:49Z"}
{"aid":"http://arxiv.org/abs/2504.21557v1","title":"Optimizing carrier balance in CsPbBr3 nanocrystal LEDs: The role of\n  alkyl ligands and polar electron transport layers","summary":"The study of lead halide perovskite nanocrystal based light-emitting diodes\n(LEDs) has advanced significantly, with notable improvements in stability and\noptical properties. However, optimizing charge carrier injection and transport\nremains a challenge. Efficient electroluminescence requires a balanced\ntransport of both holes and electrons within the emitting material. Here, we\ninvestigate cubic CsPbBr\\textsubscript{3} nanocrystals passivated with\noleylamine and oleic acid, comparing them to ligand-exchanged nanocrystals with\ndidodecyldimethylammonium bromide (DDABr). Nuclear magnetic resonance\nspectroscopy and transmission electron microscopy confirm successful ligand\nexchange, revealing reduced ligand coverage in DDABr-treated nanocrystals.\nPhotoelectron spectroscopy, spectroelectrochemistry, and single-carrier devices\nindicate improved hole injection in DDABr-capped nanocrystals. Density\nfunctional theory calculations further reveal the influence of ligand type and\ncoverage on energy levels, with oleic acid introducing localized states in\nnative nanocrystals. Additionally, incorporation of a polar electron transport\nlayer (ETL) enhances LED performance by over an order of magnitude in\nDDABr-capped nanocrystals, driven by improved charge balance arising from the\nspontaneous orientation polarization (SOP) of the ETL. These findings highlight\nthe critical role of ligand selection, passivation degree, and charge transport\ncontrol by the adjacent organic transport layers in optimizing LED efficiency.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-30T11:54:43Z"}
{"aid":"http://arxiv.org/abs/2504.21564v1","title":"Simulating quantum collision models with Hamiltonian simulations using\n  early fault-tolerant quantum computers","summary":"We develop randomized quantum algorithms to simulate quantum collision\nmodels, also known as repeated interaction schemes, which provide a rich\nframework to model various open-system dynamics. The underlying technique\ninvolves composing time evolutions of the total (system, bath, and interaction)\nHamiltonian and intermittent tracing out of the environment degrees of freedom.\nThis results in a unified framework where any near-term Hamiltonian simulation\nalgorithm can be incorporated to implement an arbitrary number of such\ncollisions on early fault-tolerant quantum computers: we do not assume access\nto specialized oracles such as block encodings and minimize the number of\nancilla qubits needed. In particular, using the correspondence between\nLindbladian evolution and completely positive trace-preserving maps arising out\nof memoryless collisions, we provide an end-to-end quantum algorithm for\nsimulating Lindbladian dynamics. For a system of $n$-qubits, we exhaustively\ncompare the circuit depth needed to estimate the expectation value of an\nobservable with respect to the reduced state of the system after time $t$ while\nemploying different near-term Hamiltonian simulation techniques, requiring at\nmost $n+2$ qubits in all. We compare the CNOT gate counts of the various\napproaches for estimating the Transverse Field Magnetization of a $10$-qubit\nXX-Heisenberg spin chain under amplitude damping. Finally, we also develop a\nframework to efficiently simulate an arbitrary number of memory-retaining\ncollisions, i.e., where environments interact, leading to non-Markovian\ndynamics. Overall, our methods can leverage quantum collision models for both\nMarkovian and non-Markovian dynamics on early fault-tolerant quantum computers,\nshedding light on the advantages and limitations of simulating open systems\ndynamics using this framework.","main_category":"quant-ph","categories":"quant-ph,cs.DS","published":"2025-04-30T12:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.21597v1","title":"Optimizing the ground state energy of the three-dimensional magnetic\n  Dirichlet Laplacian with constant magnetic field","summary":"This paper concerns the shape optimization problem of minimizing the ground\nstate energy of the magnetic Dirichlet Laplacian with constant magnetic field\namong three-dimensional domains of fixed volume. In contrast to the\ntwo-dimensional case, a generalized ''magnetic'' Faber-Krahn inequality does\nnot hold and the minimizers are not expected to be balls when the magnetic\nfield is turned on. An analysis of the problem among cylindrical domains\nreveals geometric constraints for general minimizers. In particular, minimizers\nmust elongate with a certain rate along the direction of the magnetic field as\nthe field strength increases. In addition to the theoretical analysis, we\npresent numerical minimizers which confirm this prediction and give rise to\nfurther conjectures.","main_category":"math-ph","categories":"math-ph,math.AP,math.MP,math.OC,math.SP","published":"2025-04-30T12:55:14Z"}
{"aid":"http://arxiv.org/abs/2504.21602v1","title":"Real Time Semantic Segmentation of High Resolution Automotive LiDAR\n  Scans","summary":"In recent studies, numerous previous works emphasize the importance of\nsemantic segmentation of LiDAR data as a critical component to the development\nof driver-assistance systems and autonomous vehicles. However, many\nstate-of-the-art methods are tested on outdated, lower-resolution LiDAR sensors\nand struggle with real-time constraints. This study introduces a novel semantic\nsegmentation framework tailored for modern high-resolution LiDAR sensors that\naddresses both accuracy and real-time processing demands. We propose a novel\nLiDAR dataset collected by a cutting-edge automotive 128 layer LiDAR in urban\ntraffic scenes. Furthermore, we propose a semantic segmentation method\nutilizing surface normals as strong input features. Our approach is bridging\nthe gap between cutting-edge research and practical automotive applications.\nAdditionaly, we provide a Robot Operating System (ROS2) implementation that we\noperate on our research vehicle. Our dataset and code are publicly available:\nhttps://github.com/kav-institute/SemanticLiDAR.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-30T13:00:50Z"}
{"aid":"http://arxiv.org/abs/2504.21608v1","title":"No Evidence of Anomalous Diffusion in Yukawa Crystals","summary":"Diffusion in Yukawa crystals is stochastic due to the thermally activated\nformation of vacancy-interstitial pairs, which have poor statistics in\nsimulations. This makes it difficult to argue if Yukawa crystals exhibit normal\ndiffusion, or if they could be subdiffusive or superdiffusive. To resolve this,\nwe run a long molecular dynamics simulation of an idealized Yukawa crystal for\na billion timesteps. We find no evidence of anomalous diffusion in the pure\ncrystal, but also caution readers against overinterpreting this result as real\ncrystals have complicated structures including grains and defects.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,astro-ph.SR,cond-mat.mtrl-sci","published":"2025-04-30T13:08:01Z"}
{"aid":"http://arxiv.org/abs/2504.21624v1","title":"Multicut Problems in Almost-Planar Graphs: The Dependency of Complexity\n  on the Demand Pattern","summary":"Given a graph $G$, a set $T$ of terminal vertices, and a demand graph $H$ on\n$T$, the \\textsc{Multicut} problem asks for a set of edges of minimum weight\nthat separates the pairs of terminals specified by the edges of $H$.\n  The \\textsc{Multicut} problem can be solved in polynomial time if the number\nof terminals and the genus of the graph is bounded (Colin de Verdi\\`ere\n[Algorithmica, 2017]).\n  Focke et al.~[SoCG 2024] characterized which special cases of Multicut are\nfixed-parameter tractable parameterized by the number of terminals on planar\ngraphs. Moreover, they precisely determined how the parameter genus influences\nthe complexity and presented partial results of this form for graphs that can\nbe made planar by the deletion of $\\pi$ edges. We complete the picture on how\nthis parameter $\\pi$ influences the complexity of different special cases and\nprecisely determine the influence of the crossing number.\n  Formally, let $\\mathcal{H}$ be any class of graphs (satisfying a mild closure\nproperty) and let Multicut$(\\mathcal{H})$ be the special case when the demand\ngraph $H$ is in $\\mathcal{H}$. Our fist main results is showing that if\n$\\mathcal{H}$ has the combinatorial property of having bounded distance to\nextended bicliques, then Multicut$(\\mathcal{H})$ on unweighted graphs is FPT\nparameterized by the number $t$ of terminals and $\\pi$. For the case when\n$\\mathcal{H}$ does not have this combinatorial property,\n  Focke et al.~[SoCG 2024] showed that $O(\\sqrt{t})$ is essentially the best\npossible exponent of the running time; together with our result, this gives a\ncomplete understanding of how the parameter $\\pi$ influences complexity on\nunweighted graphs.\n  Our second main result is giving an algorithm whose existence shows that that\nthe parameter crossing number behaves analogously if we consider weighted\ngraphs.","main_category":"cs.CC","categories":"cs.CC","published":"2025-04-30T13:26:46Z"}
{"aid":"http://arxiv.org/abs/2504.21632v1","title":"Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of\n  Binary Classification","summary":"To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation~(DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost.","main_category":"cs.IT","categories":"cs.IT,eess.IV,math.IT","published":"2025-04-30T13:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.21642v1","title":"Element-wise description of the $\\mathcal I$-characterized subgroups of\n  the circle","summary":"According to Cartan, given an ideal $\\mathcal I$ of $\\mathbb N$, a sequence\n$(x_n)_{n\\in\\mathbb N}$ in the circle group $\\mathbb T$ is said to {\\em\n$\\mathcal I$-converge} to a point $x\\in \\mathbb T$ if $\\{n\\in \\mathbb N: x_n\n\\not \\in U\\}\\in \\mathcal I$ for every neighborhood $U$ of $x$ in $\\mathbb T$.\nFor a sequence $\\mathbf u=(u_n)_{n\\in\\mathbb N}$ in $\\mathbb Z$, let\n$$t_{\\mathbf u}^\\mathcal I(\\mathbb T) :=\\{x\\in \\mathbb T: u_nx \\\n\\text{$\\mathcal I$-converges to}\\ 0 \\}.$$ This set is a Borel (hence,\nPolishable) subgroup of $\\mathbb T$ with many nice properties, largely studied\nin the case when $\\mathcal I = \\mathcal F in$ is the ideal of all finite\nsubsets of $\\mathbb N$ (so $\\mathcal F in$-convergence coincides with the usual\none) for its remarkable connection to topological algebra, descriptive set\ntheory and harmonic analysis. We give a complete element-wise description of\n$t_{\\mathbf u}^\\mathcal I(\\mathbb T)$ when $u_n\\mid u_{n+1}$ for every\n$n\\in\\mathbb N$ and under suitable hypotheses on $\\mathcal I$. In the special\ncase when $\\mathcal I =\\mathcal F in$, we obtain an alternative proof of a\nsimplified version of a known result.","main_category":"math.GN","categories":"math.GN,math.GR","published":"2025-04-30T13:46:01Z"}
{"aid":"http://arxiv.org/abs/2504.21648v1","title":"Moment estimates for solutions of SPDEs with Lvy colored noise","summary":"In this article, we continue the investigations initiated by the first author\nin Balan (2015) related to the study of stochastic partial differential\nequations (SPDEs) with L\\'evy colored noise on $\\mathbb{R}_{+} \\times\n\\mathbb{R}^d$. This noise is constructed from a L\\'evy white noise (which is in\nturn built from a Poisson random measure with intensity $dtdx \\nu(dz)$), using\nthe convolution with a suitable spatial kernel $\\kappa$. We assume that the\nL\\'evy measure $\\nu$ has finite variance. Therefore, the stochastic integral\nwith respect to this noise is constructed similarly to the integral with\nrespect to the spatially-homogeneous Gaussian case considered in Dalang (1999).\nUsing Rosenthal's inequality, we provide an upper bound for the $p$-th moment\nof the stochastic integral with respect to the L\\'evy colored noise, which\nallows us to identify sufficient conditions for the solution of an SPDE driven\nby this noise to have higher order moments. We first analyze this question for\nthe linear SPDE, considering as examples the stochastic heat and wave equations\nin any dimension $d$, for three examples of kernels $\\kappa$: the heat kernel,\nthe Riesz kernel, and the Bessel kernel. Then, we present a general theory for\na non-linear SPDE with Lipschitz coefficients, and perform a detailed analysis\nin the case of the heat equation (in dimension $d\\geq 1$), and wave equation\n(in dimension $d\\leq 3$), for the same kernels $\\kappa$. We show that the\nsolution of each of these equations has a finite upper Lyapounov exponent of\norder $p\\geq 2$, and in some cases, is weakly intermittent (in the sense of\nFoondun and Khoshnevisan, 2013). In the case of the parabolic/hyperbolic\nAnderson model with L\\'evy colored noise, we provide the Poisson chaos\nexpansion of the solution and the explicit form of the second-order Lyapounov\nexponent.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T13:52:09Z"}
{"aid":"http://arxiv.org/abs/2504.21649v1","title":"Spatio-temporal entanglement of the vacuum","summary":"We demonstrate that the future and left Rindler wedges of Minkowski spacetime\nare entangled, leading to the Unruh effect. Similarly, the past and right\nRindler wedges are also entangled. We propose a protocol to extract this\nentanglement using two two-state detectors located in the past and right\nRindler wedges. By scaling the detector transition frequencies inversely with\nMinkowski time, entanglement from the quantum field is transferred to the\ndetectors, suggesting they may support quantum teleportation via the vacuum.\nOur protocol can be implemented with current quantum systems, such as\nflux-tunable transmon qubits. This research provides new insights into the\nentanglement properties of spacetime and hints at practical applications for\nsecure quantum information transfer using the vacuum state of a quantum field.","main_category":"gr-qc","categories":"gr-qc,quant-ph","published":"2025-04-30T13:54:35Z"}
{"aid":"http://arxiv.org/abs/2504.21663v1","title":"Reducing Weighted Ensemble Variance With Optimal Trajectory Management","summary":"Weighted ensemble (WE) is an enhanced path-sampling method that is\nconceptually simple, widely applicable, and statistically exact. In a WE\nsimulation, an ensemble of trajectories is periodically pruned or replicated to\nenhance sampling of rare transitions and improve estimation of mean first\npassage times (MFPTs). However, poor choices of the parameters governing\npruning and replication can lead to high-variance MFPT estimates. Our previous\nwork [J. Chem. Phys. 158, 014108 (2023)] presented an optimal WE\nparameterization strategy and applied it in low-dimensional example systems.\nThe strategy harnesses estimated local MFPTs from different initial\nconfigurations to a single target state. In the present work, we apply the\noptimal parameterization strategy to more challenging, high-dimensional\nmolecular models, namely, synthetic molecular dynamics (MD) models of Trp-cage\nfolding and unfolding, as well as atomistic MD models of NTL9 folding in\nhigh-friction and low-friction continuum solvents. In each system we use WE to\nestimate the MFPT for folding or unfolding events. We show that the optimal\nparameterization reduces the variance of MFPT estimates in three of four\nsystems, with dramatic improvement in the most challenging atomistic system.\nOverall, the parameterization strategy improves the accuracy and reliability of\nWE estimates for the kinetics of biophysical processes.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.comp-ph","published":"2025-04-30T14:03:58Z"}
{"aid":"http://arxiv.org/abs/2504.21674v1","title":"Complexities of Well-Quasi-Ordered Substructural Logics","summary":"Substructural logics are formal logical systems that omit familiar structural\nrules of classical and intuitionistic logic such as contraction, weakening,\nexchange (commutativity), and associativity. This leads to a resource-sensitive\nlogical framework that has proven influential beyond mathematical logic and its\nalgebraic semantics, across theoretical computer science, linguistics, and\nphilosophical logic. The set of theorems of a substructural logic is\nrecursively enumerable and, in many cases, recursive. These logics also possess\nan intricate mathematical structure that has been the subject of research for\nover six decades.\n  We undertake a comprehensive study of substructural logics possessing an\nunderlying well-quasi-order (wqo), using established ordinal-indexed\nfast-growing complexity classes to classify the complexity of their\ndeducibility (quasiequational) and provability (equational) problems. This\nincludes substructural logics with weak variants of contraction and weakening,\nand logics with weak or even no exchange. We further consider infinitely many\naxiomatic extensions over the base systems.\n  We establish a host of decidability and complexity bounds, many of them\ntight, by developing new techniques in proof theory, well-quasi-order theory\n(contributing new length theorems), the algebraic semantics of substructural\nlogics via residuated lattices, algebraic proof theory, and novel encodings of\ncounter machines. Classifying the computational complexity of substructural\nlogics (and the complexity of the word problem and of the equational theory of\ntheir algebraic semantics) reveals how subtle variations in their design\ninfluence their algorithmic behavior, with the decision problems often reaching\nAckermannian or even hyper-Ackermannian complexity.","main_category":"cs.LO","categories":"cs.LO,cs.CC,math.LO","published":"2025-04-30T14:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.21679v1","title":"Canonicalization for Unreproducible Builds in Java","summary":"The increasing complexity of software supply chains and the rise of supply\nchain attacks have elevated concerns around software integrity. Users and\nstakeholders face significant challenges in validating that a given software\nartifact corresponds to its declared source. Reproducible Builds address this\nchallenge by ensuring that independently performed builds from identical source\ncode produce identical binaries. However, achieving reproducibility at scale\nremains difficult, especially in Java, due to a range of non-deterministic\nfactors and caveats in the build process. In this work, we focus on\nreproducibility in Java-based software, archetypal of enterprise applications.\nWe introduce a conceptual framework for reproducible builds, we analyze a large\ndataset from Reproducible Central, and we develop a novel taxonomy of six root\ncauses of unreproducibility. We study actionable mitigations: artifact and\nbytecode canonicalization using OSS-Rebuild and jNorm respectively. Finally, we\npresent Chains-Rebuild, a tool that raises reproducibility success from 9.48%\nto 26.89% on 12,283 unreproducible artifacts. To sum up, our contributions are\nthe first large-scale taxonomy of build unreproducibility causes in Java, a\npublicly available dataset of unreproducible builds, and Chains-Rebuild, a\ncanonicalization tool for mitigating unreproducible builds in Java.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-30T14:17:54Z"}
{"aid":"http://arxiv.org/abs/2504.21680v1","title":"Hoist with His Own Petard: Inducing Guardrails to Facilitate\n  Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs","summary":"Retrieval-Augmented Generation (RAG) integrates Large Language Models (LLMs)\nwith external knowledge bases, improving output quality while introducing new\nsecurity risks. Existing studies on RAG vulnerabilities typically focus on\nexploiting the retrieval mechanism to inject erroneous knowledge or malicious\ntexts, inducing incorrect outputs. However, these approaches overlook critical\nweaknesses within LLMs, leaving important attack vectors unexplored and\nlimiting the scope and efficiency of attacks. In this paper, we uncover a novel\nvulnerability: the safety guardrails of LLMs, while designed for protection,\ncan also be exploited as an attack vector by adversaries. Building on this\nvulnerability, we propose MutedRAG, a novel denial-of-service attack that\nreversely leverages the guardrails of LLMs to undermine the availability of RAG\nsystems. By injecting minimalistic jailbreak texts, such as \"\\textit{How to\nbuild a bomb}\", into the knowledge base, MutedRAG intentionally triggers the\nLLM's safety guardrails, causing the system to reject legitimate queries.\nBesides, due to the high sensitivity of guardrails, a single jailbreak sample\ncan affect multiple queries, effectively amplifying the efficiency of attacks\nwhile reducing their costs. Experimental results on three datasets demonstrate\nthat MutedRAG achieves an attack success rate exceeding 60% in many scenarios,\nrequiring only less than one malicious text to each target query on average. In\naddition, we evaluate potential defense strategies against MutedRAG, finding\nthat some of current mechanisms are insufficient to mitigate this threat,\nunderscoring the urgent need for more robust solutions.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-30T14:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.21687v1","title":"Heterogeneously error-corrected QRAMs","summary":"Quantum Random Access Memories (QRAM) could prove essential for scalable\nquantum computing, for everything from accessing classical databases for\nunordered search to creating arbitrary superpositions of states. However, like\nmost applications of quantum computing, QRAMs suffer from qubit error and\ndecoherence. Quantum Error Correction (QEC) provides a potential solution, but\nunfortunately, most QEC proposals that uniformly correct all qubits of the QRAM\nincur major overheads, making the QRAM infeasible. In this work, we propose a\nsurface code error-corrected QRAM made of heterogeneous code distance logical\nqubits. Our QRAM can produce higher fidelity queries, while keeping qubit\noverheads smaller than the uniformly error-corrected QRAMs. Comparisons between\nour novel QRAM architectures and a uniformly error corrected baseline are\npresented, showing that our designs can achieve up to polylogarithmic reduction\nin query infidelity, producing constant query infidelity scaling, while\nsimultaneously reducing qubit overhead.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T14:23:42Z"}
{"aid":"http://arxiv.org/abs/2504.21690v1","title":"Combinatorial twists in gl_n Yangians","summary":"We introduce the special set-theoretic Yang-Baxter algebra and show that it\nis a Hopf algebra. The associated universal R-matrix is also obtained via an\nadmissible Drinfel'd twist, making the algebra a quasi-triangular Hopf algebra.\nThe fundamental representation of the universal R-matrix yields the familiar\nset-theoretic (combinatorial) solutions of the Yang-Baxter equation. We then\napply the same Drinfel'd twist to the gl_n Yangian after introducing the\naugmented Yangian. We show that the augmented Yangian is also a Hopf algebra\nand we obtain the twisted version of the augmented gl_n Yangian as well as the\ntwisted R-matrix.","main_category":"math.QA","categories":"math.QA,math-ph,math.MP","published":"2025-04-30T14:25:33Z"}
{"aid":"http://arxiv.org/abs/2504.21699v1","title":"REHEARSE-3D: A Multi-modal Emulated Rain Dataset for 3D Point Cloud\n  De-raining","summary":"Sensor degradation poses a significant challenge in autonomous driving.\nDuring heavy rainfall, the interference from raindrops can adversely affect the\nquality of LiDAR point clouds, resulting in, for instance, inaccurate point\nmeasurements. This, in turn, can potentially lead to safety concerns if\nautonomous driving systems are not weather-aware, i.e., if they are unable to\ndiscern such changes. In this study, we release a new, large-scale, multi-modal\nemulated rain dataset, REHEARSE-3D, to promote research advancements in 3D\npoint cloud de-raining. Distinct from the most relevant competitors, our\ndataset is unique in several respects. First, it is the largest point-wise\nannotated dataset, and second, it is the only one with high-resolution LiDAR\ndata (LiDAR-256) enriched with 4D Radar point clouds logged in both daytime and\nnighttime conditions in a controlled weather environment. Furthermore,\nREHEARSE-3D involves rain-characteristic information, which is of significant\nvalue not only for sensor noise modeling but also for analyzing the impact of\nweather at a point level. Leveraging REHEARSE-3D, we benchmark raindrop\ndetection and removal in fused LiDAR and 4D Radar point clouds. Our\ncomprehensive study further evaluates the performance of various statistical\nand deep-learning models. Upon publication, the dataset and benchmark models\nwill be made publicly available at: https://sporsho.github.io/REHEARSE3D.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-30T14:43:38Z"}
{"aid":"http://arxiv.org/abs/2504.21701v1","title":"Leptogenesis, $0$ and lepton flavor violation in modular\n  left-right asymmetric model with polyharmonic $Maa$ forms","summary":"In the absence of supersymmetry, modular forms need not be holomorphic\nfunctions of the modulus $\\tau$. Using this idea, we construct a\nnon-supersymmetric framework using polyharmonic $Maa\\beta$ forms. In this\napproach, the Yukawa coupling is no longer strictly holomorphic in $\\tau$ but\ninstead incorporates both holomorphic and non-holomorphic components. We\nrealize a non-supersymmetric, left-right asymmetric model based on the\n$\\Gamma_3$ modular group, where the active neutrino masses are generated via an\nextended inverse seesaw mechanism. The model successfully predicts the sum of\nneutrino masses below the current experimental bound and accommodates neutrino\nmixing angles within the $3\\sigma$ range. Given its strong predictive power in\nneutrino oscillation parameters, we further explore its implications for beyond\nStandard Model (BSM) phenomena, including neutrinoless double beta\n($0\\nu\\beta\\beta$) decay, lepton flavor violation (LFV), and baryogenesis via\nleptogenesis (BAU). Our findings indicate that the model predicts an effective\nMajorana mass and LFV branching ratios consistent with experimental constraints\nwhile also providing a viable explanation for the observed baryon asymmetry\nthrough resonant leptogenesis.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-30T14:44:56Z"}
{"aid":"http://arxiv.org/abs/2504.21704v1","title":"Bounds in Sequential Unambiguous Discrimination of Multiple Pure Quantum\n  States","summary":"Sequential methods for quantum hypothesis testing offer significant\nadvantages over fixed-length approaches, which rely on a predefined number of\nstate copies. Despite their potential, these methods remain underexplored for\nunambiguous discrimination. In this work, we derive performance bounds for such\nmethods when applied to the discrimination of a set of pure states. The\nperformance is evaluated based on the expected number of copies required. We\nestablish a lower bound applicable to any sequential method and an upper bound\non the optimal sequential method. The upper bound is derived using a novel and\nsimple non-adaptive method. Importantly, the gap between these bounds is\nminimal, scaling logarithmically with the number of distinct states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T14:46:04Z"}
{"aid":"http://arxiv.org/abs/2504.21716v1","title":"LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in\n  Household Robotics","summary":"We present an embodied robotic system with an LLM-driven agent-orchestration\narchitecture for autonomous household object management. The system integrates\nmemory-augmented task planning, enabling robots to execute high-level user\ncommands while tracking past actions. It employs three specialized agents: a\nrouting agent, a task planning agent, and a knowledge base agent, each powered\nby task-specific LLMs. By leveraging in-context learning, our system avoids the\nneed for explicit model training. RAG enables the system to retrieve context\nfrom past interactions, enhancing long-term object tracking. A combination of\nGrounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating\nsemantic scene understanding for task planning. Evaluation across three\nhousehold scenarios demonstrates high task planning accuracy and an improvement\nin memory recall due to RAG. Specifically, Qwen2.5 yields best performance for\nspecialized agents, while LLaMA3.1 excels in routing tasks. The source code is\navailable at: https://github.com/marc1198/chat-hsr.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CL","published":"2025-04-30T15:00:20Z"}
{"aid":"http://arxiv.org/abs/2504.21720v1","title":"Modelling JWST mid-infrared counts II: Extension to 5.6 m, optical,\n  radio and X-rays","summary":"In Paper I (Rowan-Robinson 2024), models derived in 2009 to fit mid-infrared\n(8-24 micron) source counts from the IRAS, ISO and Spitzer missions, were found\nto provide an excellent fit to deep counts at 7.7-21 mu with JWST,\ndemonstrating that the evolution of dusty star-forming galaxies is well\nunderstood. Here the treatment of optical spectral energy distributions (SEDs)\nis improved and the counts are extended to 5.6 mu and optical wavelengths. The\nmodels proved a good fit to the latest, deeper, JWST counts. The models are\nalso extended to radio and X-ray wavelengths. Predicted redshift distributions\nare given for a range of wavelengths and flux-densities.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-30T15:06:07Z"}
{"aid":"http://arxiv.org/abs/2504.21727v1","title":"Steering reaction flux by coupling product channels","summary":"We demonstrate a method for controlling the outcome of an ultracold chemical\nfew-body reaction by redirecting a tunable fraction of reaction flux from one\nselected product channel to another one. In the reaction, three ultracold atoms\ncollide to form a diatomic molecule. This product molecule can be produced in\nvarious internal states, characterizing the different product channels of the\nreaction. Our scheme relies on the coupling between two such product channels\nat an avoided molecular energy level crossing in the presence of an external\nmagnetic field. The degree of coupling can be set by the magnetic field\nstrength and allows for a widely tunable flux control between the two channels.\nThis scheme is quite general and also holds great promise for a large variety\nof chemical processes with diverse species, since molecular energy level\ncrossings are ubiquitous in molecular systems and are often easily accessible\nby standard laboratory equipment.","main_category":"physics.atom-ph","categories":"physics.atom-ph,cond-mat.quant-gas,physics.chem-ph","published":"2025-04-30T15:19:08Z"}
{"aid":"http://arxiv.org/abs/2504.21733v1","title":"The role of terminal groups in non-chiral rod-like compounds on the\n  formation of polar fluids","summary":"The emergence of ferroelectric mesophases in non-chiral liquid crystal (LCs)\nhas sparked fundamental interest in the molecular mechanisms governing\npolarity. In this study, we investigate how terminal molecular groups influence\nthe formation and stability of polar phases by analyzing six compounds from\nthree homologous series. Specifically, we compare newly synthesized homologs\nwith a nitro group, which predominantly exhibit polar mesophases, to previously\nreported structurally related analogs containing either a cyano group or a\nfluorine atom as terminal fragment. Density Functional Theory (DFT)\ncalculations provide insights into electronic surface potential (ESP)\ndistributions, revealing alternating regions of positive and negative charge\ndensity along the molecular axis, consistent with Madhusudana model of polar\nphase stabilization. We propose the ESP-derived parameter quantifying terminal\nelectrostatic charge, revealing a direct correlation between the negative to\npositive charge ratio at the molecular termini and the formation of\nferroelectric or antiferroelectric mesophases. To validate this hypothesis, we\nanalyze the molecular structure-mesomorphic behavior relationship of other\nknown non-chiral compounds that exhibit polar phases, demonstrating the\ncritical role of terminal groups in determining mesophase polarity. Our\nfindings enhance the understanding of the molecular origins of ferroelectricity\nin non-chiral LCs, paving the way for the rational design of next-generation\nfunctional polar soft materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-30T15:22:39Z"}
{"aid":"http://arxiv.org/abs/2504.21735v1","title":"TheraQuest: A Gamified, LLM-Powered Simulation for Massage Therapy\n  Training","summary":"Massage therapy training emphasizes hands-on techniques and effective\ntherapist--patient communication. However, many educational programs struggle\nto provide realistic practice scenarios. To address this problem, we propose\nTheraQuest, a gamified, web-based simulation platform that employs large\nlanguage models (LLMs) to generate diverse virtual patients with varying\nsymptoms and cultural backgrounds. Through interactive dialogue, anatomical\ndecision-making, and immediate assessment, trainees develop both diagnostic\nreasoning and empathetic communication skills in a low-risk environment. Unlike\nexclusively VR-based solutions, TheraQuest remains accessible via standard web\nbrowsers, mitigating the cost and discomfort associated with extended headset\nuse. Preliminary testing suggests that integrating LLM-driven virtual patients\nwith real-time skill metrics can enhance trainee engagement and help bridge the\ngap between theoretical knowledge and clinical proficiency.","main_category":"cs.GT","categories":"cs.GT,cs.HC","published":"2025-04-30T15:31:52Z"}
{"aid":"http://arxiv.org/abs/2504.21744v1","title":"Jet Modification and Medium Response -- Theory Overview","summary":"This text contains a summary and personal perspective on the current status\nand challenges of jet quenching physics as portrayed by the presentations\ndelivered at the 12th International Conference on Hard and Electromagnetic\nProbes of High-Energy Nuclear Collisions (Hard Probes 2024) which took place in\nSeptember 2024 in Nagasaki, Japan.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-30T15:39:15Z"}
{"aid":"http://arxiv.org/abs/2504.21752v1","title":"VDDP: Verifiable Distributed Differential Privacy under the\n  Client-Server-Verifier Setup","summary":"Despite differential privacy (DP) often being considered the de facto\nstandard for data privacy, its realization is vulnerable to unfaithful\nexecution of its mechanisms by servers, especially in distributed settings.\nSpecifically, servers may sample noise from incorrect distributions or generate\ncorrelated noise while appearing to follow established protocols. This work\nanalyzes these malicious behaviors in a general differential privacy framework\nwithin a distributed client-server-verifier setup. To address these adversarial\nproblems, we propose a novel definition called Verifiable Distributed\nDifferential Privacy (VDDP) by incorporating additional verification\nmechanisms. We also explore the relationship between zero-knowledge proofs\n(ZKP) and DP, demonstrating that while ZKPs are sufficient for achieving DP\nunder verifiability requirements, they are not necessary. Furthermore, we\ndevelop two novel and efficient mechanisms that satisfy VDDP: (1) the\nVerifiable Distributed Discrete Laplacian Mechanism (VDDLM), which offers up to\na $4 \\times 10^5$x improvement in proof generation efficiency with only\n0.1-0.2x error compared to the previous state-of-the-art verifiable\ndifferentially private mechanism; (2) an improved solution to Verifiable\nRandomized Response (VRR) under local DP, a special case of VDDP, achieving up\na reduction of up to 5000x in communication costs and the verifier's overhead.","main_category":"cs.CR","categories":"cs.CR,cs.DB","published":"2025-04-30T15:46:55Z"}
{"aid":"http://arxiv.org/abs/2504.21767v1","title":"Whleaper: A 10-DOF Flexible Bipedal Wheeled Robot","summary":"Wheel-legged robots combine the advantages of both wheeled robots and legged\nrobots, offering versatile locomotion capabilities with excellent stability on\nchallenging terrains and high efficiency on flat surfaces. However, existing\nwheel-legged robots typically have limited hip joint mobility compared to\nhumans, while hip joint plays a crucial role in locomotion. In this paper, we\nintroduce Whleaper, a novel 10-degree-of-freedom (DOF) bipedal wheeled robot,\nwith 3 DOFs at the hip of each leg. Its humanoid joint design enables adaptable\nmotion in complex scenarios, ensuring stability and flexibility. This paper\nintroduces the details of Whleaper, with a focus on innovative mechanical\ndesign, control algorithms and system implementation. Firstly, stability stems\nfrom the increased DOFs at the hip, which expand the range of possible postures\nand improve the robot's foot-ground contact. Secondly, the extra DOFs also\naugment its mobility. During walking or sliding, more complex movements can be\nadopted to execute obstacle avoidance tasks. Thirdly, we utilize two control\nalgorithms to implement multimodal motion for walking and sliding. By\ncontrolling specific DOFs of the robot, we conducted a series of simulations\nand practical experiments, demonstrating that a high-DOF hip joint design can\neffectively enhance the stability and flexibility of wheel-legged robots.\nWhleaper shows its capability to perform actions such as squatting, obstacle\navoidance sliding, and rapid turning in real-world scenarios.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T16:07:44Z"}
{"aid":"http://arxiv.org/abs/2504.21794v1","title":"Vortex flow anisotropy in nematic superconductors","summary":"We investigate the vortex flow anisotropy in the mixed state of nematic\nsuperconductors, focusing on the effects of nematic-superconducting coupling on\nvortex dynamics. Using numerical simulations within a time-dependent\nGinzburg-Landau (TDGL) approach, we analyze vortex viscosity in a model\nfeaturing an s-wave superconducting order parameter coupled to an Ising-like\nnematic order parameter, suitable for systems with $C_4$ symmetry. Our results\nindicate that nematicity induces a significant anisotropy in the flux-flow\nresistivity, which depends on both vortex core shape anisotropy and\nnormal-phase conductivity anisotropy. These two effects can either compete or\ncooperate with each other. We discuss the implications of these findings for\nidentifying nematic superconductivity in the superconducting phase. Our work\nprovides new insights into the interplay between nematic and superconducting\norder parameters, leading to new possibilities for experimental and theoretical\nexploration of anisotropic transport properties in unconventional\nsuperconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-30T16:51:09Z"}
{"aid":"http://arxiv.org/abs/2504.21800v1","title":"How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in\n  Prolonged Exposure Dialogues","summary":"The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. In our dataset, synthetic dialogues match structural\nfeatures of real-world dialogues (e.g., speaker switch ratio: 0.98 vs. 0.99),\nhowever, synthetic interactions do not adequately reflect key fidelity markers\n(e.g., distress monitoring). We highlight gaps in existing evaluation\nframeworks and advocate for fidelity-aware metrics that go beyond surface\nfluency to uncover clinically significant failures. Our findings clarify where\nsynthetic data can effectively complement real-world datasets -- and where\ncritical limitations remain.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.HC","published":"2025-04-30T16:56:56Z"}
{"aid":"http://arxiv.org/abs/2504.21811v1","title":"Coarse Baum-Connes and warped cones: failure of surjectivity in odd\n  degree","summary":"We prove a conjecture of Roe by constructing unified warped cones that\nviolate the coarse Baum-Connes conjecture. Interestingly, the reason for this\nis probably not what Roe expected, as the obstruction arises in odd rather than\neven degree.","main_category":"math.KT","categories":"math.KT,math.MG,math.OA","published":"2025-04-30T17:15:20Z"}
{"aid":"http://arxiv.org/abs/2504.21815v1","title":"From Aesthetics to Human Preferences: Comparative Perspectives of\n  Evaluating Text-to-Music Systems","summary":"Evaluating generative models remains a fundamental challenge, particularly\nwhen the goal is to reflect human preferences. In this paper, we use music\ngeneration as a case study to investigate the gap between automatic evaluation\nmetrics and human preferences. We conduct comparative experiments across five\nstate-of-the-art music generation approaches, assessing both perceptual quality\nand distributional similarity to human-composed music. Specifically, we\nevaluate synthesis music from various perceptual dimensions and examine\nreference-based metrics such as Mauve Audio Divergence (MAD) and Kernel Audio\nDistance (KAD). Our findings reveal significant inconsistencies across the\ndifferent metrics, highlighting the limitation of the current evaluation\npractice. To support further research, we release a benchmark dataset\ncomprising samples from multiple models. This study provides a broader\nperspective on the alignment of human preference in generative modeling,\nadvocating for more human-centered evaluation strategies across domains.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-30T17:21:04Z"}
{"aid":"http://arxiv.org/abs/2504.21824v1","title":"A simple range characterization for spherical mean transform in even\n  dimensions","summary":"The paper presents a new and simple range characterization for the spherical\nmean transform of functions supported in the unit ball in even dimensions. It\ncomplements the previous work of the same authors, where they solved an\nanalogous problem in odd dimensions. The range description in even dimensions\nconsists of symmetry relations, using a special kind of elliptic integrals\ninvolving the coefficients of the spherical harmonics expansion of the function\nin the range of the transform. The article also introduces a pair of original\nidentities involving normalized Bessel functions of the first and the second\nkind. The first result is an integral cross-product identity for Bessel\nfunctions of integer order, complementing a similar relation for Bessel\nfunctions of half-integer order obtained in the aforementioned work of the same\nauthors. The second result is a new Nicholson-type identity. Both of these\nrelations can be considered as important standalone results in the theory of\nspecial functions. Finally, as part of the proof of one of the theorems, the\nauthors derive an interesting equality involving elliptic integrals, which may\nbe of independent interest.","main_category":"math.CA","categories":"math.CA,math-ph,math.FA,math.MP","published":"2025-04-30T17:27:23Z"}
{"aid":"http://arxiv.org/abs/2504.21835v1","title":"Patch bubbles for advection-dominated problems","summary":"A novel variant of the \\emph{residual-free bubble} method (RFB) for advection\ndominated problems is presented. Since the usual RFB still suffers from\noscillations and strong under/overshoots, the bubble space is enriched by\n\\emph{patch bubbles}, giving more freedom to the bubble space.\n  We use a recursive and efficient approach to accurately compute the bubbles.\nNumerical experiments clearly demonstrate the superiority of our method\ncompared to the standard RFB.\n  The method is similar to the \\emph{enhanced residual-free bubble} method\n(eRFB) proposed by Cangiani and S\\\"uli in 2005, but differs in the definition\nof the additional bubbles.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-30T17:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.21838v1","title":"Learning Universal User Representations Leveraging Cross-domain User\n  Intent at Snapchat","summary":"The development of powerful user representations is a key factor in the\nsuccess of recommender systems (RecSys). Online platforms employ a range of\nRecSys techniques to personalize user experience across diverse in-app\nsurfaces. User representations are often learned individually through user's\nhistorical interactions within each surface and user representations across\ndifferent surfaces can be shared post-hoc as auxiliary features or additional\nretrieval sources. While effective, such schemes cannot directly encode\ncollaborative filtering signals across different surfaces, hindering its\ncapacity to discover complex relationships between user behaviors and\npreferences across the whole platform. To bridge this gap at Snapchat, we seek\nto conduct universal user modeling (UUM) across different in-app surfaces,\nlearning general-purpose user representations which encode behaviors across\nsurfaces. Instead of replacing domain-specific representations, UUM\nrepresentations capture cross-domain trends, enriching existing representations\nwith complementary information. This work discusses our efforts in developing\ninitial UUM versions, practical challenges, technical choices and modeling and\nresearch directions with promising offline performance. Following successful\nA/B testing, UUM representations have been launched in production, powering\nmultiple use cases and demonstrating their value. UUM embedding has been\nincorporated into (i) Long-form Video embedding-based retrieval, leading to\n2.78% increase in Long-form Video Open Rate, (ii) Long-form Video L2 ranking,\nwith 19.2% increase in Long-form Video View Time sum, (iii) Lens L2 ranking,\nleading to 1.76% increase in Lens play time, and (iv) Notification L2 ranking,\nwith 0.87% increase in Notification Open Rate.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-30T17:48:43Z"}
{"aid":"http://arxiv.org/abs/2504.21840v1","title":"Parameter Inference of Black Hole Images using Deep Learning in\n  Visibility Space","summary":"Using very long baseline interferometry, the Event Horizon Telescope (EHT)\ncollaboration has resolved the shadows of two supermassive black holes. Model\ncomparison is traditionally performed in image space, where imaging algorithms\nintroduce uncertainties in the recovered structure. Here, we develop a deep\nlearning framework to perform parameter inference in visibility space, directly\nusing the data measured by the interferometer without introducing potential\nerrors and biases from image reconstruction. First, we train and validate our\nframework on synthetic data derived from general relativistic\nmagnetohydrodynamics (GRMHD) simulations that vary in magnetic field state,\nspin, and $R_\\mathrm{high}$. Applying these models to the real data obtained\nduring the 2017 EHT campaign, and only considering total intensity, we do not\nderive meaningful constraints on either of these parameters. At present, our\nmethod is limited both by theoretical uncertainties in the GRMHD simulations\nand variation between snapshots of the same underlying physical model. However,\nwe demonstrate that spin and $R_\\mathrm{high}$ could be recovered using this\nframework through continuous monitoring of our sources, which mitigates\nvariations due to turbulence. In future work, we anticipate that including\nspectral or polarimetric information will greatly improve the performance of\nthis framework.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-30T17:50:47Z"}
{"aid":"http://arxiv.org/abs/2504.21852v1","title":"Polka-dotted Stars: a Hierarchical Model for Mapping Stellar Surfaces\n  Using Occultation Light Curves and the Case of TOI-3884","summary":"We present StarryStarryProcess, a novel hierarchical Bayesian framework for\nmapping stellar surfaces using exoplanet transit light curves. While previous\nmethods relied solely on stellar rotational light curves--which contain limited\ninformation about spot properties -- our approach leverages planetary transits\nas probes of stellar surfaces. When a planet crosses a spot during transit, it\ncreates a distinctive change in the light curve that directly reveals spot\nproperties. Our model integrates planetary transit modeling with stellar\nvariability analysis by combining the spherical harmonic surface map\nrepresentation from starry, the probabilistic approach to spot properties of\nStarryProcess, and a comprehensive transit model that accounts for\nspot-crossing events during transits. We demonstrate through synthetic data\nexperiments that our model successfully recovers spot distributions, stellar\norientation, and spot physical properties. We extend the framework to handle\nevolving stellar surfaces through time-dependent modeling. Applying our method\nto TESS observations of TOI-3884, we find evidence for high-latitude spot\nconcentrations and significant spin-orbit misalignment. The transit-based\napproach overcomes fundamental limitations of previous models by providing\nconstraints on spot properties that would remain hidden in the null space of\nrotational light curves alone. This methodology enables more accurate exoplanet\ncharacterization by disentangling stellar activity due to starspots from\nplanetary signals while simultaneously providing insights into stellar magnetic\nactivity patterns. The whole paper is reproducible, and can be found by\nclicking the GitHub icon.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,astro-ph.SR","published":"2025-04-30T17:58:54Z"}
{"aid":"http://arxiv.org/abs/2505.00257v1","title":"Graph Privacy: A Heterogeneous Federated GNN for Trans-Border Financial\n  Data Circulation","summary":"The sharing of external data has become a strong demand of financial\ninstitutions, but the privacy issue has led to the difficulty of\ninterconnecting different platforms and the low degree of data openness. To\neffectively solve the privacy problem of financial data in trans-border flow\nand sharing, to ensure that the data is available but not visible, to realize\nthe joint portrait of all kinds of heterogeneous data of business organizations\nin different industries, we propose a Heterogeneous Federated Graph Neural\nNetwork (HFGNN) approach. In this method, the distribution of heterogeneous\nbusiness data of trans-border organizations is taken as subgraphs, and the\nsharing and circulation process among subgraphs is constructed as a\nstatistically heterogeneous global graph through a central server. Each\nsubgraph learns the corresponding personalized service model through local\ntraining to select and update the relevant subset of subgraphs with aggregated\nparameters, and effectively separates and combines topological and feature\ninformation among subgraphs. Finally, our simulation experimental results show\nthat the proposed method has higher accuracy performance and faster convergence\nspeed than existing methods.","main_category":"cs.LG","categories":"cs.LG,cs.CR","published":"2025-05-01T02:47:43Z"}
{"aid":"http://arxiv.org/abs/2505.00263v1","title":"EnronQA: Towards Personalized RAG over Private Documents","summary":"Retrieval Augmented Generation (RAG) has become one of the most popular\nmethods for bringing knowledge-intensive context to large language models (LLM)\nbecause of its ability to bring local context at inference time without the\ncost or data leakage risks associated with fine-tuning. A clear separation of\nprivate information from the LLM training has made RAG the basis for many\nenterprise LLM workloads as it allows the company to augment LLM's\nunderstanding using customers' private documents. Despite its popularity for\nprivate documents in enterprise deployments, current RAG benchmarks for\nvalidating and optimizing RAG pipelines draw their corpora from public data\nsuch as Wikipedia or generic web pages and offer little to no personal context.\nSeeking to empower more personal and private RAG we release the EnronQA\nbenchmark, a dataset of 103,638 emails with 528,304 question-answer pairs\nacross 150 different user inboxes. EnronQA enables better benchmarking of RAG\npipelines over private data and allows for experimentation on the introduction\nof personalized retrieval settings over realistic data. Finally, we use EnronQA\nto explore the tradeoff in memorization and retrieval when reasoning over\nprivate documents.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-05-01T03:07:30Z"}
{"aid":"http://arxiv.org/abs/2505.00282v1","title":"A Unifying Framework for Robust and Efficient Inference with\n  Unstructured Data","summary":"This paper presents a general framework for conducting efficient and robust\ninference on parameters derived from unstructured data, which include text,\nimages, audio, and video. Economists have long incorporated data extracted from\ntexts and images into their analyses, a practice that has accelerated with\nadvancements in deep neural networks. However, neural networks do not\ngenerically produce unbiased predictions, potentially propagating bias to\nestimators that use their outputs. To address this challenge, we reframe\ninference with unstructured data as a missing structured data problem, where\nstructured data are imputed from unstructured inputs using deep neural\nnetworks. This perspective allows us to apply classic results from\nsemiparametric inference, yielding valid, efficient, and robust estimators\nbased on unstructured data. We formalize this approach with MARS (Missing At\nRandom Structured Data), a unifying framework that integrates and extends\nexisting methods for debiased inference using machine learning predictions,\nlinking them to a variety of older, familiar problems such as causal inference.\nWe develop robust and efficient estimators for both descriptive and causal\nestimands and address challenges such as inference using aggregated and\ntransformed predictions from unstructured data. Importantly, MARS applies to\ncommon empirical settings that have received limited attention in the existing\nliterature. Finally, we reanalyze prominent studies that use unstructured data,\ndemonstrating the practical value of MARS.","main_category":"econ.EM","categories":"econ.EM,cs.LG","published":"2025-05-01T04:11:25Z"}
{"aid":"http://arxiv.org/abs/2505.00284v1","title":"LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous\n  Driving","summary":"Vision-Language Models (VLMs) have demonstrated significant potential for\nend-to-end autonomous driving. However, fully exploiting their capabilities for\nsafe and reliable vehicle control remains an open research challenge. To\nsystematically examine advances and limitations of VLMs in driving tasks, we\nintroduce LightEMMA, a Lightweight End-to-End Multimodal Model for Autonomous\ndriving. LightEMMA provides a unified, VLM-based autonomous driving framework\nwithout ad hoc customizations, enabling easy integration and evaluation of\nevolving state-of-the-art commercial and open-source models. We construct\ntwelve autonomous driving agents using various VLMs and evaluate their\nperformance on the nuScenes prediction task, comprehensively assessing metrics\nsuch as inference time, computational cost, and predictive accuracy.\nIllustrative examples highlight that, despite their strong scenario\ninterpretation capabilities, VLMs' practical performance in autonomous driving\ntasks remains concerning, emphasizing the need for further improvements. The\ncode is available at https://github.com/michigan-traffic-lab/LightEMMA.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-05-01T04:12:41Z"}
{"aid":"http://arxiv.org/abs/2505.00292v1","title":"Conformal changepoint localization","summary":"Changepoint localization is the problem of estimating the index at which a\nchange occurred in the data generating distribution of an ordered list of data,\nor declaring that no change occurred. We present the broadly applicable CONCH\n(CONformal CHangepoint localization) algorithm, which uses a matrix of\nconformal p-values to produce a confidence interval for a (single) changepoint\nunder the mild assumption that the pre-change and post-change distributions are\neach exchangeable. We exemplify the CONCH algorithm on a variety of synthetic\nand real-world datasets, including using black-box pre-trained classifiers to\ndetect changes in sequences of images or text.","main_category":"math.ST","categories":"math.ST,eess.SP,stat.ME,stat.TH","published":"2025-05-01T04:27:52Z"}
{"aid":"http://arxiv.org/abs/2505.00312v1","title":"AWARE-NET: Adaptive Weighted Averaging for Robust Ensemble Network in\n  Deepfake Detection","summary":"Deepfake detection has become increasingly important due to the rise of\nsynthetic media, which poses significant risks to digital identity and cyber\npresence for security and trust. While multiple approaches have improved\ndetection accuracy, challenges remain in achieving consistent performance\nacross diverse datasets and manipulation types. In response, we propose a novel\ntwo-tier ensemble framework for deepfake detection based on deep learning that\nhierarchically combines multiple instances of three state-of-the-art\narchitectures: Xception, Res2Net101, and EfficientNet-B7. Our framework employs\na unique approach where each architecture is instantiated three times with\ndifferent initializations to enhance model diversity, followed by a learnable\nweighting mechanism that dynamically combines their predictions. Unlike\ntraditional fixed-weight ensembles, our first-tier averages predictions within\neach architecture family to reduce model variance, while the second tier learns\noptimal contribution weights through backpropagation, automatically adjusting\neach architecture's influence based on their detection reliability. Our\nexperiments achieved state-of-the-art intra-dataset performance with AUC scores\nof 99.22% (FF++) and 100.00% (CelebDF-v2), and F1 scores of 98.06% (FF++) and\n99.94% (CelebDF-v2) without augmentation. With augmentation, we achieve AUC\nscores of 99.47% (FF++) and 100.00% (CelebDF-v2), and F1 scores of 98.43%\n(FF++) and 99.95% (CelebDF-v2). The framework demonstrates robust cross-dataset\ngeneralization, achieving AUC scores of 88.20% and 72.52%, and F1 scores of\n93.16% and 80.62% in cross-dataset evaluations.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T05:14:50Z"}
{"aid":"http://arxiv.org/abs/2505.00313v1","title":"A$_1$-A$_2$ splitting in pure $^3$He in nematic aerogel","summary":"Here, we present the results of vibrating wire experiments in pure $^3$He\n(without $^4$He coverage) in nematic aerogel. We investigated the dependence of\nsplitting of the superfluid transition temperature of $^3$He in aerogel on\nmagnetic field. In addition to our previous work, we used a wider range of\nmagnetic fields (up to 31 kOe) and managed to detect both the \"upper\" and\n\"lower\" superfluid transition temperatures. The solid paramagnetic $^3$He layer\non the aerogel strands activates the magnetic scattering channel. According to\ntheory, it should result in linear splitting at high ($\\ge20$ kOe) fields,\nwhile at lower fields the splitting is expected to be nonlinear. We were able\nto observe this nonlinearity, but we have a discrepancy with theoretical\npredictions regarding the range of fields where nonlinearity occurs. Possible\nreasons for this are discussed.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.other","published":"2025-05-01T05:16:09Z"}
{"aid":"http://arxiv.org/abs/2505.00315v1","title":"Mixture of Sparse Attention: Content-Based Learnable Sparse Attention\n  via Expert-Choice Routing","summary":"Recent advances in large language models highlighted the excessive quadratic\ncost of self-attention. Despite the significant research efforts, subquadratic\nattention methods still suffer from inferior performance in practice. We\nhypothesize that dynamic, learned content-based sparsity can lead to more\nefficient attention mechanisms. We present Mixture of Sparse Attention (MoSA),\na novel approach inspired by Mixture of Experts (MoE) with expert choice\nrouting. MoSA dynamically selects tokens for each attention head, allowing\narbitrary sparse attention patterns. By selecting $k$ tokens from a sequence of\nlength $T$, MoSA reduces the computational complexity of each attention head\nfrom $O(T^2)$ to $O(k^2 + T)$. This enables using more heads within the same\ncomputational budget, allowing higher specialization. We show that among the\ntested sparse attention variants, MoSA is the only one that can outperform the\ndense baseline, sometimes with up to 27% better perplexity for an identical\ncompute budget. MoSA can also reduce the resource usage compared to dense\nself-attention. Despite using torch implementation without an optimized kernel,\nperplexity-matched MoSA models are simultaneously faster in wall-clock time,\nrequire less memory for training, and drastically reduce the size of the\nKV-cache compared to the dense transformer baselines.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-05-01T05:22:11Z"}
{"aid":"http://arxiv.org/abs/2505.00321v1","title":"Edge Large AI Models: Revolutionizing 6G Networks","summary":"Large artificial intelligence models (LAMs) possess human-like abilities to\nsolve a wide range of real-world problems, exemplifying the potential of\nexperts in various domains and modalities. By leveraging the communication and\ncomputation capabilities of geographically dispersed edge devices, edge LAM\nemerges as an enabling technology to empower the delivery of various real-time\nintelligent services in 6G. Unlike traditional edge artificial intelligence\n(AI) that primarily supports a single task using small models, edge LAM is\nfeatured by the need of the decomposition and distributed deployment of large\nmodels, and the ability to support highly generalized and diverse tasks.\nHowever, due to limited communication, computation, and storage resources over\nwireless networks, the vast number of trainable neurons and the substantial\ncommunication overhead pose a formidable hurdle to the practical deployment of\nedge LAMs. In this paper, we investigate the opportunities and challenges of\nedge LAMs from the perspectives of model decomposition and resource management.\nSpecifically, we propose collaborative fine-tuning and full-parameter training\nframeworks, alongside a microservice-assisted inference architecture, to\nenhance the deployment of edge LAM over wireless networks. Additionally, we\ninvestigate the application of edge LAM in air-interface designs, focusing on\nchannel prediction and beamforming. These innovative frameworks and\napplications offer valuable insights and solutions for advancing 6G technology.","main_category":"cs.NI","categories":"cs.NI,cs.LG,eess.SP","published":"2025-05-01T05:44:00Z"}
{"aid":"http://arxiv.org/abs/2505.00326v1","title":"Optimal Vector Compressed Sensing Using James Stein Shrinkage","summary":"The trend in modern science and technology is to take vector measurements\nrather than scalars, ruthlessly scaling to ever higher dimensional vectors. For\nabout two decades now, traditional scalar Compressed Sensing has been\nsynonymous with a Convex Optimization based procedure called Basis Pursuit. In\nthe vector recovery case, the natural tendency is to return to a\nstraightforward vector extension of Basis Pursuit, also based on Convex\nOptimization. However, Convex Optimization is provably suboptimal, particularly\nwhen $B$ is large. In this paper, we propose SteinSense, a lightweight\niterative algorithm, which is provably optimal when $B$ is large. It does not\nhave any tuning parameter, does not need any training data, requires zero\nknowledge of sparsity, is embarrassingly simple to implement, and all of this\nmakes it easily scalable to high vector dimensions. We conduct a massive volume\nof both real and synthetic experiments that confirm the efficacy of SteinSense,\nand also provide theoretical justification based on ideas from Approximate\nMessage Passing. Fascinatingly, we discover that SteinSense is quite robust,\ndelivering the same quality of performance on real data, and even under\nsubstantial departures from conditions under which existing theory holds.","main_category":"cs.LG","categories":"cs.LG,eess.IV,eess.SP,stat.CO,stat.ME","published":"2025-05-01T05:55:01Z"}
{"aid":"http://arxiv.org/abs/2505.00328v1","title":"The spectral characteristics of the Sturm Hamiltonian with eventually\n  periodic type","summary":"In this paper we consider the spectral characteristics of the Sturm\nHamiltonian with eventually periodic type frequencies under large coupling and\nestablish strict inequalities between the optimal H\\\"older exponent of the\ndensity of states measure, the dimension of the density of states measure, the\ndimension of the spectrum, and the transport exponent by analyzing the\nthermodynamic pressure function. Also, we provide the large coupling asymptotic\nproperties of the four spectral characteristics.","main_category":"math.DS","categories":"math.DS","published":"2025-05-01T05:58:07Z"}
{"aid":"http://arxiv.org/abs/2505.00340v1","title":"Vehicular Communication Security: Multi-Channel and Multi-Factor\n  Authentication","summary":"Secure and reliable communications are crucial for Intelligent Transportation\nSystems (ITSs), where Vehicle-to-Infrastructure (V2I) communication plays a key\nrole in enabling mobility-enhancing and safety-critical services. Current V2I\nauthentication relies on credential-based methods over wireless\nNon-Line-of-Sight (NLOS) channels, leaving them exposed to remote impersonation\nand proximity attacks. To mitigate these risks, we propose a unified\nMulti-Channel, Multi-Factor Authentication (MFA) scheme that combines NLOS\ncryptographic credentials with a Line-of-Sight (LOS) visual channel. Our\napproach leverages a challenge-response security paradigm: the infrastructure\nissues challenges and the vehicle's headlights respond by flashing a structured\nsequence containing encoded security data. Deep learning models on the\ninfrastructure side then decode the embedded information to authenticate the\nvehicle. Real-world experimental evaluations demonstrate high test accuracy,\nreaching an average of 95% and 96.6%, respectively, under various lighting,\nweather, speed, and distance conditions. Additionally, we conducted extensive\nexperiments on three state-of-the-art deep learning models, including detailed\nablation studies for decoding the flashing sequence. Our results indicate that\nthe optimal architecture employs a dual-channel design, enabling simultaneous\ndecoding of the flashing sequence and extraction of vehicle spatial and\nlocational features for robust authentication.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-01T06:36:24Z"}
{"aid":"http://arxiv.org/abs/2505.00344v1","title":"Effective Redshift","summary":"The \"higher chromatic\" Quillen-Lichtenbaum conjecture, as proposed by Ausoni\nand Rognes, posits that the finite localization map $K(R) \\to L_{n + 1}^f K(R)$\nis a $p$-local equivalence in large degrees for suitable ring spectra $R$. We\ngive a simple criterion in terms of syntomic cohomology for an effective\nversion of Quillen-Lichtenbaum, i.e. for identifying the degrees in which the\nlocalization map is an isomorphism. Combining our result with recent\ncomputations implies that the finite localization map is $(-1)$-truncated in\nthe cases $R = \\mathrm{BP} \\langle n \\rangle$, $R = k(n)$, and $R =\n\\mathrm{ko}$.","main_category":"math.AT","categories":"math.AT,math.KT","published":"2025-05-01T06:42:18Z"}
{"aid":"http://arxiv.org/abs/2505.00353v1","title":"PYSED: A tool for extracting kinetic-energy-weighted phonon dispersion\n  and lifetime from molecular dynamics simulations","summary":"Machine learning potential-driven molecular dynamics (MD) simulations have\nsignificantly enhanced the predictive accuracy of thermal transport properties\nacross diverse materials. However, extracting phonon-mode-resolved insights\nfrom these simulations remains a critical challenge. Here, we introduce PYSED,\na Python-based package built on the spectral energy density (SED) method,\ndesigned to efficiently compute kinetic-energy-weighted phonon dispersion and\nextract phonon lifetime from large-scale MD simulation trajectories. By\nintegrating high-accuracy machine-learned neuroevolution potential (NEP)\nmodels, we validate and showcase the effectiveness of the implemented SED\nmethod across systems of varying dimensionalities. Specifically, the NEP-driven\nMD-SED accurately reveals how phonon modes are affected by strain in carbon\nnanotubes, as well as by interlayer coupling strength and twist angle in\ntwo-dimensional molybdenum disulfide. For three-dimensional systems, the SED\nmethod effectively establishes the thermal transport regime diagram for\nmetal-organic frameworks, distinguishing between particlelike and wavelike\npropagation regions. Moreover, using bulk silicon as an example, we show that\nphonon SED can efficiently capture quantum dynamics based on path-integral\ntrajectories. The PYSED package bridges MD simulations with detailed\nphonon-mode insights, delivering a robust tool for investigating thermal\ntransport properties with detailed mechanisms across various materials.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-05-01T06:52:18Z"}
{"aid":"http://arxiv.org/abs/2505.00355v1","title":"Attitude Control of Spacecraft for Autonomous Attenuation of Unknown\n  Periodic Disturbance Torque","summary":"Recently, deep space exploration, especially focusing on halo orbits, the\nperiodic orbits of the Moon, has been widely studied. The spacecraft in halo\norbits performs periodic orbital motion, which affects the attitude motion by\nperiodic disturbances. The conventional attitude control method, PD control, is\nwidely used, but its application to periodic disturbance attenuation is\ninefficient. To address these challenges, this study proposes a predictive\nRepetitive Control (RC) approach that addresses periodic disturbances,\nparticularly GG torque, by exploiting the periodic nature of the system\ndynamics. The proposed method is also applied to the case of using a Reaction\nWheel (RW) as an attitude control actuator. Despite the inherent challenges\nposed by RW limitations, including saturation torque and transmission delay,\nour predictive RC approach effectively mitigates these effects. Numerical\nsimulations demonstrate the robust performance of the proposed method in\nmaintaining attitude control for spacecraft traversing halo orbits near the\nEarth-Moon $L_2$ point, validating its potential for future deep space\nexploration missions.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-05-01T07:00:19Z"}
{"aid":"http://arxiv.org/abs/2505.00361v1","title":"Matrix Healy Plot: A Practical Tool for Visual Assessment of\n  Matrix-Variate Normality","summary":"Matrix-valued data, where each observation is represented as a matrix,\nfrequently arises in various scientific disciplines. Modeling such data often\nrelies on matrix-variate normal distributions, making matrix-variate normality\ntesting crucial for valid statistical inference. Recently, the\nDistance-Distance (DD) plot has been introduced as a graphical tool for\nvisually assessing matrix-variate normality. However, the Mahalanobis squared\ndistances (MSD) used in the DD plot require vectorizing matrix observations,\nrestricting its applicability to cases where the dimension of the vectorized\ndata does not exceed the sample size. To address this limitation, we propose a\nnovel graphical method called the Matrix Healy (MHealy) plot, an extension of\nthe Healy plot for vector-valued data. This new plot is based on more accurate\nmatrix-based MSD that leverages the inherent structure of matrix data.\nConsequently, it offers a more reliable visual assessment. Importantly, the\nMHealy plot eliminates the sample size restriction of the DD plot and hence\nmore applicable to matrix-valued data. Empirical results demonstrate its\neffectiveness and practicality compared to the DD plot across various\nscenarios, particularly in cases where the DD plot is not available due to\nlimited sample sizes.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-01T07:20:25Z"}
{"aid":"http://arxiv.org/abs/2505.00393v1","title":"S3AND: Efficient Subgraph Similarity Search Under Aggregated Neighbor\n  Difference Semantics (Technical Report)","summary":"For the past decades, the \\textit{subgraph similarity search} over a\nlarge-scale data graph has become increasingly important and crucial in many\nreal-world applications, such as social network analysis, bioinformatics\nnetwork analytics, knowledge graph discovery, and many others. While previous\nworks on subgraph similarity search used various graph similarity metrics such\nas the graph isomorphism, graph edit distance, and so on, in this paper, we\npropose a novel problem, namely \\textit{subgraph similarity search under\naggregated neighbor difference semantics} (S$^3$AND), which identifies\nsubgraphs $g$ in a data graph $G$ that are similar to a given query graph $q$\nby considering both keywords and graph structures (under new keyword/structural\nmatching semantics). To efficiently tackle the S$^3$AND problem, we design two\neffective pruning methods, \\textit{keyword set} and \\textit{aggregated neighbor\ndifference lower bound pruning}, which rule out false alarms of candidate\nvertices/subgraphs to reduce the S$^3$AND search space. Furthermore, we\nconstruct an effective indexing mechanism to facilitate our proposed efficient\nS$^3$AND query answering algorithm. Through extensive experiments, we\ndemonstrate the effectiveness and efficiency of our S$^3$AND approach over both\nreal and synthetic graphs under various parameter settings.","main_category":"cs.DB","categories":"cs.DB,cs.SI","published":"2025-05-01T08:30:15Z"}
{"aid":"http://arxiv.org/abs/2505.00404v1","title":"iMacSR: Intermediate Multi-Access Supervision and Regularization in\n  Training Autonomous Driving Models","summary":"Deep Learning (DL)-based street scene semantic understanding has become a\ncornerstone of autonomous driving (AD). DL model performance heavily relies on\nnetwork depth. Specifically, deeper DL architectures yield better segmentation\nperformance. However, as models grow deeper, traditional one-point supervision\nat the final layer struggles to optimize intermediate feature representations,\nleading to subpar training outcomes. To address this, we propose an\nintermediate Multi-access Supervision and Regularization (iMacSR) strategy. The\nproposed iMacSR introduces two novel components: (I) mutual information between\nlatent features and ground truth as intermediate supervision loss ensures\nrobust feature alignment at multiple network depths; and (II) negative entropy\nregularization on hidden features discourages overconfident predictions and\nmitigates overfitting. These intermediate terms are combined into the original\nfinal-layer training loss to form a unified optimization objective, enabling\ncomprehensive optimization across the network hierarchy. The proposed iMacSR\nprovides a robust framework for training deep AD architectures, advancing the\nperformance of perception systems in real-world driving scenarios. In addition,\nwe conduct theoretical convergence analysis for the proposed iMacSR. Extensive\nexperiments on AD benchmarks (i.e., Cityscapes, CamVid, and SynthiaSF datasets)\ndemonstrate that iMacSR outperforms conventional final-layer single-point\nsupervision method up to 9.19% in mean Intersection over Union (mIoU).","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T08:52:56Z"}
{"aid":"http://arxiv.org/abs/2505.00407v1","title":"Multiple generation star formation in Cepheus Flare","summary":"We present an analysis of the young stellar moving group ASCC 127 using Gaia\nDR3 data, significantly expanding its membership to 3,971 stars -- double the\nnumber identified in previous studies. Using kinematic and distance criteria,\nASCC 127 is divided into five subgroups (Groups 1-5) with ages spanning from 15\nto 32 Myr. Groups 1-5 are spatially linked to the Cepheus Flare star-forming\nregion, revealing potential evidence of four sequential star formation episodes\nat approximately 32 Myr, 20 Myr, 15 Myr, and 7 Myr. Through dust and gas\nmapping, we identify a spatial cavity extending several tens of parsecs, which\nmay have resulted from feedback processes such as supernovae associated with\nearlier generations of stars in the region. This structure, along with the\nlarger Loop III feature, indicates that feedback from massive stars likely\ninfluenced the interstellar medium (ISM). By integrating young stellar\npopulations with ISM studies, we provide a detailed picture of the\nfeedback-driven star formation history in the Cepheus Flare region.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-05-01T08:57:34Z"}
{"aid":"http://arxiv.org/abs/2505.00418v1","title":"Thermal noise induced probability switching in magnetic tunnel junction\n  based on spin-circuit simulation","summary":"The probability switching characteristics in spin transfer torque magnetic\ntunnel junctions (STT-MTJs) are simulated by considering thermal noise using a\nspin-circuit module. Thermal noise significantly affects the probability\nswitching for pulse durations exceeding 10 ns, while no probability switching\nproperties are observed for pulses shorter than 1 ns due to the precessional\nswitching. For pulse durations between 1 ns and 10 ns, the occurrence of mixed\nprobability and abrupt switching suggests that thermal noise partially\ninfluences the switching properties. These results demonstrate the\neffectiveness of our simulation model in capturing the MTJ properties under the\ninfluence of thermal noise. The spin-circuit module used in this study lays the\ngroundwork for future circuit system designs utilizing MTJ devices, such as\ntrue random number generators and neural network computing.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-05-01T09:33:12Z"}
{"aid":"http://arxiv.org/abs/2505.00432v1","title":"A Neural Network Mode for PX4 on Embedded Flight Controllers","summary":"This paper contributes an open-sourced implementation of a neural-network\nbased controller framework within the PX4 stack. We develop a custom module for\ninference on the microcontroller while retaining all of the functionality of\nthe PX4 autopilot. Policies trained in the Aerial Gym Simulator are converted\nto the TensorFlow Lite format and then built together with PX4 and flashed to\nthe flight controller. The policies substitute the control-cascade within PX4\nto offer an end-to-end position-setpoint tracking controller directly providing\nnormalized motor RPM setpoints. Experiments conducted in simulation and the\nreal-world show similar tracking performance. We thus provide a flight-ready\npipeline for testing neural control policies in the real world. The pipeline\nsimplifies the deployment of neural networks on embedded flight controller\nhardware thereby accelerating research on learning-based control. Both the\nAerial Gym Simulator and the PX4 module are open-sourced at\nhttps://github.com/ntnu-arl/aerial_gym_simulator and\nhttps://github.com/SindreMHegre/PX4-Autopilot-public/tree/for_paper. Video:\nhttps://youtu.be/lY1OKz_UOqM?si=VtzL243BAY3lblTJ.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T10:01:43Z"}
{"aid":"http://arxiv.org/abs/2505.00443v1","title":"Distributed Retrieval-Augmented Generation","summary":"As large language models (LLMs) become increasingly adopted on edge devices,\nRetrieval-Augmented Generation (RAG) is gaining prominence as a solution to\naddress factual deficiencies and hallucinations by integrating external\nknowledge. However, centralized RAG architectures face significant challenges\nin data privacy and scalability. For instance, smart healthcare services often\nrely on collecting sensitive patient data and building a centralized knowledge\nbase to provide better diagnosis and treatment advice, while privacy concerns\nsignificantly impede this process. Besides, maintaining a comprehensive and\ncontinuously updated knowledge base is costly, particularly in response to\nregional epidemics and rapidly mutating viruses. To address these challenges,\nthis paper introduces Distributed Retrieval-Augmented Generation (DRAG), a\nnovel framework that improves data privacy by eliminating the need for a\ncentralized knowledge base and restoring data control to owners. DRAG\nincorporates a Topic-Aware Random Walk (TARW) algorithm that leverages LLMs to\nextract query topics and facilitate targeted peer discovery within a\npeer-to-peer network, enabling efficient knowledge retrieval in decentralized\nenvironments. Extensive experiments across three diverse datasets and LLMs\ndemonstrate that DRAG with TARW achieves near-centralized RAG performance by\nusing half as many messages as flooding. The code is available at\nhttps://github.com/xuchenhao001/DRAG.","main_category":"cs.DC","categories":"cs.DC","published":"2025-05-01T10:37:06Z"}
{"aid":"http://arxiv.org/abs/2505.00445v1","title":"Effect of Ti$_2$Pd(Ni) on the Transformation Behavior in Sputtered\n  Ti-rich TiNiPd Shape Memory Alloys","summary":"TiNiPd based shape memory alloys (SMAs) share similar microstructural\nfeatures as TiNiCu-based SMAs known for their exceptional resistance to\nfunctional fatigue due to their high crystallographic compatibility, nanometer\nsized grains and coherent precipitates, making them an ideal system to further\nexplore the critical factors influencing cyclic stability. In this study, we\ninvestigate the effect of heat treatments (500 {\\deg}C, 600 {\\deg}C, 700\n{\\deg}C and 800 {\\deg}C) on the cyclic stability and microstructure of\nfree-standing, magnetron-sputtered Ti$_{53.6}$Ni$_{35.2}$Pd$_{11.2}$ films. All\nheat treatments promote the formation of Ti$_2$Pd(Ni) precipitates and result\nin a similar grain size (~1-4 $\\mu$m). Lower heat treatment temperatures\nimprove the cyclic stability of the stress induced transformation while\nreducing transformation temperatures and latent heat. Temperature dependent\nX-ray diffraction reveals a complex microstructure for the martensite phase\nwith Ti$_2$Pd(Ni), Ti$_2$Ni(Pd), TiNiPd(B2), B19/B19$'$ and R-phase. The\nthermal phase transition changes from a distinct 1st order to a 2nd order like\ntransition, accompanied by increasing amount of remanent austenite and R-phase,\nwith nearly no change for the sample heat treated at 500 {\\deg}C. In situ\nstress dependent X-ray diffraction demonstrates a significant difference\nbetween the temperature and stress induced phase transformation for this heat\ntreatment. The observed semi crystalline microstructure, featuring nano domains\nof Ti$_2$Pd(Ni) precipitates in the sample heat-treated at 500 {\\deg}C, leads\nto a mixture of long range martensitic and strain glass transition. This study\nhighlights the impact of heat treatment and microstructure on the phase\ntransformation behavior and functional fatigue in Ti-rich TiNiPd alloys.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-01T10:39:49Z"}
{"aid":"http://arxiv.org/abs/2505.00449v1","title":"An approach for modularly verifying the core of Rust's atomic reference\n  counting algorithm against the (X)C20 memory consistency model","summary":"We propose an approach for modular verification of programs that use\nrelaxed-consistency atomic memory access primitives and fences, sufficient for\nverifying the core of Rust's Atomic Reference Counting (ARC) algorithm, and we\nargue its soundness, when combined with a simple static analysis and admitting\nan open sub-problem, with respect to the C20 memory consistency model, as well\nas, even in the absence of any static analysis and without any assumptions,\nwith respect to XC20, a recently proposed minor strengthening of C20 that rules\nout out-of-thin-air behaviors but allows load buffering. In contrast to\nexisting work on verifying ARC, we do not assume acyclicity of the union of the\nprogram-order and reads-from relations. We define an interleaving operational\nsemantics, prove its soundness with respect to (X)C20's axiomatic semantics,\nand then apply any existing program logic for fine-grained interleaving\nconcurrency, such as Iris.","main_category":"cs.PL","categories":"cs.PL","published":"2025-05-01T10:51:20Z"}
{"aid":"http://arxiv.org/abs/2505.00458v1","title":"Memory-Centric Computing: Solving Computing's Memory Problem","summary":"Computing has a huge memory problem. The memory system, consisting of\nmultiple technologies at different levels, is responsible for most of the\nenergy consumption, performance bottlenecks, robustness problems, monetary\ncost, and hardware real estate of a modern computing system. All this becomes\nworse as modern and emerging applications become more data-intensive (as we\nreadily witness in e.g., machine learning, genome analysis, graph processing,\nand data analytics), making the memory system an even larger bottleneck. In\nthis paper, we discuss two major challenges that greatly affect computing\nsystem performance and efficiency: 1) memory technology & capacity scaling (at\nthe lower device and circuit levels) and 2) system and application performance\n& energy scaling (at the higher levels of the computing stack). We demonstrate\nthat both types of scaling have become extremely difficult, wasteful, and\ncostly due to the dominant processor-centric design & execution paradigm of\ncomputers, which treats memory as a dumb and inactive component that cannot\nperform any computation. We show that moving to a memory-centric design &\nexecution paradigm can solve the major challenges, while enabling multiple\nother potential benefits. In particular, we demonstrate that: 1) memory\ntechnology scaling problems (e.g., RowHammer, RowPress, Variable Read\nDisturbance, data retention, and other issues awaiting to be discovered) can be\nmuch more easily and efficiently handled by enabling memory to autonomously\nmanage itself; 2) system and application performance & energy efficiency can,\nat the same time, be improved by orders of magnitude by enabling computation\ncapability in memory chips and structures (i.e., processing in memory). We\ndiscuss adoption challenges against enabling memory-centric computing, and\ndescribe how we can get there step-by-step via an evolutionary path.","main_category":"cs.AR","categories":"cs.AR,cs.DC","published":"2025-05-01T11:16:09Z"}
{"aid":"http://arxiv.org/abs/2505.00464v1","title":"Stable self-charged perovskite quantum rods for liquid laser with\n  near-zero threshold","summary":"Colloidal quantum dots (QDs) are promising optical gain materials that\nrequire further threshold reduction to realize their full potential. While QD\ncharging theoretically reduces the threshold to zero, its effectiveness has\nbeen limited by strong Auger recombination and unstable charging. Here we\ntheoretically reveal the optimal combination of charging number and Auger\nrecombination to minimize the lasing threshold. Experimentally, we develop\nstable self-charged perovskite quantum rods (QRs) as an alternative to QDs via\nstate engineering and Mn-doping strategy. An unprecedented\ntwo-order-of-magnitude reduction in nonradiative Auger recombination enables\nQRs to support a sufficient charging number of up to 6. The QR liquid lasing is\nthen achieved with a near-zero threshold of 0.098 using quasi-continuous\npumping of nanosecond pulses, which is the lowest threshold among all reported\nQD lasers. These achievements demonstrate the potential of the specially\nengineered QRs as an excellent gain media and pave the way for their\nprospective applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.app-ph,physics.optics","published":"2025-05-01T11:31:09Z"}
{"aid":"http://arxiv.org/abs/2505.00469v1","title":"Enumerations of 1-rotational Steiner systems","summary":"In this paper new $1$-rotational 2-Steiner systems for different admissible\n$v,k$ pairs are introduced. In particular, $1$-rotational unitals of order $4$\nare enumerated.","main_category":"math.CO","categories":"math.CO","published":"2025-05-01T11:45:18Z"}
{"aid":"http://arxiv.org/abs/2505.00483v1","title":"Search for a parity-violating long-range spin-dependent interaction","summary":"High-sensitivity quantum sensors are a promising tool for experimental\nsearches for beyond-Standard-Model interactions. Here, we demonstrate an atomic\ncomagnetometer operating under a resonantly-coupled hybrid spin-resonance (HSR)\nregime to probe P-odd, T-even interactions. The HSR regime enables robust\nnuclear-electron spin coupling, enhancing measurement bandwidth and stability\nwithout compromising the high sensitivity of spin-exchange relaxation-free\nmagnetometers. To minimize vibration noise from velocity-modulated sources, we\nimplement a multistage vibration isolation system, achieving a vibration noise\nreduction exceeding 700-fold. We establish new constraints on\nvector-boson-mediated parity-violating interactions, improving experimental\nsensitivity by three orders of magnitude compared to previous limits. The new\nconstraints complement existing astrophysical and laboratory studies of\npotential extensions to the Standard Model.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-05-01T12:29:19Z"}
{"aid":"http://arxiv.org/abs/2505.00486v1","title":"Enumeration of idempotent-sum subsequences in finite cyclic semigroups\n  and smooth sequences","summary":"The enumeration of zero-sum subsequences of a given sequence over finite\ncyclic groups is one classical topic, which starts from one question of P.\nErd\\H{o}s. In this paper, we consider this problem in a more general setting --\nfinite cyclic semigroups. Let $\\mathcal{S}$ be a finite cyclic semigroup. By\n$\\textbf{e}$ we denote the unique idempotent of the semigroup $\\mathcal{S}$.\nLet $T$ be a sequence over the semigroup $\\mathcal{S}$, and let $N(T;\n\\textbf{e})$ be the number of distinct subsequences of $T$ with sum being the\nidempotent $\\textbf{e}$. We obtain the lower bound for $N(T; \\textbf{e})$ in\nterms of the length of $T$, and moreover, prove that $T$ contains subsequences\nwith some smooth-structure in case that $N(T; \\textbf{e})$ is not large. Our\nresult generalizes the theorem obtained by W. Gao [Discrete Math., 1994] on the\nenumeration of zero-sum subsequences over finite cyclic groups to the setting\nof semigroups.","main_category":"math.CO","categories":"math.CO,math.NT","published":"2025-05-01T12:35:23Z"}
{"aid":"http://arxiv.org/abs/2505.00489v1","title":"Weighted averages of $\\operatorname{SL}_2(\\mathbb{R})$ automorphic\n  kernel, Part I: non-oscillatory functions","summary":"We prove a theorem that evaluates weighted averages of sums parametrized by\ncongruence subgroups of $\\operatorname{SL}_2(\\mathbb{Z})$. In the proof,\nspectral methods are applied directly to the automorphic kernel instead of\ngoing over sums of Kloosterman sums. For number theoretical applications this\nbetter preserves the specific symmetries throughout the application of spectral\nmethods.","main_category":"math.NT","categories":"math.NT","published":"2025-05-01T12:42:20Z"}
{"aid":"http://arxiv.org/abs/2505.00507v1","title":"HeAL3D: Heuristical-enhanced Active Learning for 3D Object Detection","summary":"Active Learning has proved to be a relevant approach to perform sample\nselection for training models for Autonomous Driving. Particularly, previous\nworks on active learning for 3D object detection have shown that selection of\nsamples in uncontrolled scenarios is challenging. Furthermore, current\napproaches focus exclusively on the theoretical aspects of the sample selection\nproblem but neglect the practical insights that can be obtained from the\nextensive literature and application of 3D detection models. In this paper, we\nintroduce HeAL (Heuristical-enhanced Active Learning for 3D Object Detection)\nwhich integrates those heuristical features together with Localization and\nClassification to deliver the most contributing samples to the model's\ntraining. In contrast to previous works, our approach integrates heuristical\nfeatures such as object distance and point-quantity to estimate the\nuncertainty, which enhance the usefulness of selected samples to train\ndetection models. Our quantitative evaluation on KITTI shows that HeAL presents\ncompetitive mAP with respect to the State-of-the-Art, and achieves the same mAP\nas the full-supervised baseline with only 24% of the samples.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T13:24:55Z"}
{"aid":"http://arxiv.org/abs/2505.00512v1","title":"InterLoc: LiDAR-based Intersection Localization using Road Segmentation\n  with Automated Evaluation Method","summary":"Intersections are geometric and functional key points in every road network.\nThey offer strong landmarks to correct GNSS dropouts and anchor new sensor data\nin up-to-date maps. Despite that importance, intersection detectors either\nignore the rich semantic information already computed onboard or depend on\nscarce, hand-labeled intersection datasets. To close that gap, this paper\npresents a LiDAR-based method for intersection detection that (i) fuses\nsemantic road segmentation with vehicle localization to detect intersection\ncandidates in a bird's eye view (BEV) representation and (ii) refines those\ncandidates by analyzing branch topology with a least squares formulation. To\nevaluate our method, we introduce an automated benchmarking pipeline that pairs\ndetections with OpenStreetMap (OSM) intersection nodes using precise GNSS/INS\nground-truth poses. Tested on eight SemanticKITTI sequences, the approach\nachieves a mean localization error of 1.9 m, 89% precision, and 77% recall at a\n5 m tolerance, outperforming the latest learning-based baseline. Moreover, the\nmethod is robust to segmentation errors higher than those of the benchmark\nmodel, demonstrating its applicability in the real world.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-05-01T13:30:28Z"}
{"aid":"http://arxiv.org/abs/2505.00517v1","title":"An explicit description of the Khler-Einstein metrics of\n  Guenancia-Hamenstdt","summary":"Fine and Premoselli (FP) constructed the first examples of manifolds that do\nnot admit a locally symmetric metric but do admit a negatively curved Einstein\nmetric. The manifolds here are hyperbolic branched covers like those used by\nGromov and Thurston, and the construction of their model Einstein metric is a\nvariation of the hyperbolic metric written in polar coordinates. Very recently,\nGuenancia and Hamenst\\\"{a}dt (GH) proved the existence of the first examples of\nmanifolds that are not locally symmetric but admit a negatively curved\nK\\\"{a}hler-Einstein metric. The GH metrics are realized on complex hyperbolic\nbranched covers constructed by Stover and Toledo. In this article we generalize\nthe construction of FP to the complex hyperbolic setting and show that this\nyields a negatively curved Einstein metric that asymptotically approaches the\nmetric of GH.","main_category":"math.DG","categories":"math.DG,math-ph,math.GT,math.MG,math.MP","published":"2025-05-01T13:39:20Z"}
{"aid":"http://arxiv.org/abs/2505.00535v1","title":"Moving through Cartesian products, coronas and joins in general position","summary":"The general position problem asks for large sets of vertices such that no\nthree vertices of the set lie on a common shortest path. Recently a dynamic\nversion of this problem was defined, called the \\emph{mobile general position\nproblem}, in which a collection of robots must visit all the vertices of the\ngraph whilst remaining in general position. In this paper we investigate this\nproblem in the context of Cartesian products, corona products and joins, giving\nupper and lower bounds for general graphs and exact values for families\nincluding grids, cylinders, Hamming graphs and prisms of trees.","main_category":"math.CO","categories":"math.CO","published":"2025-05-01T14:00:59Z"}
{"aid":"http://arxiv.org/abs/2505.00550v1","title":"Bridging Cultural and Digital Divides: A Low-Latency JackTrip Framework\n  for Equitable Music Education in the Global South","summary":"The rapid expansion of digital technologies has transformed educational\nlandscapes worldwide, yet significant infrastructural and cultural challenges\npersist in the Global South. This paper introduces a low-latency JackTrip\nframework designed to bridge both the cultural and digital divides in music\neducation. By leveraging an open-source, UDP-based audio streaming protocol\noriginally developed at Stanford's CCRMA, the framework is tailored to address\ntechnical constraints such as intermittent connectivity, limited bandwidth, and\nhigh latency that characterize many rural and underserved regions. The study\nsystematically compares the performance of JackTrip with conventional platforms\nlike Zoom, demonstrating that JackTrip achieves sub-30~ms latency under\nsimulated low-resource conditions while preserving the intricate audio details\nessential for non-Western musical traditions. Spectral analysis confirms that\nJackTrip's superior handling of microtonal scales, complex rhythms, and\nharmonic textures provides a culturally authentic medium for real-time ensemble\nperformance and music education. These findings underscore the transformative\npotential of decentralized, edge-computing solutions in empowering educators\nand musicians across the Global South, promoting both technological equity and\ncultural preservation.","main_category":"cs.SD","categories":"cs.SD,cs.SI","published":"2025-05-01T14:27:47Z"}
{"aid":"http://arxiv.org/abs/2505.00551v1","title":"100 Days After DeepSeek-R1: A Survey on Replication Studies and More\n  Directions for Reasoning Language Models","summary":"The recent development of reasoning language models (RLMs) represents a novel\nevolution in large language models. In particular, the recent release of\nDeepSeek-R1 has generated widespread social impact and sparked enthusiasm in\nthe research community for exploring the explicit reasoning paradigm of\nlanguage models. However, the implementation details of the released models\nhave not been fully open-sourced by DeepSeek, including DeepSeek-R1-Zero,\nDeepSeek-R1, and the distilled small models. As a result, many replication\nstudies have emerged aiming to reproduce the strong performance achieved by\nDeepSeek-R1, reaching comparable performance through similar training\nprocedures and fully open-source data resources. These works have investigated\nfeasible strategies for supervised fine-tuning (SFT) and reinforcement learning\nfrom verifiable rewards (RLVR), focusing on data preparation and method design,\nyielding various valuable insights. In this report, we provide a summary of\nrecent replication studies to inspire future research. We primarily focus on\nSFT and RLVR as two main directions, introducing the details for data\nconstruction, method design and training procedure of current replication\nstudies. Moreover, we conclude key findings from the implementation details and\nexperimental results reported by these studies, anticipating to inspire future\nresearch. We also discuss additional techniques of enhancing RLMs, highlighting\nthe potential of expanding the application scope of these models, and\ndiscussing the challenges in development. By this survey, we aim to help\nresearchers and developers of RLMs stay updated with the latest advancements,\nand seek to inspire new ideas to further enhance RLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-01T14:28:35Z"}
{"aid":"http://arxiv.org/abs/2505.00568v1","title":"Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor\n  Analysis with Missing Modalities","summary":"Multimodal magnetic resonance imaging (MRI) constitutes the first line of\ninvestigation for clinicians in the care of brain tumors, providing crucial\ninsights for surgery planning, treatment monitoring, and biomarker\nidentification. Pre-training on large datasets have been shown to help models\nlearn transferable representations and adapt with minimal labeled data. This\nbehavior is especially valuable in medical imaging, where annotations are often\nscarce. However, applying this paradigm to multimodal medical data introduces a\nchallenge: most existing approaches assume that all imaging modalities are\navailable during both pre-training and fine-tuning. In practice, missing\nmodalities often occur due to acquisition issues, specialist unavailability, or\nspecific experimental designs on small in-house datasets. Consequently, a\ncommon approach involves training a separate model for each desired modality\ncombination, making the process both resource-intensive and impractical for\nclinical use. Therefore, we introduce BM-MAE, a masked image modeling\npre-training strategy tailored for multimodal MRI data. The same pre-trained\nmodel seamlessly adapts to any combination of available modalities, extracting\nrich representations that capture both intra- and inter-modal information. This\nallows fine-tuning on any subset of modalities without requiring architectural\nchanges, while still benefiting from a model pre-trained on the full set of\nmodalities. Extensive experiments show that the proposed pre-training strategy\noutperforms or remains competitive with baselines that require separate\npre-training for each modality subset, while substantially surpassing training\nfrom scratch on several downstream tasks. Additionally, it can quickly and\nefficiently reconstruct missing modalities, highlighting its practical value.\nCode and trained models are available at: https://github.com/Lucas-rbnt/bmmae","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-01T14:51:30Z"}
{"aid":"http://arxiv.org/abs/2505.00579v1","title":"Voice Cloning: Comprehensive Survey","summary":"Voice Cloning has rapidly advanced in today's digital world, with many\nresearchers and corporations working to improve these algorithms for various\napplications. This article aims to establish a standardized terminology for\nvoice cloning and explore its different variations. It will cover speaker\nadaptation as the fundamental concept and then delve deeper into topics such as\nfew-shot, zero-shot, and multilingual TTS within that context. Finally, we will\nexplore the evaluation metrics commonly used in voice cloning research and\nrelated datasets. This survey compiles the available voice cloning algorithms\nto encourage research toward its generation and detection to limit its misuse.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-05-01T15:10:29Z"}
{"aid":"http://arxiv.org/abs/2505.00583v1","title":"Gluon Parts of Gravitational Form Factors and Mass Distribution","summary":"The parton structure of the nucleon and pion is investigated in an\nexploratory model that allows one to assess whether the dressing of quarks can,\nby itself, produce realistic gluon contributions to light-cone momentum\nfractions, gravitational form factors, mass/energy distributions and their\nradii. The model is the Dyson-Schwinger Equations in Rainbow-Ladder truncation.\nFor the parton mass/energy distributions as a function of momentum transfer, we\ndirectly calculate matrix elements of the Energy-Momentum Tensor by utilizing\nits similarity to the momentum fraction moment of GPDs associated with deep\ninelastic scattering. A variety of gravitational form factors are obtained\nincluding the D-term.","main_category":"nucl-th","categories":"nucl-th,hep-ph,hep-th","published":"2025-05-01T15:15:29Z"}
{"aid":"http://arxiv.org/abs/2505.00585v1","title":"Dimension-reduced Optimization of Multi-zone Thermostatically Controlled\n  Loads","summary":"This study proposes a computationally efficient method for optimizing\nmulti-zone thermostatically controlled loads (TCLs) by leveraging\ndimensionality reduction through an auto-encoder. We develop a multi-task\nlearning framework to jointly represent latent variables and formulate a\nstate-space model based on observed TCL operation data. This significantly\nreduces the dimensionality of TCL variables and states while preserving\ncritical nonlinear interdependencies in TCL control. To address various\napplication scenarios, we introduce optimization algorithms based on system\nidentification (OptIden) and system simulation (OptSim) tailored to the latent\nvariable representation. These approaches employ automatic differentiation and\nzeroth-order techniques, respectively, for efficient implementation. We\nevaluate the proposed method using a 90-zone apartment prototype, comparing its\nperformance to traditional high-dimensional optimization. Results demonstrate\nthat our approach effectively reduces control costs while achieving\nsignificantly higher computational efficiency.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-01T15:16:04Z"}
{"aid":"http://arxiv.org/abs/2505.00587v1","title":"The Hao-Ng isomorphism theorem for reduced crossed products","summary":"We prove the Hao-Ng isomorphism for reduced crossed products by locally\ncompact Hausdorff groups. More precisely, for a non-degenerate\n$\\mathrm{C}^*$-correspondence $X$ and a generalized gauge action $G\n\\curvearrowright X$ by a locally compact Hausdorff group $G$, we prove the\ncommutation ${\\mathcal{O}}_{X\\rtimes_rG}\\cong {\\mathcal{O}}_X\\rtimes_rG$ of the\nreduced crossed product with the Cuntz-Pimsner C*-algebra construction.","main_category":"math.OA","categories":"math.OA,math.FA","published":"2025-05-01T15:18:49Z"}
{"aid":"http://arxiv.org/abs/2505.00602v1","title":"Irregularity and Topological Indices in Fibonacci Word Trees and\n  Modified Fibonacci Word Index","summary":"This paper introduces the concept of the Fibonacci Word Index\n$\\operatorname{FWI}$, a novel topological index derived from the Albertson\nindex, applied to trees constructed from Fibonacci words. Building upon the\nclassical Fibonacci sequence and its generalizations, we explore the structural\nproperties of Fibonacci word trees and their degree-based irregularity\nmeasures. We define the $\\operatorname{FWI}$ and its variants, including the\ntotal irregularity and modified Fibonacci Word Index where it defined as \\[\n\\operatorname{FWI}^*(T)=\\sum_{n,m\\in E(\\mathscr{T})}[deg F_n^2-deg F_m^2], \\]\nand establish foundational inequalities relating these indices to the maximum\ndegree of the underlying trees. Our results extend known graph invariants to\nthe combinatorial setting of Fibonacci words, providing new insights into their\nalgebraic and topological characteristics.","main_category":"math.CO","categories":"math.CO","published":"2025-05-01T15:34:48Z"}
{"aid":"http://arxiv.org/abs/2505.00605v1","title":"Surviving the Storm: The Impacts of Open RAN Disaggregation on Latency\n  and Resilience","summary":"The development of Open Radio Access Networks (Open RAN), with their\ndisaggregated architectures and virtualization of network functions, has\nbrought considerable flexibility and cost savings to mobile networks. However,\nthese architectural advancements introduce additional latency during the\ninitial attachment procedure of User Equipment (UE), increasing the risk of\nsignaling storms. This paper investigates the latency impact due to\ndisaggregation of the Base-band Unit (BBU) into the Central Unit (CU) and\nDistributed Unit (DU). Specifically, we model the delays induced due to\ndisaggregation on UE attachment, analyzing the performance under varying load\nconditions, and sensitivity to processing times. We demonstrate that while both\nmonolithic and Open RAN architectures experience performance degradation under\nhigh-load conditions, Open RAN's added overheads can increase its\nsusceptibility to congestion and signaling storms. However, Open RAN's inherent\nflexibility, enabled by disaggregation and virtualization, allows efficient\ndeployment of resources, faster service deployment, and adaptive congestion\ncontrol mechanisms to mitigate these risks and enhance overall system\nresilience. Thereby, we quantify resilience by introducing a new utility\nfunction and propose a novel adaptation mechanism to reinforce Open RAN's\nrobustness against signaling storms. Our results show that the proposed\nadaptive mechanism significantly enhances resilience, achieving improvements of\nup to 286% over fixed configurations, with resilience scores approaching 0.96\nunder optimal conditions. While simulation results show that Open RAN\ndisaggregation increases attachment latency and susceptibility to signaling\ncongestion, they also highlight that its architectural flexibility can mitigate\nthese effects, improving resilience under high-load conditions.","main_category":"cs.NI","categories":"cs.NI","published":"2025-05-01T15:35:31Z"}
{"aid":"http://arxiv.org/abs/2505.00609v1","title":"Wavefront errors in two-wavelength adaptive optics systems","summary":"Two-wavelength adaptive optics (AO) systems sense turbulence-induced\nwavefront distortions using an artificial beacon or natural guidestar at one\nwavelength, while correcting and possibly transmitting at another. Although\nmost existing AO systems employ this methodology, the literature on atmospheric\nturbulence correction and AO system design generally focuses on performance at\na single wavelength, neglecting the two-wavelength nature of the problem. In\nthis paper, we undertake a rigorous study of the relevant wavefront errors\nnecessary to quantify two-wavelength AO system performance.\n  Since most AO systems employ separate tilt and higher-order correcting\nsubsystems, our analysis mirrors this division, and we begin with higher-order\nwavefront errors. Utilizing Mellin transform techniques, we derive closed-form\nrelations for the piston-removed and piston- and tilt-removed variances. The\nformer is a measure of the total, residual wavefront error that a\ntwo-wavelength AO systems experiences; while the latter, quantifies the\nresidual wavefront error due to higher-order aberrations.\n  We then proceed to tilt or tracking errors and derive the two-wavelength\nZernike- and gradient-tilt variances. Zernike tilt is the actual amount of tilt\nin the turbulent atmosphere; yet, most AO tracking subsystems measure gradient\ntilt. Consequently, we also derive the two-wavelength gradient-tilt,\nZernike-tilt variance -- also known as centroid anisoplanatism -- to quantify\nthis error.\n  Lastly, we validate our analysis by performing two-wavelength wave-optics\nsimulations and comparing the results to theory. We observe excellent agreement\namong the simulated results and our theoretical predictions.\n  The analysis and findings presented in this paper will be useful in the\ncharacterization of existing, and the design of new, two-wavelength AO systems.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-01T15:38:21Z"}
{"aid":"http://arxiv.org/abs/2505.00611v1","title":"A new pointwise bound for $3$-torsion of class groups","summary":"Ellenberg--Venkatesh proved in 2007 that $h_3(d) \\ll_\\epsilon |d|^{1/3 +\n\\epsilon}$, where $h_3(d)$ denotes the size of the $3$-torsion of the class\ngroup of $\\mathbb{Q}(\\sqrt{d})$. We improve this bound to $h_3(d) \\ll_\\epsilon\n|d|^{\\kappa + \\epsilon}$ with $\\kappa \\approx 0.3193 \\cdots$. We also combine\nour methods with work of Heath-Brown--Pierce to give new bounds for average\n$\\ell$-torsion of real quadratic fields.","main_category":"math.NT","categories":"math.NT","published":"2025-05-01T15:41:30Z"}
{"aid":"http://arxiv.org/abs/2505.00623v1","title":"Planckian scattering and parallel conduction channels in the iron\n  chalcogenide superconductors FeTe$_{1-x}$Se$_x$","summary":"The remarkable linear in temperature resistivity of the cuprate\nsuperconductors, which extends in some samples from $T_c$ to the melting\ntemperature, remains unexplained. Although seemingly simple, this temperature\ndependence is incompatible with the conventional theory of metals that dictates\nthat the scattering rate, $1/\\tau$, should be quadratic in temperature if\nelectron-electron scattering dominates. Understanding the origin of this\ntemperature dependence and its connection to superconductivity may provide the\nkey to pick the lock of high-temperature superconductivity. Using time-domain\nterahertz spectroscopy (TDTS) we elucidate the low temperature conducting\nbehavior of two FeTe$_{1-x}$Se$_x$ (FTS) samples, one with almost equal amounts\nof Se and Te that is believed to be a topological superconductor, and one that\nis more overdoped. Constrained with DC resistivity, we find two conduction\nchannels that add in parallel, a broad one in frequency with weak temperature\ndependence and a sharper one whose scattering rate goes as the Planckian\nlimited rate, $\\sim kT/h$. Through analysis of its spectral weight we show the\nsuperconducting condensate is mainly drawn from the channel that undergoes this\nPlanckian scattering.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.str-el","published":"2025-05-01T16:04:27Z"}
{"aid":"http://arxiv.org/abs/2505.00632v1","title":"Detecting Modeling Bias with Continuous Time Flow Models on Weak Lensing\n  Maps","summary":"Simulation-based inference provides a powerful framework for extracting rich\ninformation from nonlinear scales in current and upcoming cosmological surveys,\nand ensuring its robustness requires stringent validation of forward models. In\nthis work, we recast forward model validation as an out-of-distribution (OoD)\ndetection problem within the framework of machine learning (ML)-based\nsimulation-based inference (SBI). We employ probability density as the metric\nfor OoD detection, and compare various density estimation techniques,\ndemonstrating that field-level probability density estimation via continuous\ntime flow models (CTFM) significantly outperforms feature-level approaches that\ncombine scattering transform (ST) or convolutional neural networks (CNN) with\nnormalizing flows (NFs), as well as NF-based field-level estimators, as\nquantified by the area under the receiver operating characteristic curve\n(AUROC). Our analysis shows that CTFM not only excels in detecting OoD samples\nbut also provides a robust metric for model selection. Additionally, we\nverified CTFM maintains consistent efficacy across different cosmologies while\nmitigating the inductive biases inherent in NF architectures. Although our\nproof-of-concept study employs simplified forward modeling and noise settings,\nour framework establishes a promising pathway for identifying unknown\nsystematics in the cosmology datasets.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.IM","published":"2025-05-01T16:16:47Z"}
{"aid":"http://arxiv.org/abs/2505.00653v1","title":"On the exponents of distribution of primes and smooth numbers","summary":"We show that both primes and smooth numbers are equidistributed in arithmetic\nprogressions to moduli up to $x^{5/8 - o(1)}$, using triply-well-factorable\nweights for the primes (we also get improvements for the well-factorable linear\nsieve weights). This completely eliminates the dependency on Selberg's\neigenvalue conjecture in previous works of Lichtman and the author, which built\nin turn on results of Maynard and Drappeau. We rely on recent large sieve\ninequalities for exceptional Maass forms of the author for\nadditively-structured sequences, and on a related result of Watt for\nmultiplicatively-structured sequences. As applications, we prove refined upper\nbounds for the counts of twin primes and consecutive smooth numbers up to $x$.","main_category":"math.NT","categories":"math.NT","published":"2025-05-01T16:55:08Z"}
{"aid":"http://arxiv.org/abs/2505.00662v1","title":"DeepCritic: Deliberate Critique with Large Language Models","summary":"As Large Language Models (LLMs) are rapidly evolving, providing accurate\nfeedback and scalable oversight on their outputs becomes an urgent and critical\nproblem. Leveraging LLMs as critique models to achieve automated supervision is\na promising solution. In this work, we focus on studying and enhancing the math\ncritique ability of LLMs. Current LLM critics provide critiques that are too\nshallow and superficial on each step, leading to low judgment accuracy and\nstruggling to offer sufficient feedback for the LLM generator to correct\nmistakes. To tackle this issue, we propose a novel and effective two-stage\nframework to develop LLM critics that are capable of deliberately critiquing on\neach reasoning step of math solutions. In the first stage, we utilize\nQwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for\nsupervised fine-tuning. Each seed critique consists of deliberate step-wise\ncritiques that includes multi-perspective verifications as well as in-depth\ncritiques of initial critiques for each reasoning step. Then, we perform\nreinforcement learning on the fine-tuned model with either existing\nhuman-labeled data from PRM800K or our automatically annotated data obtained\nvia Monte Carlo sampling-based correctness estimation, to further incentivize\nits critique ability. Our developed critique model built on Qwen2.5-7B-Instruct\nnot only significantly outperforms existing LLM critics (including the\nsame-sized DeepSeek-R1-distill models and GPT-4o) on various error\nidentification benchmarks, but also more effectively helps the LLM generator\nrefine erroneous steps through more detailed feedback.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-05-01T17:03:17Z"}
{"aid":"http://arxiv.org/abs/2505.00669v1","title":"Direct spectral problems for Paley-Wiener canonical systems","summary":"This note focuses on the direct spectral problem for canonical Hamiltonian\nsystems on the half-line $\\mathbb{R}_+$. Truncated Toeplitz operators have been\neffectively used to solve the inverse spectral problem when the spectral\nmeasure is a locally finite periodic measure (see \\cite{MP}). Here, we reverse\nthe inverse problem algorithm to solve the direct spectral problem for\nstep-function Hamiltonians. For a non-step-function Hamiltonian, we consider\nits step-function approximations and their corresponding spectral measures, and\nshow that these spectral measures converge to the spectral measure of the\noriginal Hamiltonian.","main_category":"math.SP","categories":"math.SP","published":"2025-05-01T17:20:13Z"}
{"aid":"http://arxiv.org/abs/2505.00671v1","title":"Multi-Constraint Safe Reinforcement Learning via Closed-form Solution\n  for Log-Sum-Exp Approximation of Control Barrier Functions","summary":"The safety of training task policies and their subsequent application using\nreinforcement learning (RL) methods has become a focal point in the field of\nsafe RL. A central challenge in this area remains the establishment of\ntheoretical guarantees for safety during both the learning and deployment\nprocesses. Given the successful implementation of Control Barrier Function\n(CBF)-based safety strategies in a range of control-affine robotic systems,\nCBF-based safe RL demonstrates significant promise for practical applications\nin real-world scenarios. However, integrating these two approaches presents\nseveral challenges. First, embedding safety optimization within the RL training\npipeline requires that the optimization outputs be differentiable with respect\nto the input parameters, a condition commonly referred to as differentiable\noptimization, which is non-trivial to solve. Second, the differentiable\noptimization framework confronts significant efficiency issues, especially when\ndealing with multi-constraint problems. To address these challenges, this paper\npresents a CBF-based safe RL architecture that effectively mitigates the issues\noutlined above. The proposed approach constructs a continuous AND logic\napproximation for the multiple constraints using a single composite CBF. By\nleveraging this approximation, a close-form solution of the quadratic\nprogramming is derived for the policy network in RL, thereby circumventing the\nneed for differentiable optimization within the end-to-end safe RL pipeline.\nThis strategy significantly reduces computational complexity because of the\nclosed-form solution while maintaining safety guarantees. Simulation results\ndemonstrate that, in comparison to existing approaches relying on\ndifferentiable optimization, the proposed method significantly reduces training\ncomputational costs while ensuring provable safety throughout the training\nprocess.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-05-01T17:22:11Z"}
{"aid":"http://arxiv.org/abs/2505.00679v1","title":"Steering Large Language Models with Register Analysis for Arbitrary\n  Style Transfer","summary":"Large Language Models (LLMs) have demonstrated strong capabilities in\nrewriting text across various styles. However, effectively leveraging this\nability for example-based arbitrary style transfer, where an input text is\nrewritten to match the style of a given exemplar, remains an open challenge. A\nkey question is how to describe the style of the exemplar to guide LLMs toward\nhigh-quality rewrites. In this work, we propose a prompting method based on\nregister analysis to guide LLMs to perform this task. Empirical evaluations\nacross multiple style transfer tasks show that our prompting approach enhances\nstyle transfer strength while preserving meaning more effectively than existing\nprompting strategies.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-01T17:39:02Z"}
{"aid":"http://arxiv.org/abs/2505.00689v1","title":"Axially symmetric collapses in the 2-D Benjamin-Ono equation","summary":"We study the nonlinear dynamics of localized perturbations within the\nframework of the essentially two-dimensional generalization of the Benjamin-Ono\nequation (2D-BO) derived asymptotically from the Navier-Stokes equation. By\nsimulating the 2D-BO equation with the pseudospectral method, we confirm that\nthe localized initial perturbations exceeding a certain threshold collapse,\nforming a point singularity. Although the 2D-BO equation does not possess axial\nsymmetry, we show that in the vicinity of the collapse singularity, the\nsolution becomes axially-symmetric, whatever its initial shape. We find that\nperturbations collapse in a self-similar manner, with the perturbation\namplitude exploding as $ (\\check \\tau)^{-\\lambda}$ and its transverse scale\nshrinking as $ (\\check \\tau)^{\\lambda}$, where $\\check \\tau$ is the time to the\nmoment of singularity. We derive a family of self-similar solutions describing\naxially symmetric collapses. The value of the free parameter $ {\\lambda}$ in\nthe self-similar solution is specified by fitting it to the numerical\nsimulation of the initial problem of the evolution of an initially localized\nperturbation. Remarkably, for the examples we examined the value of the\nparameter proved to be almost universal: $ {\\lambda} \\approx 0.9$; its\ndependence on the initial conditions is indiscernible. In the vicinity of the\nsingularity, the dynamics becomes one-dimensional, thus, the derived reduction\nof the 2D-BO equation provides an effectively one-dimensional model of\ncollapse.","main_category":"math-ph","categories":"math-ph,math.MP,nlin.PS","published":"2025-05-01T17:51:03Z"}
{"aid":"http://arxiv.org/abs/2505.00690v1","title":"Towards Autonomous Micromobility through Scalable Urban Simulation","summary":"Micromobility, which utilizes lightweight mobile machines moving in urban\npublic spaces, such as delivery robots and mobility scooters, emerges as a\npromising alternative to vehicular mobility. Current micromobility depends\nmostly on human manual operation (in-person or remote control), which raises\nsafety and efficiency concerns when navigating busy urban environments full of\nunpredictable obstacles and pedestrians. Assisting humans with AI agents in\nmaneuvering micromobility devices presents a viable solution for enhancing\nsafety and efficiency. In this work, we present a scalable urban simulation\nsolution to advance autonomous micromobility. First, we build URBAN-SIM - a\nhigh-performance robot learning platform for large-scale training of embodied\nagents in interactive urban scenes. URBAN-SIM contains three critical modules:\nHierarchical Urban Generation pipeline, Interactive Dynamics Generation\nstrategy, and Asynchronous Scene Sampling scheme, to improve the diversity,\nrealism, and efficiency of robot learning in simulation. Then, we propose\nURBAN-BENCH - a suite of essential tasks and benchmarks to gauge various\ncapabilities of the AI agents in achieving autonomous micromobility.\nURBAN-BENCH includes eight tasks based on three core skills of the agents:\nUrban Locomotion, Urban Navigation, and Urban Traverse. We evaluate four robots\nwith heterogeneous embodiments, such as the wheeled and legged robots, across\nthese tasks. Experiments on diverse terrains and urban structures reveal each\nrobot's strengths and limitations.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.RO","published":"2025-05-01T17:52:29Z"}
{"aid":"http://arxiv.org/abs/2505.00693v1","title":"Robotic Visual Instruction","summary":"Recently, natural language has been the primary medium for human-robot\ninteraction. However, its inherent lack of spatial precision for robotic\ncontrol introduces challenges such as ambiguity and verbosity. To address these\nlimitations, we introduce the Robotic Visual Instruction (RoVI), a novel\nparadigm to guide robotic tasks through an object-centric, hand-drawn symbolic\nrepresentation. RoVI effectively encodes spatial-temporal information into\nhuman-interpretable visual instructions through 2D sketches, utilizing arrows,\ncircles, colors, and numbers to direct 3D robotic manipulation. To enable\nrobots to understand RoVI better and generate precise actions based on RoVI, we\npresent Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for\nRoVI-conditioned policies. This approach leverages Vision-Language Models\n(VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from\n2D pixel space via keypoint extraction, and then transform them into executable\n3D action sequences. We additionally curate a specialized dataset of 15K\ninstances to fine-tune small VLMs for edge deployment, enabling them to\neffectively learn RoVI capabilities. Our approach is rigorously validated\nacross 11 novel tasks in both real and simulated environments, demonstrating\nsignificant generalization capability. Notably, VIEW achieves an 87.5% success\nrate in real-world scenarios involving unseen tasks that feature multi-step\nactions, with disturbances, and trajectory-following requirements. Code and\nDatasets in this paper will be released soon.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-05-01T17:55:05Z"}
{"aid":"http://arxiv.org/abs/2505.00695v1","title":"Simple Holography in General Spacetimes","summary":"The simple or \"outermost\" wedge in AdS is the portion of the entanglement\nwedge that can be reconstructed with sub-exponential effort from CFT data. Here\nwe furnish a definition in arbitrary spacetimes: given an input wedge $a$\nanalogous to a CFT boundary region, the simple wedge $z(a)$ is the largest\nwedge accessible by a \"zigzag,\" a certain sequence of antinormal light-sheets.\nWe show that $z(a)$ is a throat, and that it is contained in every other\nthroat. This implies that $z(a)$ is unique; that it is contained in the\ngeneralized entanglement wedge; and that it reduces to the AdS prescription as\na special case.\n  The zigzag explicitly constructs a preferred Cauchy slice that renders the\nsimple wedge accessible from $a$; thus it adds a novel structure even in AdS.\nSo far, no spacelike construction is known to reproduce these results, even in\ntime-symmetric settings. This may have implications for the modeling of\nholographic encoding by tensor networks.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-05-01T17:55:50Z"}
{"aid":"http://arxiv.org/abs/2505.00698v1","title":"Comprehensive Study on Heisenberg-limited Quantum Algorithms for\n  Multiple Observables Estimation","summary":"In the accompanying paper of arXiv:25XX.XXXXX, we have presented a\ngeneralized scheme of adaptive quantum gradient estimation (QGE) algorithm, and\nfurther proposed two practical variants which not only achieve doubly quantum\nenhancement in query complexity regarding estimation precision and number of\nobservables, but also enable minimal cost to estimate $k$-RDMs in fermionic\nsystems among existing quantum algorithms. Here, we provide full descriptions\non the algorithm, and provide theoretical guarantee for the estimation\nprecision in terms of the root mean squared error. Furthermore, we analyze the\nperformance of the quantum amplitude estimation algorithm, another variant of\nthe Heisenberg-limited scaling algorithm, and show how the estimation error is\nminimized under the circuit structure that resembles the phase estimation\nalgorithm. We finally describe the details for the numerical evaluation of the\nquery complexity of the Heisenberg-limited algorithms and sampling-based\nmethods to make a thorough comparison in the task of estimating fermionic\n$k$-RDMs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T17:57:27Z"}
{"aid":"http://arxiv.org/abs/2505.07178v1","title":"Accountability of Generative AI: Exploring a Precautionary Approach for\n  \"Artificially Created Nature\"","summary":"The rapid development of generative artificial intelligence (AI) technologies\nraises concerns about the accountability of sociotechnical systems. Current\ngenerative AI systems rely on complex mechanisms that make it difficult for\neven experts to fully trace the reasons behind the outputs. This paper first\nexamines existing research on AI transparency and accountability and argues\nthat transparency is not a sufficient condition for accountability but can\ncontribute to its improvement. We then discuss that if it is not possible to\nmake generative AI transparent, generative AI technology becomes ``artificially\ncreated nature'' in a metaphorical sense, and suggest using the precautionary\nprinciple approach to consider AI risks. Finally, we propose that a platform\nfor citizen participation is needed to address the risks of generative AI.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-12T02:10:55Z"}
{"aid":"http://arxiv.org/abs/2505.07179v1","title":"Lagrange Oscillatory Neural Networks for Constraint Satisfaction and\n  Optimization","summary":"Physics-inspired computing paradigms are receiving renewed attention to\nenhance efficiency in compute-intensive tasks such as artificial intelligence\nand optimization. Similar to Hopfield neural networks, oscillatory neural\nnetworks (ONNs) minimize an Ising energy function that embeds the solutions of\nhard combinatorial optimization problems. Despite their success in solving\nunconstrained optimization problems, Ising machines still face challenges with\nconstrained problems as they can get stuck at infeasible local minima. In this\npaper, we introduce a Lagrange ONN (LagONN) designed to escape infeasible\nstates based on the theory of Lagrange multipliers. Unlike existing oscillatory\nIsing machines, LagONN employs additional Lagrange oscillators to guide the\nsystem towards feasible states in an augmented energy landscape and settles\nonly when constraints are met. Taking the maximum satisfiability problem with\nthree literals as a use case (Max-3-SAT), we harness LagONN's constraint\nsatisfaction mechanism to find optimal solutions for random SATlib instances\nwith up to 200 variables and 860 clauses, which provides a deterministic\nalternative to simulated annealing for coupled oscillators. We further discuss\nthe potential of Lagrange oscillators to address other constraints, such as\nphase copying, which is useful in oscillatory Ising machines with limited\nconnectivity.","main_category":"cs.ET","categories":"cs.ET,cs.NE","published":"2025-05-12T02:12:38Z"}
{"aid":"http://arxiv.org/abs/2505.07180v1","title":"Causal View of Time Series Imputation: Some Identification Results on\n  Missing Mechanism","summary":"Time series imputation is one of the most challenge problems and has broad\napplications in various fields like health care and the Internet of Things.\nExisting methods mainly aim to model the temporally latent dependencies and the\ngeneration process from the observed time series data. In real-world scenarios,\ndifferent types of missing mechanisms, like MAR (Missing At Random), and MNAR\n(Missing Not At Random) can occur in time series data. However, existing\nmethods often overlook the difference among the aforementioned missing\nmechanisms and use a single model for time series imputation, which can easily\nlead to misleading results due to mechanism mismatching. In this paper, we\npropose a framework for time series imputation problem by exploring Different\nMissing Mechanisms (DMM in short) and tailoring solutions accordingly.\nSpecifically, we first analyze the data generation processes with temporal\nlatent states and missing cause variables for different mechanisms.\nSequentially, we model these generation processes via variational inference and\nestimate prior distributions of latent variables via normalizing flow-based\nneural architecture. Furthermore, we establish identifiability results under\nthe nonlinear independent component analysis framework to show that latent\nvariables are identifiable. Experimental results show that our method surpasses\nexisting time series imputation techniques across various datasets with\ndifferent missing mechanisms, demonstrating its effectiveness in real-world\napplications.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-05-12T02:13:14Z"}
{"aid":"http://arxiv.org/abs/2505.07185v1","title":"Exact closed-form solutions for Lamb's problem (II): a moving point load","summary":"In this article, we report on an exact closed-form solution for the\ndisplacement in an elastic homogeneous half-space elicited by a downward\nvertical point source moving with constant velocity over the surface of the\nmedium. The problem considered here is an extension to Lamb's problem. Starting\nwith the integral solutions of Bakker \\textit{et al.}, we followed the method\ndeveloped in Feng and Zhang, which focuses on the displacement triggered by a\nfixed point source observed on the free surface, to obtain the final solution\nin terms of elementary algebraic functions as well as elliptic integrals of the\nfirst, second and third kind. Our closed-form results agree perfectly with the\nnumerical results of Bakker \\textit{et al.}, which confirms the correctness of\nour formulas. The solution obtained in this article may lay a solid foundation\nfor further consideration of the response of an actual physical moving load,\nsuch as a high-speed rail train.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-05-12T02:25:27Z"}
{"aid":"http://arxiv.org/abs/2505.07186v1","title":"Reflexive Composition of Elementary State Machines, with an Application\n  to the Reversal of Cellular Automata Rule 90","summary":"We explore the dynamics of a one-dimensional lattice of state machines on two\nstates and two symbols sequentially updated via a process of \"reflexive\ncomposition.\" The space of 256 machines exhibits a variety of behavior,\nincluding substitution, reversible \"billiard ball\" dynamics, and fractal\nnesting. We show that one machine generates the Sierpinski Triangle and, for a\nsubset of boundary conditions, is isomorphic to cellular automata Rule 90 in\nWolfram's naming scheme. More surprisingly, two other machines follow\ntrajectories that map to Rule 90 in reverse. Whereas previous techniques have\nbeen developed to uncover preimages of Rule 90, this is the first study to\nproduce such inverse dynamics naturally from the formalism itself. We argue\nthat the system's symmetric treatment of state and message underlies its\nexpressive power.","main_category":"cs.DM","categories":"cs.DM,cs.FL,nlin.CG","published":"2025-05-12T02:28:46Z"}
{"aid":"http://arxiv.org/abs/2505.07190v1","title":"Connectedness of the boundaries of the strata of differentials","summary":"Let $\\mathcal{P}(\\mu)^{\\circ}$ be a connected component of the projectivized\nstratum of differentials on smooth complex curves, where the zero and pole\norders of the differentials are specified by $\\mu$. When the complex dimension\nof $\\mathcal{P}(\\mu)^{\\circ}$ is at least two, Dozier--Grushevsky--Lee, through\nexplicit degeneration techniques, showed that the boundary of\n$\\mathcal{P}(\\mu)^{\\circ}$ is connected in the multi-scale compactification\nconstructed by Bainbridge--Chen--Gendron--Grushevsky--M\\\"oller.\n  A natural question is whether the connectedness of the boundary of\n$\\mathcal{P}(\\mu)^{\\circ}$ is determined by its intrinsic properties. In the\ncase of meromorphic differentials, we provide a concise explanation that the\nboundary of $\\mathcal{P}(\\mu)^{\\circ}$ is always connected in any complete\nalgebraic compactification, based on the fact that the strata of meromorphic\ndifferentials are affine varieties. We also observe that the same result holds\nfor linear subvarieties of meromorphic differentials, as well as for the strata\nof $k$-differentials with a pole of order at least $k$.\n  In the case of holomorphic differentials, using properties of Teichm\\\"uller\ncurves, we provide an alternative argument showing that the horizontal boundary\nof $\\mathcal{P}(\\mu)^{\\circ}$ and every irreducible component of its vertical\nboundary intersect non-trivially in the multi-scale compactification.","main_category":"math.AG","categories":"math.AG,math.GT","published":"2025-05-12T02:40:16Z"}
{"aid":"http://arxiv.org/abs/2505.07193v1","title":"Geometric Bogomolov conjecture for semiabelian varieties","summary":"We establish the geometric Bogomolov conjecture for semiabelian varieties\nover function fields. We show a closed subvariety contains Zariski dense sets\nof small points, if and only if, after modulo its stabilizer, it is a torsion\ntranslate of a constant variety. A new phenomenon is that a special subvariety\nmay not have a Zariski dense set of points of height 0.","main_category":"math.AG","categories":"math.AG,math.NT","published":"2025-05-12T02:52:54Z"}
{"aid":"http://arxiv.org/abs/2505.07201v1","title":"Growth of ultra-clean single crystals of RuO2","summary":"We report the details of the growth of ultra-clean single crystals for RuO2,\na candidate material for altermagnetism. By using a crystal-growth tube with a\nnecking structure and precisely controlling the conditions of the sublimation\ntransport method, it is possible to control the morphology of the crystals. We\nobtained crystals in mainly three kinds of morphology: thick plate-like\ncrystals typically 5 x 3 x 2mm3 and up to 10 x 5 x 2mm3 with a large (101)\nfacet, rhombohedral columnar crystals elongating along the [001] direction, and\nfiber and needle crystals of length up to 8 mm and the width of 0.1-0.4 mm.\nThese crystals show residual resistivity of about 30 nOhmcm and a residual\nresistivity ratio (RRR) up to 1200. The crystals do not exhibit any signs of\nmagnetic ordering down to low temperatures.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-05-12T03:19:28Z"}
{"aid":"http://arxiv.org/abs/2505.07211v1","title":"Braided symmetric algebras and a first fundamental theorem of invariant\n  theory for ${\\rm U}_q(G_2)$","summary":"We develop invariant theory for the quantum group ${\\rm U}_q$ of $G_2$ at\ngeneric $q$ in the setting of braided symmetric algebras. Let ${\\mathcal A}_m$\nbe the braided symmetric algebra over $m$-copies of the $7$-dimensional simple\n${\\rm U}_q$-module. A set of ${\\rm U}_q$-invariants in ${\\mathcal A}_m$\nattached to certain acyclic trivalent graphs is obtained, which spans the\nsubalgebra ${\\mathcal A}_m^{{\\rm U}_q}$ of invariants as vector space. A finite\nset of homogeneous elements is constructed explicitly, which generates\n${\\mathcal A}_m^{{\\rm U}_q}$ as algebra. Commutation relations among the\nalgebraic generators are determined. These results may be regarded as a\nnon-commutative first fundamental theorem of invariant theory for ${\\rm U}_q$.\nThe algebra ${\\mathcal A}_m$ is a non-flat quantisation of the coordinate ring\nof ${\\mathbb C}^7\\otimes{\\mathbb C}^m$. As ${\\rm U}_q$-module, ${\\mathcal\nA}_m={\\mathcal A}_1^{\\otimes m}$ and we decompose ${\\mathcal A}_1$ into simple\nsubmodules. The affine scheme associated to the classical limit of ${\\mathcal\nA}_m$ is described. This is a rare case where the structure of a non-flat\nquantisation is understood.","main_category":"math.QA","categories":"math.QA,math.RT","published":"2025-05-12T03:39:36Z"}
{"aid":"http://arxiv.org/abs/2505.07222v1","title":"Compression, Regularity, Randomness and Emergent Structure: Rethinking\n  Physical Complexity in the Data-Driven Era","summary":"Complexity science offers a wide range of measures for quantifying\nunpredictability, structure, and information. Yet, a systematic conceptual\norganization of these measures is still missing.\n  We present a unified framework that locates statistical, algorithmic, and\ndynamical measures along three axes (regularity, randomness, and complexity)\nand situates them in a common conceptual space. We map statistical,\nalgorithmic, and dynamical measures into this conceptual space, discussing\ntheir computational accessibility and approximability.\n  This taxonomy reveals the deep challenges posed by uncomputability and\nhighlights the emergence of modern data-driven methods (including autoencoders,\nlatent dynamical models, symbolic regression, and physics-informed neural\nnetworks) as pragmatic approximations to classical complexity ideals. Latent\nspaces emerge as operational arenas where regularity extraction, noise\nmanagement, and structured compression converge, bridging theoretical\nfoundations with practical modeling in high-dimensional systems.\n  We close by outlining implications for physics-informed AI and AI-guided\ndiscovery in complex physical systems, arguing that classical questions of\ncomplexity remain central to next-generation scientific modeling.","main_category":"cs.LG","categories":"cs.LG,cond-mat.stat-mech,cs.IT,math.IT,physics.bio-ph,physics.data-an","published":"2025-05-12T04:30:42Z"}
{"aid":"http://arxiv.org/abs/2505.07234v1","title":"A Novel Online Pseudospectral Method for Approximation of Nonlinear\n  Systems Dynamics","summary":"This paper presents a novel online system identification approach utilizing\nthe Chebyshev pseudospectral (PS) method to approximate the dynamics of a\ncontinuous-time nonlinear system. Unlike conventional periodic sampling, the\nproposed identification scheme employs aperiodic state sampling, leveraging the\nChebyshev nodes to achieve the desired approximation accuracy. Unlike\ntraditional off-line PS approaches, the scheme utilizes a moving time-window\nstrategy to compute the sampling instants (Chebyshev nodes) forward in time for\nstate measurements. Within each time window, the number of sampling instants is\nadaptively determined to meet the specified approximation accuracy. The\nChebyshev basis is also shifted for each time window to accommodate arbitrary\napproximation intervals. The least-squares approach is employed to estimate the\ncoefficients of the shifted Chebyshev basis functions using the measured state\nand its derivatives at the end of each window, resulting in a piecewise\napproximation of the drift dynamics of the system. In the second step, the\nidentified drift dynamics are utilized to design an adaptive state estimator to\nreconstruct the continuous system states from the aperiodic state measurements.\nTo address the smoothness of the piecewise approximated system dynamics, the\nChebyshev coefficients are recomputed at the window transition instants,\nbetween two consecutive time windows, by enforcing continuity of the\napproximated function and its derivatives. In addition, analytical results are\nprovided to determine the number of sampling instants within each time window,\nwhich guarantees the desired approximation accuracy. The boundedness of\nfunction approximation and state estimation errors is also proved analytically.\nFinally, numerical simulation results are included to validate the proposed\nscheme.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-12T05:19:53Z"}
{"aid":"http://arxiv.org/abs/2505.07237v1","title":"Photometric analysis of asteroids in the Phocaea region","summary":"The Phocaea asteroid family, one of the large ancient families located in the\ninner main belt, may be the sources of near-Earth asteroids (NEAs) due to the\nnearby 3:1 mean motion resonance with Jupiter, the v6 secular resonance, and\nthe Yarkovsky and YORP effects. Thus, understanding the influence of the\nYarkovsky and YORP effects on the Phocaea family is one of the keys to figuring\nout the source of NEAs. However, the physical properties of most of the Phocaea\nfamily members are unknown at present. We perform a photometric analysis for 44\nasteroids in the Phocaea region using photometric data obtained by ground-based\nand space-based telescopes (i.e., TESS and Gaia). Based on the derived physical\nproperties, we find significant footprints of the Yarkovsky and YORP effects on\nthe Phocaea family members. Selecting five asteroids nearby the inside boundary\nof the V-shape in the absolute-magnitude semimajor-axis (H, a) space, we\nestimate their densities considering their migration in semimajor-axis arises\nfrom the Yarkovsky effect. The bulk density of (852) Wladilena ({3.54 g/cm3)\nsuggests a link to the H chondrite meteorites. Incorporating the grain density\nof the H chondrites, we estimate the macroporosities of the asteroids (290)\nBruna, (1164) Kobolda, and (587) Hypsipyle, respectively 41%, 47%, and 65%,\nimplying rubble pile structures. Considering the H chondrites link to asteroid\n(25) Phocaea, we suggest the parent body of the Phocaea family has been\ncomposed of H chondrite like material and the Phocaea family may be one of the\nsources of H chondrite meteorites.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-05-12T05:27:09Z"}
{"aid":"http://arxiv.org/abs/2505.07266v1","title":"BETTY Dataset: A Multi-modal Dataset for Full-Stack Autonomy","summary":"We present the BETTY dataset, a large-scale, multi-modal dataset collected on\nseveral autonomous racing vehicles, targeting supervised and self-supervised\nstate estimation, dynamics modeling, motion forecasting, perception, and more.\nExisting large-scale datasets, especially autonomous vehicle datasets, focus\nprimarily on supervised perception, planning, and motion forecasting tasks. Our\nwork enables multi-modal, data-driven methods by including all sensor inputs\nand the outputs from the software stack, along with semantic metadata and\nground truth information. The dataset encompasses 4 years of data, currently\ncomprising over 13 hours and 32TB, collected on autonomous racing vehicle\nplatforms. This data spans 6 diverse racing environments, including high-speed\noval courses, for single and multi-agent algorithm evaluation in feature-sparse\nscenarios, as well as high-speed road courses with high longitudinal and\nlateral accelerations and tight, GPS-denied environments. It captures highly\ndynamic states, such as 63 m/s crashes, loss of tire traction, and operation at\nthe limit of stability. By offering a large breadth of cross-modal and dynamic\ndata, the BETTY dataset enables the training and testing of full autonomy stack\npipelines, pushing the performance of all algorithms to the limits. The current\ndataset is available at https://pitt-mit-iac.github.io/betty-dataset/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-12T06:35:22Z"}
{"aid":"http://arxiv.org/abs/2505.07271v1","title":"On the Robustness of Reward Models for Language Model Alignment","summary":"The Bradley-Terry (BT) model is widely practiced in reward modeling for\nreinforcement learning with human feedback (RLHF). Despite its effectiveness,\nreward models (RMs) trained with BT model loss are prone to over-optimization,\nlosing generalizability to unseen input distributions. In this paper, we study\nthe cause of over-optimization in RM training and its downstream effects on the\nRLHF procedure, accentuating the importance of distributional robustness of RMs\nin unseen data. First, we show that the excessive dispersion of hidden state\nnorms is the main source of over-optimization. Then, we propose batch-wise\nsum-to-zero regularization (BSR) to enforce zero-centered reward sum per batch,\nconstraining the rewards with extreme magnitudes. We assess the impact of BSR\nin improving robustness in RMs through four scenarios of over-optimization,\nwhere BSR consistently manifests better robustness. Subsequently, we compare\nthe plain BT model and BSR on RLHF training and empirically show that robust\nRMs better align the policy to the gold preference model. Finally, we apply BSR\nto high-quality data and models, which surpasses state-of-the-art RMs in the 8B\nscale by adding more than 5% in complex preference prediction tasks. By\nconducting RLOO training with 8B RMs, AlpacaEval 2.0 reduces generation length\nby 40% while adding a 7% increase in win rate, further highlighting that\nrobustness in RMs induces robustness in RLHF training. We release the code,\ndata, and models: https://github.com/LinkedIn-XFACT/RM-Robustness.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-05-12T06:48:26Z"}
{"aid":"http://arxiv.org/abs/2505.07306v1","title":"Enabling Privacy-Aware AI-Based Ergonomic Analysis","summary":"Musculoskeletal disorders (MSDs) are a leading cause of injury and\nproductivity loss in the manufacturing industry, incurring substantial economic\ncosts. Ergonomic assessments can mitigate these risks by identifying workplace\nadjustments that improve posture and reduce strain. Camera-based systems offer\na non-intrusive, cost-effective method for continuous ergonomic tracking, but\nthey also raise significant privacy concerns. To address this, we propose a\nprivacy-aware ergonomic assessment framework utilizing machine learning\ntechniques. Our approach employs adversarial training to develop a lightweight\nneural network that obfuscates video data, preserving only the essential\ninformation needed for human pose estimation. This obfuscation ensures\ncompatibility with standard pose estimation algorithms, maintaining high\naccuracy while protecting privacy. The obfuscated video data is transmitted to\na central server, where state-of-the-art keypoint detection algorithms extract\nbody landmarks. Using multi-view integration, 3D keypoints are reconstructed\nand evaluated with the Rapid Entire Body Assessment (REBA) method. Our system\nprovides a secure, effective solution for ergonomic monitoring in industrial\nenvironments, addressing both privacy and workplace safety concerns.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T07:52:48Z"}
{"aid":"http://arxiv.org/abs/2505.07311v1","title":"Non-Asymptotic Analysis of Projected Gradient Descent for\n  Physics-Informed Neural Networks","summary":"In this work, we provide a non-asymptotic convergence analysis of projected\ngradient descent for physics-informed neural networks for the Poisson equation.\nUnder suitable assumptions, we show that the optimization error can be bounded\nby $\\mathcal{O}(1/\\sqrt{T} + 1/\\sqrt{m} + \\epsilon_{\\text{approx}})$, where $T$\nis the number of algorithm time steps, $m$ is the width of the neural network\nand $\\epsilon_{\\text{approx}}$ is an approximation error. The proof of our\noptimization result relies on bounding the linearization error and using this\nresult together with a Lyapunov drift analysis. Additionally, we quantify the\ngeneralization error by bounding the Rademacher complexities of the neural\nnetwork and its Laplacian. Combining both the optimization and generalization\nresults, we obtain an overall error estimate based on an existing error\nestimate from regularity theory.","main_category":"math.OC","categories":"math.OC","published":"2025-05-12T07:55:56Z"}
{"aid":"http://arxiv.org/abs/2505.07318v1","title":"Autonomous Robotic Pruning in Orchards and Vineyards: a Review","summary":"Manual pruning is labor intensive and represents up to 25% of annual labor\ncosts in fruit production, notably in apple orchards and vineyards where\noperational challenges and cost constraints limit the adoption of large-scale\nmachinery. In response, a growing body of research is investigating compact,\nflexible robotic platforms capable of precise pruning in varied terrains,\nparticularly where traditional mechanization falls short.\n  This paper reviews recent advances in autonomous robotic pruning for orchards\nand vineyards, addressing a critical need in precision agriculture. Our review\nexamines literature published between 2014 and 2024, focusing on innovative\ncontributions across key system components. Special attention is given to\nrecent developments in machine vision, perception, plant skeletonization, and\ncontrol strategies, areas that have experienced significant influence from\nadvancements in artificial intelligence and machine learning. The analysis\nsituates these technological trends within broader agricultural challenges,\nincluding rising labor costs, a decline in the number of young farmers, and the\ndiverse pruning requirements of different fruit species such as apple,\ngrapevine, and cherry trees.\n  By comparing various robotic architectures and methodologies, this survey not\nonly highlights the progress made toward autonomous pruning but also identifies\ncritical open challenges and future research directions. The findings\nunderscore the potential of robotic systems to bridge the gap between manual\nand mechanized operations, paving the way for more efficient, sustainable, and\nprecise agricultural practices.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-12T08:05:15Z"}
{"aid":"http://arxiv.org/abs/2505.07319v1","title":"Higher-order exceptional lines in a non-Hermitian JaynesCummings\n  triangle","summary":"Higher-order exceptional points (EPs) in non-Hermitian systems showcase\ndiverse physical phenomena but require more parameter space freedom or\nsymmetries. It leads to a challenge for the exploration of high-order EP\ngeometries in low-dimensional systems. Here we observe both a third-order\nexceptional surface and line in a Jaynes-Cummings triangle consisting of three\ncavities arranged in a ring. A fine-tuning artificial magnetic field\ndramatically enriches the emergence of the third-order exceptional lines\n($3$ELs), which require only three tuning parameters in the presence of chiral\nsymmetry and parity-time (PT) symmetry. Third-order EPs amplify the effect of\nperturbations through a cube-root response mechanism, displaying a greater\nsensitivity than second-order EPs. We develop novel fidelity and Loschmidt echo\nusing the associated-state biorthogonal approach, which successfully\ncharacterizes EPs and quench dynamics even in PT breaking regime. Our work\nadvances the use of higher-order EPs in quantum technology applications.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-12T08:05:20Z"}
{"aid":"http://arxiv.org/abs/2505.07320v1","title":"Dynamical Label Augmentation and Calibration for Noisy Electronic Health\n  Records","summary":"Medical research, particularly in predicting patient outcomes, heavily relies\non medical time series data extracted from Electronic Health Records (EHR),\nwhich provide extensive information on patient histories. Despite rigorous\nexamination, labeling errors are inevitable and can significantly impede\naccurate predictions of patient outcome. To address this challenge, we propose\nan \\textbf{A}ttention-based Learning Framework with Dynamic\n\\textbf{C}alibration and Augmentation for \\textbf{T}ime series Noisy\n\\textbf{L}abel \\textbf{L}earning (ACTLL). This framework leverages a\ntwo-component Beta mixture model to identify the certain and uncertain sets of\ninstances based on the fitness distribution of each class, and it captures\nglobal temporal dynamics while dynamically calibrating labels from the\nuncertain set or augmenting confident instances from the certain set.\nExperimental results on large-scale EHR datasets eICU and MIMIC-IV-ED, and\nseveral benchmark datasets from the UCR and UEA repositories, demonstrate that\nour model ACTLL has achieved state-of-the-art performance, especially under\nhigh noise levels.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-12T08:06:16Z"}
{"aid":"http://arxiv.org/abs/2505.07331v1","title":"Lepton Number Violation Higgs Decay at Muon Collider","summary":"In this paper, we consider the scalar singlet extension of type-I seesaw,\nwhere a scalar singlet $S$ and heavy neutral lepton $N$ are further introduced.\nThe Majorana mass term of heavy neutral lepton is generated through the Yukawa\ninteraction with the scalar singlet, which then induces the lepton number\nviolation decays of SM Higgs $h$ and heavy Higgs $H$ via mixing of scalars. As\na pathway to probe the origin of heavy neutral lepton mass, we investigate the\nlepton number violation Higgs decay signature at the TeV-scale muon collider.\nThe dominant production channel of Higgs bosons at the TeV-scale muon collider\nis via vector boson fusion. So we perform a detailed analysis of the signal\nprocess $\\mu^+\\mu^-\\to \\nu_\\mu \\bar{\\nu}_\\mu h/H \\to \\nu_\\mu \\bar{\\nu}_\\mu NN $\nfollowed by $ N \\to \\mu^\\pm jj$, where the two jets from $W$ boson decay are\ntreated as one fat-jet $J$. With an integrated luminosity of\n$1(10)~\\text{ab}^{-1}$, the 3 (10) TeV muon collider could discover the lepton\nnumber violation SM Higgs decay $h\\to \\mu^\\pm\\mu^\\pm JJ$ signature for the\nHiggs mixing parameter $\\sin\\alpha>0.05(0.009)$. Meanwhile, a large parameter\nspace can be detected by the lepton number violation heavy Higgs decay $H\\to\n\\mu^\\pm\\mu^\\pm JJ$ signature for $m_H\\lesssim1 (3)$ TeV and\n$\\sin\\alpha\\gtrsim0.03(0.005)$ at the 3 (10) TeV muon collider. Therefore, the\nlepton number violation SM and heavy Higgs decay signatures are both promising\nat the TeV scale muon collider.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-05-12T08:15:24Z"}
{"aid":"http://arxiv.org/abs/2505.07358v1","title":"Two-point open string amplitude as AdS transition amplitude","summary":"We compute the two-point open string amplitude at tree level and show that,\nin a t'Hooft-like limit, it takes a form structurally analogous to a\nboundary-to-boundary transition amplitude of scalar fields in Euclidean AdS\nspace. Starting from the path integral formulation of bosonic string theory on\na disk, we evaluate the amplitude using the Green's function under Neumann\nboundary conditions. In the end, we recast the result as a sum over AdS\ntransition amplitudes between scalar fields with different conformal weights.","main_category":"hep-th","categories":"hep-th","published":"2025-05-12T08:52:08Z"}
{"aid":"http://arxiv.org/abs/2505.07364v1","title":"GAN-based synthetic FDG PET images from T1 brain MRI can serve to\n  improve performance of deep unsupervised anomaly detection models","summary":"Background and Objective. Research in the cross-modal medical image\ntranslation domain has been very productive over the past few years in tackling\nthe scarce availability of large curated multimodality datasets with the\npromising performance of GAN-based architectures. However, only a few of these\nstudies assessed task-based related performance of these synthetic data,\nespecially for the training of deep models. Method. We design and compare\ndifferent GAN-based frameworks for generating synthetic brain\n[18F]fluorodeoxyglucose (FDG) PET images from T1 weighted MRI data. We first\nperform standard qualitative and quantitative visual quality evaluation. Then,\nwe explore further impact of using these fake PET data in the training of a\ndeep unsupervised anomaly detection (UAD) model designed to detect subtle\nepilepsy lesions in T1 MRI and FDG PET images. We introduce novel diagnostic\ntask-oriented quality metrics of the synthetic FDG PET data tailored to our\nunsupervised detection task, then use these fake data to train a use case UAD\nmodel combining a deep representation learning based on siamese autoencoders\nwith a OC-SVM density support estimation model. This model is trained on normal\nsubjects only and allows the detection of any variation from the pattern of the\nnormal population. We compare the detection performance of models trained on 35\npaired real MR T1 of normal subjects paired either on 35 true PET images or on\n35 synthetic PET images generated from the best performing generative models.\nPerformance analysis is conducted on 17 exams of epilepsy patients undergoing\nsurgery. Results. The best performing GAN-based models allow generating\nrealistic fake PET images of control subject with SSIM and PSNR values around\n0.9 and 23.8, respectively and in distribution (ID) with regard to the true\ncontrol dataset. The best UAD model trained on these synthetic normative PET\ndata allows reaching 74% sensitivity. Conclusion. Our results confirm that\nGAN-based models are the best suited for MR T1 to FDG PET translation,\noutperforming transformer or diffusion models. We also demonstrate the\ndiagnostic value of these synthetic data for the training of UAD models and\nevaluation on clinical exams of epilepsy patients. Our code and the normative\nimage dataset are available.","main_category":"eess.IV","categories":"eess.IV,cs.AI","published":"2025-05-12T09:00:03Z"}
{"aid":"http://arxiv.org/abs/2505.07372v1","title":"Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and\n  Synthetic Data","summary":"This paper presents a novel methodology for enhancing Automated Program\nRepair (APR) through synthetic data generation utilizing Large Language Models\n(LLMs). Current APR systems are constrained by the limited availability of\nhigh-quality training data encompassing diverse bug types across multiple\nprogramming languages. The proposed approach addresses this limitation through\na two-phase process: a synthetic sample generation followed by a rigorous\nquality assessment. Multiple state-of-the-art LLMs were employed to generate\napproximately 30,000 paired examples of buggy and fixed code across 12\nprogramming languages and 13 bug categories. Subsequently, these samples\nunderwent cross-model evaluation against five criteria: correctness, code\nquality, security, performance, and completeness. Experimental evaluation on\nthe VulRepair test set dataset showed statistically significant improvements in\nPerfect Prediction rates, with the quality-filtered synthetic dataset\noutperforming both baseline and real-world commit data configurations in\ncertain scenarios. The methodology was validated through rigorous statistical\ntesting, including ANOVA and post-hoc Tukey's Honest Significant Difference\nanalysis. Furthermore, the best-performing configurations surpassed existing\nsystems despite using a less computationally intensive decoding strategy. This\nresearch establishes a self-bootstrapping paradigm in which LLMs generate and\nevaluate their own training data, potentially transforming approaches to data\nscarcity across software engineering tasks and advancing the development of\nrobust, adaptable tools for automated code maintenance.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-05-12T09:14:20Z"}
{"aid":"http://arxiv.org/abs/2505.07375v1","title":"Boosting Global-Local Feature Matching via Anomaly Synthesis for\n  Multi-Class Point Cloud Anomaly Detection","summary":"Point cloud anomaly detection is essential for various industrial\napplications. The huge computation and storage costs caused by the increasing\nproduct classes limit the application of single-class unsupervised methods,\nnecessitating the development of multi-class unsupervised methods. However, the\nfeature similarity between normal and anomalous points from different class\ndata leads to the feature confusion problem, which greatly hinders the\nperformance of multi-class methods. Therefore, we introduce a multi-class point\ncloud anomaly detection method, named GLFM, leveraging global-local feature\nmatching to progressively separate data that are prone to confusion across\nmultiple classes. Specifically, GLFM is structured into three stages: Stage-I\nproposes an anomaly synthesis pipeline that stretches point clouds to create\nabundant anomaly data that are utilized to adapt the point cloud feature\nextractor for better feature representation. Stage-II establishes the global\nand local memory banks according to the global and local feature distributions\nof all the training data, weakening the impact of feature confusion on the\nestablishment of the memory bank. Stage-III implements anomaly detection of\ntest data leveraging its feature distance from global and local memory banks.\nExtensive experiments on the MVTec 3D-AD, Real3D-AD and actual industry parts\ndataset showcase our proposed GLFM's superior point cloud anomaly detection\nperformance. The code is available at\nhttps://github.com/hustCYQ/GLFM-Multi-class-3DAD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T09:19:25Z"}
{"aid":"http://arxiv.org/abs/2505.07382v1","title":"Charge transfer between van der Waals coupled metallic 2D layers","summary":"Van der Waals heterostructures have become a rapidly growing field in\ncondensed matter research, offering a platform to engineer novel quantum\nsystems by stacking different two-dimensional (2D) materials. A diverse range\nof material combinations, including hexagonal boron nitride, transition metal\ndichalcogenides and graphene, with electronic properties spanning from\ninsulating to semiconducting, metallic, and semimetallic, have been explored to\ntune the properties of these heterostacks. However, understanding the\ninteractions and charge transfer between the stacked layers remains\nchallenging, particularly when more than two layers are involved. In this\nstudy, we investigate the charge transfer in a\npotassium-adlayer/graphene/lead-monolayer heterostructure stacked on a SiC\nsubstrate. Using synchrotron-based angle-resolved photoemission spectroscopy,\nwe analyze the band structure of each layer, focusing on the charge transfer\nfrom K to the underlying 2D layers. Since K forms a $(2 \\times 2)$ overlayer\nwith respect to graphene, the amount of charge carriers donated by K can be\ndetermined. Our findings reveal that adsorption of K not only leads to a\nsignificant $n$-doping of the adjacent graphene layer but also to an electron\ntransfer into the Pb monolayer. Remarkably, $\\approx 44\\%$ of the electrons\ndonated by the K adlayer are transferred into its second nearest neighbouring\nlayer, i.e. Pb, while $\\approx 56\\%$ remain in the graphene.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-05-12T09:27:38Z"}
{"aid":"http://arxiv.org/abs/2505.07384v1","title":"Anti-windup design for internal model online constrained optimization","summary":"This paper proposes a novel algorithmic design procedure for online\nconstrained optimization grounded in control-theoretic principles. By\nintegrating the Internal Model Principle (IMP) with an anti-windup compensation\nmechanism, the proposed Projected-Internal Model Anti-Windup (P-IMAW) gradient\ndescent exploits a partial knowledge of the temporal evolution of the cost\nfunction to enhance tracking performance. The algorithm is developed through a\nstructured synthesis procedure: first, a robust controller leveraging the IMP\nensures asymptotic convergence in the unconstrained setting. Second, an\nanti-windup augmentation guarantees stability and performance in the presence\nof the projection operator needed to satisfy the constraints. The effectiveness\nof the proposed approach is demonstrated through numerical simulations\ncomparing it against other classical techniques.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-05-12T09:29:36Z"}
{"aid":"http://arxiv.org/abs/2505.07396v1","title":"TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin\n  Benchmark Dataset","summary":"Urban Digital Twins (UDTs) have become essential for managing cities and\nintegrating complex, heterogeneous data from diverse sources. Creating UDTs\ninvolves challenges at multiple process stages, including acquiring accurate 3D\nsource data, reconstructing high-fidelity 3D models, maintaining models'\nupdates, and ensuring seamless interoperability to downstream tasks. Current\ndatasets are usually limited to one part of the processing chain, hampering\ncomprehensive UDTs validation. To address these challenges, we introduce the\nfirst comprehensive multimodal Urban Digital Twin benchmark dataset: TUM2TWIN.\nThis dataset includes georeferenced, semantically aligned 3D models and\nnetworks along with various terrestrial, mobile, aerial, and satellite\nobservations boasting 32 data subsets over roughly 100,000 $m^2$ and currently\n767 GB of data. By ensuring georeferenced indoor-outdoor acquisition, high\naccuracy, and multimodal data integration, the benchmark supports robust\nanalysis of sensors and the development of advanced reconstruction methods.\nAdditionally, we explore downstream tasks demonstrating the potential of\nTUM2TWIN, including novel view synthesis of NeRF and Gaussian Splatting, solar\npotential analysis, point cloud semantic segmentation, and LoD3 building\nreconstruction. We are convinced this contribution lays a foundation for\novercoming current limitations in UDT creation, fostering new research\ndirections and practical solutions for smarter, data-driven urban environments.\nThe project is available under: https://tum2t.win","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-05-12T09:48:32Z"}
{"aid":"http://arxiv.org/abs/2505.07408v1","title":"Energy personas in Danish households","summary":"Technologies to monitor the provision of renewable energy are part of\nemerging technologies to help address the discrepancy between renewable energy\nproduction and its related usage in households. This paper presents various\nways householders use a technological artifact for the real-time monitoring of\nrenewable energy provision. Such a monitoring thus affords householders with an\nopportunity to adjust their energy consumption according to renewable energy\nprovision. In Denmark, Ewii, previously Barry, is a Danish energy supplier\nwhich provides householders with an opportunity to monitor energy sources in\nreal time through a technological solution of the same name. This paper use\nprovision afforded by Ewii as a case for exploring how householders organize\nthemselves to use a technological artefact that supports the monitoring of\nenergy and its related usage. This study aims to inform technology design\nthrough the derivation of four personas. The derived personas highlight the\ndifferences in energy monitoring practices for the householders and their\nengagement. These personas are characterised as dedicated, organised, sporadic,\nand convenient. Understanding these differences in energy monitoring practice\nusing the technological artefact form a solid element in the design of future\nenergy technologies that interfere with the everyday practices and energy\nconsumption for households. This is paramount for future energy related\ntechnology design, and for the clarification of usage assumptions that are\nembedded in the rollout of energy related technology as a country such as\nDenmark moves through its green transition.","main_category":"eess.SY","categories":"eess.SY,cs.CY,cs.SY","published":"2025-05-12T10:02:03Z"}
{"aid":"http://arxiv.org/abs/2505.07424v1","title":"Property FA for random $\\ell$-gonal groups","summary":"In the binomial $\\ell$-gonal model for random groups, where the random\nrelations all have fixed length $\\ell\\geq 3$ and the number of generators goes\nto infinity, we establish a double threshold near density $d=\\frac{1}{\\ell}$\nwhere the group goes from being free to having Serre's property FA.\n  As a consequence, random $\\ell$-gonal groups at densities $\\frac{1}{\\ell} <\nd< \\frac{1}{2}$ have boundaries homeomorphic to the Menger sponge, and\n$\\frac{1}{\\ell}$ is also the threshold for finiteness of $\\mathrm{Out}(G)$. We\nalso see that the thresholds for property FA and Kazhdan's property (T) differ\nwhen $\\ell \\geq 4$.\n  Our methods are inspired by work of Antoniuk-Luczak-\\'Swi\\k{a}tkowski and\nDahmani-Guirardel-Przytycki.","main_category":"math.GR","categories":"math.GR,math.PR","published":"2025-05-12T10:27:29Z"}
{"aid":"http://arxiv.org/abs/2505.07438v1","title":"Traces of wobbling accretion disk in X-ray pulsar Her X-1 from\n  observations of the ART-XC telescope of the SRG observatory","summary":"Long uninterrupted observations of the X-ray binary system Her X-1 were\nperformed with the Mikhail Pavlinsky ART-XC telescope of the\nSpectrum-R\\\"ontgen-Gamma (SRG) X-ray Observatory in the 4--25 keV energy range\nwith a total exposure of about two days around the main turn-on of the X-ray\nsource. We present the results of timing and spectral analysis of these\nobservations. The opening of the X-ray source is determined to occur at the\norbital phase $\\phi_{b}\\approx 0.25$. The analysis of the X-ray light curve\nreveals a first direct observational evidence of the nutation of a tilted\nprecessing accretion disk with a period of $\\simeq0.87$ days. The appearance of\nX-ray pulsations near the orbital phase $\\phi_{b}\\simeq 0.77$ prior to the main\nturn-on at the maximum of the nutation variability has been also detected.\nDuring the X-ray eclipse, a non-zero X-ray flux is measured, which is\npresumably associated with scattering of an X-ray emission in a hot corona\naround the optical star illuminated by the X-rays from the central neutron\nstar. An increase in the X-ray flux after the main turn-on can be described by\nthe passage of the radiation from the central source through a scattering\ncorona above the precessing accretion disk.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-12T11:01:36Z"}
{"aid":"http://arxiv.org/abs/2505.07466v1","title":"On inverse dynamical and spectral problems for the wave and\n  Schrdinger equations on finite trees. The leaf peeling method","summary":"Interest in inverse dynamical, spectral and scattering problems for\ndifferential equations on graphs is motivated by possible applications to\nnano-electronics and quantum waveguides and by a variety of other classical and\nquantum applications. Recently a new effective leaf peeling method has been\nproposed by S. Avdonin and P. Kurasov \\cite{AK} for solving inverse problems on\ntrees (graphs without cycles). It allows recalculating efficiently the inverse\ndata from the original tree to the smaller trees, `removing' leaves step by\nstep up to the rooted edge. In this paper we describe the main step of the\nspectral and dynamical versions of the peeling algorithm -- recalculating the\ninverse data for the `peeled tree'.","main_category":"math.AP","categories":"math.AP,math.CA,math.SP","published":"2025-05-12T11:54:34Z"}
{"aid":"http://arxiv.org/abs/2505.07467v1","title":"Center-vortex semiclassics with non-minimal 't Hooft fluxes on\n  $\\mathbb{R}^2\\times T^2$ and center stabilization at large $N$","summary":"We consider the semiclassical description of confinement for $4$d $SU(N)$\nYang-Mills theory on small $\\mathbb{R}^2\\times T^2$ with non-minimal 't Hooft\ntwist $p$ with $\\gcd(N,p)=1$. For this purpose, we construct the self-dual\ncenter vortex for non-minimal 't Hooft twists from the Kraan-van Baal-Lee-Lu-Yi\n(KvBLLY) monopoles by using the $3$d Abelianized description of $SU(N)$ gauge\nfields on $\\mathbb{R}^3\\times S^1$ with nontrivial holonomy backgrounds. This\nconstruction shows the self-dual vortex has (1) the fractional magnetic charge\n$q/N$ with $pq=1$ mod $N$, (2) the fractional topological charge $1/N$, and (3)\nthe fractional instanton action $S_{\\mathrm{YM}}=8\\pi^2/(Ng^2)$. The\nconfinement vacua for $NL\\Lambda\\ll 1$ can be described by the dilute gas\napproximation of center vortices, and we give the semiclassical formula for the\n$\\theta$ dependence and confining string tensions. We apply this result to\nunderstand the suitable choice of the twist $p$ for center stabilization at\nlarge $N$. In particular, we test the proposal using the Fibonacci sequence,\n$N=F_{n+2}$ and $p=F_n$, suggested in studies of the twisted Eguchi-Kawai\nmodel, from the viewpoint of the $1$-form and $0$-form center symmetries.","main_category":"hep-th","categories":"hep-th","published":"2025-05-12T11:54:59Z"}
{"aid":"http://arxiv.org/abs/2505.07470v1","title":"Unraveling the impact of competing interactions on non-equilibrium\n  colloidal gelation","summary":"Competing interactions stabilize exotic mesoscopic structures, yet the\nmicroscopic mechanisms by which they influence non-equilibrium processes\nleading to disordered states remain largely unexplored, despite their critical\nrole in self-assembly across a range of nanomaterials and biological systems.\nHere, we numerically investigate the structural evolution in charged colloidal\nmodel systems, where short-range attractions and long-range repulsions compete.\nWe reveal that these two interaction scales drive sequential ordering within\nclusters, from tetrahedra motifs to linear aggregates with chiral order. This\nprocess disrupts early-stage percolated networks, resulting in reentrant\nbehavior -- a dynamic transition from disordered cluster to network to chiral\nrigid cluster. On the other hand, the cluster-elastic network boundary in the\nfinal state is governed by isostatic percolation, which slows structural\nrearrangements, preserves branching points, and sustains a long-lived network.\nThe resulting structure consist of rigid Bernal spiral-like branches connected\nthrough flexible branching points lacking order. These insights advance our\nmicroscopic understanding of out-of-equilibrium ordering driven by competing\ninteractions, particularly phenomena like temporally delayed frustration\nreflecting different length scales of competing interactions. The mechanisms\nidentified here may play a crucial role in mesoscale self-organization across\nsoft materials, from nanoparticle assemblies to biological gels and\ncytoskeletal networks. Understanding how competing interactions regulate\nstructure and dynamics could guide the design of adaptive materials with\ntunable mechanical properties and offer new perspectives on biological\nprocesses such as cytoplasmic organization and cellular scaffolding.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-05-12T12:01:15Z"}
{"aid":"http://arxiv.org/abs/2505.07472v1","title":"Solar Orbiter's 2024 Major Flare Campaigns: An Overview","summary":"Solar Orbiter conducted a series of flare-optimised observing campaigns in\n2024 utilising the Major Flare Solar Orbiter Observing Plan (SOOP). Dedicated\nobservations were performed during two distinct perihelia intervals in\nMarch/April and October, during which over 22 flares were observed, ranging\nfrom B- to M-class. These campaigns leveraged high-resolution and high-cadence\nobservations from the mission's remote-sensing suite, including the\nHigh-Resolution EUV Imager (EUI/HRI_EUV), the Spectrometer/Telescope for\nImaging X-rays (STIX), the Spectral Imaging of the Coronal Environment (SPICE)\nspectrometer, and the High Resolution Telescope of the Polarimetric and\nHelioseismic Imager (PHI/HRT), as well as coordinated ground-based and\nEarth-orbiting observations. EUI/HRI_EUV operating in short-exposure modes,\nprovided two-second-cadence, non-saturated EUV images, revealing structures and\ndynamics on scales not previously observed. Simultaneously, STIX captured hard\nX-ray imaging and spectroscopy of accelerated electrons, while SPICE acquired\nEUV slit spectroscopy to probe chromospheric and coronal responses. Together,\nthese observations offer an unprecedented view of magnetic reconnection, energy\nrelease, particle acceleration, and plasma heating across a broad range of\ntemperatures and spatial scales. These campaigns have generated a rich dataset\nthat will be the subject of numerous future studies addressing Solar Orbiter's\ntop-level science goal: \"How do solar eruptions produce energetic particle\nradiation that fills the heliosphere?\". This paper presents the scientific\nmotivations, operational planning, and observational strategies behind the 2024\nflare campaigns, along with initial insights into the observed flares. We also\ndiscuss lessons learned for optimizing future Solar Orbiter Major Flare\ncampaigns and provide a resource for researchers aiming to utilize these unique\nobservations.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-05-12T12:05:45Z"}
{"aid":"http://arxiv.org/abs/2505.07480v1","title":"Decoherence of quantum superpositions in near-extremal\n  Reissner-Nordstrm black holes with quantum gravity corrections","summary":"We study the quantum gravity corrected decoherence of quantum superpositions\nin the near-extremal Reissner-Nordstr\\\"om black holes. By employing the\neffective field theory approach, we model the black hole as a quantum system\ncoupled to an external source via a scalar field, and derive the relation\nbetween the decoherence rate and the two-point correlation function of the\noperators acting on the black quantum system. By utilizing the low-energy\nSchwarzian effective theory, which captures the boundary dynamics of the\n$AdS_2$ near-horizon geometry of the near-extremal Reissner-Nordstr\\\"om black\nholes, we compute the decoherence rate both in the microcanonical and canonical\nensembles. We find that in the microcanonical ensemble, where the black hole\nenergy is fixed, quantum gravity corrections do not modify the decoherence rate\ncompared to the semiclassical prediction. However, in the canonical ensemble,\nwhere the black hole is in a thermal equilibrium state, quantum gravitational\neffects significantly enhance the decoherence rate at low temperatures. Our\nresults demonstrate that even in the near-extremal limit where Hawking\nradiation is suppressed, quantum gravitational fluctuations can strongly\ninfluence the coherence of nearby quantum systems.","main_category":"hep-th","categories":"hep-th,gr-qc,quant-ph","published":"2025-05-12T12:12:22Z"}
{"aid":"http://arxiv.org/abs/2505.07488v1","title":"Higgs Inflation with Vector-Like Quark Stabilisation and the ACT\n  spectral index","summary":"Recently, the Atacama Cosmology Telescope (ACT) collaboration has reported a\nscalar spectral index $n_s~=~0.9743~\\pm~0.0034$. This is substantially larger\nthan the classical prediction of Higgs Inflation, $n_s \\approx 0.965$, which is\n2.74$\\sigma$ below the ACT mean value. We show that when an otherwise\nmetastable Standard Model Higgs Inflation potential is stabilised by the\naddition of vector-like quark pairs and the potential is renormalised in the\nJordan frame, the value of $n_s$ is generally larger than 0.965 and can explain\nthe ACT observation. As an example, assuming the 2022 PDG direct measurement\ncentral value for the t quark mass, $m_{t} = 172.69$ GeV, and central values\nfor the SM inputs to the renormalisation group equations, we obtain $n_s =\n0.9792 - 0.9844$ for the case of three isosinglet vector-like B quarks with\nmass $m_{Q}$ in the range 1-3 TeV, with the lowest value of the $n_s$ range\nbeing 1.44$\\sigma$ above the ACT mean value. The model predicts primordial\ngravitational wave with tensor-to-scalar ratio $r = 7.87 \\times 10^{-3} - 1.21\n\\times 10^{-2}$ for $m_{Q} =$ 1-3 TeV, which will be easily observable in\nforthcoming CMB experiments. Observation of vector-like quarks of mass close to\n1 TeV mass combined with a large tensor-to-scalar ratio $r \\sim 0.1$ would\nsupport the model.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-05-12T12:20:22Z"}
{"aid":"http://arxiv.org/abs/2505.07489v1","title":"Beyond the Octupole Approximation in Non-Collinear Antiferromagnetic\n  Thin Films","summary":"Noncollinear antiferromagnets offer much promise for antiferromagnetic\nspintronics and neuromorphic applications with a plethora of functional\nproperties surpassing many competing magnetic systems. Films grown on\nmismatched substrates can relieve strain by the creation of slip-plane defects\n- and recently we have shown that these defects can manipulate global physical\nproperties important for application. Here we demonstrate that post growth\nannealing results in near-defect-free, structurally robust films that allow the\nmagnetic order thermal evolution to change as a function of film thickness.\nStrong spin-lattice coupling ensures that substrate clamping limits the ability\nof thinner films to transform as they are cooled to low temperature. However,\nbeyond a certain thickness, films no longer suffer this constraint, revealing\nthe extraordinary transformations that provide the pathway for spin to reach\nthe lowest energy state. We show that this transition cannot be explained by\nthe previously established mechanism of spin rotations in the (111) plane, and\nwe calculate that rotations along the chirality-inverting [1-10] direction may\nbe preferable under certain conditions. Our work suggests that chirality\ninverting rotations in these materials may have been previously overlooked in\nstudies adopting the so-called octupole approximation of the net magnetic\nmoment. This enriches the field of antiferromagnetic spintronics, raising the\npossibility of device designs with thickness engineered to exploit switching of\nchirality.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-12T12:20:41Z"}
{"aid":"http://arxiv.org/abs/2505.07494v1","title":"Machine Learning Assisted Long-Range Wireless Power Transfer","summary":"Near-field magnetic resonance wireless power transfer (WPT) technology has\ngarnered significant attention due to its broad application prospects in\nmedical implants, electric vehicles, and robotics. Addressing the challenges\nfaced by traditional WPT systems in frequency optimization and sensitivity to\nenvironmental disturbances, this study innovatively applies the gradient\ndescent optimization algorithm to enhance a system with topological\ncharacteristics. Experimental results demonstrate that the machine\nlearning-optimized Su-Schrieffer-Heeger (SSH)-like chain exhibits exceptional\nperformance in transfer efficiency and system robustness. This achievement\nintegrates non-Hermitian physics, topological physics, and machine learning,\nopening up new avenues and showcasing immense potential for the development of\nhigh-performance near-field wave functional devices.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-05-12T12:23:41Z"}
{"aid":"http://arxiv.org/abs/2505.07495v1","title":"Translating the Grievance Dictionary: a psychometric evaluation of\n  Dutch, German, and Italian versions","summary":"This paper introduces and evaluates three translations of the Grievance\nDictionary, a psycholinguistic dictionary for the analysis of violent,\nthreatening or grievance-fuelled texts. Considering the relevance of these\nthemes in languages beyond English, we translated the Grievance Dictionary to\nDutch, German, and Italian. We describe the process of automated translation\nsupplemented by human annotation. Psychometric analyses are performed,\nincluding internal reliability of dictionary categories and correlations with\nthe LIWC dictionary. The Dutch and German translations perform similarly to the\noriginal English version, whereas the Italian dictionary shows low reliability\nfor some categories. Finally, we make suggestions for further validation and\napplication of the dictionary, as well as for future dictionary translations\nfollowing a similar approach.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-12T12:27:38Z"}
{"aid":"http://arxiv.org/abs/2505.07496v1","title":"DocVXQA: Context-Aware Visual Explanations for Document Question\n  Answering","summary":"We propose DocVXQA, a novel framework for visually self-explainable document\nquestion answering. The framework is designed not only to produce accurate\nanswers to questions but also to learn visual heatmaps that highlight\ncontextually critical regions, thereby offering interpretable justifications\nfor the model's decisions. To integrate explanations into the learning process,\nwe quantitatively formulate explainability principles as explicit learning\nobjectives. Unlike conventional methods that emphasize only the regions\npertinent to the answer, our framework delivers explanations that are\n\\textit{contextually sufficient} while remaining\n\\textit{representation-efficient}. This fosters user trust while achieving a\nbalance between predictive performance and interpretability in DocVQA\napplications. Extensive experiments, including human evaluation, provide strong\nevidence supporting the effectiveness of our method. The code is available at\nhttps://github.com/dali92002/DocVXQA.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-05-12T12:30:16Z"}
{"aid":"http://arxiv.org/abs/2505.07504v1","title":"Revisit Of Meromorphic Convex Functions","summary":"Our primary aim is to explore a sufficient condition for the class of\nmeromorphically convex functions of order $\\alpha$, where $0 \\leq \\alpha < 1$.\nThe investigation will focus on studying a class of continuous functions\ndefined on $[0,1)$, and analyzing the properties of the Schwarzian norm of\nlocally univalent meromorphic functions. Moreover, a new subclass of\nmeromorphic functions is also introduced, and some of its characteristics are\nexamined.","main_category":"math.CV","categories":"math.CV","published":"2025-05-12T12:40:32Z"}
{"aid":"http://arxiv.org/abs/2505.07510v1","title":"Towards a test of the Born rule in high-energy collisions","summary":"We consider how the Born rule, a fundamental principle of quantum mechanics,\ncould be tested for particles created on the shortest timescales\n($\\sim10^{-25}\\,\\mathrm{s}$) currently accessible at high-energy colliders. We\nfocus on targeted tests of the Born rule for spin or polarisation\nprobabilities, which offer a particularly clean experimental signal, and which\ncan be described by a simple hidden-variables model of two-state systems\nproposed by Bell. These probabilities test a remarkable feature of the quantum\nformalism, whereby expectation values for incompatible experiments are linearly\nrelated. Born-rule violations can be parameterised by nonlinear expectation\nvalues for quantum measurements of spin or polarisation, along with anomalies\nin ensemble averages, which are to be constrained by experiment. Notable\nexperiments considered here include the recent detection of single photons from\ntop-quark decay, and the indirect measurement of tau-lepton polarisation.\nRepurposing these experiments as tests of the Born rule, however, presents\nseveral challenges, which are discussed in this paper.","main_category":"hep-ph","categories":"hep-ph,hep-th,quant-ph","published":"2025-05-12T12:47:47Z"}
{"aid":"http://arxiv.org/abs/2505.07512v1","title":"ToolACE-DEV: Self-Improving Tool Learning via Decomposition and\n  EVolution","summary":"The tool-using capability of large language models (LLMs) enables them to\naccess up-to-date external information and handle complex tasks. Current\napproaches to enhancing this capability primarily rely on distilling advanced\nmodels by data synthesis. However, this method incurs significant costs\nassociated with advanced model usage and often results in data compatibility\nissues, led by the high discrepancy in the knowledge scope between the advanced\nmodel and the target model. To address these challenges, we propose\nToolACE-DEV, a self-improving framework for tool learning. First, we decompose\nthe tool-learning objective into sub-tasks that enhance basic tool-making and\ntool-using abilities. Then, we introduce a self-evolving paradigm that allows\nlightweight models to self-improve, reducing reliance on advanced LLMs.\nExtensive experiments validate the effectiveness of our approach across models\nof varying scales and architectures.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-12T12:48:30Z"}
{"aid":"http://arxiv.org/abs/2505.07513v1","title":"An Approximation Framework for Subspace-based Methods in Spectral\n  Analysis with Accuracy Guarantees","summary":"A mathematical framework for the approximation of eigenvalues of self-adjoint\noperators through subspace-based methods is presented.\n  The framework contains spectral inequalities that extend to unbounded\noperators and account for multiple error sources.\n  We include conceptual remarks, on how such framework addresses contemporary\nchallenges towards a more complete approximation theory for quantum physics.\n  Further analysis considers the computational operation of subspace-based\nmethods and proposes new numerical practices.\n  In particular, analytical guarantees on dimension detection of spectral\nsubspaces in the presence of noise are introduced.\n  The generality of the framework invites application to a broad class of\nnumerical methods, and its utility is demonstrated through recent advances in\nsignal processing.","main_category":"math.NA","categories":"math.NA,cs.NA,math-ph,math.MP,math.SP,G.1.2","published":"2025-05-12T12:51:35Z"}
{"aid":"http://arxiv.org/abs/2505.07516v1","title":"Average-Reward Maximum Entropy Reinforcement Learning for Global Policy\n  in Double Pendulum Tasks","summary":"This report presents our reinforcement learning-based approach for the\nswing-up and stabilisation tasks of the acrobot and pendubot, tailored\nspecifcially to the updated guidelines of the 3rd AI Olympics at ICRA 2025.\nBuilding upon our previously developed Average-Reward Entropy Advantage Policy\nOptimization (AR-EAPO) algorithm, we refined our solution to effectively\naddress the new competition scenarios and evaluation metrics. Extensive\nsimulations validate that our controller robustly manages these revised tasks,\ndemonstrating adaptability and effectiveness within the updated framework.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-12T12:53:57Z"}
{"aid":"http://arxiv.org/abs/2505.07522v1","title":"Byam: Fixing Breaking Dependency Updates with Large Language Models","summary":"Application Programming Interfaces (APIs) facilitate the integration of\nthird-party dependencies within the code of client applications. However,\nchanges to an API, such as deprecation, modification of parameter names or\ntypes, or complete replacement with a new API, can break existing client code.\nThese changes are called breaking dependency updates; It is often tedious for\nAPI users to identify the cause of these breaks and update their code\naccordingly. In this paper, we explore the use of Large Language Models (LLMs)\nto automate client code updates in response to breaking dependency updates. We\nevaluate our approach on the BUMP dataset, a benchmark for breaking dependency\nupdates in Java projects. Our approach leverages LLMs with advanced prompts,\nincluding information from the build process and from the breaking dependency\nanalysis. We assess effectiveness at three granularity levels: at the build\nlevel, the file level, and the individual compilation error level. We\nexperiment with five LLMs: Google Gemini-2.0 Flash, OpenAI GPT4o-mini, OpenAI\no3-mini, Alibaba Qwen2.5-32b-instruct, and DeepSeek V3. Our results show that\nLLMs can automatically repair breaking updates. Among the considered models,\nOpenAI's o3-mini is the best, able to completely fix 27% of the builds when\nusing prompts that include contextual information such as the buggy line, API\ndifferences, error messages, and step-by-step reasoning instructions. Also, it\nfixes 78% of the individual compilation errors. Overall, our findings\ndemonstrate the potential for LLMs to fix compilation errors due to breaking\ndependency updates, supporting developers in their efforts to stay up-to-date\nwith changes in their dependencies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-12T13:03:26Z"}
{"aid":"http://arxiv.org/abs/2505.07525v1","title":"Adaptive Latent-Space Constraints in Personalized FL","summary":"Federated learning (FL) has become an effective and widely used approach to\ntraining deep learning models on decentralized datasets held by distinct\nclients. FL also strengthens both security and privacy protections for training\ndata. Common challenges associated with statistical heterogeneity between\ndistributed datasets have spurred significant interest in personalized FL (pFL)\nmethods, where models combine aspects of global learning with local modeling\nspecific to each client's unique characteristics. In this work, the efficacy of\ntheoretically supported, adaptive MMD measures within the Ditto framework, a\nstate-of-the-art technique in pFL, are investigated. The use of such measures\nsignificantly improves model performance across a variety of tasks, especially\nthose with pronounced feature heterogeneity. While the Ditto algorithm is\nspecifically considered, such measures are directly applicable to a number of\nother pFL settings, and the results motivate the use of constraints tailored to\nthe various kinds of heterogeneity expected in FL systems.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-12T13:08:54Z"}
{"aid":"http://arxiv.org/abs/2505.07529v1","title":"On Greenberg's generalized conjecture for families of number fields","summary":"For a number field $k$ and an odd prime $p$, let $\\tilde{k}$ be the\ncompositum of all the ${\\mathbb Z}_p$-extensions of $k$, $\\tilde{\\Lambda }$ the\nassociated Iwasawa algebra, and $X(\\tilde{k})$ the Galois group over\n$\\tilde{k}$ of the maximal abelian unramified pro-$p$-extension of $\\tilde{k}$.\nGreenberg's generalized conjecture (GGC for short) asserts that the\n$\\tilde{\\Lambda}$-module $X(\\tilde{k})$ is pseudo-null. Very few theoritical\nresults toward GGC are known. We show here that for an imaginary k, GGC is\nimplied by certain pseudo-nullity conditions imposed on a special ${\\mathbb\nZ}^2_p$-extension of $k$, and these conditions are partially or entirely\nfullfilled by certain families of number fields.","main_category":"math.NT","categories":"math.NT","published":"2025-05-12T13:11:31Z"}
{"aid":"http://arxiv.org/abs/2505.07530v1","title":"FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation\n  with Document and Live Images","summary":"Synthetic face datasets are increasingly used to overcome the limitations of\nreal-world biometric data, including privacy concerns, demographic imbalance,\nand high collection costs. However, many existing methods lack fine-grained\ncontrol over identity attributes and fail to produce paired,\nidentity-consistent images under structured capture conditions. We introduce\nFLUXSynID, a framework for generating high-resolution synthetic face datasets\nwith user-defined identity attribute distributions and paired document-style\nand trusted live capture images. The dataset generated using the FLUXSynID\nframework shows improved alignment with real-world identity distributions and\ngreater inter-set diversity compared to prior work. The FLUXSynID framework for\ngenerating custom datasets, along with a dataset of 14,889 synthetic\nidentities, is publicly released to support biometric research, including face\nrecognition and morphing attack detection.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T13:12:33Z"}
{"aid":"http://arxiv.org/abs/2505.07531v1","title":"QuantX: A Framework for Hardware-Aware Quantization of Generative AI\n  Workloads","summary":"We present QuantX: a tailored suite of recipes for LLM and VLM quantization.\nIt is capable of quantizing down to 3-bit resolutions with minimal loss in\nperformance. The quantization strategies in QuantX take into account\nhardware-specific constraints to achieve efficient dequantization during\ninference ensuring flexible trade-off between runtime speed, memory requirement\nand model accuracy. Our results demonstrate that QuantX achieves performance\nwithin 6% of the unquantized model for LlaVa-v1.6 quantized down to 3-bits for\nmultiple end user tasks and outperforms recently published state-of-the-art\nquantization techniques. This manuscript provides insights into the LLM\nquantization process that motivated the range of recipes and options that are\nincorporated in QuantX.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-12T13:13:06Z"}
{"aid":"http://arxiv.org/abs/2505.07577v1","title":"From raw affiliations to organization identifiers","summary":"Accurate affiliation matching, which links affiliation strings to\nstandardized organization identifiers, is critical for improving research\nmetadata quality, facilitating comprehensive bibliometric analyses, and\nsupporting data interoperability across scholarly knowledge bases. Existing\napproaches fail to handle the complexity of affiliation strings that often\ninclude mentions of multiple organizations or extraneous information. In this\npaper, we present AffRo, a novel approach designed to address these challenges,\nleveraging advanced parsing and disambiguation techniques. We also introduce\nAffRoDB, an expert-curated dataset to systematically evaluate affiliation\nmatching algorithms, ensuring robust benchmarking. Results demonstrate the\neffectiveness of AffRp in accurately identifying organizations from complex\naffiliation strings.","main_category":"cs.DL","categories":"cs.DL,cs.IR","published":"2025-05-12T13:57:47Z"}
{"aid":"http://arxiv.org/abs/2505.07593v1","title":"Gate modulation and interface engineering on Coulomb blockade in open\n  superconducting islands","summary":"Mesoscopic Coulomb blockade (MCB) is recognized as a phase-coherent variant\nof the conventional Coulomb blockade that arises in systems with open contacts.\nIn open quantum dots, MCB is enhanced by a decrease in background conductance.\nThis occurs because the reduction in coupling strength between the quantum dot\nand the outer reservoir renders the system more closed, thereby facilitating\nthe emergence of conventional Coulomb blockade. In this work, we demonstrate\nthat the MCB in open superconducting islands exhibits an different correlation\nwith coupling strength compared to open quantum dots. Specifically, a decrease\nin background conductance may result in a weakening of the MCB. This\nobservation indicates that the MCB in superconducting islands originates from\nthe presence of superconducting-normal interfaces.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-05-12T14:19:01Z"}
{"aid":"http://arxiv.org/abs/2505.07594v1","title":"Finite-Sample-Based Reachability for Safe Control with Gaussian Process\n  Dynamics","summary":"Gaussian Process (GP) regression is shown to be effective for learning\nunknown dynamics, enabling efficient and safety-aware control strategies across\ndiverse applications. However, existing GP-based model predictive control\n(GP-MPC) methods either rely on approximations, thus lacking guarantees, or are\noverly conservative, which limits their practical utility. To close this gap,\nwe present a sampling-based framework that efficiently propagates the model's\nepistemic uncertainty while avoiding conservatism. We establish a novel sample\ncomplexity result that enables the construction of a reachable set using a\nfinite number of dynamics functions sampled from the GP posterior. Building on\nthis, we design a sampling-based GP-MPC scheme that is recursively feasible and\nguarantees closed-loop safety and stability with high probability. Finally, we\nshowcase the effectiveness of our method on two numerical examples,\nhighlighting accurate reachable set over-approximation and safe closed-loop\nperformance.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY,math.OC","published":"2025-05-12T14:20:20Z"}
{"aid":"http://arxiv.org/abs/2505.07596v1","title":"Reinforced Internal-External Knowledge Synergistic Reasoning for\n  Efficient Adaptive Search Agent","summary":"Retrieval-augmented generation (RAG) is a common strategy to reduce\nhallucinations in Large Language Models (LLMs). While reinforcement learning\n(RL) can enable LLMs to act as search agents by activating retrieval\ncapabilities, existing ones often underutilize their internal knowledge. This\ncan lead to redundant retrievals, potential harmful knowledge conflicts, and\nincreased inference latency. To address these limitations, an efficient and\nadaptive search agent capable of discerning optimal retrieval timing and\nsynergistically integrating parametric (internal) and retrieved (external)\nknowledge is in urgent need. This paper introduces the Reinforced\nInternal-External Knowledge Synergistic Reasoning Agent (IKEA), which could\nindentify its own knowledge boundary and prioritize the utilization of internal\nknowledge, resorting to external search only when internal knowledge is deemed\ninsufficient. This is achieved using a novel knowledge-boundary aware reward\nfunction and a knowledge-boundary aware training dataset. These are designed\nfor internal-external knowledge synergy oriented RL, incentivizing the model to\ndeliver accurate answers, minimize unnecessary retrievals, and encourage\nappropriate external searches when its own knowledge is lacking. Evaluations\nacross multiple knowledge reasoning tasks demonstrate that IKEA significantly\noutperforms baseline methods, reduces retrieval frequency significantly, and\nexhibits robust generalization capabilities.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-12T14:21:57Z"}
{"aid":"http://arxiv.org/abs/2505.07605v1","title":"Explosive growth of bistability in a cavity magnonic system","summary":"We conduct a theoretical investigation into explosive growth of bistability\nin a cavity magnonic system incorporating magnetic nonlinearity. In this\nsystem, the coupling between the magnon and photon generates the cavity magnon\npolaritons. When driving the photon-like polariton mode, the bistability can\nundergo a sudden transition with the increase of the driving power, resulting\nin an explosive growth of the bistable region by several times. Conversely,\ndriving the magnon-like polariton mode only gives rise to normal bistability.\nThis depends on whether the minimum driving power required to generate the\nbistability is non-monotonic with respect to the driving frequency. In\naddition, despite driving only the photon-like polariton mode, the photon- and\nmagnon-like polariton modes can show simultaneous explosive growth of the\nbistability in microwave transmission, owing to the light-matter interaction.\nOur research sheds light on the hidden side of the nonlinear cavity magnonic\nsystem and provides a potential application for cavity spintronic devices\nfounded on this novel feature.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-05-12T14:27:44Z"}
{"aid":"http://arxiv.org/abs/2505.07610v1","title":"Concept-Level Explainability for Auditing & Steering LLM Responses","summary":"As large language models (LLMs) become widely deployed, concerns about their\nsafety and alignment grow. An approach to steer LLM behavior, such as\nmitigating biases or defending against jailbreaks, is to identify which parts\nof a prompt influence specific aspects of the model's output. Token-level\nattribution methods offer a promising solution, but still struggle in text\ngeneration, explaining the presence of each token in the output separately,\nrather than the underlying semantics of the entire LLM response. We introduce\nConceptX, a model-agnostic, concept-level explainability method that identifies\nthe concepts, i.e., semantically rich tokens in the prompt, and assigns them\nimportance based on the outputs' semantic similarity. Unlike current\ntoken-level methods, ConceptX also offers to preserve context integrity through\nin-place token replacements and supports flexible explanation goals, e.g.,\ngender bias. ConceptX enables both auditing, by uncovering sources of bias, and\nsteering, by modifying prompts to shift the sentiment or reduce the harmfulness\nof LLM responses, without requiring retraining. Across three LLMs, ConceptX\noutperforms token-level methods like TokenSHAP in both faithfulness and human\nalignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for\nrandom edits and lower attack success rates from 0.463 to 0.242, outperforming\nattribution and paraphrasing baselines. While prompt engineering and\nself-explaining methods sometimes yield safer responses, ConceptX offers a\ntransparent and faithful alternative for improving LLM safety and alignment,\ndemonstrating the practical value of attribution-based explainability in\nguiding LLM behavior.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-12T14:31:51Z"}
{"aid":"http://arxiv.org/abs/2505.07620v1","title":"Higher-Order Convolution Improves Neural Predictivity in the Retina","summary":"We present a novel approach to neural response prediction that incorporates\nhigher-order operations directly within convolutional neural networks (CNNs).\nOur model extends traditional 3D CNNs by embedding higher-order operations\nwithin the convolutional operator itself, enabling direct modeling of\nmultiplicative interactions between neighboring pixels across space and time.\nOur model increases the representational power of CNNs without increasing their\ndepth, therefore addressing the architectural disparity between deep artificial\nnetworks and the relatively shallow processing hierarchy of biological visual\nsystems. We evaluate our approach on two distinct datasets: salamander retinal\nganglion cell (RGC) responses to natural scenes, and a new dataset of mouse RGC\nresponses to controlled geometric transformations. Our higher-order CNN (HoCNN)\nachieves superior performance while requiring only half the training data\ncompared to standard architectures, demonstrating correlation coefficients up\nto 0.75 with neural responses (against 0.80$\\pm$0.02 retinal reliability). When\nintegrated into state-of-the-art architectures, our approach consistently\nimproves performance across different species and stimulus conditions. Analysis\nof the learned representations reveals that our network naturally encodes\nfundamental geometric transformations, particularly scaling parameters that\ncharacterize object expansion and contraction. This capability is especially\nrelevant for specific cell types, such as transient OFF-alpha and transient ON\ncells, which are known to detect looming objects and object motion\nrespectively, and where our model shows marked improvement in response\nprediction. The correlation coefficients for scaling parameters are more than\ntwice as high in HoCNN (0.72) compared to baseline models (0.32).","main_category":"cs.CV","categories":"cs.CV,cs.LG,q-bio.NC","published":"2025-05-12T14:43:32Z"}
{"aid":"http://arxiv.org/abs/2505.07671v1","title":"Benchmarking Retrieval-Augmented Generation for Chemistry","summary":"Retrieval-augmented generation (RAG) has emerged as a powerful framework for\nenhancing large language models (LLMs) with external knowledge, particularly in\nscientific domains that demand specialized and dynamic information. Despite its\npromise, the application of RAG in the chemistry domain remains underexplored,\nprimarily due to the lack of high-quality, domain-specific corpora and\nwell-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a\ncomprehensive benchmark designed to systematically assess the effectiveness of\nRAG across a diverse set of chemistry-related tasks. The accompanying chemistry\ncorpus integrates heterogeneous knowledge sources, including scientific\nliterature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia\nentries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG\ntoolkit that supports five retrieval algorithms and eight LLMs. Using\nChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain\n-- achieving an average relative improvement of 17.4% over direct inference\nmethods. We further conduct in-depth analyses on retriever architectures,\ncorpus selection, and the number of retrieved passages, culminating in\npractical recommendations to guide future research and deployment of RAG\nsystems in the chemistry domain. The code and data is available at\nhttps://chemrag.github.io.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR","published":"2025-05-12T15:34:45Z"}
{"aid":"http://arxiv.org/abs/2505.07672v1","title":"OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit","summary":"We present OnPrem.LLM, a Python-based toolkit for applying large language\nmodels (LLMs) to sensitive, non-public data in offline or restricted\nenvironments. The system is designed for privacy-preserving use cases and\nprovides prebuilt pipelines for document processing and storage,\nretrieval-augmented generation (RAG), information extraction, summarization,\nclassification, and prompt/output processing with minimal configuration.\nOnPrem.LLM supports multiple LLM backends -- including llama.cpp, Ollama, vLLM,\nand Hugging Face Transformers -- with quantized model support, GPU\nacceleration, and seamless backend switching. Although designed for fully local\nexecution, OnPrem.LLM also supports integration with a wide range of cloud LLM\nproviders when permitted, enabling hybrid deployments that balance performance\nwith data control. A no-code web interface extends accessibility to\nnon-technical users.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-05-12T15:36:27Z"}
{"aid":"http://arxiv.org/abs/2505.07697v1","title":"Cosmology with Galaxy Clusters","summary":"We review recent advancements in cosmology with galaxy clusters. Galaxy\nclusters are the most massive objects in the Universe. Consequently the cluster\nnumber density as a function of cluster mass, or cluster abundance, is\nsensitive to cosmological parameters, particularly the matter density of the\nUniverse $\\Omega_{\\rm m}$ and the amplitude of matter density fluctuation\n$\\sigma_8$. In this review, we describe the methods used to detect galaxy\nclusters through optical near-infrared (O-NIR), X-ray, and CMB observations,\noutlining the advantages and disadvantages of cluster detection through\ndifferent wavelengths. We describe methods for measuring cluster mass, with a\nparticular focus on calibration by WL measurements. We then discuss how the\nconnection between observables in different wavelengths and cluster abundance\ncan be modeled through a cluster selection function and MOR, and quantify the\nimpact of marginalization of nuisance parameters on cosmological constraints.\nFinally, we also walk through the recent results of cosmological constraints by\ncluster abundance with the O-NIR, X-ray, and CMB observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-12T16:05:18Z"}
{"aid":"http://arxiv.org/abs/2505.07706v1","title":"The generalized trifference problem","summary":"We study the problem of finding the largest number $T(n, m)$ of ternary\nvectors of length $n$ such that for any three distinct vectors there are at\nleast $m$ coordinates where they pairwise differ.\n  For $m = 1$, this is the classical trifference problem which is wide open.\n  We prove upper and lower bounds on $T(n, m)$ for various ranges of the\nparameter $m$ and determine the phase transition threshold on $m=m(n)$ where\n$T(n, m)$ jumps from constant to exponential in $n$.\n  By relating the linear version of this problem to a problem on blocking sets\nin finite geometry, we give explicit constructions and probabilistic lower\nbounds.\n  We also compute the exact values of this function and its linear variation\nfor small parameters.","main_category":"math.CO","categories":"math.CO,cs.IT,math.IT","published":"2025-05-12T16:14:09Z"}
{"aid":"http://arxiv.org/abs/2505.07714v1","title":"SmartUT: Receive Beamforming for Spectral Coexistence of NGSO Satellite\n  Systems","summary":"In this paper, we investigate downlink co-frequency interference (CFI)\nmitigation in non-geostationary satellites orbits (NGSOs) co-existing systems.\nTraditional mitigation techniques, such as Zero-forcing (ZF), produce a null\ntowards the direction of arrivals (DOAs) of the interfering signals, but they\nsuffer from high computational complexity due to matrix inversions and required\nknowledge of the channel state information (CSI). Furthermore, adaptive\nbeamformers, such as sample matrix inversion (SMI)-based minimum variance,\nprovide poor performance when the available snapshots are limited. We propose a\nMamba-based beamformer (MambaBF) that leverages an unsupervised deep learning\n(DL) approach and can be deployed on the user terminal (UT) antenna array, for\nassisting downlink beamforming and CFI mitigation using only a limited number\nof available array snapshots as input, and without CSI knowledge. Simulation\nresults demonstrate that MambaBF consistently outperforms conventional\nbeamforming techniques in mitigating interference and maximizing the\nsignal-to-interference-plus-noise ratio (SINR), particularly under challenging\nconditions characterized by low SINR, limited snapshots, and imperfect CSI.","main_category":"eess.SP","categories":"eess.SP,cs.ET,cs.LG","published":"2025-05-12T16:19:06Z"}
{"aid":"http://arxiv.org/abs/2505.07721v1","title":"Gameplay Highlights Generation","summary":"In this work, we enable gamers to share their gaming experience on social\nmedia by automatically generating eye-catching highlight reels from their\ngameplay session Our automation will save time for gamers while increasing\naudience engagement. We approach the highlight generation problem by first\nidentifying intervals in the video where interesting events occur and then\nconcatenate them. We developed an in-house gameplay event detection dataset\ncontaining interesting events annotated by humans using VIA video annotator.\nTraditional techniques for highlight detection such as game engine integration\nrequires expensive collaboration with game developers. OCR techniques which\ndetect patches of specific images or texts require expensive per game\nengineering and may not generalize across game UI and different language. We\nfinetuned a multimodal general purpose video understanding model such as X-CLIP\nusing our dataset which generalizes across multiple games in a genre without\nper game engineering. Prompt engineering was performed to improve the\nclassification performance of this multimodal model. Our evaluation showed that\nsuch a finetuned model can detect interesting events in first person shooting\ngames from unseen gameplay footage with more than 90% accuracy. Moreover, our\nmodel performed significantly better on low resource games (small dataset) when\ntrained along with high resource games, showing signs of transfer learning. To\nmake the model production ready, we used ONNX libraries to enable cross\nplatform inference. These libraries also provide post training quantization\ntools to reduce model size and inference time for deployment. ONNX runtime\nlibraries with DirectML backend were used to perform efficient inference on\nWindows OS. We show that natural language supervision in the X-CLIP model leads\nto data efficient and highly performant video recognition models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-12T16:28:22Z"}
{"aid":"http://arxiv.org/abs/2505.07731v1","title":"Spoken Language Understanding on Unseen Tasks With In-Context Learning","summary":"Spoken language understanding (SLU) tasks involve diverse skills that probe\nthe information extraction, classification and/or generation capabilities of\nmodels. In this setting, task-specific training data may not always be\navailable. While traditional task-specific SLU models are unable to cater to\nsuch requirements, the speech-text large language models (LLMs) offer a\npromising alternative with emergent abilities. However, out of-the-box, our\nevaluations indicate that the zero/few-shot performance of prominent\nopen-source speech-text LLMs on SLU tasks are not up to the mark. In this\npaper, we introduce a novel approach to robust task-agnostic fine-tuning using\nrandomized class labels. With this proposed fine-tuning, we illustrate that the\nperformance of the speech-text LLMs on an unseen task is significantly improved\nover standard approaches. Critically, the proposed approach avoids the\nrequirement of task-specific data annotations for enabling new tasks in\nspeech-text LLMs.","main_category":"cs.CL","categories":"cs.CL,cs.LG,eess.AS","published":"2025-05-12T16:38:43Z"}
{"aid":"http://arxiv.org/abs/2505.07742v1","title":"Flatness in finitely accessible additive categories","summary":"Motivated by some problems proposed by Cuadra and Simson related to flat\nobjects in finitely accessible Grothendieck categories, we study flatness in\nthe more general setting of finitely accessible additive categories. For such\ncategory $\\mathcal{A}$, we characterize when $\\mathcal{A}$ is preabelian and\nabelian. We prove that if the class of flat objects in $\\mathcal A$ is closed\nunder pure subobjects, then every flat object is a direct union of\n\\textit{small} flat subobjects. Finally, we characterize when $\\mathcal{A}$ has\nenough flat and projective objects and we prove that, in this case, the class\nof flat objects is closed under pure subobjects.","main_category":"math.CT","categories":"math.CT,math.RA","published":"2025-05-12T16:50:14Z"}
{"aid":"http://arxiv.org/abs/2505.07759v1","title":"\"I Apologize For Not Understanding Your Policy\": Exploring the\n  Specification and Evaluation of User-Managed Access Control Policies by AI\n  Virtual Assistants","summary":"The rapid evolution of Artificial Intelligence (AI)-based Virtual Assistants\n(VAs) e.g., Google Gemini, ChatGPT, Microsoft Copilot, and High-Flyer Deepseek\nhas turned them into convenient interfaces for managing emerging technologies\nsuch as Smart Homes, Smart Cars, Electronic Health Records, by means of\nexplicit commands,e.g., prompts, which can be even launched via voice, thus\nproviding a very convenient interface for end-users. However, the proper\nspecification and evaluation of User-Managed Access Control Policies (U-MAPs),\nthe rules issued and managed by end-users to govern access to sensitive data\nand device functionality - within these VAs presents significant challenges,\nsince such a process is crucial for preventing security vulnerabilities and\nprivacy leaks without impacting user experience. This study provides an initial\nexploratory investigation on whether current publicly-available VAs can manage\nU-MAPs effectively across differing scenarios. By conducting unstructured to\nstructured tests, we evaluated the comprehension of such VAs, revealing a lack\nof understanding in varying U-MAP approaches. Our research not only identifies\nkey limitations, but offers valuable insights into how VAs can be further\nimproved to manage complex authorization rules and adapt to dynamic changes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-12T17:03:52Z"}
{"aid":"http://arxiv.org/abs/2505.07766v1","title":"Privacy Risks of Robot Vision: A User Study on Image Modalities and\n  Resolution","summary":"User privacy is a crucial concern in robotic applications, especially when\nmobile service robots are deployed in personal or sensitive environments.\nHowever, many robotic downstream tasks require the use of cameras, which may\nraise privacy risks. To better understand user perceptions of privacy in\nrelation to visual data, we conducted a user study investigating how different\nimage modalities and image resolutions affect users' privacy concerns. The\nresults show that depth images are broadly viewed as privacy-safe, and a\nsimilarly high proportion of respondents feel the same about semantic\nsegmentation images. Additionally, the majority of participants consider 32*32\nresolution RGB images to be almost sufficiently privacy-preserving, while most\nbelieve that 16*16 resolution can fully guarantee privacy protection.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-05-12T17:16:12Z"}
{"aid":"http://arxiv.org/abs/2505.07774v1","title":"Topological Indices Among Strong Support Vertex","summary":"In this paper, we provide the irregularity properties of trees with strong\nsupport vertex by analyzing two prominent topological indices: the Albertson\nindex and the Sigma index. We further establish extremal bounds for both\nindices across families of trees defined by given degree sequences. Let $T_1$\nand $T_2$ be a star trees of order $n$, where $T_1 \\cong T_2$, then, we provide\nAlbertson index of $T_1 \\cong T_2$. Let $\\mathcal{T}_{n, \\Delta}$ be a class of\ntrees with $n$ vertices, there are a tree $T^{\\prime} \\in \\mathcal{T}_{n,\n\\Delta}$ such that $\\irr(T^{\\prime}) < \\irr(T)$.","main_category":"math.CO","categories":"math.CO,G.2.2","published":"2025-05-12T17:26:18Z"}
{"aid":"http://arxiv.org/abs/2505.07794v1","title":"Disparity in sound speeds: implications for unitarity and effective\n  potential in quantum field theory","summary":"We develop a complete unitarity framework for quantum field theories whose\nmassive scalar excitations propagate at different sound speeds. Starting from\nfirst principles we derive the exact partial-wave unitarity condition for\n$2\\rightarrow 2$ scattering with arbitrary masses and velocity hierarchies,\nrecovering the standard and massless limits as special cases. Applying the\nformalism to a renormalizable two-field model we verify the optical theorem at\none loop and obtain compact, velocity-dependent perturbative unitarity bounds.\nThen we compute the one-loop Coleman-Weinberg potential in the background-field\nmethod, tracking how a small splitting between sound speeds reshapes the\nrenormalization-group flow. We find that all of quartic $\\beta$-functions are\nrescaled in such a way that an accidental fixed line emerges.","main_category":"hep-th","categories":"hep-th","published":"2025-05-12T17:45:23Z"}
{"aid":"http://arxiv.org/abs/2505.08190v1","title":"Unsupervised Raindrop Removal from a Single Image using Conditional\n  Diffusion Models","summary":"Raindrop removal is a challenging task in image processing. Removing\nraindrops while relying solely on a single image further increases the\ndifficulty of the task. Common approaches include the detection of raindrop\nregions in the image, followed by performing a background restoration process\nconditioned on those regions. While various methods can be applied for the\ndetection step, the most common architecture used for background restoration is\nthe Generative Adversarial Network (GAN). Recent advances in the use of\ndiffusion models have led to state-of-the-art image inpainting techniques. In\nthis paper, we introduce a novel technique for raindrop removal from a single\nimage using diffusion-based image inpainting.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-05-13T03:00:01Z"}
{"aid":"http://arxiv.org/abs/2505.08199v1","title":"A Multi-scale Representation Learning Framework for Long-Term Time\n  Series Forecasting","summary":"Long-term time series forecasting (LTSF) offers broad utility in practical\nsettings like energy consumption and weather prediction. Accurately predicting\nlong-term changes, however, is demanding due to the intricate temporal patterns\nand inherent multi-scale variations within time series. This work confronts key\nissues in LTSF, including the suboptimal use of multi-granularity information,\nthe neglect of channel-specific attributes, and the unique nature of trend and\nseasonal components, by introducing a proficient MLP-based forecasting\nframework. Our method adeptly disentangles complex temporal dynamics using\nclear, concurrent predictions across various scales. These multi-scale\nforecasts are then skillfully integrated through a system that dynamically\nassigns importance to information from different granularities, sensitive to\nindividual channel characteristics. To manage the specific features of temporal\npatterns, a two-pronged structure is utilized to model trend and seasonal\nelements independently. Experimental results on eight LTSF benchmarks\ndemonstrate that MDMixer improves average MAE performance by 4.64% compared to\nthe recent state-of-the-art MLP-based method (TimeMixer), while achieving an\neffective balance between training efficiency and model interpretability.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-13T03:26:44Z"}
{"aid":"http://arxiv.org/abs/2505.08215v1","title":"Unveiling the Best Practices for Applying Speech Foundation Models to\n  Speech Intelligibility Prediction for Hearing-Impaired People","summary":"Speech foundation models (SFMs) have demonstrated strong performance across a\nvariety of downstream tasks, including speech intelligibility prediction for\nhearing-impaired people (SIP-HI). However, optimizing SFMs for SIP-HI has been\ninsufficiently explored. In this paper, we conduct a comprehensive study to\nidentify key design factors affecting SIP-HI performance with 5 SFMs, focusing\non encoder layer selection, prediction head architecture, and ensemble\nconfigurations. Our findings show that, contrary to traditional use-all-layers\nmethods, selecting a single encoder layer yields better results. Additionally,\ntemporal modeling is crucial for effective prediction heads. We also\ndemonstrate that ensembling multiple SFMs improves performance, with stronger\nindividual models providing greater benefit. Finally, we explore the\nrelationship between key SFM attributes and their impact on SIP-HI performance.\nOur study offers practical insights into effectively adapting SFMs for speech\nintelligibility prediction for hearing-impaired populations.","main_category":"cs.AI","categories":"cs.AI,cs.SD,eess.AS","published":"2025-05-13T04:07:59Z"}
{"aid":"http://arxiv.org/abs/2505.08217v1","title":"Energy-Efficient Pseudo-Ratchet for Brownian Computers through\n  One-Dimensional Quantum Brownian Motion","summary":"Brownian computers utilize thermal fluctuations as a resource for computation\nand hold promise for achieving ultra-low-energy computations. However, the lack\nof a statistical direction in Brownian motion necessitates the incorporation of\nratchets that facilitate the speeding up and completion of computations in\nBrownian computers. To make the ratchet mechanism work effectively, an external\nfield is required to overcome thermal fluctuations, which has the drawback of\nincreasing energy consumption. As a remedy for this drawback, we introduce a\nnew approach based on one-dimensional (1D) quantum Brownian motion, which\nexhibits intrinsic unidirectional transport even in the absence of external\nforces or asymmetric potential gradients, thereby functioning as an effective\npseudo-ratchet. Specifically, we exploit that quantum resonance effects in 1D\nsystems divide the momentum space of particles into subspaces. These subspaces\nhave no momentum inversion symmetry, resulting in the natural emergence of\nunidirectional flow. We analyze this pseudo-ratchet mechanism without energy\ndissipation from an entropic perspective and show that it remains consistent\nwith the second law of thermodynamics.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,quant-ph","published":"2025-05-13T04:20:07Z"}
{"aid":"http://arxiv.org/abs/2505.08220v1","title":"Deep Probabilistic Modeling of User Behavior for Anomaly Detection via\n  Mixture Density Networks","summary":"To improve the identification of potential anomaly patterns in complex user\nbehavior, this paper proposes an anomaly detection method based on a deep\nmixture density network. The method constructs a Gaussian mixture model\nparameterized by a neural network, enabling conditional probability modeling of\nuser behavior. It effectively captures the multimodal distribution\ncharacteristics commonly present in behavioral data. Unlike traditional\nclassifiers that rely on fixed thresholds or a single decision boundary, this\napproach defines an anomaly scoring function based on probability density using\nnegative log-likelihood. This significantly enhances the model's ability to\ndetect rare and unstructured behaviors. Experiments are conducted on the\nreal-world network user dataset UNSW-NB15. A series of performance comparisons\nand stability validation experiments are designed. These cover multiple\nevaluation aspects, including Accuracy, F1- score, AUC, and loss fluctuation.\nThe results show that the proposed method outperforms several advanced neural\nnetwork architectures in both performance and training stability. This study\nprovides a more expressive and discriminative solution for user behavior\nmodeling and anomaly detection. It strongly promotes the application of deep\nprobabilistic modeling techniques in the fields of network security and\nintelligent risk control.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-13T04:32:21Z"}
{"aid":"http://arxiv.org/abs/2505.08239v1","title":"ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single\n  Image","summary":"We introduce adaptive view planning to multi-view synthesis, aiming to\nimprove both occlusion revelation and 3D consistency for single-view 3D\nreconstruction. Instead of generating an unordered set of views independently\nor simultaneously, we generate a sequence of views, leveraging temporal\nconsistency to enhance 3D coherence. Most importantly, our view sequence is not\ndetermined by a pre-determined camera setup. Instead, we compute an adaptive\ncamera trajectory (ACT), specifically, an orbit of camera views, which\nmaximizes the visibility of occluded regions of the 3D object to be\nreconstructed. Once the best orbit is found, we feed it to a video diffusion\nmodel to generate novel views around the orbit, which in turn, are passed to a\nmulti-view 3D reconstruction model to obtain the final reconstruction. Our\nmulti-view synthesis pipeline is quite efficient since it involves no run-time\ntraining/optimization, only forward inferences by applying the pre-trained\nmodels for occlusion analysis and multi-view synthesis. Our method predicts\ncamera trajectories that reveal occlusions effectively and produce consistent\nnovel views, significantly improving 3D reconstruction over SOTA on the unseen\nGSO dataset, both quantitatively and qualitatively.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-05-13T05:31:59Z"}
{"aid":"http://arxiv.org/abs/2505.08241v1","title":"Weak coupling limit for quantum systems with unbounded weakly commuting\n  system operators","summary":"This work is devoted to a rigorous analysis of the weak coupling limit (WCL)\nfor the reduced dynamics of an open infinite-dimensional quantum system\ninteracting with electromagnetic field or a reservoir formed by Fermi or Bose\nparticles in the dipole approximation. The free system Hamiltonian and the\nsystem part of the Hamiltonian describing interaction with the reservoir are\nconsidered as unbounded operators with continuous spectrum which are commuting\nin a weak sense. We derive in the weak coupling limit the reservoir statistics,\nwhich is determined by whose terms in the multi-point correlation functions of\nthe reservoir which are non-zero in the WCL. Then we prove that the resulting\nreduced system dynamics converges to unitary dynamics (such behavior sometimes\ncalled as Quantum Cheshire Cat effect) with a modified Hamiltonian which can be\ninterpreted as a Lamb shift to the original Hamiltonian. We obtain exact form\nof the modified Hamiltonian and estimate the rate of convergence to the\nlimiting dynamics. For Fermi reservoir, we prove the convergence of the full\nDyson series. For Bose case the convergence is understood term by term.","main_category":"math-ph","categories":"math-ph,math.MP,quant-ph","published":"2025-05-13T05:32:34Z"}
{"aid":"http://arxiv.org/abs/2505.08265v1","title":"LLM Enhancers for GNNs: An Analysis from the Perspective of Causal\n  Mechanism Identification","summary":"The use of large language models (LLMs) as feature enhancers to optimize node\nrepresentations, which are then used as inputs for graph neural networks\n(GNNs), has shown significant potential in graph representation learning.\nHowever, the fundamental properties of this approach remain underexplored. To\naddress this issue, we propose conducting a more in-depth analysis of this\nissue based on the interchange intervention method. First, we construct a\nsynthetic graph dataset with controllable causal relationships, enabling\nprecise manipulation of semantic relationships and causal modeling to provide\ndata for analysis. Using this dataset, we conduct interchange interventions to\nexamine the deeper properties of LLM enhancers and GNNs, uncovering their\nunderlying logic and internal mechanisms. Building on the analytical results,\nwe design a plug-and-play optimization module to improve the information\ntransfer between LLM enhancers and GNNs. Experiments across multiple datasets\nand models validate the proposed module.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-13T06:29:25Z"}
{"aid":"http://arxiv.org/abs/2505.08268v1","title":"A nonlinear analogue of additive commutators","summary":"We study a nonlinear analogue of additive commutators, known as\n\\textit{polynomial commutators}, defined by \\( p(ab) - p(ba) \\) for a\npolynomial \\( p \\in F[x] \\) and elements \\( a, b \\) in an algebra \\( R \\) over\na field \\( F \\). Originally introduced by Laffey and West for matrices over\nfields, this notion is here extended to broader algebraic settings. We first\nshow that in division rings, polynomial commutators can generate maximal\nsubfields and even the entire ring as an algebra. In the matrix setting, we\nprove that matrices similar to ones with zero diagonal are polynomial\ncommutators, and under mild assumptions, every matrix can be written as a\nproduct of at most three such commutators. Furthermore, we demonstrate that the\nmatrix algebra can be decomposed as the sum of its center and the linear span\nof all polynomial commutators. Using the theory of rational identities in\ndivision rings, we also exhibit that the trace of a polynomial commutator in\nthe matrix ring can be nonzero in noncommutative cases. Lastly, we explore the\nsize of polynomial commutators via matrix norms.","main_category":"math.RA","categories":"math.RA","published":"2025-05-13T06:34:08Z"}
{"aid":"http://arxiv.org/abs/2505.08269v1","title":"First-principles electron-phonon interactions with self-consistent\n  Hubbard interaction: an application to transparent conductive oxides","summary":"The ab initio computational method known as Hubbard-corrected density\nfunctional theory (DFT+$U$) captures well ground electronic structures of a set\nof solids that are poorly described by standard DFT alone. Since lattice\ndynamical properties are closely linked to electronic structures, the\nHubbard-corrected density functional perturbation theory (DFPT+$U$) can\ncalculate them at the same level of accuracy. To investigate the effects of $U$\non electron-phonon (el-ph) interactions, we implemented DFPT+$U$ with a\nHartree-Fock-based pseudohybrid functional formalism to determine $U$\nself-consistently and applied our method to compute optical and transport\nproperties of transparent conductive oxides of CdO and ZnO. For CdO, we find\nthat opening a band gap due to $U$ restores the long-range Fr\\\"ohlich\ninteraction and that its calculated mobility and absorption spectrum are in\nexcellent agreement with experiments. For ZnO where a band gap already appears\nat the DFT level, DFPT+$U$ brings the results into much closer alignment with\nexperiment, thus demonstrating improved accuracy of our method in dealing with\nel-ph interactions in these technologically important materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-05-13T06:35:05Z"}
{"aid":"http://arxiv.org/abs/2505.08275v1","title":"The Statistics of Gas Density, Velocity, and Magnetic Fields in\n  Cool-Core Galaxy Clusters","summary":"Understanding turbulence within the Intracluster Medium (ICM) of galaxy\nclusters is pivotal for comprehending their evolution and dynamics. Employing\n3D magnetohydrodynamic (MHD) simulations of galaxy cluster mergers, we examine\nthe statistical properties of gas density, magnetic fields, and velocity,\nparticularly emphasizing the central regions spanning 400 kpc. The simulations\nfeature varied initial plasma $\\beta$ values (100, 200, and 500), mirroring\nconditions in massive cool-core clusters such as Perseus. Our findings indicate\nthat while the statistical histogram distributions of gas density and velocity\nappear similar across different $\\beta$ scenarios, their spatial distributions\nand morphological patterns exhibit noticeable differences. Through the\napplication of the second-order structure function, we identified a scaling\nrelation in velocity fluctuations, characterized by a slope of 1/2 and\npredominantly dominated by solenoidal components. Furthermore, our analysis\nreveals a pronounced anisotropy in both velocity and magnetic field\nfluctuations, with more significant fluctuations along the direction\nperpendicular to the magnetic fields. This anisotropy is scale-dependent,\nbecoming more pronounced at smaller scales, and exhibits a decreasing trend in\nscenarios where the magnetic field is relatively weak, particularly at\n$\\beta=500$. This suggests that the anisotropic nature of these fluctuations is\npredominantly regulated by the magnetic fields. Additionally, we test the\nefficacy of the Synchrotron Intensity Gradient (SIG) method for tracing\nmagnetic fields in these environments. The SIG shows a global agreement with\nthe magnetic field across all three $\\beta$ scenarios, confirming the SIG's\ninsensitivity to the medium's magnetization level.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-05-13T06:40:11Z"}
{"aid":"http://arxiv.org/abs/2505.08312v1","title":"Investigating Resolution Strategies for Workspace-Occlusion in Augmented\n  Virtuality","summary":"Augmented Virtuality integrates physical content into virtual environments,\nbut the occlusion of physical by virtual content is a challenge. This unwanted\nocclusion may disrupt user interactions with physical devices and compromise\nsafety and usability. This paper investigates two resolution strategies to\naddress this issue: Redirected Walking, which subtly adjusts the user's\nmovement to maintain physical-virtual alignment, and Automatic Teleport\nRotation, which realigns the virtual environment during travel. A user study\nset in a virtual forest demonstrates that both methods effectively reduce\nocclusion. While in our testbed, Automatic Teleport Rotation achieves higher\nocclusion resolution, it is suspected to increase cybersickness compared to the\nless intrusive Redirected Walking approach.","main_category":"cs.HC","categories":"cs.HC","published":"2025-05-13T07:42:21Z"}
{"aid":"http://arxiv.org/abs/2505.08349v1","title":"FAD: Frequency Adaptation and Diversion for Cross-domain Few-shot\n  Learning","summary":"Cross-domain few-shot learning (CD-FSL) requires models to generalize from\nlimited labeled samples under significant distribution shifts. While recent\nmethods enhance adaptability through lightweight task-specific modules, they\noperate solely in the spatial domain and overlook frequency-specific variations\nthat are often critical for robust transfer. We observe that spatially similar\nimages across domains can differ substantially in their spectral\nrepresentations, with low and high frequencies capturing complementary semantic\ninformation at coarse and fine levels. This indicates that uniform spatial\nadaptation may overlook these spectral distinctions, thus constraining\ngeneralization. To address this, we introduce Frequency Adaptation and\nDiversion (FAD), a frequency-aware framework that explicitly models and\nmodulates spectral components. At its core is the Frequency Diversion Adapter,\nwhich transforms intermediate features into the frequency domain using the\ndiscrete Fourier transform (DFT), partitions them into low, mid, and\nhigh-frequency bands via radial masks, and reconstructs each band using inverse\nDFT (IDFT). Each frequency band is then adapted using a dedicated convolutional\nbranch with a kernel size tailored to its spectral scale, enabling targeted and\ndisentangled adaptation across frequencies. Extensive experiments on the\nMeta-Dataset benchmark demonstrate that FAD consistently outperforms\nstate-of-the-art methods on both seen and unseen domains, validating the\nutility of frequency-domain representations and band-wise adaptation for\nimproving generalization in CD-FSL.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-13T08:48:06Z"}
{"aid":"http://arxiv.org/abs/2505.08367v1","title":"MA-ROESL: Motion-aware Rapid Reward Optimization for Efficient Robot\n  Skill Learning from Single Videos","summary":"Vision-language models (VLMs) have demonstrated excellent high-level planning\ncapabilities, enabling locomotion skill learning from video demonstrations\nwithout the need for meticulous human-level reward design. However, the\nimproper frame sampling method and low training efficiency of current methods\nremain a critical bottleneck, resulting in substantial computational overhead\nand time costs. To address this limitation, we propose Motion-aware Rapid\nReward Optimization for Efficient Robot Skill Learning from Single Videos\n(MA-ROESL). MA-ROESL integrates a motion-aware frame selection method to\nimplicitly enhance the quality of VLM-generated reward functions. It further\nemploys a hybrid three-phase training pipeline that improves training\nefficiency via rapid reward optimization and derives the final policy through\nonline fine-tuning. Experimental results demonstrate that MA-ROESL\nsignificantly enhances training efficiency while faithfully reproducing\nlocomotion skills in both simulated and real-world settings, thereby\nunderscoring its potential as a robust and scalable framework for efficient\nrobot locomotion skill learning from video demonstrations.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-13T09:12:32Z"}
{"aid":"http://arxiv.org/abs/2505.08387v1","title":"The Lax--Wendroff theorem for Patankar-type methods applied to\n  hyperbolic conservation laws","summary":"For hyperbolic conservation laws, the famous Lax--Wendroff theorem delivers\nsufficient conditions for the limit of a convergent numerical method to be a\nweak (entropy) solution. This theorem is a fundamental result, and many\ninvestigations have been done to verify its validity for finite difference,\nfinite volume, and finite element schemes, using either explicit or implicit\nlinear time-integration methods. Recently, the use of modified Patankar (MP)\nschemes as time-integration methods for the discretization of hyperbolic\nconservation laws has gained increasing interest. These schemes are\nunconditionally conservative and positivity-preserving and only require the\nsolution of a linear system. However, MP schemes are by construction nonlinear,\nwhich is why the theoretical investigation of these schemes is more involved.\nWe prove an extension of the Lax--Wendroff theorem for the class of MP methods.\nThis is the first extension of the Lax--Wendroff theorem to nonlinear time\nintegration methods with just an additional hypothesis on the total time\nvariation boundness of the numerical solutions. We provide some numerical\nsimulations that validate the theoretical observations.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-13T09:34:21Z"}
{"aid":"http://arxiv.org/abs/2505.08388v1","title":"MDF: Multi-Modal Data Fusion with CNN-Based Object Detection for\n  Enhanced Indoor Localization Using LiDAR-SLAM","summary":"Indoor localization faces persistent challenges in achieving high accuracy,\nparticularly in GPS-deprived environments. This study unveils a cutting-edge\nhandheld indoor localization system that integrates 2D LiDAR and IMU sensors,\ndelivering enhanced high-velocity precision mapping, computational efficiency,\nand real-time adaptability. Unlike 3D LiDAR systems, it excels with rapid\nprocessing, low-cost scalability, and robust performance, setting new standards\nfor emergency response, autonomous navigation, and industrial automation.\nEnhanced with a CNN-driven object detection framework and optimized through\nCartographer SLAM (simultaneous localization and mapping ) in ROS, the system\nsignificantly reduces Absolute Trajectory Error (ATE) by 21.03%, achieving\nexceptional precision compared to state-of-the-art approaches like SC-ALOAM,\nwith a mean x-position error of -0.884 meters (1.976 meters). The integration\nof CNN-based object detection ensures robustness in mapping and localization,\neven in cluttered or dynamic environments, outperforming existing methods by\n26.09%. These advancements establish the system as a reliable, scalable\nsolution for high-precision localization in challenging indoor scenarios","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-13T09:34:55Z"}
{"aid":"http://arxiv.org/abs/2505.08396v1","title":"Graph state extraction from two-dimensional cluster states","summary":"We propose schemes to extract arbitrary graph states from two-dimensional\ncluster states by locally manipulating the qubits solely via single-qubit\nmeasurements. We introduce graph state manipulation tools that allow one to\nincrease the local vertex degree and to merge subgraphs. We utilize these tools\ntogether with the previously introduced zipper scheme that generates multiple\nedges between distant vertices to extract the desired graph state from a\ntwo-dimensional cluster state. We show how to minimize overheads by avoiding\nmultiple edges, and compare with a local manipulation strategy based on\nmeasurement-based quantum computation together with transport. These schemes\nhave direct applications in entanglement-based quantum networks, sensor\nnetworks, and distributed quantum computing in general.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T09:49:54Z"}
{"aid":"http://arxiv.org/abs/2505.08402v1","title":"TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers","summary":"Recently, large language models(LLMs) have played an increasingly important\nrole in solving a wide range of NLP tasks, leveraging their capabilities of\nnatural language understanding and generating. Integration with external tools\nfurther enhances LLMs' effectiveness, providing more precise, timely, and\nspecialized responses. However, LLMs still encounter difficulties with\nnon-executable actions and improper actions, which are primarily attributed to\nincorrect parameters. The process of generating parameters by LLMs is confined\nto the tool level, employing the coarse-grained strategy without considering\nthe different difficulties of various tools. To address this issue, we propose\nTUMS, a novel framework designed to enhance the tool-use capabilities of LLMs\nby transforming tool-level processing into parameter-level processing.\nSpecifically, our framework consists of four key components: (1) an intent\nrecognizer that identifies the user's intent to help LLMs better understand the\ntask; (2) a task decomposer that breaks down complex tasks into simpler\nsubtasks, each involving a tool call; (3) a subtask processor equipped with\nmulti-structure handlers to generate accurate parameters; and (4) an executor.\nOur empirical studies have evidenced the effectiveness and efficiency of the\nTUMS framework with an average of 19.6\\% and 50.6\\% improvement separately on\neasy and hard benchmarks of ToolQA, meanwhile, we demonstrated the key\ncontribution of each part with ablation experiments, offering more insights and\nstimulating future research on Tool-augmented LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-13T09:57:28Z"}
{"aid":"http://arxiv.org/abs/2505.08409v1","title":"Observational constraints on the Kerr and its several single-parameter\n  modified spacetimes using quasi-periodic oscillation data","summary":"This paper investigates the dynamical effects of particles moving in the Kerr\nspacetime and its nine single-parameter modified spacetimes, including Bardeen,\nAyon-Beato and Garcia (ABG), Hayward, Kerr-Newman (KN), Kerr-Taub-NUT (KTN),\nBraneworld Kerr (BK), Kerr-MOG, Kerr-Sen, and Perfect Fluid Dark Matter (PFDM)\nblack holes. Using quasi-periodic oscillation (QPO) observational data, we\nconstrain the free parameters of the ten spacetimes through $\\chi^2$ analysis\nunder the relativistic precession model of QPO. We constrain the modification\nparameters for the nine single-parameter modified spacetimes and provide the\nspin and mass ranges of three microquasars within the ten spacetime models\n(including Kerr) at the $68\\%$ confidence level (CL). The results demonstrate\nthat, at the $68 \\%$ CL, the QPO data impose stringent constraints on the free\nparameters, as evidenced by the narrow confidence intervals. Among them, only\nthe KN spacetime yields a modification parameter constraint spanning both\nnegative and positive values (encompassing the Kerr case at zero). In contrast,\nall other tested geometries mandate positive-definite parameters at $68 \\%$ CL,\ndemonstrating statistical deviation of the Kerr solution. This highlights the\nsignificance of exploring modifications to the Kerr spacetime. Finally, we\nevaluate the spacetime models using the Bayes factor and the Akaike Information\nCriterion (AIC). Based on the current QPO observational data, the Bayesian\nfactor analysis indicates that the ABG, Hayward, KN, BK, and Kerr-MOG spacetime\nhave a slight advantage over the Kerr solution, while the Bardeen, KTN,\nKerr-Sen, and PFDM spacetime are somewhat inferior to the Kerr model. In\ncontrast, the AIC analysis shows that the Kerr spacetime remains the optimal\nmodel under the current QPO data.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-05-13T10:08:28Z"}
{"aid":"http://arxiv.org/abs/2505.08439v1","title":"A document processing pipeline for the construction of a dataset for\n  topic modeling based on the judgments of the Italian Supreme Court","summary":"Topic modeling in Italian legal research is hindered by the lack of public\ndatasets, limiting the analysis of legal themes in Supreme Court judgments. To\naddress this, we developed a document processing pipeline that produces an\nanonymized dataset optimized for topic modeling.\n  The pipeline integrates document layout analysis (YOLOv8x), optical character\nrecognition, and text anonymization. The DLA module achieved a mAP@50 of 0.964\nand a mAP@50-95 of 0.800. The OCR detector reached a mAP@50-95 of 0.9022, and\nthe text recognizer (TrOCR) obtained a character error rate of 0.0047 and a\nword error rate of 0.0248. Compared to OCR-only methods, our dataset improved\ntopic modeling with a diversity score of 0.6198 and a coherence score of\n0.6638.\n  We applied BERTopic to extract topics and used large language models to\ngenerate labels and summaries. Outputs were evaluated against domain expert\ninterpretations. Claude Sonnet 3.7 achieved a BERTScore F1 of 0.8119 for\nlabeling and 0.9130 for summarization.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-13T11:06:24Z"}
{"aid":"http://arxiv.org/abs/2505.08443v1","title":"A nonlocal-to-local approach to aggregation-diffusion equations","summary":"Over the past decades, nonlocal models have been widely used to describe\naggregation phenomena in biology, physics, engineering, and the social\nsciences. These are often derived as mean-field limits of attraction-repulsion\nagent-based models, and consist of systems of nonlocal partial differential\nequations. Using differential adhesion between cells as a biological case\nstudy, we introduce a novel local model of aggregation-diffusion phenomena.\nThis system of local aggregation-diffusion equations is fourth-order,\nresembling thin-film or Cahn-Hilliard type equations. In this framework, cell\nsorting phenomena are explained through relative surface tensions between\ndistinct cell types. The local model emerges as a limiting case of short-range\ninteractions, providing a significant simplification of earlier nonlocal\nmodels, while preserving the same phenomenology. This simplification makes the\nmodel easier to implement numerically and more amenable to calibration to\nquantitative data. Additionally, we discuss recent analytical results based on\nthe gradient-flow structure of the model, along with open problems and future\nresearch directions.","main_category":"q-bio.CB","categories":"q-bio.CB,math.AP","published":"2025-05-13T11:09:43Z"}
{"aid":"http://arxiv.org/abs/2505.08445v1","title":"Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter\n  Impact on Performance and Efficiency","summary":"Large language models achieve high task performance yet often hallucinate or\nrely on outdated knowledge. Retrieval-augmented generation (RAG) addresses\nthese gaps by coupling generation with external search. We analyse how\nhyperparameters influence speed and quality in RAG systems, covering Chroma and\nFaiss vector stores, chunking policies, cross-encoder re-ranking, and\ntemperature, and we evaluate six metrics: faithfulness, answer correctness,\nanswer relevancy, context precision, context recall, and answer similarity.\nChroma processes queries 13% faster, whereas Faiss yields higher retrieval\nprecision, revealing a clear speed-accuracy trade-off. Naive fixed-length\nchunking with small windows and minimal overlap outperforms semantic\nsegmentation while remaining the quickest option. Re-ranking provides modest\ngains in retrieval quality yet increases runtime by roughly a factor of 5, so\nits usefulness depends on latency constraints. These results help practitioners\nbalance computational cost and accuracy when tuning RAG systems for\ntransparent, up-to-date responses. Finally, we re-evaluate the top\nconfigurations with a corrective RAG workflow and show that their advantages\npersist when the model can iteratively request additional evidence. We obtain a\nnear-perfect context precision (99%), which demonstrates that RAG systems can\nachieve extremely high retrieval accuracy with the right combination of\nhyperparameters, with significant implications for applications where retrieval\nquality directly impacts downstream task performance, such as clinical decision\nsupport in healthcare.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-05-13T11:13:27Z"}
{"aid":"http://arxiv.org/abs/2505.08451v1","title":"Adaptive Bias Generalized Rollout Policy Adaptation on the Flexible\n  Job-Shop Scheduling Problem","summary":"The Flexible Job-Shop Scheduling Problem (FJSSP) is an NP-hard combinatorial\noptimization problem, with several application domains, especially for\nmanufacturing purposes. The objective is to\n  efficiently schedule multiple operations on dissimilar machines. These\noperations are gathered into jobs, and operations pertaining to the same job\nneed to be scheduled sequentially. Different methods have been previously\ntested to solve this problem, such as Constraint Solving, Tabu Search, Genetic\nAlgorithms, or Monte Carlo Tree Search (MCTS). We propose a novel algorithm\nderived from the Generalized Nested Rollout Policy Adaptation, developed to\nsolve the FJSSP. We report encouraging experimental results, as our algorithm\nperforms better than other MCTS-based approaches, even if makespans obtained on\nlarge instances are still far from known upper bounds.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-13T11:27:18Z"}
{"aid":"http://arxiv.org/abs/2505.08457v1","title":"Graviton-photon conversion in blazar jets as a probe of high-frequency\n  gravitational waves","summary":"We study graviton-photon conversion in the magnetic fields of a blazar jet\nand explore the possibility of detecting high-frequency gravitational waves\nthrough blazar observations. We calculate the conversion rate using the\nmagnetic field configurations of leptonic, lepto-hadronic, and hadronic\none-zone synchrotron self-Compton models for the blazar jet of Mrk 501. By\nrequiring that the photon flux produced within the blazar jet does not exceed\nthe observed flux of Mrk 501, we derive conservative constraints on the\nabundance of stochastic gravitational waves. We find that, for all three models\nconsidered, the resulting limits can be more stringent than previous\nconstraints in the frequency range from $10^8$ Hz to $10^{15}$ Hz.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph","published":"2025-05-13T11:40:07Z"}
{"aid":"http://arxiv.org/abs/2505.08463v1","title":"RepCali: High Efficient Fine-tuning Via Representation Calibration in\n  Latent Space for Pre-trained Language Models","summary":"Fine-tuning pre-trained language models (PLMs) has become a dominant paradigm\nin applying PLMs to downstream tasks. However, with limited fine-tuning, PLMs\nstill struggle with the discrepancies between the representation obtained from\nthe PLMs' encoder and the optimal input to the PLMs' decoder. This paper\ntackles this challenge by learning to calibrate the representation of PLMs in\nthe latent space. In the proposed representation calibration method (RepCali),\nwe integrate a specific calibration block to the latent space after the encoder\nand use the calibrated output as the decoder input. The merits of the proposed\nRepCali include its universality to all PLMs with encoder-decoder\narchitectures, its plug-and-play nature, and ease of implementation. Extensive\nexperiments on 25 PLM-based models across 8 tasks (including both English and\nChinese datasets) demonstrate that the proposed RepCali offers desirable\nenhancements to PLMs (including LLMs) and significantly improves the\nperformance of downstream tasks. Comparison experiments across 4 benchmark\ntasks indicate that RepCali is superior to the representative fine-tuning\nbaselines.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-13T11:47:00Z"}
{"aid":"http://arxiv.org/abs/2505.08468v1","title":"Judging the Judges: Can Large Vision-Language Models Fairly Evaluate\n  Chart Comprehension and Reasoning?","summary":"Charts are ubiquitous as they help people understand and reason with data.\nRecently, various downstream tasks, such as chart question answering,\nchart2text, and fact-checking, have emerged. Large Vision-Language Models\n(LVLMs) show promise in tackling these tasks, but their evaluation is costly\nand time-consuming, limiting real-world deployment. While using LVLMs as judges\nto assess the chart comprehension capabilities of other LVLMs could streamline\nevaluation processes, challenges like proprietary datasets, restricted access\nto powerful models, and evaluation costs hinder their adoption in industrial\nsettings. To this end, we present a comprehensive evaluation of 13 open-source\nLVLMs as judges for diverse chart comprehension and reasoning tasks. We design\nboth pairwise and pointwise evaluation tasks covering criteria like factual\ncorrectness, informativeness, and relevancy. Additionally, we analyze LVLM\njudges based on format adherence, positional consistency, length bias, and\ninstruction-following. We focus on cost-effective LVLMs (<10B parameters)\nsuitable for both research and commercial use, following a standardized\nevaluation protocol and rubric to measure the LVLM judge's accuracy.\nExperimental results reveal notable variability: while some open LVLM judges\nachieve GPT-4-level evaluation performance (about 80% agreement with GPT-4\njudgments), others struggle (below ~10% agreement). Our findings highlight that\nstate-of-the-art open-source LVLMs can serve as cost-effective automatic\nevaluators for chart-related tasks, though biases such as positional preference\nand length bias persist.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-05-13T11:50:08Z"}
{"aid":"http://arxiv.org/abs/2505.08494v1","title":"Universal enveloping H-pseudoalgebras of DGP pseudoalgebras","summary":"The notions of Poisson $H$-pseudoalgebras are generalizations of Poisson\nalgebras in a pseudotensor category $\\mathcal{M}^{\\ast}(H)$. This paper\nintroduces an analogue of Poisson-Ore extension in Poisson $H$-pseudoalgebras.\nPoisson $H$-pseudoalgebras with the differential graded setting induces the\nnotions of differential graded Poisson $H$-pseudoalgebras (DGP pseudoalgebras,\nfor short). The DGP pseudoalgebra with some compatibility conditions is proved\nto be closed under tensor product. Furthermore, the universal enveloping\n$H$-pseudoalgebras of DGP pseudoalgebras are constructed by a\n$\\mathcal{P}$-triple. A unique differential graded pseudoalgebra homomorphism\nbetween a universal enveloping $H$-pseudoalgebra of a DGP pseudoalgebra and a\n$\\mathcal{P}$-triple of a DGP pseudoalgebra is obtained.","main_category":"math.AC","categories":"math.AC","published":"2025-05-13T12:23:50Z"}
{"aid":"http://arxiv.org/abs/2505.08503v1","title":"ICVul: A Well-labeled C/C++ Vulnerability Dataset with Comprehensive\n  Metadata and VCCs","summary":"Machine learning-based software vulnerability detection requires high-quality\ndatasets, which is essential for training effective models. To address\nchallenges related to data label quality, diversity, and comprehensiveness, we\nconstructed ICVul, a dataset emphasizing data quality and enriched with\ncomprehensive metadata, including Vulnerability-Contributing Commits (VCCs). We\nbegan by filtering Common Vulnerabilities and Exposures from the NVD, retaining\nonly those linked to GitHub fix commits. Then we extracted functions and files\nalong with relevant metadata from these commits and used the SZZ algorithm to\ntrace VCCs. To further enhance label reliability, we developed the ESC\n(Eliminate Suspicious Commit) technique, ensuring credible data labels. The\ndataset is stored in a relational-like database for improved usability and data\nintegrity. Both ICVul and its construction framework are publicly accessible on\nGitHub, supporting research in related field.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-13T12:33:51Z"}
{"aid":"http://arxiv.org/abs/2505.08509v1","title":"On the role of pairing correlations in calculation of \\b{eta}-decay\n  half-lives within QRPA formalism","summary":"In this paper we show that the proton-neutron residual interaction can play\nan important role in the reliability of calculated $\\beta$-decay half-lives. It\nmay also improve the prediction power of the quasiparticle random phase\napproximation (QRPA) model. We further demonstrate that a reasonable choice of\nthe particle-particle (attractive) and particle-hole force (repulsive)\nparameters can result in calculated half-lives in very good comparison with the\nmeasured ones. Pairing gaps have affect on calculated half-lives which we\nexplore in this paper. We present our half-lives calculation using the\nproton-neutron QRPA (pn-QRPA) model possessing a multi-shell single-particle\ndeformed space including a schematic interaction for some medium mass\nneutron-deficient nuclei undergoing $\\beta^{+}$/EC decay. Our study shows a\nbetter agreement with the available experimental data as compared to former\ncalculations.","main_category":"nucl-th","categories":"nucl-th","published":"2025-05-13T12:40:07Z"}
{"aid":"http://arxiv.org/abs/2505.08514v1","title":"Convolutional Spiking Neural Network for Image Classification","summary":"We consider an implementation of convolutional architecture in a spiking\nneural network (SNN) used to classify images. As in the traditional neural\nnetwork, the convolutional layers form informational \"features\" used as\npredictors in the SNN-based classifier with CoLaNET architecture. Since weight\nsharing contradicts the synaptic plasticity locality principle, the\nconvolutional weights are fixed in our approach. We describe a methodology for\ntheir determination from a representative set of images from the same domain as\nthe classified ones. We illustrate and test our approach on a classification\ntask from the NEOVISION2 benchmark.","main_category":"cs.NE","categories":"cs.NE","published":"2025-05-13T12:47:13Z"}
{"aid":"http://arxiv.org/abs/2505.08529v1","title":"ExEBench: Benchmarking Foundation Models on Extreme Earth Events","summary":"Our planet is facing increasingly frequent extreme events, which pose major\nrisks to human lives and ecosystems. Recent advances in machine learning (ML),\nespecially with foundation models (FMs) trained on extensive datasets, excel in\nextracting features and show promise in disaster management. Nevertheless,\nthese models often inherit biases from training data, challenging their\nperformance over extreme values. To explore the reliability of FM in the\ncontext of extreme events, we introduce \\textbf{ExE}Bench (\\textbf{Ex}treme\n\\textbf{E}arth Benchmark), a collection of seven extreme event categories\nacross floods, wildfires, storms, tropical cyclones, extreme precipitation,\nheatwaves, and cold waves. The dataset features global coverage, varying data\nvolumes, and diverse data sources with different spatial, temporal, and\nspectral characteristics. To broaden the real-world impact of FMs, we include\nmultiple challenging ML tasks that are closely aligned with operational needs\nin extreme events detection, monitoring, and forecasting. ExEBench aims to (1)\nassess FM generalizability across diverse, high-impact tasks and domains, (2)\npromote the development of novel ML methods that benefit disaster management,\nand (3) offer a platform for analyzing the interactions and cascading effects\nof extreme events to advance our understanding of Earth system, especially\nunder the climate change expected in the decades to come. The dataset and code\nare public https://github.com/zhaoshan2/EarthExtreme-Bench.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-13T13:02:04Z"}
{"aid":"http://arxiv.org/abs/2505.08530v1","title":"The environmental impact, carbon emissions and sustainability of\n  computing in the ATLAS experiment","summary":"ATLAS, a general-purpose experiment at the Large Hadron Collider (LHC),\noperates a large internationally-distributed computing infrastructure,\nincluding over $10^6$ TB of managed data on disk and tape and almost one\nmillion simultaneously running CPU cores. Upgrades for the High-Luminosity LHC\n(HL-LHC) will increase the required computing resources by a factor of 3-4 by\nthe beginning of the 2030s, and by an order of magnitude before the conclusion\nof data taking at the beginning of the 2040s. These resources are spread over\naround 100 computing sites worldwide. Efforts are underway within the\nexperiment to evaluate and mitigate various aspects of the environmental impact\nof the sites, with the additional long-term goal of making recommendations to\nthe sites that will significantly reduce the total expected environmental\nimpact in the HL-LHC era. These efforts take several forms: building awareness\nin the experiment community, adjusting aspects of the computing policy, and\nmodifications of data center configurations, either in ways that take advantage\nof particular features of ATLAS workloads or in generic ways that reduce the\nenvironmental impact of the computing resources. This paper describes the\nongoing investigations and approaches that have already provided useful, and\nactionable outcomes that can be implemented today.","main_category":"hep-ex","categories":"hep-ex","published":"2025-05-13T13:02:24Z"}
{"aid":"http://arxiv.org/abs/2505.08532v1","title":"The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large\n  Language Models Unmask Fake News","summary":"In today's digital environment, the rapid propagation of fake news via social\nnetworks poses significant social challenges. Most existing detection methods\neither employ traditional classification models, which suffer from low\ninterpretability and limited generalization capabilities, or craft specific\nprompts for large language models (LLMs) to produce explanations and results\ndirectly, failing to leverage LLMs' reasoning abilities fully. Inspired by the\nsaying that \"truth becomes clearer through debate,\" our study introduces a\nnovel multi-agent system with LLMs named TruEDebate (TED) to enhance the\ninterpretability and effectiveness of fake news detection. TED employs a\nrigorous debate process inspired by formal debate settings. Central to our\napproach are two innovative components: the DebateFlow Agents and the\nInsightFlow Agents. The DebateFlow Agents organize agents into two teams, where\none supports and the other challenges the truth of the news. These agents\nengage in opening statements, cross-examination, rebuttal, and closing\nstatements, simulating a rigorous debate process akin to human discourse\nanalysis, allowing for a thorough evaluation of news content. Concurrently, the\nInsightFlow Agents consist of two specialized sub-agents: the Synthesis Agent\nand the Analysis Agent. The Synthesis Agent summarizes the debates and provides\nan overarching viewpoint, ensuring a coherent and comprehensive evaluation. The\nAnalysis Agent, which includes a role-aware encoder and a debate graph,\nintegrates role embeddings and models the interactions between debate roles and\narguments using an attention mechanism, providing the final judgment.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-05-13T13:03:20Z"}
{"aid":"http://arxiv.org/abs/2505.08537v1","title":"The RaspGrade Dataset: Towards Automatic Raspberry Ripeness Grading with\n  Deep Learning","summary":"This research investigates the application of computer vision for rapid,\naccurate, and non-invasive food quality assessment, focusing on the novel\nchallenge of real-time raspberry grading into five distinct classes within an\nindustrial environment as the fruits move along a conveyor belt. To address\nthis, a dedicated dataset of raspberries, namely RaspGrade, was acquired and\nmeticulously annotated. Instance segmentation experiments revealed that\naccurate fruit-level masks can be obtained; however, the classification of\ncertain raspberry grades presents challenges due to color similarities and\nocclusion, while others are more readily distinguishable based on color. The\nacquired and annotated RaspGrade dataset is accessible on HuggingFace at:\nhttps://huggingface.co/datasets/FBK-TeV/RaspGrade.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T13:07:29Z"}
{"aid":"http://arxiv.org/abs/2505.08539v1","title":"Connected signed graphs with given inertia indices and given girth","summary":"Suppose that $\\Gamma=(G, \\sigma)$ is a connected signed graph with at least\none cycle. The number of positive, negative and zero eigenvalues of the\nadjacency matrix of $\\Gamma$ are called positive inertia index, negative\ninertia index and nullity of $\\Gamma$, which are denoted by $i_+(\\Gamma)$,\n$i_-(\\Gamma)$ and $\\eta(\\Gamma)$, respectively. Denoted by $g$ the girth, which\nis the length of the shortest cycle of $\\Gamma$. We study relationships between\nthe girth and the negative inertia index of $\\Gamma$ in this article. We prove\n$i_{-}(\\Gamma)\\geq \\lceil\\frac{g}{2}\\rceil-1$ and extremal signed graphs\ncorresponding to the lower bound are characterized. Furthermore, the signed\ngraph $\\Gamma$ with $i_{-}(\\Gamma)=\\lceil\\frac{g}{2}\\rceil$ for $g\\geq 4$ are\ngiven. As a by-product, the connected signed graphs with given positive inertia\nindex, nullity and given girth are also determined, respectively.","main_category":"math.SP","categories":"math.SP","published":"2025-05-13T13:10:19Z"}
{"aid":"http://arxiv.org/abs/2505.08546v1","title":"Are We Paying Attention to Her? Investigating Gender Disambiguation and\n  Attention in Machine Translation","summary":"While gender bias in modern Neural Machine Translation (NMT) systems has\nreceived much attention, traditional evaluation metrics do not to fully capture\nthe extent to which these systems integrate contextual gender cues. We propose\na novel evaluation metric called Minimal Pair Accuracy (MPA), which measures\nthe reliance of models on gender cues for gender disambiguation. MPA is\ndesigned to go beyond surface-level gender accuracy metrics by focusing on\nwhether models adapt to gender cues in minimal pairs -- sentence pairs that\ndiffer solely in the gendered pronoun, namely the explicit indicator of the\ntarget's entity gender in the source language (EN). We evaluate a number of NMT\nmodels on the English-Italian (EN--IT) language pair using this metric, we show\nthat they ignore available gender cues in most cases in favor of (statistical)\nstereotypical gender interpretation. We further show that in anti-stereotypical\ncases, these models tend to more consistently take masculine gender cues into\naccount while ignoring the feminine cues. Furthermore, we analyze the attention\nhead weights in the encoder component and show that while all models encode\ngender information to some extent, masculine cues elicit a more diffused\nresponse compared to the more concentrated and specialized responses to\nfeminine gender cues.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-13T13:17:23Z"}
{"aid":"http://arxiv.org/abs/2505.08561v1","title":"Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided\n  Adaptive Token Selection","summary":"Masked video modeling~(MVM) has emerged as a highly effective pre-training\nstrategy for visual foundation models, whereby the model reconstructs masked\nspatiotemporal tokens using information from visible tokens. However, a key\nchallenge in such approaches lies in selecting an appropriate masking strategy.\nPrevious studies have explored predefined masking techniques, including random\nand tube-based masking, as well as approaches that leverage key motion priors,\noptical flow and semantic cues from externally pre-trained models. In this\nwork, we introduce a novel and generalizable Trajectory-Aware Adaptive Token\nSampler (TATS), which models the motion dynamics of tokens and can be\nseamlessly integrated into the masked autoencoder (MAE) framework to select\nmotion-centric tokens in videos. Additionally, we propose a unified training\nstrategy that enables joint optimization of both MAE and TATS from scratch\nusing Proximal Policy Optimization (PPO). We show that our model allows for\naggressive masking without compromising performance on the downstream task of\naction recognition while also ensuring that the pre-training remains memory\nefficient. Extensive experiments of the proposed approach across four\nbenchmarks, including Something-Something v2, Kinetics-400, UCF101, and HMDB51,\ndemonstrate the effectiveness, transferability, generalization, and efficiency\nof our work compared to other state-of-the-art methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T13:35:41Z"}
{"aid":"http://arxiv.org/abs/2505.08567v1","title":"Modelling the multi-wavelength emission and polarisation signatures of\n  the novel white-dwarf pulsar system AR Sco","summary":"The reclassification of AR Scorpii (AR Sco) from a delta Scuti variable star\nto a white dwarf binary system has initiated an in-depth exploration of this\nnovel system. The main aim of this work was to develop a general emission code\nto concurrently model the emission maps, light curves, and spectra at various\norbital phases for AR Sco. For the development of the emission code, I solved\nthe general equations of motion with included classical radiation reaction\nforces (RRF) by implementing the Dormand-Prince 8(7) numerical integrator with\nadaptive time-step methods. This yielded improved accuracy and computational\ntime vs. the commonly used Vay symplectic integrator, particularly for the high\n$B$-fields, $E_{\\perp}$-fields, and RRF needed for pulsar and pulsar-like\nmagnetospheres. Additionally, I demonstrated the novel result of the particles\nentering and conforming to the radiation reaction limit regime of Aristotelian\nElectrodynamics. As calibration for the radiation calculations, emission maps,\nand spectra I compared my model output with results from the code of the pulsar\nemission model of Harding and collaborators for a pulsar with $10\\%$ the\n$B$-field strength of Vela and how my results converged to theirs. Next, I\nshowed my exploratory modelling of the magnetic mirror scenario proposed for AR\nSco. I demonstrate I could fit the observational spectral energy distribution\nincluding the recent \\textit{NICER} pulsed X-ray spectrum well, constraining\nthe white dwarf $B$-field to $B_{\\rm S} = (2.5 - 3.0) \\times 10^{8} \\, \\rm{G}$.\nFinally, I showed the effect the $B$-field, $E_{\\perp}$-field, initial pitch\nangle, and initial particle Lorentz factor have on the mirror points, RRF,\nemission maps, and spectra. This demonstrates how crucial it is to include the\ngeneral particle dynamics to accurately model the micro-physics present in\nmagnetic mirror models.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-05-13T13:41:48Z"}
{"aid":"http://arxiv.org/abs/2505.08568v1","title":"Thermal Detection of People with Mobility Restrictions for Barrier\n  Reduction at Traffic Lights Controlled Intersections","summary":"Rapid advances in deep learning for computer vision have driven the adoption\nof RGB camera-based adaptive traffic light systems to improve traffic safety\nand pedestrian comfort. However, these systems often overlook the needs of\npeople with mobility restrictions. Moreover, the use of RGB cameras presents\nsignificant challenges, including limited detection performance under adverse\nweather or low-visibility conditions, as well as heightened privacy concerns.\nTo address these issues, we propose a fully automated, thermal detector-based\ntraffic light system that dynamically adjusts signal durations for individuals\nwith walking impairments or mobility burden and triggers the auditory signal\nfor visually impaired individuals, thereby advancing towards barrier-free\nintersection for all users. To this end, we build the thermal dataset for\npeople with mobility restrictions (TD4PWMR), designed to capture diverse\npedestrian scenarios, particularly focusing on individuals with mobility aids\nor mobility burden under varying environmental conditions, such as different\nlighting, weather, and crowded urban settings. While thermal imaging offers\nadvantages in terms of privacy and robustness to adverse conditions, it also\nintroduces inherent hurdles for object detection due to its lack of color and\nfine texture details and generally lower resolution of thermal images. To\novercome these limitations, we develop YOLO-Thermal, a novel variant of the\nYOLO architecture that integrates advanced feature extraction and attention\nmechanisms for enhanced detection accuracy and robustness in thermal imaging.\nExperiments demonstrate that the proposed thermal detector outperforms existing\ndetectors, while the proposed traffic light system effectively enhances\nbarrier-free intersection. The source codes and dataset are available at\nhttps://github.com/leon2014dresden/YOLO-THERMAL.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T13:44:21Z"}
{"aid":"http://arxiv.org/abs/2505.08573v1","title":"Joint Optimization of User Association and Resource Allocation for Load\n  Balancing With Multi-Level Fairness","summary":"User association, the problem of assigning each user device to a suitable\nbase station, is increasingly crucial as wireless networks become denser and\nserve more users with diverse service demands. The joint optimization of user\nassociation and resource allocation (UARA) is a fundamental issue for future\nwireless networks, as it plays a pivotal role in enhancing overall network\nperformance, user fairness, and resource efficiency. Given the\nlatency-sensitive nature of emerging network applications, network management\nfavors algorithms that are simple and computationally efficient rather than\ncomplex centralized approaches. Thus, distributed pricing-based strategies have\ngained prominence in the UARA literature, demonstrating practicality and\neffectiveness across various objective functions, e.g., sum-rate, proportional\nfairness, max-min fairness, and alpha-fairness. While the alpha-fairness\nframeworks allow for flexible adjustments between efficiency and fairness via a\nsingle parameter $\\alpha$, existing works predominantly assume a homogeneous\nfairness context, assigning an identical $\\alpha$ value to all users.\nReal-world networks, however, frequently require differentiated user\nprioritization due to varying application requirements and latency. To bridge\nthis gap, we propose a novel heterogeneous alpha-fairness (HAF) objective\nfunction, assigning distinct {\\alpha} values to different users, thereby\nproviding enhanced control over the balance between throughput, fairness, and\nlatency across the network. We present a distributed, pricing-based\noptimization approach utilizing an auxiliary variable framework and provide\nanalytical proof of its convergence to an $\\epsilon$-optimal solution, where\nthe optimality gap $\\epsilon$ decreases with the number of iterations.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-13T13:46:26Z"}
{"aid":"http://arxiv.org/abs/2505.08584v1","title":"Semiclassical defect measures of magnetic Laplacians on hyperbolic\n  surfaces","summary":"On a closed hyperbolic surface, we investigate semiclassical defect measures\nassociated with the magnetic Laplacian in the presence of a constant magnetic\nfield. Depending on the energy level where the eigenfunctions concentrate,\nthree distinct dynamical regimes emerge. In the low-energy regime, we show that\nany invariant measure of the magnetic flow in phase space can be obtained as a\nsemiclassical measure. At the critical energy level, we establish Quantum\nUnique Ergodicity, together with a quantitative rate of convergence of\neigenfunctions to the Liouville measure. In the high-energy regime, we prove a\nShnirelman-type result: a density-one subsequence of eigenfunctions becomes\nequidistributed with respect to the Liouville measure.","main_category":"math.AP","categories":"math.AP,math.DG,math.DS","published":"2025-05-13T13:56:38Z"}
{"aid":"http://arxiv.org/abs/2505.08588v1","title":"Small but Significant: On the Promise of Small Language Models for\n  Accessible AIED","summary":"GPT has become nearly synonymous with large language models (LLMs), an\nincreasingly popular term in AIED proceedings. A simple keyword-based search\nreveals that 61% of the 76 long and short papers presented at AIED 2024\ndescribe novel solutions using LLMs to address some of the long-standing\nchallenges in education, and 43% specifically mention GPT. Although LLMs\npioneered by GPT create exciting opportunities to strengthen the impact of AI\non education, we argue that the field's predominant focus on GPT and other\nresource-intensive LLMs (with more than 10B parameters) risks neglecting the\npotential impact that small language models (SLMs) can make in providing\nresource-constrained institutions with equitable and affordable access to\nhigh-quality AI tools. Supported by positive results on knowledge component\n(KC) discovery, a critical challenge in AIED, we demonstrate that SLMs such as\nPhi-2 can produce an effective solution without elaborate prompting strategies.\nHence, we call for more attention to developing SLM-based AIED approaches.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.HC","published":"2025-05-13T13:58:29Z"}
{"aid":"http://arxiv.org/abs/2505.08601v1","title":"Rejoining fragmented ancient bamboo slips with physics-driven deep\n  learning","summary":"Bamboo slips are a crucial medium for recording ancient civilizations in East\nAsia, and offers invaluable archaeological insights for reconstructing the Silk\nRoad, studying material culture exchanges, and global history. However, many\nexcavated bamboo slips have been fragmented into thousands of irregular pieces,\nmaking their rejoining a vital yet challenging step for understanding their\ncontent. Here we introduce WisePanda, a physics-driven deep learning framework\ndesigned to rejoin fragmented bamboo slips. Based on the physics of fracture\nand material deterioration, WisePanda automatically generates synthetic\ntraining data that captures the physical properties of bamboo fragmentations.\nThis approach enables the training of a matching network without requiring\nmanually paired samples, providing ranked suggestions to facilitate the\nrejoining process. Compared to the leading curve matching method, WisePanda\nincreases Top-50 matching accuracy from 36\\% to 52\\%. Archaeologists using\nWisePanda have experienced substantial efficiency improvements (approximately\n20 times faster) when rejoining fragmented bamboo slips. This research\ndemonstrates that incorporating physical principles into deep learning models\ncan significantly enhance their performance, transforming how archaeologists\nrestore and study fragmented artifacts. WisePanda provides a new paradigm for\naddressing data scarcity in ancient artifact restoration through physics-driven\nmachine learning.","main_category":"cs.CV","categories":"cs.CV,cond-mat.mtrl-sci","published":"2025-05-13T14:16:53Z"}
{"aid":"http://arxiv.org/abs/2505.08602v1","title":"Well-posedness and stability of the Lagrange representation of the n-D\n  wave equation via boundary triples","summary":"We study the Lagrange representation of the wave equation with generalized\nLaplacian $\\operatorname{div} T \\nabla$. We allow the coefficients -- the Young\nmodulus $T$ and the density $\\rho$ -- to be $\\mathrm{L}^{\\infty}$ or even\nnonlocal operators. Moreover, the Lipschitz boundary of the domain $\\Omega$ can\nbe split into several parts admitting Dirichlet, Neumann and/or Robin-boundary\nconditions of displacement, velocity and stress. We show well-posedness of this\nclassical model of the wave equation utilizing boundary triple theory for\nskew-adjoint operators. In addition we show semi-uniform stability of solutions\nunder slightly stronger assumptions by means of a spectral result.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-05-13T14:18:25Z"}
{"aid":"http://arxiv.org/abs/2505.08605v1","title":"Leveraging Multi-Modal Information to Enhance Dataset Distillation","summary":"Dataset distillation aims to create a compact and highly representative\nsynthetic dataset that preserves the knowledge of a larger real dataset. While\nexisting methods primarily focus on optimizing visual representations,\nincorporating additional modalities and refining object-level information can\nsignificantly improve the quality of distilled datasets. In this work, we\nintroduce two key enhancements to dataset distillation: caption-guided\nsupervision and object-centric masking. To integrate textual information, we\npropose two strategies for leveraging caption features: the feature\nconcatenation, where caption embeddings are fused with visual features at the\nclassification stage, and caption matching, which introduces a caption-based\nalignment loss during training to ensure semantic coherence between real and\nsynthetic data. Additionally, we apply segmentation masks to isolate target\nobjects and remove background distractions, introducing two loss functions\ndesigned for object-centric learning: masked feature alignment loss and masked\ngradient matching loss. Comprehensive evaluations demonstrate that integrating\ncaption-based guidance and object-centric masking enhances dataset\ndistillation, leading to synthetic datasets that achieve superior performance\non downstream tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T14:20:11Z"}
{"aid":"http://arxiv.org/abs/2505.08607v1","title":"Boosting Zero-shot Stereo Matching using Large-scale Mixed Images\n  Sources in the Real World","summary":"Stereo matching methods rely on dense pixel-wise ground truth labels, which\nare laborious to obtain, especially for real-world datasets. The scarcity of\nlabeled data and domain gaps between synthetic and real-world images also pose\nnotable challenges. In this paper, we propose a novel framework,\n\\textbf{BooSTer}, that leverages both vision foundation models and large-scale\nmixed image sources, including synthetic, real, and single-view images. First,\nto fully unleash the potential of large-scale single-view images, we design a\ndata generation strategy combining monocular depth estimation and diffusion\nmodels to generate dense stereo matching data from single-view images. Second,\nto tackle sparse labels in real-world datasets, we transfer knowledge from\nmonocular depth estimation models, using pseudo-mono depth labels and a dynamic\nscale- and shift-invariant loss for additional supervision. Furthermore, we\nincorporate vision foundation model as an encoder to extract robust and\ntransferable features, boosting accuracy and generalization. Extensive\nexperiments on benchmark datasets demonstrate the effectiveness of our\napproach, achieving significant improvements in accuracy over existing methods,\nparticularly in scenarios with limited labeled data and domain shifts.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-13T14:24:38Z"}
{"aid":"http://arxiv.org/abs/2505.08609v1","title":"A new class of compactified Jacobians for families of reduced curves","summary":"This is the first paper of a series of three. Here we give an abstract\ndefinition of the relative compactified Jacobian of a family of reduced curves.\nWe prove that, under some mild assumptions on the family of curves, the fibres\nof the relative Jacobian are schemes (and not just algebraic spaces).\n  We define V-stability conditions, and use them to construct relative\ncompactified Jacobians. This extends the classical methods to produce modular\ncompactifications of the Jacobian. To conclude, we show that, in the case when\nthe curves have at worst planar singularities, the compactified Jacobians\nconstructed from V-stability conditions have the same good properties of the\nclassical ones.","main_category":"math.AG","categories":"math.AG","published":"2025-05-13T14:29:03Z"}
{"aid":"http://arxiv.org/abs/2505.08612v1","title":"Demonstration of logical quantum phase estimation for X-ray absorption\n  spectra","summary":"In this study, we employed Fourier-based quantum phase estimation (QPE) to\ncalculate X-ray absorption spectroscopy (XAS) spectra. The primary focus of\nthis study is the calculation of the XAS spectra of transition metal\n$L_{2,3}$-edges, which are dominated by strong correlation effects. First, the\nFe $L_{2,3}$-edge X-ray absorption near-edge structure of FePO$_4$ is\ncalculated using a noiseless simulator. The present computation involves a\ncomparison of three types of input states: a uniform superposition state,\noptimal entangled input state, and Slater function state. Subsequently, we\ninvestigated the resolution error of the QPE and statistical error attributed\nto the measurements. It was revealed that post-processing to introduce\nLorentzian broadening reduces the statistical error, which becomes a\nsignificant problem for a large number of qubits. Subsequently, we implemented\nQPE on a trapped-ion quantum computer, encompassing three orbitals within the\nactive space. To this end, we implemented QPE using dynamic circuits to reduce\nancilla qubits and [[k+2, k, 2]] quantum error detection code to mitigate the\nquantum noise inherent in current quantum computers. As a result, it was\ndemonstrated that hardware noise was reduced, and spectra close to the\nnoiseless ones were obtained.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T14:30:38Z"}
{"aid":"http://arxiv.org/abs/2505.08623v1","title":"Rough Bergomi turns grey","summary":"We propose a tractable extension of the rough Bergomi model, replacing the\nfractional Brownian motion with a generalised grey Brownian motion, which we\nshow to be reminiscent of models with stochastic volatility of volatility. This\nextension breaks away from the log-Normal assumption of rough Bergomi, thereby\nmaking it a viable suggestion for the Equity Holy Grail -- the joint SPX/VIX\noptions calibration. For this new (class of) model(s), we provide semi-closed\nand asymptotic formulae for SPX and VIX options and show numerically its\npotential advantages as well as calibration results.","main_category":"q-fin.PR","categories":"q-fin.PR,math.PR","published":"2025-05-13T14:40:33Z"}
{"aid":"http://arxiv.org/abs/2505.08627v1","title":"Augmented Reality for RObots (ARRO): Pointing Visuomotor Policies\n  Towards Visual Robustness","summary":"Visuomotor policies trained on human expert demonstrations have recently\nshown strong performance across a wide range of robotic manipulation tasks.\nHowever, these policies remain highly sensitive to domain shifts stemming from\nbackground or robot embodiment changes, which limits their generalization\ncapabilities. In this paper, we present ARRO, a novel calibration-free visual\nrepresentation that leverages zero-shot open-vocabulary segmentation and object\ndetection models to efficiently mask out task-irrelevant regions of the scene\nwithout requiring additional training. By filtering visual distractors and\noverlaying virtual guides during both training and inference, ARRO improves\nrobustness to scene variations and reduces the need for additional data\ncollection. We extensively evaluate ARRO with Diffusion Policy on several\ntabletop manipulation tasks in both simulation and real-world environments, and\nfurther demonstrate its compatibility and effectiveness with generalist robot\npolicies, such as Octo and OpenVLA. Across all settings in our evaluation, ARRO\nyields consistent performance gains, allows for selective masking to choose\nbetween different objects, and shows robustness even to challenging\nsegmentation conditions. Videos showcasing our results are available at:\naugmented-reality-for-robots.github.io","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-13T14:46:23Z"}
{"aid":"http://arxiv.org/abs/2505.08631v1","title":"Learning cardiac activation and repolarization times with operator\n  learning","summary":"Solving partial or ordinary differential equation models in cardiac\nelectrophysiology is a computationally demanding task, particularly when\nhigh-resolution meshes are required to capture the complex dynamics of the\nheart. Moreover, in clinical applications, it is essential to employ\ncomputational tools that provide only relevant information, ensuring clarity\nand ease of interpretation. In this work, we exploit two recently proposed\noperator learning approaches, namely Fourier Neural Operators (FNO) and Kernel\nOperator Learning (KOL), to learn the operator mapping the applied stimulus in\nthe physical domain into the activation and repolarization time distributions.\nThese data-driven methods are evaluated on synthetic 2D and 3D domains, as well\nas on a physiologically realistic left ventricle geometry. Notably, while the\nlearned map between the applied current and activation time has its modelling\ncounterpart in the Eikonal model, no equivalent partial differential equation\n(PDE) model is known for the map between the applied current and repolarization\ntime. Our results demonstrate that both FNO and KOL approaches are robust to\nhyperparameter choices and computationally efficient compared to traditional\nPDE-based Monodomain models. These findings highlight the potential use of\nthese surrogate operators to accelerate cardiac simulations and facilitate\ntheir clinical integration.","main_category":"math.NA","categories":"math.NA,cs.NA,stat.ML","published":"2025-05-13T14:50:16Z"}
{"aid":"http://arxiv.org/abs/2505.08651v1","title":"Scaling Context, Not Parameters: Training a Compact 7B Language Model\n  for Efficient Long-Context Processing","summary":"We present MegaBeam-Mistral-7B, a language model that supports 512K-token\ncontext length. Our work addresses practical limitations in long-context\ntraining, supporting real-world tasks such as compliance monitoring and\nverification. Evaluated on three long-context benchmarks, our 7B-parameter\nmodel demonstrates superior in-context learning performance on HELMET and\nrobust retrieval and tracing capability on RULER. It is currently the only open\nmodel to achieve competitive long-range reasoning on BABILong at 512K context\nlength without RAG or targeted fine-tuning. Released as fully open source under\nthe Apache 2.0 license, the model has been downloaded over 100,000 times on\nHugging Face. Model available at:\nhttps://huggingface.co/aws-prototyping/MegaBeam-Mistral-7B-512k","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-05-13T15:13:15Z"}
{"aid":"http://arxiv.org/abs/2505.08654v1","title":"An Efficient Multi-scale Leverage Effect Estimator under Dependent\n  Microstructure Noise","summary":"Estimating the leverage effect from high-frequency data is vital but\nchallenged by complex, dependent microstructure noise, often exhibiting\nnon-Gaussian higher-order moments. This paper introduces a novel multi-scale\nframework for efficient and robust leverage effect estimation under such\nflexible noise structures. We develop two new estimators, the\nSubsampling-and-Averaging Leverage Effect (SALE) and the Multi-Scale Leverage\nEffect (MSLE), which adapt subsampling and multi-scale approaches holistically\nusing a unique shifted window technique. This design simplifies the multi-scale\nestimation procedure and enhances noise robustness without requiring the\npre-averaging approach. We establish central limit theorems and stable\nconvergence, with MSLE achieving convergence rates of an optimal $n^{-1/4}$ and\na near-optimal $n^{-1/9}$ for the noise-free and noisy settings, respectively.\nA cornerstone of our framework's efficiency is a specifically designed MSLE\nweighting strategy that leverages covariance structures across scales. This\nsignificantly reduces asymptotic variance and, critically, yields substantially\nsmaller finite-sample errors than existing methods under both noise-free and\nrealistic noisy settings. Extensive simulations and empirical analyses confirm\nthe superior efficiency, robustness, and practical advantages of our approach.","main_category":"stat.ME","categories":"stat.ME,econ.EM,q-fin.ST","published":"2025-05-13T15:15:37Z"}
{"aid":"http://arxiv.org/abs/2505.08656v1","title":"Identification and minimization of losses in microscaled spin-wave\n  transducers","summary":"Magnonics is a promising platform for integrated radio frequency (rf)\ndevices, leveraging its inherent non-reciprocity and reconfigurability.\nHowever, the efficiency of spin-wave transducers driven by rf-currents remains\na major challenge. In this study, we systematically investigate a spin-wave\ntransducer composed of micron-sized rf antennas on yttrium iron garnet (YIG)\nfilms of different thickness - an ideal testbed for integrated magnonic\ndevices. Using propagating spin-wave spectroscopy and numerical simulations, we\nanalyze spin-wave transmission, identifying key loss mechanisms and improving\ndevice efficiency by reducing ohmic resistance. The resulting improvements\nenable high transmission efficiency while exploiting non-reciprocity to achieve\nsignificant isolation on the microscale.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-05-13T15:17:14Z"}
{"aid":"http://arxiv.org/abs/2505.08659v1","title":"An excitation matched local correlation approach to excited state\n  specific perturbation theory","summary":"We develop a cubic scaling approach to excited-state-specific second order\nperturbation theory in which the completeness of a local correlation treatment\nis carefully matched between the ground and excited state. With this matching,\nthe accuracy of the parent method is maintained even as substantial portions of\nthe correlation energy are neglected. Even when treating a long-range charge\ntransfer excitation, cubic scaling is achieved in systems with as few as ten\nnon-hydrogen atoms. In a test on the influence of an explicit solvent molecule\non a long range charge transfer, the approach is qualitatively more accurate\nthan EOM-CCSD and reproduces CC3's excitation energies and excited state\npotential energy surface to within about 0.1 eV and 0.5 kcal/mol, respectively.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-05-13T15:20:58Z"}
{"aid":"http://arxiv.org/abs/2505.08664v1","title":"A Social Robot with Inner Speech for Dietary Guidance","summary":"We explore the use of inner speech as a mechanism to enhance transparency and\ntrust in social robots for dietary advice. In humans, inner speech structures\nthought processes and decision-making; in robotics, it improves explainability\nby making reasoning explicit. This is crucial in healthcare scenarios, where\ntrust in robotic assistants depends on both accurate recommendations and\nhuman-like dialogue, which make interactions more natural and engaging.\nBuilding on this, we developed a social robot that provides dietary advice, and\nwe provided the architecture with inner speech capabilities to validate user\ninput, refine reasoning, and generate clear justifications. The system\nintegrates large language models for natural language understanding and a\nknowledge graph for structured dietary information. By making decisions more\ntransparent, our approach strengthens trust and improves human-robot\ninteraction in healthcare. We validated this by measuring the computational\nefficiency of our architecture and conducting a small user study, which\nassessed the reliability of inner speech in explaining the robot's behavior.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-05-13T15:26:52Z"}
{"aid":"http://arxiv.org/abs/2505.08666v1","title":"Claycode: Stylable and Deformable 2D Scannable Codes","summary":"This paper introduces Claycode, a novel 2D scannable code designed for\nextensive stylization and deformation. Unlike traditional matrix-based codes\n(e.g., QR codes), Claycodes encode their message in a tree structure. During\nthe encoding process, bits are mapped into a topology tree, which is then\ndepicted as a nesting of color regions drawn within the boundaries of a target\npolygon shape. When decoding, Claycodes are extracted and interpreted in\nreal-time from a camera stream. We detail the end-to-end pipeline and show that\nClaycodes allow for extensive stylization without compromising their\nfunctionality. We then empirically demonstrate Claycode's high tolerance to\nheavy deformations, outperforming traditional 2D scannable codes in scenarios\nwhere they typically fail.","main_category":"cs.GR","categories":"cs.GR,cs.CG,cs.CV,cs.HC","published":"2025-05-13T15:28:06Z"}
{"aid":"http://arxiv.org/abs/2505.08668v1","title":"Near-unity quantum interference of transverse spatial modes in an\n  ultra-compact inverse-designed photonic device","summary":"The transverse spatial mode of photons is an untapped resource for scaling up\nintegrated photonic quantum computing. To be practically useful for improving\nscalability, reliable and high-visibility quantum interference between\ntransverse spatial modes on-chip needs to be demonstrated. We show repeatable\nquantum interference using inverse-designed transverse mode beamsplitters that\nhave an ultra-compact footprint of 3 $\\mu m$ $\\times$ 3 $\\mu m$ -- the smallest\ntransverse mode beamsplitters for 1550 nm photons to date. We measure a\nHong-Ou-Mandel visibility of up to 99.56$\\pm$0.64 % from a single device, with\nan average visibility across three identical devices of 99.38$\\pm$0.41 %,\nindicating a high degree of reproducibility. Our work demonstrates that\ninverse-designed components are suitable for engineering quantum interference\non-chip of multimode devices, paving the way for future compact integrated\nquantum photonic devices that exploit the transverse spatial mode of photons\nfor high-dimensional quantum information.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-13T15:30:47Z"}
{"aid":"http://arxiv.org/abs/2505.08677v1","title":"The number of cultural traits, evolving genealogies, and the descendant\n  process","summary":"We consider a Moran-type model of cultural evolution, which describes how\ntraits emerge, are transmitted, and get lost in populations. Our analysis\nfocuses on the underlying cultural genealogies; they were first described by\nAguilar (2015) and are closely related to the ancestral selection graph of\npopulation genetics, wherefore we call them ancestral learning graphs. We\ninvestigate their dynamical behaviour, that is, we are concerned with evolving\ngenealogies. In particular, we consider the total length of the genealogy of a\nsample of individuals from a stationary population as a function of the\n(forward) time at which the sample is taken. This quantity shows a\nsawtooth-like dynamics with linear increase interrupted by collapses to\nnear-zero at random times. We relate this to the metastable behaviour of the\nstochastic logistic model, which describes the evolution of the number of\nancestors, or equivalently, the number of descendants of a given sample.\n  We assume that new inventions appear independently in every individual, and\nall traits of the cultural parent are transmitted to the learner in any given\nlearning event. The set of traits of an individual then agrees with the set of\ninnovations along its genealogy. The properties of the genealogy thus translate\ninto the properties of the trait set of a sample. In particular, the moments of\nthe number of traits are obtained from the moments of the total length of the\ngenealogy.","main_category":"q-bio.PE","categories":"q-bio.PE,math.PR","published":"2025-05-13T15:40:12Z"}
{"aid":"http://arxiv.org/abs/2505.08680v1","title":"Comparison of laser system designs for quantum technologies: BECCAL\n  flight system vs. BECCAL ground test bed","summary":"We present the design of laser systems for the Bose-Einstein Condensate and\nCold Atom Laboratory (BECCAL) payload, enabling numerous quantum technological\nexperiments onboard the International Space Station (ISS), in particular dual\nspecies 87Rb and 41K Bose-Einstein condensates. A flight model (FM) and a\ncommercial off the shelf (COTS) based model are shown, both of which meet the\nBECCAL requirements in terms of functionality, but have differing size, weight\nand power (SWaP) and environmental requirements. The capabilities of both\nmodels are discussed and characteristics compared. The flight model of BECCAL\nuses specifically developed and qualified custom components to create a compact\nand robust system suitable for long-term remote operation onboard the ISS. This\nsystem is based on ECDL-MOPA lasers and free-space optical benches made of\nZerodur, as well as commercial fibre components. The COTS-based system utilizes\nentirely commercial parts to create a functionally equivalent system for\noperation in a standard laboratory, without the strict SWaP and environmental\nconstraints of the flight model.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-05-13T15:42:32Z"}
{"aid":"http://arxiv.org/abs/2505.08686v1","title":"CAD-Coder:Text-Guided CAD Files Code Generation","summary":"Computer-aided design (CAD) is a way to digitally create 2D drawings and 3D\nmodels of real-world products. Traditional CAD typically relies on hand-drawing\nby experts or modifications of existing library files, which doesn't allow for\nrapid personalization. With the emergence of generative artificial\nintelligence, convenient and efficient personalized CAD generation has become\npossible. However, existing generative methods typically produce outputs that\nlack interactive editability and geometric annotations, limiting their\npractical applications in manufacturing. To enable interactive generative CAD,\nwe propose CAD-Coder, a framework that transforms natural language instructions\ninto CAD script codes, which can be executed in Python environments to generate\nhuman-editable CAD files (.Dxf). To facilitate the generation of editable CAD\nsketches with annotation information, we construct a comprehensive dataset\ncomprising 29,130 Dxf files with their corresponding script codes, where each\nsketch preserves both editability and geometric annotations. We evaluate\nCAD-Coder on various 2D/3D CAD generation tasks against existing methods,\ndemonstrating superior interactive capabilities while uniquely providing\neditable sketches with geometric annotations.","main_category":"cs.GR","categories":"cs.GR,cs.CV,cs.LG","published":"2025-05-13T15:45:46Z"}
{"aid":"http://arxiv.org/abs/2505.08689v1","title":"Plastic deformation as a phase transition: a combinatorial model of\n  plastic flow in copper single crystals","summary":"Continuum models of plasticity fail to capture the richness of\nmicrostructural evolution because the continuum is a homogeneous construction.\nThe present study shows that an alternative way is available at the mesoscale\nin the form of truly discrete constructions and in the discrete exterior\ncalculus. A pre-existing continuum mean-field model with two parameters is\nrewritten in the language of the latter to model the properties of a network of\nplastic slip events in a perfect copper single crystal under uniaxial tension.\nThe behaviour of the system is simulated in a triangular 2D mesh in 3D space\nemploying a Metropolis-Hastings algorithm. Phases of distinct character emerge\nand both first-order and second-order phase transitions are observed. The\nphases can be interpreted as representing crystallographic phenomena like\ncross-slip, strain localisation and partial dislocations. The first-order\ntransitions mostly occur as functions of the applied stress, while the\nsecond-order transitions occur exclusively as functions of the mean-field\ncoupling parameter. The former are reminiscent of transitions in other\nstatistical-mechanical models, while the latter find parallels in experimental\nobservations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.stat-mech,math-ph,math.MP","published":"2025-05-13T15:46:53Z"}
{"aid":"http://arxiv.org/abs/2505.08702v1","title":"Uniformly boundedness of finite Morse index solutions to semilinear\n  elliptic equations with rapidly growing nonlinearities in two dimensions","summary":"We consider the Gelfand problem with rapidly growing nonlinearities in the\ntwo-dimensional bounded strictly convex domains. In this paper, we prove the\nuniformly boundedness of finite Morse index solutions. As a result, we show\nthat there exists a solution curve having infinitely many bifurcation/turning\npoints. These results are recently proved by the present author for\nsupercritical nonlinearities when the domain is the unit ball via an ODE\nargument. Instead of the ODE argument, we apply a new method focusing on the\ninteraction between the growth condition of the nonlinearities and the shape of\nthe fundamental solution. As a result, we clarify the bifurcation structure for\ngeneral convex domains.","main_category":"math.AP","categories":"math.AP","published":"2025-05-13T16:07:47Z"}
{"aid":"http://arxiv.org/abs/2505.08703v1","title":"Time as a test-field: the no-boundary universe in motion and a smooth\n  radiation bounce","summary":"We review two arguments for using the Schr\\\"odinger equation in quantum\ncosmology and propose restricting to solutions in which time acts as a\ncomponent with negligible backreaction on the metric - that is, it plays the\nrole of a test field. We apply this idea to various minisuperspace models. In\nthe semiclassical regime we recover expected results: the wavefunction peaks on\nthe classical solution and, in models with a scalar field, the variance of\n$\\zeta$ (a mini-superspace analogue of the comoving curvature perturbation) is\nconserved in time. Applied to the no-boundary wavefunction, our model\nhighlights a bouncing behavior, which gives a straightforward quantum\nrepresentation of global de Sitter space. We argue that the inevitable time\ndependence of the variance of the wavefunction breaks some of the classical de\nSitter symmetries. Then, by modeling radiation as a fluid, we analyze the epoch\nof radiation domination near the singularity. The problem is equivalent to an\n$s$-wave scattering off a central power-law potential of the form $-r^{-2/3}$.\nSuch a potential admits bound states, so the system is stable and the\nwavepacket undergoes unitary scattering. The radiation bounce, as opposed to\nthe no-boundary bounce, does not have a classical counterpart as the\ncorresponding classical solutions are singular. During the radiation bounce,\nthe uncertainty and the expectation value of the scale factor become\ncomparable. By selecting a large initial variance, the bounce can be made\narbitrarily smooth, the mean value of the Hubble parameter correspondingly\nsoft.","main_category":"hep-th","categories":"hep-th,astro-ph.CO,gr-qc","published":"2025-05-13T16:08:45Z"}
{"aid":"http://arxiv.org/abs/2505.08718v1","title":"Gravitational signatures of a nonlinear electrodynamics in $f(R,T)$\n  gravity","summary":"In this work, we investigate a nonlinear electrodynamics model within the\nframework of $f(R,T)$ gravity. We begin by outlining the general features of\nthe theory and analyzing the event horizon under conditions ensuring its real\nand positive definiteness. We then examine light trajectories, focusing on\ncritical orbits, shadow radii, and geodesics of massless particles. The\nparameters $\\alpha$ and $\\beta$, associated with the nonlinear extension of the\nReissner-Nordstr\\\"om spacetime, are constrained using observational data from\nthe Event Horizon Telescope (EHT). Subsequently, we analyze the thermodynamic\nproperties of the system, including Hawking temperature, entropy, and heat\ncapacity. Quasinormal modes are computed for scalar, vector, tensor, and\nspinorial perturbations, with the corresponding time-domain profiles explored\nas well. Gravitational lensing is then studied in both weak and strong\ndeflection limits, along with the stability of photon spheres. Finally, we\nexamine additional topological aspects, including topological thermodynamics\nand the topological photon sphere.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-05-13T16:24:12Z"}
{"aid":"http://arxiv.org/abs/2505.08729v1","title":"Assumption-robust Causal Inference","summary":"In observational causal inference, it is common to encounter multiple\nadjustment sets that appear equally plausible. It is often untestable which of\nthese adjustment sets are valid to adjust for (i.e., satisfies ignorability).\nThis discrepancy can pose practical challenges as it is typically unclear how\nto reconcile multiple, possibly conflicting estimates of the average treatment\neffect (ATE). A naive approach is to report the whole range (convex hull of the\nunion) of the resulting confidence intervals. However, the width of this\ninterval might not shrink to zero in large samples and can be unnecessarily\nwide in real applications. To address this issue, we propose a summary\nprocedure that generates a single estimate, one confidence interval, and\nidentifies a set of units for which the causal effect estimate remains valid,\nprovided at least one adjustment set is valid. The width of our proposed\nconfidence interval shrinks to zero with sample size at $n^{-1/2}$ rate, unlike\nthe original range which is of constant order. Thus, our assumption-robust\napproach enables reliable causal inference on the ATE even in scenarios where\nmost of the adjustment sets are invalid. Admittedly, this robustness comes at a\ncost: our inferential guarantees apply to a target population close to, but\ndifferent from, the one originally intended. We use synthetic and real-data\nexamples to demonstrate that our proposed procedure provides substantially\ntighter confidence intervals for the ATE as compared to the whole range. In\nparticular, for a real-world dataset on 401(k) retirement plans our method\nproduces a confidence interval 50\\% shorter than the whole range of confidence\nintervals based on multiple adjustment sets.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-05-13T16:39:19Z"}
{"aid":"http://arxiv.org/abs/2505.08740v1","title":"Sensitivity-Constrained Fourier Neural Operators for Forward and Inverse\n  Problems in Parametric Differential Equations","summary":"Parametric differential equations of the form du/dt = f(u, x, t, p) are\nfundamental in science and engineering. While deep learning frameworks such as\nthe Fourier Neural Operator (FNO) can efficiently approximate solutions, they\nstruggle with inverse problems, sensitivity estimation (du/dp), and concept\ndrift. We address these limitations by introducing a sensitivity-based\nregularization strategy, called Sensitivity-Constrained Fourier Neural\nOperators (SC-FNO). SC-FNO achieves high accuracy in predicting solution paths\nand consistently outperforms standard FNO and FNO with physics-informed\nregularization. It improves performance in parameter inversion tasks, scales to\nhigh-dimensional parameter spaces (tested with up to 82 parameters), and\nreduces both data and training requirements. These gains are achieved with a\nmodest increase in training time (30% to 130% per epoch) and generalize across\nvarious types of differential equations and neural operators. Code and selected\nexperiments are available at: https://github.com/AMBehroozi/SC_Neural_Operators","main_category":"cs.LG","categories":"cs.LG,cs.CE","published":"2025-05-13T16:54:10Z"}
{"aid":"http://arxiv.org/abs/2505.08746v1","title":"Elevated Hall Responses as Indicators of Edge Reconstruction","summary":"We investigate edge reconstruction scenarios in the $\\nu = 1$ quantum Hall\nstate, focusing on configurations with upstream and downstream charge and\nneutral modes. Our analysis shows that the coexistence of upstream charge and\nneutral modes in a multi-terminal geometry can cause pronounced deviations from\nthe expected quantized values of electrical ($e^2/h$) and thermal ($\\pi^2\nk_\\text{B}^{2}T/3h$) Hall conductance dictated by bulk-boundary correspondence.\nIn particular, we find that both electrical and thermal Hall conductances can\nbe significantly enhanced -- exceeding twice their unreconstructed values --\noffering a clear diagnostic of edge reconstruction.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-05-13T17:00:22Z"}
{"aid":"http://arxiv.org/abs/2505.08760v1","title":"On the abstract elementary class of acts with embeddings","summary":"We study the class of acts with embeddings as an abstract elementary class.\nWe show that the class is always stable and show that superstability in the\nclass is characterized algebraically via weakly noetherian monoids.\n  The study of these model-theoretic notions and limit models lead us to\nintroduce parametized weakly noetherian monoids and find a characterization of\nthem via parametrized injective acts. Furthermore, we obtain a characterization\nof weakly noetherian monoids via absolutely pure acts extending a classical\nresult of ring theory.\n  The paper is aimed at algebraists and model theorists so an effort was made\nto provide the background for both.","main_category":"math.LO","categories":"math.LO,math.GR","published":"2025-05-13T17:28:18Z"}
{"aid":"http://arxiv.org/abs/2505.08764v1","title":"The Environment-Dependent Regulatory Landscape of the E. coli Genome","summary":"All cells respond to changes in both their internal milieu and the\nenvironment around them through the regulation of their genes. Despite decades\nof effort, there remain huge gaps in our knowledge of both the function of many\ngenes (the so-called y-ome) and how they adapt to changing environments via\nregulation. Here we describe a joint experimental and theoretical dissection of\nthe regulation of a broad array of over 100 biologically interesting genes in\nE. coli across 39 diverse environments, permitting us to discover the binding\nsites and transcription factors that mediate regulatory control. Using a\ncombination of mutagenesis, massively parallel reporter assays, mass\nspectrometry and tools from information theory and statistical physics, we go\nfrom complete ignorance of a promoter's environment-dependent regulatory\narchitecture to predictive models of its behavior. As a proof of principle of\nthe biological insights to be gained from such a study, we chose a combination\nof genes from the y-ome, toxin-antitoxin pairs, and genes hypothesized to be\npart of regulatory modules; in all cases, we discovered a host of new insights\ninto their underlying regulatory landscape and resulting biological function.","main_category":"q-bio.GN","categories":"q-bio.GN,q-bio.MN","published":"2025-05-13T17:33:25Z"}
{"aid":"http://arxiv.org/abs/2505.08773v1","title":"Extreme Loss Suppression and Wide Tunability of Dipolar Interactions in\n  an Ultracold Molecular Gas","summary":"Ultracold dipolar molecules hold great promise for the creation of novel\nquantum states of matter, but the realization of long-lived molecular bulk\nsamples with strong dipole-dipole interactions has remained elusive. Here, we\nrealize a collisionally stable gas of ultracold ground state molecules with a\nlifetime of several seconds. Utilizing double microwave dressing, we achieve an\nextreme suppression of inelastic two- and three-body losses by factors of more\nthan 10,000 and 1,000, respectively. We find that losses remain suppressed\nacross a wide range of dipole-dipole interactions, allowing the continuous\ntuning of the dipolar length from 0 to 1 um $\\sim$ 20,000 $a_0$. Combined with\nthe recent realization of Bose-Einstein condensation of dipolar molecules, our\nfindings open the door to the exploration of strongly dipolar quantum liquids.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atm-clus,physics.atom-ph,quant-ph","published":"2025-05-13T17:51:51Z"}
{"aid":"http://arxiv.org/abs/2505.08774v1","title":"Generative Molecular Design with Steerable and Granular Synthesizability\n  Control","summary":"Synthesizability in small molecule generative design remains a bottleneck.\nExisting works that do consider synthesizability can output predicted synthesis\nroutes for generated molecules. However, there has been minimal attention in\naddressing the ease of synthesis and enabling flexibility to incorporate\ndesired reaction constraints. In this work, we propose a small molecule\ngenerative design framework that enables steerable and granular\nsynthesizability control. Generated molecules satisfy arbitrary multi-parameter\noptimization objectives with predicted synthesis routes containing pre-defined\nallowed reactions, while optionally avoiding others. One can also enforce that\nall reactions belong to a pre-defined set. We show the capability to\nmix-and-match these reaction constraints across the most common medicinal\nchemistry transformations. Next, we show how our framework can be used to\nvalorize industrial byproducts towards de novo optimized molecules. Going\nfurther, we demonstrate how granular control over synthesizability constraints\ncan loosely mimic virtual screening of ultra-large make-on-demand libraries.\nUsing only a single GPU, we generate and dock 15k molecules to identify\npromising candidates in Freedom 4.0 constituting 142B make-on-demand molecules\n(assessing only 0.00001% of the library). Generated molecules satisfying the\nreaction constraints have > 90% exact match rate. Lastly, we benchmark our\nframework against recent synthesizability-constrained generative models and\ndemonstrate the highest sample efficiency even when imposing the additional\nconstraint that all molecules must be synthesizable from a single reaction\ntype. The main theme is demonstrating that a pre-trained generalist molecular\ngenerative model can be incentivized to generate property-optimized small\nmolecules under challenging synthesizability constraints through reinforcement\nlearning.","main_category":"q-bio.BM","categories":"q-bio.BM,cs.LG","published":"2025-05-13T17:53:54Z"}
{"aid":"http://arxiv.org/abs/2505.08777v1","title":"Full-volume aberration-space holography","summary":"Simultaneous, diffraction-limited control of multiple optical beams is\ncrucial for applications ranging from lithography to optogenetics, deep tissue\nimaging, and tweezer-based manipulation of cells, particles, or atoms. Despite\nthe desire to address wider fields of view, deeper volumes, and\nincreasingly-disordered media, spatially-varying aberrations currently restrict\nparallelized steering to a limited \"isoplanatic\" region over which the point\nspread function is invariant. Here, we overcome this limitation by combining\nindividual propagation kernels accounting for site-specific aberrations into a\nsingle spatial light modulator (SLM) hologram. This \"aberration-space\nholography\" unlocks precise, parallel holographic shaping over the SLM's entire\nNyquist-limited volume, enabling us to realize full-field, anisoplanatic\naberration compensation for the first time. By simultaneously correcting 50\nisoplanatic patches with 8 principal aberration modes, we demonstrate a\nfull-field optical tweezer array with 8x larger field of view than the best\nisoplanatic correction. Extending to 3D, we increase the volume of a\nmultiphoton volumetric display by 12x. These performance enhancements are\nimmediately accessible to a diverse range of applications through our\nopen-source software implementation, which combines aberration-space holography\nwith automated experimental feedback, wavefront calibration, and alignment.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-13T17:54:53Z"}
