{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2616bb77-0f74-492a-91cb-e6b23fcb583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "import pyspark\n",
    "\n",
    "spark_home = os.path.abspath(os.getcwd() + \"/../spark-3.5.5-bin-hadoop3\")\n",
    "hadoop_home = os.path.abspath(os.getcwd() + \"/../winutils\")\n",
    "\n",
    "if os.name == 'nt':\n",
    "    os.environ[\"HADOOP_HOME\"] = hadoop_home\n",
    "    os.environ[\"PATH\"] = os.path.join(hadoop_home, \"bin\") + \";\" + os.environ[\"PATH\"]\n",
    "\n",
    "findspark.init(spark_home)\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StringType\n",
    "\n",
    "schema = StructType() \\\n",
    "    .add(\"aid\", StringType()) \\\n",
    "    .add(\"title\", StringType()) \\\n",
    "    .add(\"summary\", StringType()) \\\n",
    "    .add(\"main_category\", StringType()) \\\n",
    "    .add(\"categories\", StringType()) \\\n",
    "    .add(\"published\", StringType())\n",
    "\n",
    "data_path = \"file:///C:/spark_project/spark/notebooks/arxiv_streamed_data/saved_data-*/part-*\"\n",
    "raw_df = spark.read.text(data_path)\n",
    "json_df = raw_df.select(from_json(col(\"value\"), schema).alias(\"data\")).select(\"data.*\")\n",
    "\n",
    "\n",
    "json_df = json_df.dropDuplicates([\"aid\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef918da3-24e5-482b-8ed7-fdcc549e6a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, udf, col\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "json_df = json_df.withColumn(\"text\", concat_ws(\" \", col(\"title\"), col(\"summary\")))\n",
    "\n",
    "\n",
    "def extract_domains(category_str):\n",
    "    if category_str is None:\n",
    "        return []\n",
    "    return list(set([x.strip().split('.')[0].split('-')[0] for x in category_str.split(',')]))\n",
    "\n",
    "extract_domains_udf = udf(extract_domains, ArrayType(StringType()))\n",
    "json_df = json_df.withColumn(\"labels\", extract_domains_udf(col(\"categories\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85feab73-15a8-42f9-9831-6bab461aff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = json_df.select(\"aid\", \"text\", \"labels\").dropna(subset=[\"text\", \"labels\"]).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bafb6399-d3f6-43a3-b1d2-76d2f7c7549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark_project\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6590/6590 [1:01:59<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\").eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = model.device\n",
    "\n",
    "def get_embedding(text):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        outputs = model(**inputs)\n",
    "        cls = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "        return cls.squeeze().cpu().numpy()\n",
    "\n",
    "embeddings = np.stack([get_embedding(t) for t in tqdm(pdf[\"text\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450398c8-bc4d-44e8-9234-80d359b833fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(pdf[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a22a8a-c9ed-4806-ad16-299bff8bef7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          62       1.00      1.00      1.00         1\n",
      "          81       1.00      1.00      1.00         1\n",
      "          92       1.00      1.00      1.00         1\n",
      "          94       1.00      1.00      1.00         1\n",
      "           A       1.00      1.00      1.00         3\n",
      "           D       1.00      1.00      1.00         1\n",
      "           F       1.00      1.00      1.00         4\n",
      "           G       1.00      0.86      0.92        14\n",
      "           H       1.00      0.82      0.90        11\n",
      "           I       1.00      0.40      0.57        40\n",
      "           J       1.00      1.00      1.00         7\n",
      "           M       1.00      1.00      1.00         1\n",
      "       astro       1.00      1.00      1.00       457\n",
      "        cond       0.97      0.95      0.96       567\n",
      "          cs       0.95      0.96      0.95      3344\n",
      "        econ       1.00      1.00      1.00        57\n",
      "        eess       0.91      0.73      0.81       446\n",
      "          gr       1.00      0.98      0.99       208\n",
      "         hep       0.96      0.92      0.94       406\n",
      "        math       0.93      0.88      0.91      1427\n",
      "        nlin       1.00      0.93      0.96        55\n",
      "        nucl       1.00      0.97      0.99        79\n",
      "     physics       0.88      0.73      0.80       605\n",
      "           q       1.00      0.95      0.98       167\n",
      "       quant       0.98      0.95      0.96       420\n",
      "        stat       0.99      0.89      0.93       271\n",
      "\n",
      "   micro avg       0.95      0.91      0.93      8594\n",
      "   macro avg       0.98      0.92      0.94      8594\n",
      "weighted avg       0.95      0.91      0.93      8594\n",
      " samples avg       0.95      0.94      0.94      8594\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark_project\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "clf.fit(embeddings, Y)\n",
    "\n",
    "pred = clf.predict(embeddings)\n",
    "print(classification_report(Y, pred, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f479d9-ae68-4122-8b27-60269efb5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_labels = [label for sublist in pdf[\"labels\"] for label in sublist]\n",
    "label_counts = Counter(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a6a68b-0146-408b-b4b2-1b2d18dbe663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count\n",
      "cs        3344\n",
      "math      1427\n",
      "physics    605\n",
      "cond       567\n",
      "astro      457\n",
      "eess       446\n",
      "quant      420\n",
      "hep        406\n",
      "stat       271\n",
      "gr         208\n",
      "q          167\n",
      "nucl        79\n",
      "econ        57\n",
      "nlin        55\n",
      "I           40\n",
      "G           14\n",
      "H           11\n",
      "J            7\n",
      "F            4\n",
      "A            3\n",
      "62           1\n",
      "94           1\n",
      "M            1\n",
      "81           1\n",
      "D            1\n",
      "92           1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "label_df = pd.DataFrame.from_dict(label_counts, orient='index', columns=['count'])\n",
    "label_df = label_df.sort_values(by='count', ascending=False)\n",
    "print(label_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a7dc07-2553-4e7f-974a-cb01bd98ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = [\n",
    "    'cs', 'math', 'physics', 'cond', 'astro', 'eess',\n",
    "    'quant', 'hep', 'stat', 'gr', 'q', 'nucl', 'econ', 'nlin'\n",
    "]\n",
    "\n",
    "pdf[\"labels\"] = pdf[\"labels\"].apply(lambda lst: [x for x in lst if x in valid_labels])\n",
    "\n",
    "\n",
    "pdf = pdf[pdf[\"labels\"].map(len) > 0].reset_index(drop=True)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(pdf[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "523e5d85-e705-46f9-9358-2209db21d620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       astro       1.00      1.00      1.00       457\n",
      "        cond       0.97      0.95      0.96       567\n",
      "          cs       0.95      0.96      0.95      3344\n",
      "        econ       1.00      1.00      1.00        57\n",
      "        eess       0.91      0.73      0.81       446\n",
      "          gr       1.00      0.98      0.99       208\n",
      "         hep       0.96      0.92      0.94       406\n",
      "        math       0.93      0.88      0.91      1427\n",
      "        nlin       1.00      0.93      0.96        55\n",
      "        nucl       1.00      0.97      0.99        79\n",
      "     physics       0.88      0.73      0.80       605\n",
      "           q       1.00      0.95      0.98       167\n",
      "       quant       0.98      0.95      0.96       420\n",
      "        stat       0.99      0.89      0.93       271\n",
      "\n",
      "   micro avg       0.95      0.91      0.93      8509\n",
      "   macro avg       0.97      0.92      0.94      8509\n",
      "weighted avg       0.95      0.91      0.93      8509\n",
      " samples avg       0.95      0.94      0.94      8509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_filtered = embeddings[pdf.index]  # Same shape as new Y\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "clf.fit(X_filtered, Y)\n",
    "\n",
    "Y_pred = clf.predict(X_filtered)\n",
    "\n",
    "print(classification_report(Y, Y_pred, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(clf, \"cleaned_classifier.pkl\")\n",
    "joblib.dump(mlb, \"label_binarizer.pkl\")\n",
    "np.save(\"filtered_embeddings.npy\", X_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4005a32f-221e-4184-b4c3-e85453db8d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "clf = joblib.load(\"cleaned_classifier.pkl\")\n",
    "mlb = joblib.load(\"label_binarizer.pkl\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "scibert = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\").eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scibert.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f318eef8-f89a-4fd6-848e-1687f102519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_article_labels(title: str, summary: str):\n",
    "    text = f\"{title.strip()} {summary.strip()}\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "        outputs = scibert(**tokens)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    pred_binary = clf.predict(cls_embedding)\n",
    "    pred_labels = mlb.inverse_transform(pred_binary)[0]\n",
    "    \n",
    "    return pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09026ac-b340-453c-b2a5-d84d87199122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_article_labels_with_scores(title: str, summary: str, threshold=0.5):\n",
    "    text = f\"{title.strip()} {summary.strip()}\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "        outputs = scibert(**tokens)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    proba = clf.predict_proba(cls_embedding)[0]\n",
    "    labels = [label for label, p in zip(mlb.classes_, proba) if p >= threshold]\n",
    "    \n",
    "    return labels, proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f613a7c9-1cf9-4c1d-8827-e6e0b44e3989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: ('math', 'stat')\n"
     ]
    }
   ],
   "source": [
    "title = \"A new approach to gradient descent methods in high-dimensional optimization\"\n",
    "summary = \"We explore novel convergence properties of adaptive learning rates under nonconvex assumptions...\"\n",
    "\n",
    "predicted = predict_article_labels(title, summary)\n",
    "print(\"Predicted labels:\", predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e397131b-7d22-4496-95f4-b091e05c0c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: ['math', 'stat']\n",
      "astro      → 0.003\n",
      "cond       → 0.001\n",
      "cs         → 0.366\n",
      "econ       → 0.114\n",
      "eess       → 0.009\n",
      "gr         → 0.000\n",
      "hep        → 0.154\n",
      "math       → 0.721\n",
      "nlin       → 0.001\n",
      "nucl       → 0.001\n",
      "physics    → 0.002\n",
      "q          → 0.017\n",
      "quant      → 0.000\n",
      "stat       → 0.560\n"
     ]
    }
   ],
   "source": [
    "labels, probs = predict_article_labels_with_scores(title, summary, threshold=0.4)\n",
    "\n",
    "print(\"Predicted labels:\", labels)\n",
    "for label, p in zip(mlb.classes_, probs):\n",
    "    print(f\"{label:10} → {p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdd9a6-11f8-4860-9768-e998f05634a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pixi Spark",
   "language": "python",
   "name": "pixi-spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
